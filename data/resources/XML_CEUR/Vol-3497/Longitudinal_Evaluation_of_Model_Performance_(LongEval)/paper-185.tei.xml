<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.70,15.42;1,89.29,106.66,415.03,15.42;1,89.29,128.58,331.21,15.43;1,89.29,150.91,220.08,11.96">SEUPD@CLEF: Team JIHUMING on Enhancing Search Engine Performance with Character N-Grams, Query Expansion, and Named Entity Recognition Notebook for the LongEval Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,52.63,11.96"><forename type="first">Isil</forename><surname>Atabek</surname></persName>
							<email>isil.atabek@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,154.56,176.82,66.45,11.96"><forename type="first">Huimin</forename><surname>Chen</surname></persName>
							<email>huimin.chen@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,233.65,176.82,116.46,11.96"><forename type="first">Jesús</forename><surname>Moncada-Ramírez</surname></persName>
							<email>jesus.moncadaramirez@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.75,176.82,69.39,11.96"><forename type="first">Nicolò</forename><surname>Santini</surname></persName>
							<email>nicolo.santini.1@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,190.76,72.65,11.96"><forename type="first">Giovanni</forename><surname>Zago</surname></persName>
							<email>giovanni.zago.3@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,192.94,190.76,60.31,11.96"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<email>ferro@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.70,15.42;1,89.29,106.66,415.03,15.42;1,89.29,128.58,331.21,15.43;1,89.29,150.91,220.08,11.96">SEUPD@CLEF: Team JIHUMING on Enhancing Search Engine Performance with Character N-Grams, Query Expansion, and Named Entity Recognition Notebook for the LongEval Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">7A4FD8239EE93947E41AA0F3450344B5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CLEF 2023</term>
					<term>Information retrieval</term>
					<term>LongEval</term>
					<term>English</term>
					<term>French</term>
					<term>Search Engines</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our group will propose a novel search engine for the Longitudinal Evaluation of Model Performance (LongEval) task at CLEF 2023 <ref type="bibr" coords="1,244.60,267.93,9.63,8.97" target="#b0">[1]</ref>; it will also be the final work of the subject Search Engines at the University of Padova. Our system focuses on the short-term and long-term temporal persistence of the systems' performance, for a collection of both English and French documents. Our approach involves considering both English and French versions of the documents using whitespace tokenization, stopword removal and stemming. We generate character N-grams to identify recurring word structures (as prefixes or suffixes) repeated over documents. We also use query expansion with synonyms (in English) and some Natural Language Processing (NLP) techniques as Named Entity Recognition (NER) to further refine our system. The similarity function utilized in our approach is BM25. Our system was developed in Java and primarily utilized the Lucene library. After extensive experiments on these techniques, we came up with five systems that have produced the best results in terms of MAP and NDCG scores. We analyzed these five selected systems by examining their MAP, NDCG, and Rprec scores on the test data. Additionally, we performed a Two-Way ANOVA to assess the AP of these systems. To compare our systems with each other, we will utilize the Tukey Honestly Significant Difference (HSD) test. In summary, our analysis indicates that incorporating French queries enhances search results, larger N-gram sizes contribute to improved effectiveness, while our NER approach negatively affects the scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This report aims at providing a brief explanation of the Information Retrieval system built as a team project during the Search Engine course 22/23 of the master's degree in Computer Engineering and Data Science at the University of Padua, Italy. As a group in this subject, we are participating in 2023 CLEF LongEval: Longitudinal Evaluation of Model Performance <ref type="bibr" coords="1,492.30,563.69,11.53,10.91" target="#b0">[1]</ref>.</p><p>This annual evaluation campaign focuses on evaluating the temporal persistence of information retrieval (IR) systems and text classifiers.</p><p>The LongEval collection relies on a large set of data provided by Qwant (a commercial privacyfocused search engine that was launched in France in 2013). Their idea regarding the dataset was to reflect changes of the Web across time, providing evolving document and query sets. The train collection <ref type="bibr" coords="2,179.67,168.26,12.89,10.91" target="#b1">[2]</ref> consists of 1,570,734 documents, 672 queries, 98 held-out queries, and 9656 evaluation assessments. The documents were chosen based on queries using the Qwant click model, in addition to random selection from the Qwant index. The queries are categorized into twenty topics, such as: car-related, antivirus-related, employment-related, energy-related, recipe-related, etc. In addition to the original French version, the collection also includes English translations of the documents and queries using the CUBBITT <ref type="bibr" coords="2,360.59,236.01,12.68,10.91" target="#b2">[3]</ref> system. The test collection <ref type="bibr" coords="2,493.30,236.01,12.68,10.91" target="#b3">[4]</ref> for the short-term persistence sub-task was gathered during July 2022, comprising 1,593,376 documents and 882 queries. The test collection for the long-term persistence sub-task was collected in September 2022, containing 1,081,334 documents and 923 queries. We will also use the test collection evaluation assessments <ref type="bibr" coords="2,297.02,290.20,12.93,10.91" target="#b4">[5]</ref> provided for the short-term, long-term and held-out queries.</p><p>The paper is organized as follows: Section 2 introduces related works; Section 3 briefly describes our approach; Section 4 describes our code in detail; Section 5 explains our experimental setup; Section 6 discusses how we selected and which are the five systems submitted to the competition, in addition to an analysis on the test collections and our main findings; finally, Section 7 draws some conclusions and outlooks for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>There are many search engines using different techniques to enhance retrieval effectiveness from which we have taken inspiration from.</p><p>The BM25 <ref type="bibr" coords="2,149.49,484.32,13.00,10.91" target="#b5">[6]</ref> similarity function is widely used information retrieval as it considers term frequencies and document length. This function has demonstrated effectiveness in balancing precision and recall in search results, even if it doesn't consider meta-data document information as other approaches <ref type="bibr" coords="2,178.54,524.97,12.68,10.91" target="#b6">[7]</ref> do. Whitespace tokenization has not been the primary focus of research in any study, anyway, it seems to provide a useful baseline for tokenization. In contrast, E. Gow-Smith et al. <ref type="bibr" coords="2,164.82,552.07,12.68,10.91" target="#b7">[8]</ref> suggests that allowing tokens to include spaces causes problems, especially in architectures including transformers. Token lowercasing is also a recurring method in information retrieval <ref type="bibr" coords="2,161.73,579.17,11.27,10.91" target="#b8">[9]</ref>, mainly because it reduces the vocabulary size. In order to implement BM25 similarity function and tokenization, both for English documents and for French documents, we used whitespace tokenization and lowercasing using libraries provided by Lucene. We implemented the tokenization in order to get advantages in the vocabulary size, using it in each class which implement the analyzer for that specific documents set. While our system adopts whitespace tokenization, we acknowledge these concerns and are open to exploring alternative tokenization methods in future iterations.</p><p>The Terrier <ref type="bibr" coords="3,152.92,100.52,17.79,10.91" target="#b9">[10]</ref> stopword list has been used in plenty of search engines because of the good results if offers working with web documents as blogs <ref type="bibr" coords="3,332.32,114.06,17.91,10.91" target="#b10">[11]</ref> or even recommender systems. For French documents we could not use Terrier stopword list, so we had to find another one <ref type="bibr" coords="3,485.12,127.61,18.03,10.91" target="#b11">[12]</ref>. Stopowords list are stored as .txt files wich we read and use in analyze classes. Each class obviously will read French stopword list if the document set is the French one, otherwise it use the Terrier stopword list.</p><p>Another basic information retrieval technique used in our search engine has been stemming. We have relied on the work of A. G. Jivani et al. <ref type="bibr" coords="3,305.77,208.91,16.26,10.91" target="#b12">[13]</ref> to get an overview of the most adequate stemming techniques for our documents. For the English documents we have chosen a minimal stemmer developed by D. K. Harman <ref type="bibr" coords="3,263.44,236.01,16.41,10.91" target="#b13">[14]</ref>. For the French documents we have also used a minimal stemmer developed by J. Savoy <ref type="bibr" coords="3,277.48,249.56,16.41,10.91" target="#b14">[15]</ref>. Also stemmers are implemented in analyzer classes and are used the minimal stemmers classes provided by Lucene library.</p><p>We have used query expansion <ref type="bibr" coords="3,242.30,290.20,17.98,10.91" target="#b15">[16]</ref> in order to broaden the search scope by including synonyms related to the original query. These synonyms come from WordNet <ref type="bibr" coords="3,438.32,303.75,16.42,10.91" target="#b16">[17]</ref>, a popular lexical database that provides semantic relationships between words.</p><p>We have also included character N-grams of the English and French versions of the documents. Our experiments on character N-grams have been focus on comparing how the value of N can affect to the retrieval effectiveness. Our motivation for this study stemmed from the works of T. Wilson et al. <ref type="bibr" coords="3,224.06,385.05,16.41,10.91" target="#b17">[18]</ref>, and J. Goodman <ref type="bibr" coords="3,325.39,385.05,16.41,10.91" target="#b18">[19]</ref>, which also explored the impact of different N-gram models (among others) on performance. We tried to refine our results including Named Entity Recognition <ref type="bibr" coords="3,231.65,412.15,16.41,10.91" target="#b19">[20]</ref>. This technique has proven useful in other information retrieval systems addressing for example the food <ref type="bibr" coords="3,319.49,425.70,18.07,10.91" target="#b20">[21]</ref> or the archaeology <ref type="bibr" coords="3,429.44,425.70,18.07,10.91" target="#b21">[22]</ref> domain. We implemented character N-gram and NER in separated classes, used only for these scopes. In order to appreciate the results of doing different running and calculate scores for each one, we can choose in the class builder the number N of character. Doing this it is possible to appreciate the performance differences between different values of N. Synonyms are instead implemented only for the English analyzer every time an EnglishAnalyzer is instantiated it try to read and map a synonyms list.</p><p>The work from F. Cai et al. <ref type="bibr" coords="3,228.83,534.09,18.07,10.91" target="#b22">[23]</ref> remarks the importance of understanding query temporal dynamics for search result ranking.By considering the temporal patterns of queries and incorporating query temporal dynamics into the ranking process, search engines can deliver more relevant and timely results.An example of this is giving more weight to recent queries or adjusting the ranking based on a certain popularity during specific time periods. In the context of our task, with changing datasets, learning and estimating query temporal dynamics can be highly relevant.</p><p>The work from K. Hofmann et al. <ref type="bibr" coords="3,255.93,642.48,18.07,10.91" target="#b23">[24]</ref> presents valuable insights into evaluation methodologies for temporal aspects in web search systems. Specifically, the paper explores metrics for evaluating retrieval effectiveness over time, such as precision, recall, F-1 score, and mean average precision (MAP). The paper provides insights into various setups, including time-sliced evaluation, incremental evaluation, and evaluation with simulated temporal queries. These setups can serve as a basis for designing experimental setups that align with specific task requirements. With this motivation we can incorporate evaluation methodologies, metrics, and experimental setups specifically tailored for temporal information retrieval.</p><p>To compare, the work by F. Cai et al. <ref type="bibr" coords="4,270.20,168.26,18.07,10.91" target="#b22">[23]</ref> focuses on learning to estimate query temporal dynamics for web search. Their study aims to understand the temporal patterns of queries and incorporate this knowledge into the ranking process, thereby delivering more relevant and timely search results. This research addresses the importance of considering the temporal aspect of queries to improve retrieval effectiveness.</p><p>On the other hand, the work of K. Hofmann et al. <ref type="bibr" coords="4,317.12,249.56,17.76,10.91" target="#b23">[24]</ref> concentrates on evaluating web search systems while considering the dimension of time. Their paper explores evaluation methodologies specifically tailored to temporal aspects, such as time-sliced evaluation, incremental evaluation, and evaluation with simulated temporal queries. By proposing and examining these evaluation setups, the authors provide insights into assessing the performance of search engines in a temporal context.</p><p>When comparing the work of F. Cai et al. <ref type="bibr" coords="4,288.19,344.40,17.97,10.91" target="#b22">[23]</ref> and K. Hofmann et al. <ref type="bibr" coords="4,409.86,344.40,16.31,10.91" target="#b23">[24]</ref>, it is evident that they address different aspects of temporal information retrieval. While F. Cai et al. focus on learning and estimating query temporal dynamics, K. Hofmann et al. concentrate on evaluating the effectiveness of search systems over time. Both papers contribute to the field of temporal information retrieval by providing novel insights and methodologies.</p><p>In the context of our search engine, we acknowledge the importance of understanding query temporal dynamics, as emphasized by F. Cai et al. <ref type="bibr" coords="4,308.43,439.25,16.09,10.91" target="#b22">[23]</ref>. By considering the temporal patterns of queries and incorporating them into our ranking process, we strive to deliver more relevant and timely search results. Furthermore, the evaluation methodologies presented by K. Hofmann et al. <ref type="bibr" coords="4,102.93,479.89,18.22,10.91" target="#b22">[23]</ref> serve as a valuable reference for assessing the performance of our search engine in a temporal context. While our specific implementations and techniques may differ, the underlying principles and motivations align with the contributions of these referenced papers in the field of temporal information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Our search engine can be divided into the following parts: parsing of the documents and queries, indexing, text processing (analyzers), and run generation (effective search). Document parsing was performed using the JSON version of the documents. On the other hand, query parsing was based on an XML parser devloped by us.</p><p>In the index, we decided to include four fields: (1) the (processed) English version of the documents, (2) the (processed) French version, (3) character N-grams of both versions concatenated, and (4) some NER information extracted from the French (original) version. As similarity function we have used BM25 <ref type="bibr" coords="5,222.92,127.61,12.99,10.91" target="#b5">[6]</ref> as it takes into account both term frequency and document length.</p><p>The text in the fields of our indexes must first be processed, for this we have developed four different analyzers. The English analyzer is based on whitespace tokenization, breaking of words and numbers based on special characters, lowercasing, applying the Terrier stopword list, query expansion with synonyms based on the WordNet synonym map <ref type="bibr" coords="5,398.88,208.91,16.08,10.91" target="#b24">[25]</ref>, and stemming. The French analyzer is based on whitespace tokenization, breaking of words and numbers based on special characters, lowercasing, applying a French stopword list <ref type="bibr" coords="5,367.61,236.01,17.76,10.91" target="#b25">[26]</ref> and stemming. To generate the character N-grams we consider only the letters of the documents (i.e. we discard numbers and punctuation). To perform NER we apply NLP techniques based on Apache OpenNLP <ref type="bibr" coords="5,486.90,263.11,16.23,10.91" target="#b26">[27]</ref>, specifically, we used NER applied to locations, person names and organizations.</p><p>We conducted some experiments to generate the runs, i.e., we have tried different combinations of the explained techniques. Thus, our searcher will always use BM25 <ref type="bibr" coords="5,425.90,317.30,11.39,10.91" target="#b5">[6]</ref>, but the rest of characteristics will depend on the run it is generating. See Section 5 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">System Architecture</head><p>In this section, we address the technical aspects of how our system was developed following the structure (in packages) of the repository <ref type="bibr" coords="5,287.88,403.03,16.25,10.91" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Parsing</head><p>To generate an index from the provided documents, we parse them by extracting their text into Java data structures. Our parser package is based on the JSON version of the documents, allowing easy manipulation and querying using various tools and libraries. We implemented a streaming parser using the Gson library in Java.</p><p>The whole parser is made up of the following classes:</p><p>• DocumentParser: An abstract class that represents a streaming parser and implements</p><p>Iterator and Iterable.</p><p>• JsonDocument: a Java POJO for the deserialization of JSON documents.</p><p>• ParsedDocument: Represents a parsed document, containing an identifier and a body.</p><p>• LongEvalParser: Implements the DocumentParser class and handles the streaming logic. Objects of this class can be used as iterators to yield parsed documents</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Analyzer</head><p>To process the parsed document text, we developed our own Lucene analyzers. Each analyzer follows a typical workflow involving a Tokenizer and a list of TokenFilter for a TokenStream To process the already parsed documents' text, we have implemented our own Lucene analyzers. All of them follow the typical workflow: use a Tokenizer and a list of TokenFilter to a TokenStream.</p><p>The project's final version creates an index with four fields for each document, requiring four different analyzers. The AnalyzerUtildescribed below utilize functionalities from the AnalyzerUtil helper class developed by Nicola Ferro.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">English body field</head><p>The processing applied to the English version of the documents (using the EnglishAnalyzer class) includes:</p><p>1. Tokenize based on whitespaces.</p><p>2. Eliminate some strange characters found in the documents. It is unlikely that a user would perform a query including these characters.</p><p>3. Removal of punctuation marks at the beginning and end of words since whitespace tokenization is used.</p><p>4. Application of the WordDelimiterGraphFilter Lucene filter to split words into subwords based on case, divide numbers, concatenate numbers with special characters, and remove English possessive trailing "s. ".</p><p>5. Lowercase all the tokens.</p><p>6. Apply the Terrier <ref type="bibr" coords="6,196.67,481.65,17.91,10.91" target="#b9">[10]</ref> stopword list.</p><p>7. Apply query expansion with synonyms using the SynonymTokenFilter from Lucene, based on the WordNet synonym map <ref type="bibr" coords="6,284.76,517.71,16.25,10.91" target="#b24">[25]</ref>.</p><p>8. Apply minimal stemming using the EnglishMinimalStemFilterfrom Lucene.</p><p>9. Removal of empty tokens left by previous filters using a custom EmptyTokenFilter</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">French body field</head><p>The processing of French documents (in the class FrenchAnalyzer is identical to the processing of English documents in the first 5 points (excluding the English possessives' removal in 4.d).</p><p>For this point on, we apply:</p><p>6. Apply a French stopword list <ref type="bibr" coords="6,248.17,661.68,16.25,10.91" target="#b25">[26]</ref>.</p><p>7. Apply a minimal stemming process (in French) using FrenchMinimalStemFilter from Lucene.</p><p>8. Removal of empty tokens (EmptyTokenFilter).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Character N-grams</head><p>Character N-grams are created using the NGramAnalyzer class, which performs the following operations:</p><p>1. Tokenize based on whitespaces.</p><p>2. Lowercase all the tokens.</p><p>3. Removal of all characters except letters (including French accent letters).</p><p>4. Removal of empty tokens EmptyTokenFilter.</p><p>5. Generate character N-grams using NGramTokenFilter from Lucene.</p><p>The value of N has not been fixed in order to allow for the generation of different experiments. See Section 5 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4.">NER extracted information</head><p>The NER information has been extracted using the Apache OpenNLP <ref type="bibr" coords="7,403.08,381.86,18.00,10.91" target="#b26">[27]</ref> library. As Lucene does not include these functionalities directly, we have used a modified version of a token filter developed by Nicola Ferro based on the mentioned library, (OpenNLPNERFilter).</p><p>The processing of the tokens in this analyzer (NERAnalyzer) is the following:</p><p>1. Tokenization using the StandardTokenizer from Lucene.</p><p>2. NER tagging using a model for locations.</p><p>3. NER tagging using a model for person names.</p><p>4. NER tagging using a model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Index</head><p>Initially, we developed a DirectoryIndexer to handle single-language documents (English or French). However, when considering both versions, we deprecated it in favor of the final</p><p>MultilingualDirectoryIndexer.</p><p>The MultilingualDirectoryIndexer is used for indexing multilingual documents and obtaining basic vocabulary statistics. To create an instance, parameters such as document directory paths, index directory path, expected document count, and custom analyzers (English-Analyzer, FrenchAnalyzer, NGramAnalyzer, and NERAnalyzer) are required. Additionally, the chosen similarity function (BM25) and the RAM buffer size for indexing must be specified.</p><p>During indexing, the MultilingualDirectoryIndexer reads documents from the English and French directories, processes them with the specified analyzers, and creates an inverted index. Both directories must contain the same number of files and documents with matching IDs. Each iteration combines the English and French versions of the same document into a single Lucene document in the index.</p><p>After indexing, we utilize a method to print vocabulary statistics, including unique terms, total terms, and frequency lists for English and French. This provides a useful overview for analysis and optimization of the search system. The indexer also estimates the remaining time required for indexing, addressing the time-consuming nature of the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Search</head><p>The Searcher class in the search package performs effective searches by applying the specified analyzers to the query title and matching it with the corresponding index fields. The QueryParser class from Lucene is utilized for this process. The search is conducted using the BM25 similarity function. Users can specify the index path, topics file path, number of expected topics, run descriptor, and the maximum number of documents to retrieve (1000). A user-friendly menu allows the selection of desired runs and distinguishes between train and test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Topic</head><p>To read queries (in TREC format) we developed our own LongEval topic reader (LongEvalTopicReader) in the topic package. It consists of the LongEvalTopic and LongEvalTopicReader classes. The LongEvalTopic represents each query with a number (&lt;num&gt;) and a title (&lt;title&gt;), serving as the equivalent of QualityQuery in TrecTopicsReader. The LongEvalTopicReader parses the query file as an XML file using the Java XML library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results Analysis</head><p>In this section, we first present the runs that achieved the highest and lowest scores on the train and test data. Subsequently, we provide an interpretation and analysis of these score values (see Section 6.5). Similarly, the highest NDCG score (0.3285) belongs to 10_fr_fr_5gram, followed by 09_fr_fr_4gram (0.3269), 08_fr_fr_3gram (0.3208), 07_fr_fr (0.3135), and 12_fr_fr_4gram_ner (0.2881). The lowest NDCG score (0.1098) corresponds to en_en_4gram_ner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Training Data and Selection of Runs to Submit</head><p>Because of this, the five system submitted to CLEF have been (in order of importance): 10_fr_fr_5gram, 09_fr_fr_4gram, 08_fr_fr_3gram, 07_fr_fr, and 12_fr_fr_4gram_ner. Following the competition workflow, we created new indexes based on the test collection and re-executed this top five runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Short Term Test Data</head><p>Table <ref type="table" coords="12,116.25,642.48,5.17,10.91" target="#tab_1">2</ref> presents the mentioned scores computed for our five submitted systems on the (test) short-term collection.</p><p>In the Two-Way ANOVA analysis presented in Table <ref type="table" coords="13,337.59,86.97,5.08,10.91" target="#tab_2">3</ref> we observed a significant p-value (p &lt; 0.05). Thus, we can conclude that there are significant differences among our systems. As ANOVA does not tell which systems are significantly different from each other, in Table <ref type="table" coords="13,485.15,114.06,5.10,10.91" target="#tab_3">4</ref> we can observe the Tukey's Honestly Significantly Differenced (HSD) test. It suggests that pairwise comparisons between systems 7-12, 8-12, 9-12 and 10-12 reject null hypothesis (p &lt; 0.05) and indicate statistical significant differences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Long Term Test Data</head><p>Table <ref type="table" coords="13,116.25,642.48,5.17,10.91" target="#tab_4">5</ref> presents the mentioned scores computed for our five submitted systems on the (test) long-term collection.</p><p>In the Two-Way ANOVA analysis presented in Table <ref type="table" coords="14,344.68,86.97,5.17,10.91" target="#tab_5">6</ref> we observed a significant p-value (p &lt; 0.05), so we can conclude that there are significant differences among our systems. The Tukey's Honestly Significantly Differenced (HSD) test in Table <ref type="table" coords="14,371.60,114.06,5.09,10.91" target="#tab_6">7</ref> again suggests that pairwise comparisons between systems 7-12, 8-12, 9-12 and 10-12 reject null hypothesis (p &lt; 0.05). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Held Out Test Data</head><p>Table <ref type="table" coords="14,117.16,615.39,5.17,10.91" target="#tab_7">8</ref> presents mentioned scores computed for our five submitted systems on the (train) held-out collection.</p><p>In the Two-Way ANOVA analysis presented in Table <ref type="table" coords="14,330.86,656.03,4.97,10.91" target="#tab_8">9</ref> we didn't observe a significant p-value (p &gt;= 0.05), so we can conclude that there are not significant differences among our systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Discussion</head><p>Results suggest that French queries perform better than their English counterparts, possibly due to the training data's French origin and later translation into English. Moreover, the IR system's effectiveness generally increases with a larger N-gram size, as indicated by the scores of 04_en_en_5gram and 10_fr_fr_5gram. Conversely, the inclusion of NER in the indexing process seems to have a negative impact on the scores, as shown by the lower scores of 06_en_en_4gram_ner and 12_fr_fr_4gram_ner. The use of query expansion with synonyms in English does not seem to improve the search results to any great extent.</p><p>It's interesting to notice that the cross-language approaches (05_en_en_fr_5gram and 1_fr_en_fr_5gram) are out of the five bests systems. It turns out that searching for English words in French documents and vice versa messes up the search, lowering the score. Another interesting aspect is that the worst-performing index is the one with named entity recognition in English (06_en_en_4gram_ner): it combines translated queries and NER, which appears to be the two worst-performing approaches.</p><p>Our findings indicate that the MAP and NDCG scores in the training data closely align with those in the test data. Interestingly, there are instances where the scores in the test data show improvement compared to the training data. Thus, according to the test data, the ranking of our best-performing systems is the same as in Section 6.1 (in order of importance): 10_fr_fr_5gram, 09_fr_fr_4gram, 08_fr_fr_3gram, 07_fr_fr, and 12_fr_fr_4gram_ner.</p><p>Based on the ANOVA analysis, the null hypothesis is only not rejected in the runs on the held-out collection, suggesting no statistically significant difference. We attribute this finding to the limited number of queries in that particular collection. However, in cases where a statistical significant difference exists among the systems, it appears that system number 12 (12_fr_fr_4gram_ner) is the only one with a significant impact. This aligns with our expectations since system number 12 is the only submission utilizing NER among the others.</p><p>In general, we focused on trying multiple approaches, this is why our score has such a big space for improvement. As already said, French queries with bigger N-gram perform better. In this system, instead of relying on single-word matches, the queries take place with more context, resulting in better search results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>In summary, the IR systems developed in this study followed the Parsing-Analyzer-Index-Search-Topic paradigm and utilized different methodologies, among which the following stand out: processing of English documents based on whitespace tokenization, the TERRIER stopword list, query expansion, and stemming; processing of French documents based on whitespace tokenization, a stopword list and stemming; character N-grams of both versions concatenated; and NER information extraction using NLP techniques.</p><p>In terms of future work, there are several areas that could be explored to improve the effectiveness of the developed IR systems. Firstly, we could improve indexing methodologies, such as increasing the value of N in N-gram, as we have commented on in Section 6. Secondly, we could explore better NLP techniques to improve the accuracy of the IR systems, as NER turns out not to be very effective.</p><p>Overall results suggests we did not achieve the best possible results, since we preferred to explore multiple simple approaches rather than a single complex one. In most cases ANOVA results shows that we don't have a significant difference between the systems, so that we could start from any of them and improve.</p><p>One last possible future work could be a machine-learning based IR system. This would be a more dynamic approach to IR systems, as it would be able to adapt to different types of queries and documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="12,88.99,202.34,418.19,266.29"><head>Table 1</head><label>1</label><figDesc>MAP and NCDG scores for all the runs on the training collection</figDesc><table coords="12,89.29,230.38,417.89,238.25"><row><cell>Run ID</cell><cell>Run</cell><cell cols="2">MAP Score NCDG Score</cell></row><row><cell>01</cell><cell>en_en</cell><cell>0.0700</cell><cell>0.1614</cell></row><row><cell>02</cell><cell>en_en_3gram</cell><cell>0.0704</cell><cell>0.1661</cell></row><row><cell>03</cell><cell>en_en_4gram</cell><cell>0.0874</cell><cell>0.2025</cell></row><row><cell>04</cell><cell>en_en_5gram</cell><cell>0.1028</cell><cell>0.2288</cell></row><row><cell>05</cell><cell>en_en_fr_5gram</cell><cell>0.0669</cell><cell>0.1525</cell></row><row><cell>06</cell><cell>en_en_4gram_ner</cell><cell>0.0360</cell><cell>0.1098</cell></row><row><cell>07</cell><cell>fr_fr</cell><cell>0.1656</cell><cell>0.3135</cell></row><row><cell>08</cell><cell>fr_fr_3gram</cell><cell>0.1698</cell><cell>0.3208</cell></row><row><cell>09</cell><cell>fr_fr_4gram</cell><cell>0.1737</cell><cell>0.3269</cell></row><row><cell>10</cell><cell>fr_fr_5gram</cell><cell>0.1748</cell><cell>0.3285</cell></row><row><cell>11</cell><cell>fr_en_fr_5gram</cell><cell>0.1288</cell><cell>0.2797</cell></row><row><cell>12</cell><cell>fr_fr_4gram_ner</cell><cell>0.1362</cell><cell>0.2881</cell></row><row><cell cols="4">The analysis shows that, on training data, the highest MAP score (0.1748) is achieved</cell></row><row><cell cols="4">by 10_fr_fr_5gram, followed by 09_fr_fr_4gram (0.1737), 08_fr_fr_3gram (0.1698),</cell></row><row><cell cols="4">07_fr_fr (0.1656), and 12_fr_fr_4gram_ner (0.1362). The lowest MAP score (0.0360) is</cell></row><row><cell cols="2">obtained by en_en_4gram_ner.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="13,88.99,182.19,367.46,101.12"><head>Table 2</head><label>2</label><figDesc>MAP, NCDG and Rprec scores for the submitted runs on the (test) short-term collection</figDesc><table coords="13,138.82,210.23,317.63,73.08"><row><cell>Run ID</cell><cell>Run</cell><cell cols="3">NCDG Score MAP Score RPREC Score</cell></row><row><cell>07</cell><cell>fr_fr</cell><cell>0.3367</cell><cell>0.1883</cell><cell>0.1561</cell></row><row><cell>08</cell><cell>fr_fr_3gram</cell><cell>0.3384</cell><cell>0.1893</cell><cell>0.1579</cell></row><row><cell>09</cell><cell>fr_fr_4gram</cell><cell>0.3423</cell><cell>0.1911</cell><cell>0.1581</cell></row><row><cell>10</cell><cell>fr_fr_5gram</cell><cell>0.3447</cell><cell>0.1926</cell><cell>0.1603</cell></row><row><cell>12</cell><cell>fr_fr_4gram_ner</cell><cell>0.2980</cell><cell>0.1468</cell><cell>0.1172</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="13,88.99,324.06,401.54,76.42"><head>Table 3</head><label>3</label><figDesc>Two-Way ANOVA table assessing AP for the submitted systems on the (test) short-term collection</figDesc><table coords="13,161.20,352.10,272.89,48.38"><row><cell>Source</cell><cell>DF</cell><cell>SS</cell><cell>MS</cell><cell>F</cell><cell>PR(&gt;F)</cell></row><row><cell cols="2">C(system) 4</cell><cell>1.348254</cell><cell cols="3">0.337063 6.250613 0.000052</cell></row><row><cell>Error</cell><cell cols="4">4405 237.539013 0.053925 -</cell><cell>-</cell></row><row><cell>Total</cell><cell cols="3">4409 238.887267 -</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,88.99,429.27,417.00,162.88"><head>Table 4</head><label>4</label><figDesc>Tukey Honestly Significant Difference test for the submitted systems on the (test) short-term collection</figDesc><table coords="13,98.95,457.31,397.38,134.84"><row><cell>Run 1</cell><cell>Run 2</cell><cell>Diff</cell><cell>Lower</cell><cell>Upper</cell><cell>q-value p-value</cell></row><row><cell>07_fr_fr</cell><cell>08_fr_fr_3gram</cell><cell cols="4">0.000986 -0.029190 0.031162 0.126122 0.900000</cell></row><row><cell>07_fr_fr</cell><cell>09_fr_fr_4gram</cell><cell cols="4">0.002808 -0.027368 0.032984 0.359124 0.900000</cell></row><row><cell>07_fr_fr</cell><cell>10_fr_fr_5gram</cell><cell cols="4">0.004282 -0.025894 0.034458 0.547611 0.900000</cell></row><row><cell>07_fr_fr</cell><cell cols="5">12_fr_fr_4gram_ner 0.041538 0.011362 0.071714 5.312288 0.001641</cell></row><row><cell cols="2">08_fr_fr_3gram 09_fr_fr_4gram</cell><cell cols="4">0.001822 -0.028354 0.031998 0.233002 0.900000</cell></row><row><cell cols="2">08_fr_fr_3gram 10_fr_fr_5gram</cell><cell cols="4">0.003296 -0.026880 0.033472 0.421489 0.900000</cell></row><row><cell cols="6">08_fr_fr_3gram 12_fr_fr_4gram_ner 0.042524 0.012348 0.072700 5.438410 0.001152</cell></row><row><cell cols="2">09_fr_fr_4gram 10_fr_fr_5gram</cell><cell cols="4">0.001474 -0.028702 0.031650 0.188487 0.900000</cell></row><row><cell cols="6">09_fr_fr_4gram 12_fr_fr_4gram_ner 0.044346 0.014170 0.074522 5.671412 0.001000</cell></row><row><cell cols="6">10_fr_fr_5gram 12_fr_fr_4gram_ner 0.045820 0.015644 0.075995 5.859899 0.001000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="14,88.99,155.09,367.46,101.12"><head>Table 5</head><label>5</label><figDesc>MAP, NCDG and Rprec scores for the submitted runs on the (test) long-term collection</figDesc><table coords="14,138.82,183.13,317.63,73.08"><row><cell>Run ID</cell><cell>Run</cell><cell cols="3">NCDG Score MAP Score RPREC Score</cell></row><row><cell>07</cell><cell>fr_fr</cell><cell>0.3447</cell><cell>0.1880</cell><cell>0.1589</cell></row><row><cell>08</cell><cell>fr_fr_3gram</cell><cell>0.3454</cell><cell>0.1881</cell><cell>0.1600</cell></row><row><cell>09</cell><cell>fr_fr_4gram</cell><cell></cell><cell>0.1888</cell><cell>0.1611</cell></row><row><cell>10</cell><cell>fr_fr_5gram</cell><cell>0.3533</cell><cell>0.1920</cell><cell>0.1642</cell></row><row><cell>12</cell><cell>fr_fr_4gram_ner</cell><cell>0.3046</cell><cell>0.1433</cell><cell>0.1192</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="14,88.99,296.96,398.05,76.42"><head>Table 6</head><label>6</label><figDesc>Two-Way ANOVA table assessing AP for the submitted systems on the (test) long-term collection</figDesc><table coords="14,161.49,325.00,272.30,48.38"><row><cell>Source</cell><cell>DF</cell><cell>SS</cell><cell>MS</cell><cell>F</cell><cell>PR(&gt;F)</cell></row><row><cell cols="2">C(system) 4</cell><cell>1.564386</cell><cell cols="3">0.391097 8.562506 7.01E-07</cell></row><row><cell>Error</cell><cell cols="2">4610 210.56392</cell><cell cols="2">0.045675 -</cell><cell>-</cell></row><row><cell>Total</cell><cell cols="3">4614 212.128306 -</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="14,88.99,402.17,416.99,162.88"><head>Table 7</head><label>7</label><figDesc>Tukey Honestly Significant Difference test for the submitted systems on the (test) long-term collection</figDesc><table coords="14,98.95,430.21,397.38,134.84"><row><cell>Run 1</cell><cell>Run 2</cell><cell>Diff</cell><cell>Lower</cell><cell>Upper</cell><cell>q-value p-value</cell></row><row><cell>07_fr_fr</cell><cell>08_fr_fr_3gram</cell><cell cols="4">0.000340 -0.026808 0.027488 0.048345 0.900000</cell></row><row><cell>07_fr_fr</cell><cell>09_fr_fr_4gram</cell><cell cols="4">0.001090 -0.026058 0.028237 0.154891 0.900000</cell></row><row><cell>07_fr_fr</cell><cell>10_fr_fr_5gram</cell><cell cols="4">0.004239 -0.022909 0.031387 0.602592 0.900000</cell></row><row><cell>07_fr_fr</cell><cell cols="5">12_fr_fr_4gram_ner 0.044458 0.017311 0.071606 6.319943 0.001000</cell></row><row><cell cols="2">08_fr_fr_3gram 09_fr_fr_4gram</cell><cell cols="4">0.000750 -0.026398 0.027897 0.106546 0.900000</cell></row><row><cell cols="2">08_fr_fr_3gram 10_fr_fr_5gram</cell><cell cols="4">0.003899 -0.023249 0.031047 0.554247 0.900000</cell></row><row><cell cols="6">08_fr_fr_3gram 12_fr_fr_4gram_ner 0.044798 0.017651 0.071946 6.368287 0.001000</cell></row><row><cell cols="2">09_fr_fr_4gram 10_fr_fr_5gram</cell><cell cols="4">0.003149 -0.023998 0.030297 0.447701 0.900000</cell></row><row><cell cols="6">09_fr_fr_4gram 12_fr_fr_4gram_ner 0.045548 0.018400 0.072696 6.474833 0.001000</cell></row><row><cell cols="6">10_fr_fr_5gram 12_fr_fr_4gram_ner 0.048697 0.021550 0.075845 6.922534 0.001000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="15,88.99,90.49,410.37,101.12"><head>Table 8</head><label>8</label><figDesc>MAP, NCDG and Rprec scores the submitted runs on the training collection, held-out evaluation</figDesc><table coords="15,138.82,118.53,317.63,73.08"><row><cell>Run ID</cell><cell>Run</cell><cell cols="3">NCDG Score MAP Score RPREC Score</cell></row><row><cell>07</cell><cell>fr_fr</cell><cell>0.3271</cell><cell>0.1746</cell><cell>0.1397</cell></row><row><cell>08</cell><cell>fr_fr_3gram</cell><cell>0.3307</cell><cell>0.1725</cell><cell>0.1326</cell></row><row><cell>09</cell><cell>fr_fr_4gram</cell><cell>0.3364</cell><cell>0.1763</cell><cell>0.1397</cell></row><row><cell>10</cell><cell>fr_fr_5gram</cell><cell>0.3413</cell><cell>0.1788</cell><cell>0.1385</cell></row><row><cell>12</cell><cell>fr_fr_4gram_ner</cell><cell>0.2868</cell><cell>0.1369</cell><cell>0.1004</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="15,88.99,223.46,341.76,76.42"><head>Table 9</head><label>9</label><figDesc>Two-Way ANOVA table assessing AP on the training collection, held-out evaluation</figDesc><table coords="15,165.83,251.50,263.62,48.38"><row><cell>Source</cell><cell cols="2">DF SS</cell><cell>MS</cell><cell>F</cell><cell>PR(&gt;F)</cell></row><row><cell cols="2">C(system) 4</cell><cell>0.11896</cell><cell>0.02974</cell><cell cols="2">0.689161 0.599712</cell></row><row><cell>Error</cell><cell cols="4">485 20.929668 0.043154 -</cell><cell>-</cell></row><row><cell>Total</cell><cell cols="3">489 21.048628 -</cell><cell>-</cell><cell>-</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Setup</head><p>In this section, we describe the experimental setup employed in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Hardware and Software Environment</head><p>All the code and documentation related to the project were developed and stored in the group's repository (https://bitbucket.org/upd-dei-stud-prj/seupd2223-jihuming/src/master/) <ref type="bibr" coords="8,465.05,619.95,16.29,10.91" target="#b27">[28]</ref>. The repository, hosted on Bitbucket, provided a centralized location for accessing and managing the project's source code and documentation.</p><p>The development and experimentation phases of the project were conducted using personal computers. The specific software tools and versions used included Java JDK version 17, Apache version 2, Lucene version 9.5, and Maven. These tools and versions were employed to facilitate the implementation and execution of the experimental systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Evaluation Metrics</head><p>We computed the Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG) scores for all our systems' runs on the collection. These scores were used to select the top five systems to be submitted to CLEF. Additionally, MAP, NDCG, and Precision at the Recall base (Rprec) scores were computed for the submitted systems' runs on the test (short-term and long-term) and held-out collections. These metrics provided a reliable estimation of the final performance of our systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Statistical Analysis</head><p>We performed a statistical analysis using Two-Way ANOVA to assess the Average Precision (AP) of the five submitted systems across all the topics on the test and held-out collections. Furthermore, pairwise comparisons of the submitted systems were conducted using the Tukey Honestly Significant Difference (HSD) test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Indexes</head><p>In order to do different run experiments, our team has created several indexes from each of the provided collections (train, short-term test, and long-term test). Put simply, certain indexes mentioned in this report incorporate only a few of the characteristics discussed, while others encompass all the characteristics outlined in the definitive version of the project.</p><p>All the created indexes are multilingual, which allows us to take full advantage of the (bilingual) data collection. Additionally, we did some experiments with character N-grams generating different versions of indexes with 3-grams, 4-grams and 5-grams; the motivation was to compare how this parameter affects to the effectiveness of our systems. 3-grams are able to collecting more local information in our documents, while 4-grams and 5-grams are more open to the context. An additional functionality of some indexes is query expansion, but as commented, this is only applied to the English body. One index includes Named Entity Recognition which provides not only the search for keywords but also identifying and extracting specific named entities. The subsequent indexes are:</p><p>• multilingual_3gram: both languages of documents, using character 3-grams.</p><p>• multilingual_3gram_synonym: both languages, character 3-grams, (English) query expansion with synonyms.</p><p>• multilingual_4gram_synonym: both languages, character 4-grams, (English) query expansion with synonyms.</p><p>• multilingual_5gram_synonym: both languages, character 5-grams, (English) query expansion with synonyms.</p><p>• multilingual_4gram_synonym_ner: both languages, character 4-grams, (English) query expansion with synonyms, NER techniques.</p><p>The indexes also can be found in the following Google Drive folder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Runs</head><p>After creating the indexes, we were able to conduct multiple runs to evaluate the effectiveness of our system. These runs not only experiment with some techniques specified here, but also consider different versions (English or French) of the queries. With them, we can compare and analyze different aspects of our system's performance, such as precision and recall. The runs are the following:</p><p>• seupd2223-JIHUMING-01_en_en: English topics; using English body field.</p><p>• seupd2223-JIHUMING-02_en_en_3gram: English topics; using English body field and 3-gram field.</p><p>• seupd2223-JIHUMING-03_en_en_4gram: English topics; using English body field and 4-gram field.</p><p>• seupd2223-JIHUMING-04_en_en_5gram: English topics; using English body field and 5-gram field.</p><p>• seupd2223-JIHUMING-05_en_en_fr_5gram: English topics; using English and French body fileds and 5-gram field.</p><p>• seupd2223-JIHUMING-06_en_en_4gram_ner: English topics; using English body field, 4-gram field and NER information field.</p><p>• seupd2223-JIHUMING-07_fr_fr: French topics; using French body field.</p><p>• seupd2223-JIHUMING-08_fr_fr_3gram: French topics; using French body field and 3-gram field.</p><p>• seupd2223-JIHUMING-09_fr_fr_4gram: French topics; using French body field and 4-gram field.</p><p>• seupd2223-JIHUMING-10_fr_fr_5gram: French topics; using French body field and 5-gram field.</p><p>• seupd2223-JIHUMING-11_fr_en_fr_5gram: French topics; using English and French body fields and 5-gram field.</p><p>• seupd2223-JIHUMING-12_fr_fr_4gram_ner: French topics; using French body field, 4-gram field and NER information field.</p><p>The process of creating the indexes typically took around 1 hour, except the indexes that included NER, which took approximately 16 hours. On the other hand, generating the runs was a much quicker process, taking consistently less than a minute and a half to complete.</p><p>The mentioned analysis of the runs on the training collection will take place in Section 6.1. The analysis of the runs on the test collection will take place in Section 6.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="16,112.66,583.60,328.89,10.91" xml:id="b0">
	<monogr>
		<ptr target="https://clef-longeval.github.io/" />
		<title level="m" coord="16,112.66,583.60,158.12,10.91">LongEval CLEF 2023 Lab</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>CLEF2023</note>
</biblStruct>

<biblStruct coords="16,112.66,597.15,394.53,10.91;16,112.66,610.69,394.53,10.91;16,112.66,624.24,393.33,10.91;16,112.33,637.79,286.84,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuščáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Devaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-5010,LINDAT/CLARIAH" />
		<title level="m" coord="16,163.81,610.69,117.90,10.91">LongEval train collection</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,651.34,395.17,10.91;16,112.66,664.89,393.60,10.91;17,112.66,86.97,394.62,10.91;17,112.31,100.52,390.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="16,478.05,651.34,29.79,10.91;16,112.66,664.89,393.60,10.91;17,112.66,86.97,155.95,10.91">Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tomkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tomek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Žabokrtský</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-18073-9</idno>
		<ptr target="https://www.nature.com/articles/s41467-020-18073-9.doi:10.1038/s41467-020-18073-9" />
	</analytic>
	<monogr>
		<title level="j" coord="17,276.89,86.97,109.29,10.91">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,114.06,394.53,10.91;17,112.66,127.61,394.53,10.91;17,112.66,141.16,393.33,10.91;17,112.33,154.71,286.84,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuščáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Devaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-5139,LINDAT/CLARIAH" />
		<title level="m" coord="17,165.44,127.61,113.92,10.91">LongEval test collection</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,168.26,394.52,10.91;17,112.66,181.81,394.03,10.91;17,112.41,195.36,393.57,10.91;17,112.66,208.91,337.98,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuščáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Devaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-5151,LINDAT/CLARIAH" />
		<title level="m" coord="17,112.66,181.81,218.77,10.91">LongEval click-model relevance judgements (qrels)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,222.46,394.61,10.91;17,112.33,236.01,143.43,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
		<title level="m" coord="17,423.89,222.46,64.18,10.91;17,112.33,236.01,113.17,10.91">Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>Okapi at trec-3</note>
</biblStruct>

<biblStruct coords="17,112.66,249.56,64.44,10.91;17,200.78,249.56,306.41,10.91;17,112.66,263.11,394.61,10.91;17,112.66,276.66,393.16,10.91;17,112.66,290.20,261.43,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="17,200.78,249.56,301.15,10.91">The Probabilistic Relevance Framework: BM25 and Beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<ptr target="http://scholar.google.de/scholar.bib?q=info:U4l9kCVIssAJ:scholar.google.com/&amp;output=citation&amp;hl=de&amp;as_sdt=2000&amp;as_vis=1&amp;ct=citation&amp;cd=1" />
	</analytic>
	<monogr>
		<title level="j" coord="17,112.66,263.11,262.89,10.91">Foundations and Trends® in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,303.75,393.61,10.91;17,112.66,317.30,265.00,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gow-Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Madabushi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.04058</idno>
		<title level="m" coord="17,386.82,303.75,119.45,10.91;17,112.66,317.30,135.06,10.91">Improving tokenisation by alternative treatment of spaces</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,330.85,395.17,10.91;17,112.66,344.40,394.04,10.91;17,112.66,357.95,146.75,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<ptr target="http://nlp.stanford.edu/IR-book/information-retrieval-book.html" />
		<title level="m" coord="17,304.83,330.85,170.13,10.91">Introduction to Information Retrieval</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,371.50,393.33,10.91;17,112.66,385.05,394.53,10.91;17,112.14,398.60,393.85,10.91;17,112.66,412.15,122.38,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,431.79,371.50,74.20,10.91;17,112.66,385.05,254.82,10.91">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,189.87,398.60,316.11,10.91;17,112.66,412.15,39.83,10.91">Proc. of the ACM SIGIR 2006 Workshop on Open Source Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Beigbeder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Buntine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Yee</surname></persName>
		</editor>
		<meeting>of the ACM SIGIR 2006 Workshop on Open Source Information Retrieval<address><addrLine>OSIR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,425.70,394.62,10.91;17,112.66,439.25,282.40,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<ptr target="https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=905208" />
		<title level="m" coord="17,280.09,425.70,169.58,10.91">Overview of the trec-2009 blog track</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,452.79,394.04,10.91;17,112.66,466.34,133.30,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><surname>Genediazjr</surname></persName>
		</author>
		<ptr target="https://github.com/stopwords-iso/stopwords-fr/blob/master/stopwords-fr.txt" />
		<title level="m" coord="17,164.09,452.79,80.44,10.91">Stopwords French</title>
		<meeting><address><addrLine>FR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,479.89,393.33,10.91;17,112.66,493.44,86.28,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="17,195.49,479.89,197.03,10.91">A comparative study of stemming algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Jivani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,400.97,479.89,105.02,10.91">Int. J. Comp. Tech. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1930" to="1938" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,506.99,343.45,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="17,180.04,506.99,115.69,10.91">How effective is suffixing?</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,303.79,506.99,83.61,10.91">J. Am. Soc. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,520.54,395.00,10.91;17,112.66,534.09,116.91,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="17,153.41,520.54,298.11,10.91">A stemming procedure and stopword list for general french corpora</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,460.05,520.54,47.61,10.91;17,112.66,534.09,32.98,10.91">J. Am. Soc. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="944" to="952" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,547.64,393.61,10.91;17,112.33,561.19,114.13,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="17,190.97,547.64,70.11,10.91">Query expansion</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,273.24,547.64,233.03,10.91;17,117.37,561.19,30.23,10.91">Annual review of information science and technology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="121" to="187" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>ARIST)</note>
</biblStruct>

<biblStruct coords="17,112.66,574.74,393.33,10.91;17,112.66,588.29,225.93,10.91" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="17,199.15,574.74,306.83,10.91;17,112.66,588.29,69.00,10.91">WordNet: An Electronic Lexical Database, Language, Speech, and Communication</title>
		<editor>C. Fellbaum</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,601.84,393.33,10.91;17,112.66,615.39,387.34,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="17,226.32,601.84,279.66,10.91;17,112.66,615.39,93.95,10.91">Comparing word, character, and phoneme n-grams for subjective utterance recognition</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Raaijmakers</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2008-270</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1614" to="1617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,628.93,358.88,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cs/0108005</idno>
		<title level="m" coord="17,170.08,628.93,171.04,10.91">A bit of progress in language modeling</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,642.48,393.33,10.91;17,112.33,656.03,68.33,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="17,158.18,642.48,347.81,10.91">Named entity recognition, Natural language processing of semitic languages</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mohit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="221" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,669.58,393.53,10.91;18,112.66,86.97,283.70,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="17,279.57,669.58,226.62,10.91;18,112.66,86.97,121.93,10.91">A survey of named-entity recognition methods for food information extraction</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Popovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Seljak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Eftimov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,242.84,86.97,54.37,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="31586" to="31594" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,100.52,393.61,10.91;18,112.66,114.06,393.33,10.91;18,112.66,127.61,209.35,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="18,368.84,100.52,137.42,10.91;18,112.66,114.06,283.72,10.91">Can bert dig it? named entity recognition for information retrieval in the archaeology domain</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Brandsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lambers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wansleeben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,405.50,114.06,100.48,10.91;18,112.66,127.61,140.63,10.91">Journal on Computing and Cultural Heritage (JOCCH)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,141.16,394.61,10.91;18,112.66,154.71,393.33,10.91;18,112.66,168.26,193.36,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="18,221.85,141.16,266.56,10.91">Learning to estimate query temporal dynamics for web search</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.66,154.71,393.33,10.91;18,112.66,168.26,105.84,10.91">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,181.81,394.61,10.91;18,112.66,195.36,393.33,10.91;18,112.66,208.91,193.36,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="18,281.04,181.81,207.45,10.91">Evaluating web search systems considering time</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.66,195.36,393.33,10.91;18,112.66,208.91,105.84,10.91">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="321" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,222.46,394.04,10.91;18,112.66,236.01,97.62,10.91" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="18,226.24,222.46,75.85,10.91">About WordNet</title>
		<ptr target="https://wordnet.princeton.edu/download/current-version" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,249.56,394.04,10.91;18,112.66,263.11,140.07,10.91" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Suriyawongkul</surname></persName>
		</author>
		<ptr target="https://github.com/stopwords-iso/stopwords-fr/tree/master" />
		<title level="m" coord="18,239.47,249.56,104.21,10.91">Stopword list in French</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,276.66,274.51,10.91" xml:id="b26">
	<monogr>
		<ptr target="https://opennlp.apache.org/" />
		<title level="m" coord="18,112.66,276.66,115.28,10.91">Apache, Apache OpenNLP</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,290.20,395.01,10.91;18,112.66,303.75,269.43,10.91" xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Canale</forename><surname>Atabek</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Santini</forename><surname>Moncada-Ramirez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jihuming</forename><surname>Zago</surname></persName>
		</author>
		<ptr target="https://bitbucket.org/upd-dei-stud-prj/seupd2223-jihuming/src/master/" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
