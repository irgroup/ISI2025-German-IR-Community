<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.19,80.41,15.43;1,196.10,84.19,269.65,15.42;1,89.29,106.11,403.79,15.42;1,89.29,128.02,151.50,15.43">AKRaNLU</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,156.34,87.62,11.96"><forename type="first">Ryan</forename><forename type="middle">Rony</forename><surname>Dsilva</surname></persName>
							<email>dsilvar@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Purdue University</orgName>
								<address>
									<settlement>West Lafayette</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.19,80.41,15.43;1,196.10,84.19,269.65,15.42;1,89.29,106.11,403.79,15.42;1,89.29,128.02,151.50,15.43">AKRaNLU</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2141116AE9273BCA0F8F8E2A942EE802</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>sentence embeddings</term>
					<term>puns</term>
					<term>wordplay</term>
					<term>token classification</term>
					<term>wordnet</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our work for the Automatic Wordplay Analysis (JOKER) Lab at CLEF 2023. The objective of the JOKER Lab is to advance the field of automatic methods for interpreting, generating, and translating wordplay. Our participation involved two specific tasks: pun detection and pun location with interpretation. In pun detection, we employed sentence embeddings to classify puns, while for the second task, we treated the pun location sub-task as a token classification task using XLM-RoBERTa. To interpret puns, we utilized sentence embeddings in conjunction with WordNet to identify the intended senses of the pun word. We present experiments on the training data, and the results for pun detection and location on the test dataset are summarized in tables for English, French, and Spanish puns, along with an analysis of errors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Wordplay refers to a literary technique that relies on words that sound alike but have different meanings. Wordplay can be crafted using words that share the same pronunciation and spelling, words with different spellings but the same pronunciation, and words with different spellings and similar pronunciations <ref type="bibr" coords="1,212.04,452.55,11.43,10.91" target="#b0">[1]</ref>. The CLEF 2023 JOKER <ref type="bibr" coords="1,333.71,452.55,12.84,10.91" target="#b1">[2]</ref> track proposed three tasks -Task 1: Detection of puns in English, French, and Spanish; Task 2: Location of puns in English, French, and Spanish, and Interpretation of puns in English and French, and Task 3: Translation of puns from English to French and Spanish. We participated in tasks 1 and 2. The previous edition of this competition set the foundations for the direction of automatic wordplay analysis. We use sentence embeddings with binary classification to detect puns and treat pun location as a token classification task to predict labels: (1) -for a punning word or (0) -for not a punning word for every word in the sentence. For the interpretation of puns, we compare the similarity of the embeddings of the synonyms of the located pun word with the overall sentence embedding and pick the top two senses of the word. We summarise the results of our experiments and provide an analysis of errors to aid future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Data Preparation</head><p>The data from <ref type="bibr" coords="2,157.91,132.25,12.99,10.91" target="#b1">[2]</ref> was used, and text preprocessing was applied. All input sentences were read in the UTF-8 encoding, converted to lowercase, and punctuation was stripped from the sentences except for hyphens. The decision to keep the hyphens was made after examining the dataset, wherein many instances included hyphens in the pun word. After preprocessing, 375 instances of pun words from the training set changed their form: "Lee, Chamorro" became "lee chamorro, " "en? -...fermo" became "en -fermo, " "Stan, Lee" became "stan lee" and so on. This was observed for proper nouns like names, pun words with special characters like punctuation, pun words that had two forms (bovine | divine), and words that appeared in another form that did not appear exactly in the sentence (d√©gainait). For the pun location task, these instances were excluded from the training set using a Python script. The exclusion criteria were only applied to the training data, while preprocessing was applied to both training and test data. The final size of the training dataset for the pun location task was 4817 instances for English, Spanish, and French combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pun Detection</head><p>Two main strategies were used for pun detection: sentence embeddings <ref type="bibr" coords="2,426.63,344.56,13.00,10.91" target="#b2">[3]</ref> with a binary classifier and sequence classification using XLM-RoBERTa <ref type="bibr" coords="2,351.45,358.11,11.43,10.91" target="#b3">[4]</ref>.</p><p>The intuition for using sentence embeddings stems from the basic idea of word vectors and how they can be used to represent a word. Similarly, we wanted to explore if sentence embeddings could capture the representation of the entire sentence such that certain qualities about the sentence can be learned, which in this case is whether the given sentence is a pun or not. We used the paraphrase-multilingual-mpnet-base-v2 model introduced in <ref type="bibr" coords="2,481.54,425.86,12.81,10.91" target="#b4">[5]</ref> to get the sentence embeddings. These sentence embeddings are of size 768, which are used as input to a classifier along with the labels 0 or 1 for each sentence. We experimented with various classifier models like SVC <ref type="bibr" coords="2,204.80,466.51,12.72,10.91" target="#b5">[6]</ref> (Linear, Polynomial<ref type="foot" coords="2,306.05,464.75,3.71,7.97" target="#foot_0">1</ref> , and RBF<ref type="foot" coords="2,352.11,464.75,3.71,7.97" target="#foot_1">2</ref> ), Random Forests <ref type="bibr" coords="2,437.60,466.51,11.32,10.91" target="#b6">[7]</ref>, and logistic regression but then built a neural network for the task. We built a 6-layer neural network with a classifier head which gave us the best results across all three languages: English, French, and Spanish. The idea for the neural network stems from ColBERT <ref type="bibr" coords="2,370.48,507.15,11.42,10.91" target="#b7">[8]</ref>, where a supervised binary classifier was built to use BERT embeddings as input to detect humor. We used the Sentence Transformers library <ref type="bibr" coords="2,186.31,534.25,12.97,10.91" target="#b2">[3]</ref> to generate the sentence embeddings and scikit-learn <ref type="bibr" coords="2,445.53,534.25,12.97,10.91" target="#b8">[9]</ref> and Keras <ref type="bibr" coords="2,89.29,547.80,17.91,10.91" target="#b9">[10]</ref> to build the classification models. The results of our experiments on the training data are summarized in Table <ref type="table" coords="2,184.82,561.35,3.74,10.91" target="#tab_0">1</ref>.</p><p>The second method we experimented with was sequence classification using the XLM-RoBERTa-Large model. We used the HuggingFace Transformers library <ref type="bibr" coords="2,423.15,588.45,18.07,10.91" target="#b10">[11]</ref> to implement this.</p><p>We also conducted experiments to evaluate the impact of the training data size on our models. These results show an improvement in performance with an increase in dataset size. However, the results are not convincing enough to say that increasing the dataset size will necessarily improve results. The findings are presented in Table <ref type="table" coords="3,323.93,436.21,3.74,10.91">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Pun Location</head><p>We employed the token classification method for locating puns as demonstrated by <ref type="bibr" coords="3,467.67,485.93,16.38,10.91" target="#b11">[12]</ref>. We used the NP tagging scheme because it could capture instances where there could be more than one word that formed the pun. Based on the training split, we assigned a tag of 1 to every pun word and 0 to every word that is not a pun word. We used the XLM-RoBERTa-Large model to perform this token classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Pun Interpretation</head><p>Interpretation of puns used the results from the pun location subtask to disambiguate the appropriate senses of the pun word according to the sentence and find synonyms for those senses. We used WordNet<ref type="foot" coords="3,211.40,615.20,3.71,7.97" target="#foot_2">3</ref>  <ref type="bibr" coords="3,219.36,616.96,18.07,10.91" target="#b12">[13]</ref> as our sense dictionary. More specifically, since we used WordNet from the nltk library, we used the Open Multilingual WordNet <ref type="bibr" coords="3,417.83,630.50,16.41,10.91" target="#b13">[14]</ref>, which gave us access to WordNet in English, French, and Spanish. We first collected the synonyms of the pun word from WordNet and then computed the similarity between the word embedding of each synonym and the sentence embedding of the text. Both these embeddings are of size 768, and we use the cosine similarity function from the sentence transformers library. The intuition for this stems from the idea that embeddings of the synonyms of the senses that most accurately fit the sentence would be closer to the sentence in the vector space. The synonyms in WordNet each represent a distinct concept. Hence the top-2 synonyms were selected to be the most appropriate for the pun word in the sentence.</p><p>All the code for this work is made available on GitHub<ref type="foot" coords="4,343.30,180.06,3.71,7.97" target="#foot_3">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>The metrics of precision, recall, accuracy, and f-score are reported for Task 1, and accuracy is reported for Task 2, Sub-Task 1. The metrics in the tables below are computed from the test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pun Detection</head><p>Tables <ref type="table" coords="4,121.02,317.26,7.62,10.91" target="#tab_1">3,</ref><ref type="table" coords="4,131.87,317.26,3.81,10.91">4</ref>, and 5 summarise the results for our runs. We submitted classifications for 3183 instances in English, 12873 instances in French, and 2230 instances in Spanish. The low scores suggest that sentence embeddings used directly may not capture the property of the sentence that makes the sentence a pun. Furthermore, the dataset had sentences that were augmented in such a way that the pun word was deliberately replaced with a word that still makes sense in the context but makes the sentence such that it is not a pun anymore. The methods used here failed to capture that aspect accurately. The XLM-RoBERTa-Large model particularly suffered due to this and over-predicted the puns to such an extent that for English and French, no true negatives were predicted. Some examples of incorrect classifications include:</p><p>Surfing is a swell sport! Actual: 1</p><p>Predicted: 0 I used to be a banker but I lost motivation. Actual: 0 Predicted: 1</p><p>In the first example, the model fails to recognize the nuanced meaning of the word "swell," which could mean excellent, great, or fantastic (informally) or the rising and falling motion of the waves. Informal definitions and slang might not be accurately captured with this approach. The second example demonstrates what the authors of the dataset describe as a negative example where the pun word of "interest" was substituted to be "motivation, " which has a similar sense but loses the quality that makes this sentence a pun. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pun Location</head><p>Table <ref type="table" coords="5,115.84,541.58,5.08,10.91" target="#tab_2">7</ref> summarises the results for submission for the pun location task. We submitted results for 1205 instances in English, 4655 instances in French, and 960 instances in Spanish. Partial accuracy refers to the accuracy calculated from the submitted instances instead of the entire test dataset. One flaw noticed during experiments was that our model could not always capture instances where the pun word was a phrase of multiple words instead of a single word. Some examples of predictions are included in Table <ref type="table" coords="5,293.49,609.32,3.74,10.91">6</ref>.</p><p>The predictions show a variety of findings. The model does have the capability to detect a pun phrase, but it is not consistent. The last example is interesting because it picked the correct concept from the sentence (vision-blind) but failed to mark the right word, which makes it a pun. The word "vision" should have been predicted due to its dual meaning of the ability to see and the ability to plan the future with wisdom. An overall accuracy of 79% was obtained on the training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Pun Interpretation</head><p>The results for the test dataset were not ready in time for this paper, and hence only analysis of the experiments on the training data is provided. Some examples of interpretation outputs<ref type="foot" coords="6,485.44,402.09,3.71,7.97" target="#foot_4">5</ref> are included in Table <ref type="table" coords="6,168.64,417.39,3.74,10.91">8</ref>.</p><p>In the examples of common words like "quiver" and "leaked," our solution performed well, but for words that did not have the same form across senses, like in the example for "amply," our system could not predict the correct interpretation. Here, "amply" was the form for one sense which means "richly," and "amp" was the other form which means "ampere." WordNet in other languages is also less extensive than the one for English, which limits this approach. Matching synonyms that included special characters in French, like carets, returned no results, which resulted in no output from the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Scope</head><p>Our implementation of sentence embeddings to detect properties of sentences could prove to be the basis when used in conjunction with other aspects, such as phonetics, to identify puns. While building the neural network for classification, we were limited by time and believed that a better model could be built to detect the properties of sentence embeddings that make it a pun. Moreover, the dataset could be augmented to add more negative samples from other pun datasets. A better way of handling circumflex accent (caret) marks and the instances marked by the exclusion criteria could further improve the system's capabilities. Furthermore, WordNet could not match multi-word instances to their appropriate synonyms for the interpretation task, particularly for French instances. Leveraging the large knowledge base of LLMs might prove useful for interpretation tasks, but we did not explore those areas in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,365.28,305.47"><head>Table 1</head><label>1</label><figDesc>Metrics for Pun Detection -Training Data</figDesc><table coords="3,88.99,122.10,365.28,273.86"><row><cell cols="5">Precision Recall Accuracy F-Score</cell></row><row><cell>SVC (Linear)</cell><cell>0.5800</cell><cell>0.5700</cell><cell>0.5700</cell><cell>0.5700</cell></row><row><cell>SVC (Poly-3)</cell><cell>0.5500</cell><cell>0.5500</cell><cell>0.5500</cell><cell>0.5400</cell></row><row><cell>SVC (RBF-0.05-1)</cell><cell>0.5900</cell><cell>0.5800</cell><cell>0.5800</cell><cell>0.5600</cell></row><row><cell>Random Forests</cell><cell>0.5200</cell><cell>0.5200</cell><cell>0.5200</cell><cell>0.5100</cell></row><row><cell>Gradient Boosted Forests</cell><cell>0.5800</cell><cell>0.5700</cell><cell>0.5700</cell><cell>0.5600</cell></row><row><cell>Logistic Regression</cell><cell>0.5800</cell><cell>0.5800</cell><cell>0.5800</cell><cell>0.5700</cell></row><row><cell>Custom NeuralNet</cell><cell>0.6200</cell><cell>0.6200</cell><cell>0.6200</cell><cell>0.6100</cell></row><row><cell>XLM-RoBERTa-Large</cell><cell>0.5261</cell><cell>1.0000</cell><cell>0.5261</cell><cell>0.6895</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Metrics for Pun Detection -Impact of Training Data Size</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Precision Recall Accuracy F-Score</cell></row><row><cell>SentEmb-NeuralNet with 25%</cell><cell>0.5600</cell><cell>0.5600</cell><cell>0.5600</cell><cell>0.5400</cell></row><row><cell>SentEmb-NeuralNet with 50%</cell><cell>0.5800</cell><cell>0.5800</cell><cell>0.5800</cell><cell>0.5600</cell></row><row><cell>SentEmb-NeuralNet with 75%</cell><cell>0.5700</cell><cell>0.5700</cell><cell>0.5700</cell><cell>0.5700</cell></row><row><cell>SentEmb-NeuralNet with 100%</cell><cell>0.6200</cell><cell>0.6200</cell><cell>0.6200</cell><cell>0.6100</cell></row><row><cell>XLM-RoBERTa-Large with 25%</cell><cell>0.4994</cell><cell>1.0000</cell><cell>0.4994</cell><cell>0.6662</cell></row><row><cell>XLM-RoBERTa-Large with 50%</cell><cell>0.7048</cell><cell>0.4238</cell><cell>0.6235</cell><cell>0.5293</cell></row><row><cell>XLM-RoBERTa-Large with 75%</cell><cell>0.6441</cell><cell>0.5365</cell><cell>0.6204</cell><cell>0.5854</cell></row><row><cell>XLM-RoBERTa-Large with 100%</cell><cell>0.5261</cell><cell>1.0000</cell><cell>0.5261</cell><cell>0.6895</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,90.49,404.17,403.81"><head>Table 3</head><label>3</label><figDesc>Metrics for Pun Detection -English</figDesc><table coords="5,88.99,122.10,404.17,372.20"><row><cell></cell><cell cols="5">Precision Recall Accuracy F-Score</cell></row><row><cell>SentEmb-NeuralNet</cell><cell>0.2630</cell><cell cols="2">0.8640</cell><cell>0.3500</cell><cell>0.4032</cell></row><row><cell>XLM-RoBERTa-Large</cell><cell>0.2542</cell><cell cols="2">1.0000</cell><cell>0.2542</cell><cell>0.4053</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metrics for Pun Detection -French</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Precision Recall Accuracy F-Score</cell></row><row><cell>SentEmb-NeuralNet</cell><cell>0.4118</cell><cell cols="2">0.7389</cell><cell>0.4572</cell><cell>0.5289</cell></row><row><cell>XLM-RoBERTa-Large</cell><cell>0.4123</cell><cell cols="2">1.0000</cell><cell>0.4123</cell><cell>0.5839</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metrics for Pun Detection -Spanish</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Precision Recall Accuracy F-Score</cell></row><row><cell>SentEmb-NeuralNet</cell><cell>0.4140</cell><cell cols="2">0.7227</cell><cell>0.4476</cell><cell>0.5264</cell></row><row><cell>XLM-RoBERTa-Large</cell><cell>0.4256</cell><cell cols="2">0.9969</cell><cell>0.4270</cell><cell>0.5965</cell></row><row><cell>Table 6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pun Detection -Examples</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sentence</cell><cell></cell><cell></cell><cell cols="2">Pun Word</cell><cell>Predicted</cell></row><row><cell cols="2">Weather forecasters have to have lots of degrees.</cell><cell></cell><cell cols="2">degrees</cell><cell>degrees</cell></row><row><cell cols="3">Quand des √©l√©phants entrent dans un bar, le patron</cell><cell cols="3">des gros pour boire gros</cell></row><row><cell cols="2">sait qu'il peut s'attendre √† des gros pour boire.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">C'est entre mon nez et mon menton, dit Tom la bouche</cell><cell cols="3">la bouche encoeur</cell><cell>la bouche encoeur</cell></row><row><cell>encoeur.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Some people with a lot of vision started the blind</cell><cell>vision</cell><cell></cell><cell>blind</cell></row><row><cell>institute.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.98,90.49,402.28,209.82"><head>Table 7</head><label>7</label><figDesc>Accuracy for Pun Location</figDesc><table coords="6,88.99,122.10,402.27,178.20"><row><cell></cell><cell cols="2">Accuracy Partial Accuracy</cell></row><row><cell>English</cell><cell>0.7917</cell><cell>0.7917</cell></row><row><cell>French</cell><cell>0.4136</cell><cell>0.4713</cell></row><row><cell>Spanish</cell><cell>0.5615</cell><cell>0.5615</cell></row><row><cell>Table 8</cell><cell></cell><cell></cell></row><row><cell>Pun Interpretation -Examples</cell><cell></cell><cell></cell></row><row><cell>Sentence</cell><cell>Interpretation</cell><cell></cell><cell>Predicted</cell></row><row><cell>This is where I keep my arrows, said</cell><cell cols="2">palpitate; quake; quiver /</cell><cell>beat; pulsate; quiver / pal-</cell></row><row><cell>Tom, quivering.</cell><cell>quiver</cell><cell></cell><cell>pitate; quake; quiver</cell></row><row><cell cols="2">News of a coming flood was leaked. leak / leak</cell><cell></cell><cell>leak; leak out / leak</cell></row><row><cell>"It's a unit of electric current," said</cell><cell cols="2">richly / A; amp; ampere</cell><cell>richly / fully</cell></row><row><cell>Tom amply.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,660.06,114.37,8.97"><p>Polynomial SVC with degree=3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,92.57,671.02,111.63,8.97"><p>RBF SVC with ùõæ=0.05 and C=1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,92.57,671.03,156.17,8.97"><p>https://www.nltk.org/howto/wordnet.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,92.57,670.96,169.92,8.97"><p>https://github.com/RyanDsilva/clef-2023-joker</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,92.57,671.02,377.32,8.97"><p>In Table8, the symbol "/" separates the two senses and ";" separates alternate words for the same sense.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,186.24,393.33,10.91;7,112.66,199.79,325.12,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,226.59,186.24,204.90,10.91">Computationally recognizing wordplay in jokes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Mazlack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,452.94,186.24,53.05,10.91;7,112.66,199.79,244.43,10.91">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,213.34,393.72,10.91;7,112.66,226.89,393.33,10.91;7,112.66,240.44,393.33,10.91;7,112.66,253.99,379.82,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,463.73,213.34,42.66,10.91;7,112.66,226.89,288.31,10.91">Overview of JOKER -CLEF-2023 track on Automatic Wordplay Analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Palma Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,431.29,226.89,74.70,10.91;7,112.66,240.44,393.33,10.91;7,112.66,253.99,252.13,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="7,112.66,267.54,395.17,10.91;7,112.66,281.08,393.33,10.91;7,112.66,294.63,395.01,10.91;7,112.66,308.18,87.13,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,232.22,267.54,275.61,10.91;7,112.66,281.08,39.98,10.91">Sentence-BERT: Sentence embeddings using siamese BERTnetworks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1908.10084" />
	</analytic>
	<monogr>
		<title level="m" coord="7,182.44,281.08,323.55,10.91;7,112.66,294.63,282.23,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,321.73,394.53,10.91;7,112.66,335.28,393.33,10.91;7,112.66,348.83,393.32,10.91;7,112.66,362.38,144.26,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,271.58,335.28,234.41,10.91;7,112.66,348.83,20.10,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzm√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">√â</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,155.39,348.83,350.59,10.91;7,112.66,362.38,46.58,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,375.93,393.32,10.91;7,112.66,389.48,393.33,10.91;7,112.66,403.03,394.61,10.91;7,112.66,416.58,144.07,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,226.50,375.93,279.48,10.91;7,112.66,389.48,100.02,10.91">Making monolingual sentence embeddings multilingual using knowledge distillation</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2004.09813" />
	</analytic>
	<monogr>
		<title level="m" coord="7,237.77,389.48,268.21,10.91;7,112.66,403.03,339.36,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,430.13,375.65,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,208.31,430.13,109.06,10.91">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,326.19,430.13,78.19,10.91">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,443.67,277.53,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,167.61,443.67,67.74,10.91">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,243.28,443.67,78.19,10.91">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,457.22,394.53,10.91;7,112.66,470.77,181.59,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,243.17,457.22,259.73,10.91">Colbert: Using bert sentence embedding for humor detection</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Annamoradnejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zoghi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.127651</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,484.32,394.53,10.91;7,112.66,497.87,394.53,10.91;7,112.66,511.42,393.32,10.91;7,112.66,524.97,176.63,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,228.10,511.42,182.14,10.91">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,419.22,511.42,86.76,10.91;7,112.66,524.97,82.55,10.91">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,538.52,198.99,10.91" xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,552.07,394.53,10.91;7,112.66,565.62,394.53,10.91;7,112.66,579.17,395.17,10.91;7,112.66,592.72,393.33,10.91;7,112.66,606.27,394.53,10.91;7,112.66,619.81,385.60,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,315.63,579.17,192.20,10.91;7,112.66,592.72,72.82,10.91">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m" coord="7,207.25,592.72,298.74,10.91;7,112.66,606.27,390.37,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,633.36,393.33,10.91;7,112.66,646.91,393.33,10.91;7,112.66,660.46,393.33,10.91;8,112.66,86.97,394.62,10.91;8,112.31,100.52,270.55,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,187.47,633.36,202.52,10.91">Joint detection and location of English puns</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1217</idno>
		<ptr target="https://aclanthology.org/N19-1217.doi:10.18653/v1/N19-1217" />
	</analytic>
	<monogr>
		<title level="m" coord="7,419.74,633.36,86.25,10.91;7,112.66,646.91,393.33,10.91;7,112.66,660.46,186.55,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2117" to="2123" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,114.06,394.61,10.91;8,112.31,127.61,156.57,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="8,170.22,114.06,180.90,10.91">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<ptr target="https://mitpress.mit.edu/9780262561167/" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,141.16,393.33,10.91;8,112.66,154.71,340.41,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">S</forename><surname>Madonsela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mafela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Mojapelo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Masubelele</surname></persName>
		</author>
		<title level="m" coord="8,404.27,141.16,101.71,10.91;8,112.66,154.71,162.54,10.91">Proceedings of the 8th global wordnet conference, gwc 2016</title>
		<meeting>the 8th global wordnet conference, gwc 2016</meeting>
		<imprint>
			<publisher>Global WordNet Association</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
