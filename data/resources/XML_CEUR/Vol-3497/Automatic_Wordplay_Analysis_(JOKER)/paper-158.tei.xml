<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,84.74,84.92,407.75,17.04;1,84.74,105.68,283.06,17.04;1,367.63,104.66,5.60,11.04">CLEF 2023 JOKER Tasks 2 and 3: Using NLP Models for Pun Location, Interpretation and Translation 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,85.58,139.78,79.51,10.80"><forename type="first">Felix</forename><surname>Ohnesorge</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Kiel</orgName>
								<address>
									<postCode>24118</postCode>
									<settlement>Kiel</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.13,139.78,113.92,10.80"><forename type="first">Mari</forename><surname>Ángeles Gutiérrez</surname></persName>
							<email>mariangeles.gutierrez@uca.es</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Cádiz</orgName>
								<address>
									<postCode>11003</postCode>
									<settlement>Cádiz</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.39,139.78,58.49,10.80"><forename type="first">Julia</forename><surname>Plichta</surname></persName>
							<email>j.plichta.162@studms.ug.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Gdańsk</orgName>
								<address>
									<postCode>80-309</postCode>
									<settlement>Gdańsk</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,84.74,84.92,407.75,17.04;1,84.74,105.68,283.06,17.04;1,367.63,104.66,5.60,11.04">CLEF 2023 JOKER Tasks 2 and 3: Using NLP Models for Pun Location, Interpretation and Translation 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">113001A881A2BFF852E7A088BB14BB46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Wordplay</term>
					<term>computation humour</term>
					<term>pun</term>
					<term>machine translation</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The translation of puns presents a significant challenge for translators and has garnered considerable attention in the field of translation studies. While translation technology aims to automate the translation process, little focus has been placed on the translation of wordplay. Addressing this gap, the CLEF2023 JOKER track aims to develop a multilingual corpus of wordplay and evaluation metrics to advance the automation of creative-language translation. This paper provides an overview of the track's Pilot Task 3, which specifically focuses on the translation of entire phrases containing wordplay, particularly puns.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="596.04" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As Ermakova et al. explain <ref type="bibr" coords="1,213.99,408.33,11.68,9.94" target="#b0">[1]</ref>, humorous wordplay comprehension and translation often require recognizing implicit cultural references, understanding word formation processes, and discerning double meanings. These challenges are encountered by both humans and computers alike. Introducing the CLEF 2023 JOKER track, this paper adopts an interdisciplinary approach to facilitate the creation of reusable test collections, evaluation metrics, and methods for automatic wordplay processing. The track comprises interconnected shared tasks that encompass the detection, location, interpretation, and translation of puns. Furthermore, associated datasets and evaluation methodologies are described, and contributions leveraging this data are invited for further research and development.</p><p>Through the collaborative efforts of the CLEF JOKER track, advancements in automating the translation of wordplay are expected, paving the way for improved translation technology and enhancing cross-cultural communication in creative language contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Task 1: Pun Detection</head><p>A pun is a form of wordplay that exploits multiple meanings or similar sounds of words to create a humorous or clever effect. Puns can be found in various forms, including plays on words, double entendres, homophones, and wordplay involving idioms or metaphors, which implies nuanced linguistic and cultural knowledge, making it difficult for algorithms to capture the full range of punning possibilities.</p><p>However, the methods based on natural language processing (NLP) and machine learning techniques examine factors such as word similarity, part-of-speech tags, syntactic patterns, and context, so, by comparing the different senses or meanings of words and their surrounding context, algorithms can identify potential puns.</p><p>In our case, we have been provided with the JOKER dataset, which contains around 5000 sample sentences, which are labeled with either a "yes" or a "no". This is not a big dataset when considering the high dimensionality we have in text classification. Normally we would use a cross-validation technique but that requires a lot of time and computational power, which google colab could not provide enough of. So, we used a 60/20/20 split on our dataset for training, testing and evaluation.</p><p>The pun detection is a binary classification task, for which we used several different methods. The methods (some of them quite simple and only as a reference) will be explained in detail later. In addition, all statistics can be found in Ermakova et al. <ref type="bibr" coords="2,315.43,205.12,4.30,9.94">[</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Random</head><p>This Method yielded an accuracy of 49%, which is expected because our evaluation data contained 50% of "yes" samples and 50% of "no" samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Fasttext</head><p>This is an open-source library for text classification. It comes pretrained in multiple languages, which should help us because we only need to fine tune the model.</p><p>The trained model achieved a 70% accuracy on our evaluation data, with an equally distributed confusion matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3.">Ridge</head><p>Ridge is a classifier that works by regression and is most commonly used for multiclass classifications but can of cause also be used for binary classification. This is not a pretrained model, so we had to train it with our available data exclusively. The model still achieved a slightly higher accuracy on our evaluation dataset, 76%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4.">Bayes</head><p>Bayes is a well-known classifier for multimodal classification. It is basically a simple probability calculation. Here an interesting thing happened. We achieved an accuracy of 62%, but the confusion matrix showed zero true positives and zero false positives. This indicates an underfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5.">MLP</head><p>We used the MLPClassifier from the sklearn.neural_network library. This is a multi-layer perceptron that optimizes the loss function by stochastic gradient descent. This is a very powerful method, but it has many parameters that can be adjusted. For example, the number of neurons per layer, the number of layers. As a solver we used Adam, as it is the most used one. As an activation function we used ReLU which is also widely used.</p><p>This multi-layer perceptron achieved an accuracy of 75%, scoring slightly behind Ridge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.6.">SimpleTransformersT5</head><p>SimpleT5 models can be used for many tasks such as summarization, translation, text generation, and more. We used it for a binary classification which we did not expect to perform very well because it is not the intended task and is way too powerful. This showed intraining, which took an exceedingly long time and the model started overfitting after the second epoch. The only parameter we adjusted was the target_max_token_length, because we only wanted it to answer "yes" and "no" or 0 and 1, respectively.</p><p>As expected, the model only had a 70% accuracy on our evaluation data, which is slightly lower than most of the other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.7.">SimpleTransformersRoberta</head><p>This is a transformer model with a binary text classification model on top of it. We expect this model to perform better than the others because it seems best fit to this problem.</p><p>The trained model achieved a 75% accuracy on our evaluation dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Task 2: Pun Location</head><p>For the pun location, the main purpose is to identify which words carry the double meaning in a text known a priori to contain a pun. We have used the following methods, which will be explained in more detail later: The metrics used for evaluation are:</p><p>• Precision: it measures the proportion of correctly predicted positive instances (true positives) out of all instances predicted as positive (true positives + false positives).</p><p>• Recall: it measures the proportion of correctly predicted positive instances (true positives) out of all actual positive instances (true positives + false negatives).</p><p>• F1-score: it is the harmonic mean of precision and recall and provides a balanced measure of the model's performance. It takes both precision and recall into account and is particularly useful when dealing with imbalanced datasets.</p><p>• Support: The support column indicates the number of instances (samples) in the dataset that belong to each class.</p><p>A very big problem was the size of available data. For the sexism detection task, we had 7000 labeled tweets and for the pun detection around 5000 sample sentences. When training a neural network that has not been pretrained, this is not enough due to the high feature dimensionality of this task. Here it may be interesting to use different vectorization methods and analyze their impact on the result.</p><p>Normally when dealing with samples for training/evaluation a good technique would be the cross validation where all available data is split into multiple batches. We would then train a model on all batches but one and use the left-out batch for evaluation. This would be repeated for every batch. Unfortunately, this requires a lot of computing power and time, both of which we did not have. So, we used an 80/20 split on the training data for training/evaluation. For the ML models we split the training data into a training and test set, again in an 80/20 relation.</p><p>The effectiveness of Bayes, as a method for multimodal classification, is limited in the pun location task due to an excessive number of modalities or an absence of a finite set of modalities. Bayes is a naïve classification method based on probabilities with multiple classes. In the pun detection setting we have a two-class decision problem with can be realized by the bayes classifier. Additionally, Fasttext and Ridge, both commonly employed in classification problems, are anticipated to exhibit suboptimal performance in this context.</p><p>Instead, pretrained models like SimpleT5 are expected to demonstrate superior performance in this task, which is why we have used them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Results for SimpleT5</head><p>From the extensive list of classified terms, it can be said that the majority have reached 1.0 accuracy, which underlines the point that we did not have enough data. So, in summary, the SimpleT5 model achieved an accuracy of 87% on the classification task against our evaluation data set. The macro average and weighted average metrics indicate the overall performance across classes, with values of 0.77 and 0.87, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Results for SimpleTransformersT5</head><p>In the same line as the previous method, it achieved an accuracy of 83% on the classification task. The macro average and weighted average metrics indicate the overall performance across classes, with values of 0.71 and 0.70 for precision, recall, and F1-score. However, without the specific values of the confusion matrix, we cannot further analyze the model's performance for each class or discern the distribution of the predicted and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Task 3: Pun translation</head><p>In the context of pun translation, several models were employed, including those pretrained on translation tasks, as well as FastText and SimpleT5. Notably, FastText exhibited subpar performance due to its classification-oriented nature, which may not be ideally suited for the intricacies of pun translation. Similarly, SimpleT5 did not yield notably satisfactory results. However, it is worth mentioning that specific quantitative performance metrics are unavailable, precluding a more detailed assessment of their respective performances.</p><p>Regarding to the dataset with which we have worked, translations from English into French and Spanish have been obtained using two NPL models: OpusMT and M2M100.</p><p>From 1000 sentences provided, 30 have been selected to check the quality of the resulting translation. Taking said pre-selection as a reference, 96.7% of these sentences had obtained a good result in the Spanish translation. The sentences translated by OpusMT were more accurate, while M2M100 tends to make free translations, therefore meaningless occasionally.</p><p>In general, we have obtained very literal translations, so that is why 60% failed to recreate the pun in the target language. Following the "wordplay translation strategies" referenced by Ermakova et al <ref type="bibr" coords="4,75.98,576.84,11.77,9.94" target="#b3">[4]</ref>, in those sentences where the pun also works in the target language, they have performed an isomorphic pun (that is, they have used the direct translation of the words because it coincides with the main meaning that gives sense to the pun). For example, in the sentence "When you're wearing a watch on an airplane, time flies" the translation is very direct, so in Spanish it retains the same meaning when the result shows: "Cuando llevas un reloj en un avión, el tiempo vuela".</p><p>This implies that puns based on homophonic sounds are not detected or translated (ST: "You can't trust a tiger. You never know when he might be lion"; TT: "No puedes confiar en un tigre. Nunca se sabe cuándo podría ser león"), just like puns based on polysemous terms (ST: "If there's one person you don't want to interrupt in the middle of a sentence it's a judge"; TT: "Si hay una persona que no quieres interrumpir en medio de una sentencia es un juez" where the word 'sentence' loses one of its meanings, in this case 'expression' or 'group of words' besides 'a punishment given by a judge'.</p><p>However, it is very interesting to see how OpusMT recognizes the wordplay' semantic field in order to make a coherent translation: ST: "The designer wondered why his pirate room wasn't perfect, and the judge told him he went a little overboard"; TT: "El diseñador se preguntó por qué su habitación pirata no era perfecta, y el juez le dijo que se fue un poco por la borda" maintaining references to vocabulary related to the sea, while M2M100 made a neutral translation: "El diseñador se preguntó por qué su sala de piratas no era perfecta, y el juez le dijo que iba un poco por encima".</p><p>It is also curious how OpusMT is able to distinguish a formal context: the second person 'you' has two translations in Spanish: 'tú' for informal situations (under certain pragmalinguistic conditions) and 'usted' for formal situations. In the following example, this model has been able to recognize a situation that requires polite language: ST: "Waiter, there are pennies in my soup!'' Well, sir, you said you'd stop eating here if there wasn't some change in the food"; TT: " '¡Camarero, hay centavos en mi sopa!' Bueno, señor, usted dijo que dejaría de comer aquí si no había algún cambio en la comida". On the other hand, in a significantly lower proportion, we have found a few examples of pun's omissions ("pun to zero", according to Delabastita lists, cited in Ermakova et al. <ref type="bibr" coords="5,448.29,211.73,11.69,10.04" target="#b2">[3]</ref>): ST: "OLD POLICEMEN never die they just cop out"; TT: "Los viejos policías nunca mueren".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Conclusion</head><p>In conclusion, this paper focused on the interdisciplinary approach taken in the CLEF 2023 JOKER track to address the challenges of wordplay comprehension, detection, location, interpretation, and translation. We have described the creation of reusable test collections, evaluation metrics, and methods for automatic wordplay processing.</p><p>For the task of pun detection, various methods were employed, including Random, Fasttext, Ridge, Bayes, MLP, SimpleTransformersT5, and SimpleTransformersRoberta. Each method was evaluated using accuracy (F1) as the performance metric, with Ridge and MLP achieving the highest accuracies of 76% and 75%, respectively. These results demonstrated the effectiveness of machine learning and neural network-based approaches in identifying puns.</p><p>In the pun location task, we used methods such as SimpleT5, SimpleTransformersT5, Ridge, Bayes, and Fasttext. The evaluation metrics used included precision, recall, F1-score, and support. SimpleT5 achieved the highest accuracy of 87%, indicating its efficacy in identifying the words carrying double meanings in puns.</p><p>Regarding pun translation from English into Spanish, different models were utilized, including OpusMT, M2M100, FastText, and SimpleT5. The translations obtained were mostly literal, resulting in a 60% failure rate in recreating the puns in the target language. The translation models struggled to capture homophonic sounds and polysemous terms, leading to the loss of puns based on those linguistic elements. OpusMT showcased the ability to recognize the semantic field of wordplay, while M2M100 provided more neutral translations.</p><p>Overall, the CLEF JOKER track and the methods employed in this paper showcased promising advancements in automating wordplay processing. The results highlighted the potential of machine learning, neural networks, and pretrained models in tackling the complexities of pun detection, location, and translation. Further research and development in this area can contribute to improved language technology and enhanced cross-cultural communication in creative language contexts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,81.02,205.12,333.91,160.45"><head></head><label></label><figDesc><ref type="bibr" coords="2,319.73,205.12,8.60,9.94" target="#b1">2]</ref> </figDesc><table coords="2,81.02,229.94,333.91,135.63"><row><cell>Table 1</cell><cell></cell></row><row><cell>Results: Pun Detection</cell><cell></cell></row><row><cell>Method</cell><cell>Accuracy (F1)</cell></row><row><cell>Random</cell><cell>49%</cell></row><row><cell>Fasttext</cell><cell>70%</cell></row><row><cell>Ridge</cell><cell>76%</cell></row><row><cell>Bayes</cell><cell>62%</cell></row><row><cell>MLP</cell><cell>75%</cell></row><row><cell>SimpleTransformersT5</cell><cell>70%</cell></row><row><cell>SimpleTransformersRoberta</cell><cell>75%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,81.02,363.05,334.03,105.38"><head>Table 2 Results</head><label>2</label><figDesc></figDesc><table coords="3,111.01,376.61,304.04,91.82"><row><cell>: Pun Location</cell><cell></cell></row><row><cell>Method</cell><cell>Accuracy (F1)</cell></row><row><cell>SimpleT5</cell><cell>87%</cell></row><row><cell>SimpleTranformersT5</cell><cell>83%</cell></row><row><cell>Ridge</cell><cell>50%</cell></row><row><cell>Bayes</cell><cell>2%</cell></row><row><cell>Fasttext</cell><cell>5%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4.">Acknowledgements</head><p>At this point we want to thank the <rs type="institution">Erasmus program</rs>, the <rs type="institution">European University of the Seas (SEA-EU)</rs> and the <rs type="institution">Instituto de Investigación en Estudios del Mundo Hispánico (In-EMHis)</rs> for giving us the opportunity to take this course that promises to be innovative in our academic careers. We also want to acknowledge all the work done by the whole team of the CLEF 2023 project, especially <rs type="person">Liana Ermakova</rs>, who hosted the Artificial Intelligence's course and <rs type="person">Séverine Allain</rs> and <rs type="person">Ludmila Guillotin</rs> for the excellent coordination and the warm welcome from the <rs type="institution">Université de Bretagne Occidentale</rs>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="5,111.98,669.00,401.35,9.94;5,111.38,681.60,401.56,9.94;5,111.38,694.09,401.96,10.05;5,111.38,706.92,401.73,9.94;5,111.38,719.52,401.81,9.94;5,111.38,732.12,401.95,9.94;5,111.38,744.86,234.89,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,258.49,694.09,254.85,10.05;5,111.38,706.92,131.65,9.94">Overview of the CLEF 2022 JOKER Task 1: Classify and explain instances of wordplay</title>
		<author>
			<persName coords=""><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tristan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anne-Gwenn</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sílvia</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudine</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaëlle</forename><surname>Le Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Albin</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurianne</forename><surname>Damoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Campen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Orlane</forename><surname>Puchalski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,223.85,719.52,289.34,9.94;5,111.38,732.12,146.04,9.94">Proceedings of the Working Notes of CLEF 2022 --Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="5,123.37,744.86,134.48,9.94">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2022 --Conference and Labs of the Evaluation Forum<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">September 5th to 8th, 2022. 2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="1641" to="1665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,111.38,758.42,401.82,9.94;6,111.38,72.64,401.92,9.94;6,111.38,85.36,401.62,9.94;6,111.38,97.96,401.68,9.94;6,111.38,110.68,401.78,9.94;6,111.38,123.28,401.54,9.94;6,111.38,135.88,162.31,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,308.90,72.64,204.40,9.94;6,111.38,85.36,131.42,9.94">Overview of JOKER -CLEF-2023 track on Automatic Wordplay Analysis</title>
		<author>
			<persName coords=""><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tristan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anne-Gwenn</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Palma</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Jatowt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,336.61,110.68,176.55,9.94;6,111.38,123.28,401.54,9.94;6,111.38,135.88,97.89,9.94">Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<editor>
			<persName><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Theodora</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefanos</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohammad</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michalis</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association<address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="6,111.38,149.56,407.49,9.94;6,111.38,162.16,407.55,9.94;6,111.38,174.76,407.38,9.94;6,111.38,187.48,407.36,9.94;6,111.38,200.08,407.71,9.94;6,111.38,212.80,407.70,9.94;6,111.38,225.40,76.23,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,460.80,162.16,58.14,9.94;6,111.38,174.76,382.46,9.94">Overview of JOKER@CLEF 2022: Automatic Wordplay and Humor Translation Workshop</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Le Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Damoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-13643-6_27</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,111.38,187.48,407.36,9.94;6,111.38,200.08,228.21,9.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Sprinter-Verlag</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="447" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,111.38,238.96,401.63,9.94;6,111.38,251.71,401.67,9.94;6,111.38,264.20,401.87,10.05;6,111.38,276.91,401.92,9.94;6,111.38,289.63,401.80,9.94;6,111.38,302.23,401.84,9.94;6,111.38,314.95,295.28,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,316.10,264.20,197.15,10.05;6,111.38,276.91,191.63,9.94">Overview of the CLEF 2022 JOKER Task 3: Pun Translation from English into French</title>
		<author>
			<persName coords=""><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tristan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anne-Gwenn</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claudine</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benoît</forename><surname>Jeanjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Élise</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaëlle</forename><surname>Le Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Radia</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sílvia</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Albin</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurianne</forename><surname>Damoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,283.87,289.63,229.31,9.94;6,111.38,302.23,202.15,9.94">Proceedings of the Working Notes of CLEF 2022 --Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="6,183.85,314.95,134.56,9.94">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2022 --Conference and Labs of the Evaluation Forum<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">September 5th to 8th, 2022. 2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="1681" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
