<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,411.19,15.42;1,89.29,106.66,377.48,15.42;1,89.29,128.58,131.71,15.43">Exploring Humor in Natural Language Processing: A Comprehensive Review of JOKER Tasks at CLEF Symposium 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,156.89,63.97,11.96"><forename type="first">Aftab</forename><surname>Anjum</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Christian-Albrechts-Universität zu Kiel</orgName>
								<address>
									<addrLine>Christian-Albrechts-Platz 4</addrLine>
									<postCode>24118</postCode>
									<settlement>Kiel</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,171.01,156.89,92.86,11.96"><forename type="first">Nikolaus</forename><surname>Lieberum</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Christian-Albrechts-Universität zu Kiel</orgName>
								<address>
									<addrLine>Christian-Albrechts-Platz 4</addrLine>
									<postCode>24118</postCode>
									<settlement>Kiel</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,411.19,15.42;1,89.29,106.66,377.48,15.42;1,89.29,128.58,131.71,15.43">Exploring Humor in Natural Language Processing: A Comprehensive Review of JOKER Tasks at CLEF Symposium 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">40C4D71C8262B73021BC7954549A288F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pun</term>
					<term>Wordplay</term>
					<term>Natural Language Processing</term>
					<term>Computational Humour Detection</term>
					<term>Humour Location</term>
					<term>Machine Translation</term>
					<term>Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As linguistic phenomena that showcase the richness and complexity of human language, puns pose significant challenges to natural language processing (NLP) systems. The significance of these tasks lies not only in the enhancement of humor recognition capabilities in AI but also in the improvement of machine translation systems, as puns often encapsulate cultural, idiomatic, and context-sensitive information <ref type="bibr" coords="1,130.96,266.93,9.50,8.97" target="#b0">[1]</ref>. We investigate a broad range of models, including traditional machine learning methods, such as Random Forests and Naive Bayes, and state-of-the-art deep learning architectures, like Transformer and BERT-based models. Experimental results show promising advancements in these areas, with specific models outperforming others depending on the task. The results contribute valuable insights towards the goal of improving the understanding, detection, and translation of puns in AI systems, ultimately promoting a more nuanced and culturally sensitive communication interface in AI technologies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Humor plays a significant role in human communication, and puns are a common form of linguistic humor. Wordplay, characterized by the creative manipulation of language rules, is a widely utilized source of humor across various creative fields such as literature, poetry, theater, advertising, and more. Its ability to capture attention, convey playfulness, and subvert expectations makes it a favored technique in titles, headlines, proper nouns, and slogans. Consequently, there is a high demand for the translation of wordplay.</p><p>However, despite the advancements in translation technology, there is a notable absence of specific support for humor and wordplay in current translation tools. The automation of humor and wordplay translation has received limited attention in research. Additionally, most AI-based translation systems heavily rely on training data, such as parallel corpora, which has historically lacked sufficient quantity and quality when it comes to humor and wordplay.</p><p>1. Double entendre: A form of wordplay that involves a phrase or expression with two different meanings, one usually more innocent or literal and the other often risqué or humorous. For example, "Time flies like an arrow; fruit flies like a banana." Here, the word "flies" is used in two different senses, creating a humorous effect. 2. A classic form of wordplay that relies on exploiting multiple meanings of a word or using words that sound similar but have different meanings. For example, "I used to be a baker, but I couldn't make enough dough. " The pun on "dough" plays with its literal meaning as a baking ingredient and its slang meaning as money. 3. Irony: A form of wordplay that involves using words to convey a meaning that is the opposite of their literal sense. Irony often relies on context and the speaker's tone of voice. For example, when it's raining heavily outside, someone might say, "What lovely weather we're having!" The contradictory statement adds a humorous or sarcastic twist to the conversation. 4. Spoonerism: A type of wordplay that involves switching the initial sounds or letters of words to create a humorous effect. For example, "You have hissed all my mystery lectures and were caught fighting a liar in the quad." The words "missed" and "history lectures" are playfully interchanged in this sentence.</p><p>Initially, this paper will provide an overview of the fundamental concepts and significance of pun detection, pun location, interpretation, and pun translation in the realm of computational linguistic research.</p><p>Pun detection <ref type="bibr" coords="2,164.49,408.64,12.83,10.91" target="#b1">[2]</ref> involves the automatic identification of puns within text or speech. It is a fundamental task that serves as a foundation for subsequent analyses. Detecting puns is crucial for various applications, including natural language processing, sentiment analysis, and information retrieval. Accurate pun detection can enhance computational models' understanding of language and improve the performance of related tasks.</p><p>Pun location <ref type="bibr" coords="2,159.08,476.39,12.82,10.91" target="#b2">[3]</ref> aims to identify the specific words or phrases in a sentence that contribute to the creation of a pun. This task requires a deep understanding of language and context.</p><p>Pun translation <ref type="bibr" coords="2,174.75,503.49,13.00,10.91" target="#b3">[4]</ref> is the process of preserving the humor and wordplay in puns when translating them across different languages. This task is particularly challenging due to cultural and linguistic differences. Accurate pun translation not only facilitates cross-cultural communication but also contributes to machine translation systems' overall effectiveness and naturalness.</p><p>This paper aims to provide a comprehensive review of the importance of pun detection, pun location, interpretation, and pun translation in research. We will examine existing techniques, methodologies, and datasets utilized in these areas, highlighting their challenges and potential applications. The objective of the JOKER workshop is to foster collaboration among translators, linguists, and computer scientists to develop an evaluation framework for creative language. The pilot tasks encompass different objectives: Pilot Task 1 involves classifying single words containing wordplay based on a given typology and providing lexical-semantic interpretations. Pilot Task 2 focuses on translating single words that incorporate wordplay. Pilot Task 3 centers around the translation of complete phrases that either encompass or include wordplay. Initially, the translation tasks will be targeted at English and French, but the inclusion of additional languages will be considered as more data becomes available.</p><p>For the Blended Intensive Program (BIP) Artificial Intelligence (AI) for Humanities in term of application: From Text Simplification to Automatic Humor Analysis, we apply a variety of machine learning and deep learning models to the tasks of pun detection, location, and translation. We commence our analysis by conducting essential Exploratory Data Analysis (EDA) on the provided dataset. Based on the insights gained from EDA, we make informed decisions throughout the stages of model selection and implementation. Our initial approach involves employing straightforward machine learning models, namely Naive Bayes (NB), Random Forest (RF), and TF-IDF Ridge. To transform the textual data into vectorized form, we utilize encoding techniques such as Bag of Words (BoW) and Frequency-Inverse Document Frequency (TF-IDF).</p><p>In addition, we delve into the realm of more advanced techniques by exploring complex deep learning models and leveraging pre-trained language models. The models under consideration include AI21, ST5, Bloom, FastText, Multi-Layer Perceptron (MLP), Long Short-Term Memory (LSTM), and Bert. Each of these models brings unique characteristics and capabilities to the table, allowing for a broad and in-depth exploration of the problem space. Based on the experimental results obtained by training our models on the [dataset], we observe promising performance, valuable insights into model interpretability, and indications of which model types excel in multilingual datasets. This paper's overall objective is to evaluate and compare the performance of these diverse models in handling puns. We aim to identify the strengths and weaknesses of each model in the context of pun detection, location, and translation, thereby contributing valuable insights to the ongoing development of sophisticated and culturally aware AI systems.</p><p>The reset of the paper is organized as follows: Section 2 focuses on brief explanation of model designing and their implementations on three different task pun detection, location, and translation Section 3 related experiment; include dataset attributes, models hyper parameters setting during model training and results comaparison. Finally, Section 4 concludes the paper with a summary of key findings and the overall significance of advancements in pun analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Until now, Automatic Humour Analysis has garnered substantial attention in research, with various scholars focusing on different facets of the subject matter. Numerous researchers have dedicated their efforts to exploring distinct aspects within the field of Humour Analysis.</p><p>The study conducted by Antonio and Davide <ref type="bibr" coords="3,307.87,565.62,13.00,10.91" target="#b4">[5]</ref> delves into the automatic recognition of humor in Italian texts, focusing on the analysis of ambiguity, particularly morphosyntactic and syntactic ambiguity. Similarly Julia and Lawrence <ref type="bibr" coords="3,316.54,592.72,12.97,10.91" target="#b5">[6]</ref> explore the computational recognition of jokes, specifically wordplay jokes, using statistical language recognition techniques. Their research draws on Raskin's theory of humor as a foundational framework. Georgina and Sajjad Kianbakht <ref type="bibr" coords="3,136.74,633.36,12.68,10.91" target="#b6">[7]</ref> put forward a novel model for translating humor in narrative texts, such as novels. Their approach adopts a multidisciplinary perspective that recognizes the interdependence of language and culture, employing the analytical framework of cultural conceptualizations.</p><p>Antonio Reyes <ref type="bibr" coords="4,170.02,86.97,13.00,10.91" target="#b7">[8]</ref> focuses on analyzing humor and irony in social media, particularly on Twitter, and proposes a model for their automatic recognition based on textual features. The results of the experiments are positive for humor and encouraging for irony.</p><p>Hannu Toivonen and Matti Järvisalo concentrate on modeling incongruity, a crucial element of humor, in joke understanding. They propose a computational model that incorporates incongruity theory to analyze and generate humorous jokes.</p><p>Another work by Danushka Bollegala and Mitsuru Ishizuka <ref type="bibr" coords="4,363.11,168.26,12.68,10.91" target="#b7">[8]</ref> delves into the task of humor recognition and presents a method for extracting humor anchors, which are significant words or phrases contributing to the humorous effect.</p><p>Significant research is currently underway in the field of automatic humor detection, with new findings emerging alongside advancements in language models, particularly pre-trained transformer-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Utilization of Existing Models and Techniques</head><p>In this section, we present the methodology employed for three different tasks in this study. We outline the steps taken to collect and preprocess the dataset, followed by the feature extraction process. Additionally, we describe the selection and training of the machine learning model, along with the evaluation metrics used to assess its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Machine Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Text Vectorization</head><p>Text vectorization is the process of converting textual data into numerical representations that can be understood by machine learning algorithms. There exist numerous methods for text vectorization, each encompassing unique approaches and distinct characteristics. In the subsequent section, we elucidate the vectorization techniques implemented throughout our model training procedure.</p><p>1. Bag-of-Words (BoW): BoW represents a document as a collection of words, disregarding grammar and word order. It creates a vocabulary of unique words and assigns a binary or frequency-based value to each word indicating its presence or occurrence in the document. 2. Term Frequency-Inverse Document Frequency (TF-IDF): TF-IDF calculates the importance of a word in a document by considering its frequency within the document (term frequency) and inversely weighing it by the frequency of the word across all documents (inverse document frequency). This technique assigns higher weights to words that are more specific to a particular document. 3. Word Embeddings: Word embeddings are dense vector representations that capture semantic meaning and contextual relationships between words. Popular algorithms for generating word embeddings include Word2Vec, GloVe, and FastText. These embeddings can be pre-trained on large corpora or learned specifically for the task at hand. 4. Transformer-based Models: Transformer-based models, such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), have revolutionized text vectorization. They utilize attention mechanisms to capture contextual information from the entire input sequence, enabling more nuanced representations of words and sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Machine learning Models</head><p>In this section, I will provide concise descriptions of the models utilized for this particular task. Below, you will find an overview of the various models employed and their respective functionalities.</p><p>Random Forest (RF) The Random Forest model is an ensemble learning method that combines multiple decision trees to make predictions. It operates by constructing a multitude of decision trees and aggregating their outputs to determine the final prediction. This approach enhances the model's accuracy and reduces overfitting by utilizing the diversity of multiple trees.</p><p>Naive Bayes (NB) The Naive Bayes model is a simple yet powerful probabilistic classifier that utilizes Bayes' theorem to make predictions. It assumes independence between the features and calculates the probability of a class given the input data. Despite its assumption of feature independence, Naive Bayes often performs well and is computationally efficient for text classification tasks.</p><p>Ridge The Ridge model is a linear regression technique that incorporates regularization to prevent overfitting in the presence of multicollinearity. It adds a penalty term to the loss function, shrinking the coefficients towards zero while still allowing them to have non-zero values. This helps in controlling the complexity of the model and improving its generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Deep Learning and Generative Models</head><p>Multilayer Perceptron (MLP) The Multilayer Perceptron (MLP) model is a type of artificial neural network that consists of multiple layers of interconnected nodes, or neurons. It is a feed-forward neural network where information flows in one direction, from the input layer through the hidden layers to the output layer. The MLP is capable of learning complex patterns and non-linear relationships, making it suitable for a wide range of classification and regression tasks.</p><p>Long short-term memory (LSTM) The LSTM (Long Short-Term Memory) model is a type of recurrent neural network (RNN) that is specifically designed to capture and retain long-term dependencies in sequential data. It addresses the vanishing gradient problem of traditional RNNs by incorporating memory cells and gating mechanisms. These components allow the LSTM to selectively remember and forget information over extended time periods, making it effective for tasks involving sequential data such as natural language processing and time series analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bidirectional Encoder Representations from Transformers (BERT)</head><p>The BERT (Bidirectional Encoder Representations from Transformers) model is a state-of-the-art language representation model based on Transformer architecture. It leverages a bidirectional training approach, allowing it to capture contextual information from both preceding and succeeding words. BERT exhibits exceptional performance in a wide range of natural language processing tasks, including sentence classification, named entity recognition, and question-answering, by effectively encoding and understanding the intricate nuances of language.</p><p>FastText The FastText classification model is a text classification algorithm that utilizes word embeddings and character n-grams to represent and classify text. It breaks down words into subword units and generates vector representations for each subword, enabling it to handle outof-vocabulary words effectively. FastText is known for its efficiency and accuracy in handling large text datasets, making it suitable for various classification tasks such as sentiment analysis and topic categorization.</p><p>SimpleT5 SimpleT5 is a model built on top of PyTorch Lightning and Transformers. It allows users to quickly train their T5 models, including T5, mT5, and byT5 models, with only a few lines of code. The T5 models, which can be trained using SimpleT5, are versatile and can be used for a variety of natural language processing (NLP) tasks. These tasks include summarization, question answering (QA), question generation (QG), translation, text generation, and more <ref type="bibr" coords="6,492.50,249.56,11.38,10.91" target="#b8">[9]</ref>.</p><p>AI21 Labs -Jurassic-2 Grande Instruct The J2-Grande-Instruct model is a variation of the Jurassic-2 series developed by AI21. It is an auto-regressive language model based on the Transformer architecture and designed with modifications for improved efficiency. The models diverge from their GPT-3 counterparts in several aspects, including vocabulary size and the depth/width ratio of the neural net <ref type="bibr" coords="6,287.17,317.30,16.41,10.91" target="#b9">[10]</ref>. This model is specifically trained to handle instructions-only prompts, also known as "zero-shot" prompts, without the need for examples or "few-shot" prompts. It aims to provide a natural way to interact with large language models and is designed to give users an idea of the optimal output for their task without needing any examples <ref type="bibr" coords="6,133.44,371.50,16.25,10.91" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BLOOM (BigScience Large Open-science Open-access Multilingual Language Model)</head><p>The BLOOM model is an autoregressive Large Language Model (LLM) that leverages a decoderonly transformer architecture, derived from Megatron-LM GPT-2. It underwent training on approximately 366 billion tokens between March and July 2022, utilizing 1.6 Terabytes of preprocessed text. This extensive dataset included 350 billion unique tokens, encompassing 46 natural languages and 13 programming languages, enabling BLOOM to grasp a wide range of linguistic and programming contexts <ref type="bibr" coords="6,256.46,466.34,16.25,10.91" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>Wordplay encompasses a diverse range of linguistic phenomena that cleverly manipulate or defy the standard rules of pronunciation, spelling, word formation, and meaning in a language. Our extensive collection ]consists of more than two thousand translated instances of wordplay sourced from various mediums such as video games and literature, primarily in English and French. Each example has undergone meticulous manual classification, categorizing it based on a comprehensive inventory of wordplay types and structures, and further annotated to identify its specific lexical-semantic or morphosemantic components.</p><p>As the foundation for our study we use a given annotated database <ref type="bibr" coords="6,418.69,640.78,16.42,10.91" target="#b12">[13]</ref>. The database comprises three key columns: id (e.g., en_6889), text (e.g., "Soft drink inventors saw a big popportunity."), and a prediction target that varies depending on the specific task. For pun detection, the target is a binary indicator (yes/no) specifying whether a pun is present in the sentence. For pun location, the target is the specific word in the sentence that forms the pun. Finally, for pun translation, the target is the French translation of the sentence, providing a means of examining how well the models can carry the pun across languages. The statistical characteristics of the data-sets used for Task 1 and Task 2 can be observed in Table <ref type="table" coords="7,116.20,376.85,3.80,10.91" target="#tab_0">1</ref>, with the data statistics sourced from the provided <ref type="bibr" coords="7,353.70,376.85,16.39,10.91" target="#b13">[14]</ref>. Upon examining the table, it becomes evident that the datasets exhibit a significant imbalance in class distribution for each language category. Specifically, in Task 1, there is a notable disparity between the number of samples belonging to the negative class in comparison to the positive class.</p><p>The observed data imbalance is particularly pronounced for Task 1, where the quantity of samples assigned to the negative class significantly exceeds the number of samples representing the positive class. This discrepancy raises concerns regarding the potential bias and limitations that may arise during the modeling and evaluation process. Such an imbalance in class distribution can lead to challenges in accurately representing and predicting the minority class, potentially affecting the overall performance and reliability of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results Analysis</head><p>In this section, we present the findings and results obtained from our study. The training measurements derived from training the basic machine learning and NLP language models are summarized in Tables <ref type="table" coords="7,211.21,574.74,5.17,10.91" target="#tab_1">3</ref> and<ref type="table" coords="7,240.32,574.74,3.81,10.91" target="#tab_3">5</ref>. These tables provide a comprehensive overview of the performance metrics, including accuracy, F1 score, recall, and precision, achieved during the training phase.</p><p>The training evaluation results indicate that the models have been effectively trained on the available training data and demonstrate strong performance on the validation dataset. The metrics suggest high accuracy, balanced F1 scores, and satisfactory recall and precision rates. This implies that the models have successfully learned the patterns and characteristics of the training data, yielding promising results during the assessment on the validation set.</p><p>However, the evaluation results on the test dataset reveal a different picture. The performance on the test set is found to be unsatisfactory. This can be attributed to the presence of a highly imbalanced dataset. The imbalance in the dataset poses a significant challenge to the model's ability to generalize well to unseen data and accurately predict the minority classes.</p><p>Thus, it becomes essential to address the issue of data imbalance effectively. Failing to address this concern makes it exceedingly difficult for the model to achieve satisfactory performance on unseen data. By employing techniques specifically designed to handle imbalanced datasets, such as oversampling, class weighting, or the utilization of specialized algorithms, we can enhance the model's performance and improve its ability to generalize to new instances. Addressing the data imbalance is crucial in ensuring the reliability and robustness of the model's predictions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In conclusion, the JOKER project has made significant advancements in enhancing our understanding and processing of creative language, particularly in the domain of humor and wordplay. The utilization of the JOKER dataset, which encompasses a vast collection of translated examples from diverse sources, has yielded valuable insights into the nuances of various wordplay types and structures. Throughout this workshop, our implemented model has demonstrated comparable performance, shedding light on the predictive capabilities of models for different languages. Wordplay and puns rely heavily on the unique linguistic characteristics of a language, such as homophones, double entendre, and phonetic similarities. Some languages naturally lend themselves to wordplay due to their specific phonetic or lexical properties. Furthermore, it is important to acknowledge that different languages exhibit distinct humor styles and preferences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,88.99,154.75,319.75,194.02"><head>Table 1 Task</head><label>1</label><figDesc></figDesc><table coords="7,88.99,166.75,319.75,182.02"><row><cell>1 and Task 2 dataset statistics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Language</cell><cell cols="2">Task 1</cell><cell cols="2">Task 2</cell></row><row><cell></cell><cell cols="2">Train</cell><cell>Test</cell><cell cols="2">Train Test</cell></row><row><cell>English</cell><cell cols="5">5,292 3.183 2,315 1,205</cell></row><row><cell>French</cell><cell cols="5">3,999 12,873 2,000 4,655</cell></row><row><cell>Spanish</cell><cell cols="3">1,994 2,241</cell><cell>876</cell><cell>960</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Task 1 dataset statistics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Language</cell><cell></cell><cell>Train</cell><cell></cell><cell></cell><cell>Test</cell></row><row><cell cols="6">Postive Negative Positive Negative</cell></row><row><cell>English</cell><cell>3,085</cell><cell cols="2">2,207</cell><cell>809</cell><cell>2,374</cell></row><row><cell>French</cell><cell>1,998</cell><cell cols="2">2,001</cell><cell>5,308</cell><cell>7,565</cell></row><row><cell>Spanish</cell><cell>855</cell><cell cols="2">1,139</cell><cell>952</cell><cell>1,289</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.98,237.92,328.40,117.69"><head>Table 3</head><label>3</label><figDesc>Accuracy, Precision, Recall and F1-Score on the Training Data-set of Task 1 (1.1).</figDesc><table coords="8,183.90,269.53,227.49,86.07"><row><cell>Model</cell><cell cols="4">Precision Recall F1-Score Accuracy</cell></row><row><cell>Jurassic-2</cell><cell>0.51</cell><cell>0.07</cell><cell>0.14</cell><cell>0.41</cell></row><row><cell>BLOOM</cell><cell>0.58</cell><cell>0.05</cell><cell>0.01</cell><cell>0.41</cell></row><row><cell>FastText</cell><cell>0.72</cell><cell>0.84</cell><cell>0.78</cell><cell>0.72</cell></row><row><cell>RF-TFIDF</cell><cell>0.99</cell><cell>0.99</cell><cell>0.99</cell><cell>0.99</cell></row><row><cell>ST5</cell><cell>0.74</cell><cell>0.92</cell><cell>0.86</cell><cell>0.77</cell></row><row><cell>TFidfRidge</cell><cell>0.87</cell><cell>0.97</cell><cell>0.92</cell><cell>0.90</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.98,389.82,322.40,117.69"><head>Table 4</head><label>4</label><figDesc>Accuracy, Precision, Recall and F1-Score on the Test Data-set Task1 (1.1).</figDesc><table coords="8,183.90,421.44,227.49,86.07"><row><cell>Model</cell><cell cols="4">Precision Recall F1-Score Accuracy</cell></row><row><cell>Jurassic-2</cell><cell>0.27</cell><cell>0.09</cell><cell>0.019</cell><cell>0.74</cell></row><row><cell>BLOOM</cell><cell>0.30</cell><cell>0.03</cell><cell>0.07</cell><cell>0.74</cell></row><row><cell>FastText</cell><cell>0.25</cell><cell>0.80</cell><cell>0.39</cell><cell>0.35</cell></row><row><cell>RF-TFIDF</cell><cell>0.25</cell><cell>0.83</cell><cell>0.39</cell><cell>0.34</cell></row><row><cell>ST5</cell><cell>0.26</cell><cell>0.93</cell><cell>0.41</cell><cell>0.34</cell></row><row><cell>TFidfRidge</cell><cell>0.26</cell><cell>0.93</cell><cell>0.41</cell><cell>0.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,88.98,541.73,250.91,81.84"><head>Table 5</head><label>5</label><figDesc>Accuracy score on Train Data set of Task 1 (2.1).</figDesc><table coords="8,255.39,573.34,84.50,50.22"><row><cell>Model</cell><cell>Accuracy</cell></row><row><cell>Ai21</cell><cell>0.42</cell></row><row><cell>BLOOM</cell><cell>0.36</cell></row><row><cell>ST5</cell><cell>0.85</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,88.98,90.49,250.91,81.84"><head>Table 6</head><label>6</label><figDesc>Accuracy score on Test Data set of Task 1 (2.1).</figDesc><table coords="9,255.39,122.10,84.50,50.22"><row><cell>Model</cell><cell>Accuracy</cell></row><row><cell>Ai21</cell><cell>0.43</cell></row><row><cell>BLOOM</cell><cell>0.46</cell></row><row><cell>ST5</cell><cell>0.80</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,403.90,394.51,10.91;9,112.66,419.89,103.79,7.90" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Knospe</surname></persName>
		</author>
		<idno type="DOI">10.1515/9783110406719-008</idno>
		<title level="m" coord="9,165.98,403.90,176.76,10.91">A Cognitive Model for Bilingual Puns</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="161" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,431.00,393.33,10.91;9,112.66,444.55,393.33,10.91;9,112.33,458.10,144.19,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,291.40,431.00,214.59,10.91;9,112.66,444.55,62.76,10.91">Semeval-2017 task 7: Detection and interpretation of english puns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">F</forename><surname>Hempelmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,196.54,444.55,309.45,10.91;9,112.33,458.10,66.29,10.91">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,471.65,393.33,10.91;9,112.33,485.20,29.19,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00175</idno>
		<title level="m" coord="9,175.44,471.65,184.79,10.91">Joint detection and location of english puns</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,498.75,389.87,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,168.01,498.75,104.47,10.91">Wordplay in translation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,280.64,498.75,143.03,10.91">Handbook of translation studies</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="180" to="183" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,512.30,393.33,10.91;9,112.66,525.85,393.33,10.91;9,112.66,539.40,395.01,10.91;9,112.41,552.94,38.81,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,262.45,512.30,243.53,10.91;9,112.66,525.85,87.61,10.91">An analysis of the impact of ambiguity on automatic humour recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,223.38,525.85,282.61,10.91;9,112.66,539.40,18.44,10.91;9,351.48,539.40,66.21,10.91">Text, Speech and Dialogue: 12th International Conference, TSD 2009</title>
		<meeting><address><addrLine>Pilsen, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">September 13-17, 2009. 2009</date>
			<biblScope unit="page" from="162" to="169" />
		</imprint>
	</monogr>
	<note>Proceedings 12</note>
</biblStruct>

<biblStruct coords="9,112.66,566.49,393.33,10.91;9,112.66,580.04,325.12,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,226.59,566.49,204.90,10.91">Computationally recognizing wordplay in jokes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Mazlack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,452.94,566.49,53.05,10.91;9,112.66,580.04,244.43,10.91">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,593.59,393.33,10.91;9,112.66,607.14,393.32,10.91;9,112.66,620.69,95.78,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,225.83,593.59,280.16,10.91;9,112.66,607.14,100.36,10.91">Applying cultural linguistics to translation studies: a new model for humour translation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Heydon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kianbakht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,221.22,607.14,284.77,10.91;9,112.66,620.69,32.14,10.91">International Journal of Comparative Literature and Translation Studies</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,634.24,393.33,10.91;9,112.66,647.79,326.38,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,250.83,634.24,255.16,10.91;9,112.66,647.79,107.25,10.91">From humor recognition to irony detection: The figurative language of social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,228.74,647.79,141.58,10.91">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,661.34,351.59,10.91" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<ptr target="https://pypi.org/project/simplet5/" />
		<imprint>
			<date type="published" when="2022">2022. 2023-06-05</date>
		</imprint>
	</monogr>
	<note>simplet5</note>
</biblStruct>

<biblStruct coords="10,112.66,86.97,395.17,10.91;10,112.66,100.52,394.04,10.91;10,112.66,114.06,357.36,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,320.22,86.97,187.62,10.91;10,112.66,100.52,27.10,10.91">Jurassic-1: Technical Details and Evaluation</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Lieber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
		<idno>AI21</idno>
		<ptr target="https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>Labs</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="10,112.66,127.61,394.61,10.91;10,112.66,141.16,50.36,10.91" xml:id="b10">
	<monogr>
		<ptr target="https://docs.ai21.com/docs/instruct-models" />
		<title level="m" coord="10,112.66,127.61,94.45,10.91">Instruct models</title>
		<imprint>
			<date type="published" when="2023-06-05">2023. 2023-06-05</date>
		</imprint>
	</monogr>
	<note>AI21</note>
</biblStruct>

<biblStruct coords="10,112.66,154.71,395.00,10.91;10,112.66,170.70,97.35,7.90" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Workshop</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m" coord="10,175.65,154.71,301.39,10.91">Bloom: A 176b-parameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,181.81,393.33,10.91;10,112.66,195.36,394.52,10.91;10,112.39,208.91,202.55,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,311.49,181.81,194.49,10.91;10,112.66,195.36,233.85,10.91">Assessing wordplay-pun classification from joker dataset with pretrained bert humorous models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename><surname>Preciado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,370.22,195.36,132.17,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="1828" to="1833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,222.46,393.32,10.91;10,112.26,236.01,176.74,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,292.59,222.46,213.39,10.91;10,112.26,236.01,78.92,10.91">Overview of joker -clef-2023 track on automatic wordplay analysis</title>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><forename type="middle">B</forename><surname>Liana Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tristan</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,213.98,236.01,45.05,10.91">CLEF 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
