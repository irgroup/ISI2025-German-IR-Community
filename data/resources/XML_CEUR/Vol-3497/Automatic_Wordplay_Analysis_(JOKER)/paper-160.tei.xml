<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.00,77.76,450.98,14.99;1,72.00,98.51,451.26,14.99;1,72.00,119.26,357.11,14.99">Does AI Have a Sense of Humor? CLEF 2023 JOKER Tasks 1, 2 and 3: Using BLOOM, GPT, SimpleT5, and More for Pun Detection, Location, Interpretation and Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.00,144.98,62.33,10.54"><forename type="first">Olga</forename><surname>Popova</surname></persName>
							<email>olga.popova@uca.es</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Cadiz</orgName>
								<address>
									<addrLine>9 Paseo Carlos III St</addrLine>
									<postCode>11003</postCode>
									<settlement>Cadiz</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Applied Linguistics (ILA)</orgName>
								<address>
									<addrLine>16 Avenida Duque de Nájera</addrLine>
									<postCode>11002</postCode>
									<settlement>Cadiz</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,168.64,144.98,56.31,10.54"><forename type="first">Petra</forename><surname>Dadić</surname></persName>
							<email>petradadic313@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Split</orgName>
								<address>
									<addrLine>33 Ruđera Boškovića St</addrLine>
									<postCode>21000</postCode>
									<settlement>Split</settlement>
									<country key="HR">Croatia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.00,77.76,450.98,14.99;1,72.00,98.51,451.26,14.99;1,72.00,119.26,357.11,14.99">Does AI Have a Sense of Humor? CLEF 2023 JOKER Tasks 1, 2 and 3: Using BLOOM, GPT, SimpleT5, and More for Pun Detection, Location, Interpretation and Translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FDF91CFBB55B46A4F9DC2155B2DD0F8B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pun detection</term>
					<term>pun location</term>
					<term>pun interpretation</term>
					<term>pun translation</term>
					<term>CLEF2023</term>
					<term>JOKER</term>
					<term>automatic humor analysis 1</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wordplay is a vital aspect of human communication, involving creative language use to convey multiple meanings and induce humor. Automating wordplay analysis is challenging but made possible by advances in natural language processing (NLP). This study focuses on detecting, localizing, interpreting, and translating wordplay using Python and AI methods. Cultural influences on humor and wordplay are considered, particularly in English, French, and Spanish. The JOKER track at CLEF 2023 aims to advance automated humor analysis by bringing linguists, translators, and computer scientists together. Four pilot tasks are proposed: pun detection in multiple languages, pun interpretation, and pun translation from English to French and Spanish. The study provides an introduction, background on puns and wordplay, an overview of CLEF 2022 and 2023, and discusses methods, results, and future research directions. By leveraging NLP techniques, this work tries to bridge linguistic and computational approaches to enhance automated wordplay analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="596.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Wordplay is an essential aspect of human communication that involves the creative use of language to convey multiple meanings or to produce a humorous effect. In our daily life we resort to different language resources to express our feelings and emotions, one of these resources is wordplay. It is not necessarily humorous, it can contain irony or sarcasm, and if sometimes it is already difficult to capture it in a human communication, to do it automatically is logically even more complicated. However, it is not impossible, with the advent of natural language processing (NLP) techniques, machines can now perform these tasks with increasing accuracy and efficiency. In this working notes we focus on the detection, location, interpretation and translation of word sets using the Python programming language and different methods provided by artificial intelligence and machine learning.</p><p>We must take into account that humor and wordplay is a cultural phenomenon that is linked to the historical experience and background knowledge of the speakers of each language. Since we worked with English, French and Spanish, we had to be attentive to the particularities of each of these languages.</p><p>To advance in the automation of humor and wordplay analysis, we decided to take part in the JOKER track at CLEF 2023. The goal is to bring together linguists or translators and computer scientists to further the computational analysis of humor. This workshop proposed three pilot tasks <ref type="bibr" coords="2,72.00,87.64,11.90,9.66" target="#b0">[1]</ref>:</p><p>• Pilot Task 1: Detection of puns in English, French, and Spanish • Pilot Task 2: Location and interpretation of puns in English, French, and Spanish • Pilot Task 3: Translation of puns from English to French and Spanish These working notes are organized as follows: after the introduction, there is the background section where pun and wordplay definitions and an important terms for interpretation are described, moreover, in this section we do an overview of CLEF 2022 and CLEF 2023; the third section is dedicated to the approach (data and methods description), the fourth section is the discussion of the results, and the fifth section is the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>In this section we will make a brief overview of the state-of-the-art. In addition, we will clarify some terms by providing their definitions and necessary explanations, such as wordplay, pun, synonym, target synonym and machine translation. We will also summarize what was done in the CLEF 2022 edition, which will help us to choose the trajectory of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pun and wordplay definitions</head><p>The first two tasks consist in wordplay detection and location. In this way, we should start defining the two main terms of this task, which are wordplay and pun.</p><p>To begin with, we turn to some of the most relevant online dictionaries: Oxford Learner's Dictionaries and Cambridge Dictionary. The definitions that can be found there are the following:</p><p>• Wordplay1: making jokes by using words in a clever and humorous way, especially by using a word that has two meanings, or different words that sound the same (Oxford Learner's Dictionaries). • Wordplay2: the activity of joking about the meanings of words, especially in an intelligent way (Cambridge Dictionary). • Pun1: the clever or humorous use of a word that has more than one meaning, or of words that have different meanings but sound the same (Oxford Learner's Dictionaries). • Pun2: a humorous use of a word or phrase that has several meanings or that sounds like another word (Cambridge Dictionary). At first glance it may seem that these two terms mean the same thing or in other words they are synonyms. But we have to say that there is a lot of research from the linguistic point of view that shows that the term wordplay is much broader. Winter-Froemel <ref type="bibr" coords="2,373.25,514.27,12.82,9.66" target="#b1">[2]</ref> defines the wordplay like: "a historically determined phenomenon in which a speaker produces an utterance -and is aware of doing so -that juxtaposes or manipulates linguistic items from one or more languages in order to surprise the hearer(s) and produce a humorous effect on them".</p><p>Moreover, Winter-Froemel <ref type="bibr" coords="2,209.04,564.87,12.82,9.66" target="#b1">[2]</ref> proposes a classification in the form of a table, which allows us to understand that the phenomenon of wordplay is much broader and more complex than in the definition of the two dictionaries mentioned at the beginning of this section. This table is reproduced below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Subtypes of wordplay in a large sense and verbal humour <ref type="bibr" coords="2,329.27,642.28,12.31,9.70" target="#b1">[2]</ref> Verbal Humour Wordplay (broad sense) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cf. parody</head><p>This table confirms the definition of Delabastita <ref type="bibr" coords="3,301.73,640.42,11.90,9.66" target="#b2">[3]</ref>: "Wordplay is the general name for the various textual phenomena in which structural features of the language(s) used are exploited in order to bring about a communicatively significant confrontation of two (or more) linguistic structures with more or less similar forms and more or less different meanings".</p><p>Regarding puns, Attardo <ref type="bibr" coords="3,201.87,691.02,12.82,9.66" target="#b3">[4]</ref> defines it like: "a textual occurrence in which a sequence of sounds must be interpreted with a reference to a second sequence of sounds, which may, but need not, be identical to the first sequence, for the full meaning of the text to be accessed".</p><p>Based on all of the above, we can conclude that wordplay is a broader term and pun is part of wordplay as many other subtypes presented in Table <ref type="table" coords="3,310.66,741.61,4.12,9.66">1</ref>. As Attardo <ref type="bibr" coords="3,375.19,741.61,12.82,9.66" target="#b3">[4]</ref> says "the field of wordplay is beset by terminological problems", which will not be solved in these working notes. However, we have to be clear that in all tasks we actually work not so much with puns but with wordplay, because this one can take a lot of forms we observe in our data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Important terms for interpretation</head><p>One of the tasks is dedicated to the interpretation of wordplays. From the content of the training data provided by the creators of these tasks, we understood that the interpretation consisted of finding pun synonyms and target synonyms for the previously located wordplays (locations). In this section we consider it necessary to provide explanations for these two terms.</p><p>To observe the difference between pun synonym and target synonym we will take one of the examples we have in the training data.</p><p>• Example 1. Old chicken farmers never die, they just have a dozen aches. In the sentence the wordplay is based on the use of words that sound similar but have different meanings.</p><p>In this case, the pun synonym is the word "dozen", which sounds like the word "dying." The pun works because the phrase "dozen aches" sounds like "doesn't ache" when spoken out loud. The phrase "Old chicken farmers never die" is a play on the familiar saying "Old soldiers never die, they just fade away", and the word "dozen" is used as a pun to replace the word "dying" in the original saying.</p><p>On the other hand, the target synonym in this sentence is the word "aches", which is the word that is the focus or target of the pun. The phrase "dozen aches" creates a play on words with the phrase "doesn't ache", which gives the impression that the old chicken farmers are not dying but instead just experiencing some minor aches and pains.</p><p>Overall, the use of pun synonyms and target synonyms in this sentence helps to create a clever and humorous expression that plays on the sound and meaning of words. By using language in this way, the sentence creates a humorous twist on a familiar saying and adds a playful tone to the discussion of aging and physical discomfort.</p><p>This way we can conclude that the pun synonym is a word that is used in a pun in place of another word that has a similar sound or spelling; and the target synonym is a word that is the focus or target of a pun or wordplay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Humor and wordplay translation</head><p>Nowadays, translation in general and humor translation in particular are very important, especially due to globalization and intercultural communication. Translating jokes and puns is a real challenge for translators, because they are not faced with a simple search for lexical and grammatical equivalents, but must take into account the particularities of each language, interpret cultural references and make the joke funny to the recipient of the translation.</p><p>Translators can find humor in almost any type of assignment, be it a political speech, a recipe video, movie or series. The work of the translators of "The Last of Us" series recently released on HBO is truly admirable. They had to translate the jokes from a fictional book called "No Pun Intended: Volume Too", which appear throughout the series and play an important role in the plot. Such puns like "3.14% of sailors are Pi Rates", "I used to be addicted to soap. But I'm clean now", "You wanna hear a joke about pizza? Never mind, it was too cheesy" and many others were translated into Spanish, Italian, Portuguese, French among others. In the case of this series, the translation, at least into Spanish, is very successful. But there are many other movies or series where sometimes the translated jokes are not understood. The choice of strategy for any given pun depends on various factors <ref type="bibr" coords="4,106.15,665.77,11.68,9.66" target="#b4">[5]</ref>, and while strategies that preserve wordplay are generally preferable, they are often the most challenging to pull off. If human translators have a hard time making a decision about the translation of a joke and not fail, machine translation still has a lot to improve.</p><p>Although we must say that with the advent of neural machine translation (NMT), the results have improved significantly. As Stahberg <ref type="bibr" coords="4,264.94,716.36,12.82,9.66" target="#b5">[6]</ref> says, "the advent of NMT certainly marksone of the major milestones in the history of MT, and has led to a radical and sudden departure of mainstream research from many previous research lines." NMT has already been widely adopted in industry <ref type="bibr" coords="4,500.19,741.66,11.91,9.66" target="#b6">[7,</ref><ref type="bibr" coords="4,514.84,741.66,8.25,9.66" target="#b7">8,</ref><ref type="bibr" coords="4,72.00,754.31,8.25,9.66" target="#b8">9,</ref><ref type="bibr" coords="4,85.99,754.31,14.66,9.66" target="#b9">10]</ref> and is deployed in production systems by Google, Microsoft, Facebook, Amazon, SDL, Yandex, and many more. In this work we have used both neural machine translation (GPT-3, Bloom, Google) and some pre-training models (Simple-T5 and EasyNMT).</p><p>Researchers have been taking an increasing interest in the use of language technology in creative translation in general, and humor translation in particular, including the integration of MT systems into human translation workflows <ref type="bibr" coords="5,275.99,125.58,16.99,9.66" target="#b10">[11,</ref><ref type="bibr" coords="5,298.73,125.58,13.74,9.66" target="#b11">12,</ref><ref type="bibr" coords="5,318.22,125.58,13.74,9.66" target="#b12">13,</ref><ref type="bibr" coords="5,337.70,125.58,13.05,9.66" target="#b13">14]</ref>. However, puns are not suitable for off-the-shelf, end-to-end MT systems, particularly those based on the prevailing neural paradigm <ref type="bibr" coords="5,501.72,138.23,16.85,9.66" target="#b14">[15]</ref>. And while others have pointed out the potentials of digital tools to assist literary translation processes <ref type="bibr" coords="5,72.00,163.53,16.85,9.66" target="#b15">[16]</ref>, no currently available tool specifically supports the translation of puns <ref type="bibr" coords="5,408.39,163.53,16.85,9.66" target="#b16">[17]</ref>.</p><p>However, in this work we try to approach the translation of puns using different MT tools, assess the quality of the translations made and analyze the main problems. All this is described in parts 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Overview of CLEF 2022 and CLEF 2023</head><p>The JOKER project aimed to advance the automation of creative-language translation by organizing the JOKER track at CLEF 2022. Participants succeeded in wordplay location, but the interpretation tasks raised difficulties and the binary classes were unbalanced. Style shift in the translation of puns could pose an issue. In the previous edition of CLEF, Pilot Task 1 involved classifying and explaining instances of wordplay, with one team successfully predicting the location and interpretation of the wordplay. Pilot Task 2 required participants to translate single terms containing wordplay, with all participants successfully translating all instances. In Task 3, participants had to translate phrases containing wordplay from English to French, but only 13% of automatically translated wordplays were successful <ref type="bibr" coords="5,250.05,357.70,16.85,9.66" target="#b17">[18]</ref>. These results lead us to the conclusion that machine translation is still inadequate for translating puns. Successful machine translations were apparently accidental due to the existence of the same ambiguous word in both languages.</p><p>In relation to CLEF 2023, the results of the previous edition and the lessons learned from it have been taken into account. JOKER-2023 aims to expand tasks including Spanish, simplify shared tasks and focus on one type of wordplay, puns. Puns are often considered untranslatable, making them a good focus for the research. As we have already mentioned, the three shared tasks for JOKER-2023 are: detection of puns, location and interpretation of puns, and translation of puns from English to French and Spanish. The hope is that with a larger data set and more interconnected tasks, JOKER-2023 will provide better performance <ref type="bibr" coords="5,276.82,471.54,11.68,9.66" target="#b0">[1]</ref>.</p><p>The following is a brief description of the tasks and the data provided for their completion. The first task is to detect puns in English, French, and Spanish. Pun detection involves distinguishing between texts containing a pun and those that do not. The data is split into training and test sets. The English data includes positive examples from SemEval-2017 Task 7 and SemEval-2021 Task 12, while the French data is based on a corpus created in 2022 and will be improved and extended for JOKER-2023. The Spanish data set is collected from various web sources. Evaluation will be done using precision, recall, accuracy, and F-score measures for pun detection, and precision, recall, and F-score measures for pun location <ref type="bibr" coords="5,272.84,572.74,11.68,9.66" target="#b0">[1]</ref>.</p><p>Pun Location and Interpretation is the second task where systems have to identify the words with double meanings in a pun-filled text and find the two meanings of a pun. The data sets will contain synonyms or hypernyms of the words involved in the pun, except for those that share a spelling with the pun. This annotation scheme allows systems to avoid relying on a specific sense inventory or notation scheme. The data for this task will be taken from Task 1, with each pun word annotated with two sets of words, one for each meaning of the pun. The evaluation will be based on precision, recall, and F-score metrics used in word sense disambiguation, with each instance being scored as the average score for each of its senses <ref type="bibr" coords="5,229.18,673.93,11.68,9.66" target="#b0">[1]</ref>.</p><p>The objective of the third task is to translate English puns into French and Spanish while preserving the original wordplay using the PUN→PUN strategy. Updated training and test sets of punning jokes in English-French will be provided, as well as new sets in English-Spanish. The evaluation of the translations will be done manually by trained experts who will evaluate features such as preservation of lexical field, sense, wordplay form, style shift, and humorousness shift, as well as the presence of errors in syntax, word choice, and other factors. The runs will be ranked based on the number of successful translations that maintain the form and meaning of the original wordplay, and we will also experiment with other semi-automatic metrics <ref type="bibr" coords="6,333.30,87.64,11.68,9.66" target="#b0">[1]</ref>.</p><p>In the next section, 3. Approach, we will describe the methods used to carry out each of the tasks, which is why this section is divided into three sections (by tasks), every section includes data description and one more section with methods used to execute the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>In this section we will give a brief description of the data provided to perform each task and the methods used to solve them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Task 1: Detection of puns in English, French, and Spanish</head><p>The data for Task 1 (pun detection) consists of positive examples, which are short jokes containing a single pun. These examples will be drawn from existing corpora and new collections. Negative examples, used only for the pun detection subtask, will be generated through data augmentation techniques. These techniques involve manually or semi-automatically editing positive examples to remove the wordplay while preserving most of the remaining meaning. This approach aims to minimize differences in length, vocabulary, style, etc., to prevent neural approaches from simply detecting these differences.The train and the test data are provided in JSON and CSV formats <ref type="bibr" coords="6,485.71,311.55,11.68,9.66" target="#b0">[1]</ref>.</p><p>Below is a table with the size of the data provided. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Task 2: Location and interpretation of puns in English, French, and Spanish</head><p>Then in task 2.1 (pun location) we have to identify a specific word that contains the pun. We have been given the training data with the word already found and the test data only with the text of the joke. The output (results) is practically the same as in task 1.1, but instead of yes or no we would have to put the location.</p><p>The data for task 2.2 (pun interpretation) is based on the positive examples, where the pun word is annotated with two sets of words representing each sense of the pun from task 1. Each set will include synonyms or hypernyms of the respective sense or, in the case of heterographic puns, the underlying target word <ref type="bibr" coords="6,124.91,570.65,11.68,9.66" target="#b0">[1]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Task 3: Translation of puns in English, French, and Spanish</head><p>The objective of this task is to translate English punning jokes into French and Spanish while preserving both the form and meaning of the original wordplay. The translation approach should follow Delabastita's pun→pun strategy, as described in the typology of pun translation strategies. For instance, the English example "I used to be a banker but I lost interest" could be translated into French as "J'ai été banquier mais j'en ai perdu tout l'intérêt," where the pun is maintained due to the shared ambiguity between "interest" and "intérêt." <ref type="bibr" coords="7,263.93,167.97,12.82,9.66" target="#b0">[1]</ref> The task will provide an updated training and test set of English-to-French translations of punning jokes, as well as new sets of English-to-Spanish translations, similar to the English-to-French datasets created for JOKER-2022. The train and the test data are provided in JSON and CSV formats. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Methods</head><p>In this section we will describe how we approach each of the tasks. First, we provide a table summarizing the methods used for each exercise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">TF-IDF Ridge</head><p>TF-IDF (term frequency-inverse document frequency) is a numerical statistic used in information retrieval to measure the significance of a word in a document within a collection or corpus. It combines the frequency of a term in a document (TF) with its rarity across the corpus (IDF) to determine its importance <ref type="bibr" coords="7,184.02,606.08,16.85,9.66" target="#b18">[19]</ref>. It was used for task 1. We used TF-IDF Ridge with the following code: from sklearn.linear_model import RidgeClassifier clf = RidgeClassifier(tol=1e-2, solver="sparse_cg") clf.fit(X_train, y_train) pred = clf.predict(X_test)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">SimpleT5</head><p>SimpleT5 is a Python framework that is open-source and built on top of PyTorch-lightning and Transformers. It simplifies the process of training and fine-tuning T5 models. With SimpleT5, you can easily train T5 models for various NLP tasks like summarization, translation, question-answering, and text generation. It provides a streamlined and user-friendly interface, allowing you to quickly develop and deploy T5 models for your specific NLP needs <ref type="bibr" coords="8,299.42,87.64,16.85,9.66" target="#b19">[20]</ref>.</p><p>Since this method has a very wide scope of operation, in other words, it can be trained for almost any task, so we used it in all exercises. Also, the function for all tasks was the same, the only thing we had to do was to change the names of the columns in the training data: source_text and target_text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.">Random</head><p>As task 1.1. was all we had to do was to get the answer "YES" or "NO", one of the methods we used was Random. Specifically, we turned to the randit() function.</p><p>data_name["Random"]=["YES" if randint(0,1)==1 else "NO" for i in range(len(data_name))] randint() is a built-in function of the random module in Python that returns a random integer between the higher and lower limit passed as parameters. randint() takes only integer type parameters and generates an integer type random value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4.">Naive Bayes</head><p>The multinomial Naive Bayes classifier is suitable for classification with discrete features, such as word counts in text classification. Typically, integer feature counts are required for the multinomial distribution. However, in practice, fractional counts like tf-idf can also be used. This classifier utilizes Bayes' theorem to calculate the probability of a document belonging to a specific class based on the frequencies or counts of its features. It is widely used in natural language processing tasks due to its simplicity and efficiency in text classification <ref type="bibr" coords="8,293.09,390.76,16.85,9.66" target="#b20">[21]</ref>. It was used for task 1 with vectorised text sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.5.">MLP</head><p>The MLP (Multi-Layer Perceptron) Classifier is a type of artificial neural network that is commonly used for classification tasks. The MLP Classifier learns from labeled training data to make predictions on unseen data by adjusting the weights of the connections between nodes through a process called backpropagation. It is a versatile classifier capable of handling complex patterns and is widely used in various domains, including image recognition, natural language processing, and recommendation systems <ref type="bibr" coords="8,190.67,509.04,16.85,9.66" target="#b21">[22]</ref>. We used it in task 1.1 with vectorised text sentences as what we needed was precisely the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.6.">Logistic regression</head><p>Logistic regression is a widely used classification technique belonging to the group of linear classifiers. It shares similarities with polynomial and linear regression. It is a fast and straightforward method, making it convenient for result interpretation. While primarily used for binary classification, logistic regression can also be extended to handle multiclass problems. Its simplicity and interpretability make it a fundamental tool in the field of classification <ref type="bibr" coords="8,391.90,614.67,16.85,9.66" target="#b22">[23]</ref>. It also was used to solve task 1 with vectorised text sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.7.">Fast Text</head><p>We also use FastText for the detection of puns. It is a text classifier. Text classification is a task that involves assigning documents, such as emails, posts, or product reviews, to specific categories or tags. These categories can represent various aspects, such as sentiment, topic, or language. Machine learning is the predominant approach used to develop text classifiers, where classification rules are learned from labeled data. So we pre-trained the model and applied it to our test data in task 1 with vectorised text sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.8.">SpaCy</head><p>SpaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython <ref type="bibr" coords="9,272.67,104.72,16.85,9.66" target="#b23">[24]</ref>. In the case of our work we try to apply this method to the location (task 2.1) of puns and interpretation or more specifically synonym search (task 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.9.">GPT3</head><p>GPT is a pre-trained transformer large scale language learning model <ref type="bibr" coords="9,393.85,159.76,16.85,9.66" target="#b24">[25]</ref>. GPT3 was used for task 2.1, 2.2, and 3, limiting the number of examples (100 per task) due to the token issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.10.">BLOOM</head><p>BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model <ref type="bibr" coords="9,254.65,227.45,16.85,9.66" target="#b25">[26]</ref>. BLOOM was used for task 2.1, 2.2, and 3, limiting the number of examples (100 per task) due to the token issue.</p><p>The prompts used for each task are provided below.</p><p>Task 2.1 (EN), prompt for GPT3 and BLOOM: "Sentence: Herbivores come in browns and graze. Pun: graze Sentence: I used to do rock climbing as a youth, but I was much boulder back then. Pun: boulder Sentence: She dumped him because of all their lousy dates. After all, whining and dining does get tiresome after a while. Pun: whining Sentence: When you're wearing a watch on an airplane, time flies. Pun:" Task 2.1 (FR), prompt for GPT3 and BLOOM: "Sentence: Certaines personnes prennent des photos magnifiques et les coupent en morceaux. C'est un vrai puzzle pour moi. Pun: puzzle Sentence: Docteur, docteur, je continue à penser que je suis une cuillère. -Assieds-toi là et ne remue pas. Suivant. Pun: remue Sentence: Le mannequin qui avait rejoint les forces de l'air était une bombe. Pun: bombe Sentence: Ce n'était pas la pomme poussant sur l'arbre de la connaissance le problème, c'était les deux poires en dessous. Pun:" Task 2.1 (ES), prompt for GPT3 and BLOOM: "Sentence: Los diabéticos no deberían tener dulces sueños. Pun: dulces Sentence: Al amanecer me van a pasar por la guillotina y mi mujer ya ha firmado la separación. Pun: separación Sentence: Me mudé y tuve que buscar otros médicos después de estar cinco años con el mismo quiropráctico. Fue un mero ajuste. Pun: ajuste Sentence: Un científico estaba haciendo un gran experimento con químicos en estado líquido cuando se cayó y pasó a ser parte de la solución. Pun:" Translation: Me mudé y tuve que buscar otros médicos después de estar cinco años con el mismo quiropráctico. Fue un mero ajuste. Original: A scientist doing a large experiment with liquid chemicals was trying to solve a problem when he fell in and became part of the solution. Translation: Un científico que hacía un gran experimento con productos químicos líquidos estaba intentando solucionar un problema cuando cayó en que él se convertiría en parte de la solución. Original: Old electricians never die, they just keep plugging away.</p><p>Translation:"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.11.">WordNet</head><p>WordNet <ref type="bibr" coords="11,131.27,117.19,18.32,9.66" target="#b26">[27]</ref> is a large English language dictionary that can be used in python as a part of NLTKlibrary <ref type="bibr" coords="11,132.34,129.84,16.85,9.66" target="#b27">[28]</ref>. We used it in task 2.2 (interpretation) to search synonyms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.12.">Googletrans</head><p>Googletrans is a free and unlimited python library that implemented Google Translate API <ref type="bibr" coords="11,492.53,173.00,16.85,9.66" target="#b28">[29]</ref>. It was used to solve task 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.13.">EasyNMT-Opus and EasyNMT-mbart</head><p>EasyNMT is an easy to use python library for Machine Translation. This library is developed by NLP researchers from UKP Lab, TU Darmstadt <ref type="bibr" coords="11,286.56,240.69,16.85,9.66" target="#b29">[30]</ref>. It has a lot of models, but we decided to use two more well-known ones (Opus and mbart) for the pun translation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this section we will present the main results of our approach applied to the tasks and their discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Task 1. Pun detection</head><p>For the results of our runs for pun detection we compare four parameters: precision (proportion of positive actually correct identifications), recall (proportion of actual positives was identified correctly), f1 (harmonic mean of the precision and recall), and accuracy (fraction of predictions the model got right) in English, Spanish and French data.  We can observe that the best precision in general was achieved for the French data, then for Spanish data, and the precision for English data is less than 50%. The method that worked best with the French and English data is SimpleT5 and MLP for Spanish. As for recall metrics, the runs for English data have the best results, especially the NBC method (95%). The results for Spanish and French data are practically the same. We can make a curious observation that the metric for the data in the three languages is practically the same with Random (66-67%). Thus the probability of success with this method is logically more or less 50%, but it is not reliable, as the predictions are made randomly.  As the f1 metric is a harmonic mean of precision and recall.  Finally, we will analyze the accuracy. It is surprising that the results for the English data are worse than for the French and Spanish data, when most of the methods and libraries are supposedly developed on the basis of English. Due to the figure <ref type="figure" coords="14,310.59,342.44,5.50,9.66" target="#fig_3">4</ref> we can conclude that the best method for pun detection in English is SimpleT5 (50% accuracy), in French is SimpleT5 too but with better score (69% accuracy), and for Spanish is MLP method (61% accuracy).</p><p>It is really interesting to note that each method has given such different results for each language. But it must also be said that none of the methods applied has reached even 90% accuracy. So the results in general, even if they are above 50%, can be improved, since it is simply a binary prediction. We consider that with the current level of development of Artificial Intelligence the methods applied should work better with this type of exercise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Task 2.1. Pun location</head><p>Since this task does not involve any binary classification, but rather the location of the pun, we can analyze only the accuracy, comparing the results for English, Spanish and French.    According to figure <ref type="figure" coords="15,181.69,702.63,5.50,9.66" target="#fig_5">6</ref> the best results for the pun location were achieved with GPT3 (81% for English, 46% for French and 87% for Spanish). Then we can observe that SimpleT5 was very successful (79% for English, 45% for French and 82% for Spanish). Despite our expectations, BLOOM has not been very accurate. And SpaCy (figure <ref type="figure" coords="15,329.66,740.57,4.58,9.66" target="#fig_4">5</ref>) directly proved that it does not have such a well-developed library, especially in French, as its result was 0%. In general, the results for French data are worse than for English or Spanish, we can suppose that the French database is not well-developed and the methods we use are not well-trained for this language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Task 2.2. Pun interpretation</head><p>We will now briefly discuss the results of the second task. First, we provide a table with some examples of pun interpretation (source synonyms and target synonyms). In this table we provide only some of the examples. As we can see only BLOOM gives the consistent results, differentiating source and target synonyms. The other methods still need a lot of training in order to achieve good interpretation results, as many of them give the same words for two columns. We expected better results from GPT3, but possibly due to some mistake or an incorrect prompt in many of the cases it has given the word "eggs" as target synonym regardless of the joke and the pun.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Task 3. Pun translation</head><p>In this subsection we will describe the results of Task 3 (pun translation). As indicated above, we use six different methods to carry out this task. Below, we present a table containing some examples of the translations (English-Spanish) carried out with each of the methods and ordered in order from the best to the worst translation. It should be noted that the spelling and grammar obtained are preserved in the table (we emphasize this, as SimpleT5, for example, contains numerous spelling mistakes in Spanish). In this table we provide only some of the examples. As we can see, the translation done by SimpleT5 is quite incoherent and contains many spelling mistakes. Not even the general meaning of the sentence is translated well, not to mention the puns. We believe that this problem is due to very little training data.</p><p>The other methods produced fairly acceptable translations. Jokes where the wordplay is quite obvious and easy, e.g. "I've got to fix the automobile, said Tom mechanically" or "The boy swallowed a pillow, the hospital described his condition as comfortable" are understood in the target language. However, the methods used were less successful with the more complicated jokes to convey their meaning in Spanish. The best translations of more complex jokes were achieved with GPT3 and BLOOM. Among the examples in the table is the following: "When the fog burns off it won't be mist". Only BLOOM has managed to retain the Spanish pun and produce a comic effect. The translation was as follows: "Cuando se disipe la niebla no será una bruma". To translate the word "mist", BLOOM is the only method that chooses "bruma", having many other simpler options. This word is similar to "broma", only one letter is changed, so the pun is achieved. We don't know if it is a matter of luck or a "conscious" choice of translation.</p><p>We obtained very similar results for the English-French translation, the only difference being that SimpleT5 performed better (the training data for the French was much more extensive.). Those with scissors shouldn't use cutting words.</p><p>A skier retired because he was going downhill.</p><p>Je dois réparer l'automobile, dit Tom mécaniquement.</p><p>Ceux qui ont des ciseaux ne devraient pas utiliser des mots coupants.</p><p>Un skieur a pris sa retraite parce qu'il allait descendre.</p><p>We can conclude that the translation of puns still poses a great challenge for machine translation. We believe it needs more training materials and time to improve the results obtained. Very often even humans are not able to convey a joke in another language as it was said in the source language, as it is not always possible to find the direct equivalents of the puns. Therefore, translators have to make many transformations and sometimes even completely rewrite the joke, which requires more intellectual, cultural and linguistic effort than artificial intelligence has today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Limitations</head><p>The tasks were solved by two students, i.e. not professional programmers or computer scientists, but beginners in the field. Thus, during the implementation of the activities, some problems and lack of knowledge inevitably arose.</p><p>In addition, we highlighted as a limitation the use of the free Google Colaboratory, as the execution of some methods was very time-consuming. We found that Google Colab stops execution after 4 hours. Therefore, in the case of translation with Googletrans we had to split the data into four parts to perform the task. For SimpleT5 we had to use the GPU-connection, but it is not permitted to use more than one notebook with GPU at the same time. Moreover, sometimes Google Colab had a restriction to run with GPU more than some times in one day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this report we have described some theoretical issues about humor, puns and wordplay. And we have provided the results of three tasks: pun detection, location, interpretation and translation. We have submitted 21 runs for pun detection, 12 runs for pun location, 6 runs for pun interpretation and 12 runs for pun translation carried out with different methods such as TF-IDF, SimpleT5, Random, Naive Bayes, MLP, Logistic Regression, Fast Text, SpaCy, GPT3, BLOOM, WordNet, Googletrans, EasyNMT-Opus and EasyNMT-mbart. So we had both pre-training methods and neural models. We worked with the data in English, French and Spanish.</p><p>We compared the results obtained with all these methods and came to a general conclusion that artificial intelligence can perform the more or less simple tasks such as pun detection and location with relative success, but more complicated tasks such as pun interpretation and translation still require a lot of improvement. So, does artificial intelligence have a sense of humor? So far not much, but he is developing it little by little and still has a long way to go to get the perfect results, which we also believe will not be possible without human review as well. At least not in the very near future.</p><p>As perspectives for future work we could focus on tasks 2 and 3 to see how it would be possible to teach the machine to differentiate between source and target synonyms and to find more creative ways of translation. Also, more attention needs to be paid to the development of libraries, models and databases not only in English but also in other languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,86.25,87.45,183.03,9.66;10,72.00,99.98,107.87,9.59;10,72.00,112.44,371.16,9.59;10,72.00,124.91,67.36,9.59;10,72.00,137.37,236.14,9.59;10,72.00,149.83,87.61,9.59;10,72.00,162.29,330.65,9.59;10,72.00,174.75,80.86,9.59;10,72.00,187.21,168.63,9.59;10,86.25,212.24,436.43,10.59;10,72.00,225.70,87.61,9.59;10,86.25,250.74,168.98,9.66;10,72.00,263.27,269.89,9.59;10,72.00,275.74,418.42,9.59;10,72.00,288.20,377.91,9.59;10,72.00,300.66,450.67,9.59;10,72.00,313.12,134.87,9.59;10,72.00,325.58,450.67,9.59;10,72.00,338.04,450.67,9.59;10,72.00,350.50,40.36,9.59;10,72.00,362.96,450.67,9.59;10,72.00,375.42,450.67,9.59;10,72.00,387.89,101.12,9.59;10,72.00,400.35,450.67,9.59;10,72.00,412.81,20.10,9.59;10,72.00,425.27,323.90,9.59;10,72.00,437.73,431.92,9.59;10,72.00,450.19,87.61,9.59;10,86.25,475.22,436.57,10.59;10,72.00,488.68,94.37,9.59;10,86.25,513.72,168.37,9.66;10,72.00,526.25,431.92,9.59;10,72.00,538.72,404.92,9.59;10,72.00,551.18,450.67,9.59;10,72.00,563.64,236.14,9.59;10,72.00,576.10,450.67,9.59;10,72.00,588.56,229.39,9.59;10,72.00,601.02,450.67,9.59;10,72.00,613.48,337.40,9.59"><head>Task 2 . 2 ,</head><label>22</label><figDesc>prompt for GPT3 and BLOOM: "Pun: conviction Pun synonyms\/hypernyms: article of faith;strong belief Pun: graze Pun synonyms\/hypernyms: conviction Pun: reproved Pun synonyms\/hypernyms: admonish;reprove;reproof Pun: boulder Pun synonyms\/hypernyms:" Task 3 (EN-FR), prompt for GPT3: "Translate this from English into French:\n\n". Task 3 (EN-FR), prompt for BLOOM: "Original: Save the whales, spouted Tom. Translation: "Sauvez les baleines", proclama Tom à tout évent. Original: A skier retired because he was going downhill. Translation: Le skieur est parti à la retraite. Il n'arrivait pas à remonter la pente. Original: My wife uses a kitchen implement to shred garlic and parmesan cheese, which I hate. It really is the grater of two evils. Translation: Ma femme écoute du hip hop quand elle cuisine des carottes ou du gruyère. Je n'aime pas ça mais elle me dit que ça l'aide à râper. Original: Staying at the trendy, new hotel was the inn thing to do. Translation: Je rêvais de dormir dans cet hôtel. Original: The fireplaces of oriental doctors have an Asian flue. Translation:" Task 3 (EN-ES), prompt for GPT3: "Translate this from English into Spanish:\n\n". Task 3 (EN-ES), prompt for BLOOM: "Original: Diabetics should not be allowed to have sweet dreams. Translation: Los diabéticos no deberían tener dulces sueños. Original: I'm going to the guillotine at dawn and my wife has already collected my severance pay. Translation: Al amanecer me van a pasar por la guillotina y mi mujer ya ha firmado la separación. Original: After 5 years with the same chiropractor, I moved and had to change doctors. It was quite an adjustment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="12,72.00,328.56,197.55,9.70;12,73.50,73.50,451.50,249.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Precision for task 1 (pun detection)</figDesc><graphic coords="12,73.50,73.50,451.50,249.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="13,72.00,542.21,167.77,9.70;13,73.50,328.40,451.50,207.75"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: F1 for task 1 (pun detection)</figDesc><graphic coords="13,73.50,328.40,451.50,207.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="14,72.00,291.81,197.08,9.70;14,73.50,73.50,451.50,212.25"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy for task 1 (pun detection)</figDesc><graphic coords="14,73.50,73.50,451.50,212.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="15,72.00,310.56,294.47,9.70;15,73.50,73.50,451.50,231.00"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Accuracy for SimpleT5 and SpaCy (Task 2.1. Pun location)</figDesc><graphic coords="15,73.50,73.50,451.50,231.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="15,72.00,677.29,284.30,9.70;15,73.50,420.20,451.50,251.25"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Accuracy for BLOOM and GPT3 (Task 2.1. Pun location)</figDesc><graphic coords="15,73.50,420.20,451.50,251.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,72.00,350.24,404.90,67.16"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="6,72.00,363.66,404.90,53.73"><row><cell cols="2">Data size for task 1.1 (pun detection)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>train data (jokes)</cell><cell>5292</cell><cell>3998</cell><cell>839</cell></row><row><cell>test data (jokes)</cell><cell>8474</cell><cell>16871</cell><cell>4263</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.00,596.69,404.90,152.95"><head>Table 3 Data</head><label>3</label><figDesc></figDesc><table coords="6,72.00,610.12,404.90,139.52"><row><cell>size for task 2.1 (pun location)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>train data (jokes)</cell><cell>2874</cell><cell>2000</cell><cell>439</cell></row><row><cell>test data (jokes)</cell><cell>3519</cell><cell>6654</cell><cell>1835</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Data size for task 2.2 (pun interpretation)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>EN</cell><cell></cell></row><row><cell cols="2">train data (jokes)</cell><cell>2874</cell><cell></cell></row><row><cell cols="2">test data (jokes)</cell><cell>8474</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,72.00,231.96,389.32,67.16"><head>Table 5</head><label>5</label><figDesc></figDesc><table coords="7,72.00,245.38,389.32,53.73"><row><cell>Data size for task 3 (pun translation)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN-FR</cell><cell>EN-ES</cell></row><row><cell>train data (jokes)</cell><cell>5837</cell><cell>564</cell></row><row><cell>test data (jokes)</cell><cell>5726</cell><cell>5726</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,72.00,385.43,429.36,147.73"><head>Table 6</head><label>6</label><figDesc></figDesc><table coords="7,72.00,398.86,429.36,134.30"><row><cell>Methods per tasks</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Task 1</cell><cell>Task 2.1</cell><cell>Task 2.1</cell><cell>Task 3</cell></row><row><cell>EN / ES / FR</cell><cell>EN / ES / FR</cell><cell>EN / ES / FR</cell><cell>EN-ES / EN-FR</cell></row><row><cell>TF-IDF</cell><cell>SpaCy</cell><cell>GPT3</cell><cell>SimpleT5</cell></row><row><cell>SimpleT5</cell><cell>SimpleT5</cell><cell>BLOOM</cell><cell>GPT3</cell></row><row><cell>Random</cell><cell>GPT3</cell><cell>SpaCy</cell><cell>Googletrans</cell></row><row><cell>Naive Bayes</cell><cell>BLOOM</cell><cell>SimpleT5</cell><cell>EasyNMT-Opus</cell></row><row><cell>MLP</cell><cell></cell><cell>WordNet</cell><cell>EasyNMT-mbart</cell></row><row><cell>Logistic Regression</cell><cell></cell><cell></cell><cell>BLOOM</cell></row><row><cell>Fast Text</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,72.00,427.39,442.50,134.30"><head>Table 7</head><label>7</label><figDesc></figDesc><table coords="11,72.00,440.82,442.50,120.87"><row><cell cols="2">Precision for task 1 (pun detection)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>Random</cell><cell>0.2554194156456173</cell><cell>0.421484695672569</cell><cell>0.4205729166666667</cell></row><row><cell>FastText</cell><cell>0.2562081198265668</cell><cell>0.552456286427976</cell><cell>0.4075342465753425</cell></row><row><cell>NB</cell><cell>0.2612369043595809</cell><cell>0.567320703653585</cell><cell>0.4769094138543517</cell></row><row><cell>LogisticRegression</cell><cell>0.2614403600900225</cell><cell>0.58439664600802</cell><cell>0.5</cell></row><row><cell>TF-IDF</cell><cell>0.2690937870993272</cell><cell>0.587731811697574</cell><cell>0.5334143377885784</cell></row><row><cell>MLP</cell><cell>0.2778568041725936</cell><cell>0.564996614759647</cell><cell>0.5545335085413929</cell></row><row><cell>SimpleT5</cell><cell>0.319792158715163</cell><cell>0.612199693303799</cell><cell>0.4431017119838872</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,72.00,406.01,439.71,134.30"><head>Table 8</head><label>8</label><figDesc>Recall for task 1 (pun detection)</figDesc><table coords="12,87.54,435.12,424.17,105.19"><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>FastText</cell><cell>0.803461063040791</cell><cell>0.625</cell><cell>0.25</cell></row><row><cell>LogisticRegression</cell><cell>0.861557478368356</cell><cell>0.490546218487394</cell><cell>0.603993971363978</cell></row><row><cell>MLP</cell><cell>0.724351050679851</cell><cell>0.443277310924369</cell><cell>0.628862094951017</cell></row><row><cell>NB</cell><cell>0.955500618046971</cell><cell>0.5640756302521</cell><cell>0.631876412961567</cell></row><row><cell>Random</cell><cell>0.669962917181705</cell><cell>0.678571428571428</cell><cell>0.677091183119819</cell></row><row><cell>SimpleT5</cell><cell>0.836835599505562</cell><cell>0.462184873949579</cell><cell>0.676902788244159</cell></row><row><cell>TF-IDF</cell><cell>0.840543881334981</cell><cell>0.461134453781512</cell><cell>0.620949510173323</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="13,72.00,177.70,425.77,134.30"><head>Table 9</head><label>9</label><figDesc></figDesc><table coords="13,72.00,191.13,425.77,120.87"><row><cell>F1 for task 1 (pun detection)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>FastText</cell><cell>0,3885236103</cell><cell>0,4933665008</cell><cell>0,344228275</cell></row><row><cell>LogisticRegression</cell><cell>0,4011510791</cell><cell>0,4952279958</cell><cell>0,5940337224</cell></row><row><cell>MLP</cell><cell>0,4016449623</cell><cell>0,4927028605</cell><cell>0,5952211127</cell></row><row><cell>NB</cell><cell>0,4102972399</cell><cell>0,5168431184</cell><cell>0,5978609626</cell></row><row><cell>Random</cell><cell>0,3698396452</cell><cell>0,5192926045</cell><cell>0,5195518612</cell></row><row><cell>SimpleT5</cell><cell>0,4627477785</cell><cell>0,4524421594</cell><cell>0,6429274403</cell></row><row><cell>TF-IDF</cell><cell>0,4076738609</cell><cell>0,4946478873</cell><cell>0,6038842067</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="13,72.00,593.58,425.78,134.30"><head>Table 10 Accuracy</head><label>10</label><figDesc></figDesc><table coords="13,87.54,607.01,410.24,120.87"><row><cell cols="2">for task 1 (pun detection)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>FastText</cell><cell>0.3572101791</cell><cell>0.4547077198</cell><cell>0.6072399596</cell></row><row><cell>LogisticRegression</cell><cell>0.3462142633</cell><cell>0.5751896475</cell><cell>0.6595976074</cell></row><row><cell>MLP</cell><cell>0.451460886</cell><cell>0.6122266845</cell><cell>0.6473238561</cell></row><row><cell>NB</cell><cell>0.301916431</cell><cell>0.5519857207</cell><cell>0.6494989513</cell></row><row><cell>Random</cell><cell>0.4197298146</cell><cell>0.4663096832</cell><cell>0.4836479453</cell></row><row><cell>SimpleT5</cell><cell>0.5061262959</cell><cell>0.5247657296</cell><cell>0.6899712577</cell></row><row><cell>TF-IDF</cell><cell>0.3792020107</cell><cell>0.5997322624</cell><cell>0.6641031617</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="14,72.00,524.71,425.78,67.16"><head>Table 11</head><label>11</label><figDesc></figDesc><table coords="14,72.00,538.14,425.78,53.73"><row><cell cols="3">Accuracy for SimpleT5 and SpaCy (Task 2.1. Pun location)</cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>SimpleT5</cell><cell>0.7950207469</cell><cell>0.4543501611</cell><cell>0.828125</cell></row><row><cell>SpaCy</cell><cell>0.444813278</cell><cell>0.0</cell><cell>0.2416666667</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="15,72.00,336.64,425.78,67.16"><head>Table 12</head><label>12</label><figDesc>Accuracy for BLOOM and GPT3 (Task 2.1.</figDesc><table coords="15,111.09,350.06,386.69,53.73"><row><cell></cell><cell>Pun location)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>FR</cell><cell>ES</cell></row><row><cell>BLOOM</cell><cell>0.65625</cell><cell>0.3384615385</cell><cell>0.4385964912</cell></row><row><cell>GPT3</cell><cell>0.8125</cell><cell>0.4615384615</cell><cell>0.8771929825</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="16,72.00,194.01,444.41,550.56"><head>Table 13</head><label>13</label><figDesc></figDesc><table coords="16,72.00,207.44,444.41,537.13"><row><cell cols="2">Pun interpretation results</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Text</cell><cell>Location</cell><cell>Source synonym</cell><cell>Target synonym</cell></row><row><cell>BLOOM</cell><cell>Soft drink</cell><cell>popportunity</cell><cell>chance;</cell><cell>drink</cell></row><row><cell></cell><cell>inventors saw a</cell><cell></cell><cell>opportunity</cell><cell></cell></row><row><cell></cell><cell>big popportunity.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>The unveiling of</cell><cell>monumental</cell><cell>large; massive;</cell><cell>statue</cell></row><row><cell></cell><cell>the statue was a</cell><cell></cell><cell>stately</cell><cell></cell></row><row><cell></cell><cell>monumental</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>occasion.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SimpleT5,</cell><cell>OLD</cell><cell>premises</cell><cell>premises,</cell><cell>premises,</cell></row><row><cell>WordNet</cell><cell>PHILOSOPHERS</cell><cell></cell><cell>premise, premiss,</cell><cell>premise, premiss,</cell></row><row><cell></cell><cell>never die, they</cell><cell></cell><cell>assumption,</cell><cell>assumption,</cell></row><row><cell></cell><cell>just retire to their</cell><cell></cell><cell>premise</cell><cell>premise</cell></row><row><cell></cell><cell>own premises.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SpaCy, WordNet</cell><cell>OLD GEOMETRY</cell><cell>tangent</cell><cell>tangent,</cell><cell>tangent,</cell></row><row><cell></cell><cell>TEACHERS never</cell><cell></cell><cell>tangent,</cell><cell>tangent,</cell></row><row><cell></cell><cell>die, they just go</cell><cell></cell><cell>tan</cell><cell>tan</cell></row><row><cell></cell><cell>off on a tangent.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BLOOM,</cell><cell>''I prefer trout to</cell><cell>trout</cell><cell>trout, trout</cell><cell>trout, trout</cell></row><row><cell>WordNet</cell><cell>salmon,'' Tom</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>said officiously.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT3, WordNet</cell><cell>I never found</cell><cell>flare</cell><cell>flare, flair, flare,</cell><cell>flare, flair, flare,</cell></row><row><cell></cell><cell>sending signals</cell><cell></cell><cell>flare, flash</cell><cell>flare, flash</cell></row><row><cell></cell><cell>from ships</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>challenging. I</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>always had a</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>flare for it.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT3</cell><cell>I never found</cell><cell>flare</cell><cell>blaze; flame;</cell><cell>grey hairs; grey</cell></row><row><cell></cell><cell>sending signals</cell><cell></cell><cell>ignite; flare up</cell><cell>hair; gray hair;</cell></row><row><cell></cell><cell>from ships</cell><cell></cell><cell></cell><cell>gray hairs</cell></row><row><cell></cell><cell>challenging. I</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>always had a</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>flare for it.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>OLD TELEPHONE</cell><cell>disconnected</cell><cell>separated;</cell><cell>eggs</cell></row><row><cell></cell><cell>OPERATORS</cell><cell></cell><cell>isolated; divided;</cell><cell></cell></row><row><cell></cell><cell>never die, they</cell><cell></cell><cell>broken</cell><cell></cell></row><row><cell></cell><cell>just become</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>disconnected.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="17,72.00,365.37,443.18,402.85"><head>Table 14 Pun</head><label>14</label><figDesc></figDesc><table coords="17,91.71,378.79,423.47,389.43"><row><cell>translation (EN-ES) results</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Priority</cell><cell>Method</cell><cell>Source text</cell><cell>Target text</cell></row><row><cell>1</cell><cell>GPT3</cell><cell>When the fog burns</cell><cell>Cuando la niebla se</cell></row><row><cell></cell><cell></cell><cell>off it won't be mist.</cell><cell>queme, ya no será</cell></row><row><cell></cell><cell></cell><cell></cell><cell>niebla.</cell></row><row><cell></cell><cell></cell><cell>The boy swallowed a</cell><cell>El niño tragó una</cell></row><row><cell></cell><cell></cell><cell>pillow, the hospital</cell><cell>almohada, el hospital</cell></row><row><cell></cell><cell></cell><cell>described his</cell><cell>describió su condición</cell></row><row><cell></cell><cell></cell><cell>condition as</cell><cell>como cómoda.</cell></row><row><cell></cell><cell></cell><cell>comfortable.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>''Eating uranium</cell><cell>"Comer uranio me</cell></row><row><cell></cell><cell></cell><cell>makes me feel funny,''</cell><cell>hace sentir raro", dijo</cell></row><row><cell></cell><cell></cell><cell>said Tom radiantly.</cell><cell>Tom radiante.</cell></row><row><cell>2</cell><cell>BLOOM</cell><cell>When the fog burns</cell><cell>Cuando se disipe la</cell></row><row><cell></cell><cell></cell><cell>off it won't be mist.</cell><cell>niebla no será una</cell></row><row><cell></cell><cell></cell><cell></cell><cell>bruma.</cell></row><row><cell></cell><cell></cell><cell>The boy swallowed a</cell><cell>El niño se tragó un</cell></row><row><cell></cell><cell></cell><cell>pillow, the hospital</cell><cell>cojín, el hospital</cell></row><row><cell></cell><cell></cell><cell>described his</cell><cell>describió su estado</cell></row><row><cell></cell><cell></cell><cell>condition as</cell><cell>como cómodo.</cell></row><row><cell></cell><cell></cell><cell>comfortable.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>''Eating uranium</cell><cell>Tom dijo</cell></row><row><cell></cell><cell></cell><cell>makes me feel funny,''</cell><cell>radiantemente que</cell></row><row><cell></cell><cell></cell><cell>said Tom radiantly.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="19,72.00,345.94,417.48,80.59"><head>Table 15</head><label>15</label><figDesc></figDesc><table coords="19,72.00,359.37,417.48,67.16"><row><cell>SimpleT5 EN-FR translation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Priority</cell><cell>Method</cell><cell>Source text</cell><cell>Target text</cell></row><row><cell>6</cell><cell>SimpleT5</cell><cell>I've got to fix the</cell><cell></cell></row><row><cell></cell><cell></cell><cell>automobile, said Tom</cell><cell></cell></row><row><cell></cell><cell></cell><cell>mechanically.</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="20,108.00,387.44,415.14,9.66;20,108.00,400.09,415.21,9.66;20,108.00,412.74,414.78,9.66;20,108.00,425.39,414.76,9.66;20,108.00,438.04,415.20,9.66;20,108.00,450.69,89.16,9.66" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="20,108.00,400.09,326.68,9.66">Overview of JOKER -CLEF-2023 track on Automatic Wordplay Analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Palma Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,240.18,425.39,282.58,9.66;20,108.00,438.04,415.20,9.66">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,463.34,415.15,9.66;20,108.00,475.98,414.70,9.66;20,108.00,488.63,71.95,9.66" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="20,199.61,463.34,101.73,9.66">Approaching Wordplay</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Winter-Froemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,443.83,463.34,79.31,9.66;20,108.00,475.98,285.28,9.66">The Dynamics of Wordplay, volume 3 of Crossing Languages to Play with Words</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Winter-Froemel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Boston</addrLine></address></meeting>
		<imprint>
			<publisher>De Gruyter</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="11" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,501.28,414.67,9.66;20,108.00,513.93,351.82,9.66" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="20,210.40,501.28,312.27,9.66;20,108.00,513.93,68.33,9.66">Wordplay and Translation, The Translator / Studies in Intercultural Communication</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Delabastita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Routledge</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>London and New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,526.58,415.27,9.66;20,108.00,539.23,414.53,9.66;20,108.00,551.88,403.01,9.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="20,159.43,526.58,165.17,9.66">Universals and puns in humorous way</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Attardo</surname></persName>
		</author>
		<idno type="DOI">10.1515/9783110586374-005</idno>
	</analytic>
	<monogr>
		<title level="m" coord="20,108.00,539.23,414.53,9.66;20,108.00,551.88,40.10,9.66">Cultures and Traditions of Wordplay and Wordplay Research, volume 6 of The Dynamics of Wordplay</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Winter-Froemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Thaler</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Boston</addrLine></address></meeting>
		<imprint>
			<publisher>De Gruyter</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="89" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,564.53,414.90,9.66;20,108.00,577.18,415.26,9.66;20,108.00,589.82,127.63,9.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="20,166.11,564.53,113.23,9.66">Wordplay and Translation</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Klitgard</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315692845-16</idno>
	</analytic>
	<monogr>
		<title level="m" coord="20,397.44,564.53,125.47,9.66;20,108.00,577.18,137.84,9.66">The Routledge Handbook of Translation and Linguistics</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Malmkjaer</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="233" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,602.47,415.19,9.66;20,108.00,615.12,256.76,9.66" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="20,177.12,602.47,182.09,9.66">Neural Machine Translation: A Review</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Stahlberg</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.1.12007</idno>
	</analytic>
	<monogr>
		<title level="j" coord="20,374.51,602.47,148.68,9.66;20,108.00,615.12,40.29,9.66">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="343" to="418" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,108.00,627.77,414.57,9.66;20,108.00,640.42,415.13,9.66;20,108.00,653.07,322.06,9.66" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="20,205.76,640.42,317.37,9.66;20,108.00,653.07,136.32,9.66">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="20,108.00,665.72,414.98,9.66;20,108.00,678.37,414.66,9.66;20,108.00,691.02,150.82,9.66" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="20,237.53,678.37,249.65,9.66">SYSTRAN&apos;s pure neural machine translation systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rebollo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Akhanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brunelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Coquard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05540</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="20,108.00,703.67,414.91,9.66;20,108.00,716.31,204.73,9.66" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="20,226.40,703.67,296.51,9.66;20,108.00,716.31,172.94,9.66">How to move to neural machine translation for enterprise-scale programs -an early adoption case study</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Marg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,126.00,728.96,397.13,9.66;20,108.00,741.61,415.20,9.66;20,108.00,754.26,82.44,9.66" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dhanuka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Khailov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05820</idno>
		<title level="m" coord="20,404.48,728.96,118.65,9.66;20,108.00,741.61,301.21,9.66">Toward a full-scale neural machine translation in production: the booking.com use case</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="21,113.75,74.99,409.25,9.66;21,108.00,87.63,415.11,9.66;21,108.00,100.28,83.35,9.66" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="21,359.17,74.99,163.82,9.66;21,108.00,87.63,287.29,9.66">Translator&apos;s Perceptions of Literary Post-Editing Using Statistical and Neural Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Moorkens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sh</forename><surname>Castilho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="21,409.10,87.63,84.45,9.66">Translation Spaces</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="240" to="262" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,112.93,396.70,9.66;21,108.00,125.58,414.77,9.66;21,108.00,138.23,376.92,9.66" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="21,231.41,112.93,291.29,9.66;21,108.00,125.58,62.42,9.66">What Level of Quality Can Neural Machine Translation Attain on Literary Text?</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="21,473.09,125.58,49.68,9.66;21,108.00,138.23,211.91,9.66">Translation Quality Assessment: From Principles to Practice</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Moorkers</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Castilho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Gaspari</surname></persName>
		</editor>
		<editor>
			<persName><surname>Doherty</surname></persName>
		</editor>
		<imprint>
			<publisher>Cham, Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="263" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,150.88,396.65,9.66;21,108.00,163.53,245.27,9.66" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="21,240.47,150.88,282.18,9.66;21,108.00,163.53,60.49,9.66">Ethical Issues Regarding Machine(-Assisted) Translation of Literary Texts</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Taivalkoski-Shilov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="21,180.17,163.53,54.95,9.66">Perspectives</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="689" to="703" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,176.18,397.01,9.66;21,108.00,188.83,414.95,9.66;21,108.00,201.47,158.48,9.66" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="21,238.76,176.18,284.25,9.66;21,108.00,188.83,228.28,9.66">The &apos;Technological Turn&apos; in Translation Studies: Are We There Yet? A Transversal Cross-Disciplinary Approach</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Jiménez-Crespo</surname></persName>
		</author>
		<idno type="DOI">10.1075/ts.19012.jim</idno>
	</analytic>
	<monogr>
		<title level="j" coord="21,352.97,188.83,86.70,9.66">Translation Spaces</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="314" to="341" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,214.13,396.82,9.66;21,108.00,226.77,414.86,9.66;21,108.00,239.42,414.63,9.66;21,108.00,252.07,161.22,9.66" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="21,176.92,214.13,345.90,9.66;21,108.00,226.77,110.89,9.66">The Punster&apos;s Amanuensis: The Proper Place of Humans and Machines in the Translation of Wordplay</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.26615/issn.2683-0078.2019_007</idno>
	</analytic>
	<monogr>
		<title level="m" coord="21,251.38,226.77,271.49,9.66;21,108.00,239.42,193.31,9.66">Proceedings of the Second Workshop on Human-Informed Translation and Interpreting Technology</title>
		<meeting>the Second Workshop on Human-Informed Translation and Interpreting Technology<address><addrLine>Incoma, Shoumen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,264.72,397.18,9.66;21,108.00,277.37,327.42,9.66" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="21,171.62,264.72,351.56,9.66;21,108.00,277.37,58.69,9.66">Using Computers in the Translation of Literary Style: Challenges and Opportunities</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Roy</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780429030345</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Routledge</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,290.02,397.04,9.66;21,108.00,302.67,415.01,9.66;21,108.00,315.32,60.27,9.66;21,184.52,315.32,52.42,9.66;21,253.19,315.32,47.93,9.66;21,316.61,315.32,20.76,9.66;21,352.87,315.32,24.24,9.66;21,392.60,315.32,24.73,9.66;21,432.83,315.32,13.74,9.66;21,462.07,315.32,28.39,9.66;21,505.96,315.32,17.10,9.66;21,108.00,327.96,122.13,9.66" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="21,261.48,290.02,212.41,9.66">Human-computer interaction in pun translation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Waltraud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781003094159-4</idno>
	</analytic>
	<monogr>
		<title level="m" coord="21,419.99,302.67,103.03,9.66;21,108.00,315.32,60.27,9.66;21,184.52,315.32,48.06,9.66">Using Technologies for Creative-Text Translation</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hadley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Taivalkoski-Shilov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">S C</forename><surname>Teixeira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Toral</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="66" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,340.61,397.01,9.66;21,108.00,353.26,414.67,9.66;21,108.00,365.91,414.64,9.66;21,108.00,378.56,414.93,9.66;21,108.00,391.21,414.92,9.66;21,108.00,403.86,56.48,9.66;21,180.72,403.86,70.29,9.66;21,267.26,403.86,30.23,9.66;21,313.73,403.86,51.38,9.66;21,381.36,403.86,24.73,9.66;21,421.59,403.86,13.74,9.66;21,450.83,403.86,39.39,9.66;21,505.71,403.86,17.10,9.66;21,108.00,416.51,146.86,9.66" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="21,464.43,353.26,58.25,9.66;21,108.00,365.91,389.00,9.66">Overview of JOKER@CLEF 2022: Automatic Wordplay and Humor Translation Workshop</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Le Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Damoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-13643-6_27</idno>
	</analytic>
	<monogr>
		<title level="m" coord="21,108.00,378.56,414.93,9.66;21,108.00,391.21,233.66,9.66">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Sprinter-Verlag</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="447" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,429.16,396.87,9.66;21,108.00,441.80,199.90,9.66" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="21,276.42,429.16,54.75,9.66">Data Mining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rajaman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139058452.002</idno>
	</analytic>
	<monogr>
		<title level="m" coord="21,345.42,429.16,126.45,9.66">Mining of Massive Datasets</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,454.46,396.83,9.66;21,108.00,467.10,415.15,9.66;21,108.00,479.75,411.94,9.66" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="21,129.51,467.10,342.17,9.66">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j" coord="21,478.89,467.10,44.27,9.66;21,108.00,479.75,123.91,9.66">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,492.40,396.96,9.66;21,108.00,505.05,415.14,9.66;21,108.00,517.70,314.17,9.66" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="21,239.17,492.40,279.10,9.66">Graphical Models, Lecture2: Bayesian Network Representation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename></persName>
		</author>
		<ptr target="https://people.cs.umass.edu/~mccallum/courses/gm2011/02-bn-rep.pdf" />
		<imprint/>
	</monogr>
	<note>PDF. Archived (PDF) from the original on 2022-10-09, 2019</note>
</biblStruct>

<biblStruct coords="21,126.00,530.35,397.08,9.66;21,108.00,543.00,254.37,9.66" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="21,295.99,530.35,227.09,9.66;21,108.00,543.00,109.18,9.66">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,555.65,12.52,9.66;21,168.27,555.65,54.05,9.66;21,252.07,555.65,36.03,9.66;21,317.84,555.65,48.85,9.66;21,396.44,555.65,8.55,9.66;21,434.73,555.65,33.90,9.66;21,497.63,555.65,25.04,9.66;21,108.00,568.29,356.58,9.66" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stojiljkovic</surname></persName>
		</author>
		<ptr target="https://realpython.com/logistic-regression-python/#logistic-regression-in-python" />
		<title level="m" coord="21,252.07,555.65,36.03,9.66;21,317.84,555.65,48.85,9.66;21,396.44,555.65,8.55,9.66;21,434.73,555.65,29.06,9.66">Logistic Regression in Python</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,580.94,378.59,9.66" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="21,194.45,580.94,78.67,9.66">Introducing spaCy</title>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<ptr target="https://explosion.ai/blog/introducing-spacy" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,593.59,396.91,9.66;21,108.00,606.24,194.00,9.66" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="21,172.57,593.59,129.53,9.66">Gpt-3: What&apos;s it good for?</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324920000601</idno>
	</analytic>
	<monogr>
		<title level="j" coord="21,311.93,593.59,141.52,9.66">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="113" to="118" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,618.89,50.06,9.66;21,197.56,618.89,47.66,9.66;21,266.72,618.89,39.70,9.66;21,327.91,618.89,39.08,9.66;21,387.73,618.89,44.27,9.66;21,452.75,618.89,24.73,9.66;21,498.23,618.89,25.04,9.66;21,108.00,631.54,282.40,9.66" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="21,266.72,618.89,39.70,9.66">BLOOM</title>
		<idno type="DOI">10.57967/hf/0003</idno>
		<ptr target="https://huggingface.co/bigscience/bloom.doi:10.57967/hf/0003" />
	</analytic>
	<monogr>
		<title level="m" coord="21,126.00,618.89,50.06,9.66;21,197.56,618.89,42.37,9.66">BigScience Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>revision 4ab0472</note>
</biblStruct>

<biblStruct coords="21,126.00,644.19,397.03,9.66;21,108.00,656.84,183.71,9.66" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="21,190.35,644.19,190.62,9.66">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<ptr target="https://mitpress.mit.edu/9780262561167/" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,669.49,396.68,9.66;21,108.00,682.13,260.38,9.66" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="21,251.29,669.49,271.39,9.66;21,108.00,682.13,119.39,9.66">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,694.78,275.49,9.66" xml:id="b28">
	<analytic>
		<title/>
		<ptr target="https://pypi.org/project/googletrans/" />
	</analytic>
	<monogr>
		<title level="j" coord="21,126.00,694.78,53.73,9.66">Googletrans</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,126.00,707.43,396.53,9.66;21,108.00,720.08,255.65,9.66" xml:id="b29">
	<monogr>
		<title level="m" type="main" coord="21,249.67,707.43,239.51,9.66">Neural Machine Translation using EasyNMT Library</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Subramanyam Kalyan</surname></persName>
		</author>
		<ptr target="https://mr-nlp.github.io/posts/2022/07/mt-easynmt/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
