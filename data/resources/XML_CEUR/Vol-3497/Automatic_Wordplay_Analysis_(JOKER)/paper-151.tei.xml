<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,362.81,15.42;1,88.69,106.66,257.25,15.42">Overview of JOKER 2023 Automatic Wordplay Analysis Task 3 -Pun translation</title>
				<funder>
					<orgName type="full">La Maison des sciences de l&apos;homme en Bretagne</orgName>
				</funder>
				<funder ref="#_BUsFPpW">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,79.43,11.96"><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Université de Bretagne Occidentale</orgName>
								<address>
									<settlement>HCTI</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.35,134.97,67.33,11.96"><forename type="first">Tristan</forename><surname>Miller</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Austrian Research Institute for Artificial Intelligence (OFAI)</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.33,134.97,101.14,11.96"><forename type="first">Anne-Gwenn</forename><surname>Bosser</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Lab-STICC CNRS UMR 6285</orgName>
								<orgName type="institution">École Nationale d&apos;Ingénieurs de Brest</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,381.11,134.97,70.21,11.96"><forename type="first">Victor</forename><surname>Manuel</surname></persName>
						</author>
						<author>
							<persName coords="1,454.32,134.97,30.00,11.96;1,89.29,148.92,42.14,11.96"><forename type="first">Palma</forename><surname>Preciado</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Université de Bretagne Occidentale</orgName>
								<address>
									<settlement>HCTI</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,149.37,148.92,75.90,11.96"><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Centro de Investigación en Computación (CIC)</orgName>
								<orgName type="institution">Instituto Politécnico Nacional (IPN)</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.28,148.92,63.85,11.96"><forename type="first">Adam</forename><surname>Jatowt</surname></persName>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,362.81,15.42;1,88.69,106.66,257.25,15.42">Overview of JOKER 2023 Automatic Wordplay Analysis Task 3 -Pun translation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">C839280080A6569B492C8E18A7667B1C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>wordplay</term>
					<term>puns</term>
					<term>computational humour</term>
					<term>machine translation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides a comprehensive overview of Task 3 of the JOKER-2023 track. The overarching objective of the JOKER track series is to facilitate collaboration among linguists, translators, and computer scientists to advance the development of automatic interpretation, generation, and translation of wordplay. Task 3 specifically concentrates on the automatic translation of puns from English into French and Spanish. In this overview, we outline the overall structure of the shared task that we organized as part of the CLEF-2023 evaluation campaign. We discuss the approaches employed by the participants and present and analyze the results they achieved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper describes Task 3 of the JOKER-2023 1 challenge, where the goal is to accurately translate puns between different languages. This is the final task of JOKER-2023 <ref type="bibr" coords="1,445.85,447.93,11.37,10.91" target="#b0">[1]</ref>, following Tasks 1 <ref type="bibr" coords="1,124.55,461.47,12.84,10.91" target="#b1">[2]</ref> and 2 <ref type="bibr" coords="1,167.06,461.47,12.84,10.91" target="#b2">[3]</ref> on pun detection and pun location/slash interpretation, respectively.</p><p>A pun is a form of wordplay that exploits multiple meanings of a word or words with similar sounds but different meanings. Puns pose challenges in translation as they often rely on language-specific nuances that may not have direct equivalents in other languages. Nonetheless, it can be important to preserve wordplay in the target text, even if the exact type of wordplay or the specific meaning is changed. In Task 3, participating systems attempt to translate English punning jokes into French and Spanish. The translations should aim to preserve, to the extent possible, both the form and meaning of the original wordplay -that is, to implement the pun→pun strategy described in Delabastita's typology of pun translation strategies <ref type="bibr" coords="1,462.77,569.87,11.34,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,476.84,569.87,7.56,10.91" target="#b4">5]</ref>. For example, "I used to be a banker but I lost interest" might be rendered into French as "J'ai été banquier mais j'en ai perdu tout l'intérêt". This fairly straightforward translation preserves the pun, since interest and intérêt share the same semantic ambiguity.</p><p>In the remainder of this paper, we describe the data preparation process (Section 2) and participants' approaches (Section 3), and then present an analysis of their results (Section 4). Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data</head><p>Our French training data contains 5,838 translations of 1,405 distinct puns in English as used in Tasks 1 and 2. These translations come from translation contests and the JOKER-2022 track <ref type="bibr" coords="2,483.06,327.18,11.23,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,496.43,327.18,7.49,10.91" target="#b6">7]</ref>. For the test set, we provided participants with 4,290 distinct puns in English to be translated into French and Spanish. A detailed description of the corpus can be found in our SIGIR 2023 paper <ref type="bibr" coords="2,117.34,367.83,11.43,10.91" target="#b7">[8]</ref>.</p><p>We also provide new sets of English-Spanish translations of punning jokes, similar to the English-French datasets we produced for JOKER-2022. These translations were sourced via a translation contest in which professional translators were asked to translate 400 English puns. In total, they produced 2,459 pairs of translated puns. These translations underwent an expert review to ensure compliance with the data set's criteria of preserving both wordplay and the general meaning. We kept 644 translations of 217 distinct English puns for training data.</p><p>Statistics on the dataset are given in Table <ref type="table" coords="2,293.09,462.68,3.80,10.91" target="#tab_0">1</ref>. As in cases of Tasks 1 and 2, we included the training data in the input file of the test data. This allows us for comparison of the systems both on the test and training sets.</p><p>As described below, the data was provided in JSON and delimited text formats with fields containing the text of the punning joke and a unique ID; for training there were one or two additional fields containing gold-standard translations of the text into French and/or Spanish. Systems were expected to output a JSON or delimited text file containing the run ID, text ID, the text of the translation(s) into French and/or Spanish, and a boolean flag indicating whether the run was manual or automatic.</p><p>Input format. The base data is provided in JSON and CSV formats with the following fields: id_en a unique identifier text_en the text of the instance of source wordplay in English Input example:</p><p>[{"id_en":"en_1", "text_en":"I used to be a banker but I lost interest"}] Qrels. We provide training data as JSON or TSV qrels files with the following fields: id_en a unique identifier from the input file text_fr (optional) translation of the wordplay into French text_es (optional) translation of the wordplay into Spanish Example of a qrel file:</p><p>[{"id_en":"en_1", "text_fr":"J'ai été banquier mais j'en ai perdu tout l'intérêt"}] Output Format. Participating systems were expected to submit their results as a TREC-style JSON or TSV file with the following fields: run_id run ID starting with &lt;team_id&gt;_&lt;task_id&gt;_&lt;method_used&gt; -e.g., UBO_BLOOM manual whether the run is manual (0 or 1) id_en a unique identifier from the input file text_fr (optional) translation of the wordplay into French</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>text_es (optional) translation of the wordplay into Spanish</head><p>Example of an output file:</p><p>[{"run_id":"team1_task_3_DeepL", "manual":0, "id_en":"en_1", "text_fr":"J'ai été banquier mais j'en ai perdu tout l'intérêt"} ]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Participants' approaches</head><p>Nine teams submitted 47 runs for this task, as summarized in Table <ref type="table" coords="3,398.73,567.11,3.81,10.91" target="#tab_1">2</ref>. The approaches used were as follows:</p><p>1. The LJGG team submitted runs for translation from English to French and Spanish. Their model is a three-stage architecture based on T5 (SimpleT5). The two stages calculate the information necessary to concatenate the English sentence, which forms an input for the third neural network. For training the models, they enlarged Task 3's dataset with the data prepared for Task 1. They also used the DeepL translator to compare their results and found that the DeepL translations are better. 2. The NLPalma team <ref type="bibr" coords="4,204.38,285.96,12.84,10.91" target="#b8">[9]</ref> approached the translation of wordplay from English to Spanish using BLOOMZ &amp; mT5, which is an improved version of BLOOM. 3. The MiCroGerk team <ref type="bibr" coords="4,215.54,314.42,18.03,10.91" target="#b9">[10]</ref> used SimpleT5-, BLOOM-, OpenAI-, and AI21-based models and the models from the EasyNMT package (Opus-MT, mBART50_m2m, and M2M_10) for the English-Spanish translation task. The OpenAI-and AI21-based models proved to be the best, with the lowest-ranked models being SimpleT5. According to the authors, however, there is still plenty of room for improvement. 4. The UBO team <ref type="bibr" coords="4,186.73,383.52,18.06,10.91" target="#b10">[11]</ref> used the models from the EasyNMT package -namely, Opus-MT, mBART50_m2m, and M2M_100. 5. The TheLangVerse team made use of the j2-grande model from the AI21 platform. They also combined the datasets to provide more content for fine-tuning, obtaining results comparable to those obtained from their surveys. 6. Opus-MT and M2M_100 from the the EasyNMT package were selected by participants of ThePunDetectives team <ref type="bibr" coords="4,240.87,467.52,16.41,10.91" target="#b11">[12]</ref>. The authors found that M2M_100 made translations that diverged from the original senses at the expense of precision. In contrast, Opus-MT presented a slightly better translation capability, being able to comprehend some types of humour. 7. The solution of the Smroltra team <ref type="bibr" coords="4,274.29,523.07,18.06,10.91" target="#b12">[13]</ref> was to use the GPT-3, BLOOM, Opus-MT, and mBART50_m2m models from EasyNMT; SimpleT5; and the Google Translate service for both English-Spanish and English-French translations. The best results were obtained using GPT-3, while the worst came from T5, which produced incoherent sentences. GPT-3 and BLOOM obtained the highest scores on both datasets, although according to the authors, the translation of the datasets requires more data and time. 8. The Croland team <ref type="bibr" coords="4,199.42,605.72,17.91,10.91" target="#b13">[14]</ref> approached the task using GPT-3. 9. TeamCAU <ref type="bibr" coords="4,163.60,620.63,17.75,10.91" target="#b14">[15]</ref> report using large language models (LLMs), but do not specifically describe their use for their Task 3 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>We continue JOKER-2022's practice of having trained experts manually evaluate system translations according to features such as sense preservation and wordplay, since vocabulary overlap metrics such as BLEU are unsuitable for evaluating wordplay translations <ref type="bibr" coords="5,421.78,138.38,11.41,10.91" target="#b6">[7,</ref><ref type="bibr" coords="5,435.90,138.38,7.61,10.91" target="#b5">6]</ref>. Participants' runs were subject to whitespace trimming and lower-casing, and were pooled together. We then filtered out French and Spanish translations identical to the original wordplay in English, as we considered these wordplay instances to be untranslated. Then, we manually evaluated 6,590 French translations of 1,197 distinct puns in English pooled from the participants' runs used as the final test data. Besides, our experts manually assessed 9,682 French translations of 868 distinct puns in English. We manually evaluated 5,727 Spanish translations of 544 distinct English puns. The runs are ranked according to the number of successful translations -i.e., translations preserving, to the extent possible, both the form and sense of the original wordplay.</p><p>Table <ref type="table" coords="5,127.04,260.32,5.07,10.91" target="#tab_2">3</ref> shows the results on the test data while Table <ref type="table" coords="5,340.45,260.32,5.07,10.91" target="#tab_3">4</ref> displays the results obtained on the training data for the pun translation task from English into French. The following scores are reported in both tables: We will consider #S measure as the one for ranking the submitted runs. We observe that for English to French translation, the Jurassic-2 and T5 models obtained the best results (respectively, 72 and 65 translations that contain the wordplay and preserve the meaning of the source puns). We should note here, however, that the T5 model was trained on the training set while other LLMs were used only in a few-shot setup. Overall, same as in 2022 <ref type="bibr" coords="5,395.06,588.29,11.48,10.91" target="#b6">[7,</ref><ref type="bibr" coords="5,409.39,588.29,7.65,10.91" target="#b5">6]</ref>, we notice that the success rate of wordplay translation is very low, and the task is obviously very challenging. This is even the case for LLMs, with a maximum value of 6% over the total evaluated test set for French. The results are almost three times higher for the training set in French, suggesting an overfitting problem but still very low in general (less than 17%)</p><p>For English-to-Spanish translation, the best results were obtained by systems that used the Google Translate service (96 or 99 correctly translated puns) and ones based on the mBART model (99 puns). The maximum score is 18% in the case of English-to-Spanish translation, which is considerably higher than for French data. Note that for the Spanish version of the task we only have evaluations on the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have described Task 3 of the JOKER track at CLEF 2023. The task aims to advance the automation of wordplay translation, and included shared tasks on translation from English to French and from English to Spanish. We expanded the EN→FR training set described in our SIGIR 2023 paper <ref type="bibr" coords="6,199.25,612.32,12.90,10.91" target="#b7">[8]</ref> with a new parallel corpus of EN→ES wordplay translations. We evaluated the results from participants after pooling and conducting manual assessments with experts.</p><p>We observe that the success rate of wordplay translation is extremely low even in the case of LLMs, for both language pairs. The maximum value of 6% over the total evaluated test set was obtained for French while the corresponding value for Spanish was 18%. In French, even for the training set the percentage of successful translations is less than 17%. The difficulty of translation of wordplay between relatively well-studied languages, even when using LLMs, calls for more community attention to this challenging task. Among the submitted runs, those using mBART, Jurassic-2, T5, and Google Translate produced the best results. As with Tasks 1 and 2, we received many partial runs due to the constraints involved in using LLMs. Additional information on the track is available on the JOKER website: http://www. joker-project.com/ Kinlay. We also thank all other colleagues and students who participated in data construction, the translation contests, and the CLEF JOKER track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,308.86,209.13,10.91;5,89.29,330.95,254.72,10.91;5,89.29,353.03,316.14,10.91;5,89.29,375.12,331.55,10.91;5,89.29,397.21,219.47,10.91;5,89.29,419.29,234.87,10.91;5,89.29,441.38,416.70,10.91;5,89.29,463.46,416.69,10.91;5,116.56,477.01,21.62,10.91;5,89.29,499.10,416.69,10.91;5,116.56,512.65,118.00,10.91"><head>#</head><label></label><figDesc>E number of manually evaluated translations #T number of submitted translations used for evaluation #M number of translations preserving the meaning of the source puns %M percentage of translations preserving the meaning of the source puns #W number of translations containing wordplay %W percentage of translations containing wordplay #S number of translations containing wordplay and preserving the meaning of the source puns %S percentage of translations containing wordplay and preserving the meaning of the source puns %R percentage of translations containing wordplay and preserving the meaning of the source puns over the total test set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,90.49,303.61,84.86"><head>Table 1</head><label>1</label><figDesc>Task 3 dataset statistics</figDesc><table coords="2,202.67,119.88,189.93,55.47"><row><cell></cell><cell>Train</cell><cell></cell><cell>Test</cell><cell></cell></row><row><cell cols="5">Language target source target source</cell></row><row><cell>French</cell><cell>5,838</cell><cell>1,405</cell><cell>6,590</cell><cell>1,197</cell></row><row><cell>Spanish</cell><cell>644</cell><cell>217</cell><cell>5,727</cell><cell>544</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,291.00,168.77"><head>Table 2</head><label>2</label><figDesc>Statistics on the runs submitted for Task 3</figDesc><table coords="4,215.29,119.88,164.70,139.37"><row><cell>Team</cell><cell cols="2">EN→FR EN→ES</cell></row><row><cell>Croland</cell><cell>1</cell><cell>1</cell></row><row><cell>LJGG</cell><cell>4</cell><cell>5</cell></row><row><cell>MiCroGerk</cell><cell>-</cell><cell>7</cell></row><row><cell>Smroltra</cell><cell>6</cell><cell>6</cell></row><row><cell>TeamCAU</cell><cell>3</cell><cell>-</cell></row><row><cell>TheLangVerse</cell><cell>1</cell><cell>1</cell></row><row><cell>ThePunDetectives</cell><cell>2</cell><cell>2</cell></row><row><cell>UBO</cell><cell>3</cell><cell>3</cell></row><row><cell>NPalma</cell><cell>-</cell><cell>2</cell></row><row><cell>Total</cell><cell>20</cell><cell>27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,411.02,368.75"><head>Table 3</head><label>3</label><figDesc>Results for pun translation from English into French (test data)</figDesc><table coords="6,95.27,122.10,404.74,337.13"><row><cell>run ID</cell><cell>#E</cell><cell cols="8">#T #M %M #W %W #S %S %R</cell></row><row><cell>Croland_task_3_EN_FR_GPT3</cell><cell>16</cell><cell>28</cell><cell>4</cell><cell>25</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="4">LJGG_Google_Translator_EN_FR_auto 1,076 1,197 580</cell><cell>53</cell><cell>67</cell><cell cols="2">6 63</cell><cell>5</cell><cell>5</cell></row><row><cell>LJGG_task3_fr_mt5_base_auto</cell><cell cols="2">2 1,197</cell><cell cols="2">2 100</cell><cell>1</cell><cell>50</cell><cell cols="2">1 50</cell><cell>0</cell></row><row><cell>LJGG_task3_fr_mt5_base_no_label_auto</cell><cell cols="2">1 1,197</cell><cell cols="2">1 100</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>LJGG_task3_fr_t5_large_auto</cell><cell cols="2">90 1,197</cell><cell>24</cell><cell>26</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>0</cell></row><row><cell>LJGG_task3_fr_t5_large_no_label_auto</cell><cell cols="2">140 1,197</cell><cell>80</cell><cell>57</cell><cell>15</cell><cell cols="3">10 15 10</cell><cell>1</cell></row><row><cell>Smroltra_task_3_EN-FR_BLOOM</cell><cell>31</cell><cell>32</cell><cell>8</cell><cell>25</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Smroltra_task_3_EN-FR_EasyNMT-</cell><cell cols="3">786 1,197 427</cell><cell>54</cell><cell>58</cell><cell cols="2">7 56</cell><cell>7</cell><cell>4</cell></row><row><cell>Opus</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-FR_EasyNMT-</cell><cell cols="3">1,139 1,197 613</cell><cell>53</cell><cell>68</cell><cell cols="2">5 64</cell><cell>5</cell><cell>5</cell></row><row><cell>mbart</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-FR_GPT3</cell><cell>30</cell><cell>32</cell><cell>8</cell><cell>26</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Smroltra_task_3_EN-</cell><cell cols="3">1,109 1,197 602</cell><cell>54</cell><cell>71</cell><cell cols="2">6 67</cell><cell>6</cell><cell>5</cell></row><row><cell>FR_GoogleTranslation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-FR_SimpleT5</cell><cell cols="3">1,043 1,197 562</cell><cell>53</cell><cell>66</cell><cell cols="2">6 65</cell><cell>6</cell><cell>5</cell></row><row><cell>TeamCAU_task_3_EN-FR_AI21</cell><cell>30</cell><cell>32</cell><cell>8</cell><cell>26</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TeamCAU_task_3_EN-FR_BLOOM</cell><cell>32</cell><cell>32</cell><cell>8</cell><cell>25</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TeamCAU_task_3_EN-FR_ST5</cell><cell cols="3">1,090 1,197 577</cell><cell>52</cell><cell>71</cell><cell cols="2">6 69</cell><cell>6</cell><cell>5</cell></row><row><cell>TheLangVerse_task_3_j2-grande-</cell><cell cols="3">1,176 1,197 636</cell><cell>54</cell><cell>76</cell><cell cols="2">6 72</cell><cell>6</cell><cell>6</cell></row><row><cell>finetuned</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ThePunDetectives_task_3_EN-</cell><cell>13</cell><cell>340</cell><cell>9</cell><cell>69</cell><cell>2</cell><cell>15</cell><cell cols="2">2 15</cell><cell>0</cell></row><row><cell>FR_M2M100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ThePunDetectives_task_3_EN-</cell><cell>183</cell><cell>340</cell><cell>92</cell><cell>50</cell><cell>19</cell><cell cols="2">10 17</cell><cell>9</cell><cell>1</cell></row><row><cell>FR_OpusMT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>UBO_task_3_SimpleT5</cell><cell cols="2">73 1,195</cell><cell>47</cell><cell>64</cell><cell>5</cell><cell>6</cell><cell>5</cell><cell>6</cell><cell>0</cell></row><row><cell>UBO_task_3_SimpleT5_x</cell><cell cols="3">1,148 1,195 616</cell><cell>53</cell><cell>71</cell><cell cols="2">6 67</cell><cell>5</cell><cell>5</cell></row><row><cell>UBO_task_3_SimpleT5_y</cell><cell cols="3">791 1,194 429</cell><cell>54</cell><cell>61</cell><cell cols="2">7 59</cell><cell>7</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,411.02,332.88"><head>Table 4</head><label>4</label><figDesc>Results for pun translation from English into French (training data)</figDesc><table coords="7,95.27,122.10,404.74,301.27"><row><cell>run ID</cell><cell>#E</cell><cell cols="5">#T #M %M #W %W</cell><cell cols="3">#S %S %R</cell></row><row><cell>Croland_task_3_EN_FR_GPT3</cell><cell>17</cell><cell>32</cell><cell>8</cell><cell>47</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>LJGG_Google_Translator_EN_FR_auto</cell><cell cols="3">757 868 451</cell><cell cols="2">60 128</cell><cell cols="3">17 124 16</cell><cell>14</cell></row><row><cell>LJGG_task3_fr_t5_large_auto</cell><cell cols="2">21 868</cell><cell>3</cell><cell>14</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>5</cell><cell>0</cell></row><row><cell>LJGG_task3_fr_t5_large_no_label_auto</cell><cell cols="2">88 868</cell><cell>54</cell><cell>61</cell><cell>26</cell><cell>30</cell><cell cols="2">22 25</cell><cell>3</cell></row><row><cell>Smroltra_task_3_EN-FR_BLOOM</cell><cell>31</cell><cell>36</cell><cell>11</cell><cell>35</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="4">Smroltra_task_3_EN-FR_EasyNMT-Opus 432 868 250</cell><cell>58</cell><cell>65</cell><cell>15</cell><cell cols="2">64 15</cell><cell>7</cell></row><row><cell>Smroltra_task_3_EN-FR_EasyNMT-</cell><cell cols="3">793 868 470</cell><cell cols="2">59 143</cell><cell cols="3">18 136 17</cell><cell>16</cell></row><row><cell>mbart</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-FR_GPT3</cell><cell>30</cell><cell>36</cell><cell>13</cell><cell>43</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Smroltra_task_3_EN-</cell><cell cols="3">746 868 444</cell><cell cols="2">60 126</cell><cell cols="3">17 122 16</cell><cell>14</cell></row><row><cell>FR_GoogleTranslation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-FR_SimpleT5</cell><cell cols="3">697 868 412</cell><cell cols="2">59 105</cell><cell cols="3">15 100 14</cell><cell>12</cell></row><row><cell>TeamCAU_task_3_EN-FR_AI21</cell><cell>32</cell><cell>36</cell><cell>13</cell><cell>41</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TeamCAU_task_3_EN-FR_BLOOM</cell><cell>29</cell><cell>36</cell><cell>12</cell><cell>41</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TeamCAU_task_3_EN-FR_ST5</cell><cell cols="3">683 868 405</cell><cell>59</cell><cell>97</cell><cell>14</cell><cell cols="2">92 13</cell><cell>11</cell></row><row><cell>TheLangVerse_task_3_j2-grande-</cell><cell cols="3">675 868 405</cell><cell cols="2">60 127</cell><cell cols="3">19 122 18</cell><cell>14</cell></row><row><cell>finetuned</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ThePunDetectives_task_3_EN-</cell><cell cols="2">22 321</cell><cell>16</cell><cell>73</cell><cell>9</cell><cell>41</cell><cell cols="2">9 41</cell><cell>1</cell></row><row><cell>FR_M2M100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ThePunDetectives_task_3_EN-</cell><cell cols="2">164 321</cell><cell>95</cell><cell>58</cell><cell>24</cell><cell>15</cell><cell cols="2">24 15</cell><cell>3</cell></row><row><cell>FR_OpusMT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>UBO_task_3_SimpleT5</cell><cell cols="2">38 868</cell><cell>28</cell><cell>74</cell><cell>15</cell><cell>39</cell><cell cols="2">15 39</cell><cell>2</cell></row><row><cell>UBO_task_3_SimpleT5_x</cell><cell cols="3">810 868 486</cell><cell cols="2">60 148</cell><cell cols="3">18 141 17</cell><cell>16</cell></row><row><cell>UBO_task_3_SimpleT5_y</cell><cell cols="3">442 868 255</cell><cell>58</cell><cell>66</cell><cell>15</cell><cell cols="2">65 15</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,90.49,411.02,428.53"><head>Table 5</head><label>5</label><figDesc>Results for pun translation from English into Spanish (test data)</figDesc><table coords="8,95.27,122.10,404.74,396.91"><row><cell>run ID</cell><cell>#E</cell><cell cols="2">#T #M</cell><cell cols="2">%M #W</cell><cell cols="2">%W #S</cell><cell cols="2">%S %R</cell></row><row><cell>Croland_task_3_ENESGPT3</cell><cell>45</cell><cell>47</cell><cell cols="2">9 20.00</cell><cell>3</cell><cell>6.66</cell><cell>3</cell><cell>6.66</cell><cell>0</cell></row><row><cell>LJGG_task3_es_mt5_base_auto</cell><cell cols="2">34 544</cell><cell cols="2">16 47.05</cell><cell cols="2">5 14.70</cell><cell cols="2">5 14.70</cell><cell>0</cell></row><row><cell cols="3">LJGG_task3_es_mt5_base_no_label_auto 34 544</cell><cell cols="2">16 47.05</cell><cell cols="2">5 14.70</cell><cell cols="2">5 14.70</cell><cell>0</cell></row><row><cell>LJGG_task3_es_t5_large_auto</cell><cell cols="2">34 544</cell><cell cols="2">16 47.05</cell><cell cols="2">5 14.70</cell><cell cols="2">5 14.70</cell><cell>0</cell></row><row><cell cols="3">LJGG_task3_es_t5_large_no_label_auto 34 544</cell><cell cols="2">16 47.05</cell><cell cols="2">5 14.70</cell><cell cols="2">5 14.70</cell><cell>0</cell></row><row><cell cols="9">LJGG_task_3_GoogleTranslatorENESauto544 544 274 50.36 106 19.48 99 18.19</cell><cell>18</cell></row><row><cell>NLPalma_task_3_BLOOMZ_x</cell><cell cols="4">359 359 215 59.88</cell><cell cols="4">85 23.67 80 22.28</cell><cell>14</cell></row><row><cell>NLPalma_task_3_BLOOMZ_y</cell><cell cols="4">359 359 215 59.88</cell><cell cols="4">85 23.67 80 22.28</cell><cell>14</cell></row><row><cell>Smroltra_task_3_EN-ES_EasyNMT-</cell><cell cols="8">529 544 263 49.71 100 18.90 93 17.58</cell><cell>17</cell></row><row><cell>Opus</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-ES_EasyNMT-</cell><cell cols="8">529 544 263 49.71 100 18.90 93 17.58</cell><cell>17</cell></row><row><cell>Opus_x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-ES_EasyNMT-</cell><cell cols="8">529 544 263 49.71 100 18.90 93 17.58</cell><cell>17</cell></row><row><cell>Opus_y</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-</cell><cell cols="8">532 544 267 50.18 103 19.36 96 18.04</cell><cell>17</cell></row><row><cell>ES_GoogleTranslation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Smroltra_task_3_EN-ES_SimpleT5</cell><cell cols="8">531 544 265 49.90 101 19.02 94 17.70</cell><cell>17</cell></row><row><cell>Smroltra_task_3_ENESBLOOM</cell><cell>45</cell><cell>47</cell><cell cols="2">8 17.77</cell><cell>2</cell><cell>4.44</cell><cell>2</cell><cell>4.44</cell><cell>0</cell></row><row><cell>TheLangVerse_task_3_j2-grande-</cell><cell cols="4">415 544 200 48.19</cell><cell cols="4">70 16.86 65 15.66</cell><cell>11</cell></row><row><cell>finetuned</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ThePunDetectives_task_3_EN-</cell><cell cols="2">33 430</cell><cell cols="2">16 48.48</cell><cell cols="2">7 21.21</cell><cell cols="2">7 21.21</cell><cell>1</cell></row><row><cell>ES_M2M100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">ThePunDetectives_task_3_ENESOpusMT 428 430 208 48.59</cell><cell cols="4">71 16.58 66 15.42</cell><cell>12</cell></row><row><cell>MiCroGerk_task_3_EN-ES_OpenAI</cell><cell>6</cell><cell>17</cell><cell>3</cell><cell>0.5</cell><cell cols="2">1 16.66</cell><cell cols="2">1 16.66</cell><cell>0</cell></row><row><cell>MiCroGerk_task_3_EN-</cell><cell cols="8">543 544 274 50.46 106 19.52 99 18.23</cell><cell>18</cell></row><row><cell>ES_mbart50_m2m_x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MiCroGerk_task_3_EN-ES_AI21_x</cell><cell>1</cell><cell>17</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>MiCroGerk_task_3_EN-</cell><cell cols="8">543 544 274 50.46 106 19.52 99 18.23</cell><cell>18</cell></row><row><cell>ES_mbart50_m2m_y</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MiCroGerk_task_3_EN-</cell><cell cols="2">43 544</cell><cell cols="2">23 53.48</cell><cell cols="4">11 25.58 11 25.58</cell><cell>2</cell></row><row><cell>ES_m2m_100_418M</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MiCroGerk_task_3_EN-ES_SimpleT5</cell><cell cols="2">5 544</cell><cell>4</cell><cell>0.8</cell><cell>3</cell><cell>0.6</cell><cell>3</cell><cell>0.6</cell><cell>0</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This project has received a government grant managed by the <rs type="funder">National Research Agency</rs> under the program "<rs type="programName">Investissements d'avenir" integrated into France 2030</rs>, with the Reference <rs type="grantNumber">ANR-19-GURE-0001</rs>. JOKER is supported by <rs type="funder">La Maison des sciences de l'homme en Bretagne</rs>. For their help and support in the first Spanish pun translation contest, we thank <rs type="person">Carolina Palma Preciado</rs>, <rs type="person">Leopoldo Jesús Gutierrez Galeano</rs>, <rs type="person">Khatima El Krirh</rs>, <rs type="person">Nathalie Narváez Bruneau</rs>, and <rs type="person">Rachel</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BUsFPpW">
					<idno type="grant-number">ANR-19-GURE-0001</idno>
					<orgName type="program" subtype="full">Investissements d&apos;avenir&quot; integrated into France 2030</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,617.90,393.73,10.91;8,112.66,631.45,394.53,10.91;8,112.66,644.99,394.53,10.91;8,112.66,658.54,395.17,10.91;9,112.66,86.97,363.24,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,461.99,617.90,44.40,10.91;8,112.66,631.45,294.58,10.91">Overview of JOKER -CLEF-2023 Track on Automatic Wordplay Analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,234.07,658.54,273.76,10.91;9,112.66,86.97,128.32,10.91">CLEF&apos;23: Proceedings of the Fourteenth International Confer-ence of the CLEF Association</title>
		<title level="s" coord="9,248.24,86.97,155.05,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,100.52,393.33,10.91;9,112.48,114.06,350.25,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,451.47,100.52,54.52,10.91;9,112.48,114.06,281.59,10.91">Overview of JOKER 2023 automatic wordplay analysis task 1 -pun detection</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,127.61,393.33,10.91;9,112.48,141.16,394.79,10.91;9,112.66,154.71,45.73,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,451.47,127.61,54.52,10.91;9,112.48,141.16,374.88,10.91">Overview of JOKER 2023 Automatic Wordplay Analysis Task 2 -Pun location and interpretation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,395.17,10.91;9,112.66,181.81,356.39,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,180.52,168.26,327.31,10.91;9,112.66,181.81,232.20,10.91">There&apos;s a Double Tongue: an Investigation into the Translation of Shakespeare&apos;s Wordplay, with Special Reference to Hamlet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Delabastita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Rodopi, Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,393.33,10.91;9,112.66,208.91,394.53,10.91;9,112.66,222.46,274.35,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,187.70,195.36,273.52,10.91">Wordplay as a translation problem: a linguistic perspective</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Delabastita</surname></persName>
		</author>
		<idno type="DOI">10.1515/9783110137088.1.6.600</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,490.74,195.36,15.24,10.91;9,112.66,208.91,244.51,10.91">Ein internationales Handbuch zur Übersetzungsforschung</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="600" to="606" />
			<date type="published" when="2008">2008</date>
			<publisher>De Gruyter Mouton</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,236.01,394.53,10.91;9,112.66,249.56,393.33,10.91;9,112.48,263.11,395.34,10.91;9,112.66,276.66,394.53,10.91;9,112.66,290.20,395.17,10.91;9,112.66,303.75,393.33,10.91;9,112.66,317.30,394.52,10.91;9,112.66,330.85,344.81,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,448.09,249.56,57.90,10.91;9,112.48,263.11,327.40,10.91">Overview of JOKER@CLEF 2022: Automatic wordplay and humour translation workshop</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Élise</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Damoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-13643-6_27</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,298.12,290.20,209.72,10.91;9,112.66,303.75,393.33,10.91;9,112.66,317.30,129.23,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: Proceedings of the Thirteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,352.24,318.32,150.71,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">13390</biblScope>
			<biblScope unit="page" from="447" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,344.40,394.53,10.91;9,112.66,357.95,393.33,10.91;9,112.66,371.50,394.53,10.91;9,112.66,385.05,394.53,10.91;9,112.66,398.60,394.52,10.91;9,112.39,412.15,290.43,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,431.26,357.95,74.73,10.91;9,112.66,371.50,313.37,10.91">Overview of the CLEF 2022 JOKER Task 3: Pun translation from English into French</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Regattin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jeanjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Élise</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Corre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Boccou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Digue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Damoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,290.13,385.05,217.06,10.91;9,112.66,398.60,200.03,10.91">Proceedings of the Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="9,182.74,413.16,122.23,9.72">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">September 5th to 8th, 2022. 2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="1681" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,425.70,393.33,10.91;9,112.66,439.25,393.33,10.91;9,112.41,452.79,393.57,10.91;9,112.66,466.34,394.51,10.91;9,112.66,479.89,137.88,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,338.10,425.70,167.89,10.91;9,112.66,439.25,231.66,10.91">The JOKER Corpus: English-French parallel data for multilingual wordplay recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Bosser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1145/3539618.3591885</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,370.97,439.25,135.02,10.91;9,112.41,452.79,393.57,10.91;9,112.66,466.34,38.77,10.91">SIGIR &apos;23: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="9,112.66,493.44,393.32,10.91;9,112.66,506.99,330.08,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,310.97,493.44,195.01,10.91;9,112.66,506.99,261.56,10.91">NLPalma @ CLEF 2023 JOKER: A BLOOMZ and BERT approach for wordplay detection and translation</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename><surname>Preciado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,520.54,393.33,10.91;9,112.66,534.09,221.40,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,277.31,520.54,24.66,10.91;9,328.65,520.54,177.34,10.91;9,112.66,534.09,64.41,10.91">JOKER Task 1, 2, 3: pun detection, pun interpretation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Prnjak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Davari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Schmitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF. and pun translation</note>
</biblStruct>

<biblStruct coords="9,112.66,547.64,393.33,10.91;9,112.66,561.19,194.15,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,168.64,547.64,337.35,10.91;9,112.66,561.19,125.63,10.91">UBO Team @ CLEF JOKER 2023 track for Task 1, 2 and 3 -applying AI models in regards to pun translation</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Dubreuil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,574.74,393.33,10.91;9,112.66,588.29,310.17,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,303.73,574.74,202.26,10.91;9,112.66,588.29,241.65,10.91">CLEF 2023 JOKER Tasks 2 and 3: using NLP models for pun location, interpretation and translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ohnesorge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Á</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plichta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,601.84,394.62,10.91;9,112.66,615.39,393.32,10.91;9,112.66,628.93,115.02,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,206.46,601.84,300.82,10.91;9,112.66,615.39,304.63,10.91">Does AI have a sense of humor? CLEF 2023 JOKER tasks 1, 2 and 3: Using BLOOM, GPT, SimpleT5, and more for pun detection, location</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dadić</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>interpretation and translation</note>
</biblStruct>

<biblStruct coords="9,112.66,642.48,393.15,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,288.28,642.48,42.12,10.91">CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Komorowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Čatipović</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vujica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,338.40,642.48,98.44,10.91">JOKER Working Notes</title>
		<imprint>
			<biblScope unit="issue">16</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,656.03,395.17,10.91;9,112.66,669.58,324.94,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="9,224.64,656.03,283.19,10.91;9,112.66,669.58,235.23,10.91">Exploring Humor in Natural Language Processing: A Comprehensive Review of JOKER Tasks at CLEF Symposium</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lieberum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.66,100.52,262.54,10.91" xml:id="b15">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="10,112.66,86.97,393.33,10.91;10,112.66,100.52,26.38,10.91">Proceedings of the Working Notes of CLEF 2023: Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="10,147.04,100.52,175.50,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting>the Working Notes of CLEF 2023: Conference and Labs of the Evaluation Forum</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
