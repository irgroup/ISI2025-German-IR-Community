<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,417.16,15.42;1,89.29,106.66,409.45,15.42;1,89.29,128.58,70.91,15.43">Team Cadence at MEDIQA-Sum 2023: Using ChatGPT as a Data Augmentation Tool for Classifying Clinical Dialogue</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,156.89,81.04,11.96"><forename type="first">Ashwyn</forename><surname>Sharma</surname></persName>
							<email>ashwyn@cadencerpm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Cadence Solutions</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,182.56,156.89,82.97,11.96"><forename type="first">David</forename><forename type="middle">I</forename><surname>Feldman</surname></persName>
							<email>david.feldman@cadencerpm.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Cadence Solutions</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Massachusetts General Hospital</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,417.16,15.42;1,89.29,106.66,409.45,15.42;1,89.29,128.58,70.91,15.43">Team Cadence at MEDIQA-Sum 2023: Using ChatGPT as a Data Augmentation Tool for Classifying Clinical Dialogue</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">CF7844F0C7504412E42081EB66BC00FD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ChatGPT</term>
					<term>Clinical dialogue classification</term>
					<term>Data augmentation</term>
					<term>MEDIQA-Sum</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present Team Cadence's winning submission to Task A of the MEDIQA-Sum 2023 shared task, which focused on the classification of doctor-patient dialogues based on their associated topic or section header. The methodology we adopted was inspired by our previous work on the dialogue summarization task for MEDIQA-Chat 2023, where our data augmentation approach showed promising results. For this task, we leveraged gpt-3.5-turbo 1 to generate synthetic pairs of doctorpatient conversations and their corresponding section headers, subsequently augmenting the dataset. This augmented dataset was then utilized for fine-tuning the BART model (facebook/bart-large 2 checkpoint) for sequence classification. Results demonstrated that data augmentation improved classification accuracy for labels with scarce training data by 30%. Our submission ranked first on the Task A leaderboard, achieving an accuracy of 82%. Moreover, we analyzed the quality of synthetic data produced and the impact of augmentation on class imbalance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the context of NLP for clinical text, the ability to accurately classify sections of doctor-patient dialogues is crucial for understanding, summarizing, and managing healthcare conversations. This paper discusses Team Cadence's strategy for Task A of the MEDIQA-Sum 2023 <ref type="bibr" coords="1,459.56,487.38,14.18,10.91" target="#b0">[1]</ref> shared task. Task A required participants to predict the topic or section header of given doctor-patient dialogues, a classification task that required a sophisticated understanding of medical language and contextual nuances.</p><p>Our approach was inspired by our previous work <ref type="bibr" coords="1,308.30,541.57,15.18,10.91" target="#b1">[2]</ref> on the dialogue summarization task of the MEDIQA-Chat 2023 <ref type="bibr" coords="1,176.61,555.12,14.20,10.91" target="#b2">[3]</ref> shared task. In this prior endeavor, we developed a data augmentation approach that yielded promising results. Encouraged by these findings, we decided to apply a similar methodology to the Task A classification challenge.</p><p>We employed gpt-3.5-turbo to generate synthetic pairs of doctor-patient conversations and their corresponding section headers. We utilized this synthetic data to augment our training dataset, which was then used to train the BART <ref type="bibr" coords="2,305.56,114.06,17.33,10.91" target="#b3">[4]</ref> model (facebook/bart-large checkpoint) for sequence classification. This strategy demonstrated significant improvements, enhancing classification accuracy for labels with scarce training data by 30%.</p><p>Our submission achieved Rank-1 on the Task A leaderboard with an accuracy of 82%<ref type="foot" coords="2,500.53,152.96,3.71,7.97" target="#foot_0">1</ref> , demonstrating the effectiveness of our approach. Furthermore, we examined the quality of the synthetic data and the impact of this data augmentation technique on class imbalance. The detailed analysis and results of these experiments are discussed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Work</head><p>Effective classification of doctor-patient dialogues has been recognized as a critical challenge in the clinical NLP field <ref type="bibr" coords="2,182.16,267.54,11.55,10.91" target="#b4">[5]</ref>. Accurate classification of these dialogues can provide insightful data for healthcare professionals and researchers, facilitating improved patient care and medical research <ref type="bibr" coords="2,124.80,294.63,13.32,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,140.85,294.63,7.57,10.91" target="#b6">7]</ref>.</p><p>Doctor-patient dialogues form a rich data source about a patient's medical condition, symptoms, the prescribed treatment, and more. However, the unstructured nature of these dialogues poses significant challenges in efficiently extracting meaningful information. Over the years, NLP techniques have been increasingly used to tackle this issue, offering promising results in automatic information extraction, understanding, and management of these dialogues.</p><p>Several methods have been proposed for the classification of healthcare dialogues, typically involving a combination of traditional machine learning methods and, more recently, deep learning approaches. However, despite these efforts, accurately classifying healthcare dialogues remains a challenging problem due to the nuances and complexity of medical language and the inherent diversity in doctor-patient conversations <ref type="bibr" coords="2,308.46,430.13,13.57,10.91" target="#b7">[8]</ref>.</p><p>Pre-trained transformer <ref type="bibr" coords="2,206.21,443.67,14.30,10.91" target="#b8">[9]</ref> models have achieved remarkable performance on several NLP tasks, including text classification. Particularly, the BART <ref type="bibr" coords="2,344.04,457.22,17.23,10.91" target="#b3">[4]</ref> model has been widely adopted due to its ability to effectively model the sequence of text data, making it suitable for tasks like the one posed by MEDIQA-Sum 2023 <ref type="bibr" coords="2,252.16,484.32,13.32,10.91" target="#b0">[1]</ref>.</p><p>Our team's earlier work for MEDIQA-Chat 2023 involved the use of data augmentation for dialogue summarization tasks. Inspired by the promising results of that approach, we aimed to adapt it for dialogue classification. Data augmentation has been increasingly recognized as an effective technique for improving the performance of machine learning models, especially in medical scenarios where the available data is limited or imbalanced <ref type="bibr" coords="2,385.65,552.07,18.98,10.91" target="#b9">[10]</ref>.</p><p>This paper presents a data-augmentation-first approach to dialogue classification, integrating the use of synthetic data generation via gpt-3.5-turbo for data augmentation and the BART model for sequence classification. By doing so, we not only build upon the existing body of work but also introduce a methodology that we hope will inspire continued research in this crucial area. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The MEDIQA-Sum 2023 <ref type="bibr" coords="3,192.16,447.54,13.96,10.91" target="#b0">[1]</ref> dataset forms the foundation for our work in this paper. Participants were provided with conversation snippets between a doctor and a patient and were tasked with identifying the associated section header or topic. These section headers represent one of twenty normalized common section labels, such as Assessment, Diagnosis, Exam, Medications, and Past Medical History, among others. The complete list of section headers is provided in Table <ref type="table" coords="3,115.79,515.29,3.74,10.91" target="#tab_0">1</ref>.</p><p>The training set comprised 1,201 pairs of conversations and their corresponding section headers. The validation and test sets included 100 and 200 examples, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data augmentation</head><p>Two major challenges encountered in this task were the relatively small size of the training dataset and class imbalance. To overcome this, we adopted a data augmentation approach inspired by the results of our work in MEDIQA-Chat 2023 <ref type="bibr" coords="3,340.46,619.21,13.13,10.91" target="#b2">[3]</ref>. In that shared task, data augmentation proved to be a promising technique for summarizing clinical dialogues <ref type="bibr" coords="3,430.07,632.76,13.26,10.91" target="#b1">[2]</ref>.</p><p>We utilized the gpt-3.5-turbo model to generate synthetic pairs of clinical conversations and the corresponding section headers. Leveraging a few-shot learning approach, we used the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Classification</head><p>The BART <ref type="bibr" coords="4,131.22,413.73,16.86,10.91" target="#b3">[4]</ref> model, specifically the facebook/bart-large checkpoint, was fine-tuned using this augmented dataset. Our decision to use BART was based on the impressive results it yielded in our previous work at MEDIQA-Chat 2023.</p><p>The BART model was selected for its versatility in handling complex sequence-based tasks. We used the BARTForSequenceClassification wrapper provided by HuggingFace <ref type="bibr" coords="4,429.37,467.93,19.44,10.91" target="#b10">[11]</ref>, which adds a classifier head to the BART model, making it suitable for the classification task. Fine-tuning was performed using the Trainer API offered by HuggingFace <ref type="bibr" coords="4,371.32,495.02,18.05,10.91" target="#b10">[11]</ref> and the hyperparameters used for fine-tuning the classifier are detailed in Table <ref type="table" coords="4,332.53,508.57,3.74,10.91" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Classification metrics</head><p>In addition to accuracy, balanced accuracy<ref type="foot" coords="4,284.95,586.41,3.71,7.97" target="#foot_1">2</ref>  <ref type="bibr" coords="4,292.58,588.17,18.07,10.91" target="#b11">[12]</ref> and validation loss, we also evaluated the ability of the classifier to predict labels for classes where the given training data was limited. To be specific, we computed the mean accuracy for section headers where the number of training examples were less than 10. We call this metric mean scarce accuracy and such section  headers are listed in Table <ref type="table" coords="5,205.15,601.03,3.66,10.91" target="#tab_2">3</ref>. The goal here is to evaluate if data augmentation can help mitigate challenges associated with class imbalance in the training data. Figure <ref type="figure" coords="5,132.58,628.13,5.17,10.91" target="#fig_0">1</ref> illustrates the impact of data augmentation by comparing these metrics for the models fine-tuned on the augmented dataset and the original training data. It can be seen that the augmented version exhibits a lower validation loss for the most part and consistently outperforms the baseline model in mean scarce accuracy. The baseline model struggles with mean scarce accuracy initially but improves as the model is fine-tuned for 250 steps and beyond. A similar trend can be observed with balanced accuracy of the baseline model as compared to its augmented counterpart. It's clear that augmentation helps the classifier perform better for classes with limited examples, especially when the model has been trained for fewer than 250 steps. Also, data augmentation doesn't seem to have a significant impact on overall accuracy of the model evaluated against the validation set. The model is fine-tuned to minimize the loss over all classes and it can afford to have a low accuracy for scarce classes as long as the accuracy for common classes is high. Since the ground truth for the test data was not released, we were not able to confirm these trends with the test set and had to limit the analyses to the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quality of synthetic data</head><p>In Figure <ref type="figure" coords="6,134.04,619.50,3.81,10.91" target="#fig_1">2</ref>, we study the quality of the synthetic data generated by gpt-3.5-turbo by finetuning the classifier on synthetic data only. We can see that the model fine-tuned solely on synthetic data exhibits poor performance across all metrics except mean scarce accuracy. This suggests that the synthetic data generated by gpt-3.5-turbo falls short of exactly representing the distribution of the training data. This behavior could be attributed to the limited training data included in the data augmentation prompt shown to the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">System Specification</head><p>In the spirit of reproducibility, we share details of the systems used to run these experiments. The models were fine-tuned on an A100 Google Colab notebook instance<ref type="foot" coords="7,427.77,170.94,3.71,7.97" target="#foot_2">3</ref> . HuggingFace's Python package transformers <ref type="bibr" coords="7,218.89,186.24,17.75,10.91" target="#b10">[11]</ref> version 4.27.1 was used in a Python3.8 environment. Reported results were aggregated from 4 different runs using 4 different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Limitations</head><p>While our method demonstrated strong performance on the classification task in MEDIQA-Sum 2023, we acknowledge that there are limitations to our approach. Firstly, our data augmentation technique relies on a third-party API, which may pose challenges to HIPAA compliance when dealing with real-world medical data.</p><p>Another potential limitation involves the sensitivity of our method to the chosen prompt for data generation. Although we designed our prompt with careful consideration, the nature of few-shot learning using large language models often requires substantial experimentation and exploration to identify an optimal prompt that results in the most effective synthetic data.</p><p>Lastly, we note that the BART model has a maximum input length of 1024 tokens. Given that the MEDIQA-Sum 2023 dataset contained snippets of clinical conversations, this constraint did not pose a problem in our case. However, this approach might not generalize well to longer or full-length clinical conversations, which could exceed this token limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Our work in this paper underscores the power of Large Language Models (LLMs) and their potential when combined with data augmentation techniques, particularly in generating synthetic data for clinical NLP tasks. Despite the limitations noted above, we believe our approach offers a valuable contribution to the field of NLP in healthcare, as it demonstrated significant improvements in the classification of conversations with limited number of annotations for Task A of MEDIQA-Sum 2023.</p><p>Our results are a testament to the effectiveness of this approach-using a combination of gpt-3.5-turbo for data augmentation and the BART model for sequence classification, Team Cadence achieved Rank-1 on the MEDIQA-Sum 2023 leaderboard for Task A.</p><p>Moving forward, we anticipate that further improvements could be made by exploring other data augmentation techniques, optimizing prompt design, and investigating models that can handle longer text sequences. We hope our work will inspire further research and development in this important and rapidly evolving field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,411.53,379.19,8.93;5,89.29,84.19,416.70,314.77"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of classification metrics illustrating the impact of data augmentation.</figDesc><graphic coords="5,89.29,84.19,416.70,314.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,410.23,358.26,8.93;6,89.29,84.19,416.70,313.48"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Classification metrics when the model is fine-tuned with synthetic data only.</figDesc><graphic coords="6,89.29,84.19,416.70,313.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,260.20,285.06"><head>Table 1</head><label>1</label><figDesc>Section headers and their number of training examples.</figDesc><table coords="3,234.13,122.10,115.07,253.45"><row><cell>Label</cell><cell>Count</cell></row><row><cell>FAM/SOCHX</cell><cell>351</cell></row><row><cell>GENHX</cell><cell>282</cell></row><row><cell>PASTMEDICALHX</cell><cell>118</cell></row><row><cell>CC</cell><cell>77</cell></row><row><cell>PASTSURGICAL</cell><cell>63</cell></row><row><cell>ALLERGY</cell><cell>60</cell></row><row><cell>ROS</cell><cell>60</cell></row><row><cell>MEDICATIONS</cell><cell>54</cell></row><row><cell>ASSESSMENT</cell><cell>34</cell></row><row><cell>EXAM</cell><cell>23</cell></row><row><cell>DIAGNOSIS</cell><cell>19</cell></row><row><cell>DISPOSITION</cell><cell>15</cell></row><row><cell>PLAN</cell><cell>11</cell></row><row><cell>EDCOURSE</cell><cell>8</cell></row><row><cell>IMMUNIZATIONS</cell><cell>8</cell></row><row><cell>IMAGING</cell><cell>6</cell></row><row><cell>GYNHX</cell><cell>5</cell></row><row><cell>PROCEDURES</cell><cell>3</cell></row><row><cell>OTHER_HISTORY</cell><cell>2</cell></row><row><cell>LABS</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.91,90.49,418.75,284.43"><head>Table 2</head><label>2</label><figDesc>Hyperparameters used for fine-tuning the classifier. "Given this training dataset for a classifier that predicts the section_header given a dialogue between a patient and a doctor, generate {num_examples} more examples for section_header {label}. Please follow the format of the given training dataset and output a csv. Training data: {samples}. " We generated 10 synthetic pairs for each section header ten times using the prompt above. After filtering out invalid examples, we obtained 2585 examples that were added to 1201 original training examples to create an augmented dataset of 3786 examples.</figDesc><table coords="4,89.29,122.10,292.53,171.51"><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>learning_rate</cell><cell>2E-05</cell></row><row><cell>per_device_train_batch_size</cell><cell>8</cell></row><row><cell>per_device_eval_batch_size</cell><cell>8</cell></row><row><cell>weight_decay</cell><cell>0.01</cell></row><row><cell>num_train_epochs</cell><cell>30</cell></row><row><cell>fp16</cell><cell>TRUE</cell></row><row><cell>gradient_accumulation_steps</cell><cell>4</cell></row><row><cell>gradient_checkpointing</cell><cell>TRUE</cell></row><row><cell>max_source_length</cell><cell>1024</cell></row><row><cell>num_examples</cell><cell>10</cell></row><row><cell>following prompt as an input to the model:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.99,444.68,260.20,129.65"><head>Table 3</head><label>3</label><figDesc>Scarce section headers with less than 10 training examples.</figDesc><table coords="5,234.13,476.29,115.07,98.03"><row><cell>Label</cell><cell>Count</cell></row><row><cell>EDCOURSE</cell><cell>8</cell></row><row><cell>IMMUNIZATIONS</cell><cell>8</cell></row><row><cell>IMAGING</cell><cell>6</cell></row><row><cell>GYNHX</cell><cell>5</cell></row><row><cell>PROCEDURES</cell><cell>3</cell></row><row><cell>OTHER_HISTORY</cell><cell>2</cell></row><row><cell>LABS</cell><cell>2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,670.97,210.05,8.97"><p>https://github.com/ashwyn/MEDIQA-Sum-2023-Cadence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,92.57,671.00,351.82,8.97"><p>https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,92.57,670.99,260.45,8.97"><p>https://research.google.com/colaboratory/faq.html#whats-colaboratory</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,111.28,393.32,10.91;8,112.66,124.83,394.53,10.91;8,112.66,138.38,394.53,10.91;8,112.66,151.93,58.60,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,375.45,111.28,130.53,10.91;8,112.66,124.83,389.97,10.91">Overview of the mediqa-sum task at imageclef 2023: Summarization and classification of doctor-patient conversations</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yetisgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.07,138.38,113.05,10.91">CLEF 2023 Working Notes</title>
		<title level="s" coord="8,247.43,138.38,172.42,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,165.48,395.17,10.91;8,112.66,179.03,393.33,10.91;8,112.66,192.57,48.11,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,257.67,165.48,250.16,10.91;8,112.66,179.03,289.08,10.91">Team cadence at mediqa-chat 2023: Generating, augmenting and summarizing clinical dialogue with large language models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,429.25,179.03,76.74,10.91;8,112.66,192.57,18.15,10.91">ACL-ClinicalNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,206.12,393.33,10.91;8,112.66,219.67,394.53,10.91;8,112.66,233.22,142.74,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,380.30,206.12,125.69,10.91;8,112.66,219.67,389.93,10.91">Overview of the mediqa-chat 2023 shared tasks on the summarization and generation of doctor-patient conversations</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yetisgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.29,233.22,98.16,10.91">ACL-ClinicalNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,246.77,394.53,10.91;8,112.66,260.32,395.17,10.91;8,112.66,273.87,394.62,10.91;8,112.66,287.42,239.89,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,191.18,260.32,316.65,10.91;8,112.66,273.87,227.75,10.91">BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1910.13461" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,300.97,394.53,10.91;8,112.66,314.52,393.53,10.91;8,112.66,328.07,393.33,10.91;8,112.66,341.62,81.21,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,224.53,314.52,281.65,10.91;8,112.66,328.07,229.14,10.91">Impact of electronic medical record use on the patient-doctor relationship and communication: a systematic review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Alkureishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">G</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nkansah-Amankra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,349.55,328.07,156.44,10.91">Journal of general internal medicine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="548" to="560" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,355.17,394.53,10.91;8,112.33,368.71,393.66,10.91;8,112.66,382.26,93.05,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,112.33,368.71,336.42,10.91">The digital scribe in clinical practice: a scoping review and research agenda</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Van Buchem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Boosman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">M</forename><surname>Kant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Cammel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Steyerberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,457.58,368.71,48.41,10.91;8,112.66,382.26,40.46,10.91">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,395.81,393.32,10.91;8,112.66,409.36,225.11,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,190.97,395.81,203.62,10.91">Summarization of spontaneous conversations</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,417.99,395.81,87.99,10.91;8,112.66,409.36,195.12,10.91">Ninth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,422.91,394.52,10.91;8,112.28,436.46,393.98,10.91;8,112.66,450.01,146.44,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Moramarco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Korfiatis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ruffini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Perstl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Belz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Savkov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.02549</idno>
		<title level="m" coord="8,206.31,436.46,263.35,10.91">User-driven research of medical note generation software</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,463.56,395.17,10.91;8,112.66,477.11,393.33,10.91;8,112.33,490.66,29.19,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,484.04,463.56,23.79,10.91;8,112.66,477.11,143.41,10.91">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">≈Å</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,264.71,477.11,228.49,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Polosukhin</note>
</biblStruct>

<biblStruct coords="8,112.66,504.21,393.33,10.91;8,112.66,517.76,393.33,10.91;8,112.66,531.30,168.96,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,362.44,504.21,143.54,10.91;8,112.66,517.76,211.05,10.91">Medically aware gpt-3 as a data generator for medical dialogue summarization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Katariya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,352.61,517.76,153.38,10.91;8,112.66,531.30,48.47,10.91">Machine Learning for Healthcare Conference</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="354" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,544.85,394.53,10.91;8,112.66,558.40,394.62,10.91;8,112.66,571.95,394.61,10.91;8,112.66,585.50,178.59,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,213.72,558.40,269.99,10.91">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,571.95,394.61,10.91;8,112.66,585.50,100.66,10.91">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</title>
		<meeting>the 2020 conference on empirical methods in natural language processing: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,599.05,393.33,10.91;8,112.66,612.60,394.53,10.91;8,112.66,626.15,90.72,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,372.13,599.05,133.85,10.91;8,112.66,612.60,91.59,10.91">The balanced accuracy and its posterior distribution</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">H</forename><surname>Brodersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,226.51,612.60,250.25,10.91">2010 20th international conference on pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3121" to="3124" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
