<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,386.83,15.39;1,89.29,106.97,346.82,15.39;1,89.29,130.31,300.74,10.68">GAN-ISI: Generative Adversarial Networks Image Source Identification Using Texture Analysis Notebook for the ImageCLEFmedical GANs Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,156.22,117.56,10.68"><forename type="first">Mehdi</forename><forename type="middle">Mehdipour</forename><surname>Ghazi</surname></persName>
							<email>ghazi@di.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pioneer Centre for AI</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<settlement>Copenhagen</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.08,156.22,127.70,10.68"><forename type="first">Mostafa</forename><forename type="middle">Mehdipour</forename><surname>Ghazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pioneer Centre for AI</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<settlement>Copenhagen</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,386.83,15.39;1,89.29,106.97,346.82,15.39;1,89.29,130.31,300.74,10.68">GAN-ISI: Generative Adversarial Networks Image Source Identification Using Texture Analysis Notebook for the ImageCLEFmedical GANs Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">FD3250951C1663BF69876510A8367EFC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Generative adversarial networks</term>
					<term>source identification</term>
					<term>texture descriptors</term>
					<term>cumulative distribution function</term>
					<term>Wasserstein distance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative adversarial networks (GANs) have emerged as powerful tools for generating realistic images in various domains, including healthcare and medicine. However, concerns surrounding the privacy and security of personal data have become prominent. This study investigates the presence of fingerprints in synthetic medical images generated by GANs, which may indicate traces of the real images used during training and raise concerns about the sharing and limitations imposed by sensitive medical data. To address this, we analyze the texture characteristics of real and synthetic images from the ImageCLEF2023 Medical GANs challenge datasets, utilizing a range of texture descriptors and analysis methods to identify discernible patterns within the synthetic image data and determine the source images employed for training. We calculate the cumulative distribution function (CDF) of texture feature maps and apply the Wasserstein distance to compare the CDFs of the query and generated images. A binary classifier is trained to predict the utilization of the query image in generating each GAN image. The obtained results demonstrate balanced performance across various evaluation metrics, with the model exhibiting good generalization to the challenge test set, achieving an accuracy of 0.54 and an F1-score above 0.5. Our findings provide valuable insights into the security and privacy considerations when generating and utilizing artificial medical images in real-life scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Generative Adversarial Networks (GANs) <ref type="bibr" coords="1,276.96,487.59,12.84,9.74" target="#b0">[1]</ref> have revolutionized the field of image synthesis, enabling the generation of highly realistic and diverse images across various domains. In the context of healthcare and medicine, GANs have shown remarkable potential in generating biomedical images that capture complex patterns and characteristics <ref type="bibr" coords="1,397.87,528.24,11.47,9.74" target="#b1">[2]</ref>. However, as the use of GANs in medical imaging becomes more prevalent, concerns arise regarding the security and privacy of personal source data <ref type="bibr" coords="1,250.53,555.34,11.36,9.74" target="#b2">[3,</ref><ref type="bibr" coords="1,264.61,555.34,7.57,9.74" target="#b3">4]</ref>.</p><p>This study aims to investigate the hypothesis that GANs generate synthetic medical images that bear discernible traces of the real images used during the training process. The presence of these fingerprints <ref type="bibr" coords="1,169.53,595.98,11.26,9.74" target="#b4">[5,</ref><ref type="bibr" coords="1,183.51,595.98,8.89,9.74" target="#b5">6]</ref> would raise concerns about the potential sharing and usage limitations that artificial biomedical images may inherit from real sensitive medical data. Conversely, if the hypothesis is proven incorrect, it suggests that GANs can be utilized to create vast datasets of biomedical images that are free from ethical and privacy concerns, opening up new opportunities for real-life applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>The increasing availability of large-scale medical image datasets, coupled with advances in deep learning techniques, has fueled the development and utilization of GANs for medical image synthesis. These generative models have shown remarkable success in generating realistic images that capture the complex and nuanced characteristics of medical conditions. However, with the potential integration of GANs into various applications, the concern over the source image forensics and security of the generated images becomes paramount <ref type="bibr" coords="2,421.01,241.56,11.43,9.74" target="#b6">[7]</ref>.</p><p>One line of research focuses on uncovering traces of the training dataset within the generated images. Approaches based on DeepFakes Detection (DFD) have been proposed to identify manipulated or synthesized images. For example, the video-based DFD method of <ref type="bibr" coords="2,451.59,282.21,12.74,9.74" target="#b7">[8]</ref> analyzed the artifacts caused by the underlying GAN model to reveal inconsistencies between real and generated images. Similarly, the style-based metrics proposed in <ref type="bibr" coords="2,380.72,309.31,12.91,9.74" target="#b8">[9]</ref> were used to distinguish between real and GAN-generated images in the context of facial images.</p><p>Another approach involves analyzing the distributional properties and statistical characteristics of real and synthetic images. Methods such as Kernel Density Estimation (KDE) have been employed to detect deviations from the original data distribution. The effectiveness of KDE in identifying synthesized medical images was demonstrated in <ref type="bibr" coords="2,357.53,377.05,17.77,9.74" target="#b9">[10]</ref> by comparing their statistical properties with those of the training data. Additionally, approaches based on Wasserstein distance or other generative models have been explored to quantify the similarity between real and synthetic images <ref type="bibr" coords="2,186.09,417.70,16.25,9.74" target="#b10">[11]</ref>.</p><p>Furthermore, advancements in deep learning interpretability have contributed to the development of techniques that visualize and understand the internal representations of GANs. These methods enable the identification of specific image regions or features that influence the generation process. The method proposed in <ref type="bibr" coords="2,312.58,471.90,18.08,9.74" target="#b11">[12]</ref> used an attribution-based approach to identify the most important regions in GAN-generated images, shedding light on the potential sources of information within the generated data. Likewise, specific characteristics associated with fake image generators were exploited in <ref type="bibr" coords="2,291.31,512.54,17.84,9.74" target="#b12">[13]</ref> to introduce a face generator representation space that allows identification of the face-image source generator model.</p><p>By building upon the existing research, this study aims to detect fingerprints within synthetic medical image data and determine the source images used for generation during the training process. The objective of this study does not involve the identification of artificial images or the binary classification of real-fake datasets. Our focus lies in detecting the presence of discernible features or patterns within synthetic image data using various texture descriptors, aiming to determine the real images utilized for training the GANs. The results of this study provides valuable insights into the security of personal medical image data in the context of generating and utilizing artificial images across various real-life scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>To address the objective of identifying fingerprints and establishing relationships between real (source) and fake (generated) medical image datasets, this study incorporates a range of texture descriptors and analysis methods. These techniques are employed to effectively extract and analyze texture information from the images under investigation <ref type="bibr" coords="3,357.74,153.05,16.31,9.74" target="#b13">[14,</ref><ref type="bibr" coords="3,376.51,153.05,12.23,9.74" target="#b14">15]</ref>. Texture descriptors serve as computational representations that capture pertinent patterns from the images, facilitating the quantification of various texture aspects and enabling efficient comparisons across different images. The selection of texture descriptors used in this study for image analysis is detailed in the subsequent sections. It should however be noted that each of these approaches may have limitations in capturing robust complex textures and struggle with variations in lighting conditions and scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Statistical features</head><p>These features capture statistical relationships between pixel intensities by computing measures such as contrast, entropy, or homogeneity <ref type="bibr" coords="3,283.63,297.62,16.42,9.74" target="#b15">[16]</ref>. In this context, we calculate the local range of pixel intensities, local standard deviation, and local entropy of the intensities in a specified neighborhood around the corresponding image pixel. We use 3×3, 3×3, and 9×9 neighborhoods for extracting the range, standard deviation, and entropy feature maps (#3), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Filter-based features</head><p>These features employ filter banks to capture specific spatial-frequency domain information from the images that characterize complex texture patterns at various scales and orientations. Here, we create a bank of Gabor filters at different wavelengths and orientations <ref type="bibr" coords="3,453.24,415.09,18.00,9.74" target="#b16">[17]</ref> to later capture texture information from magnitudes of the filter responses. For the construction of the Gabor filter bank, we determined the minimum and maximum lengths as 𝐿 𝑚𝑖𝑛 = 4/√2 and 𝐿 𝑚𝑎𝑥 = 256/2, respectively. Accordingly, the wavelength parameter was discretized into 2 [0,1,...,log 2 (𝐿 𝑚𝑎𝑥 /𝐿 𝑚𝑖𝑛 )] 𝐿 𝑚𝑖𝑛 pixels/cycle, while the orientation parameter was regularly sampled at angles of [0, 45, 90, 135] degrees. These choices allowed us to define a comprehensive set of Gabor filters (#24) that could effectively capture a range of spatial frequencies and orientations in the images.</p><p>Besides, we use steerable filters of Gaussian derivatives <ref type="bibr" coords="3,345.64,523.49,16.13,9.74" target="#b17">[18]</ref>, in which the basis filter bank is composed of separable orthogonal kernels using the first and second-order Gaussian derivatives at a specific scale (𝜎 = 1). The texture patterns can then be obtained by a linear combination of the filter responses at different orientations. In order to generate the steerable filters, we used a regular sampling at [0, 45, 90, 135] degrees for the orientation parameter. Besides, the kernel window size was set to 2⌈2𝜎 ⌉ + 1. By employing these choices, we were able to construct a set of steerable filters (#8) that would exhibit controlled directional selectivity and effectively capture various orientations within the image data.</p><p>Furthermore, the Gaussian derivatives are used as basis functions to filter the images at different scales, where the texture features are extracted from the gradient magnitude, eigenvalues of the Hessian, Laplacian of Gaussian, Gaussian curvature, and Frobenius norm (eigen magnitude) of the Hessian at each scale <ref type="bibr" coords="4,213.07,88.09,16.16,9.74" target="#b18">[19]</ref>. To construct the multiscale filters using Gaussian derivatives, we applied standard deviations 𝜎 = [0.5, 0.75, 1, 1.25, 1.5] to the Gaussian function. The kernel window size for each scale was determined as 2⌈2𝜎 ⌉ + 1, ensuring an appropriate spatial extent for the filter. These choices enabled us to capture texture feature maps (#30) across multiple scales, facilitating the comprehensive analysis of image content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Deep features</head><p>Deep learning-based features such as convolutional neural network (CNN) representations are high-level abstract information extracted using pretrained models like ResNet <ref type="bibr" coords="4,455.56,205.56,16.27,9.74" target="#b19">[20]</ref>. These models are trained on large-scale image datasets <ref type="bibr" coords="4,303.81,219.11,17.77,9.74" target="#b20">[21]</ref> and can capture effective texture patterns from images at different scales and levels of abstraction before the output classification layer. We used the pretrained ResNet50 architecture to extract the features from the output of the 14th addition layer <ref type="bibr" coords="4,175.81,259.76,16.25,9.74" target="#b21">[22]</ref>, which would result in 7 × 7 × 2048 texture maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Histogram descriptors</head><p>These descriptors capture the distribution of intensities obtained from the local statistical features or filter maps by dividing the range of intensities into bins and counting the number of pixels falling into each bin. Since the histogram bins need to be defined and adjusted for different maps, we use the empirical cumulative distribution function (CDF) that provides information about the accumulated probability of pixel intensities. It gives insights regarding dominant intensities and their spread within the texture while allowing us to compare the intensities of different maps at specified levels of probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Image classification</head><p>After obtaining the texture descriptors based on the CDF of each abovementioned feature map, we measure the area between the texture CDFs of the query image and those of each generated image using the Wasserstein distance <ref type="bibr" coords="4,257.69,467.61,16.20,9.74" target="#b22">[23]</ref>. These multivariate distances are then used to train a binary classifier to predict whether the query image was utilized for the generation of each fake image using GANs or not. The overall decision is made based on the probability score fusion of the classifier outputs from all query-generated multivariate distance pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data</head><p>The data used in this study was sourced from the ImageCLEF2023 Medical GANs challenge datasets <ref type="bibr" coords="4,127.18,601.40,16.33,9.74" target="#b23">[24,</ref><ref type="bibr" coords="4,146.23,601.40,12.24,9.74" target="#b24">25]</ref>, which were divided into labeled training and unlabeled test sets. The training set comprises 500 artificial images obtained by training diffusion neural networks using axial slices of 3D computed tomography (CT) scans (8-bit/pixel images of dimension 256×256 pixels) from 8000 lung tuberculosis patients, along with 80 real images that were not utilized during the training of GANs, and another 80 real images that were used for training the model. The test set consists of a total of 10,000 generated images and 200 real images, all of which are unlabeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental setup</head><p>We partitioned the available training dataset into training and test sets, ensuring that the training set is exclusively used for training and inference purposes before testing the optimized models. To maintain clarity and avoid confusion between our test data split and the challenge test dataset, we will henceforth refer to them as the inner test and challenge test sets, respectively. The inner test set was generated through a stratified partitioning technique, comprising 10% of the training dataset (160×500). The input data underwent a standardization process, normalizing each feature dimension to zero mean and unit variance using the training set. The target and predicted labels were assigned values of 0 for real data instances not involved in the generation of artificial samples, and 1 for real data instances utilized in the generation of synthetic data.</p><p>We employed the support vector machine (SVM) classifiers <ref type="bibr" coords="5,373.98,230.60,18.07,9.74" target="#b25">[26]</ref> trained in a 5-fold crossvalidation fashion. To capture the non-linear relationships in the data, we utilized a radial basis function (RBF) kernel in conjunction with a logistic function, yielding membership probability scores as the output. The selection of the SVM classifiers were based on careful consideration of various classical classifiers, including discriminant analysis <ref type="bibr" coords="5,353.44,284.80,16.21,9.74" target="#b26">[27]</ref>, boosted ensemble of decision trees <ref type="bibr" coords="5,113.16,298.35,16.11,9.74" target="#b27">[28]</ref>, and feedforward neural networks <ref type="bibr" coords="5,285.74,298.35,16.12,9.74" target="#b28">[29]</ref>. We opted for the SVM classifiers due to their favorable inference and generalization performance in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation metrics</head><p>The total accuracy, precision, recall, specificity, and F1-measure were used as the evaluation metrics for the classification tasks. Specificity measures the proportion of correctly predicted negative instances out of the total actual negative instances. In addition, precision measures the proportion of correctly predicted positive instances out of the total instances predicted as positive, while recall or sensitivity quantifies the proportion of correctly predicted positive instances out of the actual positive instances. Finally, the F1-score provides a balanced assessment of both precision and recall by calculating their harmonic mean, offering a single value that reflects the overall performance of a classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results</head><p>Table <ref type="table" coords="5,115.60,506.19,5.03,9.74" target="#tab_0">1</ref> presents the cross-validated classification accuracies obtained with the proposed GAN-ISI texture analysis method for the inner test and challenge test sets. The results reveal a consistent and promising performance, demonstrating the robustness and effectiveness of the method. Notably, the proposed approach showcases a good balance between precision and recall, indicating its ability to accurately discriminate between the real source and not-used images.</p><p>Furthermore, the generalization of the model to the challenge test set underscores its capability to handle unseen data and reinforces its potential for real-world applications. The achieved accuracies, which are better than random, contribute to the understanding of the proposed method's reliability and its potential to address the security and privacy concerns associated with synthetic medical images generated by GANs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we proposed a method for identifying the source images used in the generation of synthetic medical images using GANs. The approach leveraged texture descriptors extracted from the images through the empirical CDF of texture feature maps, along with the measurement of the Wasserstein distance between the CDFs of the query and generated images. A binary classifier was then trained using these multivariate distances to predict the usage of query images in the generation process. Several binary classifiers and texture descriptors were evaluated, and the experimental results revealed the superior performance of the SVMs and stacked classical texture descriptors compared to other methods, including deep learning-based approaches. To ensure robustness and avoid overfitting, cross-validation techniques were employed and applied to an inner test set, resulting in a reasonably consistent performance that generalized well to the challenge test set. The achieved performance surpassed random guessing, indicating the effectiveness of the proposed method.</p><p>These findings offer valuable insights into the security and privacy aspects of personal medical image data when generating and utilizing synthetic images in real-life scenarios. By accurately identifying the source images, our method contributes to addressing concerns related to the potential sharing and usage limitations inherited from sensitive medical data. The use of classical texture descriptors and the balanced performance obtained demonstrate the potential of our approach in practical applications involving the generation and analysis of artificial medical images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,90.67,408.12,78.34"><head>Table 1</head><label>1</label><figDesc>The cross-validated classification accuracies of the proposed GAN-ISI method for different test sets.</figDesc><table coords="6,142.71,124.33,309.85,44.68"><row><cell>Data</cell><cell cols="5">Accuracy Precision Recall Specificity F1-score</cell></row><row><cell>Inner test set</cell><cell>0.575</cell><cell>0.591</cell><cell>0.500</cell><cell>0.650</cell><cell>0.541</cell></row><row><cell>Challenge test set</cell><cell>0.535</cell><cell>0.540</cell><cell>0.470</cell><cell>0.600</cell><cell>0.503</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,537.99,394.53,9.74;6,112.34,551.54,394.29,9.74;6,112.41,565.09,38.81,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,166.01,551.54,146.96,9.74">Generative adversarial networks</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,325.53,551.54,136.11,9.74">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="139" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,578.64,394.53,9.74;6,112.66,592.19,184.15,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,227.62,578.64,274.97,9.74">Generative adversarial network in medical imaging: A review</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Walia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Babyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,112.66,592.19,106.19,9.74">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101552</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,605.74,394.53,9.74;6,112.66,619.29,395.00,9.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,112.66,619.29,152.82,9.74">GDPR: An impediment to research?</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Vale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">P</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kirwan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hurl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">G</forename><surname>Mcelvaney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,273.35,619.29,137.66,9.74">Irish Journal of Medical Science</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="page" from="1129" to="1135" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,632.84,393.70,9.74;6,112.66,646.39,381.28,9.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,325.59,632.84,180.77,9.74;6,112.66,646.39,85.30,9.74">Privacy preservation for image data: A GAN-based method</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,207.08,646.39,192.79,9.74">International Journal of Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1668" to="1685" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,659.94,393.32,9.74;7,112.66,88.09,393.53,9.74;7,112.30,101.64,124.54,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,240.17,659.94,265.81,9.74;7,112.66,88.09,78.00,9.74">Attributing fake images to GANs: Learning and analyzing GAN fingerprints</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,215.76,88.09,290.42,9.74;7,112.30,101.64,26.65,9.74">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7556" to="7566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,115.19,394.61,9.74;7,112.66,128.74,142.55,9.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,236.94,115.19,247.22,9.74">Does a GAN leave distinct model-specific fingerprints</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,128.74,110.78,9.74">Proceedings of the BMVC</title>
		<meeting>the BMVC</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,142.29,393.32,9.74;7,112.66,155.84,238.62,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,361.36,142.29,144.63,9.74;7,112.66,155.84,99.36,9.74">A survey of deep learning-based source image forensics</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Baracchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Argenti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Piva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,220.17,155.84,83.60,9.74">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,169.38,395.17,9.74;7,112.66,182.93,393.97,9.74;7,112.66,196.48,28.67,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,428.87,169.38,78.96,9.74;7,112.66,182.93,271.82,9.74">Recurrent convolutional strategies for face manipulation detection in videos</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sabir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Abdalmageed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,394.98,182.93,72.65,9.74">Interfaces (GUI)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="80" to="87" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,210.03,395.16,9.74;7,112.66,223.58,393.32,9.74;7,112.66,237.13,273.01,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,266.81,210.03,241.02,9.74;7,112.66,223.58,195.40,9.74">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,331.85,223.58,174.13,9.74;7,112.66,237.13,185.04,9.74">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,250.68,393.32,9.74;7,112.66,264.23,393.31,9.74;7,112.66,277.78,228.76,9.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,453.86,250.68,52.13,9.74;7,112.66,264.23,393.31,9.74;7,112.66,277.78,55.98,9.74">GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Frid-Adar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Diamant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Amitai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,176.56,277.78,75.85,9.74">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,291.33,394.61,9.74;7,112.66,304.88,327.84,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,281.97,291.33,202.29,9.74">Wasserstein generative adversarial networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,304.88,207.49,9.74">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,318.43,393.32,9.74;7,112.66,331.98,393.32,9.74;7,112.66,345.52,149.51,9.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,270.76,318.43,235.22,9.74;7,112.66,331.98,51.28,9.74">Interpreting the latent space of GANs for semantic face editing</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,189.23,331.98,316.75,9.74;7,112.66,345.52,51.39,9.74">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9243" to="9252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,359.07,394.52,9.74;7,112.66,372.62,265.14,9.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,213.60,359.07,188.16,9.74">Face-image source generator identification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hel-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,424.86,359.07,82.32,9.74;7,112.66,372.62,134.82,9.74">Computer Vision-ECCV 2020 Workshops: Part V</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="511" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,386.17,394.52,9.74;7,112.66,399.72,308.37,9.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,322.02,386.17,181.12,9.74">Textural features for image classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,112.66,399.72,237.30,9.74">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,413.27,393.32,9.74;7,112.66,426.82,367.48,9.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,291.93,413.27,214.04,9.74;7,112.66,426.82,196.55,9.74">A comparative study of texture measures with classification based on featured distributions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,317.34,426.82,89.02,9.74">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,440.37,393.32,9.74;7,112.33,453.92,346.83,9.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,223.18,440.37,251.28,9.74">Filtering for texture classification: A comparative study</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Husoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,484.08,440.37,21.90,9.74;7,112.33,453.92,262.90,9.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="291" to="310" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,467.47,393.32,9.74;7,112.66,481.02,147.74,9.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,224.78,467.47,241.42,9.74">Unsupervised texture segmentation using Gabor filters</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,473.58,467.47,32.40,9.74;7,112.66,481.02,53.66,9.74">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,494.57,393.32,9.74;7,112.33,508.11,346.83,9.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,293.32,494.57,178.07,9.74">The design and use of steerable filters</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,484.08,494.57,21.90,9.74;7,112.33,508.11,262.90,9.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="891" to="906" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,521.66,393.61,9.74;7,112.66,535.21,393.33,9.74;7,112.66,548.76,91.35,9.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="7,482.55,521.66,23.71,9.74;7,112.66,535.21,283.07,9.74">Early detection of Alzheimer&apos;s disease using MRI hippocampal texture</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Liv Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Osler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rostrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,403.84,535.21,102.14,9.74">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1148" to="1161" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,562.31,395.17,9.74;7,112.66,575.86,395.01,9.74;7,112.41,589.41,38.81,9.74" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="7,259.51,562.31,203.27,9.74">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,488.38,562.31,19.45,9.74;7,112.66,575.86,348.39,9.74">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,602.96,393.33,9.74;7,112.66,616.51,283.88,9.74" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="7,295.16,602.96,210.83,9.74;7,112.66,616.51,70.43,9.74">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,191.91,616.51,130.83,9.74">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,630.06,393.32,9.74;7,112.66,643.61,203.66,9.74" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="7,234.69,630.06,271.28,9.74;7,112.66,643.61,32.31,9.74">Perceptual quality assessment of digital images using deep features</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M S</forename><surname>Asif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,156.97,643.61,114.56,9.74">Computing &amp; Informatics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,657.16,393.33,9.74;7,112.66,670.70,246.94,9.74" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.03570</idno>
		<title level="m" coord="7,228.09,657.16,277.89,9.74;7,112.66,670.70,63.89,9.74">Why the 1-Wasserstein distance is the area between the two marginal CDFs</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,88.09,394.53,9.74;8,112.66,101.64,395.17,9.74;8,112.34,115.19,394.85,9.74;8,112.66,128.74,394.53,9.74;8,112.28,142.29,395.54,9.74;8,112.66,155.84,393.32,9.74;8,112.66,169.38,394.53,9.74;8,112.66,182.93,393.32,9.74;8,112.66,196.48,178.53,9.74" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="8,201.90,155.84,304.08,9.74;8,112.66,169.38,200.52,9.74">Overview of ImageCLEF 2023: Multimedia retrieval in medical, social media and recommender systems applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-M</forename><surname>Drăgulinescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>-W. Yim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yetisgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Storås</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Papachrysos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schöler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Andrei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radzhabov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Coman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Manguinhas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-D</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,336.34,169.38,170.85,9.74;8,112.66,182.93,393.32,9.74;8,112.66,196.48,76.73,9.74">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 14th International Conference of the CLEF Association</title>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,210.03,393.32,9.74;8,112.66,223.58,393.31,9.74;8,112.66,237.13,393.33,9.74;8,112.66,250.68,190.89,9.74" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="8,449.39,210.03,56.58,9.74;8,112.66,223.58,393.31,9.74;8,112.66,237.13,285.94,9.74">Overview of ImageCLEFmedical GANs 2023 Task -Identifying training data fingerprints in synthetic biomedical images generated by GANs for medical image security</title>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Andrei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radzhabov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Coman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.45,237.13,84.54,9.74;8,112.66,250.68,160.76,9.74">CLEF2023 Working Notes, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,264.23,378.53,9.74" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="8,208.31,264.23,109.06,9.74">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,326.19,264.23,81.07,9.74">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,277.78,393.32,9.74;8,112.66,291.33,198.93,9.74" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="8,250.22,277.78,255.76,9.74;8,112.66,291.33,63.00,9.74">Regularized linear discriminant analysis and its application in microarrays</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,184.26,291.33,53.54,9.74">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="86" to="100" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,304.88,393.32,9.74;8,112.66,318.43,394.53,9.74;8,112.66,331.98,90.72,9.74" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="8,268.56,304.88,237.42,9.74;8,112.66,318.43,46.90,9.74">Totally corrective boosting algorithms that maximize the margin</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,183.68,318.43,318.75,9.74">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1001" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,345.52,395.17,9.74;8,112.26,359.07,393.72,9.74;8,112.66,372.62,352.91,9.74" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="8,205.31,345.52,302.52,9.74;8,112.26,359.07,24.38,9.74">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,158.88,359.07,347.10,9.74;8,112.66,372.62,264.90,9.74">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, JMLR Workshop and Conference Proceedings</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics, JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
