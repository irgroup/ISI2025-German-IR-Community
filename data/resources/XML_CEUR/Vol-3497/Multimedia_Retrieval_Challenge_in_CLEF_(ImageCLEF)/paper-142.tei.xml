<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.69,15.42;1,89.29,106.66,106.29,15.43">MLRG-JBTTM at MEDIQA-Sum 2023: Dialogue2Topic Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,128.91,11.96"><forename type="first">Harshida</forename><forename type="middle">Sujatha</forename><surname>Palaniraj</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.83,134.97,75.06,11.96"><forename type="first">Keerthan</forename><surname>Vinod</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.34,134.97,71.20,11.96"><forename type="first">Mohith</forename><surname>Adluru</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,397.89,134.97,98.38,11.96"><forename type="first">Bhuvana</forename><surname>Jayaraman</surname></persName>
							<email>bhuvanaj@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,113.26,148.92,71.23,11.96"><forename type="first">Mirnalinee</forename><surname>Tt</surname></persName>
							<email>mirnalineett@ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.69,15.42;1,89.29,106.66,106.29,15.43">MLRG-JBTTM at MEDIQA-Sum 2023: Dialogue2Topic Classification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">F935E1CBC1A9F42E2BA42A344FFB3CDD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Clinical dialogues</term>
					<term>Doctor-patient conversation</term>
					<term>Medical records</term>
					<term>Section headers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In medical settings, effective organization and retrieval of information from doctor-patient conversations are essential for providing quality healthcare. This paper focuses on dialogue-to-topic classification, specifically the task of identifying the topic (associated section header) in a conversation snippet between a doctor and a patient. Accurate classification of these topics can significantly improve the accessibility and efficiency of medical records, facilitating medical research, clinical decision-making, and patient care. We used the SVM, Random Forest, and KNN models for evaluation. Among these models, the SVM achieved a ranking of 18, followed by the Random Forest model at 21, and the KNN model at 22, based on the obtained accuracies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Doctor-patient conversations serve as a primary source of valuable information in the field of healthcare. Also, there is significant research to show that capacity to remember medical records is different among young and adults <ref type="bibr" coords="1,285.96,420.63,11.33,10.91" target="#b0">[1]</ref>. The ability to efficiently organize and retrieve information from these conversations is crucial for effective medical record management, knowledge extraction, and medical decision-making. However, extracting meaningful insights from large volumes of conversational data remains a challenging task. By some estimates, doctors may spend as much as two additional hours of administrative work to every one hour spent with patients <ref type="bibr" coords="1,176.26,488.37,11.30,10.91" target="#b1">[2]</ref>. This paper focuses on the problem of dialogue-to-topic classification in the context of doctor-patient conversations.</p><p>The dialogue-to-topic classification task involves automatically identifying the topics associated with a given conversation snippet <ref type="bibr" coords="1,276.50,529.02,11.58,10.91" target="#b2">[3]</ref>. The topic headers serve as labels or categories representing the main topics discussed in the conversation, such as medical history, symptoms, diagnosis, treatment, and follow-up <ref type="bibr" coords="1,257.02,556.12,11.58,10.91" target="#b3">[4]</ref>. Accurate classification of section headers enables efficient indexing, retrieval, and analysis of medical records, supporting various healthcare applications.</p><p>The primary objective of this paper is to develop and evaluate advanced techniques for dialogue-to-topic classification in doctor-patient conversations <ref type="bibr" coords="2,378.20,127.61,11.58,10.91" target="#b4">[5]</ref>. By accurately assigning topics to conversation snippets, medical practitioners, researchers, and healthcare systems can efficiently navigate and access specific information within medical records, ultimately improving patient care and medical outcomes.</p><p>The motivation behind this research stems from the increasing digitization of medical records and the growing volume of doctor-patient conversations recorded in electronic formats. Traditional manual methods of organizing and categorizing these conversations are time-consuming and error-prone, hindering the efficient retrieval and analysis of crucial medical information. By automating the dialogue-to-topic classification process, we aim to enhance the organization and accessibility of medical records, promoting more effective healthcare management.</p><p>Section 1 provides an overview of the need for medical dialogue summarization. Section 2 discusses existing research work in this area. Section 3 presents the methodology of the proposed models. Section 4 showcases the results and includes a discussion. Finally, Section 5 concludes the paper, summarizing the key findings and highlighting potential future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Survey of existing systems</head><p>The research paper focuses on clinical note summarization, which falls under Subtask A. The medical dialogues are captioned and summarised using machine learning and deep learning models. The dialogue summarization pipeline <ref type="bibr" coords="2,291.61,403.03,12.69,10.91" target="#b5">[6]</ref> combines AI and computational linguistics algorithms to automatically generate medical reports. The processes involve speech transcription, triple extraction, triple matching, and report generation .</p><p>The authors <ref type="bibr" coords="2,155.74,443.67,12.69,10.91" target="#b6">[7]</ref> developed an original automatic synthesis method for medical conversations between a patient and a healthcare professional. Some of the machine learning approaches used are naïve bayes, SVM and genetic algorithms .</p><p>The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). The paper uses a framework that integrates LoRA and structured layer pruning. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks <ref type="bibr" coords="2,480.71,565.62,11.43,10.91" target="#b7">[8]</ref>.</p><p>The authors <ref type="bibr" coords="2,157.15,579.17,12.88,10.91" target="#b8">[9]</ref> utilized deep convolutional neural networks to learn complex features and demonstrate through evaluation that their method outperforms existing natural language processing approaches by approximately 15% in terms of accuracy. The study focuses on categorizing medical text fragments and compares their CNN-based approach with three other methods: Sentence Embeddings, Mean Word Embeddings, and Word Embeddings with BOW. The CNN-based approach achieves the highest accuracy due to its ability to capture more complex features.</p><p>Manual labeling is a time consuming and errorprone task. One possible solution to this issue is to exploit the large number of unlabeled samples that are easily accessible via the internet. The proposed method <ref type="bibr" coords="3,170.12,114.06,17.95,10.91" target="#b9">[10]</ref> selects a batch of informative samples using the posterior probabilities provided by a set of multi-class SVM classifiers, and these samples are then manually labeled by an expert. Experimental results indicate that the proposed active learning method significantly reduces the labeling effort, while simultaneously enhancing the classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>The paper proposes three classifiers for text categorization namely Support Vector Machines (SVM), Random Forest, and K-Nearest Neighbors (KNN) classifiers. Each model offers unique strengths and employs different techniques, as shown in Figure <ref type="figure" coords="3,371.32,240.44,3.70,10.91" target="#fig_0">1</ref>, to accurately categorize text sections, providing researchers and practitioners with diverse options for their specific text categorization tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Classification Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">SVM</head><p>SVM is a suitable choice for dialogue-to-topic categorization from doctor-patient discussions due to its ability to handle high-dimensional data and flexibility in kernel selection. With doctor-patient discussions covering a wide range of subjects, SVM's capability to handle highdimensional data is valuable for capturing complex correlations between characteristics and topics. Additionally, SVM's support for various kernel functions enables the translation of input data into a higher-dimensional feature space, aiding in capturing nonlinear patterns in dialogue features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Random Forest</head><p>Because of the casual character of the communication, doctor-patient talks may involve noise or outliers. The ensemble technique of Random Forest helps to lessen the influence of noisy or outlier data points on overall classification performance. Furthermore, Random Forest gives a measure of feature importance, which can be helpful in determining the most significant conversation characteristics that contribute to topic categorization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">KNN</head><p>In addition to being reasonably simple to build without the need for a lengthy training procedure, KNN makes localised decisions by classifying new instances based on the majority class of its k closest neighbours. This method to localised decision-making might be useful for capturing the local structure and linkages inside doctor-patient dialogues. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature Extraction and Classification Pipeline</head><p>To convert the textual data into numerical representations, the TF-IDF vectorization technique is applied using the 'TfidfVectorizer' class from scikit-learn. The vectorizer considers unigrams and bigrams and limits the maximum number of features to 999,000. A pipeline is created using the 'Pipeline' class from scikit-learn.</p><p>Each proposed model demonstrates how to preprocess textual data, create a pipeline, and train the classifier on a dataset consisting of dialogues and their corresponding section headers with the use of SVM, Random Forest, and KNN Classifiers respectively.</p><p>It consists of two steps: TF-IDF vectorization and the classification. Each classifier is used in the pipeline, with default parameter settings. It aims to find an optimal hyperplane that separates different classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model Training and Evaluation</head><p>The models are trained on the training set, where each classifier learns the patterns and relationships between the text data and their corresponding section headers. The training process involves adjusting the parameters and optimizing the model's performance using techniques such as grid search and cross-validation <ref type="bibr" coords="5,278.03,258.64,17.95,10.91" target="#b10">[11]</ref>.To further improve the model's performance, hyperparameter tuning is conducted using a grid search approach. Hyperparameters are parameters that are not learned from the data but are set prior to the training process. Grid search involves specifying a range of values for each hyperparameter and exhaustively searching through all possible combinations to identify the best set of hyperparameters.During the grid search process, different combinations of hyperparameters are evaluated using cross-validation. Cross-validation involves splitting the training set into multiple subsets called folds. The model is trained on a subset of the folds and validated on the remaining fold. This process is repeated for each fold, and the average performance is computed.By performing grid search and crossvalidation, the models are trained with the optimal set of hyperparameters, maximizing their performance on the training set. Once trained, the models are evaluated using the test set to assess their accuracy and generalization capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Dataset Description</head><p>The Medical Conversation Dataset <ref type="bibr" coords="5,241.17,457.40,17.75,10.91" target="#b11">[12]</ref> comprises a diverse range of medical scenarios, covering chief complaints, medical history, medications, allergies, family and social history, and general health discussions. Each dialogue snippet within the dataset encapsulates a specific patient's case, providing examples of doctor-patient interactions.</p><p>The dataset, named "TrainingSet.csv," consists of a collection of medical conversations and their associated section headers and contents. It is structured in a tabular format with three columns: "id, " "section header, " and "dialogue. "</p><p>The dataset comprises 1,201 pairs of conversations in the training set, allowing for extensive training and development of natural language processing (NLP) models <ref type="bibr" coords="5,406.74,565.80,11.35,10.91" target="#b3">[4]</ref>. Each conversation pair includes the section headers, which provide a categorical context for the corresponding dialogue content.</p><p>Additionally, the dataset includes a validation set with 100 pairs of conversations and their summaries. This subset serves as a valuable resource for evaluating the performance and generalization capabilities of NLP models in summarizing medical conversations.</p><p>The pipeline undergoes training on the provided training data to learn patterns and establish a classification hyperplane. Subsequently, it is evaluated by comparing its predicted section </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and discussion</head><p>Google Colab notebook was used to train the model with RAM size of 8GB on a 2.3GHz Intel Xenon CPU.</p><p>The three models are trained and accuracy metrics is used to study the performance of the model during training. The validation accuracy of SVM, Random Forest Classifier and KNN Classifier models are 77%, 73% and 73% respectively.</p><p>Among the three models, the SVM classifier showed the highest performance, with notable precision, recall, and F1-score values for various section headers. The SVM model's generalization capabilities and handling of high-dimensional feature spaces contributed to its superior performance. However, the Random Forest and KNN classifiers also delivered competitive results, indicating their suitability for dialogue-to-topic classification tasks.</p><p>The variation in performance across different section headers suggests that the models excel in classifying certain sections but struggle with others. The inherent complexity and variety of doctor-patient dialogues is an essential element. The language used, the variety of subjects covered, and the dynamics of the discussion can all have a major influence on the categorization assignment. Some subjects may be simpler to categorise because of different patterns or explicit references, but others may be more difficult because of ambiguity or overlapping language clues. Predictions were biased due to the class imbalance, with the model favouring the dominant class. As a result, the majority class performed poorly whereas the minority classes performed well in terms of precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Submitted runs and results</head><p>The proposed models, SVM, Random Forest and KNN, have obtained a testing accuracy of 66.5%, 57% and 56.5% respectively as reported in Table 4 <ref type="bibr" coords="7,312.11,217.99,11.49,10.91" target="#b3">[4]</ref>. The variations observed in the analysis of different topics can be attributed to the sensitivity of each model. The models employed in this study incorporate distinct algorithms and make different assumptions, thereby leading to variations in their performance across various topics. Based on these accuracies, the models achieved rankings of 18, 21, and 22 respectively. The observed variations in performance across different section headers are as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Support Vector Machines (SVM) Classifier</head><p>The model achieved perfect precision, recall, and f1-score (all 1.00) for the "ALLERGY" section. Poor performance was observed for sections namely, "ASSESSMENT," "DIAGNOSIS," "EDCOURSE, " "IMAGING, " "LABS, " and "GYNHX" with all metrics being 0.00, as shown in Table <ref type="table" coords="7,89.04,375.71,3.74,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Random Forest Classifier</head><p>As depicted in Table <ref type="table" coords="7,186.62,425.04,3.81,10.91" target="#tab_0">1</ref>, good performance for sections namely "ALLERGY," "FAM/SOCHX," "GENHX, " "MEDICATIONS, " and "PASTSURGICAL" with reasonably high precision, recall, and f1-scores and poor performance for sections like "ASSESSMENT, " "DIAGNOSIS, " "DISPOSITION, " "EDCOURSE," "IMAGING," "GYNHX," and "IMMUNIZATIONS" with all metrics being 0.00 contributed to the obtained accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">K-Nearest Neighbours (KNN) Classifier</head><p>Perfect precision (1.00) for sections like "ALLERGY, " "EXAM, " "FAM/SOCHX, " "MEDICATIONS, " and "PLAN." and poor performance for sections like "ASSESSMENT," "DIAGNOSIS," "ED-COURSE, " "IMAGING, " "LABS, " "GYNHX, " and "IMMUNIZATIONS" with all metrics being 0.00 were observed in Table <ref type="table" coords="7,194.59,569.21,3.74,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Limitations</head><p>SVMs are susceptible to noisy or incorrectly labelled data. SVM performance may suffer in the presence of noisy conversation data or wrongly labelled samples. On large datasets of doctor-patient conversations, SVM model training and tweaking may consume a substantial amount of computing time. Although beneficial in terms of performance, Random Forest models can be challenging to comprehend because to their ensemble nature. It might be difficult to draw conclusions and comprehend the unique feature contributions to subject categorization from the ensemble of decision trees.</p><p>KNN takes into account all features equally while determining distances, which might be problematic if the dataset contains irrelevant or noisy characteristics. These characteristics may increase noise and have a detrimental effect on classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The focus of MLRG-JBTTM's submission is to accurately assign section headers to conversation snippets by using dialogue-to-topic classification techniques. By addressing this task, we aimed to improve medical record management, knowledge extraction, and medical decision-making processes.</p><p>To achieve this objective, three classification models, namely Support Vector Machines (SVM), Random Forest, and k-Nearest Neighbors (kNN) classifiers, were proposed and evaluated. These models were chosen due to their proven effectiveness in various text classification tasks.</p><p>The study's results have practical applications in healthcare settings because they enable automated analysis of doctor-patient conversations to get significant information. Future study may concentrate on improving dialogue to topic classification systems. This may entail investigating deep learning-based systems such as recurrent neural networks or transformers, which have showed promise in natural language processing. Model understanding and classification accuracy can be improved by including domain-specific knowledge or contextual information, such as patient demographics or medical data. Integration of domain-specific characteristics such as named entity identification or sentiment analysis may improve the models' capacity to collect complex information in discussions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,575.28,132.28,8.93;4,89.29,84.19,416.69,478.53"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture overview</figDesc><graphic coords="4,89.29,84.19,416.69,478.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,90.49,462.32,361.74"><head>Table 1</head><label>1</label><figDesc>Classification Reports for SVM, Random Forest, and KNN Classifiers</figDesc><table coords="6,89.29,122.10,462.02,330.12"><row><cell>Section Headers</cell><cell cols="7">precision recall f1-score support SVM Accuracy RF Accuracy KNN Accuracy</cell></row><row><cell>ALLERGY</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>9</cell><cell>1.00</cell><cell>0.74</cell><cell>0.82</cell></row><row><cell>ASSESSMENT</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>6</cell><cell>0.00</cell><cell>0.00</cell><cell>0.25</cell></row><row><cell>CC</cell><cell>0.50</cell><cell>0.33</cell><cell>0.40</cell><cell>15</cell><cell>0.40</cell><cell>0.57</cell><cell>0.37</cell></row><row><cell>DIAGNOSIS</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>4</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>DISPOSITION</cell><cell>0.67</cell><cell>0.67</cell><cell>0.67</cell><cell>3</cell><cell>0.67</cell><cell>0.00</cell><cell>0.67</cell></row><row><cell>EDCOURSE</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>3</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>EXAM</cell><cell>1.00</cell><cell>0.75</cell><cell>0.86</cell><cell>4</cell><cell>0.86</cell><cell>0.33</cell><cell>0.86</cell></row><row><cell>FAM/SOCHX</cell><cell>0.92</cell><cell>0.96</cell><cell>0.94</cell><cell>71</cell><cell>0.94</cell><cell>0.79</cell><cell>0.90</cell></row><row><cell>GENHX</cell><cell>0.62</cell><cell>0.95</cell><cell>0.75</cell><cell>55</cell><cell>0.75</cell><cell>0.87</cell><cell>0.71</cell></row><row><cell>GYNHX</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>4</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>IMAGING</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>2</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>LABS</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>2</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>MEDICATIONS</cell><cell>0.92</cell><cell>1.00</cell><cell>0.96</cell><cell>11</cell><cell>0.96</cell><cell>0.82</cell><cell>0.74</cell></row><row><cell>PASTMEDICALHX</cell><cell>0.69</cell><cell>0.75</cell><cell>0.72</cell><cell>24</cell><cell>0.72</cell><cell>0.39</cell><cell>0.70</cell></row><row><cell>PASTSURGICAL</cell><cell>0.90</cell><cell>0.82</cell><cell>0.86</cell><cell>11</cell><cell>0.86</cell><cell>0.64</cell><cell>0.80</cell></row><row><cell>PLAN</cell><cell>1.00</cell><cell>0.25</cell><cell>0.40</cell><cell>4</cell><cell>0.40</cell><cell>0.00</cell><cell>0.40</cell></row><row><cell>ROS</cell><cell>0.88</cell><cell>0.54</cell><cell>0.67</cell><cell>13</cell><cell>0.67</cell><cell>0.53</cell><cell>0.80</cell></row><row><cell>accuracy</cell><cell></cell><cell></cell><cell>0.77</cell><cell>241</cell><cell>0.77</cell><cell>0.73</cell><cell>0.73</cell></row><row><cell>macro avg</cell><cell>0.53</cell><cell>0.47</cell><cell>0.48</cell><cell>241</cell><cell>0.48</cell><cell>0.35</cell><cell>0.47</cell></row><row><cell>weighted avg</cell><cell>0.72</cell><cell>0.77</cell><cell>0.73</cell><cell>241</cell><cell>0.73</cell><cell>0.68</cell><cell>0.70</cell></row><row><cell cols="6">headers against the actual section headers to calculate its accuracy.</cell><cell></cell><cell></cell></row><row><cell cols="7">The dataset, stored in a CSV file, is split into training and test sets with a ratio of 80% for</cell><cell></cell></row><row><cell cols="3">training data and 20% for testing data.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.99,90.49,295.37,81.83"><head>Table 2</head><label>2</label><figDesc>Evaluated results of ImageCLEF MediQA</figDesc><table coords="8,210.91,122.10,173.45,50.21"><row><cell>Rank</cell><cell>Participant</cell><cell cols="2">Run Accuracy</cell></row><row><cell>18</cell><cell cols="2">MLRG-JBTTM run1</cell><cell>0.665</cell></row><row><cell>21</cell><cell cols="2">MLRG-JBTTM run2</cell><cell>0.57</cell></row><row><cell>22</cell><cell cols="2">MLRG-JBTTM run3</cell><cell>0.565</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,600.81,393.60,10.91;8,112.66,614.36,394.51,10.91;8,112.66,630.35,103.29,7.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,174.86,600.81,331.40,10.91;8,112.66,614.36,106.38,10.91">Remembering what the doctor said: Organization and adults&apos; memory for medical information</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mcguire</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610739608254020</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,228.56,614.36,130.36,10.91">Experimental aging research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="403" to="428" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,641.45,394.53,10.91;8,112.66,655.00,393.32,10.91;8,112.41,668.55,351.99,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,153.51,655.00,352.48,10.91;8,112.41,668.55,52.14,10.91">Allocation of physician time in ambulatory practice: A time and motion study in 4 specialties</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sinsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Colligan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Prgomet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Westbrook</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tutty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Blike</surname></persName>
		</author>
		<idno type="DOI">10.7326/M16-0961</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,172.51,668.55,124.90,10.91">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.33,10.91;9,112.26,100.52,397.88,10.91;9,112.36,116.51,32.07,7.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,271.42,86.97,234.57,10.91;9,112.26,100.52,120.19,10.91">Intention classification in multiturn dialogue systems with key sentences mining</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1111/coin.12345</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,242.66,100.52,124.15,10.91">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,127.61,393.32,10.91;9,112.66,141.16,394.53,10.91;9,112.66,154.71,394.53,10.91;9,112.66,168.26,58.60,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,375.45,127.61,130.53,10.91;9,112.66,141.16,389.97,10.91">Overview of the mediqa-sum task at imageclef 2023: Summarization and classification of doctor-patient conversations</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yetisgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,127.07,154.71,113.05,10.91">CLEF 2023 Working Notes</title>
		<title level="s" coord="9,247.43,154.71,172.42,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,181.81,393.33,10.91;9,112.66,195.36,265.77,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,238.19,181.81,189.66,10.91">Intent classification for dialogue utterances</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Frasincar</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIS.2019.2954966</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,436.23,181.81,69.75,10.91;9,112.66,195.36,50.89,10.91">IEEE Intelligent Systems PP</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,395.17,10.91;9,112.66,222.46,394.51,10.91;9,112.66,238.45,117.15,7.90" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Molenaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Burriel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Dalpiaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brinkkemper</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-49165-9_7</idno>
		<title level="m" coord="9,399.15,208.91,108.68,10.91;9,112.66,222.46,238.52,10.91">Medical Dialogue Summarization for Automated Reporting in Healthcare</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="76" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,249.56,376.54,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,188.52,249.56,227.19,10.91">Automatic summarization of medical conversations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">López</forename><surname>Espejel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>a review</note>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.33,10.91;9,112.66,276.66,311.02,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08285</idno>
		<title level="m" coord="9,266.90,263.11,239.08,10.91;9,112.66,276.66,180.61,10.91">Parameter-efficient fine-tuning with layer pruning on free-text sequence-to-sequence modeling</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,393.33,10.91;9,112.66,303.75,394.51,10.91;9,112.66,319.74,129.52,7.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,302.69,290.20,203.29,10.91;9,112.66,303.75,69.26,10.91">Medical text classification using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kotoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suzumura</surname></persName>
		</author>
		<idno type="DOI">10.3233/978-1-61499-753-5-246</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,190.65,303.75,200.97,10.91">Studies in Health Technology and Informatics</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.33,10.91;9,112.66,344.40,395.01,10.91;9,112.66,357.95,168.81,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,332.20,330.85,173.79,10.91;9,112.66,344.40,111.41,10.91">A novel active learning method using svm for text classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Goudjil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koudil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bedda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ghoggali</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11633-015-0912-z</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,231.98,344.40,231.27,10.91">International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,393.33,10.91;9,112.66,385.05,394.51,10.91;9,112.66,401.04,86.48,7.90" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,197.60,371.50,308.39,10.91;9,112.66,385.05,177.05,10.91">Efficient hyperparameter tuning with grid search for text categorization using knn approach with bm25 similarity</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ghawi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pfeffer</surname></persName>
		</author>
		<idno type="DOI">10.1515/comp-2019-0011</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,297.17,385.05,105.33,10.91">Open Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,412.15,394.53,10.91;9,112.66,425.70,395.17,10.91;9,112.66,439.25,394.53,10.91;9,112.66,452.79,395.17,10.91;9,112.39,466.34,394.80,10.91;9,112.48,479.89,394.70,10.91;9,112.66,493.44,395.17,10.91;9,112.66,506.99,393.32,10.91;9,112.66,520.54,394.52,10.91;9,112.33,534.09,120.27,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,224.93,479.89,282.25,10.91;9,112.66,493.44,228.44,10.91">Overview of ImageCLEF 2023: Multimedia retrieval in medical, socialmedia and recommender systems applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Drăgulinescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yetisgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garcıa Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brüngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Idrissi-Yaghir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Storås</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Papachrysos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schöler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Andrei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radzhabov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Coman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Manguinhas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,363.94,493.44,143.89,10.91;9,112.66,506.99,393.32,10.91;9,112.66,520.54,136.27,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 14th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,280.09,520.54,221.52,10.91">Springer Lecture Notes in Computer Science LNCS</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
