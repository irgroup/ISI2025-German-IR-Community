<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,389.36,15.42;1,89.29,106.66,171.69,15.42;1,89.29,129.00,223.49,11.96">Leveraging GPT-2 for Automated Classification of Online Sexist Content Notebook for the Exist 2023 Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,154.90,85.85,11.96"><forename type="first">Advaitha</forename><surname>Vetagiri</surname></persName>
							<email>advaitha21_rs@cse.nits.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Technology Silchar</orgName>
								<address>
									<postCode>788010</postCode>
									<settlement>Assam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,193.35,154.90,121.57,11.96"><roleName>Prottay</roleName><forename type="first">Kumar</forename><surname>Adhikary</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Technology Silchar</orgName>
								<address>
									<postCode>788010</postCode>
									<settlement>Assam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.57,154.90,69.16,11.96"><forename type="first">Partha</forename><surname>Pakray</surname></persName>
							<email>partha@cse.nits.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Technology Silchar</orgName>
								<address>
									<postCode>788010</postCode>
									<settlement>Assam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,427.73,154.90,63.13,11.96"><forename type="first">Amitava</forename><surname>Das</surname></persName>
							<email>amitava@mailbox.sc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Artificial Intelligence Institute of UofSC (AIISC)</orgName>
								<address>
									<addrLine>1112 Greene St</addrLine>
									<settlement>Columbia</settlement>
									<region>South Carolina</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Wipro AI Lab</orgName>
								<address>
									<settlement>Bangalore</settlement>
									<region>Karnataka</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,389.36,15.42;1,89.29,106.66,171.69,15.42;1,89.29,129.00,223.49,11.96">Leveraging GPT-2 for Automated Classification of Online Sexist Content Notebook for the Exist 2023 Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">DF06A2EFAAB96E3A8E19FDF58DC5A825</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sexism Classification</term>
					<term>GPT-2</term>
					<term>Exist 2023</term>
					<term>ICM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In today's digital culture, sexism and misogyny on online platforms have grown to be serious issues. To solve these problems, efficient automated sexist content detection and classification techniques must be created. In this study, we investigate the application of the GPT-2 model, a cutting-edge pre-trained language model, to the shared Exist 2023 job of sexism categorization. On the Exist 2023 dataset, we fine-tuned the GPT-2 model by adding adjustments like a classification head and weighted cross-entropy loss to tackle class imbalance. Our experimental findings show the GPT-2 model's potential for precisely recognizing and classifying instances of sexism. Using the official assessment measure ICM (Information Contrast Measure), we assess our strategy while taking into account various evaluation modes, such as hard-hard, hard-soft, and soft-soft. The results show how well the GPT-2 model handles the problem of sexism categorization, assisting in the creation of automated techniques for fostering a safer and more welcoming online environment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Sexism, encompassing various forms of oppression and prejudice against women due to gender, remains a pervasive issue today. It manifests in numerous ways, including stereotyping <ref type="bibr" coords="1,491.74,470.92,11.58,10.91" target="#b0">[1]</ref>, ideological biases <ref type="bibr" coords="1,168.42,484.47,11.30,10.91" target="#b1">[2]</ref>, and even explicit acts of sexual violence <ref type="bibr" coords="1,363.95,484.47,11.30,10.91" target="#b2">[3]</ref>. As a result of the realization that online forums significantly influence public debate, identifying and combatting sexism in social networks has emerged as a crucial subject of research. As scholars and practitioners strive to understand better and address this complex problem, the EXIST 2023 shared task <ref type="bibr" coords="1,454.50,525.11,12.68,10.91" target="#b3">[4]</ref> emerges as a pivotal platform for advancing state of the art in sexism detection and classification.</p><p>Numerous studies have shown how seriously sexism affects both individuals and society as a whole. It perpetuates gender inequalities, restricts opportunities, and reinforces harmful stereotypes, ultimately hindering progress towards gender equality <ref type="bibr" coords="1,391.30,579.31,11.43,10.91" target="#b4">[5]</ref>. Previous studies have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Literature Survey</head><p>As shown in prior work by <ref type="bibr" coords="3,205.14,111.28,16.09,10.91" target="#b11">[12]</ref>, one method for overcoming the difficulty of sexism identification is to use conventional machine learning approaches, such as n-grams. Creating a dataset for recognizing and categorizing sexist language on Twitter in both Spanish and English was the main goal of this study. Similarly, <ref type="bibr" coords="3,239.63,151.93,17.82,10.91" target="#b12">[13]</ref> used two datasets in a similar manner to identify online hate speech directed towards women.</p><p>However, recent developments in the field have investigated the use of sophisticated deeplearning approaches to produce cutting-edge outcomes in sexism detection. For instance, <ref type="bibr" coords="3,89.29,206.12,18.07,10.91" target="#b13">[14]</ref> used modified LSTMs with attention mechanisms <ref type="bibr" coords="3,344.00,206.12,18.07,10.91" target="#b14">[15]</ref> and GloVe embeddings <ref type="bibr" coords="3,475.11,206.12,18.07,10.91" target="#b15">[16]</ref> to automatically recognize sexist remarks often heard in the workplace. These studies show how deep learning techniques may be used to overcome the difficulty of identifying sexism and misogyny in natural language writing.</p><p>A strong model for a variety of natural language processing (NLP) tasks, such as text classification <ref type="bibr" coords="3,108.91,273.87,16.09,10.91" target="#b10">[11]</ref>, sentiment analysis <ref type="bibr" coords="3,214.18,273.87,16.08,10.91" target="#b16">[17]</ref>, and language modelling <ref type="bibr" coords="3,342.45,273.87,16.09,10.91" target="#b9">[10]</ref>, is GPT-2 (Generative Pre-trained Transformer 2) <ref type="bibr" coords="3,159.56,287.42,11.53,10.91" target="#b7">[8]</ref>. <ref type="bibr" coords="3,178.11,287.42,18.01,10.91" target="#b17">[18]</ref> used a GPT-2 model that has already been trained to perform binary classification on a dataset of news items, determining whether or not each article had sexist material. The outcomes showed that the GPT-2 model performed better in terms of accuracy than a number of other machine learning models.</p><p>Similar to this, <ref type="bibr" coords="3,168.46,341.62,17.97,10.91" target="#b18">[19]</ref> achieved cutting-edge performance in sentiment analysis tasks using a pre-trained GPT-2 model on a dataset of customer reviews. This research shows the possibility of using pre-trained language models like GPT-2 for diverse natural language processing tasks, even though they did not explicitly focus on sexism categorization. Due to their performance, comparable methods leveraging GPT-2 may also be successful in solving the challenge of classifying sexism <ref type="bibr" coords="3,174.82,409.36,16.41,10.91" target="#b19">[20]</ref>. Notably, Encoder-Decoder models have been the mainstay of prior methods for categorizing sexism in English and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data</head><p>The dataset used in the context of the EXIST 2023 shared task on sexism identification in social networks plays a crucial role in training and evaluating models for automated classification. The dataset is carefully constructed to encompass a wide range of expressions and terms commonly used to undermine the role of women in society, both in English and Spanish. With over 400 expressions included, the dataset aims to capture various forms of sexism, from explicit misogyny to more subtle and implicit sexist behaviours. It covers different dimensions of sexism, such as stereotyping, ideological issues, and sexual violence which is represented as a flow in Figure <ref type="figure" coords="3,120.28,576.38,3.73,10.91" target="#fig_2">3</ref>. Including descriptive or reported assertions further expands the scope of the dataset, allowing for the analysis of tweets where the sexist message is a report or description of sexist behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Sampling and Annotation</head><p>A crawling process was conducted to create the dataset, resulting in the collection of more than 8,000,000 tweets in English and Spanish. The crawling period spanned from September 2021 to September 2022, ensuring a diverse and up-to-date set of tweets. To maintain balance among the seeds, those with fewer than 60 tweets were removed. The dataset is carefully labelled through an annotation process involving crowdsourcing annotators selected through the Prolific app. To mitigate label bias, gender and age parameters are taken into account during the annotation process. Six annotators annotate each tweet, and their diverse views and annotations are captured rather than relying on a single aggregated label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Learning with Disagreements</head><p>The premise that natural language expressions possess a solitary and unequivocal interpretation within a given context is a convenient abstraction, yet it deviates significantly from reality, particularly in subjective tasks such as the identification of sexism. The learning with disagreements approach endeavours to address this predicament by enabling systems to acquire knowledge from datasets where definitive gold annotations are absent but instead encompass information pertaining to annotations from all annotators, encompassing many perspectives. In line with methodologies proposed for training directly from discordant data, as opposed to relying on aggregated labels, we will furnish all annotations per instance across the six distinct strata of annotators. This learning with disagreements paradigm acknowledges the subjective nature of sexism identification and aims to capture the diversity of perspectives. The dataset is partitioned into development, training, and test sets with specific temporal distributions to mitigate temporal bias. The training set consists of 3,660 tweets in Spanish and 3,260 tweets in English, while the development consists of 549 tweets in Spanish and 489 tweets in English, and the test sets consist of 1,098 tweets in Spanish and 978 tweets in English, respectively. Additionally, tweets containing less than five words are removed to ensure the inclusion of meaningful content. The EXIST dataset, with its comprehensive coverage of sexist expressions and behaviours, enables researchers and participants in the EXIST 2023 shared task to develop and evaluate models for sexism identification. Its carefully designed labelling process and inclusion of diverse perspectives contribute to a robust analysis of sexism in social networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Development, Training, and Test Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">System Overview</head><p>The GPT-2 (Generative Pre-trained Transformer 2) model is a highly advanced language model that can be leveraged for sexism classification in the Exist 2023 shared task context. The task consists of three specific subtasks: Task 1 focuses on sexism identification (binary classification), Task 2 involves source intention classification (a multiclass hierarchical classification), and Task 3 deals with sexism categorisation (multiclass hierarchical multi-label classification).</p><p>For Task 1, the GPT-2 model can classify text instances as sexist (YES) or not sexist (NO). The model can learn the patterns and linguistic cues indicative of sexism by fine-tuning the pre-trained GPT-2 model on a dataset specifically annotated for sexism identification. During the fine-tuning process, the model's parameters are adjusted to optimise its performance in distinguishing between YES and NO text. The output of the model for Task 1 will be a binary classification label, indicating whether the text is sexist (YES) or not sexist (NO).</p><p>In Task 2, the GPT-2 model can be utilised to classify the source intention of the sexist text. The classification is hierarchical, with the first level distinguishing between sexist and non-sexist text and the second level categorising the sexist text into three mutually exclusive subcategories: Direct, Reported, and Judgmental. The model can learn the specific linguistic cues associated with each subcategory by training the GPT-2 model on a dataset that includes source intention annotations. The model output for Task 2 will provide the source intention classification label for each text instance.</p><p>Task 3 involves sexism categorisation, a multiclass hierarchical multi-label classification problem. Like Task 2, the GPT-2 model can be fine-tuned on a dataset with annotations for sexism categorisation. The first classification level distinguishes between sexist and nonsexist text. In contrast, the second level includes subcategories such as Ideological-Inequality, Stereotyping-Dominance, Objectification, Sexual-Violence, and Misogyny-Non-Sexual-Violence. As Task 3 allows multiple subcategories to be assigned to a single text instance, the GPT-2 model must generate multi-label predictions. The model output for Task 3 will provide the probabilities or confidence scores for each subcategory, indicating the extent to which the text instance belongs to each category.</p><p>By leveraging the contextual understanding and language modelling capabilities of GPT-2, the model can effectively capture the nuanced linguistic patterns associated with sexism. It can consider the relationships between words, phrases, and sentences to make informed predictions for each task. The GPT-2 model can be optimised through the fine-tuning process to achieve high performance in sexism classification, addressing the specific requirements of Task 1, Task 2, and Task 3 in the Exist 2023 shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Setup</head><p>The first step in the experimental setup for using the GPT-2 model for sexism classification was to fine-tune the pre-trained GPT-2 model on the Exist 2023 dataset. This was done using the PyTorch framework and the Hugging Face Transformers library, which provided access to the pre-trained GPT-2 model.</p><p>During the fine-tuning process, the GPT-2 model was trained for five epochs with a learning rate (LR) of 1e-5, a commonly chosen value for fine-tuning pre-trained language models. The GPT-2 model used in this experiment had a hidden size of 768 and a maximum sequence length of 128 tokens. To adapt the model for the sexism classification task, a classification head with two output classes (sexist and not sexist) was added to the model architecture.</p><p>To train the GPT-2 model on the Exist 2023 dataset, the model was first initialised with the weights from the pre-trained GPT-2 model. Then, the model was trained on the dataset using cross-entropy loss as the objective function and the Adam optimiser. The training was performed with a batch size of 8, meaning that the model processed eight instances simultaneously during each training iteration. It's worth noting that only the weights of the classification head were updated during training, while the weights of the pre-trained model were frozen.</p><p>A regularisation technique called dropout was employed to mitigate the risk of overfitting. Dropout randomly sets a fraction (in this case, 0.1) of the input units to zero during each training step. This helps prevent the model from relying too heavily on specific features and improves its generalisation capability.</p><p>Furthermore, the weighted cross-entropy loss was utilised to handle the imbalanced distribution of classes in the Exist 2023 dataset. This approach assigned higher weights to the minority class (e.g., YES) and lower weights to the majority class (e.g., NO). Doing so encouraged the model to pay more attention to the less frequent class during training, thus addressing the class imbalance issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results &amp; Discussion</head><p>In this section, we present the outcomes of our methodologies applied to Tasks 1, 2, and 3 using the test dataset, as well as the final results provided by the organizers of the Shared Task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Test Result</head><p>The test results demonstrate the effectiveness of our approach, which validates the efficacy of our methodologies in solving the given tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1.">Task 01</head><p>Classification report on Tabel 2 provides a summary of the model's performance for each label in the classification task. For the "NO" label, the model achieved a precision of 0.76, a recall of 0.56, and an f1-score of 0.65. This suggests that the model accurately identified 76% of the instances as "NO," correctly recalling 56% of the actual "NO" instances. On the other hand, for the "YES" label, the precision was 0.62, a recall was 0.81, and the f1-score was 0.7. This indicates that the model accurately classified 62% of the instances as "YES, " correctly recalling 81% of the actual "YES" instances. Overall, the accuracy of the model was reported as 0.68, meaning that it correctly classified 68% of the instances. These results suggest that the model performs reasonably well in distinguishing between "YES" and "NO" classes, but there is room for improvement, particularly in increasing the precision for the "YES" label and the recall for the "NO" label.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2.">Task 02</head><p>The classification report in Table <ref type="table" coords="8,239.21,107.54,5.12,10.91" target="#tab_2">3</ref> provides an evaluation of the model's performance across different labels. For the "NO" label, the model achieved a precision of 0.46, a recall of 0.6, and an f1-score of 0.52. This suggests that the model accurately identified 46% of the instances as "NO" and correctly recalled 60% of the actual "NO" instances. However, for the "DIRECT" label, the precision was 0.4, the recall was 0.33, and f1-score was 0.25, indicating that the model struggled to classify instances as "DIRECT" accurately. The "REPORTED" label had precision, recall, and f1-score values of 0, indicating that the model failed to identify any instances as reported. On the other hand, the model performed well in classifying instances as "JUDGEMENTAL, " achieving a precision of 0.72, recall of 0.85, and an f1-score of 0.78. The overall accuracy of the model was reported as 0.64, meaning that it correctly classified 64% of the instances. These results highlight the model's strengths in identifying "JUDGEMENTAL" instances but its limitations in accurately distinguishing between "DIRECT" and "REPORTED" classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3.">Task 03</head><p>The classification report in Table <ref type="table" coords="8,238.16,430.86,5.08,10.91" target="#tab_3">4</ref> provides an overview of the model's performance for each label in the classification task. The precision, recall and f1-score values indicate how well the model performed for each label. For the "NO" label, the model achieved a precision of 0.71, a recall of 0.72, and an f1-score of 0.71. This suggests that the model accurately identified 71% of the instances as "NO" and correctly recalled 72% of the actual "NO" instances. However, for the other labels such as "IDEOLOGICAL-INEQUALITY," "STEREOTYPING-DOMINANCE, " "OBJECTIFICATION, " "SEXUAL-VIOLENCE, " and "MISOGYNY-NON-SEXUAL-VIOLENCE, " the model's performance was relatively lower. The precision, recall, and f1-score values for these labels indicate that the model struggled to accurately classify instances in these categories, with scores ranging from 0.15 to 0.35 for precision, 0.08 to 0.39 for recall, and 0.11 to 0.37 for f1-score.</p><p>The overall accuracy of the model was reported as 0.51, meaning that it correctly classified 51% of the instances. These results suggest that the model had relatively better performance in identifying instances as "NO" but faced challenges in accurately classifying the other labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Final Result</head><p>This section presents the evaluation methodology and metrics utilized for each task in the EXIST 2023 competition. Three types of evaluations are performed for each task, and the  official metric used across all evaluation contexts is the Information Contrast Measure (ICM).</p><p>Additionally, details about the evaluation package, including the Python script and the contents of the evaluation folder, are provided. Different evaluation metrics are employed for the three tasks in EXIST 2023 based on the classification problems' nature and the hierarchical structure of the categories involved. It also presents a comprehensive analysis of the results obtained from various runs and variants, highlighting the performance based on the ICM-Soft and ICM-Hard scores.</p><p>Task 1: Sexism Identification Task 1 requires binary classification to identify sexism. The evaluation metric for this task is mono-label classification. To determine the ground truth labels, a "hard" setting is adopted, where the majority vote from human annotators is used. In this setting, the class annotated by more than three annotators is selected as the ground truth label. The evaluation is performed in both "hard-hard" and "hard-soft" contexts. The ICM serves as the official metric for Task 1.</p><p>Task 2: Source Intention Task 2 focuses on multiclass hierarchical classification, specifically categorizing the source intention as either sexist or not sexist, with further subcategorization into direct, reported, and judgmental. The evaluation metric for this task considers the severity of confusion between different categories. In the "hard" setting, the class annotated by more than two annotators is chosen as the ground truth label. The evaluation is conducted in all three contexts: "hard-hard, " "hard-soft, " and "soft-soft. " The ICM is the official metric for Task 2.</p><p>Task 3: Sexism Categorization Task 3 involves multiclass hierarchical classification with multi-label assignments, where a tweet may belong to multiple subcategories simultaneously. Similar to Task 2, the evaluation metric for this task considers the hierarchical structure and the possibility of multiple labels. The ground truth labels are determined using a "hard" setting, selecting the labels assigned by more than one annotator. The evaluation is performed in all three contexts: "hard-hard," "hard-soft," and "soft-soft." The official metric for Task 3 is the ICM, which is extended to ICM-soft to accommodate soft system outputs and ground truth assignments.</p><p>Evaluation Variants for Each Task The evaluation is conducted in three different modes for each task: "hard-hard," "hard-soft," and "soft-soft." In the "hard-hard" evaluation, systems that provide a conventional hard output are evaluated using hard ground truth labels. The official metric used to measure the system's performance is the ICM. Additionally, F1 scores are calculated and reported for comparison purposes, considering task-specific considerations.</p><p>For systems that provide a hard output, the "hard-soft" evaluation is performed. In this variant, the categories assigned by the system are compared with the probabilities assigned to each category in the ground truth. The official evaluation metric used in this context is the ICM-soft. Probabilities for each class are calculated based on the distribution of labels and the number of annotators for each instance.</p><p>The "soft-soft" evaluation is conducted for systems that provide probabilities for each category. In this context, the system's probabilities are compared with the probabilities assigned by the human annotators. Similar to the "hard-soft" evaluation, the ICM-soft metric is used. Additional metrics may be reported in the final evaluation report.</p><p>The use of ICM and ICM-soft metrics in the evaluation process ensures the consideration of the hierarchical structure of categories and the possibility of multiple labels, providing a superior analytical evaluation framework compared to alternatives in the current state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">Task 01</head><p>In Task 01, Table <ref type="table" coords="11,165.76,476.69,5.00,10.91">5</ref> represents the results obtained from different runs and variants of a submission, comparing them based on the ICM-Soft and ICM-Hard scores. In the Soft-Soft (All) variant, the gold data achieved a score of 3.1182 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. However, the CNLP-NITS-PP submission obtained a score of -0.4237 for ICM-Soft Norm, ranking at 36. Shifting to the Hard-Hard (All) variant, the gold data did not provide a score for ICM-Soft, but it achieved a score of 0.9948 for ICM-Hard. On the other hand, the CNLP-NITS-PP submission obtained a score of 0.1093 for ICM-Hard Norm, ranking at 56. Regarding the Hard-Soft (All) variant, the gold data achieved the same scores as the Soft-Soft (All) variant, while the CNLP-NITS-PP submission obtained a score of -0.9509 for ICM-Soft Norm, ranking at 57.</p><p>Moving on to the Soft-Soft (ES) variant, the gold data achieved a score of 3.1177 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. However, the CNLP-NITS-PP submission obtained a score of -0.7839 for ICM-Soft Norm, ranking at 43. For the Hard-Hard (ES) variant, the gold data did not provide a score for ICM-Soft, but it achieved a score of 0.9999 for ICM-Hard. Conversely, the CNLP-NITS-PP submission obtained a score of -0.0382 for ICM-Hard Norm, ranking at 58.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,239.36,107.09,8.93;4,89.29,84.19,416.69,130.65"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dataset Classes</figDesc><graphic coords="4,89.29,84.19,416.69,130.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,89.29,651.41,177.37,8.93;7,155.91,366.46,283.48,272.38"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Task 01 Testing confusion Matrix</figDesc><graphic coords="7,155.91,366.46,283.48,272.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,89.29,344.12,147.82,8.93;9,155.91,84.19,283.47,247.36"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Task 02 Confusion Matrix</figDesc><graphic coords="9,155.91,84.19,283.47,247.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,89.29,521.95,147.82,8.93;10,89.29,84.19,425.20,425.20"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Task 03 Confusion Matrix</figDesc><graphic coords="10,89.29,84.19,425.20,425.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,581.79,272.25,81.83"><head>Table 1</head><label>1</label><figDesc>Dataset Split Statistics</figDesc><table coords="4,234.03,613.41,127.21,50.21"><row><cell></cell><cell cols="2">Dev Train Test</cell></row><row><cell cols="2">Spanish 549</cell><cell>3660 1098</cell></row><row><cell>English</cell><cell>489</cell><cell>3260 978</cell></row><row><cell>Total</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,269.08,290.50,73.23"><head>Table 2</head><label>2</label><figDesc>Task 01 Testing Classification Report</figDesc><table coords="7,215.79,296.73,163.71,45.59"><row><cell cols="4">Label precision recall f1-score</cell></row><row><cell>NO</cell><cell>0.76</cell><cell>0.56</cell><cell>0.65</cell></row><row><cell>YES</cell><cell>0.62</cell><cell>0.81</cell><cell>0.70</cell></row><row><cell></cell><cell>accuracy</cell><cell></cell><cell>0.68</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.99,284.11,311.82,97.14"><head>Table 3</head><label>3</label><figDesc>Task 02 Testing Classification Report</figDesc><table coords="8,194.47,311.75,206.34,69.50"><row><cell>Label</cell><cell cols="3">precision recall f1-score</cell></row><row><cell>NO</cell><cell>0.46</cell><cell>0.60</cell><cell>0.52</cell></row><row><cell>DIRECT</cell><cell>0.40</cell><cell>0.33</cell><cell>0.25</cell></row><row><cell>REPORTED</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>JUDGEMENTAL</cell><cell>0.72</cell><cell>0.85</cell><cell>0.78</cell></row><row><cell cols="2">accuracy</cell><cell></cell><cell>0.64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.99,377.27,358.71,121.04"><head>Table 4</head><label>4</label><figDesc>Task 03 Testing Classification Report</figDesc><table coords="9,147.57,404.91,300.13,93.40"><row><cell>Label</cell><cell cols="3">precision recall f1-score</cell></row><row><cell>NO</cell><cell>0.71</cell><cell>0.72</cell><cell>0.71</cell></row><row><cell>IDEOLOGICAL-INEQUALITY</cell><cell>0.35</cell><cell>0.39</cell><cell>0.37</cell></row><row><cell>STEREOTYPING-DOMINANCE</cell><cell>0.23</cell><cell>0.29</cell><cell>0.26</cell></row><row><cell>OBJECTIFICATION</cell><cell>0.23</cell><cell>0.18</cell><cell>0.20</cell></row><row><cell>SEXUAL-VIOLENCE</cell><cell>0.23</cell><cell>0.23</cell><cell>0.23</cell></row><row><cell>MISOGYNY-NON-SEXUAL-VIOLENCE</cell><cell>0.15</cell><cell>0.08</cell><cell>0.11</cell></row><row><cell>accuracy</cell><cell></cell><cell></cell><cell>0.51</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to express our gratitude to the <rs type="institution">National Institute of Technology Silchar</rs> for allowing us to conduct our research and experimentation. We are thankful for the resources and research atmosphere provided by the <rs type="institution">CNLP &amp; AI Lab, NIT Silchar</rs>.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the case of the Hard-Soft (ES) variant, the gold data achieved the same scores as the Soft-Soft (ES) variant, while the CNLP-NITS-PP submission had a score of -1.1877 for ICM-Soft Norm, ranking at 59. Now considering the Soft-Soft (EN) variant, the gold data achieved a score of 3.1141 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. Unfortunately, the scores for the CNLP-NITS-PP submission are not available for this variant. For the Hard-Hard (EN) variant, the gold data did not provide a score for ICM-Soft, but it achieved a score of 0.9798 for ICM-Hard. Conversely, the CNLP-NITS-PP submission obtained a score of 0.2508 for ICM-Hard Norm, ranking at 53. Lastly, for the Hard-Soft (EN) variant, the gold data achieved the same scores as the Soft-Soft (EN) variant, while the CNLP-NITS-PP submission had a score of -0.7779 for ICM-Soft Norm, ranking at 54. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.">Task 02</head><p>For Task 02, Table <ref type="table" coords="12,174.94,547.64,5.17,10.91">6</ref> In terms of the Soft-Soft (All) variant, the gold data achieved a score of 6.2057 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. The CNLP-NITS-PP submission scores are not provided for this variant. Moving on to the Hard-Hard (All) variant, the gold data scored 1.5378 for ICM-Hard, while the CNLP-NITS-PP submission obtained a score of -0.3601 for ICM-Hard Norm, ranking at 24. For the Hard-Soft (All) variant, the gold data achieved the same scores as the Soft-Soft (All) variant, whereas the CNLP-NITS-PP submission obtained a negative score of -7.2467 for ICM-Hard and ICM-Hard Norm, ranking at 20.</p><p>Next, looking at the Soft-Soft (ES) variant results, the gold data achieved a score of 6.2431 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. However, the CNLP-NITS-PP submission scores are not available for this variant. For the Hard-Hard (ES) variant, the gold data scored 1.6007 for ICM-Hard, while the CNLP-NITS-PP submission obtained a score of -0.5075 for ICM-Hard Norm, ranking at 24. In the case of the Hard-Soft (ES) variant, the gold data achieved the same scores as the Soft-Soft (ES) variant, but the CNLP-NITS-PP submission had a score of -7.0396 for ICM-Hard, ranking at 23.</p><p>Moving on to the Soft-Soft (EN) variant, the gold data obtained a score of 6.1178 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. The CNLP-NITS-PP submission scores are not provided for this variant. For the Hard-Hard (EN) variant, the gold data scored 1.4449 for ICM-Hard, while the CNLP-NITS-PP submission obtained a score of -0.1945 for ICM-Hard Norm, ranking at 23. Lastly, for the Hard-Soft (EN) variant, the gold data achieved the same scores as the Soft-Soft (EN) variant, whereas the CNLP-NITS-PP submission had a score of -7.9564 for ICM-Hard, ranking at 13. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.">Task 03</head><p>In task 03, Table <ref type="table" coords="13,167.48,547.64,5.17,10.91">7</ref> presents the results from different runs and variants of a submission. In terms of the Soft-Soft (All) variant, the gold data achieved an impressive score of 9.4686 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. However, the scores for the CNLP-NITS-PP submission are not available for this variant. Shifting to the Hard-Hard (All) variant, the gold data did not provide a score for ICM-Soft, but it scored 2.1533 for ICM-Hard. On the other hand, the CNLP-NITS-PP submission obtained a score of -0.8412 for ICM-Hard Norm, ranking at 20. Regarding the Hard-Soft (All) variant, the gold data achieved the same scores as the Soft-Soft (All) variant, while the CNLP-NITS-PP submission obtained a score of -11.3206 for ICM-Hard, ranking at 8. Moving on to the Soft-Soft (ES) variant, the gold data achieved a score of 9.6071 for ICM-Soft and a perfect score of 1 for ICM-Soft Norm. However, the CNLP-NITS-PP submission scores are not provided for this variant. For the Hard-Hard (ES) variant, the gold data did not provide a score for ICM-Soft, but it obtained a score of 2.2393 for ICM-Hard. On the other hand, the CNLP-NITS-PP submission obtained a score of -1.115 for ICM-Hard Norm, ranking at 23. In the case of the Hard-Soft (ES) variant, the gold data achieved the same scores as the Soft-Soft (ES) variant, but the CNLP-NITS-PP submission had a score of -10.9613 for both ICM-Hard and ICM-Hard Norm, ranking at 11. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Sexism is a pervasive issue that continues to affect individuals and society as a whole. The EXIST 2023 shared task has provided a valuable platform for advancing the understanding and detection of sexism in social networks. Significant progress has been made in identifying and combating sexism online through the application of automated methods, such as the Generative Pre-trained Transformer 2 (GPT-2) language model. GPT-2's ability to capture semantic and contextual information from text has proven to be a powerful tool in classifying sexist content. However, the results and discussions from the tasks indicate that there is still room for improvement in the accuracy and precision of the models.</p><p>The EXIST 2023 shared task results indicate that the models' performance varied across different tasks and labels. In Task 1, the models showed promising performance in distinguishing between sexist and non-sexist content, but further improvements are needed to enhance precision and recall for both categories. In Task 2, the models struggled with accurately classifying instances into the "DIRECT" and "REPORTED" labels, indicating the need for more refined approaches to handle these categories effectively. Similarly, in Task 3, the models faced challenges in categorizing instances into specific subcategories of sexism, such as ideological inequality, stereotyping dominance, objectification, sexual violence, misogyny and non-sexual violence. These findings highlight the complexity and nuances of detecting and categorizing sexism in social networks.</p><p>Future work should focus on refining and developing models that can address the specific challenges identified in the shared task. Improving the accuracy and precision of the models in distinguishing between different forms of sexism will be crucial in advancing the field. Additionally, efforts should be made to expand the datasets and incorporate more diverse examples to improve the models' generalization capabilities. Collaboration between researchers, experts, and practitioners will be essential in advancing the field and developing more effective automated systems for combating sexism in social networks. Ultimately, the EXIST 2023 shared task has provided valuable insights and a foundation for further research, bringing us closer to addressing the pervasive issue of sexism in online platforms and promoting a more inclusive and equal society.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="15,112.66,407.46,393.33,10.91;15,112.39,421.01,273.29,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,298.34,407.46,207.65,10.91;15,112.39,421.01,138.21,10.91">Debating stereotypes: Online reactions to the vice-presidential debate of 2020</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Felmlee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Julien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Francisco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,259.06,421.01,38.72,10.91">PloS one</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">280828</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,434.55,393.33,10.91;15,112.66,448.10,249.15,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="15,338.85,434.55,167.14,10.91;15,112.66,448.10,35.44,10.91">Ideological bias in social psychological research</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jussim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Anglin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,156.46,448.10,134.29,10.91">Social psychology and politics</title>
		<imprint>
			<biblScope unit="page" from="107" to="126" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,461.65,393.32,10.91;15,112.66,475.20,340.05,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,208.84,461.65,297.14,10.91;15,112.66,475.20,125.67,10.91">Restorative justice for survivors of sexual violence experienced in adulthood: A scoping review</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sinko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,246.81,475.20,121.96,10.91">Trauma, Violence, &amp; Abuse</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="340" to="354" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,488.75,394.53,10.91;15,112.66,502.30,395.17,10.91;15,112.66,515.85,394.53,10.91;15,112.66,529.40,327.59,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,112.66,502.30,276.78,10.91">Overview of exist 2023: sexism identification in social networks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,412.60,502.30,95.23,10.91;15,112.66,515.85,353.49,10.91">Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">April 2-6, 2023. 2023</date>
			<biblScope unit="page" from="593" to="599" />
		</imprint>
	</monogr>
	<note>Part III</note>
</biblStruct>

<biblStruct coords="15,112.66,542.95,393.71,10.91;15,112.66,556.50,393.98,10.91;15,112.41,570.05,32.84,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,288.03,542.95,218.34,10.91;15,112.66,556.50,121.07,10.91">Blockchain technology and gender equality: A systematic literature review</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Di</forename><surname>Vaio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Palladino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,242.21,556.50,222.07,10.91">International Journal of Information Management</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">102517</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,583.60,393.32,10.91;15,112.66,597.15,275.11,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,229.54,583.60,276.44,10.91;15,112.66,597.15,121.51,10.91">A systematic review of hate speech automatic detection using natural language processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Jahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oussalah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,246.83,597.15,75.85,10.91">Neurocomputing</title>
		<imprint>
			<biblScope unit="page">126232</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,610.69,393.32,10.91;15,112.66,624.24,395.01,10.91;15,112.66,637.79,179.18,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="15,356.76,610.69,149.22,10.91;15,112.66,624.24,230.04,10.91">Automatic classification of sexism in social networks: An empirical study on twitter data</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3042604</idno>
	</analytic>
	<monogr>
		<title level="j" coord="15,349.72,624.24,52.66,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="219563" to="219576" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,651.34,393.33,10.91;15,112.66,664.89,253.81,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="15,412.10,651.34,93.89,10.91;15,112.66,664.89,141.16,10.91">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,262.00,664.89,56.95,10.91">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,86.97,266.76,10.91" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Gpt-4 technical report</note>
</biblStruct>

<biblStruct coords="16,112.66,100.52,393.33,10.91;16,112.66,114.06,393.33,10.91;16,112.66,127.61,107.17,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="16,243.76,100.52,262.23,10.91;16,112.66,114.06,309.36,10.91">Hello, it&apos;s gpt-2-how can i help you? towards the use of pretrained language models for task-oriented dialogue systems</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05774</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,112.66,141.16,394.53,10.91;16,112.66,154.71,393.33,10.91;16,112.66,168.26,354.61,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="16,177.53,154.71,240.50,10.91">Do not have enough data? deep learning to the rescue!</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Anaby-Tavor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carmeli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Goldbraich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shlomov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tepper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zwerdling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,440.71,154.71,65.28,10.91;16,112.66,168.26,205.99,10.91">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7383" to="7390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,181.81,395.17,10.91;16,112.66,195.36,393.33,10.91;16,112.66,208.91,134.02,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="16,275.62,181.81,232.21,10.91;16,112.66,195.36,122.81,10.91">Automatic identification and classification of misogynistic language on twitter</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Anzovino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,263.72,195.36,242.26,10.91;16,112.66,208.91,104.07,10.91">International Conference on Applications of Natural Language to Data Bases</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,222.46,394.62,10.91;16,112.28,236.01,394.36,10.91;16,112.41,249.56,48.96,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="16,343.09,222.46,164.18,10.91;16,112.28,236.01,259.50,10.91">Online hate speech against women: Automatic identification of misogyny and sexism on twitter</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Frenda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,379.65,236.01,85.27,10.91">J. Intell. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4743" to="4752" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,263.11,393.32,10.91;16,112.26,276.66,180.56,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="16,226.02,263.11,279.96,10.91;16,112.26,276.66,43.71,10.91">Automatic detection of sexist statements commonly used at the workplace</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Céspedes</surname></persName>
		</author>
		<idno>ArXiv abs/2007.04181</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,290.20,393.33,10.91;16,112.66,303.75,120.75,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m" coord="16,259.76,290.20,246.22,10.91;16,112.66,303.75,56.17,10.91">Neural machine translation by jointly learning to align and translate</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,317.30,394.61,10.91;16,112.66,330.85,393.33,10.91;16,112.33,344.40,395.33,10.91;16,112.66,357.95,314.57,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="16,283.23,317.30,204.21,10.91">GloVe: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
		<ptr target="https://aclanthology.org/D14-1162.doi:10.3115/v1/D14-1162" />
	</analytic>
	<monogr>
		<title level="m" coord="16,112.66,330.85,393.33,10.91;16,112.33,344.40,236.37,10.91">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,371.50,393.33,10.91;16,112.66,385.05,346.20,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="16,407.58,371.50,98.41,10.91;16,112.66,385.05,221.12,10.91">A survey on sentiment analysis and opinion mining in greek social media</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Alexandridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Varlamis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korovesis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Caridakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tsantilas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,342.61,385.05,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">331</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,398.60,394.53,10.91;16,112.30,412.15,393.68,10.91;16,112.66,425.70,107.17,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<title level="m" coord="16,189.92,412.15,238.75,10.91">Opt: Open pre-trained transformer language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,112.66,439.25,393.33,10.91;16,112.66,452.79,393.33,10.91;16,112.66,466.34,314.71,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="16,209.48,439.25,296.51,10.91;16,112.66,452.79,143.39,10.91">A review of natural language processing techniques for sentiment analysis using pre-trained models</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bindu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,300.20,452.79,205.79,10.91;16,112.66,466.34,199.50,10.91">Fourth International Conference on Computing Methodologies and Communication (ICCMC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,479.89,394.52,10.91;16,112.66,493.44,87.86,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="16,192.25,479.89,309.97,10.91">Detecting and classifying sexism by ensembling transformers models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaca-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,112.66,493.44,40.34,10.91">language</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
