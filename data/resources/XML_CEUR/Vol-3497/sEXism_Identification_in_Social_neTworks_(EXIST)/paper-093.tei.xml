<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,394.96,15.42;1,89.29,106.66,259.62,15.42;1,89.29,129.00,229.56,11.96">Integrating Annotator Information in Transformer Fine-tuning for Sexism Detection SINAI participation at EXIST Lab in CLEF 2023</title>
				<funder ref="#_vEZ87sC">
					<orgName type="full">FEDER</orgName>
				</funder>
				<funder ref="#_6DsVsxV">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministry of Consumer Affairs of the Spanish Government</orgName>
				</funder>
				<funder ref="#_qd9wE7V">
					<orgName type="full">Andalusian Regional Government</orgName>
				</funder>
				<funder ref="#_Un3DzGw #_D2YxC7s">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_ntU8mm9">
					<orgName type="full">Plan Nacional I+D+i</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,169.81,11.96"><forename type="first">María</forename><surname>Estrella Vallecillo-Rodríguez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">SINAI</orgName>
								<orgName type="department" key="dep3">CEATIC</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
								<address>
									<postCode>23071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.75,154.90,133.17,11.96"><forename type="first">Flor</forename><forename type="middle">Miriam</forename><surname>Plaza-Del-Arco</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Bocconi University</orgName>
								<address>
									<addrLine>Via Sarfatti, 25</addrLine>
									<postCode>20100</postCode>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,168.85,125.82,11.96"><forename type="first">Luis</forename><surname>Alfonso Ureña-López</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">SINAI</orgName>
								<orgName type="department" key="dep3">CEATIC</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
								<address>
									<postCode>23071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.72,168.85,140.76,11.96"><forename type="first">María</forename><forename type="middle">Teresa</forename><surname>Martín-Valdivia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">SINAI</orgName>
								<orgName type="department" key="dep3">CEATIC</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
								<address>
									<postCode>23071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,399.22,168.85,102.71,11.96"><forename type="first">Arturo</forename><surname>Montejo-Ráez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">SINAI</orgName>
								<orgName type="department" key="dep3">CEATIC</orgName>
								<orgName type="institution">Universidad de Jaén</orgName>
								<address>
									<postCode>23071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.10,627.15,55.36,8.97"><forename type="first">M</forename><forename type="middle">E</forename><surname>Vallecillo</surname></persName>
						</author>
						<author>
							<persName coords="1,170.96,638.11,62.73,8.97"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,394.96,15.42;1,89.29,106.66,259.62,15.42;1,89.29,129.00,229.56,11.96">Integrating Annotator Information in Transformer Fine-tuning for Sexism Detection SINAI participation at EXIST Lab in CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">EF9D5A704073CB668B38A56F44A91EB3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sexism detection</term>
					<term>Text classification</term>
					<term>Transformers</term>
					<term>Natural language processing</term>
					<term>Social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of SINAI research team in the sEXism Identification in Social neTworks (EXIST) Shared Task at CLEF 2023. Specifically, we participated in Task 1 (sexism identification), Task 2 (sexism intention), and Task 3 (sexism categorization). For the three tasks, we propose three different systems, one based on a fine-tuning of a transformer pretrained model with hard labels, another exploring a data augmentation strategy, and the third system that integrates socio-demographic annotators features in order to check if this information helps in detecting sexism content. In EXIST shared task, the organizers propose three evaluation methods, Hard-Hard evaluation where they compare the hard label from the output of the system with the hard label of the ground truth, Hard-Soft evaluation which consists in evaluate the hard label from the output of the system with the soft labels of the ground truth and Soft-Soft where they compare the soft labels of the system with soft labels of the ground truth. Our team ranked 1 st in Task 1 for Soft-Soft evaluation method, 8 th in Task 2 for Soft-Soft evaluation, and 7 th in Task 3 with Hard-Hard evaluation among the participants, achieving 0.903, -2.29, and 0.1472 of the ICM metric, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>According to The Oxford Dictionary, sexism is the "prejudice, stereotyping, or discrimination, typically against women, on the basis of sex" <ref type="bibr" coords="1,285.77,494.75,11.28,10.91" target="#b0">[1]</ref>. In our daily lives, sexism manifests itself when people undervalue the views expressed by women, whether in spoken or written conversations containing fixed sayings and expressions. Today, with the prevalence of social media, sexist comments have become alarmingly prevalent, spreading rapidly and driving more instances of sexism. Moreover, identifying these comments can be challenging due to the various ways in which they can be expressed. To address these challenges, the scientific community has established numerous academic events and shared tasks. These initiatives aim to address specific issues related to the detection and classification of sexism. For example, EVALITA <ref type="bibr" coords="2,451.87,127.61,12.74,10.91" target="#b1">[2]</ref> and AMI <ref type="bibr" coords="2,89.29,141.16,12.72,10.91" target="#b2">[3]</ref> focus on the identification of misogyny, while HateEval <ref type="bibr" coords="2,351.26,141.16,12.71,10.91" target="#b3">[4]</ref> focuses on the detection of hate speech directed against women and immigrants. In addition, shared tasks such as EDOS <ref type="bibr" coords="2,492.99,154.71,13.00,10.91" target="#b4">[5]</ref> aim to develop more accurate and explainable systems for sexism detection, and EXIST <ref type="bibr" coords="2,482.84,168.26,11.42,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,496.99,168.26,9.00,10.91" target="#b6">7]</ref> attempts to classify sexism according to the different facets of women that are affected. The efforts of increasing the scope of sexism detection, contribute to a more complete understanding of the different types of sexism and how they are expressed.</p><p>This paper describes the participation of SINAI in sEXism Identification in Social neTworks (EXIST) shared task <ref type="bibr" coords="2,181.91,236.01,11.49,10.91" target="#b7">[8,</ref><ref type="bibr" coords="2,196.28,236.01,9.03,10.91" target="#b8">9]</ref> at CLEF 2023. This task aimed to capture sexism in a broad sense, from explicit misogyny to other subtle expressions that involve implicit sexist behaviors. The main purpose of this task is to contribute to developing applications that can detect sexism. For this purpose, the organizers propose three different tasks. Task 1: Sexism Identification is related to identifying if a comment is sexist or not. Once a comment is classified as sexist, Task 2: Source Intention consists of classifying the intention of the author with this sexist comment, and Task 3: Sexism Categorization, when a comment is classified as sexist, to try to detect which facets of women are attacked with this comment. An important proposal of the task is "The learning with disagreement paradigm" where the organizers propose to build systems that are able to consider the different perspectives that people have when identifying sexism. For this reason, task organizers propose three evaluation methods (Hard-Hard, Hard-Soft, and Soft-Soft) that are explained in Section 4.2 Our team SINAI has participated in the three tasks.</p><p>Our proposal for addressing EXIST task is the integration of the different features of the annotators in systems that detect sexism to gather the diversity of subjective views in sexism detection. We expect to obtain a more accurate prediction for this specific task. There are some previous works that try to integrate external knowledge into systems to obtain better results. For example, in misogyny detection task, Frenda et al. <ref type="bibr" coords="2,336.18,452.79,17.91,10.91" target="#b9">[10]</ref> introduces an approach based on aesthetic features captured by character n-grams, sentiment information, and a set of lexicons built by analyzing misogynistic tweets. Nevertheless, misogyny detection is not the only task where researchers try to integrate extra information. In hate speech detection there are some proposals that use a multi-task learning paradigm to combine different phenomena that are inextricably related to the expression of offensive language such as sentiments, emotions, target, irony, sarcasm, and constructiveness, among others <ref type="bibr" coords="2,316.34,534.09,16.31,10.91" target="#b10">[11,</ref><ref type="bibr" coords="2,335.32,534.09,12.50,10.91" target="#b11">12,</ref><ref type="bibr" coords="2,350.48,534.09,12.23,10.91" target="#b12">13]</ref>. They show that the integration of these features helps the detection of hate speech. Finally, Pérez et al. <ref type="bibr" coords="2,423.25,547.64,17.91,10.91" target="#b13">[14]</ref> evaluated the impact of incorporating contextual information in hate speech related to the news posted on social media. This study shows evidence that adding contextual information improves hate speech detection performance for systems that perform binary and multi-label prediction tasks.</p><p>The rest of the paper is structured as follows: In Section 2 we describe the different strategies used to develop the systems for the shared task. The used data and the methodology followed to achieve the goal of the task are described in Section 3. The results obtained in our experiments during the development phase and the evaluation phase are shown in Section 4. Finally, we conclude with a discussion in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Overview</head><p>Sexism identification has been approached as a text classification task. We propose two different architectures, namely base architecture (BA) and integrating annotator's information (IAI). The integrating annotator's information solution takes into account information related to the annotators of the texts with the aim of allowing the system to consider the different perspectives of the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Base Architecture</head><p>The basic architecture is a Transformers architecture <ref type="bibr" coords="3,322.08,215.20,17.76,10.91" target="#b14">[15]</ref> for text classification. In this architecture, we have texts that are tokenized and then passed to the model. The model preprocesses the input and generates an output. To perform text classification, we get the classification token from the last hidden state of the model. This token is intended to encode the whole input sequence. This token is then passed as input to a feed-forward network, that classifies the text and produces the result of this classification in the number of classes that each specific task demands. This architecture is followed for two proposed experiments called Baseline and Baseline with Data Augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Data Tokenizer</head><p>[CLS] t0 t1 ...  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Integrating Annotator's Information</head><p>This design is a multimodal architecture called Transformer With Tabular <ref type="bibr" coords="3,425.92,507.54,18.07,10.91" target="#b15">[16]</ref> that received a DataFrame as input. The DataFrame is preprocessed, extracting the columns that represent the text to classify, categorical information and numerical information. Later, text features are tokenized, the categorical features are encoded and the numerical features are transformed to an adequate format. Then, text features are passed to a Transformer model. The Transformers model output is passed to a combining module that incorporates the numerical and categorical features to generate a unique tensor that is passed to a classifier, so final predictions are generated.</p><p>In our case, we do not have numerical features, so they are not represented in Figure <ref type="figure" coords="3,468.33,602.39,3.73,10.91" target="#fig_3">2</ref>, which shows this architecture. The experiment called Integrating Annotators' Information implements this architecture. The combining module of the architecture represents the strategy to combine the different features. In this case, we have explored the following methods:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data</head><p>To run our experiments, we use the dataset provided by the organizers. The dataset is composed of comments extracted from Twitter that can contain sexist popular expressions and terms both in English and Spanish. This dataset is labeled by a total of 6 individuals with different socio-demographic characteristics, such as gender (male or female) and age <ref type="bibr" coords="4,476.97,506.99,30.22,10.91;4,89.29,520.54,62.02,10.91">(18-22, 23-45, or +46)</ref>. Moreover, in this dataset, the organizers, instead of providing a gold label for each text, give the participants the label assigned by each annotator and their personal information such as the gender and age for all tasks. The objective of the organizers with this information is to gather the diversity of views in a subjective task like sexism detection. A set of 10,034 tweets are annotated as sexist or not sexist and sexist posts are designated with more specific labels related to the intention of the author of the tweet and the category of the sexism. Table <ref type="table" coords="4,153.31,601.84,5.17,10.91" target="#tab_0">1</ref> shows the dataset size in each split. For task 1 we have to classify if a text is sexist or not (YES, NO). For task 2 we have to classify the intention of the author for sexist comments (NO, DIRECT, REPORTED, JUDGEMENTAL). For task 3, we have to detect which facets of women are more attached. As we can see in this task we can select one or more labels </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(NO, IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINANCE, OBJECTIFICATION, SEXUAL-VIOLENCE, MISOGYNY-NON-SEXUAL-VIOLENCE).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data Preprocessing and Data Augmentation</head><p>Due to the fact that the texts of the dataset are from Twitter, the language of these comments is an informal language, which contains hashtags, mentions, emojis, and URLs that enter noise into the models. In order to reduce noise and the variability of the data, we perform data preprocessing. This preprocess in the text will help to identify patterns in texts in an easier way. To preprocess the texts, we apply the following steps:</p><p>• Remove # in hashtags.</p><p>• Replace user's mentions by the string "user".</p><p>• Replace the URLs by the string "url".</p><p>In addition, the systems we developed that use an architecture incorporating annotator's information (Section 2.2) require data that includes the annotator's features. To fulfill this requirement, we replicated each text six times, assigning different annotator features (age and gender) to each replicated instance, along with the label assigned by the annotator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experiments and Selected Models</head><p>To achieve the goal of EXIST shared task, we propose three experiments for each task. Each experiment has a different configuration and different models are selected to run the experiments. The proposed experiments are the following:</p><p>• Baseline. This experiment employs the base architecture explained in Section 2.1. To conduct our experiments we selected four multilingual models due to the multilingual nature of the EXIST dataset (tweets are in English and Spanish). The selected models are mDeBERTa <ref type="bibr" coords="5,185.81,520.00,17.79,10.91" target="#b16">[17]</ref> in both base <ref type="bibr" coords="5,262.43,520.00,17.79,10.91" target="#b17">[18]</ref> and large <ref type="bibr" coords="5,326.47,520.00,17.79,10.91" target="#b18">[19]</ref> versions, and XLM-RoBERTa <ref type="bibr" coords="5,476.74,520.00,17.79,10.91" target="#b19">[20]</ref> in both base <ref type="bibr" coords="5,162.36,533.54,18.02,10.91" target="#b20">[21]</ref> and large <ref type="bibr" coords="5,227.76,533.54,18.02,10.91" target="#b21">[22]</ref> versions. This experiment consists of a fine-tuning of the selected models. • Baseline with Data Augmentation. This experiment uses the base architecture explained in Section 2.1. To run this experiment, we perform Data Augmentation. This experiment consisted of a fine-tuning of the mDeBERTa base model with an augmented version of the data, where each text was repeated six times and associated with the label of each annotator. • Integrating Annotators' Information. In this experiment, we utilize the integrating annotator's information (Section 2.2). This experiment consists of testing which combination method to integrate information related to the annotators performs the best. The selected model for this experiment was a mDeBERTa base model.</p><p>As can be seen, for baseline with data augmentation and integrating the annotator's information experiment, we use mDeBERTa base model. The reason to select this model is that we think that the mDeBERTa base model has fewer parameters and is more efficient in comparison with the other selected models. The choice of such pre-trained models is due to the multilingual nature of the tasks, as the task are proposed for two different languages, English and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training Approach and Hyper-Parameters Search</head><p>During the competition, we established two phases. In the first phase, the development one, we train our model with the train set and evaluate it with the development set. In the second phase, the evaluation one, we train our models with the train and development sets for the final models that will be used for predicting over the test set. More details are given in the next sections.</p><p>Hyper-parameter optimization: Hyper-parameter optimization is an important step during the training of a model, due to the fact that the models have a big amount of hyperparameters that should be optimized to adjust the model to a specific task. All of our experiments implement hyper-parameter optimization. For the hyper-parameter optimization, we use Optuna <ref type="bibr" coords="6,89.29,312.83,16.32,10.91" target="#b22">[23]</ref>, an automatic hyper-parameter optimization software framework. Specifically, we opted for a random search method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Search space used to optimize hyper-parameters for the selected models in tasks 1, 2, and 3 of the EXIST 2023 shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameter Search Space</head><p>Learning-rate (2e-5, 2e-7) Weight-decay (0.01, 4e-5) Batch-size <ref type="bibr" coords="6,312.30,447.59,10.42,8.87" target="#b7">[8,</ref><ref type="bibr" coords="6,325.21,447.59,11.46,8.87" target="#b15">16,</ref><ref type="bibr" coords="6,339.16,447.59,12.86,8.87">32]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this section, we present the results obtained by the system developed as part of our participation in EXIST 2023. The experiments are conducted in two phases, the development phase, where we select the best models, and the evaluation phase where we evaluate the selected models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Development Phase</head><p>In this phase, we train the models with the train and the development splits of the dataset. Then, we select the best model for each task. To evaluate our systems we use macro-F1, which is the harmonic average of precision and recall averaged over different classes. For each task of EXIST, we propose three strategies explained in Section 3.3. The results obtained in the development phase are shown in Tables 3, 4, 5, and 6. Table <ref type="table" coords="7,127.53,114.06,5.17,10.91" target="#tab_1">3</ref> shows the results obtained by the developed baseline systems for all tasks. As can be seen, the large version of all models improves the base version due to the fact that they are more complex models and can capture more information. If we observe the results for each task, we can see that for Task 1, mDeBERTa Large achieves the best result in macro-F1 score with 0.8618 followed by XLMRoBERTa Large with a macro-F1 of 0.8606. The mDeBERTa and XMLRoBERTa base models showed good results with 0.8519 and 0.8558 macro-F1 scores respectively. In task 2, mDeBERTa Large outperforms the rest of the models (0.6113). It was followed by the mDeBERTa Large model with a macro-F1 of 0.6092. The mDeBERTa Base and XLMRoBERTa Base models obtained slightly lower results with macro-F1 of 0.5736 and 0.5577 respectively. Finally, for task 3, XLMRoBERTa Large obtained the best result in macro-F1 score in task 3 with a score of 0.37, the rest of the models had lower results (0.37 to 0.3483). Once base models were set (in terms of pre-trained model selected and best performing hyperparametrization), we proceeded with the rest of our experiments. In Table <ref type="table" coords="7,447.67,425.70,3.74,10.91" target="#tab_2">4</ref>, we can see the results obtained in the systems that integrate the information from the annotators, either by adding only the labels assigned by the annotators (Experiment baseline with data augmentation) or with the socio-demographic information provided and the labels (Experiment integrating annotators' information). For this task, we can observe that the evaluated strategies achieve relatively close macro-F1 scores with a range from 0.7534 to 0.7567. The weighted strategy achieved the best result in macro-F1 (0.7567).</p><p>The results of the different proposed experiments for task 2 are presented in Table <ref type="table" coords="7,467.06,520.54,3.72,10.91" target="#tab_3">5</ref>. In this Table , we can see the result of the experiments that include annotator information (Baseline with Data Augmentation and Integrating Annotators' Information). Due to the unbalanced classes in the dataset, we propose two experiments: one without class weight in the computation of the loss during neural network training, so we train the model with the unbalanced data, and the other with class weighting to deal with the imbalance. We establish the weight of each class as the result of dividing the number of samples for that class by the total number of samples. In this task, we can see that the strategy of MLP on categorical features then concat outperforms the other strategies with a 0.4851 when class weighting is used. Moreover, we can observe that the use of class weighting outperforms the models that do not use class weighting in all of the experiments except in the Weighted strategy where the use of class weighting is the worst strategy (0.4803 to 0.4818). Regarding the base strategy (experiment baseline with data  Due to the fact that task 3 is a multilabel classification task, we propose two experiments, one without weight class and the other with class weight to try the unbalanced data. The strategy used to assign class weight to each class is different than task 2. In this task, we assigned a weight of positive examples, where we divided the total of examples of the dataset by the frequency of that class. As in the previous tasks, in <ref type="bibr" coords="8,261.89,539.82,32.34,10.91">Table 6</ref> we can see the results for the experiment with Data Augmentation and the one that integrates information from the annotators. The results show that the best strategy is Gating with class weight where the strategy achieves 0.4109 in macro-F1 scores. Moreover, we can observe that the use of class weight outperforms the models that do not use class weight in all of the experiments. Finally, if we observe the result of the base strategy with class weight, we can see that outperforms other strategies such as Attention, CategoricalMLP, and Weighted. Nevertheless, the differences between strategies are close in the range of 0.4087 to 0.4138.</p><p>As a resume, at the end of this phase, we selected three models to submit the result to the evaluation phase for all of the proposed tasks. We decided to send one model of each proposed </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Phase</head><p>In this section, we present the official results obtained by our submissions. For each task, we present submitted three runs based on the systems that reported the best performance during the pre-evaluation phase. The three runs are related to the best model in the baseline models, the best model in the baseline with data augmentation, and the best model integrating the features of the annotators. To evaluate the system in the evaluation phase, organizers use the official Information Contrast Measure (ICM) <ref type="bibr" coords="9,198.87,523.06,17.82,10.91" target="#b23">[24]</ref> which is a similarity function that tries to calculate the similarity of the output label to the ground truth. The goal of the ICM is to penalize fewer an error in similar classes and more an error between totally different classes. For example, if we have an error between sexist and non-sexist it will be more penalized than if we had it between two specific types of sexism. This happens because sexist and no sexist are two different classes and two specific types of sexism share that they are sexist.</p><p>Due to the fact that the organizers propose a learning with disagreement paradigm to consider the different points of view of the annotators, each task is evaluated in three modes: hard-hard, soft-soft, and hard-soft. Each mode and its associated metrics are described below and defined by organizers <ref type="bibr" coords="9,152.42,645.01,11.36,10.91" target="#b7">[8,</ref><ref type="bibr" coords="9,166.51,645.01,8.96,10.91" target="#b8">9]</ref> • Hard-Hard evaluation. In this type of evaluation considers the output of the system such as the traditional setting (one or more categories for each instance of the dataset) and the ground of truth such as a gold label (majority vote of the label assigned by annotators).</p><p>-ICM-Hard. The official metric for the ranking.</p><p>-ICM-Hard Norm. The ICM-Hard metric normalized. -F1. F1-score. In Task 1 the F1-score corresponds to the sexist class "YES". In the other tasks, this metric represents the average F1 score for all classes.</p><p>• Soft-Soft evaluation. This evaluation method considers the output of the system (probability for each class, for each instance) and the ground of truth such as a full set of human annotations with their variability (the proportion of human annotators that have selected each category).</p><p>-ICM-Soft. The official metric for the ranking.</p><p>-ICM-Soft Norm. The ICM-Soft metric normalized.</p><p>-Cross Entropy. The result of the cross entropy measure used only for Task 1 and Task 2.</p><p>• Hard-Soft evaluation. This mode of evaluation considers the output of the systems such as traditional settings (one or more categories for each instance of the dataset) and the ground of truth such as a full set of human annotations with their variability (the proportion of human annotators that have selected each category).</p><p>-ICM-Soft. The official metric for the ranking.</p><p>-ICM-Soft Norm. The ICM-Soft metric normalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Task 1</head><p>In task 1 (Sexist Identification), we send the following run, from best to worst results:</p><p>• Run 1: Baseline. The hyper-parameter setting for this model is 1.732959582004883e-5 for learning rate, 0.0004027852347237054 for weight decay, and 16 for batch size. • Run 2: Model integrating annotators' information with the strategy weighted feature sum on transformer output. In this run, we establish a learning rate of 1.5415726856440183e-05, a weight decay of 0.005162783476382758, and a batch size of 8. • Run 3: Data Augmentation Baseline. The hyper-parameter used in this run are 7.28772895885929e-06 of learning rate, 0.007902681589455288 of weight decay, and 16 of batch size.</p><p>Table <ref type="table" coords="10,127.53,561.19,5.17,10.91" target="#tab_5">7</ref> shows the results obtained by our team in task 1 for all of the evaluation methods. As can be observed, in Hard-Hard evaluation method SINAI_1 run outperforms the other two runs submitted to the task with a 0.5584 of ICM-Hard. The SINAI_2 and SINAI_3 achieve close values with 0.5543 and 0.544 respectively. We believe that the best run for our team in this evaluation method is because it follows the Baseline experiment. In this experiment, we train the system with the same strategy that the organizers are going to evaluate the system, with only one label assigned to each instance.</p><p>Regarding the Soft-Soft type of evaluation, we can see that SINAI_3 outperforms with a significant difference from the other runs with a 0.903 ICM-Soft. Moreover, the worst result of these runs is for SINAI_2 run with a -5.6559 of ICM-Soft. We think that SINAI_3 obtained the best results due to the fact that, in Baseline Data Augmentation experiment, each comment of the dataset has assigned all the labels selected by annotators, and with this strategy, the system can adjust in a better way the probability of each class for the texts.</p><p>Finally, in the Hard-Soft method, we can observe that the best run is SINAI_2 with a 0.2678. Nevertheless, the result of the other run is too close to SINAI_2 with 0.264 of SINAI_1 and 0.2513 of SINAI_3. In our opinion, in this type of evaluation, our systems obtain similar results even though they are trained in different ways due to the fact that the hard label of our systems is similar to each instance of the dataset. The results obtained by our team in Task 2 for all of the evaluation methods are presented in Table <ref type="table" coords="11,115.97,604.39,3.76,10.91" target="#tab_8">8</ref>. As can be seen, in Hard-Hard evaluation method SINAI_2 run outperforms the other two runs submitted to the task with a -0.0496 of ICM-Hard. The SINAI_1 and SINAI_3 achieve ICM-Hard values of -0.5959 and -0.9649 respectively. We believe that the best run for our team in this evaluation method is because it integrates annotators' information that helps the model to recognize the different sexist intentions.</p><p>Regarding the Soft-Soft type of evaluation, we can see that SINAI_3 outperforms the other runs with a -2.29 ICM-Soft. In addition, the worst result of these runs is formed SINAI_2 with a -10.9851 of ICM-Soft. We think that SINAI_3 obtained the best results due to the fact that it follows the Baseline Data Augmentation experiment, and like Task 1, for Soft to Soft method, this experiment seems to be the best strategy.</p><p>Finally, in the Hard-Soft method, we can observe that the best run is SINAI_2 with a -10.9830. Nevertheless, the results of the other runs are relatively close to this run with -11.0357 of ICM for SINAI_1 and -15.0466 for SINAI_3. In our opinion, in this type of evaluation, and for systems that include more possible labels to classify, our system is better able to match the class most voted by annotators for each text instance. We use 1.725910088321729e-5 for the learning rate, 0.006144588290326373 for weight decay, and 8 for batch size.</p><p>In Table <ref type="table" coords="12,138.88,614.22,5.07,10.91" target="#tab_10">9</ref> we can see the results obtained by our system for Task 3 (Sexism Categorization) in all of the evaluation methods. For Hard-Hard method, the run that obtains the highest result is SINAI_2 with a 0.1472 of ICM-Hard, followed by SINAI_3 with a 0.0249 score in ICM-Hard and SINAI_1 with -0.3020. It can be noted that this system implements a system proposed in Data Augmentation Baseline, where the system has the same text repeated with the different labels assigned by each annotator. This type of experiment seems to be a good way to make a multilabel classification for systems evaluated with Hard-Hard method.</p><p>For the runs evaluated like Soft-Soft can be noticed that SINAI_3 outperforms the other runs with a significant difference in ICM-Soft. SINAI_3 achieve -7.1306 ICM-Soft value. In this case, SINAI_3 has a base architecture and it is trained with hard labels.</p><p>In Hard-Soft evaluation, the best run is SINAI_3 which achieves -12.1399 in ICM-Soft metric. This run outperforms significantly the other two runs SINAI_2 and SINAI_1 with a -27.2984 and -34.9858 score in ICM-Soft respectively.</p><p>As we can observe in the last two types of evaluation, the best run is for systems implemented in the baseline strategy. This may be because with so many classes to choose from, adding annotator information may add more noise to the models that try to predict the sexism category. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper presents the participation of SINAI research group in the sEXism Identification in Social neTwork shared task at CLEF 2023. In all of the tasks, we explore some different ways to train models, a baseline strategy, a baseline strategy with data augmentation, and various types of methods used to integrate socio-demographic annotators features to implement learning with disagreement paradigm. For all the tasks, we can see how the results depend on the evaluation method. Focusing on Task 1, we can see how the strategy with data augmentation improves sexism identification. However, the other two strategies have good results. In Task 2, it can be noticed that integrating socio-demographic annotator information achieve the best results in the majority evaluation method, this can be possible because there are more label and this information can help to determine each category of sexism. Finally, in Task 3, the only task based on multilabel classification the baseline system obtains the best results. Maybe due to the fact that integrating more information can insert more noise and the model has more difficulty in the identification of the different categories of sexism. We conclude that, in general, the incorporation of socio-demographic information from annotators does not help the models to conduct the sexist tasks as we thought at the beginning of this shared task. This could be due to a need for larger training datasets for the network to better mimic human behavior according to each annotator profile. Nevertheless, it seems that when the number of classes increases, as we have observed in Task 2, this information can be more relevant. In future work, we plan to make a more rigorous analysis of the error of our systems and the impact of each socio-demographic features in our systems. In addition, we want to search for more relevant characteristics that are related to sexism and can help to detect it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,429.74,416.69,8.93;3,89.29,441.75,338.84,8.87"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Base architecture proposed for EXIST shared task. N represents the number of output nodes and depends on the task because it corresponds to the number of labels to classify.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,89.29,195.21,380.32,8.93"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Proposed architecture to incorporate annotator information for EXIST shared task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,90.49,353.64,81.83"><head>Table 1</head><label>1</label><figDesc>Instances of the dataset in each split and language.</figDesc><table coords="5,152.64,122.05,289.99,50.26"><row><cell cols="4">Dataset Split #Spanish Instances #English Instances #Total</cell></row><row><cell>Train</cell><cell>3660</cell><cell>3260</cell><cell>6920</cell></row><row><cell>Development</cell><cell>549</cell><cell>489</cell><cell>1038</cell></row><row><cell>Test</cell><cell>1098</cell><cell>978</cell><cell>2076</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,276.76,417.00,117.70"><head>Table 3</head><label>3</label><figDesc>Results of the different models in the Baseline experiment for tasks 1 (Sexism Identification), 2 (Source Intention), and 3 (Sexism Categorization) on EXIST 2023 development set. The selected model for one of the runs in the evaluation phase is shown in bold.</figDesc><table coords="7,191.28,332.29,212.71,62.17"><row><cell>Model</cell><cell>Task 1 Task 2 Task 3</cell></row><row><cell>mDeBERTa Base</cell><cell>0.8519 0.5736 0.3254</cell></row><row><cell>mDeBERTa Large</cell><cell>0.8618 0.6113 0.3483</cell></row><row><cell>XLMRoBERTa Base</cell><cell>0.8585 0.5577 0.3515</cell></row><row><cell cols="2">XLMRoBERTa Large 0.8606 0.6092 0.3700</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.89,90.49,417.38,204.72"><head>Table 4</head><label>4</label><figDesc>Results of the different proposed strategies that incorporate annotators' information (experiment base with data augmentation and experiment integrating annotator information) for Task 1: Sexism Identification on EXIST 2023 development set. The selected model for one of the runs in the evaluation phase is shown in bold.</figDesc><table coords="8,88.89,157.97,417.38,137.24"><row><cell>Strategy</cell><cell>macro-F1</cell></row><row><cell>Base DA</cell><cell>0.7537</cell></row><row><cell>Attention</cell><cell>0.7560</cell></row><row><cell>Concat</cell><cell>0.7534</cell></row><row><cell>Gating</cell><cell>0.7548</cell></row><row><cell>CategoricalMLP</cell><cell>0.7562</cell></row><row><cell>Weighted</cell><cell>0,7567</cell></row><row><cell cols="2">augmentation), we can observe that it obtains a good result, close to CategoricalMLP strategy</cell></row><row><cell cols="2">when class weights are used with a 0.4826 macro-F1 score.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,88.93,313.31,417.32,153.56"><head>Table 5</head><label>5</label><figDesc>Results of the different proposed strategies that incorporate annotators' information (experiment base with data augmentation and integrating annotator information) for Task 2 (Source Intention) on EXIST 2023 development set. The selected model for the evaluation phase is shown in bold.</figDesc><table coords="8,172.08,368.84,251.11,98.03"><row><cell>Strategy</cell><cell cols="2">macro-F1 Without Class Weight Weight Sklearn</cell></row><row><cell>Base DA</cell><cell>0.4721</cell><cell>0.4826</cell></row><row><cell>Attention</cell><cell>0.4657</cell><cell>0.4744</cell></row><row><cell>Concat</cell><cell>0.4661</cell><cell>0.4805</cell></row><row><cell>Gating</cell><cell>0.4666</cell><cell>0.4774</cell></row><row><cell>CategoricalMLP</cell><cell>0.4642</cell><cell>0.4851</cell></row><row><cell>Weighted</cell><cell>0.4818</cell><cell>0.4803</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,88.91,90.49,417.36,312.59"><head>Table 6</head><label>6</label><figDesc>Results of the different proposed strategies that incorporate annotators' information (experiment base with data augmentation and integrating annotator information) for Task 3 (Sexism Categorization) on EXIST 2023 development set. The selected model for the evaluation phase is shown in bold. For Task 1, we selected mDeBERTa Large with the baseline strategy, and two mDeBERTa Base models, once with the baseline with data augmentation and other integrating annotators' information with the strategy weighted feature sum on transformer output. In Task 2, we decided to submit for baseline model a mDeBERTa Large model, a mDeBERTa Base model for baseline with data augmentation experiment, and a mDeBERTa Base with the strategy MLP on categorical features then concat such as strategy that includes socio-demographic annotator's information. Finally, for Task 3, we selected a XLMRoBERTa Large model such as baseline model, and two versions of mDeBERTa Base model, one with the Baseline Data Augmentation strategy and the other incorporating annotator information with the strategy gating on categorical features and then sum.</figDesc><table coords="9,89.29,146.01,337.92,135.12"><row><cell>Strategy</cell><cell cols="2">macro-F1 Without Class Weight With Class Weight</cell></row><row><cell>Base DA</cell><cell>0.3109</cell><cell>0.411</cell></row><row><cell>Attention</cell><cell>0.3149</cell><cell>0.4087</cell></row><row><cell>Concat</cell><cell>0.3164</cell><cell>0.4130</cell></row><row><cell>Gating</cell><cell>0.3107</cell><cell>0.4138</cell></row><row><cell>CategoricalMLP</cell><cell>0.3124</cell><cell>0.4109</cell></row><row><cell>Weighted</cell><cell>0.3179</cell><cell>0.4089</cell></row><row><cell>experiment.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,88.99,221.92,416.99,285.23"><head>Table 7</head><label>7</label><figDesc>Results of SINAI Team submission on Task 1: Sexism Identification. The best result for each evaluation method is in bold.</figDesc><table coords="11,89.29,262.70,416.69,244.45"><row><cell>Run</cell><cell>Ranking</cell><cell>ICM-Hard</cell><cell>Hard-Hard ICM-Hard Norm</cell><cell>F1</cell><cell>Ranking</cell><cell>ICM-Soft</cell><cell cols="2">Soft-Soft ICM-Soft Norm</cell><cell>Cross Entropy</cell><cell>Ranking</cell><cell>Hard-Soft ICM-Soft</cell><cell>ICM-Soft Norm</cell></row><row><cell cols="5">SINAI_3 11 0.5440 0.7127 0.7715</cell><cell cols="5">1 0.9030 0.6421 0.7960</cell><cell cols="3">11 0.2513 0.5368</cell></row><row><cell cols="5">SINAI_1 8 0.5584 0.7219 0.7804</cell><cell cols="3">24 0.4863</cell><cell>0.5748</cell><cell>1.5759</cell><cell>9</cell><cell cols="2">0.2640 0.5389</cell></row><row><cell cols="2">SINAI_2 9</cell><cell cols="3">0.5543 0.7192 0.7719</cell><cell cols="5">56 -5.6559 -0.4175 7.3080</cell><cell cols="3">8 0.2678 0.5395</cell></row><row><cell cols="2">4.2.2. Task 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="12">In task 2 (source intention), we send the following runs, from best to worst results:</cell></row><row><cell cols="4">• Run 1: Baseline.</cell><cell cols="9">The hyper-parameter configuration for this model is</cell></row><row><cell cols="13">1.598807925394166e-5 for learning rate, 0.0005069050078567268 for weight decay, and 16</cell></row><row><cell cols="3">for batch size.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>• Run</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,107.28,497.18,400.55,65.52"><head>2: Model integrating annotators' information with the strategy MLP on categorical features then concat. The</head><label></label><figDesc></figDesc><table coords="11,107.28,509.79,400.55,52.91"><row><cell>hyper-parameter result of hyper-parameter opti-</cell></row><row><cell>mization for this model are 1.362373572892371e-05 for learning rate, 0.00634231591793882</cell></row><row><cell>for weight decay, and 16 for batch size.</cell></row><row><cell>• Run</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="11,116.16,551.79,391.02,24.46"><head>3: Data Augmentation Baseline. With</head><label></label><figDesc>a learning rate of 1.861739374638094e-05, weight decay of 0.004698351934634685, and batch size of 32.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,88.99,237.86,417.00,250.67"><head>Table 8</head><label>8</label><figDesc>Results of SINAI Team submission on Task 2: Sexism Intention. The best result for each evaluation method is in bold.</figDesc><table coords="12,89.29,278.47,416.69,210.05"><row><cell>Run</cell><cell>Ranking</cell><cell>Hard-Hard ICM-Hard ICM-Hard Norm</cell><cell>F1</cell><cell>Ranking</cell><cell>ICM-Soft</cell><cell cols="2">Soft-Soft ICM-Soft Norm</cell><cell>Cross Entropy</cell><cell>Ranking</cell><cell>Hard-Soft ICM-Soft</cell><cell>ICM-Soft Norm</cell></row><row><cell cols="4">SINAI_3 30 -0.9646 0.4667 0.2544</cell><cell>8</cell><cell cols="4">-2.2900 0.7831 1.6753</cell><cell cols="2">34 -15.0466</cell><cell>0.4573</cell></row><row><cell>SINAI_1</cell><cell cols="3">25 -0.5959 0.5453 0.2562</cell><cell cols="3">19 -4.2437</cell><cell cols="2">0.7332 2.3710</cell><cell cols="2">32 -11.0357</cell><cell>0.5597</cell></row><row><cell cols="4">SINAI_2 18 -0.0496 0.6617 0.4924</cell><cell cols="5">25 -10.9851 0.5610 4.6237</cell><cell cols="3">31 -10.9983 0.5607</cell></row><row><cell cols="2">4.2.3. Task 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="12">In task 3 (sexist categorization), we sent the following runs, from best to worst results in the</cell></row><row><cell cols="3">development phase:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">• Run 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="12,107.28,478.55,400.55,107.53"><head>: Model integrating annotator information with the strategy gating on categorical feats then sum. For</head><label></label><figDesc></figDesc><table coords="12,107.28,491.17,400.55,94.92"><row><cell>this model we use the following hyper-parameter, a</cell></row><row><cell>learning rate of 1.59165455576808e-06, a weight decay of 0.006133244155950455, and a</cell></row><row><cell>batch size of 16.</cell></row><row><cell>• Run 2: Data Augmentation Baseline. With a learning rate of 1.209486958019233e-</cell></row><row><cell>05, a weight decay of 0.00824196801678852, and a batch size of 8 for hyper-parameter</cell></row><row><cell>configuration.</cell></row><row><cell>• Run 3: Baseline.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="13,88.99,251.47,416.99,157.50"><head>Table 9</head><label>9</label><figDesc>Results of SINAI Team submission on Task 3: Sexism Categorization. The best result for each evaluation method is in bold.</figDesc><table coords="13,97.40,292.58,402.85,116.39"><row><cell>Run</cell><cell>Ranking</cell><cell>ICM-Hard</cell><cell cols="2">Hard-Hard ICM-Hard Norm</cell><cell>F1</cell><cell>Ranking</cell><cell>Soft-Soft ICM-Soft</cell><cell>ICM-Soft Norm</cell><cell>Ranking</cell><cell>Hard-Soft ICM-Soft</cell><cell>ICM-Soft Norm</cell></row><row><cell cols="4">SINAI_3 10 0.0249</cell><cell cols="2">0.5971 0.5033</cell><cell cols="3">10 -7.1306 0.7013</cell><cell cols="3">12 -12.1399 0.6112</cell></row><row><cell cols="6">SINAI_2 7 0.1472 0.6203 0.5822</cell><cell cols="3">19 -13.5493 0.5858</cell><cell cols="2">26 -27.2984</cell><cell>0.3384</cell></row><row><cell cols="6">SINAI_1 14 -0.3020 0.5352 0.5306</cell><cell cols="3">24 -34.9362 0.2010</cell><cell cols="2">28 -34.9858</cell><cell>0.2001</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially supported by <rs type="projectName">WeLee</rs> project (<rs type="grantNumber">1380939</rs>, <rs type="funder">FEDER</rs> <rs type="grantNumber">Andalucía 2014-2020</rs>) funded by the <rs type="funder">Andalusian Regional Government</rs>, and projects <rs type="projectName">CONSENSO</rs> (<rs type="grantNumber">PID2021-122263OB-C21</rs>), <rs type="projectName">MODERATES</rs> (<rs type="grantNumber">TED2021-130145B-I00</rs>), <rs type="projectName">SocialTOX</rs> (<rs type="grantNumber">PDC2022-133146-C21</rs>) funded by <rs type="funder">Plan Nacional I+D+i</rs> from the <rs type="funder">Spanish Government</rs>, and project <rs type="projectName">PRECOM</rs> (<rs type="grantNumber">SUBV-00016</rs>) funded by the <rs type="funder">Ministry of Consumer Affairs of the Spanish Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_vEZ87sC">
					<idno type="grant-number">1380939</idno>
					<orgName type="project" subtype="full">WeLee</orgName>
				</org>
				<org type="funded-project" xml:id="_qd9wE7V">
					<idno type="grant-number">Andalucía 2014-2020</idno>
					<orgName type="project" subtype="full">CONSENSO</orgName>
				</org>
				<org type="funded-project" xml:id="_Un3DzGw">
					<idno type="grant-number">PID2021-122263OB-C21</idno>
					<orgName type="project" subtype="full">MODERATES</orgName>
				</org>
				<org type="funded-project" xml:id="_D2YxC7s">
					<idno type="grant-number">TED2021-130145B-I00</idno>
					<orgName type="project" subtype="full">SocialTOX</orgName>
				</org>
				<org type="funding" xml:id="_ntU8mm9">
					<idno type="grant-number">PDC2022-133146-C21</idno>
				</org>
				<org type="funded-project" xml:id="_6DsVsxV">
					<idno type="grant-number">SUBV-00016</idno>
					<orgName type="project" subtype="full">PRECOM</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="14,112.66,339.71,394.04,10.91;14,112.39,353.26,296.77,10.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="14,112.66,339.71,235.66,10.91">Definition of sexism by the oxford english dictionary</title>
		<ptr target="https://www.oed.com/view/Entry/177027rskey=577LIN&amp;result=2&amp;isAdvanced=false#eid" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,366.81,393.60,10.91;14,112.66,380.36,218.86,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,248.13,366.81,258.13,10.91;14,112.66,380.36,83.08,10.91">Overview of the evalita 2018 task on automatic misogyny identification (ami)</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,218.52,380.36,82.10,10.91">EVALITA@CLiC-it</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,393.91,393.60,10.91;14,112.66,407.46,259.68,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,289.86,393.91,216.40,10.91;14,112.66,407.46,131.32,10.91">Overview of the Task on Automatic Misogyny Identification at IberEval 2018</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Anzovino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,267.08,407.46,74.52,10.91">IberEval@SEPLN</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,421.01,394.53,10.91;14,112.66,434.55,393.33,10.91;14,112.66,448.10,394.53,10.91;14,112.28,461.65,395.39,10.91;14,112.66,475.20,318.14,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,112.66,434.55,393.33,10.91;14,112.66,448.10,42.86,10.91">SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Rangel Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
		<ptr target="https://aclanthology.org/S19-2007.doi:10.18653/v1/S19-2007" />
	</analytic>
	<monogr>
		<title level="m" coord="14,178.63,448.10,328.55,10.91;14,112.28,461.65,183.55,10.91">Proceedings of the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics</title>
		<meeting>the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,488.75,393.32,10.91;14,112.66,502.30,188.89,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Röttger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04222</idno>
		<title level="m" coord="14,295.61,488.75,210.37,10.91;14,112.66,502.30,58.73,10.91">Semeval-2023 task 10: Explainable detection of online sexism</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,515.85,394.53,10.91;14,112.66,529.40,393.33,10.91;14,112.66,542.95,394.04,10.91;14,112.66,556.50,96.92,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,112.66,529.40,296.04,10.91">Overview of exist 2021: sexism identification in social networks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Comet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Donoso</surname></persName>
		</author>
		<ptr target="http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6389" />
	</analytic>
	<monogr>
		<title level="j" coord="14,421.79,529.40,84.20,10.91;14,112.66,542.95,75.47,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,570.05,394.52,10.91;14,112.66,583.60,393.33,10.91;14,112.66,597.15,395.01,10.91;14,112.66,610.69,335.90,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,365.45,583.60,140.54,10.91;14,112.66,597.15,140.82,10.91">Overview of exist 2022: sexism identification in social networks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mendieta-Aragón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marco-Remón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Makeienko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6443" />
	</analytic>
	<monogr>
		<title level="j" coord="14,262.32,597.15,161.40,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="229" to="240" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,624.24,393.72,10.91;14,112.66,637.79,394.53,10.91;14,112.66,651.34,395.17,10.91;14,112.66,664.89,394.53,10.91;15,112.66,86.97,393.32,10.91;15,112.66,100.52,289.10,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,463.64,624.24,42.74,10.91;14,112.66,637.79,390.18,10.91">Overview of exist 2023 -learning with disagreement for sexism identification and characterization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,329.46,664.89,177.72,10.91;15,112.66,86.97,393.32,10.91;15,112.66,100.52,161.78,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF 2023)</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,114.06,393.72,10.91;15,112.66,127.61,393.32,10.91;15,112.33,141.16,393.65,10.91;15,112.66,154.71,328.66,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,463.64,114.06,42.74,10.91;15,112.66,127.61,393.32,10.91;15,112.33,141.16,87.11,10.91">Overview of exist 2023 -learning with disagreement for sexism identification and characterization (extended overview)</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,467.49,141.16,38.49,10.91;15,112.66,154.71,297.96,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,168.26,393.33,10.91;15,112.26,181.81,393.73,10.91;15,112.66,195.36,302.79,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="15,220.65,168.26,238.87,10.91;15,481.66,168.26,24.33,10.91;15,112.26,181.81,393.73,10.91;15,112.66,195.36,21.62,10.91">Third workshop on evaluation of human language technologies for iberian languages (ibereval 2018)</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Frenda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bilal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="15,202.47,195.36,124.97,10.91">Ceur Workshop Proceedings</title>
		<imprint>
			<biblScope unit="volume">2150</biblScope>
			<biblScope unit="page" from="260" to="267" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Exploration of Misogyny in Spanish and English tweets</note>
</biblStruct>

<biblStruct coords="15,112.66,208.91,394.53,10.91;15,112.28,222.46,394.91,10.91;15,112.66,236.01,345.58,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="15,112.28,222.46,390.58,10.91">A multi-task learning approach to hate speech detection leveraging sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Plaza-Del-Arco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Molina-González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Martín-Valdivia</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3103697</idno>
	</analytic>
	<monogr>
		<title level="j" coord="15,112.66,236.01,54.37,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="112478" to="112489" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,249.56,394.53,10.91;15,112.66,263.11,393.33,10.91;15,112.66,276.66,292.72,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="15,112.66,263.11,393.33,10.91;15,112.66,276.66,82.38,10.91">Integrating implicit and explicit linguistic phenomena via multi-task learning for offensive language detection</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Plaza-Del-Arco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Molina-González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Martín-Valdivia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,203.34,276.66,119.02,10.91">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="page">109965</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,290.20,394.53,10.91;15,112.66,303.75,380.66,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Halat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Plaza-Del-Arco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Klinger</surname></persName>
		</author>
		<title level="m" coord="15,344.83,290.20,162.36,10.91;15,112.66,303.75,348.74,10.91">Multi-task learning with sentiment, emotion, and target detection to recognize hate speech and offensive language</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,317.30,394.53,10.91;15,112.66,330.85,393.33,10.91;15,112.66,344.40,397.48,10.91;15,112.66,360.39,43.94,7.90" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="15,275.34,330.85,230.65,10.91;15,112.66,344.40,93.76,10.91">Assessing the impact of contextual information in hate speech detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zayat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kondratzky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Serrati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zajac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Debandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gravano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2023.3258973</idno>
	</analytic>
	<monogr>
		<title level="j" coord="15,214.70,344.40,54.01,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="30575" to="30590" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,371.50,394.53,10.91;15,112.66,385.05,394.53,10.91;15,112.66,398.60,393.32,10.91;15,112.66,412.15,394.03,10.91;15,112.66,425.70,330.77,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="15,176.01,385.05,105.33,10.91">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="s" coord="15,314.47,398.60,191.52,10.91;15,112.66,412.15,34.49,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,439.25,394.61,10.91;15,112.66,452.79,393.53,10.91;15,112.66,466.34,395.01,10.91;15,112.66,479.89,344.49,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="15,198.83,439.25,288.64,10.91">A package for learning on tabular and text data with transformers</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Budhkar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.maiworkshop-1.10</idno>
		<ptr target="https://aclanthology.org/2021.maiworkshop-1.10.doi:10.18653/v1/2021.maiworkshop-1.10" />
	</analytic>
	<monogr>
		<title level="m" coord="15,112.66,452.79,393.53,10.91;15,112.66,466.34,113.04,10.91">Proceedings of the Third Workshop on Multimodal Artificial Intelligence, Association for Computational Linguistics</title>
		<meeting>the Third Workshop on Multimodal Artificial Intelligence, Association for Computational Linguistics<address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,493.44,393.33,10.91;15,112.66,506.99,313.71,10.91" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09543</idno>
		<title level="m" coord="15,213.83,493.44,292.16,10.91;15,112.66,506.99,183.73,10.91">Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,520.54,394.04,10.91;15,112.66,534.09,198.48,10.91" xml:id="b17">
	<monogr>
		<ptr target="https://huggingface.co/microsoft/mdeberta-v3-base" />
		<title level="m" coord="15,117.83,520.54,163.95,10.91">hugging face mdeberta base model</title>
		<imprint>
			<date type="published" when="2021-06-01">2021. June 1, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,547.64,394.04,10.91;15,112.66,561.19,192.62,10.91" xml:id="b18">
	<monogr>
		<ptr target="https://huggingface.co/microsoft/deberta-v3-large" />
		<title level="m" coord="15,112.66,547.64,172.77,10.91">Hugging face mdeberta large model</title>
		<imprint>
			<date type="published" when="2021-06-01">2021. June 1, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,574.74,394.53,10.91;15,112.66,588.29,178.78,10.91;15,307.62,588.29,198.37,10.91;15,112.66,601.84,395.01,10.91;15,112.66,617.83,97.35,7.90" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="15,307.62,588.29,198.37,10.91;15,112.66,601.84,75.38,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1911.02116" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,628.93,395.01,10.91" xml:id="b20">
	<monogr>
		<ptr target="https://huggingface.co/xlm-roberta-base" />
		<title level="m" coord="15,112.66,628.93,160.40,10.91">Hugging face xlm-roberta base model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,642.48,394.04,10.91;15,112.40,656.03,82.19,10.91" xml:id="b21">
	<monogr>
		<ptr target="https://huggingface.co/xlm-roberta-large" />
		<title level="m" coord="15,112.66,642.48,203.58,10.91">Hugging face xlm-roberta large model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,669.58,395.17,10.91;16,112.66,86.97,393.32,10.91;16,112.66,100.52,271.56,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,340.16,669.58,167.68,10.91;16,112.66,86.97,140.88,10.91">Optuna: A next-generation hyperpa-rameter optimization framework</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yanase</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,276.93,86.97,229.05,10.91;16,112.66,100.52,241.18,10.91">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,114.06,394.62,10.91;16,112.66,127.61,393.32,10.91;16,112.33,141.16,394.86,10.91;16,112.66,154.71,65.30,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="16,223.33,114.06,260.58,10.91">Evaluating extreme hierarchical multi-label classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Delgado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,112.66,127.61,393.32,10.91">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5809" to="5819" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
