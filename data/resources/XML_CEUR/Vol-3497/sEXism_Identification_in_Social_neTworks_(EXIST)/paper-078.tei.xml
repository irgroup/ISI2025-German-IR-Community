<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,362.32,15.39;1,89.29,106.97,318.11,15.39;1,89.29,130.31,198.26,10.68">CLassifiers at EXIST 2023: Detecting Sexism in Spanish and English Tweets With XLM-T Notebook for the Exist Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.22,80.78,10.68"><forename type="first">Berna</forename><forename type="middle">Ilke</forename><surname>Ersoy</surname></persName>
							<email>bernailke.ersoy@uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<addrLine>Rämistrasse 71</addrLine>
									<postCode>8006</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,194.87,156.22,57.84,10.68"><forename type="first">Gian</forename><surname>Radler</surname></persName>
							<email>gian.radler@uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<addrLine>Rämistrasse 71</addrLine>
									<postCode>8006</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.86,156.22,82.76,10.68"><forename type="first">Sofia</forename><surname>Carpentieri</surname></persName>
							<email>sofia.carpentieri@uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<addrLine>Rämistrasse 71</addrLine>
									<postCode>8006</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,362.32,15.39;1,89.29,106.97,318.11,15.39;1,89.29,130.31,198.26,10.68">CLassifiers at EXIST 2023: Detecting Sexism in Spanish and English Tweets With XLM-T Notebook for the Exist Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">12152723BCCF629EA3B78ED7EDB99ABF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>hate speech detection</term>
					<term>sexism detection</term>
					<term>sexism categorization</term>
					<term>social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the submission of our team CLassifiers to the EXIST 2023 shared task competition on sexism detection. Our approach involves utilizing multiple techniques based on a pre-trained RoBERTa model. We developed two distinct models: a binary classifier for Task 1 and a multi-label classifier for Task 3. Leveraging the multilingual XLM-T model, we tailored our models to each task and achieved favorable results in our experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With increasing numbers of online users and larger digital space, more content is being produced everyday. Along with this surge in content, there has been a parallel rise in the dissemination of hateful content. It appears in various forms, one of which is sexism -a form of prejudice or discrimination based on gender, usually targeted towards women or feminine-presenting people <ref type="bibr" coords="1,121.86,422.18,11.49,9.74" target="#b0">[1]</ref>. As it implies harmful ideals not only about femininity, but also about masculinity, it hurts everyone in societies all over the world, unrelated to culture or religion <ref type="bibr" coords="1,454.88,435.73,11.59,9.74" target="#b1">[2]</ref>. It is an on-going struggle to combat and can be especially hard to detect for humans socialized within patriarchal structures. For online spaces there is an increased need to create automatic sexism detection systems which allow to filter or censor to avoid the spreading of harmful content. The difficulty and need to develop reliable systems is evident in the amount of published research on sexism or hate speech detection <ref type="bibr" coords="1,247.75,503.48,11.43,9.74" target="#b2">[3]</ref>.</p><p>For our participation in this third edition of the shared task on sexism detection, we used multiple approaches based on a pre-trained XLM-RoBERTa model <ref type="bibr" coords="1,380.67,530.57,11.31,9.74" target="#b3">[4]</ref>. This paper describes the submission of our team CLassifiers to the EXIST 2023 shared task competition <ref type="bibr" coords="1,429.17,544.12,11.23,9.74" target="#b4">[5,</ref><ref type="bibr" coords="1,442.89,544.12,7.49,9.74" target="#b5">6]</ref>. We created two different approaches: one for Task 1 of the shared task that acts as a binary classifier and a second model for Task 3 that is a multi-label classifier. Both of our models are based on the multilingual XLM-T <ref type="bibr" coords="1,181.08,584.77,11.43,9.74" target="#b6">[7]</ref>, which we adapted for both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The field of sexism detection has seen a variety of approaches, most of them focused on social media posts. Anonymity, invisibility and accessibility make hateful posts more common amongst social media users, as they often go unnoticed and are not followed up by consequences <ref type="bibr" coords="2,492.22,139.50,11.58,9.74" target="#b7">[8]</ref>. Researchers have been attempting to automate the process of identifying sexist content to help social platforms and communities establish safer environments. However, sexism detection is challenging due to its subtle nature, the diversity of its expressions, and the complexity of the language used. Different methods have been used to tackle the sexism detection task. Traditional approaches involve rule-based systems and machine learning algorithms such as Support Vector Machines (SVM), Naive Bayes, and Random Forests. These methods usually rely on manually selected features like Bag of Words (BoW), TF-IDF, and sentiment scores <ref type="bibr" coords="2,492.41,234.35,11.44,9.74" target="#b8">[9]</ref>.</p><p>Recently, the focus has shifted towards Transformer-based models like BERT <ref type="bibr" coords="2,441.62,247.89,16.16,9.74" target="#b9">[10]</ref>, GPT <ref type="bibr" coords="2,486.98,247.89,16.16,9.74" target="#b10">[11]</ref>, and RoBERTa <ref type="bibr" coords="2,150.97,261.44,12.69,9.74" target="#b3">[4]</ref> due to their superior performance on a wide range of NLP tasks. These models leverage the Transformer architecture's strengths to capture complex language semantics and context effectively. XLM-RoBERTa <ref type="bibr" coords="2,254.03,288.54,18.07,9.74" target="#b11">[12]</ref> is an extension of RoBERTa that has been trained multilingualy in XLM style <ref type="bibr" coords="2,214.78,302.09,16.42,9.74" target="#b12">[13]</ref>. It combines the advantages of RoBERTa, which is a variant of BERT optimized for more robust performance, with the benefits of cross-lingual training, thus enabling the model to understand text in various languages. XLM-RoBERTa uses a masked language modeling objective, similar to BERT, but with modifications in the training process. It employs dynamic masking instead of static masking and removes the next sentence prediction task, which results in a more robust and versatile model. Its multilingual capabilities make it especially suitable for tasks like sexism detection, where the content may be in different languages.</p><p>Tweets pose unique challenges to sexism detection due to their casual language use, and the frequent use of slang and abbreviations <ref type="bibr" coords="2,292.68,424.03,16.41,9.74" target="#b13">[14]</ref>. The character limit of tweets often leads to condensed expressions of sexism that are difficult to identify using traditional detection methods. The XLM-T model <ref type="bibr" coords="2,213.38,451.13,11.28,9.74" target="#b6">[7]</ref>, an XLM-RoBERTa model pre-trained on multilingual tweet data, emerged as a promising tool for tackling the challenges of tweet-based content classification tasks. In the context of sexism detection, the use of XLM-T offers several advantages. Firstly, its multilingual pre-training allows it to detect sexist content across different languages, which is critical given the global nature of Twitter. The model's grounding in tweet-based language, coupled with its ability to understand the nuances and idiosyncrasies of this language, lends it robust capabilities in identifying subtle expressions of sexism. Secondly, the model can be fine-tuned on labeled datasets of sexist and non-sexist tweets. Through this fine-tuning, XLM-T can learn to distinguish the markers of sexism embedded within the tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Material and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The EXIST 2023 dataset includes postings from Twitter as well as annotations for different categories of sexism. It contains 10,034 labeled tweets, both in English and in Spanish, which are split into training, development and test sets. The two languages are balanced in their distributions. Each tweet in the dataset is annotated by six annotators and no hard unique labels are given. For an overview, see Table <ref type="table" coords="3,256.92,101.64,3.74,9.74" target="#tab_0">1</ref>. Labels for Task 1, a binary classification task, contain the values sexist or non-sexist, indicating whether the tweet is perceived to be sexist or not. Labels for Task 3, a multi-label classification task, are provided as a set of arrays (one array per annotator) indicating the type or types of sexism found in a tweet. The labels for Task 3 are: ideological-inequality, stereotypingdominance, objectification, sexual-violence, misogyny-non-sexual-violence, -(assigned to nonsexist tweets), and unknown. Additional information on each tweet and its annotation include the tweet ID, language, number of annotators, gender of the annotators, and age group of the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">External Data</head><p>As a data augmentation strategy, in addition to the EXIST 2023 dataset, we used the EXIST 2021 dataset <ref type="bibr" coords="3,123.53,389.43,16.25,9.74" target="#b14">[15]</ref>. It consists of Spanish and English tweets, namely 6,977 for training and 3,386 for testing. The data was annotated by five crowd-sourcing annotators each. Final labels were selected by majority decision. The data was used for training on Task 1, since the labels were incompatible with Task 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Evaluation Metrics</head><p>The official evaluation metrics used for the results are ICM and ICM-soft. Proposed in 2022 by Amigó and Delgado <ref type="bibr" coords="3,179.23,493.36,16.13,9.74" target="#b15">[16]</ref>, the ICM metric is based on information theory and draws inspiration from the Information Contrast Model (ICM) <ref type="bibr" coords="3,294.98,506.91,16.42,9.74" target="#b16">[17]</ref>. For the shared task, the organizers have extended the original ICM metric and created ICM-soft. This extension enables the evaluation of soft labels and is suited for learning with disagreement scenarios, as is the case in EXIST 2023. Higher values of the ICM and ICM-soft metrics indicate a stronger similarity between system outputs and ground truth; thus, higher values are considered better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Preprocessing and Data Preparation</head><p>Considering that our dataset for training our models is bilingual, we decided to do minimal preprocessing. All tweets were lower-cased, we removed HTML tags, URLs, and user mentions, and converted emojis into their CLDR (Common Locale Data Repository) short name. For instance, the emoji " " is replaced by ":purple_heart:" and the emoji " " is replaced by ":dizzy:". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Problem Modeling</head><p>In both tasks, the classification process involves hard or soft labels. Soft labels refer to predicting probabilities for each label category, while hard labels only involve a label prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.">Task 1: Binary Classification</head><p>Task 1 required binary classification to determine whether a tweet should be considered sexist and to label them as either "YES", meaning that the tweet is sexist, or "NO". indicating that a tweet is not. A tweet was labeled as sexist if it received agreement from more than three annotators, disregarding evenly split cases. The soft labels provided a representation of the uncertainty by assigning probabilities that summed up to one for each tweet. We chose XLM-T <ref type="bibr" coords="4,89.29,350.16,13.00,9.74" target="#b6">[7]</ref> for both soft and hard settings. For an overview, please refer to Table <ref type="table" coords="4,427.15,350.16,3.82,9.74" target="#tab_2">2</ref>. For our Task 1 submissions, we conducted three runs with variations in the number of training epochs. Run 1 involved training for 3 epochs, Run 2 for 4 epochs, and Run 3 for 6 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2.">Task 3: Multi-Label Classification</head><p>Task 3 involved multi-label classification, where a tweet was categorized in one or more label categories. To assign a hard label to a tweet, at least two or more annotators had to agree on the presence of a particular label. Soft labels were provided for each category, indicating the probabilities associated with the presence of that label. For soft label classification, we decided to train one model for each of the five labels to predict the probabilities of said label. For Task 3, we also used the binary classification model developed in Task 1 to enhance the labeling process.</p><p>If the Task 1 model predicted that a tweet was not sexist ("NOT SEXIST"), any corresponding hard labels predicted by the Task 3 model were replaced with "NO" to align with the model's prediction, improving the overall performance of our multi-label classification model. For our Task 3 submissions, we conducted two runs with differences in the number of training epochs.</p><p>In Run 1, we trained the model for 5 epochs, while in Run 2, we trained it for 4 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>Since our team only participated in Tasks 1 and 3, we will only discuss the results of these two tasks in the following sections. For Task 1 we submitted 3 runs and for Task 3 we handed in 2 runs. All results in Table <ref type="table" coords="4,198.53,647.80,3.66,9.74" target="#tab_3">3</ref>, Table <ref type="table" coords="4,234.28,647.80,3.66,9.74">4</ref>, Table <ref type="table" coords="4,270.02,647.80,4.97,9.74" target="#tab_4">5</ref> and Table <ref type="table" coords="4,321.81,647.80,4.97,9.74">6</ref> are taken from the official leaderboard of the corresponding task from the soft-soft and hard-hard evaluation sheets and ranked according to their ICM-Soft score along the normal ICM score. We have added the "Team Rank" column, which takes into account only the best models of a team.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Task 1</head><p>The three submitted runs for this task differed in the number of epochs during training, while using the same base model. The results in Table <ref type="table" coords="5,308.62,438.45,5.16,9.74" target="#tab_3">3</ref> show that any increase in training epochs correlates directly with an increase in the ICM-Soft score.</p><p>In the first run, we achieved an ICM-Soft score of 0.8172 and an ICM-Soft normalized score of 0.6248 whereas the highest possible score is a 3.1183 in ICM-Soft and 1.0 in the ICM-Soft normalized score. In run 2, we managed to achieve an ICM-Soft score of 0.8698 and a normalized score of 0.6368. Lastly, in run 3 we achieved our overall highest ICM-Soft score of 0.9027 and a normalized score of 0.6421. Lagging behind the first rank by only 0.0003 in the ICM-Soft score, we consider it a state-of-the-art result. Training for one more epoch might have improved results even further.</p><p>The two lowermost runs in the table are the non-informative baselines provided by the EXIST 2023 committee and ranked 47th and 52nd respectively, with an ICM-soft score of -2.3585 and -3.0717. The EXIST 2023_test_majority_class run set the probability of the class to 1 and classified all instances as the majority class. The EXIST 2023_test_minority_class classified all instances as the minority class and set the probability of the class to 1.</p><p>The evaluation results in Table <ref type="table" coords="5,243.63,628.14,5.17,9.74">4</ref> show the ICM-Hard scores for our three runs. As in the soft-soft scenario, the model in run 1 was ranked lowest among the three models. However, in this case, the second run achieved a higher ranking compared to the third run. Run 2 obtained an ICM-Hard score of 0.539 and an ICM-Hard normalized score of 0.7095 and was ranked 12th, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Task 3</head><p>The two runs for Task 3 vary according to the number of training epochs used for building the model. The difference of one epoch during training resulted in large discrepancies between the ICM-Soft scores of the two runs. Run number 2 (4 epochs) attained an ICM-Soft score of -14.7828 and a normalized score of 0.5636. The first run (5 epochs), achieved an ICM-Soft score of -6.4072 and a normalized score of 0.7143. Our two runs ranked (in order mentioned) 20th and 6th place. The total difference of the ICM-Soft score between our better run and the first ranking place is 4.0889. The difference between the normalized scores equals to 0.0736. Again, we conclude that training for more epochs may have further improved our results. We also report the results for the hard-hard evaluation scenario in Table <ref type="table" coords="6,421.81,521.34,3.70,9.74">4</ref>. Both our models have encountered difficulties in accurately predicting the hard labels. Our first run ranked 30th with an ICM-Hard score of -1.8664, while our second run was ranked 29th with a score of -1.8852. The models in the hard label scenario perform worse than the majority baseline, suggesting that more optimization is needed for both systems that go beyond changing the number of epochs trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In conclusion, the XLM-T model, pre-trained on a large corpus of multilingual tweet data, has demonstrated substantial promise for the task of sexism detection in the unique linguistic context of Twitter. Even with minimal configuration and experimentation, it has achieved second place in the binary sexism detection task and sixth place in the more complex multi-label classification task. This showcases the power of the domain-adapted XLM-T foundation model and highlights how little effort is needed to yield promising results when fine-tuning it for specific tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,129.72,347.32,20.86"><head>Table 1</head><label>1</label><figDesc>Counts and distrubution of Spanish and English tweets in dataset according to splits</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,153.18,161.32,288.92,50.25"><head>Dataset Split Spanish Tweets English Tweets Total Tweets</head><label></label><figDesc></figDesc><table coords="3,153.18,178.76,269.88,32.82"><row><cell>Train Set</cell><cell>3660</cell><cell>3260</cell><cell>6920</cell></row><row><cell>Evaluation Set</cell><cell>549</cell><cell>489</cell><cell>1038</cell></row><row><cell>Test Set</cell><cell>1098</cell><cell>978</cell><cell>2076</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.99,90.67,317.36,82.94"><head>Table 2</head><label>2</label><figDesc>Overview of the models utilized.</figDesc><table coords="4,188.93,116.48,217.42,57.13"><row><cell cols="2">Task Labels</cell><cell>Model</cell></row><row><cell>1</cell><cell cols="2">hard cardiffnlp/twitter-xlm-roberta-base</cell></row><row><cell>1</cell><cell cols="2">soft cardiffnlp/twitter-xlm-roberta-base</cell></row><row><cell>3</cell><cell>hard</cell><cell>xlm-roberta-base</cell></row><row><cell>3</cell><cell cols="2">soft cardiffnlp/twitter-xlm-roberta-base</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,88.99,90.67,402.63,245.60"><head>Table 3</head><label>3</label><figDesc>Results for Task 1 soft-soft evaluation</figDesc><table coords="5,88.99,116.47,402.63,219.80"><row><cell>Run</cell><cell cols="6">Rank Team Rank ICM-Soft ICM-Soft Norm Cross Entropy</cell></row><row><cell>test_gold_soft</cell><cell>0</cell><cell>-</cell><cell></cell><cell>3.1182</cell><cell>1</cell><cell>0.5472</cell></row><row><cell>SINAI_3</cell><cell>1</cell><cell>1</cell><cell></cell><cell>0.9030</cell><cell>0.6421</cell><cell>0.7960</cell></row><row><cell>CLassifiers_3</cell><cell>2</cell><cell>2</cell><cell></cell><cell>0.9027</cell><cell>0.6421</cell><cell>0.9754</cell></row><row><cell>CLassifiers_2</cell><cell>3</cell><cell>2</cell><cell></cell><cell>0.8698</cell><cell>0.6368</cell><cell>0.9823</cell></row><row><cell>CLassifiers_1</cell><cell>4</cell><cell>2</cell><cell></cell><cell>0.8172</cell><cell>0.6283</cell><cell>0.9672</cell></row><row><cell>CIC-SDS.KN_2</cell><cell>5</cell><cell>3</cell><cell></cell><cell>0.7960</cell><cell>0.6248</cell><cell>0.7770</cell></row><row><cell>test_majority_class</cell><cell>47</cell><cell>-</cell><cell></cell><cell>-2.3585</cell><cell>0.1152</cell><cell>4.6115</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Results for Task 1 hard-hard evaluation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell cols="5">Rank Team Rank ICM-Hard ICM-Hard Norm F1</cell></row><row><cell>test_gold_hard</cell><cell></cell><cell>0</cell><cell>-</cell><cell>2.1533</cell><cell>1</cell><cell>1</cell></row><row><cell>Mario_3</cell><cell></cell><cell>1</cell><cell>1</cell><cell>0.6575</cell><cell cols="2">0.785 0.8109</cell></row><row><cell>CLassifiers_2</cell><cell></cell><cell>12</cell><cell>5</cell><cell>0.539</cell><cell cols="2">0.7095 0.7702</cell></row><row><cell>CLassifiers_3</cell><cell></cell><cell>18</cell><cell>5</cell><cell>0.5282</cell><cell cols="2">0.7026 0.7642</cell></row><row><cell>CLassifiers_1</cell><cell></cell><cell>21</cell><cell>5</cell><cell>0.5113</cell><cell cols="2">0.6918 0.7615</cell></row><row><cell cols="2">test_majority_class</cell><cell>66</cell><cell>-</cell><cell>-0.4413</cell><cell>0.0847</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,88.89,90.67,417.09,282.29"><head>Table 5</head><label>5</label><figDesc>Results for Task 3 soft-soft evaluation</figDesc><table coords="6,88.89,116.47,417.09,256.49"><row><cell>Run</cell><cell cols="4">Rank Team Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>test_gold_soft</cell><cell>0</cell><cell>-</cell><cell>9.4686</cell><cell>1</cell></row><row><cell>AI-UPV_3</cell><cell>1</cell><cell>1</cell><cell>-2.3183</cell><cell>0.7879</cell></row><row><cell>DRIM_1</cell><cell>4</cell><cell>2</cell><cell>-3.6842</cell><cell>0.7633</cell></row><row><cell>CLassifiers_1</cell><cell>6</cell><cell>4</cell><cell>-6.4072</cell><cell>0.7143</cell></row><row><cell>test_majority_class</cell><cell>15</cell><cell>-</cell><cell>-8.7089</cell><cell>0.6729</cell></row><row><cell>CLassifiers_2</cell><cell>20</cell><cell>4</cell><cell>-14.7828</cell><cell>0.5636</cell></row><row><cell>Table 6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Results for Task 3 hard-hard evaluation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell cols="4">Rank Team Rank ICM-Hard ICM-Hard Norm</cell></row><row><cell>test_gold_hard</cell><cell>0</cell><cell>-</cell><cell>2.1533</cell><cell>1</cell></row><row><cell>roh-neil_1</cell><cell>1</cell><cell>1</cell><cell>0.4433</cell><cell>0.6763</cell></row><row><cell>test_majority_class</cell><cell>27</cell><cell>-</cell><cell>-1.5984</cell><cell>0.2898</cell></row><row><cell>CLassifiers_2</cell><cell>29</cell><cell>13</cell><cell>-1.8664</cell><cell>0.2391</cell></row><row><cell>CLassifiers_1</cell><cell>30</cell><cell>13</cell><cell>-1.8852</cell><cell>0.2355</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>31</cell><cell>14</cell><cell>-2.1587</cell><cell>0.1838</cell></row><row><cell cols="5">while run 3 had an ICM-Hard score of 0.5282 and an ICM-Soft normalized score of 0.7026 and</cell></row><row><cell>was ranked 18th.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,200.91,393.32,9.74;7,112.66,214.46,393.57,9.74;7,112.33,228.01,68.33,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,227.67,200.91,278.30,9.74;7,112.66,214.46,228.12,9.74">Overt, covert, and subtle sexism: A comparison between the attitudes toward women and modern sexism scales</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">K</forename><surname>Swim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,348.81,214.46,144.40,9.74">Psychology of women quarterly</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="103" to="118" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,241.56,396.59,9.74;7,112.66,256.35,40.52,8.14" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,170.07,241.56,83.79,9.74">Sexism hurts us all</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Horowitz</surname></persName>
		</author>
		<idno type="DOI">10.1080/10130950.1997.9675610</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,261.12,241.56,34.68,9.74">Agenda</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="75" to="80" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,268.66,393.32,9.74;7,112.66,282.21,394.61,9.74;7,112.31,295.76,394.22,9.74;7,112.39,310.55,154.88,8.14" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,243.04,268.66,262.94,9.74;7,112.66,282.21,157.60,9.74">A systematic review of hate speech automatic detection using natural language processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Jahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oussalah</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2023.126232</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2023.126232" />
	</analytic>
	<monogr>
		<title level="j" coord="7,284.49,282.21,77.37,9.74">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">546</biblScope>
			<biblScope unit="page">126232</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,322.86,395.18,9.74;7,112.66,336.40,394.90,9.74" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="7,138.53,336.40,246.92,9.74">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,349.95,394.53,9.74;7,112.66,363.50,395.16,9.74;7,112.66,377.05,394.52,9.74;7,112.66,390.60,395.16,9.74;7,112.66,404.15,393.32,9.74;7,112.66,417.70,245.27,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,112.66,363.50,395.16,9.74;7,112.66,377.05,49.79,9.74">Overview of EXIST 2023 -learning with disagreement for sexism identification and characterization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,371.27,390.60,136.55,9.74;7,112.66,404.15,393.32,9.74;7,112.66,417.70,191.18,9.74">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,431.25,394.53,9.74;7,112.66,444.80,393.32,9.74;7,112.66,458.35,393.33,9.74;7,112.33,471.90,395.20,9.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,112.66,444.80,393.32,9.74;7,112.66,458.35,159.51,9.74">Overview of EXIST 2023 -learning with disagreement for sexism identification and characterization (extended overview)</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,141.67,471.90,335.72,9.74">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,485.45,393.32,9.74;7,112.66,498.99,395.16,9.74;7,112.66,512.54,394.52,9.74;7,112.66,526.09,363.01,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,339.80,485.45,166.18,9.74;7,112.66,498.99,205.24,9.74">XLM-T: Multilingual language models in Twitter for sentiment analysis and beyond</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.lrec-1.27" />
	</analytic>
	<monogr>
		<title level="m" coord="7,346.01,498.99,161.81,9.74;7,112.66,512.54,194.34,9.74">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="258" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,539.64,393.34,9.74;7,112.66,553.19,395.00,9.74;7,112.66,566.74,165.99,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,356.77,539.64,149.22,9.74;7,112.66,553.19,230.24,9.74">Automatic classification of sexism in social networks: An empirical study on twitter data</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3042604</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,349.86,553.19,52.64,9.74">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="219563" to="219576" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,580.29,393.33,9.74;7,112.66,593.84,393.32,9.74;7,112.28,607.39,361.35,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,284.66,580.29,221.33,9.74;7,112.66,593.84,27.66,9.74">Racist and sexist hate speech detection: Literature review</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Istaiteh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Omoush</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tedmori</surname></persName>
		</author>
		<idno type="DOI">10.1109/IDSTA50958.2020.9264052</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,164.05,593.84,341.94,9.74;7,112.28,607.39,92.89,9.74">2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="95" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,620.94,393.32,9.74;7,112.66,634.49,303.55,9.74" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,326.27,620.94,179.71,9.74;7,112.66,634.49,181.08,9.74">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,648.04,395.16,9.74;7,112.66,661.58,190.20,9.74" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m" coord="7,383.02,648.04,124.80,9.74;7,112.66,661.58,158.28,9.74">Improving language understanding by generative pre-training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,88.09,394.53,9.74;8,112.66,101.64,393.32,9.74;8,112.66,115.19,141.64,9.74" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<title level="m" coord="8,271.00,101.64,234.98,9.74;8,112.66,115.19,19.96,9.74">Unsupervised cross-lingual representation learning at scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,128.74,393.32,9.74;8,112.66,142.29,186.38,9.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,223.73,128.74,186.63,9.74">Cross-lingual language model pretraining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,418.76,128.74,87.23,9.74;8,112.66,142.29,141.59,9.74">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,155.84,395.16,9.74;8,112.66,169.38,395.00,9.74;8,112.66,184.18,89.53,8.14" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharifirad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10584</idno>
		<title level="m" coord="8,230.02,155.84,277.80,9.74;8,112.66,169.38,361.45,9.74">When a tweet is actually sexist. a more comprehensive classification of different online harassment categories and the challenges in NLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,196.48,394.53,9.74;8,112.66,210.03,395.00,9.74;8,112.66,223.58,61.59,9.74" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,112.66,210.03,295.94,9.74">Overview of EXIST 2021: sEXism Identification in Social neTworks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Comet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Donoso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Proces. del Leng. Natural</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,237.13,394.61,9.74;8,112.66,250.68,393.32,9.74;8,112.33,264.23,394.85,9.74;8,112.66,277.78,396.59,9.74;8,112.66,292.57,68.22,8.14" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,223.33,237.13,260.57,9.74">Evaluating extreme hierarchical multi-label classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Delgado</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.399</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.399.doi:10.18653/v1/2022.acl-long.399" />
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,250.68,393.32,9.74">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5809" to="5819" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,304.88,393.32,9.74;8,112.66,318.43,374.94,9.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,299.54,304.88,206.44,9.74;8,112.66,318.43,25.81,9.74">On the foundations of similarity in information access</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Giner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Verdejo</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-020-09375-z</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,146.70,318.43,131.43,9.74">Information Retrieval Journal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
