<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,317.35,15.42;1,89.29,106.66,341.07,15.42;1,89.29,128.58,302.63,15.43">Overview of EXIST 2023 -Learning with Disagreement for Sexism Identification and Characterization (Extended Overview)</title>
				<funder>
					<orgName type="full">UNED University</orgName>
				</funder>
				<funder ref="#_4Dwbmru">
					<orgName type="full">ERDF</orgName>
				</funder>
				<funder ref="#_vXHpbnu">
					<orgName type="full">European Union (NextGenerationEU funds)</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministry of Economic Affairs and Digital Transformation</orgName>
				</funder>
				<funder>
					<orgName type="full">EU</orgName>
				</funder>
				<funder ref="#_EA3s2Ab #_7Wsxwjy">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
				<funder ref="#_XxtbgsA #_tkHumFS">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.89,56.79,11.96"><forename type="first">Laura</forename><surname>Plaza</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<postCode>3000</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,169.99,156.89,130.85,11.96"><forename type="first">Jorge</forename><surname>Carrillo-De-Albornoz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<postCode>3000</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.77,156.89,72.05,11.96"><forename type="first">Roser</forename><surname>Morante</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.47,156.89,74.52,11.96"><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.10,170.84,66.02,11.96"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.76,170.84,74.67,11.96"><forename type="first">Damiano</forename><surname>Spina</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<postCode>3000</postCode>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.43,170.84,58.52,11.96"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Politécnica de Valencia (UPV)</orgName>
								<address>
									<postCode>46022</postCode>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,317.35,15.42;1,89.29,106.66,341.07,15.42;1,89.29,128.58,302.63,15.43">Overview of EXIST 2023 -Learning with Disagreement for Sexism Identification and Characterization (Extended Overview)</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">CC779F746E4100451D6D91366116C76D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>sexism detection</term>
					<term>sexism categorization</term>
					<term>learning with disagreement</term>
					<term>data bias</term>
					<term>EXIST</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, the rapid increase in the dissemination of offensive and discriminatory material aimed at women through social media platforms has emerged as a significant concern. This trend has had adverse effects on women's well-being and their ability to freely express themselves. The EXIST campaign has been promoting research in online sexism detection and categorization since 2021. The third edition of EXIST, hosted at the CLEF 2023 conference, consists of three tasks, two of which are the continuation of EXIST 2022 (sexism identification and sexism categorization), and a third and novel one is on source intention identification. For this edition, new test and training data are provided and the "learning with disagreement" paradigm is adopted to address disagreements in the labelling process and promote the development of equitable systems that are able to learn from different perspectives on the sexism phenomena. 28 teams participated in the three EXIST 2023 tasks, submitting 232 runs. This extended lab overview describes the tasks, the dataset, the participants' approaches, the evaluation methodology, and the results obtained.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="31" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="32" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="33" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="34" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="35" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="36" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="37" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="38" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="39" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="40" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="41" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="42" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Sexism is defined by the Oxford English Dictionary as "prejudice, stereotyping, or discrimination, typically against women, on the basis of sex". This phenomenon remains prevalent even in contemporary, developed societies, and among the younger generations who have grown up in democratic societies. Sexism continues to pose significant challenges for women in various areas of their lives, such as work, family life, and personal growth, acting as a barrier that impedes their progress.</p><p>Sexism manifests in many different forms and can be categorized according to different dimensions. Regarding the facet of the women that is attacked, we can find attitudes such as sexual objectification, stereotyping or patriarchy. Depending on the level of society at which discrimination occurs, we can find institutional sexism, interpersonal sexism and individual sexism. Depending on the expression and underlying motivation, sexism can be categorized into two main types: hostile sexism and benevolent sexism. While hostile sexism involves openly negative and antagonistic attitudes towards women, benevolent sexism appears positive but patronizing, involving protective attitudes towards women while still reinforcing restrictive gender roles. All forms of sexism, despite their differences, contribute to the perpetuation of gender inequality and restrict the full potential of women.</p><p>The persistence of gender inequality and discrimination against women in society is now being replicated and amplified in the online realm, as highlighted by Azmina et al. <ref type="bibr" coords="2,431.63,195.36,11.45,10.91" target="#b0">[1]</ref>. The Internet not only perpetuates these gender differences but also normalizes sexist attitudes, as noted by Burgos <ref type="bibr" coords="2,137.59,222.46,11.50,10.91" target="#b1">[2]</ref>. Specially concerning is the spread of sexist messages through social networks. Social networks have allowed women to rise their voices to report abuses, discrimination and sexist experiences, but the anonymity that they provide has also facilitated the transmission of hateful behaviours against women.</p><p>This issue is particularly worrying considering that a significant portion of Internet users, particularly teenagers and social media users, are exposed to this increasing wave of sexism. Previous studies <ref type="bibr" coords="2,166.88,303.75,12.99,10.91" target="#b2">[3]</ref> have shown that media content influences how social realities are perceived, so that the exposure to sexist and even misogynous content may contribute to develop sexist attitudes or to perceive them as natural or acceptable. Urgent attention is needed to comprehensively study and engage in a social debate surrounding this issue, leading to concrete actions, particularly in the realm of education. Moreover, social media platforms are not acting efficiently to remove or avoid sexist and hateful content.</p><p>Up to date, most work dealing with sexism in online media is focused on detecting misogyny or hatred towards women <ref type="bibr" coords="2,206.99,398.60,11.35,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,221.07,398.60,7.47,10.91" target="#b4">5,</ref><ref type="bibr" coords="2,231.26,398.60,7.56,10.91" target="#b5">6]</ref>. However, sexism does not always imply misogyny. Sexism may sound "friendly" as in <ref type="bibr" coords="2,209.64,412.15,10.39,10.91" target="#b0">(1)</ref>. Sexism may sound "funny", as in sexist jokes or humour <ref type="bibr" coords="2,477.55,412.15,10.39,10.91" target="#b1">(2)</ref>. Or sexism may sound "offensive" and "hateful", as in <ref type="bibr" coords="2,317.65,425.70,10.69,10.91" target="#b2">(3)</ref>. However, even the most subtle forms of sexism can be as pernicious as the most violent ones and affect women in many facets of their lives, including domestic and parenting roles, career opportunities, sexual image and life expectations, to name a few.</p><p>(1) Women must be loved and respected, always treat them like a fragile glass.</p><p>(2) You have to love women... just that... You will never understand them.</p><p>(3) Humiliate, expose and degrade yourself as the fucking bitch you are if you want a real man to give you attention.</p><p>EXIST 2023 (http://nlp.uned.es/exist2023/) at CLEF is the third edition of the EXIST (sEXism Identification in Social neTworks) challenge that aims at combating sexism on social media. In 2021 and 2022, the EXIST shared tasks were proposed at the IberLEF forum <ref type="bibr" coords="2,448.94,601.84,11.49,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,463.46,601.84,7.65,10.91" target="#b7">8]</ref>. These editions were the first in proposing tasks focusing on identifying and classifying online sexism in a broad sense, from explicit and/or hostile to other subtle or even benevolent expressions that involve implicit sexist behaviours. In the 2021 and 2022 EXIST editions, more than 50 teams participated from research institutions and companies from all around the world. While the two previous editions only focused on classifying sexist messages according to the facet of the women that was being undermined, the 2023 edition tackles an additional task consisting in determining the intention of the author of a sexist message. Since social networks are usually used to report and criticize sexist situations, it is important to distinguish the messages that aim to undermine women from those that report sexist experiences with the aim of raising awareness against sexism.</p><p>Additionally, the main novelty of the 2023 EXIST edition, and what makes it different to other recent initiatives such as the SemEval-2023 Shared Task 10: "Explainable Detection of Online Sexism" <ref type="bibr" coords="3,160.82,181.81,11.49,10.91" target="#b8">[9]</ref>, is the adoption of the "learning with disagreement" (LwD) paradigm <ref type="bibr" coords="3,488.02,181.81,17.97,10.91" target="#b9">[10]</ref> for the development of the dataset and for the evaluation of the systems. Our previous work showed that the perception of sexism is strongly dependent on the demographic and cultural background of the subject, so that when identifying sexist attitudes and expressions, and even when classifying them in different sexist categories, people sometimes disagree. In the LwD paradigm, instead of relying on a single "correct" label for each example, the model is trained to handle and learn from conflicting or diverse annotations. In this way, that different annotators' perspectives, biases, or interpretations may be taken taken into account by the systems and the learning process becomes fairer.</p><p>In addition to adopting the LwD paradigm, we have made an effort to control bias in the annotations (see Section 3) and have developed new evaluation metrics that take into account the disagreement. This will allow us to assess whether including the different views and sensibilities of the annotators contributes to the development of more accurate and equitable NLP systems.</p><p>In the following sections, we provide comprehensive information about the tasks, the dataset, the evaluation methodology, the results and the different approaches of the systems that participated in the EXIST 2023 Lab. The competition features three distinct tasks: (i) sexism identification, (ii) source intention classification, and (iii) sexism categorization. A total of 103 teams from 29 different countries registered to participate. Ultimately, we received 232 results from 28 teams, and 24 of them completed the process by submitting the working notes. Interestingly, a significant number of teams leveraged the diverse labels representing various demographic groups and provided soft labels as the outputs of their systems. Their results showcase the effectiveness and advantages of employing the LwD paradigm in our specific domain: sexism in social networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Tasks</head><p>The two first editions of EXIST focused on detecting sexist messages in two social networks, Twitter and Gab (https://gab.com/), as well as on categorizing these messages according to the type of sexist behaviour they enclose. For the 2023 edition, we focus on Twitter only and we address an additional task, namely "source intention classification". Therefore, three tasks are proposed which are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sexism Identification</head><p>The first task is a binary classification where systems must decide whether or not a given tweet expresses ideas related to sexism in any of the three forms: it is sexist itself, it describes a sexist situation in which discrimination towards women occurs, or criticizes a sexist behaviour. The following statements show examples of sexist and not sexist messages, respectively.</p><p>(4) Sexist: Woman driving, be careful!.</p><p>(5) Not sexist: Just saw a woman wearing a mask outside spank her very tightly leashed dog and I gotta say I love learning absolutely everything about a stranger in a single instant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Source Intention</head><p>This task aims to categorize the message according to the intention of the author. We propose a ternary classification of tweets: (i) direct sexist message, (ii) reported sexist message, and (iii) judgemental message. This distinction will allow us to differentiate sexism that is actually taking place online from sexism which is being suffered by women in other situations but that is being reported in social networks with the aim of complaining and fighting against sexism.</p><p>The three categories are defined as follows:</p><p>• Direct sexist message. The intention was to write a message that is sexist by itself or incites to be sexist, as in:</p><p>(6) Women shouldn't code...perhaps be influencer/creator instead...it's their natural strength.</p><p>• Reported sexist message. The intention is to report and share a sexist situation suffered by a woman or women in first or third person, as in:</p><p>(7) Today, one of my year 1 class pupils could not believe he'd lost a race against a girl.</p><p>• Judgemental message. The intention was judgmental, since the tweet describes sexist situations or behaviours with the aim of condemning them.</p><p>(8) 21st century and we are still earning 25% less than men #Idonotrenounce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Sexism Categorization</head><p>Many facets of a woman's life may be the focus of sexist attitudes including domestic and parenting roles, career opportunities, sexual image, and life expectations, to name a few. Automatically detecting which of these facets of women are being more frequently attacked in social networks will facilitate the development of policies to fight against sexism. According to this, each sexist tweet must be assigned one or more of the following categories:</p><p>• Ideological and inequality. This category includes all tweets that discredit the feminist movement in order to devalue, belittle and defame the struggle of women in any aspect of their lives. It also includes messages that reject inequality between men and women, or present men as victims of gender-based oppression. Some examples of this type of sexism discourse can be found in the following tweets:</p><p>(9) #Feminism is a war on men, but it's also a war on women. It's a war on female nature, a war on femininity.</p><p>• Role stereotyping and dominance. This category includes messages that express false ideas about women that suggest they are more suitable or inappropriate for certain tasks. It also includes any claim that implies that men are somehow superior to women. <ref type="bibr" coords="5,116.56,135.09,16.65,10.91" target="#b9">(10)</ref> Most women no longer have the desire or the knowledge to develop a high quality character, even if they wanted to.</p><p>• Objectification. Objectification and physical stereotyping includes messages where women are presented as objects apart from their dignity and personal aspects. We also include messages that assume or describe certain physical qualities that women must have in order to fulfill traditional gender roles, for example, ideas that suggest that women should maintain a standard and ideal of beauty or attacks on a woman's physique. <ref type="bibr" coords="5,116.56,244.87,16.65,10.91" target="#b10">(11)</ref> No offense but I've never seen an attractive african american hooker. Not a single one. • Misogyny and non sexual violence: this category includes expressions of hatred and violence towards women.</p><p>(13) Domestic abuse is never okay.... Unless your wife is a bitch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset: Managing Bias in Data and Providing Pre-aggregated Annotations</head><p>An important problem in NLP that has gained attention in the recent years in parallel to the growing protagonism of large language models is bias, both in the data that are used to train and test systems, and in the way algorithms learn, mainly due to the bias in the data <ref type="bibr" coords="5,472.98,459.71,16.40,10.91" target="#b10">[11]</ref>. In EXIST 2023 we tackle one aspect of this problem, i.e., the data bias that may be introduced both during the data selection and during the labeling process. Moreover, we adopt the "learning with disagreement" paradigm and provide all labels provided by the different annotators to allow systems to learn from conflicting and subjective information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Sampling</head><p>To gather the data, we follow the methodology used in previous EXIST editions <ref type="bibr" coords="5,442.81,563.64,11.30,10.91" target="#b6">[7,</ref><ref type="bibr" coords="5,456.83,563.64,7.53,10.91" target="#b7">8]</ref>. We first collected different popular expressions and terms, both in English and Spanish, commonly used to underestimate the role of women in our society. These expressions have been extracted from different sources: (a) previous works in the area; (b) Twitter accounts (journalist, teenagers, etc.) or hashtags used to report sexist situations; (c) expressions extracted from The Every Day Sexism Project (https://everydaysexism.com/); and d) a compendium of feminist dictionaries. These expressions were later used as seeds to retrieve Twitter data. To mitigate the seed bias, we have also gathered other common hashtags and expressions less frequently used in sexist contexts to ensure a balanced distribution between sexist/not sexist expressions. This first set of seeds contains more than 400 expressions. The set of seeds was then used to extract tweets in English and Spanish (more than 8,000,000 tweets were downloaded). The crawling was performed during the period from the September 1, 2021 till September 30, 2022. 100 tweets were downloaded for each seed per day (no retweets and promotional tweets were included). To ensure an appropriate balance between seeds, we removed those with less than 60 tweets. The final set of seeds contains 183 seeds for Spanish and 163 seeds for English.</p><p>To mitigate the terminology and temporal bias, the final sets of tweets were selected as follows: for each seed, approximately 20 tweets were randomly selected within the period from 1st September 1, February 28, 2022 for the training set, taking into account a representative temporal distribution between tweets of the same seed. Similarly, 3 tweets per seed were selected for the development set within the period from 1st to 31st May of 2022, and 6 tweets per seed within the period from August 1, 2022 to September, 30 2022 were selected for the test set. Only one tweet per author was included in the final selection to avoid author bias. Finally, tweets containing less than 5 words were removed. As a result, we have more than 3,200 tweets per language for the Training set, around 500 per language for the Development set, and nearly 1,000 tweets per language for the Test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Labeling Process</head><p>Before starting the annotation process we considered possible sources of label bias <ref type="bibr" coords="6,459.09,367.03,16.10,10.91" target="#b11">[12]</ref>. Label bias may be introduced by socio-demographic differences of the persons that participate in the annotation process.</p><p>The labeling of the data was carried out by crowd-workers. No personally identifiable information about the crowd-workers was collected. Workers were informed that the tweets could contain offensive information and were allowed to withdraw voluntarily at any time. Full consent was obtained. The workers were selected according to their different demographic characteristics in order to minimize the label bias. We consider gender (male/female) and age (18-22 y.o./23-45 y.o./+46 y.o). Each tweet was annotated by 6 crowdsourcing annotators selected through Prolific (https://www.prolific.co/). The Prolific crowdsourcing platform was specifically selected because of the features it provides to define participant criteria in the recruiting process -in our case, gender, age, and fluency in the different languages.</p><p>Different quality control mechanisms were employed, including small/medium size batches to ensure that the data is labeled by a significant/diverse amount of annotators, control of the time employed to perform the task, outlier analysis, and the use of attention mechanisms and ground truth data. We communicated frequently with the workers to solve doubts and to correct errors was kept.</p><p>The annotators were provided with annotation guidelines that included a detailed description of the different tasks along with numerous examples, both positive and negative, for all different categories/labels. The guidelines were developed by two experts in gender issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Guidelines for Annotators</head><p>Firstly, the annotators were informed that no identifying information would be obtained from them, and they were warned that they would be reading potentially violent messages that could be distressing. They were informed that they had the option to discontinue the task if they felt offended.</p><p>Secondly, the annotators were informed about the task, which involved reviewing 60 tweets individually. They were specifically instructed to read each tweet attentively in order to provide an answer to the following question: You stay alone". IMPORTANT NOTE: Remember that sexism may be expressed in different forms! It may sound friendly, funny, offensive, hateful or even violent. Sexism comprises any form of oppression or prejudice against women because of their sex. This discrimination can be based on different beliefs such as stereotypes, the belief that men are superior to women or irrational hatred of women (misogyny). Note that misogyny is a radical/hate-driven sexism.</p><p>If the answer to the previous question was YES, then the two following questions were showed to the annotators and had to be answered: 2. What do you think the intention of the person that wrote the tweet is? a) DIRECT: the intention is to write a message that is sexist by itself, as in: <ref type="bibr" coords="7,140.56,596.69,16.65,10.91" target="#b19">(20)</ref>  IMPORTANT NOTE: Sexism may affect women in many facets of their lives, including domestic and parenting roles, career opportunities, sexual image and life expectations, to name a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pre-aggregated Annotations: The Learning with Disagreement Paradigm</head><p>As stated in <ref type="bibr" coords="9,144.97,222.97,16.37,10.91" target="#b9">[10]</ref>, the assumption that natural language expressions have a single and clearly identifiable interpretation in a given context is a convenient idealization, but far from reality. To deal with this, Uma et al. <ref type="bibr" coords="9,220.07,250.07,18.07,10.91" target="#b9">[10]</ref> have proposed the Learning With Disagreement paradigm (LwD), which consists mainly in letting systems learn from datasets with information about the annotations from all annotators, in an attempt to gather the diversity of views. In the case of sexism identification, this is particularly relevant, since the perception of a situation as sexist or not can be subjective and may depend on the gender, age and cultural background of the person who is judging it. Following methods proposed for training directly from the data with disagreements, instead of using an aggregated label <ref type="bibr" coords="9,347.97,331.36,16.54,10.91" target="#b12">[13,</ref><ref type="bibr" coords="9,367.25,331.36,12.59,10.91" target="#b13">14,</ref><ref type="bibr" coords="9,382.57,331.36,12.40,10.91" target="#b14">15]</ref>, the EXIST 2023 dataset provides multiple annotations per example. The LwD paradigm may also help to mitigate bias and produce equitable NLP systems. The selection of annotators for the development of the EXIST 2023 dataset took into account the heterogeneity necessary to avoid gender and age biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">EXIST 2023 Dataset statistics</head><p>This section provides a detailed description of the EXIST 2023 dataset, which serves as a valuable resource for analyzing and understanding sexism detection in social media. The dataset encompasses a wide range of tweets from various countries and includes annotations provided by a diverse group of annotators. The distribution of data within the EXIST 2023 dataset is presented in Table <ref type="table" coords="9,172.95,489.48,3.69,10.91" target="#tab_3">1</ref>, highlighting the number of tweets, annotators, and countries represented in each subset (Training, Development, and Test). As shown in Table <ref type="table" coords="9,184.17,633.22,3.68,10.91" target="#tab_3">1</ref>, the EXIST 2023 dataset was created by large and diverse group of 1,065 annotators, who contributed to the annotation process. This diverse pool of annotators ensures a wide range of perspectives and enhances the representativeness of the dataset. The dataset includes annotators from 45 countries in the Training subset, 23 countries in the Development subset, and 28 countries in the Test subset. This broad representation across countries allows for cross-cultural analysis and provides a comprehensive view of the global understanding sexism on social media.</p><p>In total, the EXIST 2023 dataset consists of 10,034 annotated tweets. The Training subset contains the majority of the tweets with 6,920 samples, 3660 in Spanish and 3260 in English. The Dev and Test subsets contain 1,038 and 2,076 tweets, respectively, distributed in 549 in Spanish and 489 in English for the Development set and 1098 in Spanish and 978 in English for the Test set.</p><p>The final distribution of labels for Task 1 is shown in Figure <ref type="figure" coords="10,378.79,208.91,3.81,10.91" target="#fig_0">1</ref>. The label "YES" indicates that the annotator considered the tweet to be sexist, while the label "NO" indicates that the annotator determined that the tweet was non-sexist. The charts in Figure <ref type="figure" coords="10,408.94,236.01,4.97,10.91" target="#fig_0">1</ref> show the percentage of "YES" and "NO" labels in the three subsets. It can be seen that, in the three subsets, the distribution among sexist and not sexist tweet is well-balanced, being the "NO" label slightly more frequent than the "YES" one. Similarly, the distribution of labels for Task 2 is shown in Figure <ref type="figure" coords="10,377.29,479.89,3.66,10.91" target="#fig_1">2</ref>. The DIRECT label indicates that the annotator considered the tweet to be inherently sexist in their content. These tweets displayed explicit or overt sexist language or sentiments. On the other hand, the REPORTED label indicates that the annotator considered that the tweet was describing specific instances of sexist events or behaviors experienced by women. These tweets shed light on real-life incidents and their impact. Lastly, the JUDGEMENTAL label means that the annotator determined that the tweet made judgments about sexist acts or situations. These tweets expressed opinions or evaluations of sexist occurrences.</p><p>The charts in Figure <ref type="figure" coords="10,187.99,588.29,4.97,10.91" target="#fig_1">2</ref> show the percentage of "DIRECT" , "REPORTED" and "JUDGEMENTAL" labels in the three subsets. The distribution is homogeneous across the different datasets, being the "DIRECT" label the most frequent one (near 50%), followed by the "JUDGEMENTAL" label (around 28%), and finally the "REPORTED" label (around 25%).</p><p>Finally, the distribution of labels for Task 3 is shown in Figure <ref type="figure" coords="10,381.46,642.48,3.78,10.91" target="#fig_2">3</ref>. Again, the distribution of labels is quite homogenous across the three subsets, being the "STEREOTYPING-DOMINANCE" the most frequent label, followed by the "IDEOLOGICAL-INEQUALITY", "OBJECTIFICATION",  In order to provide a comprehensive analysis of the dataset, we present the statistics for the hard version of the dataset, i.e., that obtained by assigning to each tweet the majority vote among all annotators' labels following the methodology described in Section 6. However, as shown in Table <ref type="table" coords="11,127.80,520.42,3.74,10.91" target="#tab_4">2</ref>, this approach results in a significant loss of information in cases where annotators do not reach a consensus. It is important to note that disagreements among annotators were expected because, to some extent, they are inherent to subjective tasks such as sexism detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Lab Setup and Participation</head><p>The EXIST 2023 Lab was conducted and overseen via the website http://nlp.uned.es/exist2023/. Participants had access to task details, dataset information, as well as the registration and participation process on this website.</p><p>Although 103 teams from 29 different countries registered for participation, the number of participants who finally submitted results were 28, submitting 232 runs. Teams were allowed to participate in any of the three tasks and submit hard and/or soft outputs. Table <ref type="table" coords="12,444.86,386.08,5.10,10.91" target="#tab_5">3</ref> summarizes the participation in the different tasks and evaluation contexts. The evaluation campaign started on February 13, 2023 with the release of the training set. The development set was released on March 27, and the test set was made available on April 10. The participant teams were provided with the official evaluation script. Runs had to be submitted by May 15. Each team could submit up to three runs per task, that may contain soft and/or hard outputs.</p><p>For a comprehensive description of the systems submitted by the participants, please refer to Section 5 and to the participant papers. Here we summarize the main approaches. Approximately 90% of the systems submitted utilized large language models, both monolingual and multilingual. Some teams employed ensembles of multiple language models to enhance the overall performance. Only two teams utilized deep learning architectures such as BiLSTM, CNN, and RNN, while two others opted for traditional machine learning methods, including perceptrons, Naive Bayes, and SVM.</p><p>Data augmentation techniques were used by several teams, involving the translation of tweets, the utilization of data from similar tasks (such as previous EXIST editions), and the duplication of instances within the training set. Additionally, Twitter-specific models and transfer learning techniques from domains like hate speech, toxicity, and sentiment analysis were also utilized.</p><p>Most participants made use of the soft labels and applied the LwD paradigm, rather than opting for a traditional approach and providing only hard labels as outputs.</p><p>For each of the three tasks, the organization also provided different baseline runs:</p><p>• Majority class: non-informative baseline that classifies all instances as the majority class.</p><p>• Minority class: non-informative baseline that classifies all instances as the minority class. • Oracle most voted: hard approach that selects the most voted label following the same procedure as the one used to generate the gold hard. Note that this baseline is only employed in the hard-soft evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Overview of Approaches</head><p>In this section we provide a brief description of the approaches adopted by the participants. More detailed information of each work is provided in the working notes.</p><p>• Team AIT_FHSTP <ref type="bibr" coords="13,207.42,372.46,18.07,10.91" target="#b15">[16]</ref> utilized embeddings derived from a sentiment analysis and a toxicity analysis model, which were based on XLM_RoBERTa. These embeddings were then used to train a random forest model. Additionally, they explored the application of Principal Component Analysis. They obtained both soft and hard predictions for Tasks 1 and 2, while for Task 3, they only obtained a hard multi-label prediction. • The AI-UPV team <ref type="bibr" coords="13,199.31,441.56,17.76,10.91" target="#b16">[17]</ref> utilized BERT-base-multilingual uncased and XLM-RoBERTa-base.</p><p>They obtained both soft and hard predictions for all three tasks by employing ensembles to combine the probabilities from both models. • The Alex_P_UPB team <ref type="bibr" coords="13,221.47,483.57,17.75,10.91" target="#b17">[18]</ref> utilized the MiniLMv2 model <ref type="bibr" coords="13,367.91,483.57,16.09,10.91" target="#b18">[19]</ref>, a multilingual model based on deep self-attention distillation. The selection of the best parameters was performed manually, as the fine-tuning process involved using all the training data without any splits. They obtained both soft and hard predictions for all three tasks. • Team Awakened employed BiLSTM models along with sentence embeddings built using "pysentimiento/bertweet-hate-speech" for English and "cardiffnlp/twitter-xlm-robertabase-hate-spanish" for Spanish. They obtained both soft and hard predictions for all three tasks. • Team CIC-SDS.KN <ref type="bibr" coords="13,204.83,594.67,17.76,10.91" target="#b19">[20]</ref> participated only in the first task. They fine-tuned a multilingual language model called Bernice specifically for Twitter data. They used the proportion of annotators with a label of YES as the label for training. To obtain hard labels, they applied a rule where the model's prediction had to be greater than 0.5 to predict YES, and NO otherwise.</p><p>• Team CLassifiers <ref type="bibr" coords="14,198.58,86.97,17.77,10.91" target="#b20">[21]</ref> participated in Tasks 1 and 3 using a multilingual approach. They employed XLMRoBERTa for hard classification in Task 3 and the CardiffNLP Twitter XLM-RoBERTa for the hard approach in Task 1. For soft labels, they utilized the CardiffNLP Twitter XLM-RoBERTa model. In Task 1, they utilized data augmentation with EXIST 2021. For Task 3, they employed a cascade model using the model from Task 1. • Team CNLP-NITS-PP <ref type="bibr" coords="14,219.20,154.71,17.77,10.91" target="#b21">[22]</ref> utilized the GPT-2 model trained exclusively on the provided training dataset. They generated both soft and hard labels for Task 1, while only hard labels were provided for Tasks 2 and 3. • Team DRIM <ref type="bibr" coords="14,179.22,195.36,18.07,10.91" target="#b22">[23]</ref> performed fine-tuning on three BERT models separately for Task 1, Task 2, and Task 3. They then froze the models and concatenated them together, incorporating manual features such as tweet length and the number of hashtags. On top of the concatenated representation, they added three dense layers. For generating labels, they considered the possible distributions, which were finite and had values in multiples of 1/6 (reflecting the number of annotators). They selected the output that was closest to the possible distributions, providing both hard and soft labels for all three tasks. • Team I2C-Huelva-1 <ref type="bibr" coords="14,216.33,290.20,18.07,10.91" target="#b23">[24]</ref> explored various approaches for Task 1. They utilized an ensemble of models including bert-large-uncased, bert-base-uncased, and distilbert. Additionally, they employed a fine-tuned model based on distilbert_sexism from the Hugging Face library, as well as a fine-tuned model based on bert-large-uncased. • Team IIIT-Surat <ref type="bibr" coords="14,196.67,344.40,18.07,10.91" target="#b24">[25]</ref> exclusively participated in Task 1, utilizing a standard Bi-LSTM architecture to provide hard predictions. • Team InsightX <ref type="bibr" coords="14,189.96,371.50,18.01,10.91" target="#b25">[26]</ref> solely participated in Task 1, delivering both hard and soft predictions. They employed RoBERTa and BERT models for English and Spanish, along with monolingual transformers such as BERTTweet for English and distill-BERT for Spanish. • Team iimasGIL_NLP <ref type="bibr" coords="14,220.11,412.15,18.07,10.91" target="#b26">[27]</ref> participated in Tasks 1 and 3 providing both hard and soft labels. For the binary classification task (Task 1), they evaluated many linguistic patterns combined with bag-of-words and n-gram features as input in classical machine learning algorithms. For the intention and category of sexist messages categorization (Task 3), they fine-tuned transformers models in the English and Spanish datasets. • Team IUExist <ref type="bibr" coords="14,181.77,479.89,17.76,10.91" target="#b27">[28]</ref> participated in Task 1, providing both hard and soft predictions. They fine-tuned and optimized various models from huggingface, including XLM-Roberta Base, XLM-Roberta Large, TWHIN Base, and TWHIN Large. Additionally, they utilized extended data from previous EXIST datasets. They trained an XGB Classifier using the predictions generated by the four mentioned models and evaluated its performance on the development dataset. They employed multilingual models and data augmentation techniques with EXIST 2021. • Team IU-NLP-JeDi <ref type="bibr" coords="14,206.78,574.74,17.80,10.91" target="#b28">[29]</ref> participated in Task 1, providing both hard and soft predictions.</p><p>They explored various approaches, including SVM with TF-IDF on bigrams and trigrams, as well as CNN and RNN models. • Team IU-Percival <ref type="bibr" coords="14,202.27,615.39,17.93,10.91" target="#b29">[30]</ref> participated in Task 1, providing both hard and soft predictions.</p><p>They employed a traditional machine learning approach using single-layer perceptrons and utilized 1-, 2-, and 3-grams as features. • Team JPM-UNED <ref type="bibr" coords="14,202.24,656.03,18.01,10.91" target="#b30">[31]</ref> participated in Task 1 and Task 2, providing both hard and soft predictions. They utilized data augmentation techniques by translating tweets from one language to another and trained different models for each cohort based on the gender and age of the annotators. The best-performing models employed were "PlanTL-GOB-ES/roberta-base-bne" for Spanish and "distilbert-base-uncased" for English. • Team KUCST participated in all three tasks, providing only hard labels. They trained a gradient boosting classifier for Task 1 and Task 2, and employed a separate classifier for each label in Task 3. Their feature set included Bag of Words, TF-IDF weighted words, POS tags, n-grams, morphological features, and BERT representations. • Team M&amp;S NLP <ref type="bibr" coords="15,195.63,184.52,18.07,10.91" target="#b31">[32]</ref> participated in Task 1 and Task 2, providing both hard and soft labels. In Task 3, they provided only soft labels. To address imbalanced classes, they employed text augmentation techniques. Their approach involved the use of multiple transformers, including BERT, XLM-RoBERTa, and DistilBERT. • Team Mario <ref type="bibr" coords="15,174.16,240.07,17.76,10.91" target="#b32">[33]</ref> participated in all three tasks, providing both hard and soft labels. They</p><p>utilized the "open-source GPT-NeoX" model for English and the "BERTIN-GPT-J-6B" model for Spanish. Their approach involved organizing the LLMs in cascades. One model was fine-tuned with in-domain training data for all three tasks, while the other hate-speech boosted model was sequentially fine-tuned on various hate speech datasets, including an open-sourced hate-speech tweets dataset from the Hugging Face library in the respective target language (English or Spanish). Finally, both models were fine-tuned with task-specific training data. • Team MART participated solely in Task 1, providing hard labels. They employed various pre-processing techniques, such as TF-IDF vectorization, emoji/abbreviation replacement, accent removal, tokenization, stop words removal, and lemmatization. In addition, they utilized a standard BERT model for their approach. • Team roh-neil <ref type="bibr" coords="15,187.19,405.37,18.01,10.91" target="#b33">[34]</ref> participated in the three tasks, providing both hard and soft labels.</p><p>They utilized the "xlm-roberta-large-twitter" model from HuggingFace and employed Optuna for parameter optimization. Additionally, they incorporated data augmentation techniques by leveraging data from previous editions of EXIST. • Team shm2023 participated exclusively in Task 1, providing hard labels. They employed the "bert-lapse" embedded model to embed the tweets, and then utilized a random forest algorithm to predict the results based on the embedded text. • Team SINAI <ref type="bibr" coords="15,177.26,502.93,18.07,10.91" target="#b34">[35]</ref> participated in the three tasks, providing hard and soft labels. They utilized the mDeBERTa base model and employed data augmentation techniques by replicating instances. Additionally, they incorporated categorical information of the annotators, such as gender and age, during the training process. They experimented with different strategies to incorporate this information, such as concatenating the transformer output and the categorical features, applying a multilayer perceptron on the categorical features, or using attention-based summation of the transformer outputs and categorical features, among others. • Team SMS <ref type="bibr" coords="15,167.47,612.68,18.03,10.91" target="#b35">[36]</ref> participated in Tasks 1 and 2, providing hard and soft labels for Task 1, and hard labels for Task 2. They utilized 200-dimensional GloVe Twitter word embeddings for English texts and 300-dimensional FastText word embeddings for Spanish texts, along with an LSTM layer. For the calculation of the soft score, they aimed to replicate human annotator performance by using different models and aggregating the probabilities predicted by these models. The ensemble of models included Multinomial Naive Bayes, Linear Support Vector Classifier, Multi-Layer Perceptron, XGBoost, LSTM using GloVe embeddings, and LSTM using FastText embeddings. The probabilities predicted by these models were combined to derive the soft score. • Team Tlatlamiztli <ref type="bibr" coords="16,208.77,141.50,18.07,10.91" target="#b36">[37]</ref> participated in Task 1, providing both hard and soft labels.</p><p>Their approach involves preprocessing the data using regex, spaCy, spaCymoji, and wordsegment libraries. They further perform translation to Spanish using the Googletrans library. They then utilize a RoBERTuito model that has been fine-tuned on the EXIST 2021 dataset. This multilingual model allows for the classification of hate speech in both English and Spanish. • Team UMU Team <ref type="bibr" coords="16,201.45,223.12,17.89,10.91" target="#b37">[38]</ref> participated in all three tasks. They provided both hard and soft labels for Tasks 1 and 2, and only hard labels for Task 3. Their approach involved using a combination of different Large Language Models (LLMs) with Label Functions (LFs) and training them on multilingual data. They also experimented with the use of sentence embeddings extracted from MarIA and mDeBERTa models. • Team UniBo <ref type="bibr" coords="16,178.08,291.20,18.01,10.91" target="#b38">[39]</ref> participated in all three tasks, providing hard labels. They employed a translation approach to convert the Spanish data into English using the Google API. Additionally, they enriched their feature set by incorporating Emotions retrieved using EmoBerta, which were added as features to the RobertaHate embeddings. • Team ZaRa-IU-NLP <ref type="bibr" coords="16,214.99,345.73,18.07,10.91" target="#b39">[40]</ref> participated in Task 1 providing only hard labels. They test two different models: XML-RoBERTa and RoBERTa+ BETO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation Methodology and Metrics</head><p>As in SemEval 2021, we have carried out a "hard evaluation" and a "soft evaluation". In the hard evaluation paradigm, both the system and the gold standard consist of one or more labels assigned to each instance in the dataset. In contrast, the soft evaluation is intended to measure the ability of the model to capture disagreements, by considering the probability distribution of labels in the output as a soft label and comparing it with the probability distribution of the annotations.</p><p>From the point of view of evaluation metrics, the tasks can be described as follows:</p><p>• Task 1 (sexism identification): binary classification, monolabel.</p><p>• Task 2 (source intention): multiclass hierarchical classification, monolabel. The hierarchy of classes has a first level with two categories, sexist/not sexist, and a second level for the sexist category with three mutually-exclusive subcategories: direct/reported/judgemental. A suitable evaluation metric must reflect the fact that a confusion between not sexist and a sexist category is more severe than a confusion between two sexist subcategories. • Task 3 (sexism categorization): multiclass hierarchical classification, multilabel. Again the first level is a binary distinction between sexist/not sexist, and there is a second level for the sexist category that includes five subcategories: ideological and inequality, stereotyping and dominance, objectification, sexual violence, and misogyny and nonsexual violence. These classes are not mutually exclusive: a tweet may belong to several subcategories at the same time.</p><p>The LwD paradigm can be considered in both sides of the evaluation process:</p><p>• The ground truth. In a "hard" setting, the variability in the human annotations is reduced by selecting one and only one gold category per instance, the hard label. In a "soft" setting, the gold standard label for one instance is the set of all the human annotations existing for that instance. Therefore, the evaluation metric incorporates the proportion of human annotators that have selected each category (soft labels). Note that in Tasks 1 and 2, which are monolabel problems, the sum of probabilities of each class must be one. But in Task 3, which is multilabel, each annotator may select more than one category for a single instance. Therefore, the sum of probabilities of each class may be larger than one. • The system output. In a "hard", traditional setting, the system predicts one or more categories for each instance. In a "soft" setting, the system predicts a probability for each category, for each instance. The evaluation score is maximized when the probabilities predicted match the actual probabilities in a soft ground truth.</p><p>In EXIST 2023, for each of the tasks, three types of evaluation have been performed:</p><p>1. Soft-soft evaluation. For systems that provide probabilities for each category, we provide a soft-soft evaluation that compares the probabilities assigned by the system with the probabilities assigned by the set of human annotators. The probabilities of the classes for each instance are calculated according to the distribution of labels and the number of annotators for that instance. We use a modification of the original ICM metric (Information Contrast Measure <ref type="bibr" coords="17,290.03,379.43,15.74,10.91" target="#b40">[41]</ref>), ICM-Soft (see details below), as the official evaluation metric in this variant and we also provide results for the normalized version of ICM-Soft (ICM-Soft Norm). It is important to note that ICM is a measure that quantifies information, and its upper and lower bounds are +∞ and -∞, respectively. To normalize the results, we used the gold standard score as the upper bound and minority class baseline (see Section 4) as the lower bound. We also provide results for Cross Entropy. 2. Hard-hard evaluation. For systems that provide a hard, conventional output, we provide a hard-hard evaluation. To derive the hard labels in the ground truth from the different annotators' labels, we use a probabilistic threshold computed for each task. As a result, for Task 1, the class annotated by more than 3 annotators is selected; for Task 2, the class annotated by more than 2 annotators is selected; and for Task 3 (multilabel), the classes annotated by more than 1 annotator are selected. The instances for which there is no majority class (i.e., no class receives more probability than the threshold) are removed from this evaluation scheme. The official metric for this task is the original ICM, as defined by Amigó and Delgado <ref type="bibr" coords="17,218.96,570.47,16.09,10.91" target="#b40">[41]</ref>. We also report a normalized version of ICM (ICM Norm) and F1. In Task 1, we use F1 for the positive class. In Tasks 2 and 3, we use the average of F1 for all classes. Note, however, that F1 is not ideal in our experimental setting: although it can handle multilabel situations, it does not take into account the relationships between classes. In particular, a confusion between not sexist and any of the sexist subclasses, and a confusion between two of the sexist subclasses, are penalized equally. 3. Hard-soft evaluation. For systems that provide a hard output, we will also provide a hardsoft evaluation comparing the categories assigned by the system with the probabilities assigned to each category in the ground truth. As in the previous case, we use ICM-Soft as the official evaluation metric in this variant. In this evaluation, the hard outputs are transformed into soft outputs by assigning a probability of 1.0 to the selected class and 0.0 to the other classes.</p><p>ICM is a similarity function that generalizes Pointwise Mutual Information (PMI), and can be used to evaluate system outputs in classification problems by computing their similarity to the ground truth. The general definition of ICM is:</p><formula xml:id="formula_0" coords="18,178.74,205.85,237.81,10.63">ICM(𝐴, 𝐵) = 𝛼 1 𝐼𝐶(𝐴) + 𝛼 2 𝐼𝐶(𝐵) -𝛽𝐼𝐶(𝐴 ∪ 𝐵)</formula><p>Where 𝐼𝐶(𝐴) is the Information Content of the instance represented by the set of features A. ICM maps into PMI when all parameters take a value of 1. The general definition of ICM by <ref type="bibr" coords="18,103.38,252.25,18.07,10.91" target="#b40">[41]</ref> is applied to cases where categories have a hierarchical structure and instances may belong to more than one category. The resulting evaluation metric is proved to be analytically superior to the alternatives in the state of the art. The definition of ICM in this context is:</p><formula xml:id="formula_1" coords="18,152.59,307.17,290.09,9.57">ICM(𝑠(𝑑), 𝑔(𝑑)) = 2𝐼𝐶(𝑠(𝑑)) + 2𝐼𝐶(𝑔(𝑑)) -3𝐼𝐶(𝑠(𝑑) ∪ 𝑔(𝑑))</formula><p>Where 𝐼𝐶() stands for Information Content, 𝑠(𝑑) is the set of categories assigned to document 𝑑 by system 𝑠, and 𝑔(𝑑) the set of categories assigned to document 𝑑 in the gold standard.</p><p>As there is not, to the best of our knowledge, any current metric that fits hierarchical multilabel classification problems in a learning with disagreement scenario, we have defined an extension of ICM (ICM-soft) that accepts both soft system outputs and soft ground truth assignments. ICM-soft works as follows: first, we define the Information Content of a single assignment of a category 𝑐 with an agreement 𝑣 to a given instance: 𝐼({⟨𝑐, 𝑣⟩}) = -log 2 (𝑃 ({𝑑 ∈ 𝐷 : 𝑔 𝑐 (𝑑) ≥ 𝑣}) Note that the information content of assigning a category 𝑐 with an agreement 𝑣 grows inversely with the probability of finding an instance that receives category 𝑐 with agreement equal or larger than 𝑣. To this end, we compute the mean and deviation of the agreement levels for each class across instances, and applying the cumulative probability over the inferred normal distribution. Note that, in the case of zero variance, we must consider that the probability for values equals or below the mean is 1 (zero IC) and the probability for values above the mean must be smoothed.</p><p>The system output and the gold standards are sets of assignments. Therefore, in order to estimate their information content, we apply a recursive function similar to the one described by Amigó and Delgado <ref type="bibr" coords="18,194.59,576.83,16.25,10.91" target="#b40">[41]</ref>.</p><formula xml:id="formula_2" coords="18,178.16,607.93,328.42,64.71">𝐼𝐶 (︃ 𝑛 ⋃︁ 𝑖=1 {⟨𝑐 𝑖 , 𝑣 𝑖 ⟩} )︃ = 𝐼𝐶(⟨𝑐 1 , 𝑣 1 ⟩) + 𝐼𝐶 (︃ 𝑛 ⋃︁ 𝑖=2 {⟨𝑐 𝑖 , 𝑣 𝑖 ⟩} )︃ -𝐼𝐶 (︃ 𝑛 ⋃︁ 𝑖=2 {⟨lca(𝑐 1 , 𝑐 𝑖 ), 𝑚𝑖𝑛(𝑣 1 , 𝑣 𝑖 )⟩} )︃<label>(33)</label></formula><p>where lca(𝑎, 𝑏) is the lowest common ancestor of categories 𝑎 and 𝑏. Within that definition, ICM accepts multi-class, multi-label, hierarchical and soft classification problems. Hard labels or large soft values assigned to infrequent classes produce high information quantity. The class specificity affects both the successes and the failures. The more the system and the gold standard differ to each other, the more their labelling conjunction is unlikely, the more the joint information quantity IC(S,G) is high, and the more the resulting score is low.</p><p>For example, if the system output and the gold standard are equal then IC(S)=IC(G)=IC(S,G) and the score is proportional to the gold standard information content (ICM=IC(G)). If the system does not label any class (empty system output) then IC(S)=0 and IC(S,G)=IC(G). Therefore, the score is negative and proportional to the gold standard information quantity (ICM=-IC(G)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results</head><p>In the next subsections, we report the results of the participants and the baseline systems for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Task 1 Sexism Identification</head><p>We first report and analyze the results for Task 1, which focuses on sexism identification. This task involves a binary classification. As discussed in Section 6, we report three sets of evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1.">Soft-Soft Evaluation</head><p>Table <ref type="table" coords="19,117.41,420.79,5.17,10.91" target="#tab_6">4</ref> presents the results for this evaluation context. 54 runs were submitted. 46 runs outperformed the non-informative majority class baseline (all instances are labeled as "NO"), while 51 runs surpassed the non-informative minority class baseline (all instances are labeled as "YES").</p><p>Looking at the results in Table <ref type="table" coords="19,239.91,474.98,3.78,10.91" target="#tab_6">4</ref>, we observe a notable variation in the performance of the runs, ranging from an ICM-Soft score of 0.903 (equivalent to a 64% ICM-Soft Norm) to -5.6659 (lower than the empirically determined lower bound). However, it is worth mentioning that the best run only reached a 64% ICM-Soft Norm. Once again, this scores are due to the fact that ICM-Soft highly penalize errors in the minority class, which is really remarkable in a binary classification task. Also, this suggests that there is still room for improvement when it comes to capturing the appropriate distribution that represents real data.</p><p>These findings highlight the complexity of modeling the distribution of disagreements in a subjective task such as sexism identification. We next analyze the performance of the top ten systems. As shown in Table <ref type="table" coords="21,444.65,410.15,3.78,10.91" target="#tab_6">4</ref>, the top five systems achieve similar results in terms of ICM-Soft, with a difference of less than 2% percentage points in terms of ICM-Soft Norm. The difference among the top ten systems was also less than 4% percentage points.</p><p>Among the top ten systems, the top nine utilized multilingual learning models, while the tenth system used a monolingual Spanish model. The variations between the systems primarily stemmed from the use of data augmentation techniques, such as in the fourth and tenth ranked systems, as well as the incorporation of domain-specific Twitter models and ensembles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2.">Hard-Hard Evaluation</head><p>Table <ref type="table" coords="21,115.40,554.33,4.99,10.91" target="#tab_8">5</ref> presents the results for the hard-hard evaluation. In this scenario, the annotations from the six annotators are combined into a single label using the majority vote, resulting in the loss of information about the different perspectives provided by each annotator. Out of the 67 systems submitted for this task, 65 ranked above the majority class baseline (all instances labeled as "NO"). All systems surpassed the minority class baseline (all instances labeled as "YES").</p><p>Similar to the soft-soft evaluation, the results vary considerably for the ICM-Hard metric, ranging from 0.6575 (78.50% ICM-Hard Norm) to -0.5335 (2.59%). However, the impact of this variation is not as prominent when considering the F1 score, indicating that ICM-Hard penalizes systems that predominantly suggest only one class for all instances more severely. For example, systems like "shm2023_1" labeled 2063 out of 2076 instances as "NO" , while "M&amp;S_NLP_3" labeled 1594 out of 2076 instances as "YES", thus getting very poor results in the ICM metrics.</p><p>Furthermore, the comparison between the ICM-Hard and F1 scores, as reflected in the ranking, shows a similar distribution, particularly at the top of the table. A strong correlation between the two metrics has been observed. However, in contrast to the soft-soft evaluation, the behavior of the best systems in the hard-hard evaluation aligns more closely with the gold standard. This highlights the higher complexity of the soft scenario and the inherent differences between the soft and hard evaluation contexts As shown in Table <ref type="table" coords="24,187.84,206.92,3.81,10.91" target="#tab_8">5</ref>, the performance of the top ten runs is more remarkable in the hard context evaluation, with a difference of 7% percentage points in terms of ICM-Hard Norm. This difference is primarily due to the good performance of the top three systems ("Mario" team) which outperform the 4th ranked system by 5%. The "Mario" team utilizes a cascade model consisting of two fine-tuned monolingual GPT-based models trained on EXIST 2023 data and on data from other related hate speech tasks. Interestingly, the efficiency of the "Mario" team's runs in the soft context is considerably lower, as they are ranked 14th, 15th, and 16th. Among the other top ten teams, all of them employ multilingual approaches, with some using Twitter-specific models and none utilizing data augmentation techniques. It is also worth noting the performance of the "CIS-SDK.KN" team, which achieves similar rankings in both evaluations (5th and 6th in the soft context, and 6th and 7th in hard context).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3.">Hard-Soft Evaluation</head><p>The hard-soft evaluation context aims to assess the impact of information loss when using the majority vote strategy. Although the results of the soft-soft and hard-soft evaluations are not strictly comparable, they provide insights into the performance of hard systems compared to soft systems in a real-world context.</p><p>The evaluation included 67 systems, 65 outperformed the majority class baseline (all instances labeled as "NO"), and all surpassed the minority class baseline (all instances labeled as "YES"). Notably, the loss of information in the hard-soft context was more significant than expected when compared to the soft-soft context. This had a clear impact on the behaviour of the systems, as evidenced by the first-ranked system achieving 64.21% in terms of ICM-Soft in the soft-soft evaluation context compared to the 57.25% achieved in the hard-soft context. This phenomenon is also reflected in the performance of the "EXIST2023_oracle_most_vote" baseline, which considers the most voted label by the annotators, and achieves a score of 1.1977 in the hard-soft context and a score of 3.1182 in the soft-soft context.</p><p>Also interesting is the difference found between the first system, with a score of 0.4719 in ICM-Soft, and the oracle most voted baseline, where a large difference can be seen. This difference is, in general, very pronounced in all the results obtained by all participants, specially in those at the end of the table, in this evaluation context. This fact, again, suggests that the errors made by the systems in the minority class are strongly penalised by the ICM-Soft metric, and that these errors are especially identifiable in the hard-soft context. Regarding the analysis of the top ten systems, the first five positions are exactly the same as in the hard-hard evaluation context, while the next four represent the same systems but in different positions. The only system that has changed in the top ten ranking is SINAI_3, ranked in the 11th position in the hard-hard and ranked 10th in hard-soft. In fact, this behaviour is observed in nearly all the systems in the ranking, suggesting a high correlation between both contexts and metrics, with small variations mainly due to the strong weight given to probabilities in the hard-soft case (classes are assigned with probability 1.0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Task 2 Source Intention</head><p>The second task is a hierarchical multiclass classification problem where systems must determine whether a tweet is sexist or not, and categorize the sexist tweets according to the source intention in: JUDGEMENTAL, REPORTED and DIRECT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1.">Soft-Soft evaluation</head><p>Table <ref type="table" coords="27,117.02,183.96,5.17,10.91" target="#tab_13">7</ref> presents the results for the soft-soft evaluation of Task 2. The table shows that 25 runs were submitted. Among them, 21 runs achieved better results compared to the majority class baseline (where all instances are labeled as "NO"). Furthermore, all of the submitted runs outperformed the minority class baseline (where all instances are labeled as "REPORTED"). The differences between the scores achieved by the gold standard and the worst-performing system, the non-informative minority class baseline, are higher compared to Task 1. This can be attributed to the hierarchical and multiclass nature of Task 2, which allows for a wider range of values in the quantification of information by the ICM-Soft metric. It is also worth noting the correlation between the ICM-Soft and Cross-Entropy measures. The results indicate a strong correlation between the two metrics, but some differences can still be observed. Our initial analysis suggests that ICM-Soft is better at capturing the hierarchical nature of the task, as evidenced by a preliminary analysis of runs "JPM_UNED_2" and "SINAI_3". This observation is further supported by the fact that "JPM_UNED_2" utilizes a cascade model to determine whether a tweet is sexist or not sexist as a first step. However, further analysis is required to confirm this observation. The top-performing run achieved a score of -1.3443 in terms of ICM-Soft, which is quite similar to the scores obtained by the other top nine systems. The tenth system achieved a score of -2.5674, resulting in a difference of only 3.1% in terms of ICM-Soft normalized. The first system ("DRIM_1") proposed an ensemble model consisting of three monolingual models, each trained on one of the three EXIST tasks. These models were fine-tuned using the ICM-Soft measure and optimized with manual features and annotator distribution information to calculate similarities.</p><p>Regarding the other nine systems, most of them utilized multilingual models, with the exception of "JPM_UNED". The systems employed a combination of techniques such as data augmentation, transfer learning, and ensembles, as in the previous task. One notable difference among the top ten systems is the use of socio-demographic knowledge by the "JPM_UNED" team, where six models were trained for each population's cohort to calculate the final distribution of probabilities.</p><p>Finally, upon comparing the performance of the top ten systems in Task 1 and Task 2 in the soft-soft context, we find that the "AI-UPV_2" and "SINAI_3" teams consistently excel in accurately identifying sexism content and its properties in both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2.">Hard-Hard Evaluation</head><p>Table <ref type="table" coords="28,116.84,594.97,5.17,10.91" target="#tab_15">8</ref> presents the results of the hard-hard evaluation for Task 2, where 33 systems were assessed against the hard gold standard. 28 runs outperform the majority class baseline (all instances labeled as "NO"), while all systems demonstrate superior performance compared to the minority class baseline (all instances labeled as "REPORTED"). Similar to the soft-soft evaluation context, the discrepancies between the gold standard and the worst-performing system (minority class baseline) are higher in Task 2 than in Task 1. The correlation between ICM-Hard and F1 is generally high, with slight variations observed among the top-ranked systems, and higher variability towards the end of the table. This discrepancy can be attributed to the inability of F1 to capture the hierarchical nature of the task, unlike ICM-Hard, which penalizes misclassifications between different levels of the hierarchy more severely. Regarding the comparison between the top ten runs in terms of the ICM-Hard, the first system ("Mario_2") achieves a score of 0.4887 and the tenth system ("JPM_UNED_3") achieves a score of 0.1806 (only a 6.6% point difference). Unlike the previous task and context evaluation, where multilingual models were predominant, this task comprises an equal presence of multilingual and monolingual approaches among the top systems. Specifically, the first-ranked system is a monolingual GPT-based model that utilizes transfer learning and a cascade approach to identify and filter sexist tweets. The other top systems employ similar techniques, including transfer learning, data augmentation, and Twitter domain-specific models. Once again, the "JPM_UNED" team stands out as the only top-performing system that leverages the demographic features of the annotators, training six models, one for each cohort. It is interesting to note the comparison with Task 1 in the hard-hard context, where the systems from the "roh-neil" and "Mario" teams are also among the top 5 in the ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3.">Hard-Soft Evaluation</head><p>In this evaluation, 35 hard approaches were evaluated against the soft gold standard. Only 2 systems outperformed the majority class baseline, while all systems showed significant improvement over the minority class baseline. This behaviour is attributed to the fact that ICM-Soft penalizes errors in the minority classes to a greater extent, as they provide more informative signals than the majority classes. This observation gains further significance in this context for two reasons: the increasing number of classes and the absolute probabilities assigned to hard labels (hard labels are interpreted in this context as soft labels with probability 1.0). Also significant is that the difference between the gold standard and participants' systems is even more pronounced than in Task 1. This can be attributed to the multiclass and hierarchical nature of the task, which presents additional complexities.</p><p>Finally, when comparing the results with the soft-soft evaluation, similar trends were observed as in Task 1. The system that performed the best in the soft-soft evaluation achieved an ICM-Soft Norm score of 80.72%, while the top-performing system in the hard-soft evaluation scored 71.08%. In the context of the hard-soft evaluation, the discussion of the top ten systems reveals several interesting findings. Firstly, the best-performing system is based on a monolingual model for Spanish, highlighting the effectiveness of language-specific approaches in contrast with previous evaluations. Interestingly, when comparing the results between the first-ranked system, excluding the majority vote baseline, and the tenth-ranked system, the differences are minimal. The discrepancy is less than 1 point in the ICM-Soft metric and 4 percentage points in the normalized metric, suggesting a similar performance. Moreover, the remaining systems are a mix of monolingual and multilingual models, employing ensemble techniques and data augmentation. Surprisingly, two teams utilizing deep learning (LSTM), and traditional ML (gradient boosting), have achieved top 10 results. A preliminary analysis suggests that these types of techniques tend to prioritize the majority class, which, when correctly classified, contributes to overall higher accuracy. These conclusions, however, should be considered preliminary, and further analysis within this context is necessary to provide a comprehensive comparison between the hard and soft evaluation contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Task 3 Sexism Categorization</head><p>The third task is the most challenging one since is a hierarchical multiclass and multilabel classification problem, where systems must determine if a tweet is sexist or not, and categorize the sexist tweets according to the five categories of sexism defined in Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1.">Soft-Soft Evaluation</head><p>Table <ref type="table" coords="32,116.95,389.26,10.35,10.91" target="#tab_18">10</ref> displays the results of the soft-soft evaluation for Task 3. A total of 23 runs were submitted, with 14 runs surpassing the majority class baseline (all instances labeled as "NO"), and all systems outperforming the minority class baseline (all instances labeled as "SEXUAL-VIOLENCE"). This highlights the complexity of categorizing sexism in social networks. The comparison among the system scores and the gold standard further emphasizes this difficulty, with a notable difference of more than 10 points in ICM-Soft scores: 9.4686 for the gold standard and -2.3183 for the best system ("AI-UPV_3"). Additionally, the differences between the best and the worst systems are significantly higher than in any of the previous tasks. However, despite the complexity, the results of the ICM-Soft Norm metric indicate that the systems are still able to correctly capture relevant information concerning the different types of sexism. The best system in this task utilizes an ensemble approach with two multilingual models that have been optimized with the number of annotators to calculate probability distributions, achieving an ICM-Soft score of -2.3183. The differences between the top ten systems in this task are higher compared to previous tasks, with a nearly 9% difference in terms of ICM-Soft Norm between the 1st and 10th system. In terms of the techniques employed by the top ten systems, the prevalent architecture is multilingual, often combined with data augmentation techniques, domain-specific models for Twitter, and ensembles. It is noteworthy that the "AI-UPV_2" and "SINAI_3" teams consistently perform well in all three soft-soft evaluation tasks, securing a position in the top ten of the ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2.">Hard-Hard Evaluation</head><p>In the hard-hard evaluation context for the last task, a total of 30 systems were submitted. As shown in Table <ref type="table" coords="33,158.51,615.39,8.20,10.91" target="#tab_20">11</ref>, 26 systems outperformed the majority class baseline (all instances labeled as "NO"), while all systems achieved better results than the minority class baseline (all instances labeled as "SEXUAL-VIOLENCE"). Similar to Task 2, the discrepancies between the gold standard and the worst-performing system (minority class baseline) are higher in Task 3 due to its more complex nature of being hierarchical, multiclass, and multilabel.</p><p>The variation in results among different runs follows a similar distribution to that observed in Task 2, except for the last four systems which obtained substantially lower results due to that a high number of not sexist instances have been incorrectly assigned to different sexist subclasses, resulting in a strong penalization by the ICM-Hard metric that considers the class hierarchy.</p><p>The correlation between the F1 and the ICM-Hard measure is not as strong as in Task 2. This can be attributed to the fact that the ICM-Hard measure takes into account the hierarchy and penalizes errors between hierarchy levels more severely.</p><p>Finally, comparing the behaviour of the different tasks in a hard-hard context, the efficiency of the systems in this task, in terms of ICM-Hard Norm, is substantially lower than in previous tasks, further highlighting the complexity of categorizing sexism. As in the soft-soft evaluation of Task 3, the differences among the top ten systems are higher than in other tasks, up to 8% points between the 1st ("roh-neil_1") and 10th ("SINAI_3") systems. In this scenario, the best system proposed a multilingual domain specific model trained on Twitter data, and uses parameter optimization using the Optuna framework. Roughly an equal number of systems utilized monolingual and multilingual approaches. The majority of these systems employed a combination of techniques, including data augmentation, domainspecific models, and transfer learning. Interestingly, the only team that exploit the demographic knowledge is the "SINAI" team. Upon analyzing the performance of the top ten hard approaches across all tasks, it is evident that the "Mario" and "roh-neil" teams consistently achieve favorable results, ranking within the top 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.3.">Hard-Soft Evaluation</head><p>Finally, we provide a brief summary of the main findings for the hard-soft evaluation. In this evaluation, a total of 30 systems were evaluated, and none of them outperformed the majority class baseline, while all of them improved upon the minority class baseline. As mentioned in the hard-soft evaluation for Task 2, the ICM-Soft measure heavily penalizes errors in the minority classes, while errors in the majority class are not as heavily penalized. This behaviour is particularly significant in the hard-soft evaluation due to the automatic assignment of higher probabilities to the hard labels, and specially significant when the number of classes augmented. Also, the multi-label nature of the task amplifies the significance of penalizing errors in the minority class even further. In the context of sexism categorization, where multiple labels can be present simultaneously, correctly identifying and classifying instances belonging to the minority classes becomes increasingly challenging. Therefore, the importance of addressing the issue of penalization in the context of the minority classes cannot be overstated, as it directly affects the accuracy and fairness of the system's predictions. Finally, when comparing the results with the soft-soft evaluation, we observe that the best performance system in the soft-soft evaluation achieved an ICM-Soft Norm score of 78.79%, while the top-performing system in the hard-soft evaluation scored 66.52%. This difference is even larger than that found in Tasks 1 and 2, once again highlighting the complex nature of the task. In the hard-soft evaluation, the best-performing system is a monolingual GPT-based model. The differences between the first-ranked system, excluding the baselines, and the 10th-ranked system are more noticeable compared to previous tasks, reaching up more than 5 percentage points in terms of the normalized ICM-Soft metric. The remaining systems in the top 10 primarily Furthermore, it is important to note that these results are preliminary, and a more comprehensive comparative analysis between the soft evaluation context and the hard evaluation context should be conducted to draw more robust conclusions from the hard-soft evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">The Information Contrast Model Analysis</head><p>In this campaign, ICM is applied over both hard (discrete labels) and soft outputs and gold standards. Figure <ref type="figure" coords="37,169.48,426.86,5.12,10.91" target="#fig_3">4</ref> shows the correlation between ICM (hard output and hard gold standard) and F1. In these charts, the dashed line represents the score for the empty system output (ICM=-I(G)). According to the graphs, in the hard-hard evaluation, all systems contribute to a certain extent regarding the empty output. Generally, there is a high correlation when ICM is positive, although in Task 3, there are not enough samples to notice it. The reason is that ICM penalises failures in infrequent classes (which have more information quantity) to a greater extent than F1. Particularly in Task 1 and Task 2, an interesting point is that ICM discriminates "returning always the minority class" (red point) from the rest of outputs to a greater extent than F1.</p><p>In Figure <ref type="figure" coords="37,144.00,548.80,3.81,10.91" target="#fig_4">5</ref>, we compare the ICM scores when considering the hard output (discrete class) versus soft outputs. The gold standard in both cases is soft. As the graphs show, both scores differ substantially. In general, considering hard outputs (vertical axis) often leads to a decrease ICM, especially when considering more than two classes. This means that hard outputs are missing out on a lot of information when they restrict themselves to outputting one or a few classes in hard mode. Once again, the dashed line in the ICM on soft outputs represents "doing nothing" (ICM=-I(G)). Here, it can be observed that as the task becomes more complex, there are more systems that contributes with useful information (Task 3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>The objective of the EXIST challenge is to encourage research on the automated detection and modeling of sexism in online environments, with a specific focus on social networks. The EXIST Lab held in 2023 as part of CLEF garnered significant interest, attracting over 100 registered teams for participation. We received a total of 232 submissions. Participants adopted a wide range of approaches including data augmentation through automatic translation, data duplication and utilization of past EXIST editions' data, multilingual language models, Twitterspecific language models, and transfer learning techniques from domains such as hate speech, toxicity, and sentiment analysis. Fortunately, most participants chose to leverage the multiple annotations available and embrace the LwD paradigm, rather than opting for a traditional approach and providing only hard labels as outputs.</p><p>In addition to obtaining new insights into the detection and categorization of sexist messages in social networks, the Lab has also contributed to raise awareness about the importance of addressing annotator disagreements and label bias by selecting annotators from diverse population groups. This is particularly true for tasks where subjectivity and moral considerations come into play, and interpretations may vary across cultures and over time. Moreover, the EXIST lab has provided a valuable dataset that can be utilized for future experimentation and benchmarking purposes, further contributing to the advancement of research in this field.</p><p>For future editions of EXIST, we plan to extend our study to other languages, communication channels and media, as well as studying sexism in particular scenarios and population groups.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,89.29,450.54,319.13,8.93;10,89.29,299.08,416.69,138.90"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of labels by subset for Task 1 in the EXIST 2023 dataset</figDesc><graphic coords="10,89.29,299.08,416.69,138.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,89.29,207.87,319.13,8.93;11,130.96,84.19,333.34,111.11"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of labels by subset for Task 2 in the EXIST 2023 dataset</figDesc><graphic coords="11,130.96,84.19,333.34,111.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,89.29,450.06,319.13,8.93;11,89.29,298.60,416.69,138.90"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distribution of labels by subset for Task 3 in the EXIST 2023 dataset</figDesc><graphic coords="11,89.29,298.60,416.69,138.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="37,89.29,200.66,297.33,8.93;37,89.29,84.19,416.68,103.91"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Correspondence between F1 and the ICM metrics across tasks</figDesc><graphic coords="37,89.29,84.19,416.68,103.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="38,89.29,194.15,416.69,8.93;38,89.29,206.15,416.69,8.87;38,88.93,218.11,153.47,8.87;38,89.29,84.19,416.69,102.53"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Correspondence of ICM between hard and soft outputs. The figures show that considering hard outputs substantially decreases the ICM scores, suggesting that relevant information is missed when discretizing the system outputs</figDesc><graphic coords="38,89.29,84.19,416.69,102.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,107.28,265.90,398.91,45.48"><head>•</head><label></label><figDesc>Sexual violence. This category includes messages where sexual suggestions, requests or harassment of a sexual nature (rape or sexual assault) are made:</figDesc><table /><note coords="5,116.56,300.47,329.96,10.91"><p>(12) I wanna touch your tits..you can't imagine what I can do on your body.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.99,532.04,400.33,72.82"><head>Table 1</head><label>1</label><figDesc>Number of tweets, annotators and countries of annotators per partition in the EXIST 2023 dataset</figDesc><table coords="9,194.99,559.73,205.30,45.13"><row><cell></cell><cell cols="3">Annotators Countries Tweets</cell></row><row><cell>Training</cell><cell>725</cell><cell>45</cell><cell>6,920</cell></row><row><cell>Development</cell><cell>113</cell><cell>23</cell><cell>1,038</cell></row><row><cell>Test</cell><cell>227</cell><cell>28</cell><cell>2,076</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,88.99,90.49,392.32,240.76"><head>Table 2 EXIST</head><label>2</label><figDesc></figDesc><table coords="12,111.48,102.49,369.83,228.76"><row><cell cols="2">2023 dataset hard labels statistics</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell></cell><cell cols="3">Development</cell><cell></cell><cell>Test</cell><cell></cell></row><row><cell></cell><cell>ES</cell><cell>EN</cell><cell cols="7">Total ES EN Total ES EN Total</cell></row><row><cell>Task 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NO</cell><cell cols="5">1634 1733 3367 229 250</cell><cell>479</cell><cell cols="2">491 489</cell><cell>980</cell></row><row><cell>YES</cell><cell cols="5">1560 1137 2697 261 194</cell><cell>455</cell><cell cols="2">478 349</cell><cell>827</cell></row><row><cell>Task 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DIRECT</cell><cell>749</cell><cell>545</cell><cell cols="3">1294 117 87</cell><cell>204</cell><cell cols="2">244 152</cell><cell>396</cell></row><row><cell>REPORTED</cell><cell>265</cell><cell>194</cell><cell>459</cell><cell>40</cell><cell>35</cell><cell>75</cell><cell>78</cell><cell>45</cell><cell>123</cell></row><row><cell>JUDGEMENTAL</cell><cell>228</cell><cell>148</cell><cell>376</cell><cell>55</cell><cell>28</cell><cell>83</cell><cell>78</cell><cell>75</cell><cell>153</cell></row><row><cell>Task 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>OBJECTIFICATION</cell><cell>611</cell><cell>492</cell><cell>1103</cell><cell>88</cell><cell>95</cell><cell>183</cell><cell cols="2">194 150</cell><cell>344</cell></row><row><cell>SEXUAL-VIOLENCE</cell><cell>359</cell><cell>316</cell><cell>675</cell><cell>74</cell><cell>49</cell><cell>123</cell><cell>99</cell><cell>97</cell><cell>196</cell></row><row><cell>STEREOTYPING-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DOMINANCE</cell><cell>810</cell><cell>613</cell><cell cols="3">1423 136 105</cell><cell>241</cell><cell cols="2">257 187</cell><cell>444</cell></row><row><cell>IDEOLOGICAL-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>INEQUALITY</cell><cell>632</cell><cell>481</cell><cell cols="3">1113 117 95</cell><cell>212</cell><cell cols="2">223 161</cell><cell>384</cell></row><row><cell>MISOGYNY-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">NON-SEXUAL-VIOLENCE 552</cell><cell>304</cell><cell>856</cell><cell>90</cell><cell>68</cell><cell>158</cell><cell cols="2">166 109</cell><cell>275</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,88.99,428.64,314.87,73.22"><head>Table 3</head><label>3</label><figDesc>Runs submitted per task and evaluation scenario</figDesc><table coords="12,188.92,456.33,214.94,45.53"><row><cell></cell><cell cols="2">Task 1</cell><cell cols="2">Task 2</cell><cell cols="2">Task 3</cell></row><row><cell></cell><cell cols="6">Hard Soft Hard Soft Hard Soft</cell></row><row><cell># runs</cell><cell>67</cell><cell>54</cell><cell>33</cell><cell>25</cell><cell>30</cell><cell>23</cell></row><row><cell># teams</cell><cell>28</cell><cell></cell><cell>15</cell><cell></cell><cell>14</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="20,135.86,95.45,323.55,577.78"><head>Table 4 :</head><label>4</label><figDesc>Systems' results for Task 1 in the soft-soft evaluation</figDesc><table coords="20,135.86,109.40,323.55,563.83"><row><cell>Run</cell><cell cols="4">Rank ICM-Soft ICM-Soft Norm Cross Entropy</cell></row><row><cell>Gold_soft</cell><cell>0</cell><cell>3.1182</cell><cell>1</cell><cell>0.5472</cell></row><row><cell>SINAI_3</cell><cell>1</cell><cell>0.9030</cell><cell>0.6421</cell><cell>0.7960</cell></row><row><cell>CLassifiers_3</cell><cell>2</cell><cell>0.9027</cell><cell>0.6421</cell><cell>0.9754</cell></row><row><cell>CLassifiers_2</cell><cell>3</cell><cell>0.8698</cell><cell>0.6368</cell><cell>0.9823</cell></row><row><cell>CLassifiers_1</cell><cell>4</cell><cell>0.8172</cell><cell>0.6283</cell><cell>0.9672</cell></row><row><cell>CIC-SDS.KN_2</cell><cell>5</cell><cell>0.7960</cell><cell>0.6248</cell><cell>0.7770</cell></row><row><cell>CIC-SDS.KN_3</cell><cell>6</cell><cell>0.7555</cell><cell>0.6183</cell><cell>0.7620</cell></row><row><cell>AI-UPV_2</cell><cell>7</cell><cell>0.7343</cell><cell>0.6149</cell><cell>1.3607</cell></row><row><cell>CIC-SDS.KN_1</cell><cell>8</cell><cell>0.7200</cell><cell>0.6126</cell><cell>0.7846</cell></row><row><cell>IUEXIST_1</cell><cell>9</cell><cell>0.7115</cell><cell>0.6112</cell><cell>1.1537</cell></row><row><cell>Tlatlamiztli_1</cell><cell>10</cell><cell>0.6879</cell><cell>0.6074</cell><cell>1.0538</cell></row><row><cell>UMUTeam_1</cell><cell>11</cell><cell>0.6818</cell><cell>0.6064</cell><cell>0.8707</cell></row><row><cell>JPM_UNED_1</cell><cell>12</cell><cell>0.6779</cell><cell>0.6058</cell><cell>0.8023</cell></row><row><cell>AI-UPV_3</cell><cell>13</cell><cell>0.6772</cell><cell>0.6056</cell><cell>1.6400</cell></row><row><cell>Mario_1</cell><cell>14</cell><cell>0.6696</cell><cell>0.6044</cell><cell>1.9247</cell></row><row><cell>Mario_2</cell><cell>15</cell><cell>0.6629</cell><cell>0.6033</cell><cell>1.8536</cell></row><row><cell>Mario_3</cell><cell>16</cell><cell>0.6603</cell><cell>0.6029</cell><cell>1.9503</cell></row><row><cell>IUEXIST_2</cell><cell>17</cell><cell>0.6141</cell><cell>0.5955</cell><cell>1.8418</cell></row><row><cell>JPM_UNED_2</cell><cell>18</cell><cell>0.5972</cell><cell>0.5927</cell><cell>0.8852</cell></row><row><cell>AIT_FHSTP_3</cell><cell>19</cell><cell>0.5955</cell><cell>0.5924</cell><cell>0.9392</cell></row><row><cell>AIT_FHSTP_1</cell><cell>20</cell><cell>0.5648</cell><cell>0.5875</cell><cell>1.1491</cell></row><row><cell>AI-UPV_1</cell><cell>21</cell><cell>0.5448</cell><cell>0.5843</cell><cell>1.5543</cell></row><row><cell>DRIM_1</cell><cell>22</cell><cell>0.5433</cell><cell>0.5840</cell><cell>0.8932</cell></row><row><cell>UMUTeam_2</cell><cell>23</cell><cell>0.4969</cell><cell>0.5765</cell><cell>0.8100</cell></row><row><cell>SINAI_1</cell><cell>24</cell><cell>0.4863</cell><cell>0.5748</cell><cell>1.5759</cell></row><row><cell>Alex_P_UPB_1</cell><cell>25</cell><cell>0.3214</cell><cell>0.5482</cell><cell>1.1709</cell></row><row><cell>SMS_1</cell><cell>26</cell><cell>0.3142</cell><cell>0.5470</cell><cell>1.6650</cell></row><row><cell>SMS_2</cell><cell>27</cell><cell>0.3142</cell><cell>0.5470</cell><cell>1.6650</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>28</cell><cell>0.2990</cell><cell>0.5445</cell><cell>0.8496</cell></row><row><cell>JPM_UNED_3</cell><cell>29</cell><cell>0.2467</cell><cell>0.5361</cell><cell>2.2342</cell></row><row><cell>M&amp;S_NLP_2</cell><cell>30</cell><cell>0.1802</cell><cell>0.5254</cell><cell>0.9724</cell></row><row><cell>IU-NLP-JeDi_3</cell><cell>31</cell><cell>0.1244</cell><cell>0.5163</cell><cell>1.0878</cell></row><row><cell>InsightX_2</cell><cell>32</cell><cell>-0.0357</cell><cell>0.4905</cell><cell>0.9122</cell></row><row><cell>Awakened_2</cell><cell>33</cell><cell>-0.1496</cell><cell>0.4721</cell><cell>0.8706</cell></row><row><cell>IU-NLP-JeDi_2</cell><cell>34</cell><cell>-0.1499</cell><cell>0.4720</cell><cell>0.9097</cell></row><row><cell>InsightX_1</cell><cell>35</cell><cell>-0.2351</cell><cell>0.4583</cell><cell>0.9145</cell></row><row><cell>UMUTeam_3</cell><cell>36</cell><cell>-0.3460</cell><cell>0.4403</cell><cell>0.9318</cell></row><row><cell>Awakened_3</cell><cell>37</cell><cell>-0.4369</cell><cell>0.4257</cell><cell>0.9282</cell></row><row><cell>IU-Percival_2</cell><cell>38</cell><cell>-0.4435</cell><cell>0.4246</cell><cell>3.1682</cell></row><row><cell></cell><cell></cell><cell cols="2">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="21,135.86,86.43,323.55,276.81"><head>Table 4 -continued from previous page</head><label>4</label><figDesc></figDesc><table coords="21,135.86,102.97,323.55,260.27"><row><cell>Run</cell><cell cols="4">Rank ICM-Soft ICM-Soft Norm Cross Entropy</cell></row><row><cell>IU-Percival_1</cell><cell>39</cell><cell>-0.4612</cell><cell>0.4217</cell><cell>3.1777</cell></row><row><cell>IU-Percival_3</cell><cell>40</cell><cell>-0.5491</cell><cell>0.4075</cell><cell>3.2560</cell></row><row><cell cols="2">CNLP-NITS-PP_2 41</cell><cell>-0.5775</cell><cell>0.4029</cell><cell>2.0155</cell></row><row><cell>Awakened_1</cell><cell>42</cell><cell>-0.5931</cell><cell>0.4004</cell><cell>0.9625</cell></row><row><cell>InsightX_3</cell><cell>43</cell><cell>-0.6356</cell><cell>0.3936</cell><cell>0.9402</cell></row><row><cell cols="2">iimasGIL_NLP_3 44</cell><cell>-1.9161</cell><cell>0.1867</cell><cell>1.8619</cell></row><row><cell cols="2">iimasGIL_NLP_2 45</cell><cell>-1.9438</cell><cell>0.1822</cell><cell>1.8151</cell></row><row><cell cols="2">iimasGIL_NLP_1 46</cell><cell>-2.1678</cell><cell>0.1460</cell><cell>2.2546</cell></row><row><cell>Majority_class</cell><cell>47</cell><cell>-2.3585</cell><cell>0.1152</cell><cell>4.6115</cell></row><row><cell>M&amp;S_NLP_3</cell><cell>48</cell><cell>-2.4596</cell><cell>0.0989</cell><cell>3.1670</cell></row><row><cell>roh-neil_2</cell><cell>49</cell><cell>-2.8848</cell><cell>0.0302</cell><cell>1.5472</cell></row><row><cell>roh-neil_1</cell><cell>50</cell><cell>-2.8851</cell><cell>0.0301</cell><cell>7.3091</cell></row><row><cell>roh-neil_3</cell><cell>51</cell><cell>-2.8851</cell><cell>0.0301</cell><cell>6.7608</cell></row><row><cell>Minority_class</cell><cell>52</cell><cell>-3.0717</cell><cell>0</cell><cell>5.3572</cell></row><row><cell>I2C-Huelva-1_3</cell><cell>53</cell><cell>-4.0609</cell><cell>-0.1598</cell><cell>2.5776</cell></row><row><cell>I2C-Huelva-1_1</cell><cell>54</cell><cell>-4.1626</cell><cell>-0.1762</cell><cell>2.4439</cell></row><row><cell>I2C-Huelva-1_2</cell><cell>55</cell><cell>-4.3175</cell><cell>-0.2013</cell><cell>2.9025</cell></row><row><cell>SINAI_2</cell><cell>56</cell><cell>-5.6559</cell><cell>-0.4175</cell><cell>7.3080</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="22,149.09,238.84,297.10,432.27"><head>Table 5 :</head><label>5</label><figDesc>Systems' results for Task 1 in the hard-hard evaluation</figDesc><table coords="22,149.09,256.32,297.10,414.79"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>Gold_hard</cell><cell>0</cell><cell>0.9948</cell><cell>1</cell><cell>1</cell></row><row><cell>Mario_3</cell><cell>1</cell><cell>0.6575</cell><cell>0.7850</cell><cell>0.8109</cell></row><row><cell>Mario_1</cell><cell>2</cell><cell>0.6540</cell><cell>0.7828</cell><cell>0.8058</cell></row><row><cell>Mario_2</cell><cell>3</cell><cell>0.6120</cell><cell>0.7560</cell><cell>0.8029</cell></row><row><cell>roh-neil_1</cell><cell>4</cell><cell>0.5795</cell><cell>0.7353</cell><cell>0.7840</cell></row><row><cell>roh-neil_2</cell><cell>5</cell><cell>0.5795</cell><cell>0.7353</cell><cell>0.7840</cell></row><row><cell>CIC-SDS.KN_2</cell><cell>6</cell><cell>0.5715</cell><cell>0.7302</cell><cell>0.7775</cell></row><row><cell>CIC-SDS.KN_3</cell><cell>7</cell><cell>0.5647</cell><cell>0.7259</cell><cell>0.7721</cell></row><row><cell>SINAI_1</cell><cell>8</cell><cell>0.5584</cell><cell>0.7219</cell><cell>0.7804</cell></row><row><cell>SINAI_2</cell><cell>9</cell><cell>0.5543</cell><cell>0.7192</cell><cell>0.7719</cell></row><row><cell>roh-neil_3</cell><cell>10</cell><cell>0.5474</cell><cell>0.7149</cell><cell>0.7754</cell></row><row><cell>SINAI_3</cell><cell>11</cell><cell>0.5440</cell><cell>0.7127</cell><cell>0.7715</cell></row><row><cell>CLassifiers_2</cell><cell>12</cell><cell>0.5390</cell><cell>0.7095</cell><cell>0.7702</cell></row><row><cell>UniBo_1</cell><cell>13</cell><cell>0.5381</cell><cell>0.7089</cell><cell>0.7716</cell></row><row><cell>UniBo_2</cell><cell>14</cell><cell>0.5381</cell><cell>0.7089</cell><cell>0.7716</cell></row><row><cell>IUEXIST_2</cell><cell>15</cell><cell>0.5341</cell><cell>0.7064</cell><cell>0.7717</cell></row><row><cell>IUEXIST_1</cell><cell>16</cell><cell>0.5313</cell><cell>0.7046</cell><cell>0.7734</cell></row><row><cell>CIC-SDS.KN_1</cell><cell>17</cell><cell>0.5303</cell><cell>0.7040</cell><cell>0.7677</cell></row><row><cell>CLassifiers_3</cell><cell>18</cell><cell>0.5282</cell><cell>0.7026</cell><cell>0.7642</cell></row><row><cell>JPM_UNED_3</cell><cell>19</cell><cell>0.5223</cell><cell>0.6989</cell><cell>0.7623</cell></row><row><cell>AI-UPV_3</cell><cell>20</cell><cell>0.5119</cell><cell>0.6922</cell><cell>0.7574</cell></row><row><cell>CLassifiers_1</cell><cell>21</cell><cell>0.5113</cell><cell>0.6918</cell><cell>0.7615</cell></row><row><cell>AI-UPV_2</cell><cell>22</cell><cell>0.5106</cell><cell>0.6914</cell><cell>0.7589</cell></row><row><cell>AIT_FHSTP_2</cell><cell>23</cell><cell>0.5086</cell><cell>0.6901</cell><cell>0.7571</cell></row><row><cell>UMUTeam_2</cell><cell>24</cell><cell>0.5083</cell><cell>0.6899</cell><cell>0.7604</cell></row><row><cell>I2C-Huelva-1_1</cell><cell>25</cell><cell>0.5075</cell><cell>0.6894</cell><cell>0.7611</cell></row><row><cell>I2C-Huelva-1_2</cell><cell>26</cell><cell>0.5075</cell><cell>0.6894</cell><cell>0.7611</cell></row><row><cell>I2C-Huelva-1_3</cell><cell>27</cell><cell>0.5075</cell><cell>0.6894</cell><cell>0.7611</cell></row><row><cell></cell><cell cols="3">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="23,149.09,86.43,297.10,580.37"><head>Table 5 -continued from previous page</head><label>5</label><figDesc></figDesc><table coords="23,149.09,102.97,297.10,563.83"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>JPM_UNED_1</cell><cell>28</cell><cell>0.5057</cell><cell>0.6883</cell><cell>0.7560</cell></row><row><cell>UMUTeam_1</cell><cell>29</cell><cell>0.5053</cell><cell>0.6880</cell><cell>0.7611</cell></row><row><cell cols="2">iimasGIL_NLP_3 30</cell><cell>0.5024</cell><cell>0.6862</cell><cell>0.7568</cell></row><row><cell>Tlatlamiztli_1</cell><cell>31</cell><cell>0.5013</cell><cell>0.6855</cell><cell>0.7535</cell></row><row><cell>MART_1</cell><cell>32</cell><cell>0.4937</cell><cell>0.6806</cell><cell>0.7587</cell></row><row><cell>JPM_UNED_2</cell><cell>33</cell><cell>0.4863</cell><cell>0.6759</cell><cell>0.7533</cell></row><row><cell>AIT_FHSTP_1</cell><cell>34</cell><cell>0.4850</cell><cell>0.6751</cell><cell>0.7550</cell></row><row><cell>AIT_FHSTP_3</cell><cell>35</cell><cell>0.4832</cell><cell>0.6739</cell><cell>0.7544</cell></row><row><cell cols="2">iimasGIL_NLP_1 36</cell><cell>0.4751</cell><cell>0.6688</cell><cell>0.7484</cell></row><row><cell>AI-UPV_1</cell><cell>37</cell><cell>0.4700</cell><cell>0.6655</cell><cell>0.7445</cell></row><row><cell>MART_2</cell><cell>38</cell><cell>0.4672</cell><cell>0.6637</cell><cell>0.7490</cell></row><row><cell cols="2">iimasGIL_NLP_2 39</cell><cell>0.4626</cell><cell>0.6608</cell><cell>0.7477</cell></row><row><cell>Alex_P_UPB_1</cell><cell>40</cell><cell>0.4021</cell><cell>0.6222</cell><cell>0.7302</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>41</cell><cell>0.3975</cell><cell>0.6193</cell><cell>0.7202</cell></row><row><cell>ZaRa-IU-NLP_2</cell><cell>42</cell><cell>0.3914</cell><cell>0.6154</cell><cell>0.7305</cell></row><row><cell>Awakened_2</cell><cell>43</cell><cell>0.3623</cell><cell>0.5969</cell><cell>0.7222</cell></row><row><cell>M&amp;S_NLP_2</cell><cell>44</cell><cell>0.3057</cell><cell>0.5608</cell><cell>0.6820</cell></row><row><cell>IU-Percival_1</cell><cell>45</cell><cell>0.3024</cell><cell>0.5587</cell><cell>0.6971</cell></row><row><cell>IU-Percival_2</cell><cell>46</cell><cell>0.2964</cell><cell>0.5549</cell><cell>0.6981</cell></row><row><cell>ZaRa-IU-NLP_1</cell><cell>47</cell><cell>0.2842</cell><cell>0.5471</cell><cell>0.6955</cell></row><row><cell>IU-NLP-JeDi_3</cell><cell>48</cell><cell>0.2753</cell><cell>0.5414</cell><cell>0.6909</cell></row><row><cell>InsightX_2</cell><cell>49</cell><cell>0.2689</cell><cell>0.5373</cell><cell>0.6883</cell></row><row><cell>IU-NLP-JeDi_1</cell><cell>50</cell><cell>0.2676</cell><cell>0.5365</cell><cell>0.6872</cell></row><row><cell>IU-Percival_3</cell><cell>51</cell><cell>0.2675</cell><cell>0.5365</cell><cell>0.6907</cell></row><row><cell>SMS_3</cell><cell>52</cell><cell>0.2469</cell><cell>0.5233</cell><cell>0.6717</cell></row><row><cell>InsightX_1</cell><cell>53</cell><cell>0.2458</cell><cell>0.5226</cell><cell>0.6809</cell></row><row><cell>SMS_1</cell><cell>54</cell><cell>0.2369</cell><cell>0.5170</cell><cell>0.6787</cell></row><row><cell>SMS_2</cell><cell>55</cell><cell>0.2369</cell><cell>0.5170</cell><cell>0.6787</cell></row><row><cell>UMUTeam_3</cell><cell>56</cell><cell>0.1882</cell><cell>0.4859</cell><cell>0.6639</cell></row><row><cell>IU-NLP-JeDi_2</cell><cell>57</cell><cell>0.1851</cell><cell>0.4839</cell><cell>0.6485</cell></row><row><cell>Awakened_3</cell><cell>58</cell><cell>0.1457</cell><cell>0.4588</cell><cell>0.6400</cell></row><row><cell cols="2">CNLP-NITS-PP_1 59</cell><cell>0.1093</cell><cell>0.4356</cell><cell>0.6409</cell></row><row><cell cols="2">CNLP-NITS-PP_2 60</cell><cell>0.1093</cell><cell>0.4356</cell><cell>0.6409</cell></row><row><cell>IIIT SURAT_1</cell><cell>61</cell><cell>0.1042</cell><cell>0.4324</cell><cell>0.6355</cell></row><row><cell>Awakened_1</cell><cell>62</cell><cell>0.0723</cell><cell>0.4120</cell><cell>0.6322</cell></row><row><cell>InsightX_3</cell><cell>63</cell><cell>-0.0403</cell><cell>0.3403</cell><cell>0.4804</cell></row><row><cell>shm2023_2</cell><cell>64</cell><cell>-0.1470</cell><cell>0.2723</cell><cell>0.4638</cell></row><row><cell>KUCST_2</cell><cell>65</cell><cell>-0.3578</cell><cell>0.1379</cell><cell>0.4062</cell></row><row><cell>Majority_class</cell><cell>66</cell><cell>-0.4413</cell><cell>0.0847</cell><cell>0</cell></row><row><cell></cell><cell cols="3">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="24,149.09,86.43,297.09,73.57"><head>Table 5 -continued from previous page</head><label>5</label><figDesc></figDesc><table coords="24,149.09,102.97,297.09,57.03"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>shm2023_1</cell><cell>67</cell><cell>-0.4473</cell><cell>0.0809</cell><cell>0.0071</cell></row><row><cell>M&amp;S_NLP_3</cell><cell>68</cell><cell>-0.5335</cell><cell>0.0259</cell><cell>0.5312</cell></row><row><cell>Minority_class</cell><cell>69</cell><cell>-0.5742</cell><cell>0</cell><cell>0.5698</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="25,142.93,95.45,309.43,567.62"><head>Table 6 :</head><label>6</label><figDesc>Systems' results for Task 1 in the hard-soft evaluation</figDesc><table coords="25,142.93,109.40,309.43,553.67"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>EXIST2023_test_gold_soft</cell><cell>0</cell><cell>3.1182</cell><cell>1</cell></row><row><cell>EXIST2023_oracle_most_voted</cell><cell>1</cell><cell>1.1977</cell><cell>0.6897</cell></row><row><cell>Mario_3</cell><cell>2</cell><cell>0.4719</cell><cell>0.5725</cell></row><row><cell>Mario_1</cell><cell>3</cell><cell>0.4507</cell><cell>0.5691</cell></row><row><cell>Mario_2</cell><cell>4</cell><cell>0.3634</cell><cell>0.555</cell></row><row><cell>roh-neil_1</cell><cell>5</cell><cell>0.3111</cell><cell>0.5465</cell></row><row><cell>roh-neil_2</cell><cell>6</cell><cell>0.3111</cell><cell>0.5465</cell></row><row><cell>CIC-SDS.KN_2</cell><cell>7</cell><cell>0.2784</cell><cell>0.5412</cell></row><row><cell>SINAI_2</cell><cell>8</cell><cell>0.2678</cell><cell>0.5395</cell></row><row><cell>SINAI_1</cell><cell>9</cell><cell>0.264</cell><cell>0.5389</cell></row><row><cell>CIC-SDS.KN_3</cell><cell>10</cell><cell>0.2606</cell><cell>0.5383</cell></row><row><cell>SINAI_3</cell><cell>11</cell><cell>0.2513</cell><cell>0.5368</cell></row><row><cell>roh-neil_3</cell><cell>12</cell><cell>0.2497</cell><cell>0.5366</cell></row><row><cell>UniBo_1</cell><cell>13</cell><cell>0.2292</cell><cell>0.5333</cell></row><row><cell>UniBo_2</cell><cell>14</cell><cell>0.2292</cell><cell>0.5333</cell></row><row><cell>IUEXIST_1</cell><cell>15</cell><cell>0.215</cell><cell>0.531</cell></row><row><cell>IUEXIST_2</cell><cell>16</cell><cell>0.2109</cell><cell>0.5303</cell></row><row><cell>JPM_UNED_3</cell><cell>17</cell><cell>0.2041</cell><cell>0.5292</cell></row><row><cell>CIC-SDS.KN_1</cell><cell>18</cell><cell>0.197</cell><cell>0.5281</cell></row><row><cell>JPM_UNED_1</cell><cell>19</cell><cell>0.1685</cell><cell>0.5235</cell></row><row><cell>CLassifiers_3</cell><cell>20</cell><cell>0.1652</cell><cell>0.5229</cell></row><row><cell>UMUTeam_2</cell><cell>21</cell><cell>0.1614</cell><cell>0.5223</cell></row><row><cell>AI-UPV_2</cell><cell>22</cell><cell>0.1578</cell><cell>0.5217</cell></row><row><cell>UMUTeam_1</cell><cell>23</cell><cell>0.1578</cell><cell>0.5217</cell></row><row><cell>CLassifiers_2</cell><cell>24</cell><cell>0.1563</cell><cell>0.5215</cell></row><row><cell>Tlatlamiztli_1</cell><cell>25</cell><cell>0.1512</cell><cell>0.5207</cell></row><row><cell>AI-UPV_3</cell><cell>26</cell><cell>0.1453</cell><cell>0.5197</cell></row><row><cell>AIT_FHSTP_2</cell><cell>27</cell><cell>0.1411</cell><cell>0.519</cell></row><row><cell>I2C-Huelva-1_1</cell><cell>28</cell><cell>0.1253</cell><cell>0.5165</cell></row><row><cell>I2C-Huelva-1_2</cell><cell>29</cell><cell>0.1253</cell><cell>0.5165</cell></row><row><cell>I2C-Huelva-1_3</cell><cell>30</cell><cell>0.1253</cell><cell>0.5165</cell></row><row><cell>CLassifiers_1</cell><cell>31</cell><cell>0.1199</cell><cell>0.5156</cell></row><row><cell>JPM_UNED_2</cell><cell>32</cell><cell>0.1075</cell><cell>0.5136</cell></row><row><cell>AIT_FHSTP_1</cell><cell>33</cell><cell>0.1014</cell><cell>0.5126</cell></row><row><cell>iimasGIL_NLP_3</cell><cell>34</cell><cell>0.1</cell><cell>0.5124</cell></row><row><cell>AIT_FHSTP_3</cell><cell>35</cell><cell>0.0932</cell><cell>0.5113</cell></row><row><cell>MART_1</cell><cell>36</cell><cell>0.0868</cell><cell>0.5103</cell></row><row><cell>iimasGIL_NLP_1</cell><cell>37</cell><cell>0.059</cell><cell>0.5058</cell></row><row><cell>AI-UPV_1</cell><cell>38</cell><cell>0.0478</cell><cell>0.504</cell></row><row><cell></cell><cell></cell><cell cols="2">Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="26,142.93,86.43,309.43,457.89"><head>Table 6 -continued from previous page</head><label>6</label><figDesc></figDesc><table coords="26,142.93,99.44,309.43,444.88"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>MART_2</cell><cell>39</cell><cell>0.0333</cell><cell>0.5016</cell></row><row><cell>iimasGIL_NLP_2</cell><cell>40</cell><cell>-0.0255</cell><cell>0.4921</cell></row><row><cell>Alex_P_UPB_1</cell><cell>41</cell><cell>-0.096</cell><cell>0.4807</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>42</cell><cell>-0.1419</cell><cell>0.4733</cell></row><row><cell>ZaRa-IU-NLP_2</cell><cell>43</cell><cell>-0.1485</cell><cell>0.4723</cell></row><row><cell>Awakened_2</cell><cell>44</cell><cell>-0.2577</cell><cell>0.4546</cell></row><row><cell>M&amp;S_NLP_2</cell><cell>45</cell><cell>-0.3266</cell><cell>0.4435</cell></row><row><cell>IU-Percival_2</cell><cell>46</cell><cell>-0.4435</cell><cell>0.4246</cell></row><row><cell>ZaRa-IU-NLP_1</cell><cell>47</cell><cell>-0.4449</cell><cell>0.4244</cell></row><row><cell>IU-Percival_1</cell><cell>48</cell><cell>-0.4612</cell><cell>0.4217</cell></row><row><cell>InsightX_2</cell><cell>49</cell><cell>-0.4813</cell><cell>0.4185</cell></row><row><cell>IU-NLP-JeDi_3</cell><cell>50</cell><cell>-0.5071</cell><cell>0.4143</cell></row><row><cell>IU-NLP-JeDi_1</cell><cell>51</cell><cell>-0.5097</cell><cell>0.4139</cell></row><row><cell>IU-Percival_3</cell><cell>52</cell><cell>-0.5491</cell><cell>0.4075</cell></row><row><cell>SMS_3</cell><cell>53</cell><cell>-0.5638</cell><cell>0.4052</cell></row><row><cell>InsightX_1</cell><cell>54</cell><cell>-0.5887</cell><cell>0.4011</cell></row><row><cell>SMS_1</cell><cell>55</cell><cell>-0.6017</cell><cell>0.399</cell></row><row><cell>SMS_2</cell><cell>56</cell><cell>-0.6017</cell><cell>0.399</cell></row><row><cell>IU-NLP-JeDi_2</cell><cell>57</cell><cell>-0.7054</cell><cell>0.3823</cell></row><row><cell>UMUTeam_3</cell><cell>58</cell><cell>-0.7329</cell><cell>0.3778</cell></row><row><cell>Awakened_3</cell><cell>59</cell><cell>-0.8536</cell><cell>0.3583</cell></row><row><cell>IIIT SURAT_1</cell><cell>60</cell><cell>-0.9432</cell><cell>0.3439</cell></row><row><cell>CNLP-NITS-PP_1</cell><cell>61</cell><cell>-0.9509</cell><cell>0.3426</cell></row><row><cell>CNLP-NITS-PP_2</cell><cell>62</cell><cell>-0.9509</cell><cell>0.3426</cell></row><row><cell>Awakened_1</cell><cell>63</cell><cell>-1.1382</cell><cell>0.3124</cell></row><row><cell>InsightX_3</cell><cell>64</cell><cell>-1.2069</cell><cell>0.3013</cell></row><row><cell>shm2023_2</cell><cell>65</cell><cell>-1.6131</cell><cell>0.2356</cell></row><row><cell>KUCST_2</cell><cell>66</cell><cell>-1.8431</cell><cell>0.1985</cell></row><row><cell>EXIST2023_test_majority_class</cell><cell>67</cell><cell>-2.3585</cell><cell>0.1152</cell></row><row><cell>shm2023_1</cell><cell>68</cell><cell>-2.3774</cell><cell>0.1122</cell></row><row><cell>M&amp;S_NLP_3</cell><cell>69</cell><cell>-2.805</cell><cell>0.0431</cell></row><row><cell>EXIST2023_test_minority_class</cell><cell>70</cell><cell>-3.0717</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="27,137.74,417.13,319.80,252.60"><head>Table 7 :</head><label>7</label><figDesc>Systems' results for Task 2 in the soft-soft evaluation</figDesc><table coords="27,137.74,431.08,319.80,238.65"><row><cell>Run</cell><cell cols="4">Rank ICM-Soft ICM-Soft Norm Cross Entropy</cell></row><row><cell>Gold_soft</cell><cell>0</cell><cell>6.2057</cell><cell>1</cell><cell>0.9128</cell></row><row><cell>DRIM_1</cell><cell>1</cell><cell>-1.3443</cell><cell>0.8072</cell><cell>1.7833</cell></row><row><cell>AIT_FHSTP_2</cell><cell>2</cell><cell>-1.4350</cell><cell>0.8049</cell><cell>1.6486</cell></row><row><cell>JPM_UNED_2</cell><cell>3</cell><cell>-1.6750</cell><cell>0.7988</cell><cell>2.5549</cell></row><row><cell>AI-UPV_2</cell><cell>4</cell><cell>-1.6836</cell><cell>0.7985</cell><cell>2.1697</cell></row><row><cell>JPM_UNED_3</cell><cell>5</cell><cell>-1.6888</cell><cell>0.7984</cell><cell>2.5561</cell></row><row><cell>AI-UPV_3</cell><cell>6</cell><cell>-1.7691</cell><cell>0.7964</cell><cell>2.5424</cell></row><row><cell>AIT_FHSTP_3</cell><cell>7</cell><cell>-2.1619</cell><cell>0.7863</cell><cell>2.0897</cell></row><row><cell>SINAI_3</cell><cell>8</cell><cell>-2.2900</cell><cell>0.7831</cell><cell>1.6753</cell></row><row><cell>UMUTeam_3</cell><cell>9</cell><cell>-2.5405</cell><cell>0.7767</cell><cell>2.2271</cell></row><row><cell>UMUTeam_1</cell><cell>10</cell><cell>-2.5674</cell><cell>0.7760</cell><cell>1.8102</cell></row><row><cell>Alex_P_UPB_1</cell><cell>11</cell><cell>-3.1765</cell><cell>0.7604</cell><cell>3.2050</cell></row><row><cell>Awakened_2</cell><cell>12</cell><cell>-3.1954</cell><cell>0.7599</cell><cell>1.6668</cell></row><row><cell cols="2">iimasGIL_NLP_3 13</cell><cell>-3.5072</cell><cell>0.7520</cell><cell>1.8860</cell></row><row><cell>Mario_2</cell><cell>14</cell><cell>-3.5509</cell><cell>0.7509</cell><cell>3.0061</cell></row><row><cell></cell><cell></cell><cell cols="2">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="28,137.74,86.43,319.80,209.06"><head>Table 7 -continued from previous page</head><label>7</label><figDesc></figDesc><table coords="28,137.74,102.97,319.80,192.53"><row><cell>Run</cell><cell cols="4">Rank ICM-Soft ICM-Soft Norm Cross Entropy</cell></row><row><cell cols="2">iimasGIL_NLP_1 15</cell><cell>-3.5570</cell><cell>0.7507</cell><cell>1.9067</cell></row><row><cell cols="2">iimasGIL_NLP_2 16</cell><cell>-3.6387</cell><cell>0.7486</cell><cell>1.9149</cell></row><row><cell>Awakened_1</cell><cell>17</cell><cell>-3.9152</cell><cell>0.7416</cell><cell>1.7741</cell></row><row><cell>UMUTeam_2</cell><cell>18</cell><cell>-4.0482</cell><cell>0.7382</cell><cell>4.0452</cell></row><row><cell>SINAI_1</cell><cell>19</cell><cell>-4.2437</cell><cell>0.7332</cell><cell>2.3710</cell></row><row><cell>Awakened_3</cell><cell>20</cell><cell>-4.3598</cell><cell>0.7302</cell><cell>1.8594</cell></row><row><cell>AI-UPV_1</cell><cell>21</cell><cell>-4.3632</cell><cell>0.7301</cell><cell>3.0172</cell></row><row><cell>Majority_class</cell><cell>22</cell><cell>-5.4460</cell><cell>0.7025</cell><cell>4.6233</cell></row><row><cell>roh-neil_1</cell><cell>23</cell><cell>-5.7590</cell><cell>0.6945</cell><cell>3.7519</cell></row><row><cell>roh-neil_2</cell><cell>24</cell><cell>-5.7592</cell><cell>0.6945</cell><cell>3.2828</cell></row><row><cell>SINAI_2</cell><cell>25</cell><cell>-10.9851</cell><cell>0.5610</cell><cell>4.6237</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>26</cell><cell>-12.5531</cell><cell>0.5210</cell><cell>7.5639</cell></row><row><cell>Minority_class</cell><cell>27</cell><cell>-32.9552</cell><cell>0</cell><cell>8.8517</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="29,149.09,173.55,297.10,500.01"><head>Table 8 :</head><label>8</label><figDesc>Systems' results for Task 2 in the hard-hard evaluation</figDesc><table coords="29,149.09,191.02,297.10,482.54"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>Gold_hard</cell><cell>0</cell><cell>1.5378</cell><cell>1</cell><cell>1</cell></row><row><cell>Mario_2</cell><cell>1</cell><cell>0.4887</cell><cell>0.7764</cell><cell>0.5715</cell></row><row><cell>roh-neil_1</cell><cell>2</cell><cell>0.3883</cell><cell>0.7550</cell><cell>0.5480</cell></row><row><cell>roh-neil_2</cell><cell>3</cell><cell>0.3883</cell><cell>0.7550</cell><cell>0.5480</cell></row><row><cell>UniBo_2</cell><cell>4</cell><cell>0.2786</cell><cell>0.7316</cell><cell>0.5283</cell></row><row><cell>UniBo_1</cell><cell>5</cell><cell>0.2439</cell><cell>0.7243</cell><cell>0.5217</cell></row><row><cell>AIT_FHSTP_1</cell><cell>6</cell><cell>0.2229</cell><cell>0.7198</cell><cell>0.5029</cell></row><row><cell>AI-UPV_2</cell><cell>7</cell><cell>0.1951</cell><cell>0.7139</cell><cell>0.4962</cell></row><row><cell>AI-UPV_3</cell><cell>8</cell><cell>0.1870</cell><cell>0.7121</cell><cell>0.4993</cell></row><row><cell>JPM_UNED_2</cell><cell>9</cell><cell>0.1862</cell><cell>0.7120</cell><cell>0.5054</cell></row><row><cell>JPM_UNED_3</cell><cell>10</cell><cell>0.1806</cell><cell>0.7108</cell><cell>0.5092</cell></row><row><cell>JPM_UNED_1</cell><cell>11</cell><cell>0.1673</cell><cell>0.7079</cell><cell>0.5032</cell></row><row><cell>AIT_FHSTP_3</cell><cell>12</cell><cell>0.1662</cell><cell>0.7077</cell><cell>0.4911</cell></row><row><cell>AIT_FHSTP_2</cell><cell>13</cell><cell>0.1475</cell><cell>0.7037</cell><cell>0.4759</cell></row><row><cell>UMUTeam_1</cell><cell>14</cell><cell>0.1409</cell><cell>0.7023</cell><cell>0.5013</cell></row><row><cell>AI-UPV_1</cell><cell>15</cell><cell>0.1217</cell><cell>0.6982</cell><cell>0.4897</cell></row><row><cell>Awakened_2</cell><cell>16</cell><cell>0.0088</cell><cell>0.6741</cell><cell>0.4606</cell></row><row><cell>UMUTeam_2</cell><cell>17</cell><cell>-0.0453</cell><cell>0.6626</cell><cell>0.4495</cell></row><row><cell>SINAI_2</cell><cell>18</cell><cell>-0.0496</cell><cell>0.6617</cell><cell>0.4924</cell></row><row><cell>SMS_1</cell><cell>19</cell><cell>-0.0892</cell><cell>0.6533</cell><cell>0.3654</cell></row><row><cell>SMS_3</cell><cell>20</cell><cell>-0.1226</cell><cell>0.6461</cell><cell>0.3504</cell></row><row><cell>UMUTeam_3</cell><cell>21</cell><cell>-0.1349</cell><cell>0.6435</cell><cell>0.4300</cell></row><row><cell>Alex_P_UPB_1</cell><cell>22</cell><cell>-0.1481</cell><cell>0.6407</cell><cell>0.4278</cell></row><row><cell>SMS_2</cell><cell>23</cell><cell>-0.2571</cell><cell>0.6175</cell><cell>0.3246</cell></row><row><cell cols="2">CNLP-NITS-PP_1 24</cell><cell>-0.3601</cell><cell>0.5955</cell><cell>0.3663</cell></row><row><cell>SINAI_1</cell><cell>25</cell><cell>-0.5959</cell><cell>0.5453</cell><cell>0.2562</cell></row><row><cell>Awakened_1</cell><cell>26</cell><cell>-0.7515</cell><cell>0.5121</cell><cell>0.2910</cell></row><row><cell>Awakened_3</cell><cell>27</cell><cell>-0.9048</cell><cell>0.4794</cell><cell>0.3087</cell></row><row><cell>KUCST_2</cell><cell>28</cell><cell>-0.9333</cell><cell>0.4734</cell><cell>0.2383</cell></row><row><cell>Majority_class</cell><cell>29</cell><cell>-0.9504</cell><cell>0.4697</cell><cell>0.1603</cell></row><row><cell>SINAI_3</cell><cell>30</cell><cell>-0.9646</cell><cell>0.4667</cell><cell>0.2544</cell></row><row><cell cols="2">iimasGIL_NLP_3 31</cell><cell>-0.9925</cell><cell>0.4608</cell><cell>0.2910</cell></row><row><cell cols="2">iimasGIL_NLP_1 32</cell><cell>-1.0631</cell><cell>0.4457</cell><cell>0.2505</cell></row><row><cell></cell><cell cols="3">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="30,149.09,86.43,297.09,73.57"><head>Table 8 -continued from previous page</head><label>8</label><figDesc></figDesc><table coords="30,149.09,102.97,297.09,57.03"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell cols="2">iimasGIL_NLP_2 33</cell><cell>-1.0778</cell><cell>0.4426</cell><cell>0.2629</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>34</cell><cell>-2.9687</cell><cell>0.0396</cell><cell>0.0765</cell></row><row><cell>Minority_class</cell><cell>35</cell><cell>-3.1545</cell><cell>0</cell><cell>0.0280</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17" coords="31,142.93,95.45,309.43,526.57"><head>Table 9 :</head><label>9</label><figDesc>Systems' results for Task 2 in the hard-soft evaluation</figDesc><table coords="31,142.93,109.40,309.43,512.63"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>EXIST2023_test_gold_soft</cell><cell>0</cell><cell>6.2057</cell><cell>1</cell></row><row><cell>EXIST2023_oracle_most_voted</cell><cell>1</cell><cell>-2.3974</cell><cell>0.7803</cell></row><row><cell>UMUTeam_2</cell><cell>2</cell><cell>-5.12</cell><cell>0.7108</cell></row><row><cell>UMUTeam_3</cell><cell>3</cell><cell>-5.3093</cell><cell>0.706</cell></row><row><cell>EXIST2023_test_majority_class</cell><cell>4</cell><cell>-5.446</cell><cell>0.7025</cell></row><row><cell>UMUTeam_1</cell><cell>5</cell><cell>-5.5369</cell><cell>0.7001</cell></row><row><cell>SMS_2</cell><cell>6</cell><cell>-5.627</cell><cell>0.6978</cell></row><row><cell>Mario_2</cell><cell>7</cell><cell>-5.8157</cell><cell>0.693</cell></row><row><cell>SMS_3</cell><cell>8</cell><cell>-5.9579</cell><cell>0.6894</cell></row><row><cell>KUCST_2</cell><cell>9</cell><cell>-5.9955</cell><cell>0.6884</cell></row><row><cell>SMS_1</cell><cell>10</cell><cell>-6.0774</cell><cell>0.6863</cell></row><row><cell>AIT_FHSTP_2</cell><cell>11</cell><cell>-6.3494</cell><cell>0.6794</cell></row><row><cell>roh-neil_1</cell><cell>12</cell><cell>-6.522</cell><cell>0.675</cell></row><row><cell>roh-neil_2</cell><cell>13</cell><cell>-6.522</cell><cell>0.675</cell></row><row><cell>AIT_FHSTP_3</cell><cell>14</cell><cell>-6.735</cell><cell>0.6696</cell></row><row><cell>AIT_FHSTP_1</cell><cell>15</cell><cell>-6.8143</cell><cell>0.6675</cell></row><row><cell>UniBo_2</cell><cell>16</cell><cell>-6.8552</cell><cell>0.6665</cell></row><row><cell>AI-UPV_2</cell><cell>17</cell><cell>-7.0678</cell><cell>0.6611</cell></row><row><cell>Awakened_2</cell><cell>18</cell><cell>-7.1322</cell><cell>0.6594</cell></row><row><cell>UniBo_1</cell><cell>19</cell><cell>-7.2258</cell><cell>0.657</cell></row><row><cell>CNLP-NITS-PP_1</cell><cell>20</cell><cell>-7.2467</cell><cell>0.6565</cell></row><row><cell>AI-UPV_3</cell><cell>21</cell><cell>-7.2669</cell><cell>0.656</cell></row><row><cell>JPM_UNED_2</cell><cell>22</cell><cell>-7.3346</cell><cell>0.6542</cell></row><row><cell>JPM_UNED_1</cell><cell>23</cell><cell>-7.5078</cell><cell>0.6498</cell></row><row><cell>JPM_UNED_3</cell><cell>24</cell><cell>-7.5205</cell><cell>0.6495</cell></row><row><cell>Awakened_1</cell><cell>25</cell><cell>-7.7378</cell><cell>0.6439</cell></row><row><cell>AI-UPV_1</cell><cell>26</cell><cell>-7.7615</cell><cell>0.6433</cell></row><row><cell>Alex_P_UPB_1</cell><cell>27</cell><cell>-8.8468</cell><cell>0.6156</cell></row><row><cell>iimasGIL_NLP_1</cell><cell>28</cell><cell>-10.1498</cell><cell>0.5824</cell></row><row><cell>iimasGIL_NLP_2</cell><cell>29</cell><cell>-10.6025</cell><cell>0.5708</cell></row><row><cell>iimasGIL_NLP_3</cell><cell>30</cell><cell>-10.7368</cell><cell>0.5674</cell></row><row><cell>SINAI_2</cell><cell>31</cell><cell>-10.9983</cell><cell>0.5607</cell></row><row><cell>SINAI_1</cell><cell>32</cell><cell>-11.0357</cell><cell>0.5597</cell></row><row><cell>Awakened_3</cell><cell>33</cell><cell>-11.9799</cell><cell>0.5356</cell></row><row><cell>SINAI_3</cell><cell>34</cell><cell>-15.0466</cell><cell>0.4573</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>35</cell><cell>-23.8919</cell><cell>0.2314</cell></row><row><cell>EXIST2023_test_minority_class</cell><cell>36</cell><cell>-32.9552</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18" coords="32,157.15,557.13,278.26,117.11"><head>Table 10 :</head><label>10</label><figDesc>Systems' results for Task 3 in the soft-soft evaluation</figDesc><table coords="32,175.65,571.08,243.98,103.16"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>Gold_soft</cell><cell>0</cell><cell>9.4686</cell><cell>1</cell></row><row><cell>AI-UPV_3</cell><cell>1</cell><cell>-2.3183</cell><cell>0.7879</cell></row><row><cell>AI-UPV_2</cell><cell>2</cell><cell>-2.5616</cell><cell>0.7835</cell></row><row><cell>AI-UPV_1</cell><cell>3</cell><cell>-3.3437</cell><cell>0.7695</cell></row><row><cell>DRIM_1</cell><cell>4</cell><cell>-3.6842</cell><cell>0.7633</cell></row><row><cell></cell><cell cols="2">Continued on next page</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19" coords="33,175.65,86.43,243.98,317.45"><head>Table 10 -continued from previous page</head><label>10</label><figDesc></figDesc><table coords="33,175.65,102.97,243.98,300.92"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>Alex_P_UPB_1</cell><cell>5</cell><cell>-4.2139</cell><cell>0.7538</cell></row><row><cell>CLassifiers_1</cell><cell>6</cell><cell>-6.4072</cell><cell>0.7143</cell></row><row><cell>roh-neil_1</cell><cell>7</cell><cell>-6.6622</cell><cell>0.7098</cell></row><row><cell>roh-neil_2</cell><cell>8</cell><cell>-6.6622</cell><cell>0.7098</cell></row><row><cell>roh-neil_3</cell><cell>9</cell><cell>-6.6622</cell><cell>0.7098</cell></row><row><cell>SINAI_3</cell><cell>10</cell><cell>-7.1306</cell><cell>0.7013</cell></row><row><cell cols="2">iimasGIL_NLP_3 11</cell><cell>-7.7704</cell><cell>0.6898</cell></row><row><cell cols="2">iimasGIL_NLP_2 12</cell><cell>-7.8073</cell><cell>0.6892</cell></row><row><cell cols="2">iimasGIL_NLP_1 13</cell><cell>-7.8867</cell><cell>0.6877</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>14</cell><cell>-8.3574</cell><cell>0.6793</cell></row><row><cell>Majority_class</cell><cell>15</cell><cell>-8.7089</cell><cell>0.6729</cell></row><row><cell>Mario_1</cell><cell>16</cell><cell>-11.4241</cell><cell>0.6241</cell></row><row><cell>Mario_2</cell><cell>17</cell><cell>-11.4241</cell><cell>0.6241</cell></row><row><cell>Mario_3</cell><cell>18</cell><cell>-11.4241</cell><cell>0.6241</cell></row><row><cell>SINAI_2</cell><cell>19</cell><cell>-13.5493</cell><cell>0.5858</cell></row><row><cell>CLassifiers_2</cell><cell>20</cell><cell>-14.7828</cell><cell>0.5636</cell></row><row><cell>Awakened_1</cell><cell>21</cell><cell>-20.0399</cell><cell>0.4690</cell></row><row><cell>Awakened_2</cell><cell>22</cell><cell>-23.6389</cell><cell>0.4043</cell></row><row><cell>Awakened_3</cell><cell>23</cell><cell>-25.9233</cell><cell>0.3632</cell></row><row><cell>SINAI_1</cell><cell>24</cell><cell>-34.9362</cell><cell>0.2010</cell></row><row><cell>Minority_class</cell><cell>25</cell><cell>-46.1080</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20" coords="34,118.25,268.39,358.79,405.17"><head>Table 11 :</head><label>11</label><figDesc>Systems' results for Task 3 in the hard-hard evaluation</figDesc><table coords="34,118.25,285.87,358.79,387.69"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>EXIST2023_test_gold_hard</cell><cell>0</cell><cell>2.1533</cell><cell>1</cell><cell>1</cell></row><row><cell>roh-neil_1</cell><cell>1</cell><cell>0.4433</cell><cell>0.6763</cell><cell>0.6296</cell></row><row><cell>roh-neil_2</cell><cell>2</cell><cell>0.4433</cell><cell>0.6763</cell><cell>0.6296</cell></row><row><cell>AIT_FHSTP_1</cell><cell>3</cell><cell>0.2366</cell><cell>0.6372</cell><cell>0.5842</cell></row><row><cell>UniBo_2</cell><cell>4</cell><cell>0.2263</cell><cell>0.6352</cell><cell>0.5909</cell></row><row><cell>UniBo_1</cell><cell>5</cell><cell>0.1776</cell><cell>0.6260</cell><cell>0.5850</cell></row><row><cell>Mario_3</cell><cell>6</cell><cell>0.1700</cell><cell>0.6246</cell><cell>0.5323</cell></row><row><cell>SINAI_2</cell><cell>7</cell><cell>0.1472</cell><cell>0.6203</cell><cell>0.5822</cell></row><row><cell>Mario_2</cell><cell>8</cell><cell>0.1228</cell><cell>0.6156</cell><cell>0.5145</cell></row><row><cell>Mario_1</cell><cell>9</cell><cell>0.0896</cell><cell>0.6094</cell><cell>0.5011</cell></row><row><cell>SINAI_3</cell><cell>10</cell><cell>0.0249</cell><cell>0.5971</cell><cell>0.5033</cell></row><row><cell>AI-UPV_1</cell><cell>11</cell><cell>-0.1862</cell><cell>0.5571</cell><cell>0.4732</cell></row><row><cell>Alex_P_UPB_1</cell><cell>12</cell><cell>-0.1948</cell><cell>0.5555</cell><cell>0.4817</cell></row><row><cell>AI-UPV_2</cell><cell>13</cell><cell>-0.2516</cell><cell>0.5448</cell><cell>0.4757</cell></row><row><cell>SINAI_1</cell><cell>14</cell><cell>-0.3020</cell><cell>0.5352</cell><cell>0.5306</cell></row><row><cell>Awakened_2</cell><cell>15</cell><cell>-0.4276</cell><cell>0.5115</cell><cell>0.4027</cell></row><row><cell>UMUTeam_3</cell><cell>16</cell><cell>-0.5121</cell><cell>0.4955</cell><cell>0.5130</cell></row><row><cell>AI-UPV_3</cell><cell>17</cell><cell>-0.5788</cell><cell>0.4828</cell><cell>0.4195</cell></row><row><cell>UMUTeam_1</cell><cell>18</cell><cell>-0.5963</cell><cell>0.4795</cell><cell>0.5108</cell></row><row><cell>iimasGIL_NLP_3</cell><cell>19</cell><cell>-0.6510</cell><cell>0.4692</cell><cell>0.4482</cell></row><row><cell>Awakened_3</cell><cell>20</cell><cell>-0.6731</cell><cell>0.4650</cell><cell>0.3794</cell></row><row><cell>iimasGIL_NLP_1</cell><cell>21</cell><cell>-0.6859</cell><cell>0.4626</cell><cell>0.4406</cell></row><row><cell>iimasGIL_NLP_2</cell><cell>22</cell><cell>-0.7786</cell><cell>0.4450</cell><cell>0.4255</cell></row><row><cell>CNLP-NITS-PP_1</cell><cell>23</cell><cell>-0.8412</cell><cell>0.4332</cell><cell>0.3199</cell></row><row><cell>Awakened_1</cell><cell>24</cell><cell>-0.9507</cell><cell>0.4124</cell><cell>0.3283</cell></row><row><cell>roh-neil_3</cell><cell>25</cell><cell>-0.9626</cell><cell>0.4102</cell><cell>0.3139</cell></row><row><cell></cell><cell cols="2">Continued on next page</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21" coords="35,118.25,86.43,358.78,127.77"><head>Table 11 -continued from previous page</head><label>11</label><figDesc></figDesc><table coords="35,118.25,102.97,358.78,111.23"><row><cell>Run</cell><cell cols="3">Rank ICM-Hard ICM-Hard Norm</cell><cell>F1</cell></row><row><cell>UMUTeam_2</cell><cell>26</cell><cell>-0.9727</cell><cell>0.4083</cell><cell>0.4630</cell></row><row><cell cols="2">EXIST2023_test_majority_class 27</cell><cell>-1.5984</cell><cell>0.2898</cell><cell>0.1069</cell></row><row><cell>KUCST_2</cell><cell>28</cell><cell>-1.7934</cell><cell>0.2529</cell><cell>0.2889</cell></row><row><cell>CLassifiers_2</cell><cell>29</cell><cell>-1.8664</cell><cell>0.2391</cell><cell>0.3047</cell></row><row><cell>CLassifiers_1</cell><cell>30</cell><cell>-1.8852</cell><cell>0.2355</cell><cell>0.3126</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>31</cell><cell>-2.1587</cell><cell>0.1838</cell><cell>0.0017</cell></row><row><cell cols="2">EXIST2023_test_minority_class 32</cell><cell>-3.1295</cell><cell>0</cell><cell>0.0288</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22" coords="36,142.93,95.45,309.43,485.93"><head>Table 12 :</head><label>12</label><figDesc>Systems' results for Task 3 in the hard-soft evaluation</figDesc><table coords="36,142.93,109.40,309.43,471.98"><row><cell>Run</cell><cell cols="3">Rank ICM-Soft ICM-Soft Norm</cell></row><row><cell>EXIST2023_test_gold_soft</cell><cell>0</cell><cell>9.4686</cell><cell>1</cell></row><row><cell>EXIST2023_oracle_most_voted</cell><cell>1</cell><cell>-8.3816</cell><cell>0.6788</cell></row><row><cell>EXIST2023_test_majority_class</cell><cell>2</cell><cell>-8.7089</cell><cell>0.6729</cell></row><row><cell>Mario_1</cell><cell>3</cell><cell>-9.1398</cell><cell>0.6652</cell></row><row><cell>M&amp;S_NLP_1</cell><cell>4</cell><cell>-9.504</cell><cell>0.6586</cell></row><row><cell>Mario_2</cell><cell>5</cell><cell>-9.6735</cell><cell>0.6556</cell></row><row><cell>Mario_3</cell><cell>6</cell><cell>-10.2297</cell><cell>0.6456</cell></row><row><cell>AI-UPV_3</cell><cell>7</cell><cell>-10.9218</cell><cell>0.6331</cell></row><row><cell>CNLP-NITS-PP_1</cell><cell>8</cell><cell>-11.3206</cell><cell>0.6259</cell></row><row><cell>Alex_P_UPB_1</cell><cell>9</cell><cell>-11.7145</cell><cell>0.6188</cell></row><row><cell>AI-UPV_1</cell><cell>10</cell><cell>-11.8571</cell><cell>0.6163</cell></row><row><cell>Awakened_2</cell><cell>11</cell><cell>-11.8918</cell><cell>0.6157</cell></row><row><cell>SINAI_3</cell><cell>12</cell><cell>-12.1399</cell><cell>0.6112</cell></row><row><cell>roh-neil_1</cell><cell>13</cell><cell>-12.195</cell><cell>0.6102</cell></row><row><cell>roh-neil_2</cell><cell>14</cell><cell>-12.195</cell><cell>0.6102</cell></row><row><cell>AI-UPV_2</cell><cell>15</cell><cell>-12.2553</cell><cell>0.6091</cell></row><row><cell>AIT_FHSTP_1</cell><cell>16</cell><cell>-13.6923</cell><cell>0.5833</cell></row><row><cell>UniBo_2</cell><cell>17</cell><cell>-14.2263</cell><cell>0.5737</cell></row><row><cell>Awakened_3</cell><cell>18</cell><cell>-14.3296</cell><cell>0.5718</cell></row><row><cell>iimasGIL_NLP_2</cell><cell>19</cell><cell>-14.3422</cell><cell>0.5716</cell></row><row><cell>iimasGIL_NLP_3</cell><cell>20</cell><cell>-14.6869</cell><cell>0.5654</cell></row><row><cell>iimasGIL_NLP_1</cell><cell>21</cell><cell>-14.9609</cell><cell>0.5604</cell></row><row><cell>Awakened_1</cell><cell>22</cell><cell>-15.2776</cell><cell>0.5547</cell></row><row><cell>UniBo_1</cell><cell>23</cell><cell>-15.4834</cell><cell>0.551</cell></row><row><cell>KUCST_2</cell><cell>24</cell><cell>-22.9796</cell><cell>0.4162</cell></row><row><cell>roh-neil_3</cell><cell>25</cell><cell>-24.3698</cell><cell>0.3911</cell></row><row><cell>SINAI_2</cell><cell>26</cell><cell>-27.2984</cell><cell>0.3384</cell></row><row><cell>UMUTeam_3</cell><cell>27</cell><cell>-34.5038</cell><cell>0.2088</cell></row><row><cell>SINAI_1</cell><cell>28</cell><cell>-34.9858</cell><cell>0.2001</cell></row><row><cell>UMUTeam_1</cell><cell>29</cell><cell>-35.0505</cell><cell>0.199</cell></row><row><cell>CLassifiers_2</cell><cell>30</cell><cell>-36.0875</cell><cell>0.1803</cell></row><row><cell>UMUTeam_2</cell><cell>31</cell><cell>-37.3056</cell><cell>0.1584</cell></row><row><cell>CLassifiers_1</cell><cell>32</cell><cell>-37.5046</cell><cell>0.1548</cell></row><row><cell>EXIST2023_test_minority_class</cell><cell>33</cell><cell>-46.108</cell><cell>0</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been financed by the <rs type="funder">European Union (NextGenerationEU funds)</rs> through the "<rs type="programName">Plan de Recuperación, Transformación y Resiliencia</rs>", by the <rs type="funder">Ministry of Economic Affairs and Digital Transformation</rs> and by the <rs type="funder">UNED University</rs>. It has also been financed by the <rs type="funder">Spanish Ministry of Science and Innovation</rs> (project <rs type="projectName">FairTransNLP</rs> (<rs type="grantNumber">PID2021-124361OB-C31</rs> and <rs type="grantNumber">PID2021-124361OB-C32</rs>)) funded by <rs type="grantNumber">MCIN/AEI/10.13039/501100011033</rs> and by <rs type="funder">ERDF</rs>, <rs type="funder">EU</rs> A way of making Europe, and by the <rs type="funder">Australian Research Council</rs> (<rs type="grantNumber">DE200100064</rs> and <rs type="grantNumber">CE200100005</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vXHpbnu">
					<orgName type="program" subtype="full">Plan de Recuperación, Transformación y Resiliencia</orgName>
				</org>
				<org type="funded-project" xml:id="_XxtbgsA">
					<idno type="grant-number">PID2021-124361OB-C31</idno>
					<orgName type="project" subtype="full">FairTransNLP</orgName>
				</org>
				<org type="funding" xml:id="_tkHumFS">
					<idno type="grant-number">PID2021-124361OB-C32</idno>
				</org>
				<org type="funding" xml:id="_4Dwbmru">
					<idno type="grant-number">MCIN/AEI/10.13039/501100011033</idno>
				</org>
				<org type="funding" xml:id="_EA3s2Ab">
					<idno type="grant-number">DE200100064</idno>
				</org>
				<org type="funding" xml:id="_7Wsxwjy">
					<idno type="grant-number">CE200100005</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="39,112.66,145.59,393.33,10.91;39,112.66,159.14,394.04,10.91;39,112.66,172.69,348.15,10.91" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dhrodia</surname></persName>
		</author>
		<ptr target="https://www.newstatesman.com/culture/social-media/2017/11/social-media-and-silencing-effect-why-misogyny-online-human-rights-issue" />
		<title level="m" coord="39,170.18,145.59,335.81,10.91;39,112.66,159.14,50.25,10.91">Social media and the silencing effect: Why misogyny online is a human rights issue</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,186.24,394.52,10.91;39,112.66,199.79,356.80,10.91" xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Burgos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Donoso-Vázquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cabañó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Prado-Soto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Velasco-Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,287.52,199.79,92.54,10.91">Violencias de género</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2014">2014</date>
			<publisher>E-litterae</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,213.34,393.32,10.91;39,112.66,226.89,321.63,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="39,327.99,213.34,177.99,10.91;39,112.66,226.89,98.82,10.91">Living with television: The dynamics of the cultivation process</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gerbner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Signorielli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,219.86,226.89,130.50,10.91">Perspectives on media effects</title>
		<imprint>
			<biblScope unit="page" from="17" to="40" />
			<date type="published" when="1986">1986. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,240.44,395.17,10.91;39,112.66,253.99,393.32,10.91;39,112.33,267.54,393.65,10.91;39,112.66,281.08,154.56,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="39,261.50,240.44,246.33,10.91;39,112.66,253.99,98.56,10.91">Automatic identification and classification of misogynistic language on twitter</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anzovino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,143.88,267.54,251.38,10.91">Natural Language Processing and Information Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Silberztein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Atigui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kornyshova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Métais</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Meziane</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,294.63,393.33,10.91;39,112.66,308.18,260.01,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="39,280.51,294.63,225.47,10.91;39,112.66,308.18,84.54,10.91">Misogyny detection in twitter: a multilingual and cross-domain study</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Pamungkas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,205.53,308.18,89.18,10.91">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">102360</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,321.73,393.33,10.91;39,112.66,335.28,393.33,10.91;39,112.66,348.83,394.53,10.91;39,112.28,362.38,319.29,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="39,411.47,321.73,94.52,10.91;39,112.66,335.28,196.68,10.91">An expert annotated dataset for the detection of online misogyny</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Guest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Margetts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,333.27,335.28,172.72,10.91;39,112.66,348.83,394.53,10.91;39,112.28,362.38,186.39,10.91">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1336" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,375.93,394.53,10.91;39,112.33,389.48,395.50,10.91;39,112.66,403.03,220.34,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="39,167.42,389.48,300.08,10.91">Overview of EXIST 2021: Sexism identification in social networks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Comet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Donoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,478.57,389.48,29.25,10.91;39,112.66,403.03,136.41,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,416.58,395.17,10.91;39,112.66,430.13,394.62,10.91;39,112.66,443.67,393.98,10.91;39,112.66,457.22,38.81,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="39,395.80,430.13,111.47,10.91;39,112.66,443.67,177.79,10.91">Overview of EXIST 2022: Sexism identification in social networks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mendieta-Aragón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Marco-Remón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Makeienko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,299.39,443.67,164.18,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="229" to="240" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,470.77,393.33,10.91;39,112.66,484.32,393.33,10.91;39,112.33,497.87,265.82,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="39,293.62,470.77,212.37,10.91;39,112.66,484.32,59.98,10.91">SemEval-2023 Task 10: Explainable Detection of Online Sexism</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Röttger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,194.35,484.32,311.64,10.91;39,112.33,497.87,42.35,10.91">Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval)</title>
		<meeting>the 17th International Workshop on Semantic Evaluation (SemEval)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,511.42,394.53,10.91;39,112.66,524.97,393.33,10.91;39,112.41,538.52,393.78,10.91;39,112.66,552.07,238.79,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="39,163.47,524.97,234.07,10.91">SemEval-2021 task 12: Learning with disagreements</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Uma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dumitrache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,421.63,524.97,84.36,10.91;39,112.41,538.52,315.88,10.91">Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</title>
		<meeting>the 15th International Workshop on Semantic Evaluation (SemEval-2021)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="338" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,565.62,393.32,10.91;39,112.33,579.17,394.86,10.91;39,112.66,592.72,168.00,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="39,275.31,565.62,87.00,10.91">Managing bias in ai</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Talagala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,384.43,565.62,121.55,10.91;39,112.33,579.17,218.83,10.91">Companion Proceedings of The 2019 World Wide Web Conference, WWW &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="539" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,606.27,393.33,10.91;39,112.66,619.81,188.37,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="39,228.14,606.27,225.74,10.91">Five sources of bias in natural language processing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="39,462.42,606.27,43.57,10.91;39,112.66,619.81,110.61,10.91">Language and Linguistics Compass</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">12432</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="39,112.66,633.36,393.33,10.91;39,112.66,646.91,393.33,10.91;40,112.66,86.97,393.33,10.91;40,112.66,100.52,289.53,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="39,291.82,633.36,214.17,10.91;39,112.66,646.91,190.67,10.91">Get another label? improving data quality and data mining using multiple, noisy labelers</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="39,328.75,646.91,177.24,10.91;40,112.66,86.97,336.21,10.91">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,114.06,395.17,10.91;40,112.66,127.61,393.33,10.91;40,112.28,141.16,393.70,10.91;40,112.66,154.71,314.25,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="40,238.35,114.06,122.59,10.91">Deep learning from crowds</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,386.98,114.06,120.85,10.91;40,112.66,127.61,393.33,10.91;40,112.28,141.16,393.70,10.91;40,112.66,154.71,226.70,10.91">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;18/IAAI&apos;18/EAAI&apos;18</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;18/IAAI&apos;18/EAAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,168.26,395.17,10.91;40,112.66,181.81,393.33,10.91;40,112.33,195.36,344.19,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="40,356.21,168.26,151.61,10.91;40,112.66,181.81,89.90,10.91">Human uncertainty makes classification more robust</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Battleday</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,249.18,181.81,256.81,10.91;40,112.33,195.36,28.58,10.91">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="9616" to="9625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,208.91,394.53,10.91;40,112.28,222.46,394.91,10.91;40,112.66,236.01,393.59,10.91;40,112.66,249.56,264.01,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="40,170.30,222.46,336.89,10.91;40,112.66,236.01,267.02,10.91">AIT_FHSTP at EXIST 2023 Benchmark: Sexism detection by transfer learning, sentiment and toxicity embeddings and hand-crafted features</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Böck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schütz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Q S</forename><surname>Daria Liakhovets</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Babic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Slijepcevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zeppelzauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,402.15,236.01,104.10,10.91;40,112.66,249.56,233.32,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,263.11,395.17,10.91;40,112.66,276.66,394.61,10.91;40,112.14,290.20,372.64,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="40,318.21,263.11,189.61,10.91;40,112.66,276.66,374.50,10.91">AI-UPV at EXIST 2023 -Sexism Characterization Using Large Language Models Under The Learning with Disagreement Regime</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F M</forename><surname>De Paula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rizzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,112.14,290.20,341.95,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,303.75,393.59,10.91;40,112.66,317.30,264.01,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="40,169.64,303.75,206.68,10.91">Leveraging MiniLMv2 Pipelines for EXIST</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Petrescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,400.04,303.75,106.21,10.91;40,112.66,317.30,233.32,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,330.85,393.33,10.91;40,112.66,344.40,394.52,10.91;40,112.66,357.95,394.53,10.91;40,112.39,371.50,249.50,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="40,337.22,330.85,168.77,10.91;40,112.66,344.40,255.00,10.91">Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="40,271.90,357.95,230.46,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5776" to="5788" />
			<date type="published" when="2020">2020</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,385.05,393.32,10.91;40,112.66,398.60,394.53,10.91;40,112.66,412.15,22.69,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="40,272.47,385.05,233.52,10.91;40,112.66,398.60,34.35,10.91">Multilingual Sexism Identification using contrastive learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aroyehun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,169.12,398.60,332.90,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,425.70,393.33,10.91;40,112.66,439.25,393.33,10.91;40,112.66,452.79,178.54,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="40,287.69,425.70,218.29,10.91;40,112.66,439.25,180.31,10.91">CLassifiers at EXIST 2023: Detecting Sexism in Spanish and English Tweets with XLM-T</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Radler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">I</forename><surname>Ersoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carpentieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,316.52,439.25,189.47,10.91;40,112.66,452.79,147.84,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,466.34,395.17,10.91;40,112.66,479.89,393.33,10.91;40,112.66,493.44,124.68,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="40,314.25,466.34,193.57,10.91;40,112.66,479.89,126.66,10.91">Leveraging GPT-2 for Automated Classification of Online Sexist Content</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vetagiri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">K</forename><surname>Adhikary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,262.56,479.89,243.43,10.91;40,112.66,493.44,93.98,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,506.99,393.33,10.91;40,112.66,520.54,393.33,10.91;40,112.66,534.09,393.33,10.91;40,112.66,547.64,302.52,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="40,365.61,506.99,140.38,10.91;40,112.66,520.54,393.33,10.91;40,112.66,534.09,304.45,10.91">When Multiple Perspectives and an Optimization Process Lead to Better Performance, an Automatic Sexism Identification on Social Media With Pretrained Transformers in a Soft Label Context</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Erbani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Egyed-Zsigmond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P.-E</forename><surname>Portier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,439.96,534.09,66.03,10.91;40,112.66,547.64,271.82,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,561.19,393.33,10.91;40,112.66,574.74,393.32,10.91;40,112.66,588.29,330.95,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="40,328.09,561.19,177.90,10.91;40,112.66,574.74,331.69,10.91">I2C at CLEF-2023 EXIST task: Leveraging Ensembling Language Models to Detect Multilingual Sexism in Social Media</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">P</forename><surname>Pablo Cordón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacinto</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Domínguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,467.70,574.74,38.28,10.91;40,112.66,588.29,300.25,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,601.84,393.33,10.91;40,112.66,615.39,290.91,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="40,226.81,601.84,177.04,10.91">Sexism Identification In Social Networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,427.38,601.84,78.61,10.91;40,112.66,615.39,260.22,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,628.93,393.33,10.91;40,112.66,642.48,394.52,10.91;40,112.66,656.03,232.29,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="40,414.16,628.93,91.82,10.91;40,112.66,642.48,231.26,10.91">Detection of Sexism on Social Media with Multiple Simple Transformers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jhakal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Singal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gorton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="40,367.56,642.48,139.62,10.91;40,112.66,656.03,201.59,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="40,112.66,669.58,395.17,10.91;41,112.66,86.97,395.16,10.91;41,112.66,100.52,394.53,10.91;41,112.66,114.06,22.69,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="41,152.30,86.97,355.52,10.91;41,112.66,100.52,31.85,10.91">iimasGIL_NLP@Exist2023: Unveiling Sexism on Twitter with Fine-tuned Transformers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sanchez-Urbina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bel-Enguix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Rodríguez-Figueroa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Monge-Barrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,167.21,100.52,334.80,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,127.61,393.33,10.91;41,112.66,141.16,394.52,10.91;41,112.66,154.71,232.29,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="41,305.50,127.61,200.49,10.91;41,112.66,141.16,235.15,10.91">IUEXIST: Multilingual Pre-trained Language Models for Sexism Detection on Twitter in EXIST</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hatekar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,371.22,141.16,135.96,10.91;41,112.66,154.71,201.59,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,168.26,393.33,10.91;41,112.66,181.81,393.33,10.91;41,112.66,195.36,107.76,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="41,309.29,168.26,196.70,10.91;41,112.66,181.81,101.61,10.91">IU-NLP-JeDi: Investigating Sexism Detection in English and Spanish</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Buzzell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,238.30,181.81,267.69,10.91;41,112.66,195.36,77.06,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,208.91,393.33,10.91;41,112.66,222.46,393.33,10.91;41,112.66,236.01,57.08,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="41,387.57,208.91,118.42,10.91;41,112.66,222.46,42.05,10.91">Linear Models for Sexism Detection</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Redman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Iu-Percival</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,181.40,222.46,324.58,10.91;41,112.66,236.01,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,249.56,395.17,10.91;41,112.66,263.11,393.32,10.91;41,112.66,276.66,330.95,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="41,308.08,249.56,199.75,10.91;41,112.66,263.11,330.23,10.91">Combining large language models with sociodemographic information for improving Sexism Detection in Social Media</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedrosa-Marín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,466.66,263.11,39.32,10.91;41,112.66,276.66,300.25,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,290.20,393.70,10.91;41,112.66,303.75,394.52,10.91;41,112.66,317.30,387.27,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="41,307.49,290.20,198.87,10.91;41,112.66,303.75,390.01,10.91">Towards Robust Online Sexism Detection: A Multi-Model Approach with BERT, XLM-RoBERTa, and DistilBERT for EXIST 2023 Tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bagheri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,127.29,317.30,341.95,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,330.85,393.33,10.91;41,112.66,344.40,393.33,10.91;41,112.66,357.95,57.08,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="41,244.61,330.85,261.38,10.91;41,112.66,344.40,71.18,10.91">Efficient multilingual sexism detection via Large Language Models Cascades</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,205.54,344.40,300.45,10.91;41,112.66,357.95,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,371.50,393.33,10.91;41,112.66,385.05,393.33,10.91;41,112.66,398.60,124.68,10.91" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="41,232.14,371.50,273.84,10.91;41,112.66,385.05,127.88,10.91">ROH_NEIL@EXIST2023: Detecting sexism in tweets using multilingual language models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Koonireddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Adel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,263.79,385.05,242.20,10.91;41,112.66,398.60,93.98,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,412.15,394.53,10.91;41,112.28,425.70,393.92,10.91;41,112.66,439.25,393.33,10.91;41,112.66,452.79,57.08,10.91" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="41,199.18,425.70,307.01,10.91;41,112.66,439.25,73.03,10.91">Integrating Annotator Information in Transformer Fine-tuning for Sexism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Vallecillo-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M P</forename><surname>Del Arco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Martín-Valdivia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Ráez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,206.93,439.25,299.06,10.91;41,112.66,452.79,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,466.34,393.33,10.91;41,112.66,479.89,393.33,10.91;41,112.66,493.44,57.08,10.91" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="41,276.83,466.34,229.16,10.91;41,112.66,479.89,73.03,10.91">LSTM-Attention Architecture for Online Bilingual Sexism Detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kelkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Madasamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,206.93,479.89,299.06,10.91;41,112.66,493.44,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,506.99,393.33,10.91;41,112.66,520.54,393.33,10.91;41,112.66,534.09,57.08,10.91" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="41,298.23,506.99,207.76,10.91;41,112.66,520.54,42.05,10.91">Tlatlamiztli: Fine-Tuned RoBERTuito for Sexism Detection</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Asnani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rajanala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,181.40,520.54,324.58,10.91;41,112.66,534.09,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,547.64,393.33,10.91;41,112.66,561.19,393.33,10.91;41,112.66,574.74,290.91,10.91" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="41,293.63,547.64,212.35,10.91;41,112.66,561.19,292.92,10.91">UMUTeam at EXIST 2023: Sexism identification and categorisation fine-tuning Multilingual Large Language Models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A G</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Valencia-Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,428.61,561.19,77.38,10.91;41,112.66,574.74,260.22,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,588.29,393.33,10.91;41,112.66,601.84,393.33,10.91;41,112.66,615.39,136.29,10.91" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="41,201.60,588.29,304.39,10.91;41,112.66,601.84,139.65,10.91">Enriching Hate-Tuned Transformer-Based Embeddings with Emotions for the Categorization of Sexism</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mancini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,275.42,601.84,230.56,10.91;41,112.66,615.39,105.59,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,628.93,393.33,10.91;41,112.66,642.48,393.33,10.91;41,112.66,656.03,107.76,10.91" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="41,296.78,628.93,209.20,10.91;41,112.66,642.48,103.52,10.91">Specialized or Generalized? Sexism Detection for EXIST 2023 at CLEF</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Regulagedda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Leech</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="41,240.29,642.48,265.69,10.91;41,112.66,656.03,77.06,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="41,112.66,669.58,394.62,10.91" xml:id="b40">
	<monogr>
		<title level="m" type="main" coord="41,223.33,669.58,260.58,10.91">Evaluating extreme hierarchical multi-label classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Delgado</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
