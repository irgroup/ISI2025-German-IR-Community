<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.19,369.60,15.42;1,89.29,106.11,158.09,15.42;1,89.29,128.45,205.10,11.96">IU-NLP-JeDi: Investigating Sexism Detection in English and Spanish Notebook for the EXIST Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.35,81.83,11.96"><forename type="first">Matthew</forename><surname>Buzzell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.77,154.35,87.23,11.96"><forename type="first">Jeremy</forename><surname>Dickinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.64,154.35,70.54,11.96"><forename type="first">Natasha</forename><surname>Singh</surname></persName>
							<email>singhnat@iu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.17,154.35,69.50,11.96"><forename type="first">Sandra</forename><surname>KÃ¼bler</surname></persName>
							<email>skuebler@indiana.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.19,369.60,15.42;1,89.29,106.11,158.09,15.42;1,89.29,128.45,205.10,11.96">IU-NLP-JeDi: Investigating Sexism Detection in English and Spanish Notebook for the EXIST Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A427C18DD726B236B91CC66F82A1E33E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>TweetTokenizer</term>
					<term>SVM</term>
					<term>RNN</term>
					<term>CNN</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present the results from three different classification algorithms our team (IU-NLP-JeDi) developed for Task 1 of the EXIST 2023 shared task on Sexism Identification on Social Networks. The task consists of identifying sexism within English and Spanish tweets. We separated the English and Spanish tweets and then developed two different neural model approaches and an SVM model for each language. We achieved our highest ICM score on the test set from the RNN model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Sexism is defined as discrimination of a person or group based on sex. In many cases, these gender stereotypes assume a difference in social standing between men and women. However, this discrimination can be expressed explicitly (discrimination that is stated plainly) or implicitly (discrimination that is implied or obfuscated). The examples below from the EXIST 2023 dataset show the distinction between explicit and implicit sexism:</p><p>Explicit: Call me sexist all you want but no Nation ever succeeds with a woman as the Head. It's just the way it is. They final nail is already in the coffin. Implicit: Wife material, wake up and cook for your husband. Implicit sexism has been used in many online platforms to perpetuate gender stereotypes without risk of penalty from administrators of online platforms. In addition, the popularity and easy access of social media has only resulted in a further increase in content involving gender discrimination across the internet. Swim et al. <ref type="bibr" coords="1,342.62,512.87,12.84,10.91" target="#b0">[1]</ref> have shown that such prejudice impacts the performance of its victim in a tangibly negative way. Thus, detecting and limiting sexist behavior on online platforms has become a central topic of research in the field of computational linguistics. To contribute to the growing body of research on sexism detection, this paper participates in Task 1 of the sEXism Identification in Social neTworks (EXIST) 2023 shared task <ref type="bibr" coords="1,142.87,580.62,11.39,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,156.99,580.62,8.98,10.91" target="#b2">3]</ref> by training a binary classifier to predict if a given text has gender-bias. The goal of this shared task is to develop systems that can decide whether or not a given tweet contains sexist expressions or behaviors.</p><p>Our work focuses on investigating different machine learning models with regard to their suitability for the task. In this study, we conducted an in-depth analysis of the impact of several factors on the performance of various models. Specifically, we examined :</p><p>1. The effects of data pre-processing techniques on model performance.</p><p>2. The implications of utilizing word-level versus character-level models.</p><p>3. The use of soft labels versus hard labels during the training process. These approaches were developed during a course on machine learning in NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>There is a growing body of research on the topic of sexism detection. In line with our task, Vaca-Serrano <ref type="bibr" coords="2,150.18,266.21,12.84,10.91" target="#b3">[4]</ref> built a system for sexism identification and for sexism categorization for both English and Spanish. For the English tweets, DeBERTa-v3-large, RoBERTa-large and BERTweetlarge were trained, while for Spanish tweets, BERTIN, MarIA-base, BETO, and RoBERTuito were trained. After training, Vaca-Serrano implemented ensemble learning using weighted majority voting over all the models to decide on the final classification for a tweet. For sexism identification, BERTweet-large reached the highest F1-score of 0.903 for English tweets while MarIA-base reached the highest F1-score of 0.883 for Spanish tweets. For sexism identification, DeBERTa-v3-large had the highest F1-score of 0.729 for English tweets while BETO had the highest F1-score of 0.820 for Spanish tweets. Another approach taken by Chiril et al. <ref type="bibr" coords="2,493.14,374.60,12.84,10.91" target="#b4">[5]</ref> examined the effectiveness of data augmentation methods based on sentence similarity and the use of gender stereotype detection for sexism classification on a multilingual data set. The best results were obtained by a SentenceBERT model trained to detect both sexism and gender stereotypes (multiclass classification), which achieved precision and recall scores of 0.816 and 0.827 respectively, outperforming a BERT model trained on word embeddings, linguistic features and generalization strategies. Differing from the previous two approaches, <ref type="bibr" coords="2,471.60,455.89,34.38,10.91;2,89.29,469.44,51.11,10.91">Jha and Mamidi [6]</ref> used an SVM and a sequence-to-sequence model to detect sexism according to ambivalent sexism theory <ref type="bibr" coords="2,203.57,482.99,11.28,10.91" target="#b6">[7]</ref>, according to which sexism comes in hostile and benevolent forms.</p><p>By training an SVM model and a sequence-to-sequence model on a dataset labeled for hostile and benevolent sexism they found that the SVM model outperformed the sequence-to-sequence model for benevolent tweets, while the sequence-to-sequence model outperformed the SVM model for the detection of hostile tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data</head><p>We used the EXIST 2023 shared task training, validation, and test set provided by the shared task organizers. This dataset was constructed by compiling a list of over 400 commonly used sexist expressions in English and Spanish, and tweets containing these expressions were extracted for both languages. Each tweet was then classified by six crowd-sourced annotators as "sexist" or "nonsexist". Additionally, the annotators' gender (male or female) and age group (18-22 years, 23-45 years, or 46 or more years) was recorded. Since these annotations were crowdsourced, the annotators were provided with guidelines created by two experts in gender issues. It is important to note that this dataset follows the learning with disagreements paradigm, i.e., there were no gold annotations as such provided. Given that six annotations were provided for each tweet, there were cases in which there was a tie for the majority class. To generate the hard labels for the dataset, any tweet labeled as sexist by three or more of the annotators was considered "sexist".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pre-Processing</head><p>HTML characters were converted to Unicode (e.g., the HTML "&amp;gt;" was converted to "&gt;", the text font was normalized to Roman characters, removing any non-Roman characters while ensuring Spanish characters with diacritics were not removed. Any emoticons were converted to their emoji equivalents and URL links were removed. Spaces were added between consecutive usernames, and any symbols were converted to their literals (e.g., the Â°symbol to the word "degrees"). All special characters were removed before passing each tweet through NLTK's TweetTokenizer. Additionally, any numbers or words with numbers were removed. Subsequently, all hashtags were passed through a parser that removed the "#" symbol and tokenized the contents of the hashtag using Wordninja (https://github.com/keredson/wordninja), a probabilistic parser of concatenated words that was trained on the Spanish Billion Words Corpus <ref type="bibr" coords="3,392.99,353.48,12.69,10.91" target="#b7">[8]</ref> and the Kaggle English Word Frequency dataset (https://www.kaggle.com/datasets/rtatman/english-word-frequency). Pairs of upside-down question/exclamation marks and rightside-up question/exclamation marks were condensed down to a single question mark and exclamation point respectively. Finally, duplicate usernames, exclamation points, and question marks were counted before being removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Models</head><p>The following classification algorithms were chosen for the task of sexism detection in Spanish and English: Support Vector Machines with term frequency-inverse document frequency (TF-IDF) using bigrams and trigrams. Recurrent Neural Network (RNN) with one embedding layer, two bidirectional long short-term memory layers, followed by a dense layer with softmax activation. A Convolutional Neural Network (CNN) model with an embedding layer, a convolutional layer, a max pooling layer, a flatten layer, and two dense layers with ReLU and sigmoid activations respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Data Transformation &amp; Feature Extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Support Vector Machines</head><p>Support Vector Machines seek to find a line or hyperplane that maximizes the margin between two classes that are projected into vector space <ref type="bibr" coords="3,307.36,622.54,11.58,10.91" target="#b8">[9]</ref>. The SVM models trained in the present study utilize a mixture of features for sexism detection. In this study, five SVM models were trained for Spanish, and five SVM models were trained for English, resulting in ten SVM models total. All models were trained using TF-IDF of word / character bigrams and trigrams. The additional features used to train the SVM models, except for the TF-IDF bigrams and trigrams, were obtained using the tokenizer described in section 3.2. This tokenizer counts and returns the number of usernames in each tweet, the number of exclamation points, questions marks, usernames used in the possessive, and the number of hashtags present in the tweet.</p><p>Furthermore, upsampling was conducted on two clean and two original datasets for each language. The upsampling step consists of duplicating the sexist tweets present in the training set. The purpose of conducting upsampling was to increase the number of sexist tweets to improve recall on the minority class (sexism).</p><p>To summarize, the following models were trained for each language, all with TF-IDF character bigrams and trigrams: one with clean data, one with the original data, one with upsampling on the clean data, and one with upsampling on the original data, and one with upsampling and the additional features described (username counts, hashtag counts, etc.) on the clean data.</p><p>For parameter optimization, we performed grid search to obtain the best regularization(C) and gamma parameter for each SVM model. The optimal parameters for each SVM model are shown in Table <ref type="table" coords="4,160.05,485.95,3.74,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Neural Models</head><p>First, unique words from the tokenized input data are collected to form a vocabulary. Then two special tokens '[UNK]' and '[PAD]' are added to vocabulary. [UNK] is used to mask any word in test data which is not present in the vocabulary. [PAD] is used to make all the sentences of equal length. The vocabulary thus obtained is then used to encode the words in an input sentence to numbers based on the index at which they are present in the vocabulary. All unknown words are mapped to the index of [UNK] token. Finally, all the sentences are extended to a sentence of length 'max_len' (100 words or 300 chars) by adding [PAD] tokens at the end. Similarly, the output labels are one hot-encoded and are used to train the RNN and CNN model for 10 epochs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Evaluation Metrics</head><p>To allow for the comparison of the classification algorithms implemented in this study, the key metrics calculated were Accuracy, Precision, Recall and F1-score. The performance of the models were assessed primarily using the F1-score during the training and validation phase.</p><p>The final evaluation metric used to evaluate the performance of models on the test set was ICM metric <ref type="bibr" coords="5,142.81,271.24,16.25,10.91" target="#b9">[10]</ref>. ICM calculates the below scores for each model:</p><p>1. HARD-HARD: hard system output and hard ground truth. 2. HARD-SOFT: hard system output and soft ground truth. 3. SOFT-SOFT: soft system output and soft ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Performance in the Official Evaluation</head><p>For the official ICM evaluation on the test set, we submitted the predictions obtained by an RNN model (IU-NLP-JeDi_3) that was trained on the word-level processed sequences with soft labels, a CNN model (IU-NLP-JeDi_2) that was trained on word-level raw sequence with soft labels, and an SVM model (IU-NLP-JeDi_1) that was trained using TF-IDF of character bigrams and trigrams of a processed sequence.</p><p>Table <ref type="table" coords="5,127.19,470.89,5.11,10.91" target="#tab_1">2</ref> shows the results of the official evaluation on the text set for these models. Among these models, the RNN model exhibits the highest performance across all three evaluation types, followed by the SVM model and then the CNN model. Notably, both the RNN model and the SVM model attained the highest ICM scores of 0.2753 and 0.2676, respectively, in the Hard-hard evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance on the Validation Set</head><p>We performed more extensive experiments on the validation set. Table <ref type="table" coords="5,408.82,574.74,5.11,10.91" target="#tab_2">3</ref> shows the results of the ICM evaluations for the models with the best performance. Table <ref type="table" coords="5,407.02,588.29,5.17,10.91" target="#tab_3">4</ref> shows the results of a range of CNN, RNN, and SVM experiments respectively. The best macro F1 scores for each model are marked in bold for each language.</p><p>Based on the macro F1-scores, the highest performing SVM model for English was trained on TF-IDF character bigrams and trigrams constructed from English tweets that had not been preprocessed. This English model included upsampling of the minority class and achieved a macro F1-score of 0.746. The best performing CNN and RNN models were trained using word-level processed input sequences and hard-label outputs. These models achieved a macro F1-score of 0.721 and 0.7546 respectively. As for Spanish, the best performing SVM model was trained on TF-IDF character bigrams and trigrams taken from preprocessed Spanish tweets without any additional features. This model did not include upsampling and it reached a macro F1-score of 0.740. The highest performing CNN and RNN models were trained on word level raw sequences with hard labels. They attained an F1-score of 0.702 and 0.701 respectively. For the ICM evaluation on the validation set, the prediction result of each model for both languages was consolidated and evaluated based on Hard-hard and Hard-soft scores. Among the various models, the SVM model trained using TF-IDF of processed input and the RNN model trained on word-level processed sequences and soft labels emerged as the top-performing models, exhibiting Hard-hard scores of 0.2992 and 0.2923, respectively. Only the RNN trained on word-level sequences and soft labels achieved a positive Hard-soft score of 0.2831. All the remaining models performed poorly on this metric and obtained negative results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Investigating the Effects of Preprocessing</head><p>Table 4 also shows the experiments using pre-processing for all models and for upsampling with the SVM. These results show that the cleaning and preprocessing step results in a higher performance for both languages. For English, the macro F1-score increases from 0.727 to 0.739, and for Spanish, it increases from 0.692 to 0.740. Upsampling sexist tweets also improves the SVM models. The results also show that preprocessing boosts the performance of the RNN and CNN models for English, but affects the performance negatively for Spanish. In the case of English, the RNN model's F1-score improves from 0.722 to 0.7546 and the CNN model's F1-score improves from 0.713 to 0.721. However, for Spanish, the RNN model's F1-score declines from 0.701 to 0.6849 and the CNN model's F1-score drops from 0.705 to 0.6947.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitation and Challenges</head><p>The main limitations in our study comes from two sources: (i) the inability of neural models, such as RNNs and CNNs, to handle long sequences and (ii) the information loss due to preprocessing. Some of the tweets in the EXIST 2023 dataset were around 100 words long and in such cases, the neural models are not able to effectively model long dependencies. Neural models tend to forget the initial words of the sequence, leading to a decline in model performance. This problem is more prominent when using a character level model where the sequence length was roughly 300 characters long. This was evident from the experiments as the character-level models consistently under-performed against the word-level models. The other major limitation of information loss due to preprocessing was a combined effect of non-standard spelling in the tweets, the presence of both English and Spanish words in the same tweet, and the presence of words and characters from other languages. All words which were not seen during the training phase were replaced by [UNK] token, thus preventing the models from accessing information which may be crucial in determining if a tweet was sexist or not. In our training setup, we created a separate model for English and Spanish tweets. Due to this, we categorized the tweets with both English and Spanish words as Spanish and treated English words as out of vocabulary words, thus replacing them with the token [UNK]. Lastly, some tweets had characters/words from other languages which were completely removed in our analysis. All these factors lead to an information loss for our models, hence decreasing the model's performance.</p><p>Additionally, there were many challenges we faced throughout our study, specifically focused on the creation of an accurate tokenizer. While analyzing the tweets, we encountered tweets using non-Roman characters, leading to issues when trying to tokenize these tweets. These included characters from other languages, such as Arabic, Gregorian, CJK, Hangul, and Hiranaga characters, and non-traditional styles of Roman characters, such as Gothic letters. To handle this issue, we used the unicode values of the characters we wanted and removed any characters outside of that range of unicode values. Another challenge with the tokenizer came from punctuation marks and the differences in punctuation between Spanish and English. In order to simplify processing, we decided to delete the Spanish inverted punctuation. However, punctuation tends to be irregular or missing in tweets. For this reason, we developed a heuristic that deleted an inverted punctuation mark only if a regular one could be found in the tweet. We faced additional challenges when handling emoji, removing usernames and inconsistent diacritics. For all of those cases, we developed diacritics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>In this study we demonstrated that when optimized on F1-score, the neural models trained on word level with hard labels and an SVM trained on TF-IDF of character bigrams and trigrams are our best performing models. However, when optimized on ICM metric, the neural models show better performance with soft labels and the behavior of the SVM remains unchanged. These findings illustrate the dependency of model behavior on the choice of evaluation metric. Additionally, we showed that applying upsampling techniques on the minority class can enhance the performance of SVM models when dealing with an imbalanced datasets.</p><p>For future work, we will investigate how to utilize the gender and age information of the annotators, either by modeling this latent variable in the models, or by choosing reliable training data or labels. Additionally, we will investigate whether the labels are influenced by the gender bias of the annotators.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,90.49,369.00,165.51"><head>Table 1</head><label>1</label><figDesc>Optimal hyperparameters for each SVM model.</figDesc><table coords="4,137.28,122.10,320.71,133.90"><row><cell>Model</cell><cell cols="2">Lang. C</cell><cell cols="2">Gamma Kernel</cell></row><row><cell>raw SVM</cell><cell>EN</cell><cell>1</cell><cell>1</cell><cell>RBF</cell></row><row><cell>processed SVM</cell><cell>EN</cell><cell cols="2">0.1 10</cell><cell>Poly</cell></row><row><cell>raw SVM with upsampling</cell><cell>EN</cell><cell cols="2">10 1</cell><cell>RBF</cell></row><row><cell>processed SVM with upsampling</cell><cell>EN</cell><cell cols="2">0.1 10</cell><cell>Poly</cell></row><row><cell cols="2">processed SVM with upsampling &amp; features EN</cell><cell>1</cell><cell>10</cell><cell>Poly</cell></row><row><cell>raw SVM raw</cell><cell>ES</cell><cell>1</cell><cell>0.1</cell><cell>RBF</cell></row><row><cell>processed SVM</cell><cell>ES</cell><cell>1</cell><cell>1</cell><cell>Poly</cell></row><row><cell>raw SVM with upsampling</cell><cell>ES</cell><cell cols="2">10 1</cell><cell>RBF</cell></row><row><cell>processed SVM with upsampling</cell><cell>ES</cell><cell cols="2">10 1</cell><cell>RBF</cell></row><row><cell cols="2">processed SVM with upsampling &amp; features ES</cell><cell cols="2">10 0.1</cell><cell>Linear</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,90.49,373.18,79.60"><head>Table 2</head><label>2</label><figDesc>Official evaluation scores on test set.</figDesc><table coords="5,133.10,119.88,329.07,50.21"><row><cell>Model</cell><cell cols="6">Class. Rank Soft-soft Hard-hard F1 score Hard-soft</cell></row><row><cell cols="2">IU-NLP-JeDi_3 RNN</cell><cell>31</cell><cell>0.1244</cell><cell>0.2753</cell><cell>0.6909</cell><cell>-0.5071</cell></row><row><cell cols="2">IU-NLP-JeDi_2 CNN</cell><cell>34</cell><cell>-0.1499</cell><cell>0.1851</cell><cell>0.6485</cell><cell>0.4139</cell></row><row><cell cols="2">IU-NLP-JeDi_1 SVM</cell><cell>-</cell><cell>-</cell><cell>0.2676</cell><cell>0.4839</cell><cell>-0.5097</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,352.22,163.29"><head>Table 3</head><label>3</label><figDesc>ICM evaluation scores on the validation set.</figDesc><table coords="6,154.06,119.88,287.15,133.90"><row><cell>Model</cell><cell cols="4">Level Labels Hard-hard Hard-soft</cell></row><row><cell>processed RNN</cell><cell cols="2">word soft</cell><cell>0.2923</cell><cell>0.2831</cell></row><row><cell></cell><cell cols="2">word hard</cell><cell>0.1447</cell><cell>-0.4564</cell></row><row><cell></cell><cell>char</cell><cell>hard</cell><cell>-0.2652</cell><cell>-0.9556</cell></row><row><cell></cell><cell>char</cell><cell>soft</cell><cell>-0.1883</cell><cell>-0.8432</cell></row><row><cell>raw CNN</cell><cell>char</cell><cell>soft</cell><cell>-0.2491</cell><cell>-0.9167</cell></row><row><cell></cell><cell>char</cell><cell>hard</cell><cell>-0.2687</cell><cell>-1.0151</cell></row><row><cell></cell><cell cols="2">word hard</cell><cell>0.1853</cell><cell>-0.0603</cell></row><row><cell></cell><cell cols="2">word soft</cell><cell>0.2104</cell><cell>0.0022</cell></row><row><cell>processed SVM</cell><cell>char</cell><cell>hard</cell><cell>0.2992</cell><cell>-0.2773</cell></row><row><cell cols="2">raw SVM with upsampling char</cell><cell>hard</cell><cell>0.2581</cell><cell>-0.4038</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,276.03,384.10,216.59"><head>Table 4</head><label>4</label><figDesc>Macro F1 scores for the different models.</figDesc><table coords="6,122.19,305.43,350.90,187.19"><row><cell>Model</cell><cell cols="5">Lang. Level F1: CNN F1: RNN F1: SVM</cell></row><row><cell>raw</cell><cell>EN</cell><cell>word</cell><cell>0.713</cell><cell>0.722</cell><cell>0.307</cell></row><row><cell></cell><cell>EN</cell><cell>char</cell><cell>0.544</cell><cell>0.618</cell><cell>0.727</cell></row><row><cell>raw + upsampling</cell><cell>EN</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.746</cell></row><row><cell>processed</cell><cell>EN</cell><cell>word</cell><cell>0.721</cell><cell>0.755</cell><cell>0.379</cell></row><row><cell></cell><cell>EN</cell><cell>char</cell><cell>0.556</cell><cell>0.556</cell><cell>0.739</cell></row><row><cell>processed + upsampling</cell><cell>EN</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.737</cell></row><row><cell cols="2">processed + upsampling + features EN</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.686</cell></row><row><cell>raw</cell><cell>ES</cell><cell>word</cell><cell>0.654</cell><cell>0.701</cell><cell>0.392</cell></row><row><cell></cell><cell>ES</cell><cell>Char</cell><cell>0.539</cell><cell>0.576</cell><cell>0.692</cell></row><row><cell>raw + upsampling</cell><cell>ES</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.707</cell></row><row><cell>processed</cell><cell>ES</cell><cell>word</cell><cell>0.702</cell><cell>0.685</cell><cell>0.372</cell></row><row><cell></cell><cell>ES</cell><cell>char</cell><cell>0.601</cell><cell>0.641</cell><cell>0.740</cell></row><row><cell>processed + upsampling</cell><cell>ES</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.732</cell></row><row><cell cols="2">processed + upsampling + features ES</cell><cell>char</cell><cell>-</cell><cell>-</cell><cell>0.701</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,366.81,393.53,10.91;8,112.66,380.36,393.33,10.91;8,112.66,393.91,131.66,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,366.27,366.81,139.91,10.91;8,112.66,380.36,340.90,10.91">Everyday sexism: Evidence for its incidence, nature, and psychological impact from three daily diary studies</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">K</forename><surname>Swim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Hyers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,461.70,380.36,44.29,10.91;8,112.66,393.91,55.76,10.91">Journal of Social Issues</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="31" to="53" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,407.46,394.53,10.91;8,112.66,421.01,393.33,10.91;8,112.66,434.55,394.53,10.91;8,112.66,448.10,393.33,10.91;8,112.66,461.65,333.46,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,112.66,421.01,393.33,10.91;8,112.66,434.55,72.05,10.91">Overview of EXIST 2023 -Learning with Disagreement for Sexism Identification and Characterization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De-Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,401.00,448.10,104.99,10.91;8,112.66,461.65,206.17,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,475.20,394.53,10.91;8,112.66,488.75,393.33,10.91;8,112.66,502.30,393.33,10.91;8,112.33,515.85,395.22,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,112.66,488.75,393.33,10.91;8,112.66,502.30,164.31,10.91">Overview of EXIST 2023 -Learning with Disagreement for Sexism Identification and Characterization (Extended Overview)</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De-Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.67,515.85,335.74,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,529.40,394.61,10.91;8,112.66,542.95,103.02,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,189.20,529.40,298.41,10.91">Detecting and classifying sexism by ensembling transformers models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaca-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,542.95,72.06,10.91">IberLEF@SEPLN</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,556.50,393.33,10.91;8,112.66,570.05,393.33,10.91;8,112.66,583.60,271.52,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,275.02,556.50,230.97,10.91;8,112.66,570.05,253.28,10.91">be nice to your wife! the restaurants are closed&quot;: Can gender stereotype detection improve sexism classification?</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Chiril</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,387.61,570.05,118.38,10.91;8,112.66,583.60,169.84,10.91">Findings of the Association for Computational Linguistics: EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2833" to="2844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,597.15,393.33,10.91;8,112.66,610.69,393.33,10.91;8,112.66,624.24,223.43,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,195.61,597.15,310.38,10.91;8,112.66,610.69,166.48,10.91">When does a compliment become sexist? Analysis and classification of ambivalent sexism using Twitter data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mamidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,302.12,610.69,203.87,10.91;8,112.66,624.24,148.79,10.91">Proceedings of the Second Workshop on NLP and Computational Social Science</title>
		<meeting>the Second Workshop on NLP and Computational Social Science</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="7" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,637.79,395.17,10.91;8,112.66,651.34,305.76,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,201.56,637.79,306.27,10.91;8,112.66,651.34,47.81,10.91">The ambivalent sexism inventory: Differentiating hostile and benevolent sexism</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Glick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Fiske</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,169.06,651.34,199.49,10.91">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="page">491</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,395.01,10.91;9,112.66,100.52,83.81,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cardellino</surname></persName>
		</author>
		<ptr target="https://crscardellino.github.io/SBWCE/" />
		<title level="m" coord="9,176.24,86.97,206.79,10.91">Spanish Billion Words Corpus and embeddings</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,393.53,10.91;9,112.66,127.61,354.30,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="9,258.66,114.06,247.54,10.91;9,112.66,127.61,140.48,10.91">An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Christianini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,394.62,10.91;9,112.66,154.71,393.32,10.91;9,112.33,168.26,122.11,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,223.40,141.16,260.55,10.91">Evaluating extreme hierarchical multi-label classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Delgado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,154.71,393.32,10.91;9,112.33,168.26,23.88,10.91">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5809" to="5819" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
