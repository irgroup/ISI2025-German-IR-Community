<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,396.40,15.42;1,89.29,106.66,163.96,15.42">Detection of Sexism on Social Media with Multiple Simple Transformers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,73.28,11.96"><forename type="first">Chirayu</forename><surname>Jhakal</surname></persName>
							<email>jhakalchirayu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Netaji Subhas University of Technology (NSUT)</orgName>
								<address>
									<addrLine>Dwarka Sector-3</addrLine>
									<postCode>110078</postCode>
									<settlement>Dwarka</settlement>
									<region>Delhi</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,186.73,134.97,67.83,11.96"><forename type="first">Khushi</forename><surname>Singal</surname></persName>
							<email>khushisingal7@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Netaji Subhas University of Technology (NSUT)</orgName>
								<address>
									<addrLine>Dwarka Sector-3</addrLine>
									<postCode>110078</postCode>
									<settlement>Dwarka</settlement>
									<region>Delhi</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.72,134.97,56.74,11.96"><forename type="first">Manan</forename><surname>Suri</surname></persName>
							<email>manansuri27@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Netaji Subhas University of Technology (NSUT)</orgName>
								<address>
									<addrLine>Dwarka Sector-3</addrLine>
									<postCode>110078</postCode>
									<settlement>Dwarka</settlement>
									<region>Delhi</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.62,134.97,87.05,11.96"><forename type="first">Divya</forename><surname>Chaudhary</surname></persName>
							<email>d.chaudhary@northeastern.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Khoury College of Computer Sciences</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,148.92,77.61,11.96"><forename type="first">Bijendra</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Netaji Subhas University of Technology (NSUT)</orgName>
								<address>
									<addrLine>Dwarka Sector-3</addrLine>
									<postCode>110078</postCode>
									<settlement>Dwarka</settlement>
									<region>Delhi</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.42,148.92,53.43,11.96"><forename type="first">Ian</forename><surname>Gorton</surname></persName>
							<email>i.gorton@northeastern.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Khoury College of Computer Sciences</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,396.40,15.42;1,89.29,106.66,163.96,15.42">Detection of Sexism on Social Media with Multiple Simple Transformers</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4F41867EC41641E9C17023D316975C10</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sexism Detection</term>
					<term>Simple Transformer Models</term>
					<term>Natural Language Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media platforms have become virtual communication channels, allowing users to voice their thoughts and opinions. However, this openness and features of anonymity have also given rise to the proliferation of harmful and offensive content, including sexism. This research aims at proposing a methodology and explores the use of different simple transformers. Monolingual Simple Transformers such as BERT, RoBERTa[1], BERTweet, DistilBERT, XLNet were evaluated on the EXIST2023 shared task challenge at the IberLEF2023 dataset. It was observed that RoBERTa has given the best results among all other transformers. The proposed approach has great scope for the efficient detection of sexist content on social media, aiding in the development of effective content moderation systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Social media platforms have been revolutionary in the way people communicate and express themselves in this digital age. These platforms have become a ubiquitous part of our daily lives, enabling users to share thoughts and opinions and engage in social interactions. However, along with the numerous benefits, the openness and features like anonymity and accessibility of social media have also given rise to a concerning issue -the rapid increase of offensive and harmful content, including sexism.</p><p>Sexism, defined as discrimination, stereotyping, or prejudice based on gender, continues to be a pervasive problem in society. The presence of such content on social media not only perpetuates harmful gender biases on possibly young and impressionable minds but also undermines the inclusivity and safety of these online spaces. Consequently, there is a pressing need to develop effective methods for detecting and mitigating sexist content on social media.</p><p>In this work, we mainly focus on using Natural Language Processing techniques and state-ofthe-art models for sexism detection, which aims to identify if a specific sentence contains sexist content. The salient features of the proposed methodology are:</p><p>• The use of transformer-based language models, such as BERT (Bidirectional Encoder Representations from Transformers) <ref type="bibr" coords="2,280.71,123.03,14.16,10.91" target="#b1">[2]</ref>, RoBERTa (Robustly Optimized BERT) <ref type="bibr" coords="2,473.55,123.03,14.42,10.91" target="#b1">[2]</ref>[1], and BERTweet, etc. These models, pre-trained on vast amounts of textual data, have demonstrated exceptional capabilities in understanding and processing the complexities of human language <ref type="bibr" coords="2,199.13,163.68,13.90,10.91" target="#b1">[2]</ref>. • The methodology involves training and fine-tuning the transformer models on the EX-IST2023 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>There has been an increase in the work and interest in sexism detection as all social media platforms want to limit offensive content and make their platforms more inclusive. Examples of such work are from the EXIST2022 edition: In <ref type="bibr" coords="2,314.79,277.86,11.59,10.91" target="#b2">[3]</ref>, the use of Multilingual Models <ref type="bibr" coords="2,476.24,277.86,14.87,10.91" target="#b2">[3]</ref>and Data Augmentation has been employed, and researchers have leveraged multilingual models to detect sexist content across different languages <ref type="bibr" coords="2,295.80,304.95,28.36,10.91">[3] [4]</ref>. To overcome the lack of data in specific languages, data augmentation techniques have been employed <ref type="bibr" coords="2,363.76,318.50,12.69,10.91" target="#b2">[3]</ref> [4] <ref type="bibr" coords="2,394.24,318.50,26.51,10.91">[5] [6]</ref>. In <ref type="bibr" coords="2,439.16,318.50,11.28,10.91" target="#b6">[7]</ref>, the English dataset and the Spanish dataset have been trained separately using a HuggingFace transformer <ref type="bibr" coords="2,89.29,345.60,12.69,10.91" target="#b6">[7]</ref> [8] <ref type="bibr" coords="2,119.05,345.60,11.28,10.91" target="#b5">[6]</ref>. <ref type="bibr" coords="2,137.09,345.60,12.68,10.91" target="#b3">[4]</ref> uses the ensemble of 5 classification monolingual models and back-translation has been used for augmenting the data; while <ref type="bibr" coords="2,270.30,359.15,12.69,10.91" target="#b4">[5]</ref> used datasets of different languages such as French, German, and Italian and translated them into the pivot languages and BERTweet and BETO have been used for English and Spanish respectively in a gradual unfreezing-discriminative finetuning fashion <ref type="bibr" coords="2,157.71,399.80,31.98,10.91">[9] [10]</ref>. In <ref type="bibr" coords="2,208.94,399.80,16.33,10.91" target="#b10">[11]</ref>, pre-processing methods like TFIDF (Term Frequency-Inverse Document Frequency), Bag of words, and word2vec have been employed <ref type="bibr" coords="2,407.89,413.35,17.76,10.91" target="#b10">[11]</ref> and have seen the use of basic algorithms like Naive Bayes, Support Vector Machines (SVM), and Linear Regression to achieve remarkable results. In <ref type="bibr" coords="2,240.29,440.45,16.41,10.91" target="#b11">[12]</ref>, a framework for sexism detection on social media via ByT5 and TabNet has been implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The EXIST2023 dataset comprises posts from social media platforms like Twitter and Gab, accompanied by annotations categorizing them into different types of sexism. The dataset is divided into separate train and test partitions. The training set contains 6920 instances in both English <ref type="bibr" coords="2,124.30,574.24,12.26,10.91" target="#b2">(3,</ref><ref type="bibr" coords="2,136.56,574.24,16.35,10.91">260)</ref> and Spanish (3,660) languages. Meanwhile, the test set consists of 2,076 instances, with 978 posts in English and 1098 posts in Spanish. Each data instance is labeled with binary labels (for task 1) to determine whether it is classified as sexist or non-sexist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Exploratory Analysis</head><p>Before proceeding with the preprocessing steps, we performed an exploratory analysis of the dataset <ref type="bibr" coords="2,120.01,664.61,17.55,10.91" target="#b12">[13]</ref>. This analysis involved gaining insights into the distribution of sexist content, identifying common patterns, and understanding the characteristics of the data. We examined the frequency of sexist posts, the prevalent forms of sexist language and expressions, and any potential biases in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Preprocessing</head><p>The preprocessing began with the segregation of English data and Spanish data because both languages are structurally and semantically quite different, so applying various language models to the data would be easy and efficient <ref type="bibr" coords="3,287.57,190.89,12.99,10.91" target="#b6">[7]</ref> [4] [10] <ref type="bibr" coords="3,341.91,190.89,11.58,10.91" target="#b8">[9]</ref>. After cleaning the data various preprocessing techniques were applied <ref type="bibr" coords="3,264.92,204.44,16.39,10.91" target="#b13">[14]</ref>:</p><p>• Removing web addresses from text.</p><p>• Removing emoticons from the text.</p><p>• Removing unrecognized characters, emojis, and stickers from text.</p><p>• Removing special characters.</p><p>• Removing repeating patterns like aaaaa, bbbbb, 00 etc.</p><p>• Stemming words using Porter stemmer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pre-trained Transformer Models</head><p>• RoBERTa: Robustly Optimized BERT (RoBERTa) <ref type="bibr" coords="3,330.66,351.20,12.70,10.91" target="#b0">[1]</ref> is an optimized variant of BERT that incorporates additional pre-training techniques. We fine-tuned the pre-trained RoBERTa model on our dataset to specifically detect and classify instances of sexist content. In English models, we applied RoBERTa after pre-processing and got decent results but in the Spanish model, we got even better results <ref type="bibr" coords="3,321.31,405.40,17.91,10.91" target="#b14">[15]</ref> [7] <ref type="bibr" coords="3,357.51,405.40,11.43,10.91" target="#b3">[4]</ref>. • BERT: Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" coords="3,438.62,420.30,17.82,10.91" target="#b15">[16]</ref> is a widely used transformer model that captures bidirectional contextual information. We fine-tuned the pre-trained BERT model on our dataset to identify sexist content with improved accuracy. BERT didn't give satisfactory results on the English dataset but performed better on the Spanish dataset <ref type="bibr" coords="3,248.44,474.50,17.91,10.91" target="#b16">[17]</ref> [18] <ref type="bibr" coords="3,289.72,474.50,11.43,10.91" target="#b8">[9]</ref>. • Distill-BERT <ref type="bibr" coords="3,169.79,489.40,17.74,10.91" target="#b18">[19]</ref>: DistilBERT is a distilled version of the BERT model that offers a lighter and faster alternative while maintaining comparable performance. We fine-tuned the pretrained DistilBERT model on our dataset to detect sexist content efficiently. DistilBERT was applied only on the Spanish dataset and gave poor results <ref type="bibr" coords="3,395.54,530.05,11.43,10.91" target="#b5">[6]</ref>. • BERTweet <ref type="bibr" coords="3,163.69,544.96,16.23,10.91" target="#b19">[20]</ref>: We fine-tuned the pre-trained BERTweet model on our dataset, specifically designed to handle social media text. BERTweet employs a specialized vocabulary and tokenization scheme tailored to social media language, enabling it to effectively detect and classify instances of sexism in social media posts <ref type="bibr" coords="3,355.32,585.60,12.84,10.91" target="#b6">[7]</ref> [17] <ref type="bibr" coords="3,391.53,585.60,11.43,10.91" target="#b4">[5]</ref>. • CamemBERT: CamemBERT is a transformer model specifically designed for the French language. It is trained on large-scale French corpora and exhibits strong language understanding capabilities. We fine-tuned the pre-trained CamemBERT model on our dataset to accurately detect and categorize instances of sexism in French social media posts.</p><p>CamemBERT was only applied to the Spanish dataset and it gave the best results <ref type="bibr" coords="3,477.65,654.71,12.81,10.91" target="#b6">[7]</ref> [8] <ref type="bibr" coords="3,116.56,668.25,11.43,10.91" target="#b5">[6]</ref>.</p><p>• XLNet: XLNet is a transformer model that employs permutation-based training, allowing it to capture bidirectional and context-aware representations effectively. We fine-tuned the pre-trained XLNet model on our dataset to enhance the detection and classification of sexist content. XlNet on the English dataset gave the best results among other models <ref type="bibr" coords="4,116.56,141.16,12.84,10.91" target="#b6">[7]</ref> [8] <ref type="bibr" coords="4,147.70,141.16,11.43,10.91" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this study, we aimed to detect sexism in tweets written in both English and Spanish using pre-trained transformer models. Specifically, we employed four different models for English tweets, namely RoBERTa, BERT, BERTweet, and XLNet, while for Spanish tweets, we utilized BERT, DistilBERT, RoBERTa, and CamemBERT. The performance of each model was evaluated based on its accuracy in identifying instances of sexism in the tweets.</p><p>For the English language, the RoBERTa model achieved an accuracy of 59.02% in detecting sexism, while the BERT model achieved an accuracy of 56.16%. The BERTweet model, designed specifically for tweets, achieved an accuracy of 69.60%, outperforming both RoBERTa and BERT. The XLNet model, which incorporates a permutation-based approach, demonstrated the highest accuracy among the English models, achieving 71.34%.</p><p>In the case of Spanish tweets, the BERT model achieved an accuracy of 62.24% in detecting sexism, followed by DistilBERT with an accuracy of 58.38%. The RoBERTa model exhibited an accuracy of 62.77%, while the CamemBERT model demonstrated the highest accuracy among the Spanish models, achieving 69.05%.</p><p>These results indicate that the choice of pre-trained model has a significant impact on the performance of sexism detection in tweets. While all models achieved relatively moderate accuracy, the BERTweet model for English and the CamemBERT model for Spanish exhibited the highest accuracies, suggesting their effectiveness in identifying instances of sexism in tweets.</p><p>It is important to note that accuracy alone does not capture the full picture of model performance, and other evaluation metrics, such as precision, recall, and F1 score, should be considered for a comprehensive analysis. Furthermore, the generalizability of these models to different datasets and domains should be further investigated to assess their robustness and applicability in real-world scenarios. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The results of our study demonstrate the performance of various pre-trained transformer models in detecting sexism in tweets written in both English and Spanish. Overall, the models exhibited varying levels of accuracy, indicating their effectiveness in identifying instances of sexism in social media content.</p><p>For the English language, the BERTweet and XLNet models performed relatively better than the RoBERTa <ref type="bibr" coords="5,146.28,293.27,16.68,10.91" target="#b0">[1]</ref> and BERT models <ref type="bibr" coords="5,245.26,293.27,19.23,10.91" target="#b15">[16]</ref>. This observation suggests that models specifically designed for processing Twitter data, such as BERTweet, may be more suitable for capturing the nuances and informal language commonly used in tweets. The XLNet model, which utilizes a permutation-based approach, outperformed the other models, possibly due to its ability to capture long-range dependencies in the text.</p><p>In the case of Spanish tweets, the CamemBERT model displayed the highest accuracy among the evaluated models. This indicates that CamemBERT, which is specifically trained on Spanish text, is effective in capturing the linguistic characteristics and context-specific aspects of Spanish tweets. However, it is worth noting that the accuracies achieved by the Spanish models were relatively lower compared to the English models, suggesting the need for further research and improvement in detecting sexism in Spanish-language tweets.</p><p>It is important to consider the limitations of our study. First, the evaluation was performed on a specific dataset, and the results may not be directly generalizable to other datasets or real-world scenarios. Additionally, the performance of the models may vary depending on the nature of the tweets, the distribution of sexism-related content, and cultural or contextual factors. Further research is needed to assess the robustness and generalizability of these models across diverse datasets and contexts.</p><p>Moreover, accuracy alone may not be sufficient to fully evaluate the performance of sexism detection models. Additional metrics such as precision, recall, and F1 score should be considered to assess the models' ability to correctly identify instances of sexism while minimizing false positives and false negatives.</p><p>In conclusion, our study highlights the effectiveness of pre-trained transformer models in detecting sexism in tweets, both in English and Spanish. The results demonstrate the importance of using language-specific models and models designed for social media data to achieve higher accuracy. This research contributes to the development of automated systems for identifying and addressing sexism in online communication, ultimately fostering a more inclusive and respectful digital environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this research, we investigated the detection of sexism in tweets using pre-trained transformer models for both English and Spanish languages. Our results demonstrate that these models can be effective in identifying instances of sexism in social media content. The BERTweet model performed well in capturing the nuances of English tweets, while the CamemBERT model showed promise for Spanish tweets. Additionally, the XLNet model exhibited superior performance among the English models, highlighting the effectiveness of permutation-based approaches. However, it is important to note that the accuracies achieved, especially for Spanish models, can still be improved.</p><p>The findings of this study have implications for developing automated systems that can detect and mitigate sexism in online communication. By leveraging pre-trained transformer models, we can gain insights into the prevalence of sexism and take steps toward fostering a more inclusive and respectful digital environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Future Work</head><p>While this research provides valuable insights into the detection of sexism in tweets, there are several avenues for future work that can enhance the accuracy and robustness of the models.</p><p>Firstly, data augmentation techniques can be employed to improve model performance [3] [4] [5] <ref type="bibr" coords="6,119.99,359.59,11.28,10.91" target="#b5">[6]</ref>. By increasing the diversity and quantity of training data through techniques such as back-translation, word replacement, or text synthesis, we can potentially reduce the model's bias and enhance its ability to detect subtle forms of sexism.</p><p>Secondly, ensemble modeling can be explored to leverage the strengths of multiple models and improve overall performance. By combining predictions from different models, either by majority voting or weighted averaging, we can potentially achieve higher accuracy and mitigate the limitations of individual models.</p><p>Furthermore, it is important to expand the evaluation of sexism detection models to different languages and cultural contexts. The linguistic characteristics and contextual nuances can significantly vary across languages, necessitating the development of language-specific models and datasets.</p><p>Additionally, further research should focus on addressing the issue of bias in the models. It is crucial to identify and mitigate any biases encoded in the pre-trained models to ensure fair and equitable detection of sexism.</p><p>Finally, it would be beneficial to conduct user studies and assess the real-world impact of automated systems in addressing sexism in online spaces. Understanding user perceptions, reactions, and potential ethical concerns will guide the development of more effective and responsible solutions.</p><p>By pursuing these avenues, we can advance the field of sexism detection in social media and contribute to the development of robust and inclusive technologies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,524.43,272.71,86.37"><head>Table 1</head><label>1</label><figDesc>English Classification Models and Accuracy</figDesc><table coords="4,233.58,552.52,128.12,58.28"><row><cell cols="2">English Models Accuracy (%)</cell></row><row><cell>RoBERTa</cell><cell>59.02</cell></row><row><cell>BERT</cell><cell>56.16</cell></row><row><cell>BERTweet</cell><cell>69.60</cell></row><row><cell>XLNet</cell><cell>71.34</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,111.28,394.53,10.91;7,112.30,124.83,393.68,10.91;7,112.66,138.38,107.17,10.91" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="7,173.53,124.83,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,151.93,393.33,10.91;7,112.66,165.48,373.82,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Turc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08962</idno>
		<title level="m" coord="7,323.12,151.93,182.87,10.91;7,112.66,165.48,191.23,10.91">Well-read students learn better: On the importance of pre-training compact models</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,179.03,394.53,10.91;7,112.48,192.57,393.50,10.91;7,112.26,206.12,393.72,10.91;7,112.66,219.67,273.60,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,293.51,192.57,212.47,10.91;7,112.26,206.12,160.79,10.91">Transfer learning for automatic sexism detection with multilingual transformer models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Liakhovets</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schütz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Böck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Andresel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kirchknopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Babic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Slijpcevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zeppelzauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,294.98,206.12,211.00,10.91;7,112.66,219.67,94.37,10.91">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2022)</title>
		<meeting>the Iberian Languages Evaluation Forum (IberLEF 2022)<address><addrLine>A Coruna, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS. org</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,233.22,393.33,10.91;7,112.66,246.77,128.82,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ahuir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Á</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-F</forename><surname>Hurtado</surname></persName>
		</author>
		<title level="m" coord="7,283.12,233.22,222.87,10.91;7,112.66,246.77,96.91,10.91">Enhancing sexism identification and categorization in low-data situations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,260.32,340.81,10.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,234.40,260.32,186.69,10.91">Are examples worth more than language?</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Tamayo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Bueno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,273.87,393.32,10.91;7,112.66,287.42,393.33,10.91;7,112.33,300.97,29.19,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>García-Baena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Á</forename><surname>García-Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Jiménez-Zafra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>García-Vega</surname></persName>
		</author>
		<title level="m" coord="7,472.60,273.87,33.38,10.91;7,112.66,287.42,393.33,10.91">Sinai at exist 2022: Exploring data augmentation and machine translation for sexism identification</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,314.52,394.52,10.91;7,112.66,328.07,87.86,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,192.25,314.52,309.97,10.91">Detecting and classifying sexism by ensembling transformers models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaca-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,112.66,328.07,40.34,10.91">language</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,341.62,393.33,10.91;7,112.66,355.17,235.12,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,367.42,341.62,138.57,10.91;7,112.66,355.17,203.20,10.91">Automatic sexism identification using an ensemble of pretrained transformers</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">P</forename><surname>Álvarez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chibane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Domínguez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,368.71,394.53,10.91;7,112.66,382.26,393.33,10.91;7,112.66,395.81,73.61,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Plaza-Del Arco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-D</forename><surname>Molina-González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Martín-Valdivia</surname></persName>
		</author>
		<title level="m" coord="7,112.66,382.26,393.33,10.91;7,112.66,395.81,41.69,10.91">Exploring the use of different linguistic phenomena for sexism identification in social networks</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,409.36,393.33,10.91;7,112.66,422.91,113.26,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bengoetxea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aguirregoitia</surname></persName>
		</author>
		<title level="m" coord="7,259.93,409.36,246.06,10.91;7,112.66,422.91,81.34,10.91">Multiaztertest@ exist-iberlef2022: Sexism identification in social networks</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,436.46,393.33,10.91;7,112.66,450.01,73.61,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rizvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jamatia</surname></persName>
		</author>
		<title level="m" coord="7,206.96,436.46,299.02,10.91;7,112.66,450.01,41.69,10.91">Nit-agartala-nlp-team at exist 2022: Sexism identification in social networks</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,463.56,393.33,10.91;7,112.66,477.11,59.97,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,229.77,463.56,276.22,10.91;7,112.66,477.11,28.05,10.91">A framework for sexism detection on social media via byt5 and tabnet</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Younus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Qureshi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,490.66,332.37,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<title level="m" coord="7,194.65,490.66,111.68,10.91">Exploratory data analysis</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,504.21,393.33,10.91;7,112.66,517.76,395.00,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,317.51,504.21,188.48,10.91;7,112.66,517.76,104.62,10.91">Transfer learning from multilingual deberta for sexism identification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Najjar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,239.69,517.76,128.02,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,531.30,393.33,10.91;7,112.66,544.85,393.33,10.91;7,112.66,558.40,393.33,10.91;7,112.66,571.95,393.33,10.91;7,112.14,585.50,234.16,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,248.37,531.30,257.62,10.91;7,112.66,544.85,249.90,10.91">Detection and classification of sexism on social media using multiple languages, transformers, and ensemble models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F M</forename><surname>De Paula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,386.71,544.85,119.27,10.91;7,112.66,558.40,393.33,10.91;7,112.66,571.95,359.74,10.91">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2022) co-located with the XXXVIII International Conference of the Spanish Society for Natural Language Processing (SEPLN 2022)</title>
		<title level="s" coord="7,479.43,571.95,26.55,10.91;7,112.14,585.50,100.24,10.91">CEUR Workshop proceedings</title>
		<meeting>the Iberian Languages Evaluation Forum (IberLEF 2022) co-located with the XXXVIII International Conference of the Spanish Society for Natural Language Processing (SEPLN 2022)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3202</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,599.05,393.33,10.91;7,112.66,612.60,363.59,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,353.43,599.05,152.55,10.91;7,112.66,612.60,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,626.15,393.53,10.91;7,112.66,639.70,389.08,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,360.43,626.15,145.76,10.91;7,112.66,639.70,144.95,10.91">Bi-ensembles of transformer for online bilingual sexism detection</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villa-Cueva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sanchez-Vega</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>López-Monroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,280.54,639.70,129.93,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,653.25,393.33,10.91;7,112.66,666.80,313.65,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,285.82,653.25,220.17,10.91;7,112.66,666.80,69.01,10.91">Sexism identification in social media using deep learning models</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mahibha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Thenmozhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,205.10,666.80,129.93,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,393.33,10.91;8,112.66,100.52,170.09,10.91" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="8,218.87,86.97,287.12,10.91;8,112.66,100.52,138.17,10.91">Twitter data analysis using distill bert and graph based convolution neural network during disaster</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Danday</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Murthy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,393.32,10.91;8,112.66,127.61,209.16,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="8,273.39,114.06,232.59,10.91;8,112.66,127.61,26.95,10.91">Bertweet: A pre-trained language model for english tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10200</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
