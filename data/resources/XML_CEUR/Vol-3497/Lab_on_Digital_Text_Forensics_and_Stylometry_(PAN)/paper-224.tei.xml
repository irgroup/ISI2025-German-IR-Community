<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,401.55,15.42;1,89.29,106.66,217.22,15.42;1,89.29,129.00,157.29,11.96">Text Enrichment with Japanese Language to Profile Cryptocurrency Influencers Notebook for PAN at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,102.34,11.96"><forename type="first">Francesco</forename><surname>Lomonaco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution" key="instit1">Università degli Studi di Milano Bicocca</orgName>
								<orgName type="institution" key="instit2">Sistemistica e Comunicazione</orgName>
								<address>
									<postCode>20126</postCode>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,204.27,154.90,58.76,11.96"><forename type="first">Marco</forename><surname>Siino</surname></persName>
							<email>marco.siino@unipa.it</email>
							<affiliation key="aff1">
								<orgName type="department">Istituto di Informatica e Telematica</orgName>
								<orgName type="institution">CNR</orgName>
								<address>
									<postCode>56127</postCode>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Dipartimento di Ingegneria</orgName>
								<orgName type="institution">Università degli Studi di Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.31,154.90,84.10,11.96"><forename type="first">Maurizio</forename><surname>Tesconi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Istituto di Informatica e Telematica</orgName>
								<orgName type="institution">CNR</orgName>
								<address>
									<postCode>56127</postCode>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,401.55,15.42;1,89.29,106.66,217.22,15.42;1,89.29,129.00,157.29,11.96">Text Enrichment with Japanese Language to Profile Cryptocurrency Influencers Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">6A11A0DB561C52D834BE39B907B6F7EE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cryptocurrency influencers</term>
					<term>data augmentation</term>
					<term>author profiling</term>
					<term>text classification</term>
					<term>Twitter</term>
					<term>text enrichment</term>
					<term>japanese</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>From a few-shot learning perspective, we propose a strategy to enrich the latent semantic of the text provided in the dataset provided for the Profiling Cryptocurrency Influencers with Few-shot Learning, the task hosted at PAN@CLEF2023. Our approach is based on data augmentation using the backtranslation forth and back to and from Japanese language. We translate samples in the original training dataset to a target language (i.e. Japanese). Then we translate it back to English. The original sample and the backtranslated one are then merged. Then we fine-tuned two state-of-the-art Transformer models on this augmented version of the training dataset. We evaluate the performance of the two fine-tuned models using the Macro and Micro F1 accordingly to the official metric used for the task. After the fine-tuning phase, ELECTRA and XLNet obtained a Macro F1 of 0.7694 and 0.7872 respectively on the original training set. Our best submission obtained a Macro F1 equal to 0.3851 on the official test set provided.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The task proposed at PAN@CLEF2023 <ref type="bibr" coords="1,269.48,480.20,13.00,10.91" target="#b0">[1]</ref> was about Profiling Cryptocurrency Influencers with Few-shot Learning on Twitter <ref type="bibr" coords="1,249.20,493.75,11.48,10.91" target="#b1">[2]</ref>. The task was to profile cryptocurrency influencers in social media, from a low-resource perspective. The task organizers proposed three multilabel classification subtasks: 1) Low-resource influencer profiling, 2) Low-resource influencer interest identification, 3) Low-resource influencer intent identification. All the subtasks are multilabel classification tasks requiring strategies based on few-shot learning considering the size of the three dataset provided. In fact, the authors in the three corresponding datasets were, respectively, 32, 64 and 64. Furthermore, the number of tweets available for each author was never above ten. With such a low-resource perspective some form of transfer-learning was definitely required.</p><p>The rest of this work is organized as follows. In Section 2 we briefly present related work about text classification, along with a brief discussion on some of the architecture proposed in the previous editions of PAN. In Section 3 we describe our framework, including training and inferencing stages. In Section 4 we discuss the experimental evaluation of our framework, reporting the results obtained. In Section 5 we propose future works and conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>With our submission we extend the one conducted in <ref type="bibr" coords="2,330.42,199.79,11.46,10.91" target="#b2">[3]</ref>. Considering that the proposed task hosted at PAN@CLEF2023 consists of a few-shot learning one, we used the mentioned work as a starting point. In this work the authors propose a data augmentation technique based on backtranslation to augment samples in the dataset. The authors made use of the Italian language for the backtranslation proving the effectiveness of this strategy when compared to a non-augmented version of the training dataset. However, for our submission we wanted to investigate the impact of a morphologically different language as Japanese. Because, just like English, Japanese has no gender and there is no differentiation between plural and singular but, compared to English, in Japanese word order is normally subject-object-verb.</p><p>For the above-mentioned reasons, our participation at PAN@CLEF2023 <ref type="bibr" coords="2,422.82,321.73,11.41,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,436.97,321.73,8.99,10.91" target="#b4">5]</ref> is based on a text data augmentation strategy, plus a further stage which consists in the use of two state-ofthe-art Transformers (namely, XLNet <ref type="bibr" coords="2,252.88,348.83,12.69,10.91" target="#b5">[6]</ref> and ELECTRA <ref type="bibr" coords="2,333.15,348.83,10.93,10.91" target="#b6">[7]</ref>). We looked into the top-performing models that were taking part in the shared tasks presented by PAN to construct the method we propose. We examined the outcomes of the top team in the author profiling challenge held during PAN@CLEF 2021, where the proposed architecture consisted of a shallow CNN presented in <ref type="bibr" coords="2,145.96,403.03,11.23,10.91" target="#b7">[8,</ref><ref type="bibr" coords="2,159.88,403.03,7.49,10.91" target="#b8">9]</ref>. We also looked at the winning model at PAN@CLEF2022 where the authors won the competition because of a soft voting ensemble technique that combines BERTweet models with various loss functions and a BERT feature-based CNN model. In the 2020 author profiling edition <ref type="bibr" coords="2,165.62,443.67,16.39,10.91" target="#b9">[10]</ref>, based on their most recent 100 tweets, the aim was to identify authors who were likely to share false information. The authors of <ref type="bibr" coords="2,360.05,457.22,16.55,10.91" target="#b10">[11,</ref><ref type="bibr" coords="2,379.63,457.22,14.11,10.91" target="#b11">12]</ref> were the winners of the proposed task. On the supplied test set, their models achieved a 0.77 overall accuracy. The winning strategies are based on an ensemble of various machine learning models, an SVM, n-grams, and other techniques. Other ensemble models have been proposed at the following year task hosted at PAN about irony and stereotype spreaders detection <ref type="bibr" coords="2,411.46,511.42,16.43,10.91" target="#b12">[13,</ref><ref type="bibr" coords="2,430.61,511.42,12.32,10.91" target="#b13">14]</ref>.</p><p>In <ref type="bibr" coords="2,112.24,524.97,18.03,10.91" target="#b14">[15]</ref> SVM, Naive Bayes, Logistic Regression, and Recurrent Neural Networks (RNN) are just a few of the popular machine learning algorithms that the authors compare. SVM and Naive Bayes perform better than other algorithms on the dataset used, according to experimental results. In addition to the RNN, authors do not mention evaluation of a CNN or models based on deep learning. In another relevant comparative study <ref type="bibr" coords="2,327.13,579.17,16.17,10.91" target="#b15">[16]</ref>, on three separate datasets, scholars assess seven machine learning models. The models employed are based on Random Forest, SVM, Gaussian Naive Bayes, AdaBoost, KNN, Multi-Layer Perceptron, and Gradient Boosting Algorithm. The Gradient Boosting Algorithm performs better than the other examined models in terms of accuracy and F1 score.</p><p>In <ref type="bibr" coords="2,112.15,646.91,16.31,10.91" target="#b16">[17]</ref>, in order to profile spreaders of fake news, the authors feed a CNN using psycholinguistic and linguistic characteristics. The outcomes of their experiments demonstrate that their suggested strategy is successful in identifying users sharing misinformation. On a dataset created especially for their goal, the authors compare their findings. The performance of deep models is not extensively examined, and BERT is the only Transformer that has been tested. The proposed architecture is also tested in <ref type="bibr" coords="3,284.34,127.61,18.07,10.91" target="#b17">[18]</ref> (where the PAN@CLEF2020 dataset is used). Accordingly to the paper, the model is able to reach 0.52 and 0.51 of accuracy on the English and on the Spanish dataset respectively. Within the study <ref type="bibr" coords="3,322.30,154.71,16.08,10.91" target="#b17">[18]</ref>, the authors suggest a novel approach that performs better for both languages than the two PAN@CLEF2020 winning models by utilizing personality data and visual elements.</p><p>In the work conducted in <ref type="bibr" coords="3,210.04,195.36,16.09,10.91" target="#b18">[19]</ref>, for the purpose of classifying sentiments, authors suggest using CNN. The authors demonstrate that consecutive convolutional layers are useful for classifying lengthy texts.</p><p>Additionally, we examined numerous contemporary methods for text classification problems. The usage of Explainable Artificial Intelligence (XAI) techniques rather than black box-based strategies has increased significantly, and this is noteworthy to note. Several of these techniques have graph-based foundations and have practical applications in social networking <ref type="bibr" coords="3,465.56,276.66,16.35,10.91" target="#b19">[20]</ref>, text classification <ref type="bibr" coords="3,149.60,290.20,16.25,10.91" target="#b20">[21]</ref>, computer vision <ref type="bibr" coords="3,247.71,290.20,17.91,10.91" target="#b21">[22]</ref> and traffic prediction <ref type="bibr" coords="3,364.70,290.20,16.25,10.91" target="#b22">[23]</ref>.</p><p>With regard to cryptocurrency, authors in <ref type="bibr" coords="3,301.14,303.75,18.07,10.91" target="#b23">[24]</ref> create a series of sequence-to-sequence hyperbolic models based on the power-law dynamics of cryptocurrencies and user activity on social media that are appropriate for bubble detection identification challenges. An interesting study from an NLP perspective is the one presented in <ref type="bibr" coords="3,338.11,344.40,16.41,10.91" target="#b24">[25]</ref>. To understand the relationships between cryptocurrency values and social media, the authors analyze what happened in social media starting in June 2019 using a combination of statistical models and NLP techniques, concentrating on the rise of the Ethereum and Bitcoin prices.</p><p>We chose to use XLNet and ELECTRA as classifiers in light of the results obtained in a similar multi-label text classification task <ref type="bibr" coords="3,245.35,412.15,18.07,10.91" target="#b25">[26]</ref> and presuming, as discussed in <ref type="bibr" coords="3,410.39,412.15,16.56,10.91" target="#b26">[27,</ref><ref type="bibr" coords="3,429.91,412.15,12.42,10.91" target="#b27">28]</ref>, that deep AI models are actually capable of outperforming traditional techniques used in the field of NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed Approach</head><p>The proposed framework is evaluated through a three-stage empirical experiment. First, the baseline of author profiling models are established using datasets without our augmentation modules. The second stage involves generating augmented data using backtranslation to and from Japanese. Backtranslating to and from a morphologically so different can produce very interesting results in terms of latent semantic that is made explicit thanks to the translation <ref type="bibr" coords="3,89.29,552.07,16.27,10.91" target="#b28">[29]</ref>. After the backtranslation of the original sample, the backtranslated version is merged to the original one. Then the augmented data is used to train the XLNet and ELECTRA to compare the performances with or without the backtranslation module. We use ELECTRA for our first submission and XLNet for the second one. This choice was dictated by the results presented in <ref type="bibr" coords="3,89.29,606.27,17.86,10.91" target="#b29">[30]</ref> where the authors report the remarkable performance of ELECTRA for one-shot-learning tasks. Similarly, XLNet has shown interesting results on another few-shot-learning-oriented task as reported in <ref type="bibr" coords="3,179.39,633.36,16.41,10.91" target="#b25">[26]</ref>. We did not use other larger Transformer models (as BERT, T5 or RoBERTa) to better asses the impact of the Japanese language. In our setting, each sample is a user's set of tweets, and we hypothesise that semantically enriching the user's tweets using our proposed modules can improve performance. By augmenting each sample with one or multiple translations, we aim to increase the diversity and informativeness of the data and improve the representation of the input, ultimately leading to better classification performance of different NLP models. Our results outperform the not-augmented baseline, showing that the expansion of samples with multiple languages using backtranslation leads to improved performances in author profiling tasks. Thanks to the backtranslation module our framework is able to outperform the results obtained without expanding the samples.</p><p>No preprocessing is applied to the source text in the training datasets. In Figure <ref type="figure" coords="4,444.52,487.14,4.97,10.91" target="#fig_0">1</ref> we show the frameworks we used for our two submissions at the subtask 1. In the first submission we used the augmented training set for fine-tuning and for inferencing using an ELECTRA Transformer, for the second submission we used an XLNet instead.</p><p>Our model is trained on the augmented versions of the datasets. For both the submissions we fine-tuned ELECTRA and XLNet for 30 epochs on the augmented dataset. To perform the translation forth and back to and from Japanese we used the Google Translate API<ref type="foot" coords="4,472.27,566.68,3.71,7.97" target="#foot_0">1</ref> . After the training phase, we used the fine-tuned Transformers to predict on the unlabeled test set provided by the task organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Our training and inferencing notebooks, developed in TensorFlow and using the Simple Transformers<ref type="foot" coords="5,122.14,144.04,3.71,7.97" target="#foot_1">2</ref> library, are publicly available as a Jupyter Notebook on GitHub<ref type="foot" coords="5,407.55,144.04,3.71,7.97" target="#foot_2">3</ref> . For the training and for the inferencing phases we made use of ELECTRA and XLNet <ref type="bibr" coords="5,376.32,159.35,11.36,10.91" target="#b5">[6]</ref>. According to what stated in <ref type="bibr" coords="5,101.04,172.89,11.55,10.91" target="#b6">[7]</ref>, ELECTRA suggests to replace certain tokens with possible replacements taken from a small generator network, instead of masking input like in BERT. Then, a discriminative model is trained to predict whether each token in the corrupted input was replaced by a generator sample or not, as opposed to developing a model that predicts the original identities of the corrupted tokens. Along with a graph neural network, ELECTRA can also be employed as an embedding layer as in <ref type="bibr" coords="5,135.66,240.64,16.09,10.91" target="#b20">[21]</ref>. In our experiments, the original version of ELECTRA, presented in <ref type="bibr" coords="5,448.54,240.64,11.28,10.91" target="#b6">[7]</ref>, was used. XLNet was developed by optimizing the predicted likelihood across all combinations of the factorization order to enable learning bidirectional contexts. XLNet surpasses BERT, frequently by a significant margin, on a number of tasks, including question answering, sentiment analysis, document ranking and natural language inference. For our study we used the pre-trained XLNet using the zero-shot cross lingual transfer discussed in <ref type="bibr" coords="5,331.19,308.39,16.26,10.91" target="#b30">[31]</ref>. In both cases we used a batch size of 1. We fine-tuned both models for 30 epochs. No improvements are obtained in fine-tuning for more epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The Dataset</head><p>The PAN organizers' dataset includes a list of Twitter authors and a variable number of corresponding tweets. For each author in the training set the labels are also provided. All the details are reported on the official task website <ref type="foot" coords="5,261.78,410.56,3.71,7.97" target="#foot_3">4</ref> . With regard to the three proposed subtask, they were, namely: 1) Low-resource influencer profiling, 2) Low-resource influencer interest identification, 3) Low-resource influencer intent identification. For the first subtask the organizers provided an English dataset with 32 users per label with a maximum of 10 English tweets each. The five labels available were: (1) null, (2) nano, (3) micro, (4) macro, (5) mega depending on the type of influencer the author was. For the second subtask were provided 64 users per label with 1 English tweets each. The five labels available in this case were: (1) technical information, (2) price update, (3) trading matters, (4) gaming, (5) other. Finally, for the third subtask, 64 users per label with 1 English tweets each were available and the classes available for predictions were: (1) subjective opinion, (2) financial information, (3) advertising, (4) announcement. In this paper we discuss the framework we used to participating at the first subtask (i.e., low-resource influencer profiling).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>The Macro F1 is the adopted metric for the author profiling task at PAN@CLEF2023. This metric, along with accuracy, is the same used in the rest of this section and defined in <ref type="bibr" coords="5,438.83,624.63,10.48,10.91" target="#b0">(1)</ref>. </p><formula xml:id="formula_0" coords="6,228.82,340.51,277.82,24.43">𝑀 𝑎𝑐𝑟𝑜𝐹 1 = 𝑠𝑢𝑚(𝐹 1𝑠𝑐𝑜𝑟𝑒𝑠) #𝑐𝑙𝑎𝑠𝑠𝑒𝑠<label>(1)</label></formula><p>In Table <ref type="table" coords="6,139.03,371.89,5.09,10.91" target="#tab_0">1</ref> we report the results using the F1 related to the five classes. The F1 is calculated, using the official evaluator, for all the classes available and using the original non-augmented version of the training set provided by the task organizers. The Python code of the evaluator is available on GitHub <ref type="foot" coords="6,178.52,410.78,3.71,7.97" target="#foot_4">5</ref> .</p><p>Finally, in Table <ref type="table" coords="6,172.87,426.09,3.69,10.91" target="#tab_1">2</ref>, we report the results with the metrics related to all the classes (i.e. Macro F1, accuracy), evaluating the results for the original non-augmented version of the training set.</p><p>Although the Macro F1 and the accuracy prove that XLNet fine-tuned on the Japanese backtranslated version of the dataset outperforms ELECTRA, as can be seen from Table <ref type="table" coords="6,459.52,466.73,5.06,10.91" target="#tab_1">2</ref> for three out of five classes the Micro F1 is higher using ELECTRA. However, a further investigation on the effect of the backtranslation on the original samples could eventually lead to an explanation of these differences among the classes. Finally, according to the final ranking <ref type="foot" coords="6,449.52,505.63,3.71,7.97" target="#foot_5">6</ref> it is worth mentioning that on the unlabelled test set provided, our best submission reached a Macro F1 equal to 0.3851.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Works</head><p>In this paper we have described our submitted model for our participation at the author profiling task hosted at PAN@CLEF 2023. It consists of a backtranslation layer followed by an expansion module to expand every sample in the dataset. These augmented versions of the samples are then provided to ELECTRA and XLNet both for training and inference phase.</p><p>We plan to assess performance using other backtranslation methods and additional languages in future works. Improved performance on the proposed classification task may even result from conducting an error analysis on authors who were incorrectly classified. The size of the dataset made available allowed for the application of certain other data augmentation techniques. Before the training and testing phases of our model, some research into the content of each tweet may help steer the construction of the model by applying various strategies to remove noise (i.e., irrelevant characteristics) from input samples. We found that enriching samples with their respective backtranslations can lead to performance improvements.</p><p>It would be interesting to further explore the matter also using additional datasets relevant to those used for author profiling tasks. Eventually, it could also be interesting to assess the effect of using different languages in the backtranslation module.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,330.78,416.69,8.93;4,89.29,342.79,416.70,8.87;4,89.29,354.74,333.10,8.87;4,89.29,84.19,425.18,239.17"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall architecture of the proposed framework. For our submission, the backtranslation module translates the original source text into Japanese and then back into English. Then XLNet and ELECTRA are separately fine-tuned on the augmented version of the training set.</figDesc><graphic coords="4,89.29,84.19,425.18,239.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,90.49,416.99,97.93"><head>Table 1</head><label>1</label><figDesc>Results achieved in terms of F1 per each class at the end of the fine-tuning of the two Transformers on the augmented training set. The evaluation is performed using precision and recall on the non-augmented version of the training set.</figDesc><table coords="6,158.46,142.49,278.35,45.93"><row><cell cols="5">F1 results per each class on the original non-augmented training set</cell></row><row><cell></cell><cell>Macro Nano</cell><cell>No</cell><cell>Mega</cell><cell>Micro</cell></row><row><cell cols="4">ELECTRA 0.8108 0.8064 0.7692 0.6800</cell><cell>0.7805</cell></row><row><cell>XLNet</cell><cell cols="3">0.7631 0.7451 0.8750 0.7857</cell><cell>0.7671</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,208.32,416.99,97.93"><head>Table 2</head><label>2</label><figDesc>Macro results achieved by our framework at the end of the fine-tuning on the augmented dataset using Japanese. The results reported are obtained evaluating the fine-tuned Transformers on the original training set.</figDesc><table coords="6,226.84,260.32,141.60,45.93"><row><cell cols="3">Results on the original training set</cell></row><row><cell></cell><cell>Macro F1</cell><cell>Acc</cell></row><row><cell>ELECTRA</cell><cell>0.7694</cell><cell>0.7750</cell></row><row><cell>XLNet</cell><cell>0.7872</cell><cell>0.7875</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,92.57,670.92,134.52,8.97"><p>https://pypi.org/project/googletrans/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,92.57,649.12,134.68,8.97"><p>https://simpleTransformers.ai/about/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,92.57,660.07,190.62,8.97"><p>https://github.com/marco-siino/PAN-CRYPTO-2023</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,92.57,671.03,222.76,8.97"><p>https://pan.webis.de/clef23/pan23-web/author-profiling.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,92.57,660.07,365.18,8.97"><p>https://github.com/pan-webis-de/pan-code/tree/master/clef23/profiling-cryptocurrency-influencers</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,92.57,671.03,222.76,8.97"><p>https://pan.webis.de/clef23/pan23-web/author-profiling.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank anonymous reviewers for their comments and suggestions that have helped to improve the presentation of the paper.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CRediT Authorship Contribution Statement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Online Resources</head><p>The source code of our model is available via • GitHub</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,452.53,394.52,10.91;7,112.66,466.08,394.53,10.91;7,112.66,479.63,394.52,10.91;7,112.66,493.18,393.53,10.91;7,112.66,506.73,394.53,10.91;7,112.66,520.28,395.17,10.91;7,112.66,533.83,393.33,10.91;7,112.66,547.38,394.53,10.91;7,112.66,560.93,65.44,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,294.21,479.63,212.97,10.91;7,112.66,493.18,393.53,10.91;7,112.66,506.73,42.05,10.91">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,371.28,520.28,136.55,10.91;7,112.66,533.83,393.33,10.91;7,112.66,547.38,197.14,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="7,342.79,547.38,159.86,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="7,112.66,574.48,393.33,10.91;7,112.66,588.02,393.33,10.91;7,112.14,601.57,159.26,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,466.53,574.48,39.46,10.91;7,112.66,588.02,261.87,10.91">Profiling Cryptocurrency Influencers with Few shot Learning at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,417.97,588.02,88.02,10.91;7,112.14,601.57,47.32,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="7,167.44,601.57,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,615.12,393.33,10.91;7,112.66,628.67,394.53,10.91;7,112.39,642.22,183.73,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,255.49,615.12,250.50,10.91;7,112.66,628.67,235.99,10.91">Improving irony and stereotype spreaders detection using data augmentation and convolutional neural network</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mangione</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Garbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,372.27,628.67,130.20,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2585" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,393.33,10.91;8,112.66,100.52,394.53,10.91;8,112.66,114.06,103.95,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,273.13,86.97,232.86,10.91;8,112.66,100.52,210.95,10.91">Profiling cryptocurrency influencers with few-shot learning using data augmentation and electra</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,354.39,100.52,147.43,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="8,112.66,114.06,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,127.61,394.53,10.91;8,112.66,141.16,266.06,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,213.36,127.61,289.53,10.91">Xlnet on augmented dataset to profile cryptocurrency influencers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.29,141.16,139.49,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="8,274.77,141.16,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,154.71,393.33,10.91;8,112.66,168.26,393.32,10.91;8,112.66,181.81,130.43,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,420.76,154.71,85.22,10.91;8,112.66,168.26,242.11,10.91">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,363.54,168.26,142.44,10.91;8,112.66,181.81,85.64,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,195.36,393.33,10.91;8,112.66,208.91,347.38,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="8,335.14,195.36,170.85,10.91;8,112.66,208.91,165.13,10.91">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,222.46,393.33,10.91;8,112.66,236.01,393.32,10.91;8,112.33,249.56,258.17,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,345.70,222.46,160.29,10.91;8,112.66,236.01,163.64,10.91">Detection of hate speech spreaders using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,299.96,236.01,206.03,10.91;8,112.33,249.56,66.45,10.91">PAN 2021 Profiling Hate Speech Spreaders on Twitter@ CLEF</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2021">2936. 2021</date>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,263.11,393.33,10.91;8,112.66,276.66,247.67,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,322.45,263.11,183.54,10.91;8,112.66,276.66,122.75,10.91">Fake news spreaders detection: Sometimes attention is not all you need</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,244.08,276.66,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">426</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,290.20,393.33,10.91;8,112.66,303.75,394.53,10.91;8,112.39,317.30,243.38,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,345.21,290.20,160.78,10.91;8,112.66,303.75,243.15,10.91">Overview of the 8th author profiling task at pan 2020: Profiling fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H H</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,376.55,303.75,126.02,10.91">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Sun SITE Central Europe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,330.85,386.41,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,159.51,330.85,244.37,10.91">Using n-grams to detect fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,426.46,330.85,21.05,10.91">CLEF</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,344.40,393.61,10.91;8,112.66,357.95,237.86,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,201.71,344.40,304.55,10.91;8,112.66,357.95,142.28,10.91">An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bolonyai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CLEF</publisher>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,371.50,393.33,10.91;8,112.66,385.05,395.01,10.91;8,112.66,398.60,48.96,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,246.47,371.50,259.52,10.91;8,112.66,385.05,90.19,10.91">An svm ensamble approach to detect irony and stereotype spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Garlisi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,228.97,385.05,133.53,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2426" to="2432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,412.15,393.60,10.91;8,112.66,425.70,395.01,10.91;8,112.66,439.25,48.96,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,281.48,412.15,224.78,10.91;8,112.66,425.70,107.15,10.91">T100: A modern classic ensemble to profile irony and stereotype spreaders</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,242.57,425.70,127.79,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2666" to="2674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,452.79,393.33,10.91;8,112.66,466.34,393.33,10.91;8,112.66,479.89,207.08,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,291.57,452.79,214.41,10.91;8,112.66,466.34,109.94,10.91">Detecting fake news using machine learning and deep learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Mahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Huq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,245.81,466.34,260.17,10.91;8,112.66,479.89,112.65,10.91">2019 7th International Conference on Smart Computing &amp; Communications (ICSCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,493.44,393.32,10.91;8,112.66,506.99,393.32,10.91;8,112.66,520.54,256.47,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,333.97,493.44,172.01,10.91;8,112.66,506.99,192.37,10.91">Comparative performance of machine learning algorithms for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P S</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Choubey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,327.91,506.99,178.07,10.91;8,112.66,520.54,126.10,10.91">International conference on advances in computing and data sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,534.09,393.33,10.91;8,112.66,547.64,394.53,10.91;8,112.66,561.19,224.61,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,443.62,534.09,62.37,10.91;8,112.66,547.64,390.03,10.91">The impact of psycholinguistic patterns in discriminating between fake news spreaders and fact checkers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oberski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,112.66,561.19,141.58,10.91">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">101960</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,574.74,393.33,10.91;8,112.66,588.29,393.33,10.91;8,112.66,601.84,221.05,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,253.78,574.74,252.21,10.91;8,112.66,588.29,82.93,10.91">Profiling Fake News Spreaders: Personality and Visual Information Matter</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cervero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,218.58,588.29,287.41,10.91;8,112.66,601.84,90.15,10.91">International Conference on Applications of Natural Language to Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,615.39,393.33,10.91;8,112.66,628.93,100.24,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,200.26,615.39,263.05,10.91">Sentiment classification using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-S</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,471.48,615.39,34.51,10.91;8,112.66,628.93,37.51,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2347</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,642.48,393.73,10.91;8,112.66,656.03,393.33,10.91;8,112.66,669.58,272.03,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,279.25,642.48,227.14,10.91;8,112.66,656.03,235.00,10.91">Whosnext: Recommending twitter users to follow using a spreading activation network based approach</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.10,656.03,134.89,10.91;8,112.66,669.58,166.48,10.91">2020 International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="62" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.33,10.91;9,112.66,100.52,393.33,10.91;9,112.66,114.06,358.09,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,276.68,86.97,229.31,10.91;9,112.66,100.52,180.65,10.91">Courage at checkthat! 2022: Harmful tweet detection using graph neural networks and electra</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Donabauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,316.04,100.52,189.95,10.91;9,112.66,114.06,204.09,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="573" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,127.61,395.17,10.91;9,112.66,141.16,395.17,10.91;9,112.66,154.71,394.52,10.91;9,112.66,168.26,90.72,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,261.82,127.61,246.02,10.91;9,112.66,141.16,277.34,10.91">Graph neural network (gnn) in image and video understanding using deep learning for computer vision applications</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pradhyumna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shreya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,413.12,141.16,94.71,10.91;9,112.66,154.71,363.55,10.91">2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1183" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,181.81,395.17,10.91;9,112.66,195.36,289.92,10.91" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<title level="m" coord="9,252.12,181.81,255.71,10.91;9,112.66,195.36,107.88,10.91">Diffusion convolutional recurrent neural network: Datadriven traffic forecasting</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,208.91,393.33,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,107.17,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.06320</idno>
		<title level="m" coord="9,401.32,208.91,104.67,10.91;9,112.66,222.46,321.55,10.91">Cryptocurrency bubble detection: a new stock market dataset, financial task &amp; hyperbolic models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,249.56,393.33,10.91;9,112.66,263.11,393.33,10.91;9,112.66,276.66,290.20,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="9,332.67,249.56,173.32,10.91;9,112.66,263.11,393.33,10.91;9,112.66,276.66,45.44,10.91">Cryptocurrency ecosystems and social media environments: An empirical analysis through hawkes&apos; models and natural language processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ortu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vacca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Destefanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Conversano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,166.57,276.66,163.41,10.91">Machine Learning with Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100229</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,393.33,10.91;9,112.66,303.75,393.65,10.91;9,112.66,317.30,393.32,10.91;9,112.33,330.85,394.85,10.91;9,112.66,344.40,397.48,10.91;9,112.66,360.39,74.11,7.90" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,281.99,290.20,223.99,10.91;9,112.66,303.75,393.65,10.91;9,112.66,317.30,45.44,10.91">McRock at SemEval-2022 task 4: Patronizing and condescending language detection using multi-channel CNN, hybrid LSTM, DistilBERT and XLNet</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.semeval-1.55</idno>
		<ptr target="https://aclanthology.org/2022.semeval-1.55.doi:10.18653/v1/2022.semeval-1.55" />
	</analytic>
	<monogr>
		<title level="m" coord="9,181.93,317.30,324.05,10.91;9,112.33,330.85,67.42,10.91">Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)</title>
		<meeting>the 16th International Workshop on Semantic Evaluation (SemEval-2022)<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="409" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,395.17,10.91;9,112.66,385.05,244.76,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="9,223.22,371.50,247.47,10.91">Review of text classification methods on deep learning</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,480.36,371.50,27.47,10.91;9,112.66,385.05,150.68,10.91">CMC-Computers, Materials &amp; Continua</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,398.60,393.33,10.91;9,112.26,412.15,393.93,10.91;9,112.66,425.70,107.04,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="9,257.56,398.60,248.43,10.91;9,112.26,412.15,199.87,10.91">Classifying tweets using convolutional neural networks with multi-channel distributed representation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hashida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,320.53,412.15,185.66,10.91;9,112.66,425.70,33.25,10.91">IAENG International Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,439.25,395.01,10.91;9,112.33,452.79,232.72,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="9,175.87,439.25,270.00,10.91">The evolving treatment of semantics in machine translation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,454.53,439.25,53.13,10.91;9,112.33,452.79,187.93,10.91">Adv. Empir. Transl. Stud. Dev. Transl. Resour. Technol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,395.00,10.91" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-Y</forename><surname>Kao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.08141</idno>
		<title level="m" coord="9,185.72,466.34,142.62,10.91">Electra is a zero-shot learner, too</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,479.89,395.17,10.91;9,112.66,493.44,394.61,10.91;9,112.66,506.99,394.53,10.91;9,112.66,520.54,70.43,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="9,433.31,479.89,74.52,10.91;9,112.66,493.44,374.48,10.91">Zero-shot crosslingual transfer of neural machine translation with multilingual pretrained encoders</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,506.99,390.05,10.91">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
