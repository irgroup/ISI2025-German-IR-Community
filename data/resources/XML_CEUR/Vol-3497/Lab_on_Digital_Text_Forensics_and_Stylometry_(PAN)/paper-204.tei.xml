<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,400.64,15.42;1,88.78,106.66,138.72,15.42;1,89.29,129.00,157.29,11.96">A Dual-model Classification Based on RoBERTa for Trigger Detection Notebook for PAN at CLEF 2023</title>
				<funder ref="#_mV995fV">
					<orgName type="full">Heilongjiang Province Philosophy and Social Science Research Planning Project</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,64.43,11.96"><forename type="first">Guiyuan</forename><surname>Cao</surname></persName>
							<email>caoguiyuan2020@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.36,154.90,78.38,11.96"><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
							<email>hanzhongyuan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.66,154.90,54.25,11.96"><forename type="first">Haojie</forename><surname>Cao</surname></persName>
							<email>caohaojie0322@163.com</email>
						</author>
						<author>
							<persName coords="1,330.56,154.90,66.28,11.96"><forename type="first">Ximin</forename><surname>Huang</surname></persName>
							<email>huangximin2020@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,409.48,154.90,80.21,11.96"><forename type="first">Zhengqiao</forename><surname>Zeng</surname></persName>
							<email>zhengqiaozeng@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,88.95,168.85,50.55,11.96"><forename type="first">Yaozu</forename><surname>Tan</surname></persName>
							<email>tanyaozu2023@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,152.14,168.85,42.38,11.96"><forename type="first">Jiyin</forename><surname>Cai</surname></persName>
							<email>caijiyin0904@163.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.51,168.85,35.85,11.96"><forename type="first">Xu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Heilongjiang Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,400.64,15.42;1,88.78,106.66,138.72,15.42;1,89.29,129.00,157.29,11.96">A Dual-model Classification Based on RoBERTa for Trigger Detection Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B24F5646D10A2D4C32D63E5AA891390C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Trigger Detection</term>
					<term>dual-model classification</term>
					<term>RoBERTa</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to predict whether a text contains much potentially uncomfortable or harmful information, our team proposed a dual-model classification method based on RoBERTa for trigger detection. After analyzing the dataset, we found that the frequency of the "pornographic-content" label was higher than the other 31 labels. To avoid this label causing unbalanced prediction results, we tried to use two models to predict the labels that this text might contain. This method involves two rounds of sampling from the original dataset. In the first round, only the label with the highest frequency is retained, forming Dataset A; in the second round, the remaining 31 labels are retained, forming Dataset B. Using these two datasets, we separately trained two RoBERTa models. The two fine-tuned models are used to predict the test documents, and the results of the two models are combined to obtain multiple labels as predictive labels. The method we used obtained a macro f1 score of 0.225 on the test set of the Trigger Detection Task at PAN 2023.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the development of the Internet, various types of information have emerged online. Among this information, there are many useful ones, but also many potentially uncomfortable or harmful ones. Therefore, PAN at CLEF 2023 proposed a Trigger Detection task <ref type="bibr" coords="1,432.07,486.38,12.69,10.91" target="#b0">[1]</ref> to investigate this issue. PAN at CLEF 2023 requires participants to develop software or models to determine whether a document contains trigger content <ref type="bibr" coords="1,291.90,513.48,11.36,10.91" target="#b1">[2]</ref>, with trigger content including pornographic content, violence, death, sexual assault, and 32 other labels <ref type="bibr" coords="1,345.98,527.03,12.02,10.91" target="#b2">[3]</ref>. For this task, our team proposes a dual-model classification approach for trigger detection based on RoBERTa <ref type="bibr" coords="1,437.34,540.58,15.83,10.91" target="#b3">[4]</ref>, aiming to improve the model's accuracy. This approach trains two models based on RoBERTa to determine whether a document fits specific labels. If a document's score for a specific label exceeds a threshold, then the content of that document matches the label. Otherwise, the content of that document does not match the label.</p><p>Section 2 of this paper describes the specific methods used, including the data processing process, a brief introduction to the models, and the model training process. Section 3 describes the predicted results obtained using this method and analyzes those results. Section 4 presents the conclusions drawn from this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>This section provides an overview of the classification methods and specific model training used. Section 2.1 details the process of data processing; Section 2.2 describes the overall structure of the model; Section 2.3 explains the key points of model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Data Processing</head><p>The dataset is sourced from CLEF 2023PAN <ref type="bibr" coords="2,302.88,303.10,11.28,10.91" target="#b4">[5]</ref>. In the dataset, there is a text corpus where each text is assigned at least one warning trigger. In the original dataset provided by 2023PAN, there are many HTML tags present. Therefore, we first cleaned the HTML tags. Secondly, while analyzing the cleaned dataset, we discovered a long-tail frequency issue, where some tags have high frequency while others have low frequency. To address this problem, we recorded the most frequent tags, the least frequent tags, and the tags with frequencies in between. Next, we processed the texts that contained the most frequent tags as follows: we extracted 80,000 samples from the original dataset, where 40,000 samples matched the most frequent tags and another 40,000 did not. We then processed these sampled data by dividing long texts into subsets of no more than 512 words while maintaining the same tags as their parent sets to obtain the processed training dataset A. Finally, for the remaining 31 tags, we employed a sampling method of oversampling and undersampling, which balanced the occurrence frequency of each tag to some extent. The oversampling rule is as follows: if a tag appears less than 20 times in the original dataset, the data with that tag will be replicated and added to the dataset six times. If a tag appears between 20 and 200 times in the original dataset, the data with that tag will be replicated four times and added to the dataset. The undersampling rule is as follows: if a tag appears more than 3,000 times in the original dataset, only 3,000 data with that tag will be retained. After the aforementioned sampling process, we obtained the training dataset B. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Model</head><p>Our team conducted two rounds of sampling on the original dataset. In the first round, dataset A was obtained through random sampling. In the second round, resampling and undersampling techniques were used to create a new dataset, dataset B. These two datasets were used as training data for the RoBERTa models, resulting in the training of two new models, model A and model B. In this process, we used RoBERTa, which is an improved version based on BERT. RoBERTa incorporates more model parameters, more training data, and larger batch sizes compared to BERT. It undergoes training on a scale that is an order of magnitude larger than BERT, which takes a longer time. This enables RoBERTa representations to generalize better to downstream tasks and exhibit superior performance compared to the original BERT. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Model Training</head><p>First, on the hardware platform of Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz + NVIDIA A800-SXM4-80GB, the batch size for each training round is set to 32, and the data is fed into RoBERTa for training. After five rounds of training, Model A and Model B are generated. For Model A, each training round takes about 10 nutes, while prediction time takes about 20 minutes. For Model B, each training round takes 10 hours, and prediction time takes about 20 minutes.</p><p>Then, based on the output results of Model A and Model B, our team has established the following criteria to evaluate the matching degree between the text and labels: "In the data processing step, since each long text has been divided into several smaller text segments, the matching degree between each long text and the label depends on the average score of all relevant small texts and labels. This average score is called the total score. If the total score of a label exceeds the threshold of 0.5, the label is assigned a value of 1; otherwise, it is assigned a value of 0. " According to this criterion, if the output of the model is 1, the file corresponds to a certain label; if it is 0, the file does not correspond to a certain label.</p><p>Since Model B needs to learn multiple labels, its output results need to be connected to a fully connected layer, forming a mapping relationship between the output results of Model B and the 31 labels mentioned in Section 2.1 of the data processing part. If this mapping relationship meets the criteria of the text-label fitting mentioned above, it can be considered that the text matches some of the 31 labels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Result</head><p>Based on the above experiments, we obtained the following results on the CLEF 2023PAN dataset <ref type="foot" coords="4,123.54,458.91,3.71,7.97" target="#foot_0">1</ref> . The analysis shows that the difference in macro f1 scores between the test set and the validation set is 0.002, and the difference in micro f1 scores is 0.007. Both differences are less than 0.01. Therefore, the model can predict the possible labels contained in a document stably. Although this method has high stability, there is still a lot of room for improvement in its accuracy. Therefore, in the future, we will continue to explore how to use dual models to improve the matching between documents and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>Regarding the question of determining whether a document contains potentially uncomfortable or harmful information, our team proposed a dual-model classification method based on RoBERTa. This method involves setting two sampling rules for the dataset based on the RoBERTa model. The training sets obtained from these two sampling methods are used to train RoBERTa, resulting in Model A and Model B. By combining the predictions of both models on the same text, we achieved a macro f1 score of 0.225 and an accuracy of 0.317 on the CLEF 2023PAN dataset. Finally, we conclude that using a dual-model approach has a positive effect on determining whether a document contains one or more harmful information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,545.75,174.31,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Process for Obtaining Dataset A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,210.47,174.18,8.93"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Process for Obtaining Dataset B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,89.29,540.99,150.00,8.93"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overall Prediction Process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,89.29,369.95,138.64,8.93"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model Training Process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,487.23,299.05,67.65"><head>Table 1 Predicted</head><label>1</label><figDesc></figDesc><table coords="4,130.79,499.23,257.26,55.64"><row><cell>results for different datasets</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">mac_f1 mic_f1 sub_acc</cell></row><row><cell>validation set</cell><cell>0.223</cell><cell>0.623</cell><cell>0.323</cell></row><row><cell>test set</cell><cell>0.225</cell><cell>0.616</cell><cell>0.317</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,92.57,671.03,141.96,8.97"><p>Pan23 trigger detection (1.1) [data set],</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2023" xml:id="foot_1" coords="4,258.03,671.03,164.76,8.97"><p>URL: https://doi.org/10.5281/zenodo.7612628.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgments</head><p>This work is supported by the <rs type="funder">Heilongjiang Province Philosophy and Social Science Research Planning Project</rs> (No.<rs type="grantNumber">20TQB065</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mV995fV">
					<idno type="grant-number">20TQB065</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,107.59,336.93,398.40,10.91;5,107.59,350.47,399.59,10.91;5,107.59,364.02,73.37,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,320.77,336.93,185.21,10.91;5,107.59,350.47,20.05,10.91">Overview of the Trigger Detection Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,170.42,350.47,331.59,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,377.57,400.24,10.91;5,107.59,391.12,398.40,10.91;5,107.59,404.67,398.60,10.91;5,107.59,418.22,224.92,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,324.45,377.57,183.38,10.91;5,107.59,391.12,170.94,10.91">Trigger warning assignment as a multilabel document classification problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,306.50,391.12,199.49,10.91;5,107.59,404.67,209.59,10.91">Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="5,107.59,431.77,398.39,10.91;5,107.59,445.32,400.08,10.91;5,107.59,458.87,320.58,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,308.73,431.77,197.25,10.91;5,107.59,445.32,97.82,10.91">Trigger warnings: Bootstrapping a violence detector for fanfiction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Borchardt</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2209.04409</idno>
		<idno type="arXiv">arXiv:2209.04409</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2209.04409.doi:10.48550/arXiv.2209.04409" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,472.42,399.59,10.91;5,107.59,485.97,393.49,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="5,242.14,472.42,260.26,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1907.11692" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.59,499.52,398.60,10.91;5,107.59,513.06,400.25,10.91;5,107.59,526.61,399.60,10.91;5,107.59,540.16,285.55,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,366.85,499.52,139.34,10.91;5,107.59,513.06,39.67,10.91">Overview of pan 2023: Trigger detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,170.29,513.06,337.54,10.91;5,107.59,526.61,371.12,10.91">Experimental IR Meets Multilinguality, Multimodality and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="5,107.59,540.16,155.05,10.91">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
			<biblScope unit="page" from="518" to="526" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
