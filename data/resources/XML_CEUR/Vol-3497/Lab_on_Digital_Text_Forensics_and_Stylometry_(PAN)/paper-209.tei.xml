<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,406.94,15.42;1,89.29,106.66,70.69,15.43;1,89.29,129.00,196.50,11.96">Profiling Cryptocurrency Influencers with Few-shot Learning Notebook for the PAN Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,86.33,11.96"><forename type="first">Isabel</forename><surname>Ferri-Molla</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de Valencia</orgName>
								<address>
									<addrLine>Camí de Vera, s/n</addrLine>
									<postCode>46022</postCode>
									<settlement>València, Valencia</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.26,154.90,118.26,11.96"><forename type="first">Jaume</forename><surname>Santamaria-Jorda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de Valencia</orgName>
								<address>
									<addrLine>Camí de Vera, s/n</addrLine>
									<postCode>46022</postCode>
									<settlement>València, Valencia</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,406.94,15.42;1,89.29,106.66,70.69,15.43;1,89.29,129.00,196.50,11.96">Profiling Cryptocurrency Influencers with Few-shot Learning Notebook for the PAN Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2C22458658236BFFC18E969C9E77585B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>author profiling</term>
					<term>cryptocurrency influencers</term>
					<term>language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our systems for participating in the "Profiling Cryptocurrency Influencers with Few-shot Learning" task shared on PAN 2023. This work focuses on profiling cryptocurrency influencers from limited data obtained from social networks. We employ sparse data learning techniques to classify cryptocurrency influencers into different categories. During the work, different subtasks will be tackled. On the one hand, influencers will be classified according to their number of followers. On the other hand, influencers will be classified by their interests. Finally, in the third subtask, the classification will be based on the influencer's intent. Our approach is to compare the performance of statistical models and pre-trained linguistic models, taking into account the limitations of the data. Our approach is to compare the performance of statistical models and pre-trained linguistic models, taking into account the limitations of the data. Furthermore, we will focus on an in-depth exploration of the best parameters that can be used in the training process of the selected model to obtain the best possible metrics. Experimental results show that the pre-trained models in all tasks obtain better global metrics even with the poor amounts of data available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The interest in cryptocurrencies has experienced a significant surge in recent years <ref type="bibr" coords="1,464.89,465.26,11.43,10.91" target="#b0">[1]</ref>. With their decentralized nature and independence from any authority, various cryptocurrency projects have gained popularity among the general public. This rise has given birth to influencers who propagate their viewpoints on social media platforms. Consequently, the profiling of cryptocurrency influencers has become a topic of increasing interest due to the substantial influence they can wield over investments and the overall market. Identifying and understanding the characteristics of these influencers can provide valuable insights for investors and companies involved in cryptocurrency.</p><p>Presently, a large segment of the population spends a considerable amount of time on social networks, particularly platforms that allow people to post short messages, such as Twitter, have gained prominent popularity. Within this social media landscape, it is evident that some users possess greater influence than others. Certain individuals' popularity can be so significant that their opinions and messages have the power to shape the views of other users. These influential users amass a substantial following and exert a wide-ranging impact on online social interactions. Their tweets can reach diverse audiences and stimulate discussions and debates on the topics they address. Therefore, it is crucial to determine if there exists a relationship between users' level of influence and the type of tweets they post.</p><p>In this paper, we undertake the task of profiling cryptocurrency influencers using a dataset with limited data. Our work revolves around the shared task titled "Profiling Cryptocurrency Influencers with Few-Shot Learning at PAN 2023 <ref type="bibr" coords="2,319.23,181.81,11.58,10.91" target="#b1">[2]</ref>, which falls within the PAN 2023 lab on digital text forensics and stylometry <ref type="bibr" coords="2,269.01,195.36,11.52,10.91" target="#b2">[3]</ref>. This study addresses the challenge of classifying cryptocurrency influencers into different categories by employing few-shot learning. This methodology proves particularly valuable when the available dataset is limited, and we aim to generalize knowledge to new samples. Our approach relies on applying machine learning techniques and comparing the performance of statistical models and pre-trained language models in this specific case. We explore various parameter combinations of the latter to identify the ones that yield superior accuracy and generalization, considering the data constraints we encounter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related word</head><p>This section provides an overview of similar solutions adopted in related problems within the field of author profiling. Author profiling focuses on analyzing and extracting key characteristics of an author based on their linguistic usage and style in text. Techniques employed in this field include natural language processing (NLP), deep learning (DL), and data analytics.</p><p>With the increasing popularity of social networking, author profiling has found significant application in these platforms. Various areas within author profiling in social networks are dedicated to predicting attributes of authors, such as gender <ref type="bibr" coords="2,366.02,430.13,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,380.43,430.13,7.65,10.91" target="#b4">5]</ref>, age <ref type="bibr" coords="2,413.46,430.13,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,427.88,430.13,7.65,10.91" target="#b5">6]</ref>, or personality <ref type="bibr" coords="2,89.29,443.67,11.36,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,103.37,443.67,7.57,10.91" target="#b6">7]</ref>.</p><p>A comprehensive review of technologies used in author profiling can be found in <ref type="bibr" coords="2,464.25,457.22,11.43,10.91" target="#b7">[8]</ref>.</p><p>In previous years, statistical models were widely employed in author profiling, as evidenced in <ref type="bibr" coords="2,101.42,484.32,11.58,10.91" target="#b8">[9]</ref>, where techniques like Decision Trees, Random Forest, and Support Vector Machines (SVM) are utilized to discern demographic and psychometric traits based on English emails. Another notable example can be found in <ref type="bibr" coords="2,274.35,511.42,16.16,10.91" target="#b9">[10]</ref>, where statistical models were utilized to profile gender and age from both English and Spanish texts.</p><p>Nevertheless, there has been a noticeable shift towards deep learning techniques, specifically the utilization of large language models (LLMs). These techniques have gained significant momentum and popularity in recent times. Moreover, these approaches have exhibited promising metrics, further reinforcing their appeal and potential, as evidenced in <ref type="bibr" coords="2,407.36,579.17,16.33,10.91" target="#b10">[11]</ref>. Additionally, the utilization of multi-model ensembles, as exemplified in <ref type="bibr" coords="2,335.73,592.72,16.25,10.91" target="#b11">[12]</ref>, has become a popular approach.</p><p>In <ref type="bibr" coords="2,113.33,606.27,16.42,10.91" target="#b12">[13]</ref>, a transformer-based approach is employed for author profiling, utilizing vector representations of contextualized words and hand-crafted features. This approach incorporates a self-attention mechanism and a novel coding technique that integrates stylistic, thematic, and personal information of the author. Another innovative approach explored in this field is the use of Convolutional Neural Networks (cnns), as demonstrated in <ref type="bibr" coords="2,383.57,660.46,16.25,10.91" target="#b13">[14]</ref>.</p><p>When specifically considering author profiling in tweets, several studies have been conducted. For instance, <ref type="bibr" coords="3,148.71,100.52,17.89,10.91" target="#b14">[15]</ref> applies a product-based fusion strategy to combine encoded text representations from BERT_base and image features from EfficientNet. Similarly, <ref type="bibr" coords="3,413.78,114.06,18.06,10.91" target="#b15">[16]</ref> investigates the authorship of tweets related to COVID-19 in Portuguese. Further examples can be found in <ref type="bibr" coords="3,89.29,141.16,16.41,10.91" target="#b16">[17]</ref>, where language aggressiveness is detected in Spanish tweets using diverse approaches such as Bag of Terms, Second Order Attributes representation, Convolutional Neural Networks, and Ensemble of N-grams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposal approaches</head><p>The task we conducted our work for consists of three subtasks, the first subtask is about low-resource influencer profiling, the second one pertains to low-resource influencer interest identification and finally, the third subtask deals with low-resource influencer intent identification.</p><p>In the first subtask the objective was to profile influencers among 5 different categories based on their number of followers. The categories were "null", "nano", "micro", "macro" and "mega" influencers. To carry out this objective, a dataset of 160 tweeters with a list of a maximum of 10 English-language tweets was used as a training dataset. In addition, there was a truth file with the corresponding tag class for each of the tweeters.</p><p>On the other hand in the second task, the aim is to classify tweets into 5 possible areas of interest, which are "technical information", "price update", "trading matters", "gaming", and "other". The provided dataset consists on 64 tweets per label with one tweet each, all of them in English. It was accompanied by a truth file with the corresponding tag class for each user.</p><p>Finally, regarding the third subtask the data followed a similar format as in the previous task. However, the goal was to classify the influencer into one of the following categories: "subjective opinion", "financial information", "advertising", or "announcement". The given dataset was similar to the previous one, same size and characteristics, but with 4 labels.</p><p>The shared-task comprises three distinct subtasks, each focusing on low-resource influencer profiling. The first subtask involves categorizing influencers into five different categories based on their number of followers, namely "null," "nano," "micro," "macro," and "mega" influencers. To achieve this objective, a training dataset consisting of 160 tweeters was utilized, with each tweeter having a maximum of 10 English-language tweets. A corresponding truth file was provided, containing the tag class for each tweeter.</p><p>Moving on to the second subtask, the objective is to classify tweets into five possible areas of interest: "technical information," "price update," "trading matters," "gaming," and "other." The dataset provided for this task consisted of 64 tweets per label, with a single tweet per user written in English. Similar to the first subtask, a truth file accompanied the dataset, indicating the corresponding tag class for each user.</p><p>Lastly, in the third subtask, the dataset followed a similar format as the previous task. However, the goal was to classify the influencer into one of the following four categories: "subjective opinion, " "financial information, " "advertising, " or "announcement".</p><p>In relation to subtask 1, we experimented with two different approaches due to the varying number of tweets assigned to each user. Initially, we attempted to profile each influencer by merging all their tweets into a single string, which served as input for our model. However, this approach yielded poor results during our tests. Consequently, we pursued a second approach. In this alternative approach, we split the list of tweets corresponding to each tweeter so that each tweet was individually associated with the tweeter's category. By doing so, we determined the class mode assigned to all tweets from the same influencer, and this label was then assigned to the user.</p><p>The second approach proved to be more successful in achieving desirable results for subtask 1. As a result, we directly utilized this approach for subtask 2 and subtask 3.</p><p>Throughout our experimentation, we explored various models and solutions for the classification task. Additionally, we aimed to compare these models and evaluate their performance, taking into consideration potential variations in accuracy based on the train-test partition. To achieve this, we implemented a 5-fold cross-validation technique, which allowed us to obtain f1 and accuracy scores for each model. We strived to maintain balanced partitions during cross-validation, ensuring that samples from the same user did not appear in different partitions and aiming to have equal representation of the classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup</head><p>This section presents the experimentation conducted for both approaches in subtask 1, as well as the experiments carried out for subtask 2 and 3.</p><p>Regarding subtask 1, each approach involved the utilization of two different methods: statistical methods and language models (LM) specifically pre-trained for the task at hand.</p><p>For the LM approach, we used tensorflow <ref type="bibr" coords="4,287.66,389.48,16.23,10.91" target="#b17">[18]</ref>, to finetune and evaluate the performance of some hugging-face models, specifically the BERT-base-uncased model <ref type="bibr" coords="4,402.87,403.03,16.23,10.91" target="#b18">[19]</ref>, BERTweet-base (a BERT model fine-tuned for English tweets) <ref type="bibr" coords="4,283.21,416.58,16.24,10.91" target="#b19">[20]</ref>, and a RoBERTa model fine-tuned specifically for English tweets <ref type="bibr" coords="4,172.85,430.13,16.25,10.91" target="#b20">[21]</ref>.</p><p>On the other hand, for the statistical approach, we employed various models from the scikitlearn library <ref type="bibr" coords="4,146.43,457.22,16.09,10.91" target="#b21">[22]</ref>. Specifically, we conducted experiments with Support Vector Machines (SVM) <ref type="bibr" coords="4,89.29,470.77,16.32,10.91" target="#b22">[23]</ref>, K-means clustering <ref type="bibr" coords="4,201.88,470.77,16.32,10.91" target="#b23">[24]</ref>, Perceptron <ref type="bibr" coords="4,276.93,470.77,16.31,10.91" target="#b24">[25]</ref>, and logistic regression <ref type="bibr" coords="4,403.58,470.77,16.31,10.91" target="#b25">[26]</ref>. Tokenization was performed for the statistical models, wherein special characters such as @, #, etc. were replaced with corresponding keywords.</p><p>Table <ref type="table" coords="4,126.55,511.42,4.98,10.91" target="#tab_0">1</ref> demonstrates the outcomes obtained using the first approach. It reveals that superior results were achieved through the application of statistical methods, with logistic regression yielding the highest macro F1 score, closely followed by Support Vector Machines (SVM). Among the fine-tuned methods, the BERT-base-uncased classifier emerged as the top-performing model. These findings highlight the efficacy of logistic regression and SVM in the context of subtask 1, while also showcasing the competitive performance of the BERT-base-uncased classifier among the fine-tuned methods.</p><p>On the other hand, Table <ref type="table" coords="4,217.82,606.27,5.17,10.91" target="#tab_1">2</ref> presents the results obtained using the second approach. It is evident that, overall, higher metrics were achieved for all the models compared to the first approach. Notably, the finest outcomes were attained through the fine-tuning of the BERT-baseuncased model. Conversely, the statistical models exhibited slightly lower F1 scores in this case. These findings highlight the superior performance of the BERT-based approach in subtask 1 of influencer profiling, further emphasizing the potential of fine-tuned language models in this domain. After conducting multiple tests, we made a decision to explore a different approach inspired by the existing literature. Our main goal was to utilize Convolutional Neural Networks (CNNs) <ref type="bibr" coords="5,89.29,452.79,17.80,10.91" target="#b26">[27]</ref> for author classification, as CNNs have demonstrated their effectiveness in capturing local patterns and extracting relevant features.</p><p>To begin, we partitioned the data using the second approach described previously, then we preprocessed and normalized the text data. This involved removing HTML tags, normalizing characters, converting text to lowercase, and applying other necessary transformations. Subsequently, we performed tokenization, padding, and feature extraction to prepare the data for the CNN.</p><p>The CNN architecture incorporated Conv1D layers, which utilized filters to capture local patterns and extract word features from the embedded representations of the tweets. To optimize the performance of the CNN, we conducted experiments to determine the best parameters. After thorough exploration, we selected 180 epochs, a batch size of 128, and an embed_size of 300, Upon evaluating the model using the F1 score metric, we obtained a value of 0.45, which did not rank among the top-performing models.</p><p>As the results with the CNN were not as expected, we reverted to the approach of using pre-trained LLMs, in this case, we created an ensemble of LM using the BERT base, RoBERTa and BERTweet fine-tuned models explained above. To do so, we first pre-trained the different LMs with the Subtask 1 data, previously separated following the approach 2. Then, to classify a new sample, we combined the prediction of the 3 models so that the class finally predicted is the mode of the predictions of all the LLMs used in the ensemble.</p><p>Although the ensemble was not a bad approach and good results were obtained, it is true that there was quite a large difference between the individual BERT base uncased and BERTweet metrics, so we wanted to test whether the results obtained with the individual BERT model by exploring its training parameters could be better than those we obtained with the assembly. We found the DistilBERT <ref type="bibr" coords="6,187.70,168.26,17.95,10.91" target="#b27">[28]</ref> variant, which is a distilled version of the BERT model, lighter and faster, but maintaining its understanding capabilities.</p><p>In order to try to improve the results of the ensemble, we tested different parameters when training DistilBERT. The initial parameters used in previous tests of BERT are based on those recommended by <ref type="bibr" coords="6,168.19,222.46,16.18,10.91" target="#b18">[19]</ref>, but adapted to the size of the task. These were a learning rate of 2e-5, 6 epochs and a batch size of 16. After testing these parameters, an exhaustive exploration was carried out to find the best possible combination, from the learning rate and bach size to the the number of epochs, limiting their values to specific ranges. As results were obtained, we did different iterations in which we explored different parameters ranges to narrow down the error rate. After testing various combinations, we determined that the optimal parameters for this approach were a learning rate of 5e-5, 3 epochs, and a batch size of 4, with this parameters we obtained the best F1 score in our experiments for this task with a 0.61 of macro F1.</p><p>In order to achieve the objective of subtask 2, different models were also trained. To ensure optimal training and evaluation, a test partition was created by splitting the original training data. Cross-validation was employed by equally dividing the number of samples into folds.</p><p>As in subtask 1, we have compared different methods. The first one involved statistical models, including the ones used in subtask 1, with the addition of multilayer perceptron <ref type="bibr" coords="6,456.19,385.05,16.41,10.91" target="#b28">[29]</ref>, Naive Bayes <ref type="bibr" coords="6,119.08,398.60,16.41,10.91" target="#b29">[30]</ref>, Random Forest <ref type="bibr" coords="6,214.87,398.60,16.42,10.91" target="#b30">[31]</ref>, and ridge classifier <ref type="bibr" coords="6,328.20,398.60,16.41,10.91" target="#b31">[32]</ref>. These models have demonstrated competitive results even with limited data. The second approach involved fine-tuning pretrained models, which, akin to Subtask 1, demonstrated improved performance. These results can be observed in Table <ref type="table" coords="6,202.80,439.25,3.77,10.91" target="#tab_2">3</ref>. The best parameters found for this task were also the same as for the previous one. The second approach focused on fine-tuning pre-trained models, proved to be more effective as observed in subtask 1. The results of these different models can be observed in Table <ref type="table" coords="6,127.71,479.89,3.74,10.91" target="#tab_2">3</ref>.</p><p>In Subtask 3, we employed a similar methodology as in Subtask 2. Initially, we conducted experiments using different statistical models. However, these models did not attain the desired level of accuracy. Consequently, we focused our efforts primarily on testing and fine-tuning the DistilBERT model, as it had exhibited the most promising outcomes in previous tasks.</p><p>To evaluate the performance of the models, we compared their accuracy and F1 metrics. The results are summarized in Table <ref type="table" coords="6,233.59,561.19,3.74,10.91" target="#tab_3">4</ref>.</p><p>The table 4 provided illustrates the accuracy and F1 scores attained by various models. Among the statistical models, accuracy scores ranged from 0.56 to 0.62, while F1 scores fell between 0.58 and 0.61. However, the pre-trained language models demonstrated superior performance compared to the statistical models, achieving accuracy scores of up to 0.83 and F1 scores of 0.84. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>This section presents the final results obtained in TIRA <ref type="foot" coords="7,334.13,446.01,3.71,7.97" target="#foot_0">1</ref> .</p><p>In subtask 1, two different models were tested on the platform. Firstly, the ensemble of the three different language models (LM) discussed in section 4 was evaluated, achieving an F1 score of 0.45.</p><p>Additionally, the DistilBERT model explained in section 4 was employed too. Regarding DistilBERT models after the parameter exploration, we determined that the optimal parameters for this approach were a learning rate of 5e-5, 3 epochs, and a batch size of 4. Notably, this approach outperformed the ensemble approach in TIRA, attaining a macro F1 score of 0.57.</p><p>These results highlight the effectiveness of the DistilBERT model for low-resource influencer profiling in subtask 1, surpassing the performance of the ensemble model on the TIRA platform.</p><p>Regarding second subtask after the experimentation explained in section 4 we got the conclusion that DistilBERT fine-tuned obtained the best F1 metric so this one was the one presented in TIRA. This model achieved final results on the platform of 0.55 macro F1 score.</p><p>In Subtask 3, our experimental findings revealed that the DistilBERT fine-tuned model yielded the most favorable outcomes that is the reason why this one whas the model tested in the platform. It consistently achieved results in the TIRA evaluation that surpassed the average performance, exhibiting a noteworthy macro F1 score of 0.61. Extensive experimentation was conducted for the DistilBERT models employed in both Subtasks 2 and 3 to identify the optimal parameters. Surprisingly, the best parameters obtained for both tasks were consistent: a learning rate of 5e-5, 3 epochs, and a batch size of 4, mirroring the parameters used in Subtask 1. This observation suggests that the tasks may share a certain level of similarity, leading to the convergence of optimal parameter values across them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Works</head><p>In this work we have trained several models with few data in order to profile criptocurrency influencers. Throughout our experiments, we observed that fine-tuning pre-trained models generally yielded superior results than using statistical models. Specifically, for Subtask 1 we found that splitting the tweet list of each influencer and individually associating each tweet with the corresponding label proved to be a more effective approach. Although the performance improvement over statistical models was not as substantial compared to other subtasks, the fine-tuned neural models demonstrated better performance. Through an ensemble of neural models in TIRA, we achieved an F1 score of 0.45. Furthermore, after extensive parameter testing, we obtained the best results using a pre-trained DistilBERT model, achieving an F1 score of 0.57.</p><p>In relation to Subtask 2, a more pronounced disparity was observed between statistical and neural models. Notably, the best outcomes were achieved using a DistilBERT model, which yielded an F1 score of 0.55. Finally, in relation with Subtask 3, we once again experimented with both statistical and neural models. After exploring various training parameters, it was determined that a fine-tuned DistilBERT model emerged as the superior choice, resulting in an F1 metric of 0.61.</p><p>Although the best results have been obtained with pre-trained models, there is still room for improvement and it would be of interest to explore other models, as well as alternative structures and ways of assembling them Given that the statistical techniques have given a good overall result, it would be interesting to further explore them and to test with ensembles of models, as well as experiment with new ways of preprocessing data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.98,90.49,321.53,118.09"><head>Table 1</head><label>1</label><figDesc>Accuracy of the different tests performed with the first approach in Subtask 1</figDesc><table coords="5,184.76,122.10,225.76,86.47"><row><cell>Model tested</cell><cell cols="2">Accuracy MacroF1</cell></row><row><cell>K-means (k=5)</cell><cell>0.18</cell><cell>0.11</cell></row><row><cell>Logistic Regression</cell><cell>0.49</cell><cell>0.50</cell></row><row><cell>Perceptron (tol=1e-3)</cell><cell>0.45</cell><cell>0.43</cell></row><row><cell>SVM (tol=1e-3)</cell><cell>0.46</cell><cell>0.47</cell></row><row><cell>Fine-tuned bert-base-uncased</cell><cell>0.50</cell><cell>0.44</cell></row><row><cell>Fine-tuned vinai/bertweet-base</cell><cell>0.47</cell><cell>0.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.98,274.68,390.26,130.05"><head>Table 2</head><label>2</label><figDesc>Accuracy of the different tests performed with the second approach in Subtask 1</figDesc><table coords="5,116.02,306.30,363.22,98.43"><row><cell>Model tested</cell><cell cols="2">Accuracy MacroF1</cell></row><row><cell>K-means (k=5)</cell><cell>0.25</cell><cell>0.12</cell></row><row><cell>Logistic Regresion</cell><cell>0.56</cell><cell>0.57</cell></row><row><cell>Perceptron (tol=1e-3)</cell><cell>0.51</cell><cell>0.52</cell></row><row><cell>SVM (tol=1e-3, random_state=0)</cell><cell>0.57</cell><cell>0.57</cell></row><row><cell>Fine-tuned bert-base-uncased</cell><cell>0.61</cell><cell>0.59</cell></row><row><cell>Fine-tuned tner/twitter-roberta-base-dec2021-tweetner7-random</cell><cell>0.57</cell><cell>0.57</cell></row><row><cell>Fine-tuned vinai/bertweet-base</cell><cell>0.56</cell><cell>0.55</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.98,90.49,413.25,189.82"><head>Table 3</head><label>3</label><figDesc>Accuracy and MacroF1 of the different tests performed in Subtask 2</figDesc><table coords="7,95.27,122.10,406.97,158.20"><row><cell>Model tested</cell><cell cols="2">Accuracy MacroF1</cell></row><row><cell>KNeighbors (metric=minkowski, weight=distance)</cell><cell>0.35</cell><cell>0.36</cell></row><row><cell>Logistic Regression</cell><cell>0.42</cell><cell>0.43</cell></row><row><cell>MLP (ReLU activation, batch=64, lr=0.01, 𝛼=1e-5)</cell><cell>0.40</cell><cell>0.4</cell></row><row><cell>Naive Bayes</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>Perceptron (tol=1e-3)</cell><cell>0.41</cell><cell>0.39</cell></row><row><cell>RandomForest (No bootstrap, estimators=800)</cell><cell>0.47</cell><cell>0.46</cell></row><row><cell>Ridge (𝛼=1.0)</cell><cell>0.45</cell><cell>0.46</cell></row><row><cell>SGD (loss=modified huber, penalty=l1)</cell><cell>0.43</cell><cell>0.41</cell></row><row><cell>SVC (C=10, kernel=rbf)</cell><cell>0.44</cell><cell>0.43</cell></row><row><cell>SVM (tol=1e-3)</cell><cell>0.43</cell><cell>0.42</cell></row><row><cell>DistilBERT fine-tuned</cell><cell>0.63</cell><cell>0.63</cell></row><row><cell>RobBERTa tner/twitter-roberta-base-dec2021-tweetner7-random fine-tuned</cell><cell>0.63</cell><cell>0.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.98,302.56,307.51,94.19"><head>Table 4</head><label>4</label><figDesc>Accuracy of the different tests performed in Subtask 3</figDesc><table coords="7,198.78,334.18,197.72,62.57"><row><cell>Model tested</cell><cell cols="2">Accuracy MacroF1</cell></row><row><cell>SVM (tol=1e-3)</cell><cell>0.62</cell><cell>0.61</cell></row><row><cell>Perceptron (tol=1e-3)</cell><cell>0.59</cell><cell>0.58</cell></row><row><cell>Logistic Regression</cell><cell>0.56</cell><cell>0.58</cell></row><row><cell>DistilBERT fine-tuned</cell><cell>0.83</cell><cell>0.84</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,92.30,649.11,415.20,8.97;7,92.57,660.07,414.79,8.97;7,92.57,671.03,72.87,8.97"><p>TIRA is a platform for reproducible participation in shared tasks from information retrieval, natural language processing, and machine learning, where organizers can provide datasets to participants and manage their submissions. https://www.tira.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,556.50,393.60,10.91;8,112.66,570.05,394.53,10.91;8,112.66,583.60,395.17,10.91;8,112.66,597.15,393.33,10.91;8,112.66,610.69,394.62,10.91;8,112.31,624.24,383.98,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,433.71,556.50,72.55,10.91;8,112.66,570.05,389.56,10.91">Cryptocurrency bubble detection: A new stock market dataset, financial task &amp; hyperbolic models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.405</idno>
		<ptr target="https://aclanthology.org/2022.naacl-main.405.doi:10.18653/v1/2022.naacl-main.405" />
	</analytic>
	<monogr>
		<title level="m" coord="8,131.10,583.60,376.74,10.91;8,112.66,597.15,393.33,10.91;8,112.66,610.69,135.42,10.91">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5531" to="5545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,637.79,393.33,10.91;8,112.66,651.34,393.33,10.91;8,112.14,664.89,159.26,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,466.53,637.79,39.46,10.91;8,112.66,651.34,261.87,10.91">Profiling Cryptocurrency Influencers with Few shot Learning at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,417.97,651.34,88.02,10.91;8,112.14,664.89,47.32,10.91">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="8,167.44,664.89,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,394.52,10.91;9,112.66,100.52,394.53,10.91;9,112.66,114.06,394.52,10.91;9,112.66,127.61,393.53,10.91;9,112.66,141.16,394.53,10.91;9,112.66,154.71,395.17,10.91;9,112.66,168.26,393.33,10.91;9,112.66,181.81,394.53,10.91;9,112.66,195.36,65.44,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,294.21,114.06,212.97,10.91;9,112.66,127.61,393.53,10.91;9,112.66,141.16,42.05,10.91">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,371.28,154.71,136.55,10.91;9,112.66,168.26,393.33,10.91;9,112.66,181.81,197.14,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,342.79,181.81,159.86,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,112.66,208.91,394.61,10.91;9,112.66,222.46,394.53,10.91;9,112.66,236.01,80.57,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,270.49,208.91,216.48,10.91">Stylometric analysis of bloggers&apos; age and gender</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rustagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,222.46,342.95,10.91">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="214" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,249.56,393.53,10.91;9,112.66,263.11,394.53,10.91;9,112.66,276.66,22.69,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,219.51,249.56,286.68,10.91;9,112.66,263.11,141.42,10.91">Can we hide in the web? large scale simultaneous age and gender author profiling in social media</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Flekova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,279.59,263.11,138.70,10.91">CLEF 2012 Labs and Workshop</title>
		<title level="s" coord="9,426.85,263.11,75.65,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,394.53,10.91;9,112.28,303.75,393.71,10.91;9,112.66,317.30,389.33,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,367.27,303.75,138.71,10.91;9,112.66,317.30,269.15,10.91">Personality, gender, and age in the language of social media: The open-vocabulary approach</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Ramones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,390.59,317.30,38.72,10.91">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">73791</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.33,10.91;9,112.66,344.40,395.01,10.91;9,112.66,357.95,28.67,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,382.34,330.85,123.65,10.91;9,112.66,344.40,65.06,10.91">Personality and patterns of facebook usage</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,200.67,344.40,261.11,10.91">Proceedings of the 4th annual ACM web science conference</title>
		<meeting>the 4th annual ACM web science conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="24" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,395.17,10.91;9,112.66,385.05,395.17,10.91;9,112.66,398.60,393.33,10.91;9,112.66,412.15,394.53,10.91;9,112.66,425.70,393.33,10.91;9,112.33,439.25,395.34,10.91;9,112.66,452.79,38.81,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,192.76,398.60,313.22,10.91;9,112.66,412.15,329.22,10.91">Overview of pan 2023: Authorship verification, multi-author writing style analysis, profiling cryptocurrency influencers, and trigger detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,142.51,439.25,153.20,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="518" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,393.33,10.91;9,112.66,479.89,393.33,10.91;9,112.66,493.44,204.28,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,384.85,466.34,121.14,10.91;9,112.66,479.89,26.02,10.91">Author profiling for english emails</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Estival</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gaustad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,159.99,479.89,346.00,10.91;9,112.66,493.44,46.58,10.91">Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics</title>
		<meeting>the 10th Conference of the Pacific Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">263</biblScope>
			<biblScope unit="page">272</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,506.99,393.33,10.91;9,112.66,520.54,393.33,10.91;9,112.66,534.09,377.04,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,402.99,506.99,102.99,10.91;9,112.66,520.54,208.50,10.91">Author profiling using corpus statistics, lexicons and stylistic features</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De-Arteaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Duenas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mancera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Baquero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,329.37,520.54,176.61,10.91;9,112.66,534.09,313.50,10.91">Online Working Notes of the 10th PAN evaluation lab on uncovering plagiarism, authorship. and social misuse</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,547.64,393.33,10.91;9,112.66,561.19,393.33,10.91;9,112.66,574.74,168.33,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,336.83,547.64,169.16,10.91;9,112.66,561.19,47.01,10.91">Bertaa: Bert fine-tuning for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fabien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Parida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,183.31,561.19,322.68,10.91;9,112.66,574.74,80.10,10.91">Proceedings of the 17th International Conference on Natural Language Processing (ICON)</title>
		<meeting>the 17th International Conference on Natural Language Processing (ICON)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,588.29,393.33,10.91;9,112.66,601.84,223.54,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,273.28,588.29,232.71,10.91;9,112.66,601.84,69.14,10.91">Multi-source bert stack ensemble for cross-domain author profiling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Paraboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,189.81,601.84,68.63,10.91">Expert Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">12869</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,615.39,393.33,10.91;9,112.66,628.93,393.33,10.91;9,112.26,642.48,278.95,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,478.41,615.39,27.57,10.91;9,112.66,628.93,393.33,10.91;9,112.26,642.48,52.75,10.91">When attention is not enough to unveil a text&apos;s author profile: Enhancing a transformer with a wide branch</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>López-Santillán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>López-Monroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,173.68,642.48,161.67,10.91">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,656.03,393.53,10.91;9,112.66,669.58,393.33,10.91;10,112.33,86.97,81.40,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,275.51,656.03,230.68,10.91;9,112.66,669.58,36.58,10.91">A straightforward multimodal approach for author profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Aragón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-P</forename><surname>López-Monroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,171.76,669.58,334.22,10.91;10,112.33,86.97,51.66,10.91">Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018)</title>
		<meeting>the Ninth International Conference of the CLEF Association (CLEF 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,100.52,393.53,10.91;10,112.66,114.06,357.57,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,325.28,100.52,180.91,10.91;10,112.66,114.06,26.95,10.91">A multimodal author profiling system for tweets</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Suman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Naman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,148.03,114.06,233.19,10.91">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1407" to="1416" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,395.17,10.91;10,112.66,141.16,393.33,10.91;10,112.66,154.71,320.18,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,441.39,127.61,66.43,10.91;10,112.66,141.16,257.15,10.91">A characterization of portuguese tweets regarding the covid-19 pandemic</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Brum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vimieiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meira</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Pappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,393.24,141.16,112.74,10.91;10,112.66,154.71,208.30,10.91">Anais do VIII Symposium on Knowledge Discovery, Mining and Learning</title>
		<imprint>
			<publisher>SBC</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,168.26,393.33,10.91;10,112.66,181.81,320.15,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,281.74,168.26,224.25,10.91;10,112.66,181.81,127.37,10.91">Author profiling and aggressiveness detection in spanish tweets: Mex-a3t 2018</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Aragón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>López-Monroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,266.94,181.81,77.06,10.91">IberEval@ SEPLN</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="134" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,195.36,394.53,10.91;10,112.48,208.91,395.34,10.91;10,112.66,222.46,394.53,10.91;10,112.66,236.01,395.17,10.91;10,112.66,249.56,394.53,10.91;10,112.30,263.11,395.36,10.91;10,112.66,276.66,330.68,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="10,160.36,263.11,316.02,10.91">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/,softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,290.20,393.33,10.91;10,112.66,303.75,393.33,10.91;10,112.66,317.30,393.32,10.91;10,112.66,330.85,393.33,10.91;10,112.66,344.40,394.03,10.91;10,112.66,357.95,185.51,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,323.15,290.20,182.83,10.91;10,112.66,303.75,186.91,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423.doi:10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="10,327.87,303.75,178.11,10.91;10,112.66,317.30,393.32,10.91;10,112.66,330.85,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="10,112.66,371.50,393.32,10.91;10,112.33,385.05,393.65,10.91;10,112.66,398.60,230.27,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,270.60,371.50,235.39,10.91;10,112.33,385.05,28.53,10.91">BERTweet: A pre-trained language model for English Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,162.88,385.05,343.10,10.91;10,112.66,398.60,157.27,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,412.15,393.33,10.91;10,112.66,425.70,393.53,10.91;10,112.66,439.25,393.53,10.91;10,112.66,452.79,395.01,10.91;10,112.66,466.34,254.51,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,286.18,412.15,219.80,10.91;10,112.66,425.70,108.05,10.91">An all-round python library for transformer-based named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ushio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T-Ner</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-demos.7</idno>
		<ptr target="https://aclanthology.org/2021.eacl-demos.7.doi:10.18653/v1/2021.eacl-demos.7" />
	</analytic>
	<monogr>
		<title level="m" coord="10,242.65,425.70,263.54,10.91;10,112.66,439.25,393.53,10.91;10,112.66,452.79,117.86,10.91">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="53" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,479.89,394.53,10.91;10,112.66,493.44,394.53,10.91;10,112.66,506.99,393.32,10.91;10,112.66,520.54,176.63,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,228.10,506.99,182.14,10.91">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,419.22,506.99,86.76,10.91;10,112.66,520.54,82.55,10.91">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,534.09,393.33,10.91;10,112.66,547.64,258.44,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="10,370.31,534.09,106.12,10.91">Support vector machines</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Osuna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,484.95,534.09,21.04,10.91;10,112.66,547.64,184.65,10.91">IEEE Intelligent Systems and their applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,561.19,393.32,10.91;10,112.66,574.74,323.14,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,236.46,561.19,217.63,10.91">Algorithm as 136: A k-means clustering algorithm</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Hartigan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,462.53,561.19,43.45,10.91;10,112.66,574.74,239.20,10.91">Journal of the royal statistical society. series c (applied statistics)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,588.29,395.17,10.91;10,112.66,601.84,237.69,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,175.21,588.29,332.62,10.91;10,112.66,601.84,69.12,10.91">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,193.74,601.84,93.87,10.91">Psychological review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">386</biblScope>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,615.39,178.85,10.91" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="10,173.44,615.39,81.75,10.91">Logistic regression</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,628.93,394.53,10.91;10,112.66,642.48,395.01,10.91;10,112.41,656.03,18.52,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="10,289.96,628.93,212.35,10.91">Understanding of a convolutional neural network</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Albawi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Al-Zawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,127.50,642.48,309.64,10.91">2017 international conference on engineering and technology (ICET)</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,669.58,394.53,10.91;11,112.66,86.97,243.23,10.91" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m" coord="10,302.07,669.58,205.12,10.91;11,112.66,86.97,113.82,10.91">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,100.52,393.33,10.91;11,112.66,114.06,393.98,10.91;11,112.66,127.61,48.96,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="11,244.27,100.52,261.71,10.91;11,112.66,114.06,223.99,10.91">Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dorling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,344.95,114.06,118.88,10.91">Atmospheric environment</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2627" to="2636" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,141.16,393.32,10.91;11,112.66,154.71,309.72,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="11,172.38,141.16,204.54,10.91">An empirical study of the naive bayes classifier</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,398.90,141.16,107.08,10.91;11,112.66,154.71,186.48,10.91">IJCAI 2001 workshop on empirical methods in artificial intelligence</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,168.26,277.53,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="11,167.61,168.26,67.74,10.91">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,243.28,168.26,78.19,10.91">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,181.81,393.33,10.91;11,112.48,195.36,329.02,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="11,244.98,181.81,159.25,10.91">Kernel ridge regression classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,426.44,181.81,79.55,10.91;11,112.48,195.36,204.23,10.91">2014 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2263" to="2267" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
