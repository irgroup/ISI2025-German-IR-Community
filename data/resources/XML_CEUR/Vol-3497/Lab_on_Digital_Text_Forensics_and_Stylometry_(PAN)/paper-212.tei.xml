<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,384.64,15.42;1,88.78,106.66,402.39,15.42;1,89.29,129.00,157.29,11.96">Enhancing Writing Style Change Detection using Transformer-based Models and Data Augmentation Notebook for PAN at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,154.90,82.00,11.96"><forename type="first">Ahmad</forename><surname>Hashemi</surname></persName>
							<email>ahmadhashemi@cmail.carleton.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Carleton University</orgName>
								<address>
									<settlement>Ottawa</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.52,154.90,37.46,11.96"><forename type="first">Wei</forename><surname>Shi</surname></persName>
							<email>wei.shi@carleton.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Carleton University</orgName>
								<address>
									<settlement>Ottawa</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,384.64,15.42;1,88.78,106.66,402.39,15.42;1,89.29,129.00,157.29,11.96">Enhancing Writing Style Change Detection using Transformer-based Models and Data Augmentation Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">256E46B33C68E20DAAF4A53F5F492198</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plagiarism Detection</term>
					<term>Ensemble Learning</term>
					<term>Transformers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our participation in the Style Change Detection task for PAN at CLEF 2023. The primary goal of this task is to identify alterations in writing style at the paragraph level within a provided document that has been authored by multiple writers. The task comprises three sub-tasks that differ in difficulty levels, primarily based on the diversity of topics addressed within the paragraphs. To address these sub-tasks, we investigate the effectiveness of fine-tuning different pre-trained transformer-based models, with a particular emphasis on RoBERTa. Additionally, we employ data augmentation techniques to enhance the performance of our models. Furthermore, we incorporate ensemble modeling to further improve the accuracy and robustness of our style change detection system. In the competition, our provided models achieved the first rank in terms of F1 score for two of the sub-tasks, and secured the second position for the remaining sub-task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-Author writing style analysis is an interesting area of study that focuses on analyzing documents that have been written by multiple authors. It involves a range of tasks, such as determining whether a document is the product of a single author or multiple authors <ref type="bibr" coords="1,459.25,448.52,11.28,10.91" target="#b0">[1]</ref>, as well as investigating the occurrence and positioning of style changes in multi-authored documents <ref type="bibr" coords="1,89.29,475.62,11.53,10.91" target="#b1">[2]</ref>. The primary motivation behind Multi-Author writing style analysis is that it enables the identification of positions where authors switch within a text, allowing for the detection of plagiarism and the verification of claimed authorship, even in the absence of comparison texts. Style change detection also assists in uncovering gift authorships and can contribute to the development of innovative technologies for writing support <ref type="bibr" coords="1,358.51,529.82,11.43,10.91" target="#b2">[3]</ref>.</p><p>The style change detection task introduced by PAN <ref type="bibr" coords="1,326.35,543.37,12.68,10.91" target="#b3">[4]</ref> this year focuses on detecting writing style changes at the paragraph level in a given text document. The objective is to detect style changes between consecutive paragraphs, assessing whether there was a transition in writing style. The task provides datasets of three difficulty levels: easy (subtask 1), medium (subtask 2), and hard (subtask 3. In the easy level, paragraphs cover a range of topics, allowing approaches to utilize topic information for detecting authorship changes. The medium level features a smaller topical variety, requiring the approach to focus more on style to effectively solve the detection task. The hard level consists of paragraphs on the same topic throughout the document <ref type="bibr" coords="2,480.90,114.06,11.43,10.91" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>With the advancements in natural language processing techniques, many researchers have directed their attention toward various tasks within the realm of digital text forensics. These tasks cover a wide range, including the detection of fake news <ref type="bibr" coords="2,371.18,199.79,11.50,10.91" target="#b5">[6]</ref>, spam <ref type="bibr" coords="2,415.75,199.79,11.50,10.91" target="#b6">[7]</ref>, and hate speech <ref type="bibr" coords="2,89.29,213.34,11.58,10.91" target="#b7">[8]</ref>, as well as author profiling <ref type="bibr" coords="2,233.71,213.34,11.58,10.91" target="#b8">[9]</ref>, authorship attribution <ref type="bibr" coords="2,358.26,213.34,16.41,10.91" target="#b9">[10]</ref>, and style change detection <ref type="bibr" coords="2,89.29,226.89,16.23,10.91" target="#b10">[11]</ref>. Earlier studies primarily employed feature-based approaches, involving the extraction of stylistic features followed by applying traditional machine learning or deep learning algorithms. However, the emergence of pre-trained transformer-based models, with their remarkable capabilities, has led to a shift in focus for many recent studies. These studies now mostly center around fine-tuning pre-trained models to customize them for their respective tasks.</p><p>In the domain of style change detection, early attempts primarily revolved around the extraction of stylometric features. For instance, Eissen and Stein <ref type="bibr" coords="2,371.75,308.18,17.75,10.91" target="#b11">[12]</ref> employed word frequency classes to differentiate between distinct writing styles in order to investigate intrinsic plagiarism detection. Bensalem et al. <ref type="bibr" coords="2,201.71,335.28,17.76,10.91" target="#b12">[13]</ref> utilized n-grams to identify authorial style changes, while Gianella <ref type="bibr" coords="2,89.29,348.83,17.76,10.91" target="#b13">[14]</ref> applied Bayesian modeling techniques to segment a document based on authorship. Another approach <ref type="bibr" coords="2,134.37,362.38,16.41,10.91" target="#b14">[15]</ref>, involved the use of neural networks in conjunction with various stylometric features.</p><p>More recent approaches in style change detection have mostly leveraged pre-trained models, although some still incorporate stylometric features. For example, Iyer and Vosoughi <ref type="bibr" coords="2,487.91,403.03,18.07,10.91" target="#b15">[16]</ref> employed Google AI's BERT pre-trained bidirectional models to tokenize and generate sentence embeddings, which were then utilized to train a random forest classifier for the PAN's SCD task. For the PAN SCD task of 2021, Singh et al. <ref type="bibr" coords="2,304.89,443.67,17.93,10.91" target="#b16">[17]</ref> extracted stylometric features from each paragraph and used the absolute differences between the feature vectors to train a Logistic Regression classifier to determine if two paragraphs were written by the same author. Lin et al. <ref type="bibr" coords="2,102.67,484.32,17.86,10.91" target="#b17">[18]</ref> fine-tuned transformer models such as BERT, RoBERTa, and ALBERT, along with their classifiers, to measure the similarity between paragraphs or sentences for authorship analysis in the most recent PAN style change detection task in 2022.</p><p>In our work, we investigate the effectiveness of leveraging three pre-trained transformerbased models in detecting style changes between consecutive paragraphs, where both the author and topic change, as well as cases where only the author changes while the topic remains the same. Additionally, we apply data augmentation techniques and employ ensemble modeling to enhance the performance of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset</head><p>For each of the subtasks, a separate dataset has been provided. These datasets comprise multiple documents, with each document containing some paragraphs. For every document, a corresponding ground truth file is available, providing two pieces of information: 1) the number of authors associated with the document, and 2) the identification of consecutive paragraphs where a style change has occurred, indicating a transition in authorship. Each subtask's dataset has been divided into a training set and a validation set. For our experimental setup, we treated every pair of consecutive paragraphs as a sample and concatenated them. Each sample was assigned a label indicating whether a style change occurred between the two paragraphs (labeled as 1) or if they were written by the same author (labeled as 0). Further details and statistics about the datasets in our experimental setup can be found in Table <ref type="table" coords="3,156.55,353.64,3.74,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data preparation</head><p>To create the samples, we begin by concatenating two consecutive paragraphs within each document using a separator token. Next, we assign the associated binary label indicating whether a style change occurs between the two paragraphs. This allows us to transform the task into a binary classification problem. To prepare the samples for fine-tuning the pretrained transformer-based models (specifically BERT, RoBERTa, and ELECTRA), we employ the corresponding tokenizer associated with each model. However, it is important to note that these models have limitations regarding the maximum input sequence size, typically set at 512 tokens. To address this limitation, we analyze the datasets and find that in each dataset only a few samples exceed the maximum token limit. Therefore, we opt to truncate the longer samples. To ensure equal attention is given to each paragraph in the sample, we adopt a truncation strategy that involves removing tokens from both ends of the sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Pre-trained Transformer Models</head><p>Pre-trained transformer models are powerful language models that are trained on massive amounts of text data. They learn to understand the structure and patterns of language, enabling them to generate high-quality text and perform various natural language processing (NLP) tasks. Fine-tuning the pre-trained models allows us to leverage their language understanding capabilities and transfer the knowledge they have acquired from their extensive pre-training to our specific task. In our study, we employed three popular pre-trained transformer models, namely BERT, RoBERTa, and ELECTRA.</p><p>BERT (Bidirectional Encoder Representations from Transformers) is a revolutionary model that introduced the concept of bidirectional context to capture the dependencies between words. It utilizes a transformer architecture and pre-training tasks such as masked language modeling to learn contextualized representations of words <ref type="bibr" coords="4,305.25,168.26,16.17,10.91" target="#b18">[19]</ref>. RoBERTa, an extension of BERT, further enhanced the pre-training process by utilizing additional training data and applying dynamic masking strategies. This enabled RoBERTa to achieve even better performance across a range of NLP tasks <ref type="bibr" coords="4,135.89,208.91,16.12,10.91" target="#b19">[20]</ref>. ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) introduced a novel pre-training method called "discriminative masked language modeling. " It improves efficiency by generating synthetic training data and training the model to differentiate between original and replaced tokens <ref type="bibr" coords="4,327.33,249.56,16.25,10.91" target="#b20">[21]</ref>.</p><p>To adapt these pre-trained models for our specific task of style change detection, we added a binary classification layer on top of each model. This allowed the models to learn and classify whether a style change occurred between the consecutive paragraphs in each sample. For each subtask, we fine-tuned the models using the associated dataset to consider the unique characteristics of each subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Data augmentation</head><p>To explore the potential impact of generating more samples while disregarding the consecutiveness and order of the paragraphs, we conduct an investigation. We transform the task into determining whether the same author wrote two concatenated paragraphs (not necessarily consecutive or in order). This allows us to explore different approaches for data augmentation. In our first approach, we swap the order of the two paragraphs in each sample, creating a new sample with the same label to double the number of samples. Additionally, we leverage the metadata provided in the datasets to identify paragraphs written by the same authors that are not necessarily consecutive. Using the metadata, which includes the number of authors in each document, we employ the Algorithm 1 for each document to retrieve such pairs of paragraphs and augment the data.</p><p>As Algorithm 1 demonstrates, we incorporate additional non-consecutive pairs of paragraphs into our sample set and assign them labels based on the inferred relationships. For example, if there are three consecutive paragraphs without a style change, we can infer that the first and third paragraphs are written by the same author. Similarly, if there are style changes between the first and second paragraphs and between the second and third paragraphs, we can deduce that the authors of the first and third paragraphs are different, given that the number of authors in the document exceeds the number of style changes by one.</p><p>After data augmentation, we utilize our extended sample sets for each subtask to fine-tune the pre-trained model following the same process explained earlier. It is important to note that this augmentation introduces a change in the nature of the train set, deviating from the consecutive and ordered structure that exists in the test data. However, the advantage of having a larger dataset can improve the model's ability to capture patterns across paragraphs written by the same author. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Generalization and Ensemble modeling</head><p>Given the similarity in the nature of datasets across different subtasks, particularly in terms of the presence of style changes, we explore the potential benefits of leveraging datasets from other subtasks to enhance the model performance for a specific subtask. For example, Task 2 and Task 3 share similarities as they both involve style changes occurring while the topic remains consistent. Similarly, Task 2 and Task 1 exhibit similarities as they both encompass style changes alongside topic transitions. We believe that the datasets from Task 1 and Task 3 can provide valuable insights to Task 2, as they encompass scenarios that align with this task. Accordingly, our investigation involves not only fine-tuning the model using the provided dataset specific to the subtask but also incorporating additional samples from other subtasks' datasets to assess the impact of having a generalized model.</p><p>To maximize the potential benefits offered by the various approaches mentioned, we employ an ensemble strategy based on the majority voting approach. For each subtask, we develop three models, all based on fine-tuning the RoBERTa pre-trained model, which we will discuss in subsequent sections as the most effective among the investigated pre-trained models for all subtasks. The first model utilizes the initial samples exclusively from the task-specific dataset for fine-tuning. The second model incorporates augmented samples derived from the task-specific dataset, thereby expanding the training data. Lastly, the third model combines all the original samples from the other datasets in addition to the task-specific dataset to provide a generalized model. By ensembling these models, we aim to leverage the strengths of each approach and enhance the overall performance of our style change detection system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental settings</head><p>We downloaded the large versions of pre-trained BERT, RoBERTa, and ELECTRA models from HuggingFace <ref type="bibr" coords="6,151.13,207.21,16.29,10.91" target="#b21">[22]</ref>. The implementation and fine-tuning of these models were conducted on a server equipped with an NVIDIA A100 GPU. To optimize the performance of our models, we selected hyperparameter values as follows: We set the maximum sequence length to 512, the learning rate to 0.00001, the batch size to 16, and the number of epochs to 10.</p><p>To assess the effectiveness of the models for each subtask, we evaluate their performance by computing the F1 score on the provided evaluation set. The F1 score is calculated based on the predictions made by the models for detecting style changes between consecutive paragraph pairs within the evaluation set of each subtask. After conducting our experiments and obtaining results on the evaluation sets, we select the best-performing model for each subtask and run the model on an unseen test set using the TIRA platform <ref type="bibr" coords="6,344.40,329.15,16.25,10.91" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>The results of our experiments are presented in this section. Firstly, Table <ref type="table" coords="6,441.70,378.88,5.17,10.91" target="#tab_2">2</ref> displays the performance comparison of fine-tuning pre-trained models on the original task-specific datasets for each subtask. The findings indicate that RoBERTa consistently outperforms both BERT and ELECTRA across all subtasks, establishing its superiority in the task of style change detection. As a result, we have selected RoBERTa as the preferred approach for our style change detection system.</p><p>Moving on, Table <ref type="table" coords="6,185.61,460.17,5.17,10.91" target="#tab_3">3</ref> presents the performance evaluation results of our RoBERTa-based experiments on the evaluation set. It highlights the F1 scores for each subtask and approach. The findings reveal that fine-tuning RoBERTa on the original task-specific dataset yields the highest F1 scores among all the provided approaches for subtasks 1 and 3. As can be seen, the performance of the generalized model trained on all the datasets drops for subtask 1 and subtask 3, which aligns with our expectations as these subtasks possess exclusive characteristics that may not benefit from additional data from the other subtasks. On the other hand, subtask 2 exhibits similarities to both subtask 1 (style changes along with topic changes) and subtask 3 (style changes without topic change), which explains why the performance drop for the generalized model is less significant in subtask 2.</p><p>Furthermore, incorporating augmented data for subtask 3 leads to a notable performance drop, suggesting that considering paragraph order and consecutiveness is not negligible for detecting style changes when the topic is consistent. However, the utilization of augmented data produces competitive performance compared to only using the original samples for subtasks 1 and 2. Notably, the ensemble model for subtask 2 achieves the best F1 score, indicating that the individual models capture complementary patterns that contribute to the overall performance improvement.</p><p>Based on the validation set results, we select the ensemble approach for subtask 2 and the basic RoBERTa models for subtasks 1 and 3 to perform on the final test sets. The final results of our selected models on the unseen test sets are presented in Table <ref type="table" coords="7,414.39,497.25,3.81,10.91" target="#tab_4">4</ref>. According to the provided results reported by the competition organizers, our provided models for subtasks 1 and 2 outperformed all other participants' models, securing the first position. For subtask 3, we achieved the second position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In conclusion, our investigation aimed to enhance style change detection in textual documents through various techniques and approaches. We explored data augmentation strategies to generate non-consecutive paragraph pairs, allowing the model to learn patterns beyond sequential and ordered paragraphs. We found that fine-tuned RoBERTa models outperformed BERT and ELECTRA in all the task difficulty levels, demonstrating their effectiveness in capturing style changes. The results also highlighted the importance of considering the unique nature of each task, as incorporating additional data from unrelated tasks did not necessarily improve performance.</p><p>Furthermore, the ensemble approach proved to be valuable in capturing complementary patterns, particularly for subtask 2, where the nature of the subtask contained similarities to both the other subtasks. This ensemble model outperformed individual models, emphasizing the benefits of combining multiple perspectives. We believe these insights contribute to advancements in authorship attribution and plagiarism detection applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,418.09,141.60"><head>Table 1</head><label>1</label><figDesc>Datasets statistics. "Training 1, " "Training 2, " and "Training 3" correspond to the tasks with easy, medium, and hard difficulty levels, respectively. Similarly, "Validation 1, " "Validation 2, " and "Validation 3" represent the validation sets for each respective task.</figDesc><table coords="3,107.96,146.01,379.37,86.07"><row><cell>Dataset</cell><cell cols="5">documents Avg. paragraphs per document samples positive negetive</cell></row><row><cell>Training 1</cell><cell>4200</cell><cell>4.07</cell><cell>12,904</cell><cell>11,347</cell><cell>1,557</cell></row><row><cell>Training 2</cell><cell>4200</cell><cell>7.71</cell><cell>28,216</cell><cell>13,215</cell><cell>15,001</cell></row><row><cell>Training 3</cell><cell>4200</cell><cell>5.55</cell><cell>19,113</cell><cell>9,021</cell><cell>10,092</cell></row><row><cell>Validation 1</cell><cell>900</cell><cell>4.14</cell><cell>2,828</cell><cell>2,451</cell><cell>377</cell></row><row><cell>Validation 2</cell><cell>900</cell><cell>8.82</cell><cell>7,042</cell><cell>3,029</cell><cell>4,013</cell></row><row><cell>Validation 3</cell><cell>900</cell><cell>5.56</cell><cell>4,112</cell><cell>1,953</cell><cell>2,159</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,94.31,89.50,395.31,301.90"><head>Algorithm 1 :</head><label>1</label><figDesc>Pseudocode for data augmentation based on non-consecutive paragraph pairs</figDesc><table coords="5,100.14,120.63,389.48,199.25"><row><cell cols="2">if style_changes.count(1) = (authors_count -1) then</cell></row><row><cell>for 𝑖 in range(len(paragraphs) -1) do</cell><cell></cell></row><row><cell>𝑗 ← 𝑖 + 1 ;</cell><cell>// set the next paragraph index</cell></row><row><cell cols="2">while 𝑗 &lt; len(paragraphs) and style_changes[𝑗 -1] = 0 do</cell></row><row><cell>;</cell><cell>// while same author</cell></row><row><cell>if 𝑗 &gt; 𝑖 + 1 then</cell><cell></cell></row><row><cell cols="2">samples.append(paragraphs[𝑖] + seperator + paragraphs[𝑗])</cell></row><row><cell>labels.append(0) ;</cell><cell>// same author</cell></row><row><cell>end</cell><cell></cell></row><row><cell>𝑗 ← 𝑗 + 1 ;</cell><cell>// move to the next paragraph</cell></row><row><cell>end</cell><cell></cell></row><row><cell>while 𝑗 &lt; len(paragraphs) do</cell><cell></cell></row><row><cell>if 𝑗 &gt; 𝑖 + 1 then</cell><cell></cell></row><row><cell cols="2">samples.append(paragraphs[𝑖] + seperator + paragraphs[𝑗])</cell></row><row><cell>labels.append(1) ;</cell><cell></cell></row></table><note coords="5,400.60,311.41,89.02,7.90;5,150.15,324.45,18.17,9.76;5,150.15,337.06,51.29,10.91;5,317.52,339.51,172.10,7.90;5,133.48,352.55,18.17,9.76;5,116.81,367.09,18.17,9.76;5,100.14,381.64,18.17,9.76"><p>// style change end 𝑗 ← 𝑗 + 1 ; // move to the next paragraph end end end</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,90.49,417.00,93.79"><head>Table 2</head><label>2</label><figDesc>F1 score obtained by fine-tuning each pre-trained model for each of the subtasks on the associated validation set. The best result for each dataset is given in bold.</figDesc><table coords="7,182.66,134.06,229.95,50.22"><row><cell cols="4">Pre-trained Model Subtask 1 Subtask 2 Subtask 3</cell></row><row><cell>BERT</cell><cell>0.9823</cell><cell>0.7451</cell><cell>0.7048</cell></row><row><cell>ELECTRA</cell><cell>0.9882</cell><cell>0.8024</cell><cell>0.7797</cell></row><row><cell>RoBERTa</cell><cell>0.9957</cell><cell>0.8106</cell><cell>0.8140</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,206.53,416.99,105.75"><head>Table 3</head><label>3</label><figDesc>F1 score obtained by each RoBERTa-based approach for each of the subtasks on the associated validation set. The best result for each dataset is given in bold.</figDesc><table coords="7,168.36,250.10,258.54,62.17"><row><cell>Approach</cell><cell cols="3">Subtask 1 Subtask 2 Subtask 3</cell></row><row><cell>Basic</cell><cell>0.9957</cell><cell>0.8106</cell><cell>0.8140</cell></row><row><cell>Augmented data</cell><cell>0.9832</cell><cell>0.8053</cell><cell>0.7266</cell></row><row><cell>Generalized (all datasets)</cell><cell>0.9661</cell><cell>0.8042</cell><cell>0.7449</cell></row><row><cell>Ensemble</cell><cell>0.9907</cell><cell>0.8221</cell><cell>0.7906</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,334.52,271.67,81.83"><head>Table 4</head><label>4</label><figDesc>Final performance results on the unseen test sets.</figDesc><table coords="7,234.60,366.14,126.06,50.21"><row><cell>Task</cell><cell>Reported F1 Score</cell></row><row><cell>Subtask 1</cell><cell>0.984</cell></row><row><cell>Subtask 2</cell><cell>0.843</cell></row><row><cell>Subtask 3</cell><cell>0.812</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,226.89,395.16,10.91;8,112.66,240.44,393.32,10.91;8,112.66,253.99,395.17,10.91;8,112.66,267.54,394.53,10.91;8,112.66,281.08,39.94,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,489.23,226.89,18.59,10.91;8,112.66,240.44,393.32,10.91;8,112.66,253.99,165.18,10.91">Overview of the author identification task at pan-2018: cross-domain authorship attribution and style change detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,300.54,253.99,207.29,10.91;8,112.66,267.54,43.80,10.91">Working Notes Papers of the CLEF 2018 Evaluation Labs</title>
		<editor>et al.</editor>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14, 2018/Cappellato. 2018</date>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
	<note>Potthast</note>
</biblStruct>

<biblStruct coords="8,112.66,294.63,393.33,10.91;8,112.66,308.18,270.06,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,372.11,294.63,133.87,10.91;8,112.66,308.18,92.73,10.91">Overview of the style change detection task at pan</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,237.13,308.18,100.80,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">93</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,321.73,394.04,10.91;8,112.66,335.28,256.08,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,112.66,321.73,181.40,10.91">Style Change Detection Task at CLEF</title>
		<ptr target="https://pan.webis.de/clef23/pan23-web/style-change-detection.html" />
		<imprint>
			<date type="published" when="2023-07-02">2023. 2023. July 2, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,348.83,394.52,10.91;8,112.66,362.38,394.53,10.91;8,112.66,375.93,394.52,10.91;8,112.66,389.48,393.53,10.91;8,112.66,403.03,394.53,10.91;8,112.66,416.58,395.17,10.91;8,112.66,430.13,393.33,10.91;8,112.66,443.67,394.53,10.91;8,112.66,457.22,65.44,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,294.21,375.93,212.97,10.91;8,112.66,389.48,393.53,10.91;8,112.66,403.03,42.05,10.91">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.28,416.58,136.55,10.91;8,112.66,430.13,393.33,10.91;8,112.66,443.67,197.14,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="8,342.79,443.67,159.86,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,112.66,470.77,393.33,10.91;8,112.28,484.32,394.91,10.91;8,112.14,497.87,395.04,10.91;8,112.66,511.42,22.69,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,312.82,470.77,193.17,10.91;8,112.28,484.32,119.92,10.91">Overview of the Multi-Author Writing Style Analysis Task at PAN 2023</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.14,497.87,339.19,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,524.97,394.52,10.91;8,112.66,538.52,303.93,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,210.99,524.97,296.19,10.91;8,112.66,538.52,77.18,10.91">A survey of fake news: Fundamental theories, detection methods, and opportunities</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zafarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,198.23,538.52,149.64,10.91">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,552.07,394.53,10.91;8,112.66,565.62,333.60,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,246.50,552.07,260.69,10.91;8,112.66,565.62,91.44,10.91">A review on social spam detection: Challenges, open issues, and future directions</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bhatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,212.26,565.62,150.97,10.91">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page">115742</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,579.17,393.32,10.91;8,112.66,592.72,235.52,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,203.63,579.17,302.35,10.91;8,112.66,592.72,57.75,10.91">Towards generalisable hate speech detection: a review on obstacles and solutions</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,178.63,592.72,107.01,10.91">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">598</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,606.27,393.33,10.91;8,112.26,619.81,144.70,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,205.72,606.27,223.09,10.91">Survey on profiling age and gender of text authors</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hacohen-Kerner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,437.29,606.27,68.70,10.91;8,112.26,619.81,79.61,10.91">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="page">117140</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,633.36,393.61,10.91;8,112.66,646.91,224.40,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,188.79,633.36,209.65,10.91">A review on authorship attribution in text mining</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,405.75,633.36,100.52,10.91;8,112.66,646.91,151.71,10.91">Wiley Interdisciplinary Reviews: Computational Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1584</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,660.46,394.53,10.91;9,112.66,86.97,395.17,10.91;9,112.66,100.52,393.33,10.91;9,112.66,114.06,393.33,10.91;9,112.66,127.61,394.53,10.91;9,112.66,141.16,123.33,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,315.12,86.97,192.71,10.91;9,112.66,100.52,313.25,10.91">Overview of pan 2022: Authorship verification, profiling irony and stereotype spreaders, and style change detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ortega-Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,447.41,100.52,58.58,10.91;9,112.66,114.06,393.33,10.91;9,112.66,127.61,161.73,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="382" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,154.71,393.33,10.91;9,112.66,168.26,394.53,10.91;9,112.66,181.81,220.87,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,230.19,154.71,133.09,10.91">Intrinsic plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M Z</forename><surname>Eissen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,391.32,154.71,114.67,10.91;9,112.66,168.26,278.19,10.91">Advances in Information Retrieval: 28th European Conference on IR Research, ECIR 2006</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">April 10-12, 2006. 2006</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="565" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,394.61,10.91;9,112.66,208.91,393.33,10.91;9,112.33,222.46,136.87,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,259.66,195.36,227.92,10.91">Intrinsic plagiarism detection using n-gram classes</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bensalem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chikhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,208.91,393.33,10.91;9,112.33,222.46,37.99,10.91">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1459" to="1464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,236.01,393.53,10.91;9,112.66,249.56,393.98,10.91;9,112.41,263.11,38.81,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,174.30,236.01,331.89,10.91;9,112.66,249.56,41.98,10.91">An improved algorithm for unsupervised decomposition of a multi-author document</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Giannella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,163.79,249.56,300.16,10.91">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="400" to="411" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,276.66,393.33,10.91;9,112.66,290.20,184.41,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,260.37,276.66,201.73,10.91">Segmenting documents by stylistic character</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Marthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,471.54,276.66,34.45,10.91;9,112.66,290.20,100.47,10.91">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="397" to="415" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.98,10.91;9,112.41,317.30,17.62,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,205.98,303.75,145.78,10.91">Style change detection using bert</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,363.23,303.75,100.97,10.91">CLEF (Working Notes)</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.53,10.91;9,112.66,344.40,268.67,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,293.93,330.85,212.26,10.91;9,112.66,344.40,43.74,10.91">Writing style change detection on multi-author documents</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weerasinghe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,184.68,344.40,98.72,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2137" to="2145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,357.95,393.32,10.91;9,112.66,371.50,208.96,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="9,317.95,357.95,188.03,10.91;9,112.66,371.50,148.94,10.91">Ensemble pre-trained transformer models for writing style change detection</title>
		<author>
			<persName coords=""><forename type="first">T.-M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-W</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-H</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>CLEF</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,385.05,393.33,10.91;9,112.66,398.60,363.59,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="9,353.43,385.05,152.55,10.91;9,112.66,398.60,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,412.15,394.53,10.91;9,112.30,425.70,393.68,10.91;9,112.66,439.25,107.17,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="9,173.53,425.70,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,452.79,393.33,10.91;9,112.66,466.34,347.38,10.91" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="9,335.14,452.79,170.85,10.91;9,112.66,466.34,165.13,10.91">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,479.89,394.53,10.91;9,112.66,493.44,395.17,10.91;9,112.66,506.99,212.50,10.91" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="9,206.90,493.44,300.93,10.91;9,112.66,506.99,30.43,10.91">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,520.54,394.52,10.91;9,112.66,534.09,394.62,10.91;9,112.48,547.64,394.70,10.91;9,112.28,561.19,393.71,10.91;9,112.66,574.74,393.33,10.91;9,112.66,588.29,129.64,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,174.00,534.09,296.53,10.91">Continuous Integration for Reproducible Shared Tasks with TIRA</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kolyada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grahm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elstner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Loebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,192.86,561.19,313.12,10.91;9,112.66,574.74,95.19,10.91">Advances in Information Retrieval. 45th European Conference on IR Research (ECIR 2023)</title>
		<title level="s" coord="9,215.26,574.74,158.83,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="236" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
