<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.02,74.78,380.91,18.06;1,72.02,98.36,82.34,17.04;1,72.02,118.51,148.95,9.94">A Contrastive Learning of Sample Pairs for Authorship Verification Notebook for PAN at CLEF 2023</title>
				<funder ref="#_Ten8WEb">
					<orgName type="full">National Social Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,145.21,63.36,10.80"><forename type="first">Mingcan</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,144.53,145.21,77.54,10.80"><forename type="first">Zhongyuan</forename><surname>Han</surname></persName>
							<email>hanzhongyuan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,232.18,145.21,68.90,10.80"><forename type="first">Haoyang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.72,145.21,59.04,10.80"><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
							<email>haoliang.qi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.02,74.78,380.91,18.06;1,72.02,98.36,82.34,17.04;1,72.02,118.51,148.95,9.94">A Contrastive Learning of Sample Pairs for Authorship Verification Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">238F65C84DF76FAF2340A8905D1A42BE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>contrastive learning</term>
					<term>sample pairs</term>
					<term>authorship verification</term>
					<term>cosine similarity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe a contrastive learning method using sample pairs to compute loss for tackling the authorship verification task. Classical sample-based contrastive learning is not applicable to this task because it needs to compare multiple samples in the same batch. Our method pushes away the distance between positive sample pairs and negative sample pairs according to the cosine similarity contrast of positive and negative sample pairs so that the model has the ability to judge whether a sample pair is more similar or less similar. Evaluation results on the dataset of the PAN corpus show that the method is effective and that it could determine whether more than 50% of the sample pairs are written by the same author with an overall score greater than 0.6.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.96" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.96" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.96" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.96" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="594.96" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Text classification is a basic research direction in NLP tasks. The purpose of Authorship Verification in this direction is to judge whether two texts are written by the same person. Authorship Verification can be widely used in article duplication verification, article source finding, plagiarism detection, and other fields. In the data set of the Authorship Verification task of PAN@CLEF 2023 <ref type="bibr" coords="1,431.21,450.74,11.64,9.94" target="#b0">[1,</ref><ref type="bibr" coords="1,446.54,450.74,7.78,9.94" target="#b1">2]</ref>, similar to last year, the organizers provide four types of text data: interview, email, essay, and speech transcription. For this task, our work builds a sentence vector model based on the naive idea of using sample pair matching labeled data, where the labeled data used are common text pair samples, and each sample is "(text1, text2, label)" format, then use the contrastive learning method of improving the loss function to complete the task. At the same time, to solve the problem of fewer training samples, we use the method of splitting and reorganizing to obtain a large amount of train data and train our model through a large number of sample pairs to improve its reasoning ability on the test set. Finally, we submit our run on TIRA.io <ref type="bibr" coords="1,143.09,553.75,11.63,9.94" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head><p>In the organizers' dataset provided by the Authorship Verification task, a total of 8836 labeled text pair samples from 56 authors are included. The label is represented by 1 or 0, representing whether the two texts are from the same author.</p><p>This year, there are four kinds of discourse types: interview, email, essay, and speech transcription. The length of each text is between 1 and 3499, and the distribution number and average length of the two texts are shown in Table <ref type="table" coords="1,201.85,674.73,4.02,9.94" target="#tab_0">1</ref>.</p><p>In PAN@CLEF 2023, the organizers firstly focuses on (cross-discourse type) authorship verification, where both written language (i.e., essays and emails) and spoken language (i.e., interviews and speech transcriptions) are represented in the set of discourse types. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology 3.1. Dataset Preprocessing</head><p>The training set contains a total of 56 authors. In the data set processing part, a total of 886 unique texts are obtained after deduplication. The text list is established according to the order of these authors, and each text is matched with a positive example belonging to the positive samples from the same authors or negative samples from different authors.</p><p>Specifically, suppose the extracted text list list_all= [texta1, texta2, textb1, ..., textz16], where a, b, etc. represent different authors, 1, 2, etc. represent different texts by the same author. We recombine these texts using a strategy the first and second texts of the same author match, the second and third texts match, and a total of</p><formula xml:id="formula_0" coords="2,186.31,389.24,40.72,21.79">‚àë ( 2 ùëõ ùëñ ) ùëö ùëñ=1</formula><p>positive sample pairs can be generated, where m is the total number of authors, ùëõ ùëñ represents the number of texts of the i-th author, ùëñ ‚àà {1,2,3, ‚Ä¶ , ùëö}. Then match the first author's first document with the second author's random text, and the first author's second document with the third author's random text, a total of ùëõ ùëñ ùëö(ùëö -1) negative sample pairs can be generated. We can finally obtain 55,000 new sample data sets, such as (texta1, texta2, 1), (texta1, textb1, 0), etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Network Architecture</head><p>In the traditional way, most sentence vectors are formed by summing word vectors (word vectors are usually trained by methods such as word2vec). Obviously, such a method is relatively simple and crude, and the direct summing method does not utilize the interaction information between words. Instead, there are various models based on BERT. In the BERT <ref type="bibr" coords="2,361.82,559.27,12.80,9.94" target="#b3">[4]</ref> series of pre-training models, by stacking Transformer encoders, it is possible to capture the deep bidirectional word-to-word information in a sentence and use the token vector in the output layer to represent the semantic information of the entire sentence, such as BERT-flow <ref type="bibr" coords="2,324.60,597.19,12.80,9.94" target="#b4">[5]</ref> and BERT-whitening <ref type="bibr" coords="2,440.81,597.19,11.61,9.94" target="#b5">[6]</ref>, etc. Our work adopts a text-based contrastive learning method. The purpose of contrastive learning is to obtain a better representation vector of text by shortening the intra-class distance and increasing the inter-class distance. Simcse <ref type="bibr" coords="2,107.57,635.13,12.80,9.94" target="#b6">[7]</ref> proved the effectiveness of contrastive learning in the text paraphrase classification task. However, Since it does not use the smallest data enhancement method to construct positive sample pairs when calculating loss, but simply uses samples that are different from itself in a batch as negative sample pairs. At the same time, a larger batch size will lead to a decrease in SimCSE performance. For this, we use a new scheme to optimize the loss function cos.</p><p>Note that Œ© pos is the set of all positive sample pairs, and Œ© neg is the set of all negative sample pairs.</p><p>For any positive sample pair (i, j) ‚ààŒ© pos and negative sample pair (k, l) ‚ààŒ© neg , there are cos (ui, uj) &gt; cos (uk, ul), among them, ùë¢ ùëñ , ùë¢ ùëó , ùë¢ ùëò , ùë¢ ùëô represent their respective sentence vectors and the new loss is shown in formula ( <ref type="formula" coords="2,186.84,744.12,4.27,9.94">1</ref>) and ( <ref type="formula" coords="2,220.66,744.12,3.88,9.94" target="#formula_1">2</ref>), where Œª is the hyperparameter of the loss function. ùê∑(ùë¢ ùëò , ùë¢ ùëô , ùë¢ ùëñ , ùë¢ ùëó ) = ùúÜ(cos(ùë¢ ùëò , ùë¢ ùëô ) -cos(ùë¢ ùëñ , ùë¢ ùëó ))</p><p>(1)</p><formula xml:id="formula_1" coords="3,174.55,99.22,333.95,26.83">ùëôùëúùë†ùë† = log (1 + ‚àë ùëí ùê∑(ùë¢ ùëò ,ùë¢ ùëô ,ùë¢ ùëñ ,ùë¢ ùëó ) (i,j)‚ààŒ© pos ,(k,l)‚ààŒ© neg ) (<label>2</label></formula><formula xml:id="formula_2" coords="3,508.50,101.18,4.07,11.04">)</formula><p>Our structure is shown in Figure <ref type="figure" coords="3,233.21,140.83,4.14,9.94" target="#fig_0">1</ref>. Our work uses BERT-Large as our pre-training model, and the pre-processed sample pairs {ta1,...,tb1,...,tc1}, {ta2,...,tc2,...,td2} are respectively sent to BERT-large for encoding to obtain the vector representation of the text, then take the hidden layers of the first layer and the last layer for average pooling to obtain sentence features {fa1,...,fb1,...,fc1}, {fa2,...,fc2,...,fd2}, The features at the same position constitute a sample pair, and finally compare the cosine similarity of each positive sample pair with the cosine similarity of the negative sample pair by widening the distance between the positive and negative sample pairs, the positive sample pairs are closer to "more similar" and farther away from "less similar", and the negative sample pairs are closer to "less similar" and farther away from "more similar". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setting</head><p>In terms of dataset division, we preprocessed the train set and divided the train set and test set according to 7:3.</p><p>In this work, we choose BERT-Large, which has 1,024 hidden units, 24 layers and 340 million parameters. We set the batch size to 30, encoder maximum length to 512, learning rate to 2e-5, and random seed to 34. At the same time, we set the temperature coefficient Œª of formula (1) to 20. We use the AdamW optimizer to update our model weights at train phase. Finally, we used an A800 for 20epoch training.</p><p>The last layer of BERT-Large output does not select CLS, but average pools the hidden layers of the first and last layers into a new 1024-dimensional vector. In other words, the CLS embedding (of BERT-Large's output) is not used to represent the text segment pair of the input. Instead, all token embeddings except CLS and SEP are average pooled <ref type="bibr" coords="3,250.66,665.85,11.61,9.94" target="#b7">[8]</ref>. When we use BERT-Large as the encoder, we believe that the described method can obtain more comprehensive sentence features than adopting CLS embeddings.</p><p>During the prediction phase, we freeze the weights of the model to output the final result for the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>We obtain the organizers' two baselines for comparison, among which baseline-compressor23 is a baseline author authentication method based on text compression, which uses the partial match prediction (PPM) compression model of text1 to calculate the cross entropy of text2, and vice versa. The mean and absolute difference of the two cross-entropies is used to estimate a score in [0,1], representing the probability that the two texts were written by the same author. baseline-cngdist23 provides a simple TF-IDF weighted bag-of-character-ngrams model representation, optimized by rescaling after computing cosine similarity and projection operations so that they can act as probabilities.</p><p>In addition, we also obtained the system of najafi22, the best performer in all submissions last year, and ran our test set with reference to the parameters mentioned in the paper <ref type="bibr" coords="4,412.73,177.55,12.80,9.94" target="#b8">[9]</ref> to better evaluate our work.</p><p>To evaluate the performance of our proposed model, we used the evaluation platform provided by PAN, which includes the following metrics:</p><p>‚Ä¢ AUC: the conventional area under the curve score. ‚Ä¢ c@1: rewards systems that leave complicated problems unanswered <ref type="bibr" coords="4,410.57,244.05,16.80,9.94" target="#b9">[10]</ref>. ‚Ä¢ f_05_u: focus on deciding same-author cases correctly <ref type="bibr" coords="4,351.26,257.49,16.80,9.94" target="#b10">[11]</ref>. ‚Ä¢ F1: a harmonic way of combining the precision and recall of the model <ref type="bibr" coords="4,424.01,270.93,16.80,9.94" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>‚Ä¢</head><p>Brier: Brier Score evaluates the accuracy of probabilistic predictions <ref type="bibr" coords="4,413.21,284.37,16.80,9.94" target="#b12">[13]</ref>. We input the split train data and test data into our model for training and testing, and then we use the evaluation program to evaluate the results. As shown in Table <ref type="table" coords="4,364.13,309.60,4.07,9.94" target="#tab_1">2</ref>, our method performs best on auc, f_05_u, brier and overall. Ultimately, we submitted two runs, named irregular-strategist and uniform-reward. Between them, the irregular-strategist uses the 11th epoch weight of the model training (the overall performance is the best), and the uniform-reward is the 20th (the last epoch), their performance on pan23 authorship verification test is shown in Table <ref type="table" coords="4,227.25,499.00,4.14,9.94">3</ref>. It can be seen that our best run exceeded two baselines, and the overall reached 0.614. Since the uniform-reward used the last epoch and produce overfitting problems, it only surpassed najafi22 and obtained an overall score of 0.572.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>The final performance of our submission on pan23 authorization verification test Team Software AUC c@1 f_05_u F1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper mainly introduces our work results on authorship verification 2023. Our work uses a sample pair contrastive learning method based on the bert-large model and improves the loss calculation function to judge whether two texts are written by the same author. Our method is effectively verified by comparing with different method or models, such as the baseline on the divided dataset. In the follow-up work, we should incorporate more effective methods to improve the performance of the system, such as adding features in extracting the author's methods style text and compressing long text. Our method still has room for improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.02,433.92,451.24,11.04;3,72.02,447.36,358.16,11.04;3,72.00,266.86,451.00,152.10"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A contrastive learning model structure based on sample pairs, where a, b, c... represent different authors, 1,2...represent different articles belonging to the same author</figDesc><graphic coords="3,72.00,266.86,451.00,152.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.02,124.97,409.82,96.74"><head>Table 1</head><label>1</label><figDesc>Quantity and the average length of different text types</figDesc><table coords="2,101.33,153.35,380.51,68.36"><row><cell>Type</cell><cell>Quantity</cell><cell>Average length</cell></row><row><cell>interview</cell><cell>275</cell><cell>478</cell></row><row><cell>email</cell><cell>450</cell><cell>352</cell></row><row><cell>essay</cell><cell>93</cell><cell>388</cell></row><row><cell>Speech transcription</cell><cell>68</cell><cell>409</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,72.02,347.26,438.05,95.30"><head>Table 2</head><label>2</label><figDesc>Performance of different methods on the split test set</figDesc><table coords="4,78.74,376.32,431.33,66.24"><row><cell>Method</cell><cell>AUC</cell><cell>c@1</cell><cell>f_05_u</cell><cell>F1</cell><cell>Brier</cell><cell>overall</cell></row><row><cell>Ours</cell><cell>0.593</cell><cell>0.567</cell><cell>0.581</cell><cell>0.617</cell><cell>0.748</cell><cell>0.621</cell></row><row><cell>baseline-cngdist23</cell><cell>0.558</cell><cell>0.505</cell><cell>0.56</cell><cell>0.671</cell><cell>0.747</cell><cell>0.608</cell></row><row><cell>najafi22</cell><cell>0.465</cell><cell>0.742</cell><cell>0.495</cell><cell>0.662</cell><cell>0.55</cell><cell>0.583</cell></row><row><cell>baseline-compressor23</cell><cell>0.509</cell><cell>0.11</cell><cell>0.048</cell><cell>0.283</cell><cell>0.75</cell><cell>0.34</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgements</head><p>This work is supported by the <rs type="funder">National Social Science Foundation of China</rs> (No. <rs type="grantNumber">22BTQ101</rs>).</p></div>
<div><head n="7.">References</head></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Ten8WEb">
					<idno type="grant-number">22BTQ101</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,93.41,215.49,429.68,9.94;5,93.41,228.21,345.36,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,256.48,215.49,261.64,9.94">Overview of the Authorship Verification Task at PAN 2023</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,107.79,228.21,144.77,9.94">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="5,260.74,228.21,104.11,9.94">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,240.93,429.97,9.94;5,93.41,253.41,429.46,9.94;5,93.41,266.13,429.67,9.94;5,93.41,278.85,429.73,9.94;5,93.41,291.36,230.63,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,348.34,240.93,175.04,9.94;5,93.41,253.41,429.46,9.94;5,93.41,266.13,78.10,9.94">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-R√≠ Os</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,196.05,266.13,322.85,9.94;5,93.41,278.85,397.85,9.94">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="5,93.41,291.36,155.03,9.94">Lecture Notes in Computer Science</title>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multi-linguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="5,93.41,304.08,429.63,9.94;5,93.41,316.80,429.89,9.94;5,93.41,329.52,429.98,9.94;5,93.41,342.00,19.32,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,262.52,304.08,260.52,9.94;5,93.41,316.80,34.73,9.94">Continuous Integration for Reproducible Shared Tasks with TIRA.io</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fr√∂be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kolyada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,149.50,316.80,373.80,9.94;5,93.41,329.52,23.70,9.94">Advances in Information Retrieval. 45th European Conference on IR Research (ECIR 2023)</title>
		<title level="s" coord="5,124.35,329.52,152.65,9.94">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="236" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,354.72,429.82,9.94;5,93.41,367.44,414.74,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,365.23,354.72,157.99,9.94;5,93.41,367.44,176.84,9.94">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,277.65,367.44,153.98,9.94">Proceedings of NAACL-HLT 2019</title>
		<meeting>NAACL-HLT 2019</meeting>
		<imprint>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,379.94,429.82,9.94;5,93.41,392.66,429.93,9.94;5,93.41,405.38,146.57,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,207.31,379.94,294.14,9.94">On the sentence embeddings from pre-trained language models</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,93.41,392.66,429.93,9.94;5,93.41,405.38,41.46,9.94">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9119" to="9130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,418.10,429.81,9.94;5,93.41,430.58,222.91,9.94" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,227.32,418.10,295.91,9.94;5,93.41,430.58,35.30,9.94">Whitening sentence representations for better semantics and faster retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15316</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,93.41,443.30,429.78,9.94;5,93.41,456.02,429.95,9.94;5,93.41,468.52,266.61,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,211.14,443.30,266.83,9.94">Simcse: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,93.41,456.02,429.95,9.94;5,93.41,468.52,162.00,9.94">Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="6894" to="6910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,481.24,429.72,9.94;5,93.41,493.96,57.20,9.94" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,233.70,481.24,284.59,9.94">Authorship verification based on fully interacted text segments</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,506.44,429.92,9.94;5,93.41,519.16,197.03,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,185.03,506.44,338.30,9.94;5,93.41,519.16,33.99,9.94">Text-to-text transformer in authorship verification via stylistic and semantical analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,148.81,519.16,108.13,9.94">Proceedings of the CLEF</title>
		<meeting>the CLEF</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,531.88,316.26,9.94" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pe√±as</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<title level="m" coord="5,193.17,531.88,181.69,9.94">A simple measure to assess non-response</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,544.63,429.87,9.94;5,93.41,557.11,429.41,9.94;5,93.41,569.83,429.46,9.94;5,93.41,582.55,85.34,9.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,323.13,544.63,179.65,9.94">Generalizing unmasking for short texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,93.41,557.11,429.41,9.94;5,93.41,569.83,262.82,9.94">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="5,93.41,595.03,429.73,9.94;5,93.41,607.75,232.03,9.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,286.92,595.03,179.11,9.94">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,474.01,595.03,49.13,9.94;5,93.41,607.75,130.76,9.94">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,93.41,620.47,429.17,9.94;5,93.41,632.97,65.16,9.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,151.90,620.47,254.95,9.94">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,414.08,620.47,108.50,9.94">Monthly weather review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
