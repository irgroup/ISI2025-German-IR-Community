<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,85.05,300.79,15.39">Trigger Detection in Social Media Text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,114.37,59.15,10.68"><forename type="first">Asha</forename><surname>Hegde</surname></persName>
							<email>hegdekasha@gmail.com</email>
						</author>
						<author>
							<persName coords="1,160.69,114.37,136.80,10.68"><forename type="first">Fazlourrahman</forename><surname>Balouchzahi</surname></persName>
							<email>fbalouchzahi2021@cic.ipn.mx</email>
						</author>
						<author>
							<persName coords="1,89.29,128.32,108.35,10.68"><forename type="first">Hosahalli</forename><surname>Lakshmaiah</surname></persName>
						</author>
						<title level="a" type="main" coord="1,88.78,85.05,300.79,15.39">Trigger Detection in Social Media Text</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">20E33BFEB8BE4C7589640990A58EB965</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Trigger detection</term>
					<term>Social media text</term>
					<term>Pretrained word vectors</term>
					<term>Long Short Term Memory</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Trigger detection in social media content refers to the process of identifying and flagging content that may potentially trigger negative emotions or psychological responses in individuals. The study contributes to the Trigger Detection shared task at PAN@CLEF 2023, which aims to automatically assign violence trigger warnings to narratives. Using pretrained Global Vectors for Word Representation (GloVe) embeddings to train the Long Short Term Memory (LSTM) model, the proposed models achieved macro F1 scores of 0.57 and 0.048 on the Validation and Test sets respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Social media has become an integral part of our daily lives, allowing us to connect to others, share information with others, and to engage in online communities. Moreover, as a rich source of user-generated content, social media presents a vast amount of textual data that can be leveraged through text processing techniques to gain insights, understand users' behaviors, and enhance user experiences <ref type="bibr" coords="1,208.32,424.58,11.58,9.74" target="#b0">[1]</ref>. However, the content such as folk tales, fairy tales, children's and youth fiction and so on, which often contain violence and cruelty <ref type="bibr" coords="1,413.18,438.13,11.58,9.74" target="#b1">[2]</ref>, shared on social media platforms can sometimes be disturbing or triggering for some individuals. Such situation could be avoided by generating warnings which alarm the individuals with prior knowledge of sensitive topics that could evoke emotional or psychological distress, allowing them to make an informed decision about whether to engage with such content or not. Such warnings are called as trigger warnings and these warnings which appeared for discussion way back in the early 2000's in online communities (Tumblr and Live-Journal) stressed the need for such warnings <ref type="bibr" coords="1,89.29,532.97,11.43,9.74" target="#b2">[3]</ref>.</p><p>Trigger warnings are brief notices that are used to alert readers about potentially distressing or triggering content that may be present in the textual content such as articles, books, or online posts. By highlighting potentially distressing content, trigger warnings allow readers, especially those who have been through trauma, mental health challenges, or other sensitivities, to make informed decisions about what they consume to protect their well-being and emotional safety <ref type="bibr" coords="2,89.29,115.19,11.42,9.74" target="#b3">[4]</ref>. The purpose of trigger warnings is to create more inclusive and considerate environment, promoting individual autonomy and reducing the risk of distress or discomfort for individuals who may encounter triggering content unexpectedly. However, it is important to note that the use of trigger warnings is a subject of ongoing debate and opinions on their effectiveness and implementation may vary <ref type="bibr" coords="2,207.59,169.38,11.36,9.74" target="#b1">[2,</ref><ref type="bibr" coords="2,221.67,169.38,7.57,9.74" target="#b4">5]</ref>.</p><p>The analysis and detection of trigger warnings in Natural Language Processing (NLP) is a relatively underexplored area despite its importance. To address this gap, "Trigger Detection" shared task<ref type="foot" coords="2,139.19,207.35,4.06,7.79" target="#foot_0">1</ref> in PAN@CLEF 2023 invites researchers to develop models to automatically assign violence trigger warnings to the given comments/posts. The task recognized the potential impact of violent content on individuals and sought to explore the feasibility of NLP techniques in identifying and flagging such triggers. This initiative highlights the growing recognition for automated methods to assist in the identification and labeling of potentially disturbing and triggering content. The outcomes of this task have the potential to inform future research and development in NLP applications related to trigger warnings and content moderation. To address the challenges of the trigger detection, in this paper, we describe Long Short Term Memory (LSTM) model utilizing Global Vectors for Word Representation (GloVe) pretrained embeddings to represent the text data.</p><p>The rest of the paper is arranged as follows: a review of related work is included in Section 2, and the methodology is discussed in Section 3. Experiments and results are described in Section 4 followed by concluding the paper with future work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The rapid growth of social media platforms has resulted in an increase in the volume of violent, offensive, and hate speech content being shared. This has created a pressing need for tools and models that can efficiently detect and address such unwanted content. Early detection of such content is crucial for maintaining the health and integrity of social media platforms, ensuring user safety, and fostering positive online communities. The development and deployment of robust detection systems can help mitigate the negative impact of harmful content, allowing platforms to take appropriate actions and create a healthier social media environment. Few of the relevant works which have discussed by the researchers to identify unhealthy content and trigger warnings in social media text are described below: Sahoo et al. <ref type="bibr" coords="2,143.19,553.19,12.84,9.74" target="#b5">[6]</ref> discussed multilingual event and argument trigger detection and classification problem under the sequence labeling framework. They collected and annotated disaster related news data crawled from the online news portal in different low-resource Indian languages (Hindi, Bengali, and multilingual) for their experiments. The authors trained LSTM models considering word embeddings from FastText pretrained word vectors as features and their models obtained F1 scores of 0.42, 0.55, and 0.61 for Hindi, Bengali and multilingual texts respectively. Wiegmann et al. <ref type="bibr" coords="2,114.48,634.49,12.84,9.74" target="#b6">[7]</ref> created the Webis Trigger Warning Corpus 2022 with 41 million fan-fiction works data categorised into 36 different warning tags and the authors considered this problem as multi-label classification task. The authors proposed four classification models (Support Vector Machine (SVM), Extreme Gradient Boost (XGBoost), Robustly Optimized Bidirectional Encoder Representations from Transformers (Roberta), and Long Forms (LF)) to benchmark their dataset and achieved a maximum F1 score of 0.47 for SVM model. Hegde and Shashirekha <ref type="bibr" coords="3,454.13,128.74,12.84,9.74" target="#b7">[8]</ref> describe the learning models submitted to "Sentiment Analysis and Homophobia Detection of YouTube Comments in Code-Mixed Dravidian Languages" shared task at Forum for Information Retrieval Evaluation (FIRE) 2022. Using preprocessing of converting emojis to text and removal of digits and stopwords, these models make use of Dynamic Meta Embedding (DME) to train LSTM model to perform Sentiment Analysis (SA) and detect Homopobic/Transphobic content in code-mixed Dravidian languages viz. Kannada, Malayalam, and Tamil. These models obtained 6 th , 4 th , and 9 th ranks for Tamil, Malayalam, and Kannada respectively in Task A and 1 st , 4 th , 1 st , and 5 th ranks for Tamil, English, Tamil-English, and Malayalam texts respectively in Task B.</p><p>Code-Mixing Offensive Language Identification (COOLI)-Ensemble and COOLI-Keras models are developed by Balouchzahi et al. <ref type="bibr" coords="3,250.08,264.23,12.84,9.74" target="#b8">[9]</ref> to identify offensive language in Dravidian languages at "Offensive Languages in Dravidian Languages 2021" shared task. Using term frequency of character sequences and words they trained ensembled Machine Learning (ML) classifiers (Logistic Regession (LR), eXtreme Gradient Boosting (XGB), and Multi Layer Perceptron) and Keras sequential model. COOLI-Ensemble model outperformed the other model securing 1 st , 6 th , and 4 th ranks for code-mixed Malayalam-English, Tamil-English, and Kannada texts respectively. Balouchzahi and Shashirekha <ref type="bibr" coords="3,220.58,345.52,17.91,9.74" target="#b9">[10]</ref> proposed three distinct models: i) ensemble of ML classifiers (RFC, LR, and Support Vector Classification (SVC)), ii) Transfer Learning (TL) classifier using Universal Language Model Fine-tuning (ULMFiT) model, and iii) ensemble of ML-TL models, to the HASOC 2020 shared task for identifying hate speech and offensive content in English, German and Hindi languages. The TL and ML-TL models exhibited macro F1 scores of 0.2517 and 0.4979 for English securing 5 th and 21 st ranks in Subtask A and Subtask B respectively. The ensembled ML classifier exhibited macro F1 score of 0.5044 for German securing 11 th rank in Subtask A and ML-TL model for Hindi language exhibited macro F1 score of 0.5182 securing 8 th rank in Subtask B.</p><p>Wolska et al. <ref type="bibr" coords="3,163.05,467.47,12.84,9.74" target="#b1">[2]</ref> created a labelled corpus for trigger warning assignment by extracting narrative works hosted on Archive of Our Own (AO3) from a well known fan-fiction site. The authors focus on assigning a most frequent type of trigger warning i.e., violence and carried out a binary classification task at document-level. Further, they categorized both the corpora into four categories: small easy, small difficult, large easy, and large difficult based on the size and the complexity of the corpora. In their study, the authors utilized SVM model trained on Term Frequency-Inverse Document Frequency (TF-IDF) features of word uni-grams and bi-grams, as well as Bidirectional Encoder Representations from Transformers (BERT) models, to detect trigger warnings. They found that the SVM model outperformed the BERT model, achieving F1 scores of 0.798, 0.676, 0.780, and 0.686 for small easy, small difficult, large easy, and large difficult corpora respectively, indicating its superior performance in trigger warning detection across different dataset sizes and difficulty levels.</p><p>Trigger detection in social media text is rarely explored. The evolving nature of the user generated text on social media platforms, trigger content, and the need for nuanced understanding of context present ongoing challenges. Continued research and innovation in this area are essential to enhance the effectiveness and accuracy of detection systems, enabling social media platforms to stay ahead of evolving threats and ensure the well-being of their users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>The methodology employed in this study is visualized in Figure <ref type="figure" coords="4,371.46,146.66,5.01,9.74" target="#fig_0">1</ref> and the steps involved in the methodology are briefly described below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preprocessing</head><p>To prepare the textual data for analysis, various preprocessing functions (stripping HTML tags, removing accented characters, expanding contractions, lemmatizing, stemming, removing special characters and digits, converting text to lowercase, and removing stopwords) are used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Text Representation</head><p>GloVe<ref type="foot" coords="4,115.14,555.53,4.06,7.79" target="#foot_1">2</ref> embeddings are a type of word representation model used in NLP <ref type="bibr" coords="4,412.30,558.20,16.10,9.74" target="#b10">[11]</ref>. These are dense vector representations that capture semantic and syntactic information about words based on their distributional properties in a given corpus. GloVe embeddings are available with 25, 50, 100, 200, and 300 dimensions and this work utilizes GloVe embeddings with dimension 100. While GloVe embeddings are effective in mapping a large number of words present in the training set, there is still a possibility of encountering Out-Of-Vocabulary (OOV) words that are not included in the mapping. The proposed model is trained using the GloVe features and OOV words are handled with '0' vectors of size 100. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model construction</head><p>LSTM is a type of Recurrent Neural Network (RNN) architecture that has achieved remarkable success in various NLP tasks. Its ability to effectively capture and model sequential dependencies makes it well-suited for applications such as language modeling, sentiment analysis <ref type="bibr" coords="5,451.54,235.46,11.28,9.74" target="#b7">[8]</ref>, machine translation <ref type="bibr" coords="5,140.27,249.01,16.24,9.74" target="#b11">[12]</ref>, and named entity recognition <ref type="bibr" coords="5,297.91,249.01,16.24,9.74" target="#b12">[13]</ref>, among others. LSTM's capacity to handle long-term dependencies and its ability to retain and forget information over extended sequences have made it a popular choice in the NLP community.</p><p>The proposed LSTM model that aims to detect trigger content in social media text utilizes the Tokenizer<ref type="foot" coords="5,149.09,300.53,4.06,7.79" target="#foot_2">3</ref> class from the Keras library to tokenize the text data. In order to ensure uniform input dimensions to train the classification model as per the requirement of the model, the tokenized sequences are padded or truncated to a fixed length of 5,000. The proposed LSTM model is initialized by defining an input layer that expects the maximum length of the input sequences. Further, an embedding layer using the Embedding function that maps the input sequences to dense vector representations is created. An LSTM layer containing 128 hidden units is constructed and is applied to the embedding_layer input. Eventually, the final dense layer is created with 32 units (as the task contains 32 labels) and a sigmoid activation function to make the target prediction. It takes the output of the LSTM layer as input and performs non-linear transformations on it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>The organizers of "Trigger Detection" task provided Train, Development, and Test sets and the statistics of the dataset is shown in Table <ref type="table" coords="5,294.19,497.33,3.80,9.74" target="#tab_0">1</ref>. This dataset exhibits a long-tailed frequency distribution indicating that there are few labels that occur frequently, while the majority of labels are increasingly rare. This can pose challenges for training the learning models, as they struggle to accurately learn from the infrequent labels due to their limited representation in the dataset. Glimpse of the label distribution in the dataset is shown in Figure <ref type="figure" coords="5,421.26,551.52,3.74,9.74" target="#fig_1">2</ref>.</p><p>The proposed model is trained for 10 epochs with a batch size of 128 to minimize the binary cross entropy loss function and is evaluated on the Test set provided by the shared task organizers. Performances of the models submitted by all the participants of the shared task are ranked based on macro F1 score. The proposed model is placed 7 th in the task with macro F1 scores of 0.57 and 0.048 on Validation and Test sets respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper describes the model submitted to "Trigger Detection" shared task in PAN@CLEF 2023 to detect trigger content in social media text. Utilizing LSTM model trained with GloVe embeddings, the proposed model achieved macro F1 scores of 0.57 and 0.048 on the Validation and Test sets respectively, indicating its effectiveness in detecting and classifying triggering content. Various feature extraction techniques will be explored further to enhance the performance of ML models to identify the triggering content.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,491.55,183.76,8.91;4,122.74,258.47,349.80,220.55"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Framework of the proposed model</figDesc><graphic coords="4,122.74,258.47,349.80,220.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,367.44,250.38,8.91;6,89.29,84.19,424.22,270.72"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Classwise distribution of the labels in the Train set</figDesc><graphic coords="6,89.29,84.19,424.22,270.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,90.67,282.39,71.77"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="5,89.29,102.62,282.10,59.82"><row><cell>Dataset statistics</cell><cell></cell></row><row><cell>Dataset</cell><cell># of comments</cell></row><row><cell>Train set</cell><cell>3,07,102</cell></row><row><cell>Development set</cell><cell>17,104</cell></row><row><cell>Test set</cell><cell>17,040</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.46,671.96,276.08,8.01"><p>https://pan.webis.de/clef23/pan23-web/trigger-detection.html#related-work</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,92.46,671.96,137.28,8.01"><p>https://github.com/stanfordnlp/GloVe</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,92.46,671.90,308.46,8.01"><p>https://www.tensorflow.org/api_docs/python/tf/keras/ preprocessing/text/Tokenizer</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,556.75,393.31,9.74;6,112.66,570.30,393.32,9.74;6,112.66,583.85,149.50,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,354.89,556.75,151.08,9.74;6,112.66,570.30,308.96,9.74">What Goes on Inside Rumour and Non-rumour Tweets and their Reactions: A Psycholinguistic Analyses</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,445.31,570.30,60.67,9.74;6,112.66,583.85,73.19,9.74">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="page">107345</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,597.40,395.16,9.74;6,112.66,610.95,366.94,9.74" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Borchardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.04409</idno>
		<title level="m" coord="6,376.98,597.40,130.84,9.74;6,112.66,610.95,173.76,9.74">Trigger Warnings: Bootstrapping a Violence Detector for FanFiction</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,112.66,624.50,275.26,9.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,162.46,624.50,194.11,9.74">Trigger Warnings: History, Theory, Context</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Knox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,638.05,394.61,9.74;6,112.66,651.60,394.53,9.74;7,112.66,88.09,393.62,9.74;7,112.66,101.64,145.96,9.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,348.26,638.05,159.01,9.74;6,112.66,651.60,389.48,9.74">MUCS@ Text-LT-EDI@ ACL 2022: Detecting Sign of Depression from Social Media Text using Supervised Learning Approach</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E</forename><surname>Dashti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,127.64,88.09,378.64,9.74;7,112.66,101.64,58.31,9.74">Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion</title>
		<meeting>the Second Workshop on Language Technology for Equality, Diversity and Inclusion</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="312" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,115.19,393.32,9.74;7,112.66,128.74,393.33,9.74;7,112.66,142.29,250.73,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,316.10,115.19,189.88,9.74;7,112.66,128.74,226.54,9.74">Ensemble based machine learning models for hate speech and offensive content identification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Anusha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,362.37,128.74,143.62,9.74;7,112.66,142.29,149.97,9.74">Forum for Information Retrieval Evaluation (Working Notes)(FIRE)</title>
		<imprint>
			<publisher>CEUR-WS. org</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,155.84,393.32,9.74;7,112.33,169.38,393.66,9.74;7,112.66,182.93,230.12,9.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,340.04,155.84,165.93,9.74;7,112.33,169.38,156.08,9.74">A Multi-task Model for Multilingual Trigger Detection and Classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,291.08,169.38,214.91,9.74;7,112.66,182.93,142.25,9.74">Proceedings of the 16th International Conference on Natural Language Processing</title>
		<meeting>the 16th International Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,196.48,393.54,9.74;7,112.14,210.03,395.04,9.74;7,112.66,223.58,39.94,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,472.37,196.48,33.83,9.74;7,112.14,210.03,316.67,9.74">Trigger Warning Assignment as a Multi-Label Document Classification Problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Borchardt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,452.67,210.03,24.36,9.74">Genre</title>
		<imprint>
			<biblScope unit="page" from="90" to="95" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,237.13,393.32,9.74;7,112.66,250.68,394.52,9.74;7,112.66,264.23,394.52,9.74;7,112.66,277.78,22.69,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,238.45,237.13,267.53,9.74;7,112.66,250.68,389.61,9.74">Leveraging Dynamic Meta Embedding for Sentiment Analysis and Detection of Homophobic/Transphobic Content in Code-mixed Dravidian Languages</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,128.05,264.23,302.28,9.74">Forum for Information Retrieval Evaluation (Working Notes)(FIRE)</title>
		<imprint>
			<publisher>CEUR-WS. org</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,291.33,394.62,9.74;7,112.66,304.88,393.32,9.74;7,112.14,318.43,395.53,9.74;7,112.66,331.98,38.81,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,321.87,291.33,185.40,9.74;7,112.66,304.88,250.71,9.74">MUCS@ DravidianLangTech-EACL2021: COOLI-code-mixing Offensive Language Identification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Balouchzahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Aparna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,394.66,304.88,111.32,9.74;7,112.14,318.43,345.43,9.74">Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</title>
		<meeting>the First Workshop on Speech and Language Technologies for Dravidian Languages</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="323" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,345.52,393.32,9.74;7,112.66,359.07,367.23,9.74" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,265.03,345.52,240.96,9.74;7,112.66,359.07,160.76,9.74">LAs for HASOC-Learning Approaches for Hate Speech and Offensive Content Identification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Balouchzahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>FIRE</publisher>
			<biblScope unit="page" from="145" to="151" />
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="7,112.66,372.62,393.32,9.74;7,112.30,386.17,242.99,9.74" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,296.39,372.62,209.59,9.74;7,112.30,386.17,54.74,9.74">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,399.72,395.16,9.74;7,112.39,413.27,393.59,9.74;7,112.14,426.82,393.85,9.74;7,112.66,440.37,219.24,9.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,294.63,399.72,213.19,9.74;7,112.39,413.27,261.50,9.74">MUCS@mixwmt-Machine Translation for Dravidian Languages using Stacked Long Short Term Memory</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gashaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,398.91,413.27,107.06,9.74;7,112.14,426.82,393.85,9.74;7,112.66,440.37,131.70,9.74">Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages, Association for Computational Linguistics</title>
		<meeting>the First Workshop on Speech and Language Technologies for Dravidian Languages, Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,453.92,393.60,9.74;7,112.66,467.47,339.00,9.74" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,373.72,453.92,132.54,9.74;7,112.66,467.47,145.96,9.74">Improving Multi-word Entity Recognition for Biomedical Texts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Nayel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Shashirekha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05691</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
