<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,413.82,15.42;1,89.29,106.66,70.69,15.43;1,89.29,129.00,196.50,11.96">Profiling Cryptocurrency Influencers using Few-shot Learning Notebook for the PAN Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,106.34,11.96"><forename type="first">Hamna</forename><surname>Muslihuddeen</surname></persName>
							<email>hamnamuslihuddeen.201it221@nitk.edu.</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<postCode>575025</postCode>
									<settlement>Surathkal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.24,154.90,104.66,11.96"><forename type="first">Pallapothula</forename><surname>Sathvika</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<postCode>575025</postCode>
									<settlement>Surathkal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.51,154.90,73.44,11.96"><forename type="first">Shalaka</forename><surname>Sankar</surname></persName>
							<email>shalakasankar.201it158@nitk.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<postCode>575025</postCode>
									<settlement>Surathkal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.55,154.90,69.68,11.96"><forename type="first">Shreya</forename><surname>Ostwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<postCode>575025</postCode>
									<settlement>Surathkal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,88.87,168.85,69.09,11.96"><forename type="first">Anand</forename><surname>Kumar</surname></persName>
							<email>m1_anandkumar@nitk.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<postCode>575025</postCode>
									<settlement>Surathkal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,413.82,15.42;1,89.29,106.66,70.69,15.43;1,89.29,129.00,196.50,11.96">Profiling Cryptocurrency Influencers using Few-shot Learning Notebook for the PAN Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">5ADBD97F460A56178A51453D1E78FBFB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>low-resource</term>
					<term>cryptocurrency</term>
					<term>few-shot</term>
					<term>zero-shot</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research provides a novel method for identifying cryptocurrency influencers on social media in a low-resource environment. The analysis focuses on English-language Twitter messages and divides influencers into impact categories ranging from minimal to massive. With a maximum of 10 English tweets per user, the dataset consists of 32 people per category. By comparing the suggested approach to two baseline models-Usercharacter Logistic Regression and t5-large (bi-encoders) using zero-shot and label tuning few-shot methods-the proposed system is evaluated using the Macro F1 measure. The findings show that the suggested approach operates effectively in low-resource environments and has the potential to be used to further in-depth studies of influencer profiling.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Cryptography is used by cryptocurrencies, which are digital or virtual tokens, to safeguard their transactions and limit the generation of new tokens. They operate independently of a central authority or middleman, such as a bank or the government, because they are decentralised. In addition to being saved in digital wallets, cryptocurrency is frequently exchanged on online exchanges. They have no government or physical backing, and the market forces of supply and demand determine their price.</p><p>The rapidly rising ubiquity and dissemination of online information such as social media text and news improve user accessibility towards financial markets, however, modeling these vast streams of irregular, temporal data poses a challenge.(Ramit Sawhney, Shivam Agarwal, Megh Thakkar, Arnav Wadhwa, and Rajiv Ratn Shah. 2021.) Here, the challenge of effectively modeling large volumes of online information, such as social media text and news, which have irregular patterns and evolve over time. The authors introduce a novel model, HTLSTM, that uses hyperbolic geometry to better capture the unique characteristics of online information streams, especially in the context of finance.With cryptocurrencies becoming more and more popular, it is very common to find people or organisations with sizable online followings who are able to influence the thoughts and behaviours of their followers with regard to cryptocurrencies. These people or organisations are known as cryptocurrency influencers. These influencers may include traders, analysts, investors, journalists, or cryptocurrency specialists. Since their followers' buying and selling decisions are influenced by their thoughts and suggestions, crypto influencers can have a big impact on the acceptance and value of cryptocurrencies. Many cryptocurrency influencers express their views, analyses, and opinions about various cryptocurrencies and blockchain-related projects on social media sites like Twitter, YouTube, and Instagram.</p><p>While some influencers are renowned for their precise market predictions and analyses, others are renowned for their outspoken and divisive viewpoints. To advertise their goods and services, some influencers also work with cryptocurrency initiatives and businesses. But it's vital to remember that not all cryptocurrency influencers are reliable or trustworthy, and some can even participate in dishonest or deceptive behaviour. As a result, it's crucial for people to conduct their own research and use caution when acting on cryptocurrency influencers' advise. But since not everyone can afford this, a solution that can profile crypto influencers in real-time in a matter of milliseconds must be developed. This needs processing as little data as possible in order to to get fast and accurate results.</p><p>Making use of the Few Short Learning method is one strategy for solving this issue. A form of machine learning called few-shot learning entails teaching a model to recognise new classes of data with a very small sample size. When discussing cryptocurrency influencers, this refers to training a model to recognise influencers based on a sparse sample of their tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Literature Survey</head><p>In <ref type="bibr" coords="2,97.26,497.87,11.95,10.91" target="#b0">[1]</ref>, it's about author profiling, which is the process of identifying characteristics of an author based on their writing, such as gender, age, native language, personality type, etc. It specifically focuses on the gender and age aspects of author profiling in social media, using everyday language to reflect basic social and personality processes. Author profiling involves applying computational tools and linguistic analysis to analyse written materials in order to predict and identify features about the authors, such as their demographics, personality traits, and behaviour. It can be used in areas like marketing, social media analysis, and forensic linguistics.</p><p>In <ref type="bibr" coords="2,101.09,633.36,11.34,10.91" target="#b1">[2]</ref>, discuss few-shot and zero-shot learning in the context of author profiling. They explain that few-shot learning aims to train classifiers with little training data, while zero-shot learning does not use any labelled data. They also describe how the entailment approach can be used for zero-shot text classification, which relies on neural language models such as BERT trained on large NLI datasets. The authors assess their framework using two tests that determine an author's gender and age based on their written work. They contrast their strategy with a number of industry standards and show that their framework produces competitive performance, especially in situations where only a small amount of labeled data is available.</p><p>Overall, the study makes a significant contribution to the field of author profiling and emphasises how zero-shot and few-shot learning have great potential for this task. By utilising these methods, models for author profiling can be created more accurately and more effectively while overcoming the problem of scarce labelled data.</p><p>In <ref type="bibr" coords="3,102.12,222.46,11.66,10.91" target="#b2">[3]</ref>, An approach for active few-shot learning is suggested by the authors. The authors suggest a technique known as FASL (Fast Active Selection for Labelling), which combines fewshot learning and active learning. In order to enhance the performance of the few-shot learning model, FASL seeks to choose the most instructive examples for labelling. The process entails selecting the most instructive examples for labelling from a huge pool of unlabeled examples by first training a few-shot learning model on a limited set of labelled examples. The few-shot learning model is then retrained using the labelled examples that were chosen earlier.On a number of few-shot learning datasets, the authors assess their approach and compare it to other cutting-edge techniques. They show that FASL performs competitively on some datasets and outperforms other approaches on others. They also offer a thorough examination of the influence of various selection procedures as well as the efficacy of the active selection approach.</p><p>In <ref type="bibr" coords="3,101.03,385.05,11.27,10.91" target="#b3">[4]</ref>, adopts machine learning model based on text analysis, using tf-idf for feature extraction of data, and then uses logistic regression model for data training.The idea of linear regression is to fit a straight line through historical data and use this line to predict new data. The objective of logistic regression is to calculate the likelihood that an observation belongs to a given class. A logistic (sigmoid) function is used in the logistic regression model to convert the linear regression equation and limit the output to a range between 0 and 1. This enables us to translate the result into a probability.</p><p>In <ref type="bibr" coords="3,97.91,493.44,12.93,10.91" target="#b4">[5]</ref> ,the application of active learning with random forest, a cutting-edge multi-class classifier. The suggested strategy uses an effective active learning algorithm to maximise the combined entropy of a group of samples while minimising information redundancy. The technique performs better than the basic batch mode of active learning when used to adaptively classify undersea mines.</p><p>In <ref type="bibr" coords="3,97.35,574.74,12.09,10.91" target="#b5">[6]</ref>, it mentions that adequate hyper-parameter tuning is crucial for the effective use of SVM classifiers. For this issue, a number of techniques have been employed, including grid search, random search, estimation of distribution algorithms (EDAs), and bio-inspired metaheuristics . The conclusion is backed by experimental findings, and according to the set standards, EDAs are the best techniques for optimising SVM classifier hyperparameter settings. It is crucial to keep in mind that the effectiveness of the remaining algorithms depends on the precise values of the user-defined parameters that are used to control them.</p><p>In <ref type="bibr" coords="4,98.58,86.97,13.94,10.91" target="#b6">[7]</ref>,The term "term frequency inverse document frequency" (TF-IDF) is used to examine the applicability of key terms to corpus documents. The application of the algorithm to various numbers of documents is the main topic of the study. To start, the actions that should be taken for TF-IDF implementation are explained along with their functioning principle. The results are then provided, and the strengths and shortcomings of the TD-IDF algorithm are contrasted in order to verify the conclusions drawn from using the algorithm.</p><p>In <ref type="bibr" coords="4,97.26,181.81,11.95,10.91" target="#b7">[8]</ref>, examines the use of Word2Vec to identify implicit linkages in multi-participant Computer-Supported Collaborative Learning chat sessions. Word2Vec is a potent and one of the most recent Natural Language Processing semantic models used to determine text cohesion and document similarity. The intensity of the semantic ties between two utterances is measured by cohesion scores in this study; the higher the score, the more similar the two utterances are to one another.With Word2Vec, the context before and after each word occurrence in the training dataset is used to compute each embedding. As a result, words that frequently appear together in comparable contexts are represented closer together in the embedded space, while words that do not frequently occur together in similar situations are represented in various areas of this space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Statement</head><p>It is important to recognise that not all cryptocurrency influencers are trustworthy or honest, and that some may engage in misleading or manipulative behaviour. People should therefore do their homework and exercise caution while adopting the advice of these influencers.</p><p>To solve this problem, we aim to develop a low-resource model that can categorise cryptocurrency influencers on social media into five different groups based on their level of influence: null, nano, micro, macro, and mega. Our concentration is on English-language Twitter messages, and our goal is to create a strong model that, using the Few Short Learning technique <ref type="bibr" coords="4,469.22,443.67,13.76,10.91" target="#b1">[2]</ref>, can precisely profile and categorise cryptocurrency influencers on social media. By doing this, we intend to give people a useful tool that will help them decide wisely when interacting with social media bitcoin influencers <ref type="bibr" coords="4,227.90,484.32,12.89,10.91" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>The project involves 2 major parts: data processing and developing the model. Under data processing we perform feature extraction to obtain maximum information possible from the limited dataset. Following feature extraction we proceed to develop the model based on few short learning which makes use of active learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>The dataset used in our few-shot learning task consists of two JSON files: train_text.json and train_truth.json. The train_text file contains 160 JSON objects, each of which contains the Twitter user ID and the corresponding user tweets. The number of tweets per user varies The dataset is relatively small, with only 32 users under each of the five class labels, resulting in a total of 160 entries. This presents a challenge for the few-shot learning task, as the model must learn to recognize and classify users based on a limited amount of training data. Therefore, it is important to carefully select and pre-process the data to ensure that the model can effectively learn and generalize from it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Data Pre-processing</head><p>Data cleaning and feature extraction are important steps in preparing the dataset for few-shot learning. In our approach, we perform the following steps to preprocess the data:</p><p>Combine tweets: To simplify the data and create a single input sequence for each user, we combine all the tweets of a particular user into a single sentence.</p><p>Remove punctuation: We remove all punctuation marks from the text, as they do not provide meaningful information for our task.</p><p>Convert emojis and emoticons: Emojis or emoticons are often used to communicate thoughts and can be perceived to be more effective than text in social media. Therefore we convert all emojis and emoticons into their corresponding text representations to get more information and to ensure consistency in the data.</p><p>Replace hyperlinks: Some tweets contain hyperlinks to other websites. For valid links, we replace the hyperlink with the data scraped from the website or the title of the website. For invalid links, we replace the hyperlink with a blank space.</p><p>Overall, these preprocessing steps help to standardize the data and remove irrelevant information, allowing the model to focus on the key features that are important for classifying cryptocurrency influencers. By cleaning and processing the data in this way, we can improve the model's performance and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Feature extraction</head><p>Feature extraction is a crucial step in data preprocessing that aims to reduce the dimensionality of raw data by selecting and transforming relevant features to improve the accuracy and efficiency of machine learning algorithms. In our task of profiling cryptocurrency influencers in social media, we adopt various feature extraction techniques to capture the most important characteristics of the dataset and enable effective analysis, modeling, and decision-making.</p><p>We first encode the preprocessed tweet of each Twitter user into a vector using TF-IDF <ref type="bibr" coords="6,478.99,288.78,11.20,10.91" target="#b6">[7]</ref>. In natural language processing, the TF-IDF (term frequency-inverse document frequency) sentence transformation approach is used to assess the significance of a given sentence within a corpus or document. It determines each word's relevance in a sentence by comparing its frequency in the sentence to its rarity across the entire document or corpus. By doing so, the original sentences can be changed into vector representations that reflect the semantic significance of the words included within them. This approach makes it simpler to assess how similar two sentences are.</p><p>In addition to TF-IDF encoding, we also extract various other features that are unique to our problem statement and help in improving the model's performance. We keep count of the number of tweets per user, the number of hyperlinks mentioned in the tweets, and the number of valid and invalid hyperlinks. We also count the number of cryptocurrency-related terms used in the text, which is a critical aspect of our task, given that we are profiling cryptocurrency influencers. Finally, we also include the word2vec <ref type="bibr" coords="6,308.32,451.37,12.58,10.91" target="#b7">[8]</ref> embedding of size 200 of the names of the most popular cryptocurrencies to capture the relationships and similarities between the various cryptocurrencies.</p><p>When we combine all the selected features, our feature matrix consists of 973 columns and 160 rows in this case, with each row, representing a unique Twitter user. In general the number of columns in the feature matrix will be equal to the sum of total number of words in the dataset and the additional columns we have added and the number of rows will be the total number of twitter users given in the dataset. This feature matrix serves as the input to our machine learning algorithm, which use it to train and make predictions on new and unseen data. By adopting a comprehensive feature extraction approach, we can capture the most critical and relevant information from the dataset, which helps us to understand better and analyze the dynamics of cryptocurrency influencers on social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Classification model using Few-Shot Learning</head><p>In order to execute few shot learning in our project, we employed active learning. Selecting the most informative samples from a dataset for expert annotation or for active learning by a machine learning algorithm is a key component of the active learning machine learning approach <ref type="bibr" coords="7,127.74,478.93,14.42,10.91" target="#b2">[3]</ref>. For labels on particular samples that are most likely to increase the model's accuracy, the algorithm actively asks the user or expert in active learning. There are several sampling techniques available to choose the most illuminating samples for training. Only a few of the strategies are effective at picking samples from a dataset this huge. As follows:</p><p>• Uncertainty Sampling: According to uncertainty sampling, retraining the model using the most uncertain data points would improve the model's accuracy. • Diversity Sampling: Using a diverse sample The representative test data are gathered using this technique from unsupervised learning. Predicted results for such samples are provided as training data to the algorithm.</p><p>In order to perform active learning, we used diversity sampling. K means clustering is the unsupervised learning method we used to choose the samples. We have divided the data into two parts, namely the initial training data and test data, to imitate the real-life scenario where the test data is unsupervised. On the first set of training data, the model is trained.Multinomial Logistic regression <ref type="bibr" coords="7,134.48,669.58,13.56,10.91" target="#b3">[4]</ref> is chosen as the base model .As there are 5 classes, the test data is divided into 5 1. Initial splitting of dataset into training and splitting.The desired splitting should contain more testing data. We have used 2 different approaches to split the data into testing and training sets. Firstly we used the conventional method of using 80%training data and 20% testing data. The second method involves finding the median of the number of tweets in each class of user and classifying the data such that users whose number of tweets is more than or equal to the median are classified into the training set and the rest are categorized to the test set. 2. Iterative clustering is performed on the testing data to collect the samples. The number of samples should at least be 15% of the data. 3. The collected samples are appended to the training data and are used to retrain the model 4. The remaining data is used to test the model.</p><p>Along with active learning, we also implemented transfer learning to compare and evaluate and choose the better model. To implement transfer learning, we have used logistic regression as both a pre-trained model and a learning model. Logistic regression is the most suitable classification model since it allows to extract coefficients for the learning model. First, we have pre-trained the logistic regression model with 12.5% of the dataset to extract the weights. The weights of the first layer are then set to that of the pre-trained model. The layer is frozen to fix those pre-defined weights. We then retrain the model with another 12.5% of the dataset. The remaining dataset is used for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Hyperparameters</head><p>The performance of active learning was compared with respect to three classifiers: Logistic Regression, Support Vector machine classifier <ref type="bibr" coords="8,293.28,587.12,11.70,10.91" target="#b5">[6]</ref>, and Random Forest classifier <ref type="bibr" coords="8,440.02,587.12,11.70,10.91" target="#b4">[5]</ref>. In Logistic Regression, the model has been initialized with the following parameters: a. "multiclass" which has been set to multinomial, and solver which has been set to 'lbfgs', which stands for Limitedmemory Broyden-Fletcher-Goldfarb-Shanno. This solver is most suitable for multiclass problems with small to medium-sized datasets. In the Random Forest classifier, the only hyperparameter used was "n-estimators" which was set to 40. The value for this hyperparameter was obtained by the trial-and-error method. The hyperparameters defined in The SVM classifier <ref type="bibr" coords="9,330.34,280.49,11.97,10.91" target="#b5">[6]</ref> are the kernel, degree, random state, and gamma. the kernel used here was "poly" due to the higher dimensionality and linear separability. The degree for the poly kernel was set to 5. The random seed for various random processes within an algorithm, including random initialization, shuffling of data, or random sampling is set to 0 to ensure that the algorithm's random processes produce the same results when the code is run again with the same random seed value. The gamma hyperparameter is set to 'auto', which means the value of gamma is automatically determined based on the training data. The 'auto' option calculates gamma as 1 / n-features, where n-features is the number of features in the input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>We evaluated the performance of our created model using a different test dataset. We compared the performance of our model with the accuracy and F1 Macro scores attained by conducting logistic regression, SVM, and Random Forest, each of which is a well-established machine learning approach for classification problems, in order to guarantee the validity of our results.</p><p>We were able to validate our method and evaluate its effectiveness in identifying cryptocurrency influencers on social media by comparing the accuracy of our model with that of the logistic regression, random forest, and SVM. Through this comparison, we were able to ensure that our model is reliable and robust and that it can correctly classify influencers into the five categories of null, nano, micro, macro, and mega. Refer TABLE <ref type="table" coords="9,371.64,555.90,5.07,10.91" target="#tab_2">2</ref> This evaluation procedure provides a quantitative assessment of the accuracy and effectiveness of our developed model and demonstrates its ability to perform well in a low-resource setting when compared to a well-established machine-learning algorithm. In addition to accuracy, we also utilized the F1 score as an evaluation metric for our developed model. The F1 score is a commonly used performance measure in classification tasks, which considers both precision and recall of the model's predictions.</p><p>The F1 scores obtained from our developed model as recorded in  performs logistic regression and other methods in a low-resource situation. This is a significant finding, as it indicates that our model is effective in profiling cryptocurrency influencers on social media using limited resources, and can be a valuable tool for researchers and individuals seeking to make informed decisions when engaging with influencers.</p><p>Along with comparing the models TABLE <ref type="table" coords="10,291.40,557.43,5.12,10.91" target="#tab_3">3</ref> depicts the accuracy obtained for the different types of test-train dataset split. Upon observing it we can say that the convention 40-60 split is a better approach to split the dataset rather than taking the median as the threshold for the split.</p><p>Overall, the use of the F1 score provides a more comprehensive and robust evaluation of our developed model's performance and further confirms its superiority over logistic regression in a low-resource setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In conclusion, the task of profiling cryptocurrency influencers in social media and categorizing related aspects of their influence is a challenging one, especially when working with lowresource settings. However, by focusing on English Twitter posts and making use of Few shot learning, it is possible to extract valuable insights and information about these influencers. It is important to continue developing and refining techniques for analyzing social media data in order to better understand the influence of cryptocurrency influencers and their impact on the wider industry. By doing so, we can gain a deeper understanding of the dynamics of the cryptocurrency world and make more informed decisions about its future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,202.45,152.25,8.93;5,89.29,128.27,416.68,61.62"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Train_text and Train_truth</figDesc><graphic coords="5,89.29,128.27,416.68,61.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,210.53,157.07,8.93;6,89.29,84.19,416.68,113.78"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dataset after preprocessing.</figDesc><graphic coords="6,89.29,84.19,416.68,113.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,89.29,429.28,238.77,8.93;7,89.29,84.19,416.69,332.53"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distribution of tweets under each class of users.</figDesc><graphic coords="7,89.29,84.19,416.69,332.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,89.29,170.55,133.99,8.93;8,89.29,84.19,416.71,73.79"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Working of the model.</figDesc><graphic coords="8,89.29,84.19,416.71,73.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,88.99,90.49,333.28,163.29"><head>Table 1</head><label>1</label><figDesc>Predicted Class Results</figDesc><table coords="9,172.44,119.83,249.83,133.95"><row><cell>Twitter_UserID</cell><cell cols="2">Class Probability</cell></row><row><cell cols="2">0037a672f0ed64b3231bac64853a278d Nano</cell><cell>0.453</cell></row><row><cell cols="2">03eaa72711143b521c073d9ac5745923 Nano</cell><cell>0.39</cell></row><row><cell cols="2">0409fe210a0edfe258d21e3404e1ce05 Micro</cell><cell>0.42</cell></row><row><cell cols="2">05ca545f2f700d0d5c916657251d010b Macro</cell><cell>0.53</cell></row><row><cell cols="2">062492818c984febba843b650a4a602e Micro</cell><cell>0.35</cell></row><row><cell>f8404b995e68fac31ac3f8318884a0a9</cell><cell>Micro</cell><cell>0.34</cell></row><row><cell>fa8d3942f7e1420a5a3d9d19b672f8f2</cell><cell>Nano</cell><cell>0.59</cell></row><row><cell>faed79f6d4a62e1c984a62d064f2c8d6</cell><cell>Mega</cell><cell>0.98</cell></row><row><cell>fb41227b22d727fbcff4fe780d849de6</cell><cell>Micro</cell><cell>0.49</cell></row><row><cell>fec182516cba4b665e2215094bbcc527</cell><cell>Nano</cell><cell>0.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,89.29,650.74,418.54,24.46"><head></head><label></label><figDesc>TABLE 2 can confidently conclude that our developed model of combining Logistic Regression with Active Learning out-</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,88.99,90.49,363.82,129.65"><head>Table 2</head><label>2</label><figDesc>Comparing Models</figDesc><table coords="10,142.46,122.05,310.35,98.08"><row><cell>Model</cell><cell cols="2">Accuracy F1 Macro Score</cell></row><row><cell>Random Forest</cell><cell>0.266</cell><cell>0.23</cell></row><row><cell>SVM</cell><cell>0.12</cell><cell>0.05</cell></row><row><cell>Logistic Regression</cell><cell>0.29</cell><cell>0.26</cell></row><row><cell>Random forest with Active Learning</cell><cell>0.29</cell><cell>0.24</cell></row><row><cell>SVM with Active Learning</cell><cell>0.14</cell><cell>0.08</cell></row><row><cell>Logistic Regression with Active learning</cell><cell>0.34</cell><cell>0.32</cell></row><row><cell>Logistic Regression with Transfer Learning</cell><cell>0.34</cell><cell>0.23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,88.99,242.39,356.20,69.87"><head>Table 3</head><label>3</label><figDesc>Evaluation Metrics For Dataset split in Logistic Regression with Active Learning Model</figDesc><table coords="10,168.15,273.96,258.98,38.30"><row><cell cols="4">Sno Dataset split Method Accuracy F1 Macro Score</cell></row><row><cell>1</cell><cell>80-20 method</cell><cell>0.34</cell><cell>0.32</cell></row><row><cell>2</cell><cell>Median Method</cell><cell>0.18</cell><cell>0.23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,88.99,334.52,341.19,144.35"><head>Table 4</head><label>4</label><figDesc>Evaluation Metrics of Logistic Regression with Active Learning</figDesc><table coords="10,164.48,366.09,265.70,112.79"><row><cell>Sno</cell><cell cols="4">Precision Recall F1 score Support</cell></row><row><cell>1</cell><cell>0.25</cell><cell>0.33</cell><cell>0.29</cell><cell>6</cell></row><row><cell>2</cell><cell>0.50</cell><cell>0.40</cell><cell>0.44</cell><cell>5</cell></row><row><cell>3</cell><cell>0.25</cell><cell>0.25</cell><cell>0.25</cell><cell>4</cell></row><row><cell>4</cell><cell>0.50</cell><cell>0.12</cell><cell>0.20</cell><cell>8</cell></row><row><cell>5</cell><cell>0.36</cell><cell>0.56</cell><cell>0.43</cell><cell>9</cell></row><row><cell>Accuracy</cell><cell></cell><cell></cell><cell>0.34</cell><cell>32</cell></row><row><cell>Macro Average</cell><cell>0.37</cell><cell>0.33</cell><cell>0.32</cell><cell>32</cell></row><row><cell>Weighted Average</cell><cell>0.38</cell><cell>0.34</cell><cell>0.33</cell><cell>32</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>First and foremost, we would like to express our sincere gratitude to CLEF for giving us the chance to take part in this prestigious competition. We deeply value their support in making it possible for us to demonstrate our abilities on this platform. We would also like to take this opportunity to thank our professor and guide <rs type="person">Dr Anand Kumar</rs> for their guidance, support, and encouragement throughout the entire process. Their mentorship and expertise were invaluable in helping us to shape the direction of our research and to bring our ideas to fruition.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,391.12,393.53,10.91;11,112.66,404.67,393.33,10.91;11,112.28,418.22,122.51,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,401.02,391.12,105.17,10.91;11,112.66,404.67,93.77,10.91">Overview of the Author Profiling Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Inches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,233.46,404.67,272.53,10.91;11,112.28,418.22,78.68,10.91">CLEF Conference on Multilingual and Multimodal Information Access Evaluation</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="352" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,431.77,393.33,10.91;11,112.66,445.32,394.52,10.91;11,112.66,458.87,20.29,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,188.44,445.32,225.60,10.91">Zero and Few-Shot Learning for Author Profiling In</title>
		<author>
			<persName coords=""><forename type="first">Mara</forename><surname>Chinea-Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gretel</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liz</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">La</forename><forename type="middle">Peña</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Franco-Salvador</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,421.04,445.32,23.42,10.91">NLDB</title>
		<imprint>
			<biblScope unit="page" from="333" to="344" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,472.42,393.33,10.91;11,112.66,485.97,262.22,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,476.67,472.42,29.32,10.91;11,112.66,485.97,175.35,10.91">Active Few-Shot Learning with FASL In: NLDB</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guillermo</forename><surname>Pérez-Torró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angelo</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="323" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,499.52,393.33,10.91;11,112.66,513.06,394.52,10.91;11,112.66,526.61,245.70,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,209.04,499.52,289.82,10.91">Application of Logistic Regression in WEB Vulnerability Scanning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/SNSP.2018.00097</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,135.78,513.06,366.98,10.91">International Conference on Sensor Networks and Signal Processing (SNSP), Xi&apos;an</title>
		<meeting><address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="486" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,540.16,393.33,10.91;11,112.66,553.71,394.52,10.91;11,112.66,567.26,241.54,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,329.25,540.16,176.74,10.91;11,112.66,553.71,60.81,10.91">Efficient batch-mode active learning of random forest</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yadegar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1109/SSP.2012.6319769</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,207.19,553.71,223.94,10.91">IEEE Statistical Signal Processing Workshop (SSP)</title>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="596" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,580.81,395.01,10.91;11,112.66,594.36,393.32,10.91;11,112.66,607.91,394.87,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,148.16,594.36,357.83,10.91;11,112.66,607.91,41.15,10.91">Optimal Hyper-Parameter Tuning of SVM Classifiers With Application to Medical Diagnosis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rojas-Domínguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Padierna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Puga-Soberanes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Fraire</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2017.2779794</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,174.87,607.91,51.47,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="7164" to="7176" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,621.46,393.33,10.91;11,112.66,635.01,395.01,10.91;11,112.41,648.56,105.06,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,298.94,621.46,207.05,10.91;11,112.66,635.01,150.95,10.91">Text Mining: Use of TF-IDF to Examine the Relevance of Words to Documents</title>
		<author>
			<persName coords=""><forename type="first">Shahzad</forename><surname>Qaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ramsha</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">181.10.5120/ijca2018917395</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,271.67,635.01,211.01,10.91">International Journal of Computer Applications</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,662.11,393.53,10.91;12,112.66,86.97,393.32,10.91;12,112.28,100.52,395.00,10.91;12,112.41,114.06,108.52,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,411.38,662.11,94.81,10.91;12,112.66,86.97,187.65,10.91">Unlocking the Power of Word2Vec for Identifying Implicit Links</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gutu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dascalu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruseti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rebedea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Trausan-Matu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICALT.2017.120</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,332.97,86.97,173.01,10.91;12,112.28,100.52,189.75,10.91">IEEE 17th International Conference on Advanced Learning Technologies (ICALT)</title>
		<meeting><address><addrLine>Timisoara, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="199" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,127.61,395.01,10.91;12,112.66,141.16,395.17,10.91;12,112.66,154.71,393.33,10.91;12,112.33,168.26,395.33,10.91;12,112.66,181.81,176.99,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,139.89,141.16,193.63,10.91">Hyperbolic Online Time Stream Modeling</title>
		<author>
			<persName coords=""><forename type="first">Ramit</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shivam</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Megh</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arnav</forename><surname>Wadhwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rajiv Ratn</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463119</idno>
		<ptr target="https://doi.org/10.1145/3404835.3463119" />
	</analytic>
	<monogr>
		<title level="m" coord="12,356.09,141.16,151.74,10.91;12,112.66,154.71,393.33,10.91;12,112.33,168.26,49.10,10.91">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;21)</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;21)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1682" to="1686" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
