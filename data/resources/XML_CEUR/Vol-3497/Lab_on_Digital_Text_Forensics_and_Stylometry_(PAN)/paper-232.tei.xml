<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,409.05,15.42;1,89.29,106.66,392.75,15.42;1,89.29,129.00,157.29,11.96">Profiling Cryptocurrency Influencers with Few-Shot Learning Using Data Augmentation and ELECTRA Notebook for PAN at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,154.90,58.76,11.96"><forename type="first">Marco</forename><surname>Siino</surname></persName>
							<email>marco.siino@unipa.it</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics and Telematics</orgName>
								<orgName type="laboratory">Cyber Intelligence Lab</orgName>
								<orgName type="institution">National Research Council</orgName>
								<address>
									<postCode>56127</postCode>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,165.98,154.90,84.11,11.96"><forename type="first">Maurizio</forename><surname>Tesconi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics and Telematics</orgName>
								<orgName type="laboratory">Cyber Intelligence Lab</orgName>
								<orgName type="institution">National Research Council</orgName>
								<address>
									<postCode>56127</postCode>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.08,154.90,78.83,11.96"><forename type="first">Ilenia</forename><surname>Tinnirello</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Palermo</orgName>
								<address>
									<postCode>90128</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,409.05,15.42;1,89.29,106.66,392.75,15.42;1,89.29,129.00,157.29,11.96">Profiling Cryptocurrency Influencers with Few-Shot Learning Using Data Augmentation and ELECTRA Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">6BCD63E8E658F42435A660C3D5AA345F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cryptocurrency influencers</term>
					<term>few-shot learning</term>
					<term>author profiling</term>
					<term>text classification</term>
					<term>Twitter</term>
					<term>data augmentation</term>
					<term>electra Conceptualization</term>
					<term>Formal analysis</term>
					<term>Investigation</term>
					<term>Methodology</term>
					<term>Resources</term>
					<term>Software</term>
					<term>Validation</term>
					<term>Visualization</term>
					<term>Writing -Original draft</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With this work we propose an application of the ELECTRA Transformer, fine-tuned on two augmented version of the same training dataset. Our team developed the novel framework for taking part at the Profiling Cryptocurrency Influencers with Few-shot Learning task hosted at PAN@CLEF2023. Our proposed strategy consists of an early data augmentation stage followed by a fine-tuning of ELECTRA. At the first stage we augment the original training dataset provided by the organizers using backtranslation. Using this augmented version of the training dataset, we perform a fine tuning of ELECTRA. Finally, using the fine-tuned version of ELECTRA, we inference the labels of the samples provided in the test set. To develop and test our model we used a two-ways validation on the training set. Firstly, we evaluate all the metrics on the augmented training set, and then we evaluate on the original training set. The metrics we considered span from accuracy to Macro F1, to Micro F1, to Recall and Precision. According to the official evaluator, our best submission reached a Macro F1 value equal to 0.3762.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The author profiling challenge introduced at PAN@CLEF2023 <ref type="bibr" coords="1,373.60,455.37,13.00,10.91" target="#b0">[1]</ref> was about Profiling Cryptocurrency Influencers with Few-shot Learning on Twitter <ref type="bibr" coords="1,349.48,468.92,11.34,10.91" target="#b1">[2]</ref>. The assignment was to identify and profile social media cryptocurrency influencers from a low-resource perspective. The task organizers proposed three multilabel classification subtasks. They were, namely: 1) Lowresource influencer profiling, 2) Low-resource influencer interest identification, 3) Low-resource influencer intent identification. For the first subtask the organizers provided an English dataset with 32 users per label with a maximum of 10 English tweets each. The five labels available were: (1) null, (2) nano, (3) micro, (4) macro, (5) mega depending on the type of influencer the author was. For the second subtask, 64 users per label with 1 English tweets each were provided. The five labels available in this case were: (1) technical information, (2) price update, (3) trading matters, (4) gaming, (5) other. Finally, for the third subtask, 64 users per label with 1 English tweets each were available and classes available for predictions were: (1) subjective opinion, (2) financial information, (3) advertising, (4) announcement. In this paper we discuss the framework we used to participate in the first subtask (i.e., low-resource influencer profiling).</p><p>After this introduction section, in Section 2 we discuss some traditional and deep approaches for text classification, along with a brief discussion on some of the architecture proposed in the previous editions of PAN. In Section 3 we provide the description of our method, including the training and the simulation steps. In Section 4 we detail the experimental setup and the evaluation of our framework, reporting the results obtained. In Section 5 we introduce some future works and conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>A comprehensive discussion on the proposed task for PAN@CLEF2023 is conducted in <ref type="bibr" coords="2,476.29,253.99,11.41,10.91" target="#b2">[3]</ref>. To develope our proposed approaches <ref type="bibr" coords="2,249.60,267.54,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,263.83,267.54,7.65,10.91" target="#b4">5]</ref>, we evaluated the best performing methods participating at the previous-shared competitions organized by PAN. We looked at the results of the winning team at the author profiling task in 2021, where the best performing model consisted of a shallow CNN presented in <ref type="bibr" coords="2,216.70,308.18,11.35,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,230.77,308.18,7.56,10.91" target="#b6">7]</ref>. We also considered the winning model at PAN@CLEF2022 where the authors won the challenge thanks to a soft voting ensemble technique that combines BERTweet models with various loss functions and a BERT feature-based CNN model. In the 2020 edition of the author profiling task <ref type="bibr" coords="2,262.88,348.83,12.42,10.91" target="#b7">[8]</ref>, based on their most recent 100 tweets, the aim was to identify the authors likely to disseminate false information. The winners at the shared task were <ref type="bibr" coords="2,114.01,375.93,12.99,10.91" target="#b8">[9]</ref> and <ref type="bibr" coords="2,149.55,375.93,16.41,10.91" target="#b9">[10]</ref>. On the given test set, their models' total accuracy was 0.77. The winning strategies are based on n-grams, an SVM, and an ensemble of other machine learning models. Other ensemble models have been proposed at the following tasks hosted at PAN about irony and stereotype spreaders detection <ref type="bibr" coords="2,247.04,416.58,16.43,10.91" target="#b10">[11,</ref><ref type="bibr" coords="2,266.19,416.58,12.32,10.91" target="#b11">12]</ref>.</p><p>We also examined a number of contemporary models for text categorization problems. It is important to note that Explainable Artificial Intelligence (XAI) techniques are increasingly being used in place of black box-based strategies. Several of these techniques based on graphs are applied in actual applications like text classification <ref type="bibr" coords="2,315.00,470.77,16.09,10.91" target="#b12">[13]</ref>, traffic prediction <ref type="bibr" coords="2,412.75,470.77,16.09,10.91" target="#b13">[14]</ref>, computer vision <ref type="bibr" coords="2,89.29,484.32,17.76,10.91" target="#b14">[15]</ref> and social networking <ref type="bibr" coords="2,207.07,484.32,16.08,10.91" target="#b15">[16]</ref>. Authors in <ref type="bibr" coords="2,278.44,484.32,17.75,10.91" target="#b16">[17]</ref> compare SVM, Naive Bayes, Logistic Regression, and Recurrent Neural Networks (RNN) as well as other popular machine learning methods. Experimental results demonstrate that SVM and Naive Bayes outperform other approaches on the dataset employed. In addition to the RNN, they do not report the evaluation of CNN or deep learning-based models. In another relevant comparative study <ref type="bibr" coords="2,366.90,538.52,16.19,10.91" target="#b17">[18]</ref>, on three separate datasets, scholars assess seven machine learning methods. Gradient Boosting Algorithm, Gaussian Naive Bayes, SVM, Random Forest, AdaBoost, KNN and Multi-Layer Perceptron are among the models that were utilized. The Gradient Boosting Algorithm surpasses the others in terms of accuracy and F1 score. There are not additional deep model experiments in this work, though.</p><p>In <ref type="bibr" coords="2,111.20,606.27,17.76,10.91" target="#b18">[19]</ref> the task of automatically detecting fake news spreaders of COVID-19 news is addressed by the authors by extending the CoAID dataset <ref type="bibr" coords="2,296.31,619.81,17.17,10.91" target="#b19">[20]</ref>. A deep learning model and Transformer's ability to produce language embeddings are combined in the authors' stacked Transformer-based neural network.</p><p>In <ref type="bibr" coords="2,111.98,660.46,16.16,10.91" target="#b20">[21]</ref>, the authors profile fake news spreaders using psycholinguistic and linguistic charac-teristics as input to CNN. The outcomes of their experiments demonstrate how well suggested model categorizes users as fake news spreaders. The dataset used for the authors' comparison was created expressly for their goal. However, only BERT was tested as Transformer model, and no further investigations are provided about the performance of deep models. Their model has also been evaluated on the PAN2020 dataset in <ref type="bibr" coords="3,300.40,141.16,16.29,10.91" target="#b21">[22]</ref>. On the English and Spanish datasets, the tested model achieves a binary accuracy of 0.52 and 0.51, respectively. In the same work <ref type="bibr" coords="3,486.77,154.71,16.33,10.91" target="#b21">[22]</ref>, the authors suggest a novel model that outperforms the two winning models at PAN@CLEF2020 on both languages by utilizing personality data and visual features.</p><p>In the work conducted in <ref type="bibr" coords="3,215.92,195.36,16.31,10.91" target="#b22">[23]</ref>, for the purpose of sentiment classification, scholars suggest using CNN. The authors demonstrate that using consecutive convolutional layers is efficient for categorizing lengthy texts through tests with three well-known datasets.</p><p>In regards to cryptocurrencies, authors in <ref type="bibr" coords="3,290.59,236.01,18.02,10.91" target="#b23">[24]</ref> develop a number of sequence-to-sequence hyperbolic models that are suitable for bubble detection identification issues based on the power-law dynamics of cryptocurrencies and user activity on social media. The study described in <ref type="bibr" coords="3,101.02,276.66,18.03,10.91" target="#b24">[25]</ref> is intriguing from the standpoint of NLP. The authors use a combination of statistical models and NLP techniques to examine what happened in social media starting in June 2019 with a focus on the rise of the Ethereum and Bitcoin prices, in order to better understand the connections between cryptocurrency values and social media.</p><p>Finally, the survey in <ref type="bibr" coords="3,195.75,330.85,17.84,10.91" target="#b25">[26]</ref> gives a succinct rundown of various text classification algorithms. This overview discusses several ways for extracting text features, dimensionality reduction, existing algorithms and methods, and evaluation strategies.</p><p>Given the performances shown in another international multi-label text classification challenge <ref type="bibr" coords="3,114.87,385.05,17.75,10.91" target="#b26">[27]</ref> and, as discussed in <ref type="bibr" coords="3,220.58,385.05,16.30,10.91" target="#b27">[28,</ref><ref type="bibr" coords="3,238.94,385.05,12.23,10.91" target="#b28">29]</ref>, presuming that natural language processing conventional methods can truly be outperformed by deep AI models, we decided to employ a Transformer based architecture (namely, ELECTRA <ref type="bibr" coords="3,268.62,412.15,15.89,10.91" target="#b29">[30]</ref>). Considering that the proposed task hosted at PAN@CLEF2023 consists on few-shot learning we also evaluated the augmented technique discussed in <ref type="bibr" coords="3,146.90,439.25,16.42,10.91" target="#b30">[31]</ref>. In this work the authors propose a data augmentation technique based on backtranslation to augment samples in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed Approach</head><p>An empirical experiment with three stages is used to assess the suggested framework. First, datasets without our augmentation modules are used to construct the baseline of author profiling models. In the second phase, backtranslation from English to a target language and back to English is used to create enriched data. For our two submissions we used two different target languages. The first one is Italian, according to our previous study discussed in <ref type="bibr" coords="3,433.29,565.62,16.09,10.91" target="#b30">[31]</ref>. The second language we used was German. This choice was motivated by the promising results obtained in a similar study based on backtranslation <ref type="bibr" coords="3,270.38,592.72,16.20,10.91" target="#b31">[32]</ref>. The backtranslated sample is then concatenated to the original one. In the final stage, the augmented data are used to train ELECTRA <ref type="bibr" coords="3,487.91,606.27,18.07,10.91" target="#b29">[30]</ref> and to compare the performances with or without the backtranslation module. In our setting, each sample is a user's set of tweets, and we hypothesise that semantically enriching the user's tweets using our proposed modules can improve performance. By augmenting each sample with one or multiple translations, we aim to increase the diversity and informativeness of the data and improve the representation of the input, ultimately leading to better classification performance of different NLP models. Our results outperform the not-augmented baseline, showing that the expansion of samples with multiple languages using backtranslation leads to improved performances in author profiling tasks. Thanks to the backtranslation module our framework is able to outperform the results obtained without expanding the samples.</p><p>No preprocessing is applied to the source text in the training datasets. In Figure <ref type="figure" coords="4,459.03,460.04,5.10,10.91" target="#fig_0">1</ref> we show the frameworks we used for our two submissions at the subtask 1. In the first submission we augmented the training set backtranslating from Italian <ref type="bibr" coords="4,348.42,487.14,18.06,10.91" target="#b30">[31]</ref> and in the second submission we backtranslated from German. In <ref type="bibr" coords="4,256.01,500.69,16.41,10.91" target="#b30">[31]</ref>, as a last stage classifier, the authors did not use a Transformer but a shallow CNN instead.</p><p>The training of our model is performed on the augmented versions of the datasets. For the first submission we fine-tuned ELECTRA for 30 epochs on the dataset augmented using the backtranslation tecnique with the Italian language. For the second one we used the German as a target language. We used ELECTRA both for the interesting performance in terms of training and inferencing time and results <ref type="bibr" coords="4,230.72,581.98,16.46,10.91" target="#b29">[30,</ref><ref type="bibr" coords="4,249.89,581.98,12.24,10.91" target="#b32">33]</ref>. In both cases we backtranslated the samples using the Google Translate API<ref type="foot" coords="4,185.84,593.78,3.71,7.97" target="#foot_0">1</ref> . After the training phase, we used the fine-tuned ELECTRA to predict on the unlabeled test set provided by the task organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>Our training and inferencing models, developed in TensorFlow and using Simple Transformers<ref type="foot" coords="5,501.78,130.49,3.71,7.97" target="#foot_1">2</ref> library, are publicly available as a Jupyter Notebook on GitHub<ref type="foot" coords="5,372.94,144.04,3.71,7.97" target="#foot_2">3</ref> . For the training and for the inferencing phases we made use of ELECTRA. According to what stated in <ref type="bibr" coords="5,436.70,159.35,16.42,10.91" target="#b29">[30]</ref>, ELECTRA suggests to replace certain tokens with possible replacements taken from a small generator network, instead of masking input like in BERT. Then, a discriminative model is trained to predict whether each token in the corrupted input was replaced by a generator sample or not, as opposed to developing a model that predicts the original identities of the corrupted tokens. Along with a graph neural network, ELECTRA can also be employed as an embedding layer as in <ref type="bibr" coords="5,113.13,240.64,16.37,10.91" target="#b12">[13]</ref>. In our experiments, the original version of ELECTRA, presented in <ref type="bibr" coords="5,440.83,240.64,16.37,10.91" target="#b29">[30]</ref>, was used. In both submissions we used a batch size of 1. We fine-tuned ELECTRA for 30 epochs. No improvements are obtained in fine-tuning for more epochs. Furthermore, we executed the fine-tuning for five runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The Dataset</head><p>The dataset provided by the PAN organizers consists of a set of Twitter authors and a variable number of corresponding tweets. For each author in the training set the labels are also provided. In Figure <ref type="figure" coords="5,132.24,358.11,5.07,10.91" target="#fig_1">2</ref> is reported the image from the official task website<ref type="foot" coords="5,366.03,356.36,3.71,7.97" target="#foot_3">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>The official metric used for the author profiling task at PAN@CLEF2023 is the Macro F1. This metric, along with others, is the same used in the rest of this section and defined in <ref type="bibr" coords="5,461.78,421.39,10.48,10.91" target="#b0">(1)</ref>.</p><formula xml:id="formula_0" coords="5,228.82,444.85,277.82,24.43">𝑀 𝑎𝑐𝑟𝑜𝐹 1 = 𝑠𝑢𝑚(𝐹 1𝑠𝑐𝑜𝑟𝑒𝑠) #𝑐𝑙𝑎𝑠𝑠𝑒𝑠<label>(1)</label></formula><p>In Table <ref type="table" coords="5,140.35,476.23,5.17,10.91">1</ref> we report the results of our two submissions on the augmented version of the datasets in terms of Macro F1. We report the highest Macro F1 along the 30 epochs of training and also the median one. The median is calculated along five random initialization and fine-tuning of ELECTRA. We also report the loss at the end of the training stage.</p><p>In Table <ref type="table" coords="5,136.88,530.42,4.97,10.91" target="#tab_0">2</ref> we report the results using all the metrics provided by the official evaluator available on GitHub<ref type="foot" coords="5,137.20,542.22,3.71,7.97" target="#foot_4">5</ref> for all the classes available and using the original non-augmented version of the training set. Finally, in Table <ref type="table" coords="5,215.84,557.52,3.66,10.91" target="#tab_1">3</ref>, we report the results with the metrics already presented in Table <ref type="table" coords="5,89.04,571.07,3.74,10.91">1</ref>, but using the original non-augmented version of the training set.</p><p>Although the Macro F1 and the accuracy prove that ELECTRA fine-tuned on the Italian backtranslated version of the dataset outperforms the German one, as can be seen from Table <ref type="table" coords="5,500.99,598.17,4.99,10.91" target="#tab_0">2</ref> for three out of five classes the Precision is higher in the case of the submission using German </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Results achieved by our framework at the end of the fine-tuning on the two augmented versions of the training set. ELECTRA performs better in the augmented version of the dataset using the Italian language. The Median Macro F1 is obtained as the median accuracy along five runs. backtranslation. However, a further investigation on the effect of the backtranslation on the original samples could eventually lead to an explanation of these differences among the classes. Finally, while on augmented dataset used for training both the fine-tuned ELECTRA are able to reach a Macro F1 equal to 0.9937, the version fine-tuned with the Italian backtranslation appears to generalize better with a gap of 5-6% with respect to Macro F1 and Accuracy when </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Works</head><p>In this paper we have described our submitted model for our participation at the author profiling task hosted at PAN@CLEF 2023. It consists of a backtranslation layer followed by an expansion module to expand every sample in the dataset. These augmented versions of the samples are then provided to ELECTRA both for training and inference phases. We intend to assess performance using different backtranslation techniques and other languages in future studies. We also consider for future works to perform an error analysis on authors who were incorrectly classified to assess the impact on the performance for the considered classification task. Increasing the model's complexity, perhaps by utilizing other recent generative tool (i.e. ChatGPT), is another way that could eventually boost accuracy in author profiling tasks. Given the size of the dataset that was provided, additional data augmentation techniques could possibly be used. Before the training and testing phases of our model, some research into the content of each tweet could influence the construction of the model in the use of some strategies to remove noise (i.e., not relevant features) from input samples. According to our research, enhancing samples with their respective backtranslations can lead to performance improvements.</p><p>As future works, it would also be interesting to investigate the performance of our approach also on other datasets used for author profiling tasks. Furthermore, it could also be of interest to evaluate the impact of other languages used in the backtranslation module discussed here.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,330.78,418.35,8.93;4,89.29,342.79,416.69,8.87;4,89.29,354.74,208.82,8.87;4,89.29,84.19,425.18,239.17"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1:The overall architecture of the proposed framework. For the first submission, the backtranslation module translates the original source text into Italian and then back into English. For our second submission, the target language used was German.</figDesc><graphic coords="4,89.29,84.19,425.18,239.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,319.51,416.69,8.93;6,89.29,331.52,77.80,8.87;6,89.29,84.19,425.18,228.73"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Official PAN page on webis.de about the three subtasks and the related datasets, metrics and baselines provided.</figDesc><graphic coords="6,89.29,84.19,425.18,228.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,416.62,417.00,170.39"><head>Table 2</head><label>2</label><figDesc>Results achieved by our framework at the end of the fine-tuning on the two augmented versions of the training set. The evaluation is performed using Precision and Recall on the original non-augmented version of the training dataset.</figDesc><table coords="6,94.49,416.62,406.30,170.39"><row><cell></cell><cell></cell><cell></cell><cell cols="5">Results on the augmented training set</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Best Macro F1 Median Macro F1</cell><cell>Loss</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Italian</cell><cell></cell><cell>0.9937</cell><cell></cell><cell>0.9431</cell><cell cols="2">0.0176</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">German</cell><cell>0.9937</cell><cell></cell><cell>0.9311</cell><cell cols="2">0.0135</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Results per each class on the non-augmented training set</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Macro</cell><cell cols="2">Nano</cell><cell>No</cell><cell></cell><cell cols="2">Mega</cell><cell cols="2">Micro</cell></row><row><cell></cell><cell cols="10">Precision Recall Precision Recall Precision Recall Precision Recall Precision Recall</cell></row><row><cell>Italian</cell><cell>0.6383</cell><cell>0.9375</cell><cell>0.8710</cell><cell>0.8437</cell><cell>1.0000</cell><cell>0.7500</cell><cell>0.9444</cell><cell>0.5312</cell><cell>0.8000</cell><cell>1.0000</cell></row><row><cell>German</cell><cell>0.7838</cell><cell>0.9062</cell><cell>1.0000</cell><cell>0.4375</cell><cell>0.9355</cell><cell>0.9062</cell><cell>1.0000</cell><cell>0.5312</cell><cell>0.5246</cell><cell>1.0000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,90.49,417.17,143.71"><head>Table 3</head><label>3</label><figDesc>Results achieved by our framework at the end of the fine-tuning on the two augmented versions of the training set. In this case the results are obtained using the original version of the training dataset for the evaluation.</figDesc><table coords="7,89.29,140.26,416.69,93.94"><row><cell cols="3">Results on the original training set</cell></row><row><cell></cell><cell>Macro F1</cell><cell>Acc</cell></row><row><cell>Italian</cell><cell>0.8085</cell><cell>0.8125</cell></row><row><cell>German</cell><cell>0.7504</cell><cell>0.7562</cell></row><row><cell cols="3">evaluated on the original non-augmented training set. On the official test set provided, our best</cell></row><row><cell cols="2">submission reached a Macro F1 value equal to 0.3762.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,92.57,670.95,134.52,8.97"><p>https://pypi.org/project/googletrans/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,92.57,638.15,134.68,8.97"><p>https://simpleTransformers.ai/about/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,92.57,649.11,190.62,8.97"><p>https://github.com/marco-siino/PAN-CRYPTO-2023</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,92.57,660.07,222.76,8.97"><p>https://pan.webis.de/clef23/pan23-web/author-profiling.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,92.57,671.03,365.18,8.97"><p>https://github.com/pan-webis-de/pan-code/tree/master/clef23/profiling-cryptocurrency-influencers</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank anonymous reviewers for their comments and suggestions that have helped to improve the presentation of the paper.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Online Resources</head><p>The source code of our model is available via • GitHub</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,111.28,394.52,10.91;8,112.66,124.83,394.53,10.91;8,112.66,138.38,394.52,10.91;8,112.66,151.93,393.53,10.91;8,112.66,165.48,394.53,10.91;8,112.66,179.03,395.17,10.91;8,112.66,192.57,393.33,10.91;8,112.66,206.12,394.53,10.91;8,112.66,219.67,65.44,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,294.21,138.38,212.97,10.91;8,112.66,151.93,393.53,10.91;8,112.66,165.48,42.05,10.91">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.28,179.03,136.55,10.91;8,112.66,192.57,393.33,10.91;8,112.66,206.12,197.14,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="8,342.79,206.12,159.86,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,112.66,233.22,393.33,10.91;8,112.66,246.77,393.33,10.91;8,112.14,260.32,159.26,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,466.53,233.22,39.46,10.91;8,112.66,246.77,261.87,10.91">Profiling Cryptocurrency Influencers with Few shot Learning at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,417.97,246.77,88.02,10.91;8,112.14,260.32,47.32,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="8,167.44,260.32,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,273.87,395.17,10.91;8,112.66,287.42,394.53,10.91;8,112.66,300.97,395.17,10.91;8,112.66,314.52,393.32,10.91;8,112.66,328.07,394.53,10.91;8,112.66,341.62,55.16,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,298.39,287.42,208.80,10.91;8,112.66,300.97,395.17,10.91;8,112.66,314.52,28.57,10.91">Overview of pan 2023: Authorship verification, multi-author writing style analysis, profiling cryptocurrency influencers, and trigger detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,163.71,314.52,342.28,10.91;8,112.66,328.07,87.08,10.91">Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">April 2-6, 2023. 2023</date>
			<biblScope unit="page" from="518" to="526" />
		</imprint>
	</monogr>
	<note>Part III</note>
</biblStruct>

<biblStruct coords="8,112.66,355.17,393.33,10.91;8,112.66,368.71,394.53,10.91;8,112.66,382.26,103.95,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,273.13,355.17,232.86,10.91;8,112.66,368.71,210.95,10.91">Profiling cryptocurrency influencers with few-shot learning using data augmentation and electra</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,354.39,368.71,147.43,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="8,112.66,382.26,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,395.81,394.53,10.91;8,112.66,409.36,266.06,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,213.36,395.81,289.53,10.91">Xlnet on augmented dataset to profile cryptocurrency influencers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.29,409.36,139.49,10.91">CLEF 2023 Labs and Workshops</title>
		<title level="s" coord="8,274.77,409.36,73.93,10.91">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,422.91,393.33,10.91;8,112.66,436.46,393.32,10.91;8,112.33,450.01,258.17,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,345.70,422.91,160.29,10.91;8,112.66,436.46,163.64,10.91">Detection of hate speech spreaders using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,299.96,436.46,206.03,10.91;8,112.33,450.01,66.45,10.91">PAN 2021 Profiling Hate Speech Spreaders on Twitter@ CLEF</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2021">2936. 2021</date>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,463.56,393.33,10.91;8,112.66,477.11,247.67,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,322.45,463.56,183.54,10.91;8,112.66,477.11,122.75,10.91">Fake news spreaders detection: Sometimes attention is not all you need</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Di Nuovo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,244.08,477.11,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">426</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,490.66,393.33,10.91;8,112.66,504.21,394.53,10.91;8,112.39,517.76,243.38,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,345.21,490.66,160.78,10.91;8,112.66,504.21,243.15,10.91">Overview of the 8th author profiling task at pan 2020: Profiling fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H H</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,376.55,504.21,126.02,10.91">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Sun SITE Central Europe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,531.30,386.41,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,159.51,531.30,244.37,10.91">Using n-grams to detect fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,426.46,531.30,21.05,10.91">CLEF</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,544.85,393.61,10.91;8,112.66,558.40,237.86,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="8,201.71,544.85,304.55,10.91;8,112.66,558.40,142.28,10.91">An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bolonyai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CLEF</publisher>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,571.95,393.33,10.91;8,112.66,585.50,395.01,10.91;8,112.66,599.05,48.96,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,246.47,571.95,259.52,10.91;8,112.66,585.50,90.19,10.91">An svm ensamble approach to detect irony and stereotype spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Garlisi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,228.97,585.50,133.53,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2426" to="2432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,612.60,393.60,10.91;8,112.66,626.15,395.01,10.91;8,112.66,639.70,48.96,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,281.48,612.60,224.78,10.91;8,112.66,626.15,107.15,10.91">T100: A modern classic ensemble to profile irony and stereotype spreaders</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,242.57,626.15,127.79,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2666" to="2674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,653.25,393.33,10.91;8,112.66,666.80,393.33,10.91;9,112.66,86.97,358.09,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,276.68,653.25,229.31,10.91;8,112.66,666.80,180.65,10.91">Courage at checkthat! 2022: Harmful tweet detection using graph neural networks and electra</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Donabauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,316.04,666.80,189.95,10.91;9,112.66,86.97,204.09,10.91">Working Notes of CLEF 2022-Conference and Labs of the Evaluation Forum, CLEF &apos;2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="573" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,100.52,395.17,10.91;9,112.66,114.06,289.92,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<title level="m" coord="9,252.12,100.52,255.71,10.91;9,112.66,114.06,107.88,10.91">Diffusion convolutional recurrent neural network: Datadriven traffic forecasting</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,127.61,395.17,10.91;9,112.66,141.16,395.17,10.91;9,112.66,154.71,394.52,10.91;9,112.66,168.26,90.72,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,261.82,127.61,246.02,10.91;9,112.66,141.16,277.34,10.91">Graph neural network (gnn) in image and video understanding using deep learning for computer vision applications</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pradhyumna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shreya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,413.12,141.16,94.71,10.91;9,112.66,154.71,363.55,10.91">2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1183" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,181.81,393.73,10.91;9,112.66,195.36,393.33,10.91;9,112.66,208.91,272.03,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,279.25,181.81,227.14,10.91;9,112.66,195.36,235.00,10.91">Whosnext: Recommending twitter users to follow using a spreading activation network based approach</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,371.10,195.36,134.89,10.91;9,112.66,208.91,166.48,10.91">2020 International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="62" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,222.46,393.33,10.91;9,112.66,236.01,393.33,10.91;9,112.66,249.56,207.08,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,291.57,222.46,214.41,10.91;9,112.66,236.01,109.94,10.91">Detecting fake news using machine learning and deep learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Mahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Huq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,245.81,236.01,260.17,10.91;9,112.66,249.56,112.65,10.91">2019 7th International Conference on Smart Computing &amp; Communications (ICSCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.32,10.91;9,112.66,276.66,393.32,10.91;9,112.66,290.20,256.47,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,333.97,263.11,172.01,10.91;9,112.66,276.66,192.37,10.91">Comparative performance of machine learning algorithms for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P S</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Choubey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,327.91,276.66,178.07,10.91;9,112.66,290.20,126.10,10.91">International conference on advances in computing and data sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.61,10.91;9,112.66,317.30,235.67,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,259.84,303.75,246.43,10.91;9,112.66,317.30,111.03,10.91">Automated classification of fake news spreaders to break the misinformation chain</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Leonardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Morisio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,232.08,317.30,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">248</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.33,10.91;9,112.66,344.40,107.17,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.00885</idno>
		<title level="m" coord="9,189.55,330.85,236.40,10.91">Coaid: Covid-19 healthcare misinformation dataset</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,357.95,393.33,10.91;9,112.66,371.50,394.53,10.91;9,112.66,385.05,224.61,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,443.62,357.95,62.37,10.91;9,112.66,371.50,390.03,10.91">The impact of psycholinguistic patterns in discriminating between fake news spreaders and fact checkers</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Ríssola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oberski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,385.05,141.58,10.91">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">101960</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,398.60,393.33,10.91;9,112.66,412.15,393.33,10.91;9,112.66,425.70,221.05,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,253.78,398.60,252.21,10.91;9,112.66,412.15,82.93,10.91">Profiling Fake News Spreaders: Personality and Visual Information Matter</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cervero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,218.58,412.15,287.41,10.91;9,112.66,425.70,90.15,10.91">International Conference on Applications of Natural Language to Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,439.25,393.33,10.91;9,112.66,452.79,100.24,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,200.26,439.25,263.05,10.91">Sentiment classification using convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-S</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,471.48,439.25,34.51,10.91;9,112.66,452.79,37.51,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2347</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,393.33,10.91;9,112.66,479.89,393.33,10.91;9,112.66,493.44,107.17,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.06320</idno>
		<title level="m" coord="9,401.32,466.34,104.67,10.91;9,112.66,479.89,321.55,10.91">Cryptocurrency bubble detection: a new stock market dataset, financial task &amp; hyperbolic models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,506.99,393.33,10.91;9,112.66,520.54,393.33,10.91;9,112.66,534.09,290.20,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="9,332.67,506.99,173.32,10.91;9,112.66,520.54,393.33,10.91;9,112.66,534.09,45.44,10.91">Cryptocurrency ecosystems and social media environments: An empirical analysis through hawkes&apos; models and natural language processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ortu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vacca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Destefanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Conversano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,166.57,534.09,163.41,10.91">Machine Learning with Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100229</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,547.64,393.33,10.91;9,112.66,561.19,276.35,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,486.17,547.64,19.82,10.91;9,112.66,561.19,151.63,10.91">Text classification algorithms: A survey</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kowsari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jafari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Meimandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Heidarysafa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mendu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,272.76,561.19,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">150</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,574.74,393.33,10.91;9,112.66,588.29,393.65,10.91;9,112.66,601.84,393.32,10.91;9,112.33,615.39,394.85,10.91;9,112.66,628.93,397.48,10.91;9,112.66,644.93,74.11,7.90" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="9,281.99,574.74,223.99,10.91;9,112.66,588.29,393.65,10.91;9,112.66,601.84,45.44,10.91">McRock at SemEval-2022 task 4: Patronizing and condescending language detection using multi-channel CNN, hybrid LSTM, DistilBERT and XLNet</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>La Cascia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tinnirello</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.semeval-1.55</idno>
		<ptr target="https://aclanthology.org/2022.semeval-1.55.doi:10.18653/v1/2022.semeval-1.55" />
	</analytic>
	<monogr>
		<title level="m" coord="9,181.93,601.84,324.05,10.91;9,112.33,615.39,67.42,10.91">Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)</title>
		<meeting>the 16th International Workshop on Semantic Evaluation (SemEval-2022)<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="409" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,656.03,395.17,10.91;9,112.66,669.58,244.76,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="9,223.22,656.03,247.47,10.91">Review of text classification methods on deep learning</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,480.36,656.03,27.47,10.91;9,112.66,669.58,150.68,10.91">CMC-Computers, Materials &amp; Continua</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.26,100.52,393.93,10.91;10,112.66,114.06,107.04,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="10,257.56,86.97,248.43,10.91;10,112.26,100.52,199.87,10.91">Classifying tweets using convolutional neural networks with multi-channel distributed representation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hashida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,320.53,100.52,185.66,10.91;10,112.66,114.06,33.25,10.91">IAENG International Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,393.33,10.91;10,112.66,141.16,347.38,10.91" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="10,335.14,127.61,170.85,10.91;10,112.66,141.16,165.13,10.91">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,154.71,393.33,10.91;10,112.66,168.26,394.53,10.91;10,112.39,181.81,183.73,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="10,255.49,154.71,250.50,10.91;10,112.66,168.26,235.99,10.91">Improving irony and stereotype spreaders detection using data augmentation and convolutional neural network</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mangione</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Garbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,372.27,168.26,130.20,10.91">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2585" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,195.36,393.33,10.91;10,112.66,208.91,393.98,10.91;10,112.41,222.46,32.84,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="10,307.31,195.36,198.68,10.91;10,112.66,208.91,177.68,10.91">Data expansion using back translation and paraphrasing for hate speech detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Beddiar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Jahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oussalah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,301.50,208.91,160.58,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">100153</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,236.01,393.53,10.91;10,112.66,249.56,393.33,10.91;10,112.66,263.11,243.98,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="10,254.53,236.01,251.66,10.91;10,112.66,249.56,66.61,10.91">An empirical comparison of bert, roberta, and electra for fact verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Naseer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Asvial</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F</forename><surname>Sari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,200.75,249.56,305.24,10.91;10,112.66,263.11,129.61,10.91">2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
