<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.08,75.66,450.22,16.83;1,72.08,96.05,240.60,16.83;1,72.08,116.70,162.04,10.80">Contrastive Learning for Authorship Verification using BERT and Bi-LSTM in a Siamese Architecture Notebook for PAN at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,72.08,144.30,110.87,10.80"><forename type="first">Panagiotis</forename><surname>Petropoulos</surname></persName>
							<email>panos.petr1@gmail.com</email>
						</author>
						<title level="a" type="main" coord="1,72.08,75.66,450.22,16.83;1,72.08,96.05,240.60,16.83;1,72.08,116.70,162.04,10.80">Contrastive Learning for Authorship Verification using BERT and Bi-LSTM in a Siamese Architecture Notebook for PAN at CLEF 2023</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CF59F43378AE2763926DDB9C088E7849</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Authorship Verification</term>
					<term>Contrastive Learning</term>
					<term>BERT</term>
					<term>Bi-LSTM</term>
					<term>Siamese Architecture</term>
					<term>NLP</term>
					<term>Authorship Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship Verification constitutes an important and essential part in the more general area of authorship analysis. In the age of digital communication, where information traverses the globe at the speed of light, determining the true authorship of a text has become a paramount challenge. From verifying the authenticity of legal documents to investigating plagiarism cases and combating online fraud, the field of authorship verification has emerged as a crucial domain in the realm of textual forensics. The PAN 2023 Authorship Verification [1] challenge focuses on determining whether two different types of texts are written by the same author, specifically when the corresponding model is consuming unseen Authors (open set setup). This paper proposes a Contrastive Learning approach with Siamese architecture, that consists of BERT <ref type="bibr" coords="1,157.98,316.25,12.60,9.72" target="#b1">[2]</ref>[1] and Bi-LSTM on top of BERT. Additionally, this work proposes the creation of 2 dataset from the original one. One for written language texts and one for oral texts. In this way it would be more helpful for a model to compare-contrasts texts to extract stylistic features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.2" lry="841.8"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Authorship Verification is defined as the task in which an artificial intelligence model, after being trained, is able to determine the probability of two or more texts belonging to the same author or not. This can be achieved by analyzing and retrieving useful information from texts. Modern applications are aimed at retrieving writing style to solve the specific problem. There are many approaches that use traditional techniques for feature extraction to solve the task <ref type="bibr" coords="1,339.35,498.79,11.50,9.72" target="#b2">[3]</ref>, <ref type="bibr" coords="1,357.98,498.79,11.47,9.72" target="#b3">[4]</ref>, <ref type="bibr" coords="1,376.60,498.79,11.47,9.72" target="#b4">[5]</ref>. They use modern approaches hand-engineered features in combination with n-grams extracted from multiple CNNs <ref type="bibr" coords="1,451.67,511.40,12.60,9.72" target="#b5">[6]</ref> or pretrained word embeddings <ref type="bibr" coords="1,157.38,524.00,11.47,9.72" target="#b6">[7]</ref>. Other approaches use pre-trained language models and contrastive learning frameworks <ref type="bibr" coords="1,127.93,536.62,11.49,9.72" target="#b7">[8]</ref>, <ref type="bibr" coords="1,147.15,536.62,12.60,9.72" target="#b8">[9]</ref> and <ref type="bibr" coords="1,182.60,536.62,18.00,9.72" target="#b9">[10]</ref> or a combination of one Encoder-Decoder Transformer with traditional features such as pos-tags and n-grams <ref type="bibr" coords="1,256.48,549.22,16.56,9.72" target="#b10">[11]</ref>. Finally, there are also approaches based on Cosine Similarity or dissimilarity of feature vectors for the final decision <ref type="bibr" coords="1,373.58,561.82,18.00,9.72" target="#b11">[12]</ref> and a modified or improved Impostors method, which also a method that calculated the cosine similarity between the feature vectors <ref type="bibr" coords="1,72.08,587.05,16.58,9.72" target="#b12">[13]</ref>.</p><p>In this work a pretrained BERT model with a Bi-LSTM on top of that in a Siamese architecture for a contrastive learning framework is applied. The main challenge in this task is to create a model that can be able to handle stylistic information about the authors between different type of texts (email vs essay vs interview vs speech transcription). Also, the metadata information about the types of text is used and the original train dataset is reconstructed in a way that there is one train dataset that consists of written language texts (email vs essay) and another with oral language texts (interview vs speech transcription).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model Overview</head><p>The proposed model is illustrated in Figure <ref type="figure" coords="2,281.70,106.10,4.05,9.72" target="#fig_0">1</ref>. The BERT model is kept frozen during training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Experimental setup</head><p>A Siamese architecture is used that was originally introduced by <ref type="bibr" coords="2,359.17,474.17,18.00,9.72" target="#b14">[15]</ref> and consists of 2 same instances of BERT (same weights) and on top of each instance there is a Bi-LSTM to capture the appropriate information from 2 different directions of a long sequence du ring Contrastive Learning procedure. Based on the experiments the best results are obtained from the concatenation of CLS token Embeddings from 2 to 12 Encode Layers. Those Embeddings are then passed through a Bi-LSTM in order to handle the stylistic information. The final embeddings (E and E') are the concatenation of the last hidden states from 2 directions of Bi-LSTM. The selected optimizer is Adam with learning rate equals to 0.002. The PAN 2023 AV dataset consists of different types of texts. Based on PAN 2022 results <ref type="bibr" coords="2,103.90,575.65,12.60,9.72" target="#b4">[5]</ref> a cross-DT task was very challenging. For that reason, a model for written texts (email vs essays) was created, another one for texts that came from speech (speech transcription vs interviews) and a general model that was trained on all types. The final predictions for those pairs that do not have a specific model for them (i.e. essay vs interview) were produced from an Ensemble procedure Figure <ref type="figure" coords="2,72.08,626.07,5.40,9.72" target="#fig_1">2</ref> between the 3 trained models. All models were trained for 5 epochs and the batch size was 32. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Data preparation and processing</head><p>The PAN 2023 Authorship Verification challenge provided a dataset that consists of 8837 problems located in FoLD<ref type="foot" coords="3,147.15,306.71,3.60,6.48" target="#foot_0">2</ref>  <ref type="bibr" coords="3,153.75,307.25,16.58,9.72" target="#b13">[14]</ref>. Each problem contains a pair of text and information about the type of each of them. This specific dataset consists of 4 main categories of text types:</p><p>1. Email 2. Essay 3. Interview 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech transcription</head><p>Exactly 4418 of these pairs were written from same author and 4418 from different author. Instead of using the predefined pairs from original dataset, All texts for each Author were collected and were appended to a pool in a way that each Author will have N texts. After the collection, a chunking procedure for each text was applied. The final illustration of the collection pool is shown in Figure <ref type="figure" coords="3,515.33,433.94,4.06,9.72" target="#fig_2">3</ref>.</p><p>Based on this figure, for each author there are N lists of M chunks. Not all chunks were collected in one list because during retrieval in training/validation procedure there was no desire to select 2 chunks from the same text, to avoid handling information about the topic. Due the fact that BERT has limitation on the length of input tokens, a chunking procedure on text is applied with max sequence length to 128. This size was selected, because in the dataset there were small and bigger texts. BERT Tokenizer decided where to chunk a text. Between chunks of the same text, an overlapping approach was applied in order to avoid too long padding sequences.</p><p>All numbers in texts masked with a specific digit '1' keep the original format and length of text. Additionally, all special words such as &lt;nl&gt;, &lt;new&gt; etc were removed from the text. For the email cases the html tags were removed as well.</p><p>For a Contrastive Learning framework, we need to consider the false negatives. So, in order to create a batch, the below steps were followed: 1. Random Select Author. 2.</p><p>Random Select 2 chunks from different texts, to construct a Same Author pair. In this way a batch with different authors and same author pairs is created. The loss function is calculated for all combination in the batch. As input to the model, same Author pairs are passed (main diagonal of Figure <ref type="figure" coords="4,158.58,214.17,5.40,9.72" target="#fig_5">5</ref> in blue) and the negative pairs are calculated inside the loss function. This can be seen as an alternative way to increase the batch size during calculation of loss function. Due to this approach, caution is required on how to create the batch to avoid the false negatives. An illustration of how the cosine similarity is calculated is shown in Figure <ref type="figure" coords="4,333.95,252.00,4.05,9.72" target="#fig_5">5</ref>. Based on this figure the different author pairs are located above and below the main diagonal of dot product matrix. For example, above the main diagonal there is P = Ei x Ej and below the main diagonal there is the transpose of this product P T (P = Ej x Ei).</p><p>The following example describes a false negative scenario. Imagine that batch size is 64. So, 2 chunks from 32 Authors should be chosen randomly (32*2=64). For each Author within the batch there will be 2 chunks from different texts. The implemented loss will get those chunks as input and will apply cosine similarity as metric that contributes to loss. The main diagonal of Figure <ref type="figure" coords="4,158.58,353.47,5.40,9.72" target="#fig_5">5</ref> will have the cosine similarity values of the same author pairs (2 chunks of Same Author). The results of cosine similarity between different author pairs will be located above and below the main diagonal of this matrix. Each chunk of the same Author will be compared with each chunk by another Author. In this way if a data loader selects twice the same author within the same batch, 4 chunks (2 + 2) by the same Author will be selected, resulting to a false negative scenario. In other words, some values above and below the main diagonal will be treated (wrongly) as different Author pairs by the loss function. The reason for the strictness of data selection is the non-existence of False Negative within Batch. If all the Authors are selected in a batch , then based on the image and the calculations of all combinations within batch, for the same Authors there will also be a pair that will be treated as Negative. In this way, within the batch there will be some False Negatives. Below is the illustration (Figure <ref type="figure" coords="4,160.38,480.17,4.50,9.72" target="#fig_3">4</ref>) of an incorrect Batch for better understanding of the above description. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Loss Function</head><p>In order to train and evaluate the model a contrastive learning procedure with modified contrastive loss <ref type="bibr" coords="5,72.08,118.72,18.00,9.72" target="#b15">[16]</ref> based on Cosine similarity is followed.</p><formula xml:id="formula_0" coords="5,95.50,143.20,413.20,25.39">ùêø(ùê∏, ùê∏ ‚Ä≤ ,ùëå) = 1 2 (ùëåùëöùëéùë• {(ùê∑(ùê∏,ùê∏ ‚Ä≤ ) -ùëö ùëù ) ,0} 2 + (1 -ùëå)ùëöùëéùë• {(ùëö ùëõ -ùê∑(ùê∏, ùê∏ ‚Ä≤ )) ,0} 2 ) (<label>1</label></formula><formula xml:id="formula_1" coords="5,508.70,143.20,3.89,10.80">)</formula><p>Where mp is the positive margin, mn is the negative margin. Value above positive margin and under negative margin do not contribute to loss.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3.">Evaluation</head><p>After splitting original data in open set setup w.r.t to authors, 70% for training 15% for validation and 15% for a holdout test set were kept. For the test set the chunking procedure for each text in a pair was performed and during inference and prediction the average predicted Embeddings from all chunks for each text in a pair was taken. After that, a cosine similarity calculation is performed. The final prediction is calculated via a threshold. Another approach would be to calculate the cosine similarities for all combinations of chunks (Embeddings) from one text with all chunks from the other text (and vice versa) and as final score calculate the average similarity. The final decision is calculated for all combination of chunks from 2 texts in a pair and not from specific chunk pairs, because the model trained with random combinations. To find an optimal threshold a grid search approach is performed, in order to calibrate the models and the threshold with the best overall score is kept. The values of those threshold per model are 0.697 for Essay vs Email model, 0.67 for Interview vs speech transcription and for the general model is 0.56. As evaluation metrics I use the metrics provided in <ref type="bibr" coords="5,399.42,678.32,11.47,9.72" target="#b3">[4]</ref>.</p><p>‚Ä¢ AUC: the conventional area-under-the-curve of the precision-recall curve ‚Ä¢ F1-score: the harmonic mean of the precision and recall [17] ‚Ä¢ c@1: a variant of the conventional F1-score, which rewards systems that leave difficult problems unanswered (i.e. scores of exactly 0.5) <ref type="bibr" coords="5,302.10,731.15,18.00,9.72" target="#b17">[18]</ref> ‚Ä¢ overall: the simple average of all previous metrics</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>Table <ref type="table" coords="6,118.33,106.10,5.40,9.72" target="#tab_1">2</ref> below shows Accuracy, F1-score AUC and C@1 scores with their corresponding std between 3 runs on my custom unseen test set. The test set was created based on open-set setup. In Tira system <ref type="foot" coords="6,103.30,130.78,3.60,6.48" target="#foot_1">3</ref> [20] 2 approaches were submitted with different thresholds for the final decision as shown in below Table <ref type="table" coords="6,130.93,143.92,37.55,9.72" target="#tab_0">(Table 1</ref>). The values for the threshold are not selected randomly but based on the best Overall score in my test set. For The first run the threshold values are selected from the best (top-1) Overall score and for the second run the values are selected from the second-best score. In Table <ref type="table" coords="6,501.52,169.15,5.40,9.72" target="#tab_1">2</ref> the first column of Table <ref type="table" coords="6,169.97,181.75,5.40,9.72" target="#tab_0">1</ref> 0.697, 0.67, 0.56 respectively were used as thresholds. The difference between the 2 runs (approaches) in Tira system is the values of thresholds. All the architectures, hyper-parameters and training procedure are the same. From the results it can be seen that using the information about the type of text and creating separate models to solve the task can be very helpful. The General model in Table <ref type="table" coords="6,407.83,707.12,5.40,9.72" target="#tab_1">2</ref> was not performed very well like the other models that were created for specific types of texts. The Final model is the model that consumes the whole custom test dataset and performs prediction including the Ensemble procedure with the sub-models. The results are lower than the other models in table, due to the fact that the test dataset contains more pairs that there is not a specific model for them such as interview vs email. For this challenging dataset the final model performs very well in this test set.  <ref type="table" coords="7,227.03,306.64,5.40,9.72" target="#tab_2">3</ref> that the 2 runs in Tira system returned roughly the same results. The proposed methodology did not performed very well, but makes the AV task feasible with a contrastive learning framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>Based on results, it is observed that, handling stylistic information between different types of texts is a very challenging task. That can be also confirmed from the optimal thresholds. They are too high and that means that trained models cannot create a clean Embeddings space where negative pairs stand apart from each other and positive pairs the opposite. It can also be observed that the proposed methodology can make the cross-DT AV task feasible, with some modifications, especially when the metadata information about the type of texts is used. As future work it would be great to train a model with a triplet loss with online and fast hard negatives mining <ref type="bibr" coords="7,340.55,478.37,16.58,9.72" target="#b20">[21]</ref>. Also, additional features, apart from POS-tags, such as n-grams and complexity of texts features can be combined with contextualized word Embeddings, to create a joint embeddings space for a contrastive learning framework. Due to lack of time and resources there was no application of the same procedure with RoBERTa <ref type="bibr" coords="7,459.47,516.79,18.00,9.72" target="#b21">[22]</ref> model or another pre-trained language model like GPT <ref type="bibr" coords="7,279.30,529.40,18.00,9.72" target="#b22">[23]</ref> and it would be a good choice as feature work to perform benchmarks with other powerful pre-trained models. Finally, a more interesting and challenging approach is to re-train the BERT model with additional initial Embeddings Layer that produce embeddings from pos-tags of the original input sequence. This approach needs more data and special care on the other pre-trained layers because the new initial Layer will not be pre-trained.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,72.08,402.00,249.59,10.80;2,86.20,128.39,347.00,271.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Siamese Architecture of the proposed Model.</figDesc><graphic coords="2,86.20,128.39,347.00,271.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.08,197.25,337.94,10.80;3,72.00,72.00,451.00,122.95"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Final System overview -Ensemble Procedure for Final prediction.</figDesc><graphic coords="3,72.00,72.00,451.00,122.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,72.08,696.20,247.47,10.80;3,72.00,481.20,372.73,212.15"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Collection of Chunks w.r.t. Authors and texts.</figDesc><graphic coords="3,72.00,481.20,372.73,212.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,72.08,722.03,222.88,10.80;4,72.00,502.06,343.48,217.45"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of a Batch with False Negative.</figDesc><graphic coords="4,72.00,502.06,343.48,217.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,257.92,194.97,265.72,9.72;5,72.08,208.07,451.59,9.83;5,72.08,220.69,451.65,9.83;5,72.08,233.39,451.24,9.72;5,72.08,246.00,451.65,9.72;5,72.08,258.62,451.51,9.72;5,72.08,271.22,451.15,9.72;5,72.08,283.82,66.94,9.72"><head></head><label></label><figDesc>For training and validation those margins were kept at 1 and 0, respectively. Y is the target label as ground truth and E &amp; E' are the Embeddings Vectors of a pair in a batch. D(E,E') are the Cosine Similarity values between the pairs of Vectors. D can also be Euclidean or Manhattan distances. In Figure 5 the calculation of similarities between all pairs and combinations in a batch is illustrated. For the AV task the cosine similarities between same authors pairs are expected to be positive real numbers and equal to 1 (ideal scenario) and lower or negative values with minimum value equal to -1 for the different authors pairs. Cosine similarity have values between [-1,1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,72.08,466.85,419.63,10.80;5,72.00,293.49,387.65,170.55"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Dot Product on normalized Embeddings calculation for all combinations in a batch.</figDesc><graphic coords="5,72.00,293.49,387.65,170.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,72.08,244.67,284.34,127.31"><head>Table 1 :</head><label>1</label><figDesc>Threshold values for 2 different runs on test set in Tira.</figDesc><table coords="6,78.08,259.40,242.31,112.58"><row><cell>Method</cell><cell>Threshold 1 st run</cell><cell>Threshold 2 nd</cell></row><row><cell></cell><cell></cell><cell>run</cell></row><row><cell>Model Email vs</cell><cell>0.697</cell><cell>0.71</cell></row><row><cell>Essay</cell><cell></cell><cell></cell></row><row><cell>Model Interview</cell><cell>0.67</cell><cell>0.65</cell></row><row><cell>vs Speech</cell><cell></cell><cell></cell></row><row><cell>transcription</cell><cell></cell><cell></cell></row><row><cell>General Model</cell><cell>0.56</cell><cell>0.54</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,72.08,452.43,450.50,223.94"><head>Table 2</head><label>2</label><figDesc>Metrics and std on my custom unseen test set for three proposed models (written language model, speech language model and general model).</figDesc><table coords="6,78.08,495.05,358.02,181.32"><row><cell>Method</cell><cell>Accuracy</cell><cell>F1-score</cell><cell>AUC</cell><cell>C@1</cell></row><row><cell>Model Email vs</cell><cell>0.82(+/-0.03)</cell><cell>0.72(+/-0.05)</cell><cell>0.80</cell><cell>0.58</cell></row><row><cell>Essay (sub-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>model)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model Interview</cell><cell>0.87(+/-0.05)</cell><cell>0.72(+/-0.04)</cell><cell>0.81</cell><cell>0.58</cell></row><row><cell>vs Speech</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>transcription</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(sub-model)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>General Model</cell><cell>0.55 (+/-0.03)</cell><cell>0.51(+/-0.02)</cell><cell>0.48</cell><cell>0.49</cell></row><row><cell>(sub-model)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Final Model</cell><cell>0.70(+/-0.04)</cell><cell>0.68 (+/-0.04)</cell><cell>0.62</cell><cell>0.51</cell></row><row><cell>(Ensemble</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Figure 2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,72.08,137.20,436.86,179.16"><head>Table 3</head><label>3</label><figDesc>Metrics of 2 runs on Tira system with unseen test set.</figDesc><table coords="7,82.88,179.23,426.06,137.13"><row><cell>Method</cell><cell>AUC</cell><cell>C@1</cell><cell>F_05_u</cell><cell>F1-Score</cell><cell>brier</cell><cell>Overall</cell></row><row><cell></cell><cell></cell><cell></cell><cell>[19]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>clever-</cell><cell>0.525</cell><cell>0.516</cell><cell>0.55</cell><cell>0.624</cell><cell>0.743</cell><cell>0.591</cell></row><row><cell>daemon (1 st</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>run)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>graceful-</cell><cell>0.526</cell><cell>0.514</cell><cell>0.549</cell><cell>0.622</cell><cell>0.743</cell><cell>0.591</cell></row><row><cell>chianti (2 nd</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>run)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">It can be observed from Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,76.28,763.22,146.48,7.02"><p>https://fold.aston.ac.uk/handle/123456789/17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="6,76.28,754.22,62.10,7.02"><p>https://www.tira.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,93.70,701.12,428.74,9.72;7,93.70,713.33,429.75,10.15;7,93.70,726.35,307.37,9.72" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,216.83,713.33,300.92,9.91">Overview of the Authorship Verification Task at PAN 2023</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krzysztof</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Annina</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,93.70,726.35,144.39,9.72">CLEF 2023 Labs and Workshops</title>
		<imprint>
			<date type="published" when="2023-09">September 2023</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="7,93.70,738.95,429.56,9.72;7,93.70,751.57,252.19,9.72" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,205.50,738.95,317.76,9.72;7,93.70,751.57,61.50,9.72">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,93.70,74.87,428.69,9.72;8,93.70,87.50,166.05,9.72" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,207.81,74.87,245.31,9.72">Authorship verification: a review of recent advances</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,468.42,74.87,53.98,9.72;8,93.70,87.50,86.94,9.72">Research in Computing Science</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="9" to="25" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,100.09,429.10,9.72;8,93.70,112.70,166.43,9.72" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,209.18,100.09,313.62,9.72;8,93.70,112.70,19.33,9.72">Overview of the Cross-Domain Authorship Verification Task at PAN 2020</title>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">CLEF</note>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="8,93.70,125.32,429.29,9.72;8,93.70,137.50,429.63,10.15;8,93.70,150.12,429.15,10.15;8,93.70,163.75,307.37,9.72" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,301.50,137.50,221.83,9.91;8,93.70,150.12,60.54,9.91">Overview of the Authorship Verification Task at PAN 2022</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krzysztof</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Annina</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,93.70,163.75,144.39,9.72">CLEF 2023 Labs and Workshops</title>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023-09">September 2023</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="8,93.70,176.35,429.80,9.72;8,93.70,188.97,389.00,9.72" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,269.56,176.35,253.93,9.72;8,93.70,188.97,204.35,9.72">Character-level and multi-channel convolutional neural networks for large-scale authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ghaffari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Breslin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.06686</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,93.70,201.57,429.26,9.72;8,93.70,214.17,236.01,9.72" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kolossa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10105</idno>
		<title level="m" coord="8,338.85,201.57,184.11,9.72;8,93.70,214.17,49.56,9.72">Deep bayes factor scoring for authorship verification</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,93.70,226.79,429.59,9.72;8,93.70,239.40,134.04,9.72" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,336.27,226.79,178.51,9.72">Siamese Bert for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Tyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">CLEF</note>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="8,93.70,252.00,430.13,9.72;8,93.70,264.62,429.45,9.72;8,93.70,277.22,103.48,9.72" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,238.40,252.00,275.61,9.72">Similarity learning for authorship verification in social media</title>
		<author>
			<persName coords=""><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Benedikt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,93.70,264.62,429.45,9.72;8,93.70,277.22,41.33,9.72">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,289.85,366.63,9.72;8,93.70,302.45,337.04,9.72" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jafariakinabad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Hua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06786</idno>
		<title level="m" coord="8,225.60,289.85,234.73,9.72;8,93.70,302.45,152.06,9.72">A self-supervised representation learning of sentence structure for authorship attribution</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,93.70,315.64,429.03,9.72;8,93.70,328.27,298.35,9.72" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,263.25,315.64,259.48,9.72;8,93.70,328.27,145.76,9.72">Text-to-Text Transformer in Authorship Verification Via Stylistic and Semantical Analysis</title>
		<author>
			<persName coords=""><forename type="first">Maryam</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ehsan</forename><surname>Tavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,250.81,328.27,107.85,9.72">Proceedings of the CLEF</title>
		<meeting>the CLEF</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,340.87,429.94,9.72;8,93.70,353.47,429.02,9.72;8,93.70,366.10,404.35,9.72" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,294.57,340.87,220.81,9.72">A profile-based method for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">Nektaria</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,93.70,353.47,424.16,9.72">Artificial Intelligence: Methods and Applications: 8th Hellenic Conference on AI, SETN 2014</title>
		<meeting><address><addrLine>Ioannina, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">May 15-17, 2014. 2014</date>
		</imprint>
	</monogr>
	<note>Proceedings 8</note>
</biblStruct>

<biblStruct coords="8,93.70,378.69,429.46,9.72;8,93.70,391.29,428.76,9.72;8,93.70,403.92,429.43,9.72;8,93.70,416.52,288.76,9.72" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,305.92,378.69,217.24,9.72;8,93.70,391.29,50.03,9.72">An improved impostors method for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">Nektaria</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,154.35,391.29,368.11,9.72;8,93.70,403.92,280.28,9.72">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 8th International Conference of the CLEF Association, CLEF 2017</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">September 11-14, 2017. 2017</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,429.15,429.09,9.72;8,93.70,441.75,291.17,9.72" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<title level="m" coord="8,258.54,429.15,264.25,9.72;8,93.70,441.75,96.10,9.72">100 Idiolects -a corpus for research on individual variation across discourse types</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Aston University ; FoLD Repository</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,454.34,339.65,9.72;8,93.70,467.57,389.21,9.72;8,93.70,480.17,316.94,9.72" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,207.01,454.34,226.34,9.72;8,93.70,467.57,59.89,9.72">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,174.68,467.57,308.23,9.72;8,93.70,480.17,91.72,9.72">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,492.77,389.59,9.72;8,93.70,505.39,379.91,9.72;8,93.70,518.00,358.25,9.72" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,333.51,492.77,149.77,9.72;8,93.70,505.39,117.68,9.72">Similarity learning for authorship verification in social media</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kolossa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,233.40,505.39,240.21,9.72;8,93.70,518.00,224.24,9.72">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2457" to="2461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,530.60,429.54,9.72;8,93.70,543.22,429.66,9.72;8,93.70,555.82,230.92,9.72" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,286.72,543.22,180.46,9.72">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,474.79,543.22,48.57,9.72;8,93.70,555.82,130.10,9.72">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,568.45,315.53,9.72" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pe√±as</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<title level="m" coord="8,193.23,568.45,182.70,9.72">A simple measure to assess non-response</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,581.04,429.33,9.72;8,93.70,593.65,429.23,9.72;8,93.70,606.27,428.46,9.72;8,93.70,619.47,84.38,9.72" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,323.38,581.04,179.72,9.72">Generalizing unmasking for short texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,93.70,593.65,429.23,9.72;8,93.70,606.27,263.58,9.72">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="659" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="8,93.70,632.07,428.80,9.72;8,93.70,644.69,355.91,9.72" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,180.44,632.07,274.41,9.72">Continuous integration for reproducible shared tasks with TIRA</title>
		<author>
			<persName coords=""><forename type="first">Maik</forename><surname>Fr√∂be</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,481.11,632.07,41.40,9.72;8,93.70,644.69,161.51,9.72">European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Cham; Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,657.19,429.97,9.83;8,93.70,669.90,179.60,9.72" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,296.62,657.19,218.37,9.83">Fast hard negative mining for deep metric learning</title>
		<author>
			<persName coords=""><forename type="first">Bojana</forename><surname>Gajiƒá</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ariel</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,93.70,669.90,88.14,9.72">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page">107795</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,93.70,682.52,428.67,9.72;8,93.70,695.12,114.30,9.72" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="8,188.25,682.52,256.44,9.72">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,93.70,707.75,409.20,9.72" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="8,190.52,707.75,270.68,9.72">Improving language understanding by generative pre-training</title>
		<author>
			<persName coords=""><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
