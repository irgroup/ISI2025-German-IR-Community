<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.32,327.40,16.17;1,89.29,106.24,91.59,16.17;1,88.90,130.81,168.58,10.37">Using BERT to Profiling Cryptocurrency Influencers (Notebook for PAN at CLEF 2023)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.71,109.33,10.37"><forename type="first">Daniel</forename><forename type="middle">Yacob</forename><surname>Espinosa</surname></persName>
							<email>espinosagonzalezdaniel@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,209.79,156.71,75.87,10.37"><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
							<email>sidorov@cic.ipn.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación en Computación</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.32,327.40,16.17;1,89.29,106.24,91.59,16.17;1,88.90,130.81,168.58,10.37">Using BERT to Profiling Cryptocurrency Influencers (Notebook for PAN at CLEF 2023)</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">49A325DD84AB881F312254148EDC9AF2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BERT</term>
					<term>Cryptocurrency Influencers</term>
					<term>Tweets</term>
					<term>Twitter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, the rise of influential individuals in cryptocurrencies on social media has played a significant role both on the internet and in investments. One of the major challenges in this area is determining which users are experts or influencers who can directly contribute to the value of cryptocurrencies. In this instance, PAN 2023 created the task "Profiling Cryptocurrency Influencers with Few-shot Learning" in which we are participating <ref type="bibr" coords="1,227.45,266.45,9.47,7.77" target="#b0">[1]</ref>. Our solution approach for this task involves using the BERT model with a preprocessing layer, where we achieved classification results with over 92% precision for all three subtasks included in this challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Since the emergence and popularity of Bitcoin in 2009 <ref type="bibr" coords="1,327.99,392.10,14.16,9.46" target="#b1">[2]</ref>, new ways of conducting commerce have arisen. Similarly, the internet has played a significant role in making this cryptocurrency popular worldwide. In this case, we are primarily referring to social media networks. As we have seen in recent years, social media has been a very useful mechanism for communication, whether it's for viralizing content such as videos or photos, or for staying informed about world news. Therefore, to promote the growth of this new way of conducting commerce, it is undoubtedly a good approach to encourage investments in a new market. As we come to understand, the value of cryptocurrencies is not regulated like traditional currency, and much of their value depends on the demand from investors, which can be used to create a "bubble" in their value <ref type="bibr" coords="1,442.48,500.49,11.59,9.46" target="#b2">[3]</ref>.</p><p>Many of the top cryptocurrency influencers are investors or creators themselves. One example is Vitalik Buterin, who is the creator of Ethereum <ref type="bibr" coords="1,317.95,527.59,11.74,9.46" target="#b3">[4]</ref>, which is one of the most well-known cryptocurrencies worldwide. We can see that Vitalik has a deep understanding of cryptocurrencies and blockchain, making him an influencer in this field. With his comments on social media, he can contribute to or harm the value of his cryptocurrency in the market. Due to the free use of social media and the ability for anyone to express their opinions on any topic, it becomes difficult to determine who truly has influence and the impact they can have on their community. Financial bubbles, mainly driven by speculation, can rise or fall based on societal speculation on social media <ref type="bibr" coords="2,118.68,101.60,11.59,9.46" target="#b2">[3]</ref>.</p><p>On this occasion, PAN has decided to launch the task "Profiling Cryptocurrency Influencers with Few-shot Learning" where it proposes a series of influencer profiling and other classifications with limited training data <ref type="bibr" coords="2,205.41,142.24,12.86,9.46" target="#b4">[5]</ref>  <ref type="bibr" coords="2,221.28,142.24,11.74,9.46" target="#b0">[1]</ref>. To solve this task, we decided to use the BERT model with different text configurations, which we will detail later on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Corpus</head><p>To solve this task, PAN introduced a corpus that is divided into three subtasks to classify:</p><p>1. For the first subtask, there are 160 users with the following classifications: non-influencer, nano, micro, mega, and macro.</p><p>2. In the second subtask, we have 320 users with the following classifications: technical information, price update, trading matters, gaming, and other.</p><p>3. For the last subtask, we have a total of 256 users with the following classifications: subjective opinion, financial information, advertising, and announcement. The complexity of this task lies in the number of samples. In this case, we have one tweet to perform the classification of each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Regarding Twitter, in previous tasks, we had been using different classifiers and methods to profile users for different tasks. For example, in PAN 2019 <ref type="bibr" coords="2,344.29,411.19,11.45,9.46" target="#b5">[6]</ref>, we used an N-gram configuration with various classifiers such as RandomForest, SVM, and LinearSVM, but we had much more data for the classifications <ref type="bibr" coords="2,205.27,438.29,12.33,9.46" target="#b6">[7]</ref>. Due to this, we decided to use BERT <ref type="bibr" coords="2,395.73,438.29,11.74,9.46" target="#b7">[8]</ref>, with a small amount of training data, methods that incorporate "Attention" are assumed to be the most suitable for finding a solution <ref type="bibr" coords="2,164.24,465.39,12.65,9.46" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pre-processing steps</head><p>As in every text-related task, we always recommend using a preprocessing layer before directly using the models. The use of preprocessing on the data helps transform, clean, and prepare it for analysis or modeling. This helps improve the data quality and facilitates its use in algorithms and models.</p><p>The next configuration is using for the three subtasks:</p><p>Lowercase Were transform all tweets into lowercase to standardize the texts for the model.</p><p>Links were changed by the label 'link' within the data.</p><p>User Mentions are changed by the 'usermention' label that the tweets contain.</p><p>Hashtags the 'hashtag' label was modified and placed.</p><p>Emojis The emojis were modified and the label 'emoji' was placed.</p><p>Other symbols The symbols that are not registered within the ASCI reference standard are eliminated within the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In the past task, we used N-gram structures, used N-grams of words and N-grams of characters, mainly for tasks that involved social networks, since they showed outstanding results with this type of arrangement.The results of these experiment are in the Table <ref type="table" coords="3,403.61,269.52,5.45,9.81" target="#tab_0">1</ref> and Table <ref type="table" coords="3,461.05,269.52,4.12,9.81">2</ref>. All the results obtained in this work were tested with Accuracy except Table <ref type="table" coords="3,397.70,283.07,5.45,9.81">5</ref> where show the results with F1 because this is the metric which PAN evaluates the results <ref type="bibr" coords="3,377.40,297.04,11.98,9.46" target="#b0">[1]</ref>.</p><p>Since the results with the combination of Ngrams did not have the expected precision, it was thought to implement another model to carry out the profiling.</p><p>In PAN 2022 <ref type="bibr" coords="3,153.29,337.69,18.70,9.46" target="#b9">[10]</ref>, Wang Bin <ref type="bibr" coords="3,224.46,337.69,18.03,9.46" target="#b10">[11]</ref> used BERTweet <ref type="bibr" coords="3,315.72,337.69,18.03,9.46" target="#b11">[12]</ref> obtaining a result close to 95% accurate with this methodology, so he experimented with it, Table <ref type="table" coords="3,341.27,350.81,5.45,9.81" target="#tab_2">3</ref> shows the results.</p><p>Although the results with BERTweet were better, we decided to test with the BERT configuration as we wanted to compare a similar model across all three subtasks. We used a batch size configuration of 16. Previously, we used 32, but with a batch size of 32 and 8 epochs, it required more than 22 GB of GPU memory.</p><p>All our experiments were conducted using GPU to accelerate processing and enable parallelization of the processes. Furthermore, by reducing the batch size, we were able to add an extra epoch, significantly reducing GPU consumption while maintaining precision at a very similar level. Both the BERTweet and BERT results were obtained using 9 epochs, and with this configuration, we achieved the best results without overfitting the models. The results we chose to participate with were from the BERT model, and the results for all three subtasks are shown in Table <ref type="table" coords="4,413.69,519.22,4.09,9.81">4</ref>.</p><p>Regarding the results using BertTweet, which were not as expected, we tried other BERT configurations to see if we could improve the results. Therefore, we used three more variations: DistilBERT <ref type="bibr" coords="4,137.55,560.30,19.30,9.46" target="#b12">[13]</ref>, RoBERTa Liu et al. <ref type="bibr" coords="4,252.87,560.30,16.72,9.46" target="#b13">[14]</ref>, and TinyBERT <ref type="bibr" coords="4,336.95,560.30,20.98,9.46" target="#b14">[15]</ref>.</p><p>As shown in Table <ref type="table" coords="4,189.09,573.42,4.12,9.81" target="#tab_3">6</ref>, the results with DistilBERT and TinyBERT were very close but not the best for the task. On the other hand, with RoBERTa, the results improved compared to BERT, but they were not outstanding either. The issue with RoBERTa was the time and resource requirements. With BERT and the mentioned hyperparameters, the training took around 45 minutes. In contrast, with RoBERTa, it took approximately 4 hours and 40 minutes. These tests were performed using a 13 GB GPU. Consequently, we decided not to use RoBERTa because we did not consider its results to be significantly better than BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>Given the mechanism of BERT, it is a powerful option for tweet classification due to its ability to understand context and utilize attention, which can be highly beneficial when there is limited training data. These combined advantages can significantly enhance the accuracy and classification capability of tweets. Despite the challenge of training with limited data, it is interesting and useful that models work with these characteristics since data collection can be costly and, in some cases, difficult. This makes machine learning more straightforward and accessible, allowing for faster adaptation to the real world.</p><p>An outstanding observation from these experiments was the use of BERTweet <ref type="bibr" coords="5,467.21,207.73,18.32,9.46" target="#b11">[12]</ref> and BERT <ref type="bibr" coords="5,111.01,221.28,16.29,9.46" target="#b7">[8]</ref>. Although both models are based on the Transformer architecture, they were trained on different datasets, highlighting their distinct approaches. While the accuracy of BERTweet was not bad, we definitely preferred using BERT as it demonstrated better precision with limited data. These findings are highly interesting, and in our opinion, they should be utilized in other experiments.</p><p>The use of social media is filled with opinions, highlighting the importance of learning who shares the truth. In the case of cryptocurrency influencers, they can be a reliable source of information, but the challenge lies in knowing who is truly an expert or a trustworthy person on the internet. These types of experiments promote the use of truth on social media, although when it comes to investments, it is best to seek advice and assistance from a professional in the field before investing or making decisions on these matters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.98,459.79,114.60,21.31"><head>Table 1</head><label>1</label><figDesc>Results of combinations N</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,88.98,471.75,332.13,189.37"><head>-grams character accuracy</head><label></label><figDesc></figDesc><table coords="3,88.98,487.31,332.13,173.80"><row><cell cols="4">N-grams character subtask1 subtask2 subtask3</cell></row><row><cell>2-3-4-5-9</cell><cell>61.22</cell><cell>63.12</cell><cell>61.98</cell></row><row><cell>3-4-5-9</cell><cell>62.45</cell><cell>62.91</cell><cell>62.38</cell></row><row><cell>5-7-8-9</cell><cell>64.37</cell><cell>65.74</cell><cell>64.40</cell></row><row><cell>8-9</cell><cell>71.21</cell><cell>71.95</cell><cell>72.06</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Results of combinations N-grams words accuracy</cell><cell></cell><cell></cell></row><row><cell cols="4">N-grams words subtask1 subtask2 subtask3</cell></row><row><cell>2-3-4-5-9</cell><cell>71.87</cell><cell>72.90</cell><cell>71.99</cell></row><row><cell>3-4-5-9</cell><cell>81.25</cell><cell>83.02</cell><cell>82.76</cell></row><row><cell>5-7-8-9</cell><cell>80.30</cell><cell>81.07</cell><cell>82.28</cell></row><row><cell>8-9</cell><cell>82.71</cell><cell>83.99</cell><cell>83.54</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.98,90.03,363.55,257.86"><head>Table 3</head><label>3</label><figDesc>Results of BERTweet accuracy with and without preprocessing layer</figDesc><table coords="4,88.98,117.55,363.55,230.34"><row><cell>task</cell><cell cols="2">without preprocessing layer with preprocessing layer</cell></row><row><cell>subtask 1</cell><cell>86.21</cell><cell>86.98</cell></row><row><cell>subtask 2</cell><cell>87.12</cell><cell>88.76</cell></row><row><cell>subtask 3</cell><cell>90.14</cell><cell>92.33</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell></row><row><cell cols="2">Results of BERT accuracy with and without preprocessing layer</cell><cell></cell></row><row><cell>task</cell><cell cols="2">without preprocessing layer with preprocessing layer</cell></row><row><cell>subtask 1</cell><cell>89.34</cell><cell>92.34</cell></row><row><cell>subtask 2</cell><cell>93.21</cell><cell>95.44</cell></row><row><cell>subtask 3</cell><cell>95.88</cell><cell>96.94</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell></row><row><cell cols="2">Results of BERT F1 with and without preprocessing layer</cell><cell></cell></row><row><cell>task</cell><cell cols="2">without preprocessing layer with preprocessing layer</cell></row><row><cell>subtask 1</cell><cell>79.02</cell><cell>86.77</cell></row><row><cell>subtask 2</cell><cell>81.33</cell><cell>83.44</cell></row><row><cell>subtask 3</cell><cell>81.54</cell><cell>85.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,88.98,367.10,370.99,73.14"><head>Table 6</head><label>6</label><figDesc>Results of DistilBERT, TinyBERT and RoBERTa accuracy with preprocessing layer</figDesc><table coords="4,186.28,394.63,219.12,45.62"><row><cell>task</cell><cell cols="3">DistilBERT TinyBERT RoBERTa</cell></row><row><cell>subtask 1</cell><cell>83.29</cell><cell>75.21</cell><cell>93.14</cell></row><row><cell>subtask 2</cell><cell>85.12</cell><cell>76.84</cell><cell>95.61</cell></row><row><cell>subtask 3</cell><cell>85.98</cell><cell>77.23</cell><cell>97.03</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,112.92,416.73,386.27,9.46;5,112.92,430.28,393.06,9.46;5,112.41,443.83,158.95,9.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,461.00,416.73,38.19,9.46;5,112.92,430.28,255.58,9.46">Profiling Cryptocurrency Influencers with Few shot Learning at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,413.93,430.28,92.05,9.46;5,112.41,443.83,46.39,9.46">CLEF 2022 Labs and Workshops</title>
		<title level="s" coord="5,166.68,443.83,72.88,9.46">Notebook Papers</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.92,457.37,376.47,9.46;5,112.92,470.92,277.46,9.46;5,112.92,484.47,183.34,9.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,274.95,457.37,209.94,9.46">Cryptocurrency: A new investment opportunity?</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L W Y</forename><surname>Kuo Chuen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename><surname>David</surname></persName>
		</author>
		<idno type="DOI">10.3905/jai.2018.20.3.016</idno>
		<ptr target="https://ink.library.smu.edu.sg/lkcsb_research/5784.doi:10.3905/jai.2018.20.3.016" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.92,498.02,389.91,9.46;5,112.92,511.57,393.03,9.46;5,112.92,525.12,339.32,9.46;5,112.92,538.67,393.06,9.46;5,112.92,552.22,276.06,9.46;5,112.92,565.77,201.40,9.46;5,112.92,579.32,223.11,9.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,402.33,498.02,100.51,9.46;5,112.92,511.57,317.24,9.46">Cryptocurrency bubble detection: A new stock market dataset, financial task &amp; hyperbolic models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.405</idno>
		<ptr target="https://aclanthology.org/2022.naacl-main.405.doi:10.18653/v1/2022.naacl-main.405" />
	</analytic>
	<monogr>
		<title level="m" coord="5,453.59,511.57,52.36,9.46;5,112.92,525.12,339.32,9.46;5,112.92,538.67,393.06,9.46;5,112.92,552.22,46.95,9.46">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5531" to="5545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.92,592.87,390.12,9.46;5,112.92,606.42,201.98,9.46;5,112.92,619.96,263.96,9.46" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Buterin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<ptr target="https://books.google.com.mx/books?id=hWpVEAAAQBAJ" />
		<title level="m" coord="5,225.00,592.87,278.04,9.46;5,112.92,606.42,51.94,9.46">Proof of Stake: The Making of Ethereum and the Philosophy of Blockchains</title>
		<imprint>
			<publisher>Seven Stories Press</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.92,633.51,364.89,9.46;5,112.53,647.06,394.82,9.46;5,112.92,660.61,382.54,9.46;6,112.53,88.05,386.48,9.46;6,112.92,101.60,322.43,9.46;6,112.92,115.14,368.78,9.46;6,112.92,128.69,392.92,9.46;6,112.92,142.24,393.06,9.46;6,112.92,155.79,164.09,9.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,337.47,660.61,157.99,9.46;6,112.53,88.05,386.48,9.46;6,112.92,101.60,94.17,9.46">Overview of PAN 2023: Authorship Verification, Multi-Author Writing Style Analysis, Profiling Cryptocurrency Influencers, and Trigger Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Borrego-Obrador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chinea-Ríos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Heini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kredens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pęzik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,112.92,128.69,392.92,9.46;6,112.92,142.24,299.15,9.46">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="6,445.30,142.24,60.68,9.46;6,112.92,155.79,89.65,9.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="6,112.92,169.34,389.06,9.46;6,112.92,182.89,374.07,9.46;6,112.92,196.44,240.93,9.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,203.56,169.34,142.75,9.46">CLEF 2019 Labs and Workshops</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,198.67,182.89,288.33,9.46;6,112.92,196.44,208.98,9.46">Overview of the 7th Author Profiling Task at PAN 2019: Bots and Gender Profiling, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">N</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">H</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="6,112.92,209.99,384.83,9.46;6,112.92,223.54,387.27,9.46;6,112.41,237.09,388.52,9.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,312.01,209.99,185.74,9.46;6,112.92,223.54,34.74,9.46">Bots and Gender Profiling using Character Bigrams</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Espinosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/" />
	</analytic>
	<monogr>
		<title level="m" coord="6,406.56,223.54,93.63,9.46;6,112.41,237.09,46.39,9.46">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="6,166.68,237.09,103.09,9.46">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,250.64,378.92,9.46;6,112.92,264.19,317.41,9.46" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="6,321.51,250.64,170.32,9.46;6,112.92,264.19,175.35,9.46">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,277.74,363.98,9.46;6,112.92,291.28,311.09,9.46" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m" coord="6,176.56,291.28,105.33,9.46">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,304.83,376.24,9.46;6,112.92,318.38,394.58,9.46;6,112.92,331.93,177.61,9.46" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,359.33,304.83,129.83,9.46;6,112.92,318.38,287.37,9.46">Profiling irony and stereotype spreaders on twitter (irostereo). overview for pan at clef 2022, ???</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Bueno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-3180/#paper-185" />
		<imprint>
			<biblScope unit="page" from="2314" to="2343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,345.48,392.95,9.46;6,112.92,359.03,278.70,9.46" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hui</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-225.pdf" />
		<title level="m" coord="6,185.18,345.48,320.69,9.46;6,112.92,359.03,26.93,9.46">Notebook for pan at clef 2022:profiling irony and stereotype spreaders on twitter</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,372.58,375.37,9.46;6,112.92,386.13,391.20,9.46;6,112.92,399.68,394.28,9.46;6,112.92,413.23,335.04,9.46;6,112.92,426.78,216.56,9.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,288.03,372.58,200.26,9.46;6,112.92,386.13,62.29,9.46">BERTweet: A pre-trained language model for English tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Tuan</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.2</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-demos.2.doi:10.18653/v1/2020.emnlp-demos.2" />
	</analytic>
	<monogr>
		<title level="m" coord="6,198.41,386.13,305.71,9.46;6,112.92,399.68,390.05,9.46">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,440.33,380.97,9.46;6,112.92,453.87,252.49,9.46" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m" coord="6,297.48,440.33,196.41,9.46;6,112.92,453.87,111.19,9.46">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,467.42,380.60,9.46;6,112.53,480.97,334.07,9.46;6,112.92,495.55,107.45,7.68" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="6,170.14,480.97,244.44,9.46">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,508.07,385.13,9.46;6,112.92,521.62,312.26,9.46" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.10351</idno>
		<title level="m" coord="6,413.39,508.07,84.67,9.46;6,112.92,521.62,170.20,9.46">Tinybert: Distilling bert for natural language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
