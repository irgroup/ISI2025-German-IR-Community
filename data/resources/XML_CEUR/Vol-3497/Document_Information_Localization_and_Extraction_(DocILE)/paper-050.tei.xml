<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,353.45,15.42;1,89.29,106.66,315.04,15.42;1,89.29,129.00,210.20,11.96">RoBERTa Ensemble Technique for Document Information Localization and Extraction Notebook for the DocILE Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,64.68,11.96"><forename type="first">Bao</forename><forename type="middle">Gia</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.61,154.90,74.46,11.96"><forename type="first">Duy-Ngo</forename><surname>Minh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.22,154.90,52.30,11.96"><forename type="first">Gia</forename><surname>Khanh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.51,154.90,16.62,11.96"><surname>Bui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.78,154.90,80.58,11.96"><forename type="first">Huy</forename><forename type="middle">Viet</forename><surname>Duong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,168.85,46.72,11.96"><forename type="first">Hai</forename><surname>Dang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,139.00,168.85,38.57,11.96"><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.56,168.85,94.39,11.96"><forename type="first">Hieu</forename><forename type="middle">Minh</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Information Technology -VNUHCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,353.45,15.42;1,89.29,106.66,315.04,15.42;1,89.29,129.00,210.20,11.96">RoBERTa Ensemble Technique for Document Information Localization and Extraction Notebook for the DocILE Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">6E4A5F7E797E1B5C190C66EBC7496DD1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>DocILE</term>
					<term>RoBERTa</term>
					<term>Ensemble</term>
					<term>Pseudo-Labeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Document Information Localization and Extraction (DocILE) is attracting a large amount of attention from the research community due to its potential to significantly reduce manual work. With the explosive growth of technology as they are today, we want to experiment with a method that leverages the advantages of language models in information extraction since it requires an understanding of the contextual information of the text, which large language models are currently successful on. The experiments include using a new combination of published baseline with our model ùëÖùëúùêµùê∏ùëÖùëá ùëé, along with a post-processing step, which helped us achieve a Top 3 position in the competition ranking board.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Extracting information from documents is an indispensable part of human activities in the modern era. However, manual information extraction is time-consuming and labor-intensive. Therefore, automating the process of extracting information has gained much attention from the research community as it has high applicability in reducing workload for workers in manual tasks and creating opportunities for them to focus more on strategic work.</p><p>The information extraction process is challenged since it requires an understanding of the semantics, layout, and context of content in the documents. In Machine Learning (ML), the scope of addressing this issue is called Document Information Extraction (IE), a part of Document Understanding.</p><p>DocILE 2023 <ref type="bibr" coords="1,157.25,524.44,12.69,10.91" target="#b0">[1]</ref>[2] is a competition for extracting information from business documents. The participating teams will receive a dataset of invoice-like documents such as tax invoices, orders, purchase orders, receipts, sales orders, proforma invoices, credit notes, utility bills, and debit notes <ref type="bibr" coords="1,115.54,565.09,11.28,10.91" target="#b0">[1]</ref>. In Track 1, also known as KILE (Key Information Localization and Extraction), participants were challenged to develop algorithms that can locate and extract specific information such as names, dates, addresses, .. or any other key data from a given document.</p><p>The pipeline to localize Key Information and extract them is built upon the provided baselines for the DocILE competition, and we acknowledge their contributions <ref type="bibr" coords="2,406.86,114.06,11.58,10.91" target="#b0">[1]</ref>. At first, the input data is a set of PDF pages containing invoices processed using DocTR <ref type="bibr" coords="2,415.67,127.61,11.58,10.91" target="#b2">[3]</ref>, from which the bounding boxes and content of the information are obtained. Afterward, they classify those content using Token Classification models. Finally, they merge content based on their field type. The flowchart is shown in Figure <ref type="figure" coords="2,239.02,168.26,3.74,10.91" target="#fig_0">1</ref>. Our focus lies in optimizing their pipeline. Specifically, we leverage different versions of ùëÖùëúùêµùê∏ùëÖùëá ùëé -a large language model that is used to achieve state-of-the-art results on GLUE, RACE, and SQuAD in Natural Language Processing <ref type="bibr" coords="2,317.45,427.56,11.29,10.91" target="#b3">[4]</ref>, i.e. two provided baseline RoBERTa <ref type="bibr" coords="2,493.29,427.56,12.70,10.91" target="#b4">[5]</ref> and one RoBERTa trained by us -together with a post-processing step. After that, we use it to generate pseudo-label datasets from provided unlabeled dataset and re-train our models on that, which showed a relatively good result. Our pipeline is shown in Figure <ref type="figure" coords="2,427.67,468.21,3.70,10.91" target="#fig_1">2</ref>. We will discuss each component in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Ensemble</head><p>After evaluating several models provided, we see that one model only performs well in certain categories while the opposite thing happens for the other models. This leads us to the idea of using Ensemble <ref type="bibr" coords="2,161.99,588.29,11.43,10.91" target="#b5">[6]</ref>.</p><p>We first implement Ensemble using Average and Max Voting <ref type="bibr" coords="2,363.03,601.84,12.68,10.91" target="#b5">[6]</ref> since they are two of the most common methods. However, the results acquired show a relatively high score precision while the recall is not significant, which means that the models provide fairly accurate predictions but the proportion of positive samples missed in the dataset is quite large.</p><p>From the concept of affirmative ensemble presented in prior research <ref type="bibr" coords="2,423.08,656.03,11.58,10.91" target="#b6">[7]</ref>, we decided to incorporate this concept into our problem as a method to address the aforementioned issues. Specifically, if any of the models predict that certain content belongs to a particular field type, we consider that content to actually belong to that field type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pseudo-labeling</head><p>In this task, we are provided an abnormally huge amount of unlabeled data compared to the small amount of labeled data <ref type="bibr" coords="3,218.90,669.58,11.35,10.91" target="#b0">[1]</ref>. We believe that utilizing this unlabeled data will improve the performance of the models. This leads us to the idea of using semi-supervised learning methods.</p><p>Pseudo-Labeling <ref type="bibr" coords="4,175.82,100.52,12.74,10.91" target="#b7">[8]</ref> is a more effective method compared to other methods such as <ref type="bibr" coords="4,469.16,100.52,11.33,10.91" target="#b8">[9]</ref>, <ref type="bibr" coords="4,487.00,100.52,16.14,10.91" target="#b9">[10]</ref>, and <ref type="bibr" coords="4,108.44,114.06,16.25,10.91" target="#b10">[11]</ref>. We propose a different way to implement this technique for our models:</p><p>1. Models will be trained on the Train (annotated) dataset. 2. We use the Ensemble technique with Post-processing to predict labels for the unlabeled dataset, which is then called as pseudo-labeled dataset. 3. Train the model on the pseudo-labeled dataset for some epochs. 4. Fine-tune the model on the Train dataset.</p><p>Here, we train the model on the pseudo-labeled dataset instead of mixing it with the labeled dataset, because it is a dataset that we have little control over, and it may contain cases that are completely different from the training dataset. Training the model on the pseudo-labeled dataset for some epochs helps the model approach more types of data, thereby learning general features. Then, we fine-tune the model on the training dataset to learn the correct features for each specific problem, helping the model improve its effectiveness on that problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Post processing</head><p>The models we use struggle in distinguishing information that have the same field type but is a bit far apart. This leads to the problem that even though the information belongs to the same field type and the same bounding box, the model predicts it as multiple different bounding boxes. Moreover, after observing the prediction results compared to the ground truth, and experimenting on various documents, we found that it is rare for information of the same field type to be close to each other on the same document.</p><p>We first find the distance between the centers of each pair of bounding boxes belonging to the same field type predicted by the model. Then, we experiment with grouping these bounding boxes on different thresholds. For each pair of bounding boxes of information belonging to the same field type, if their Euclidean distance is below or equal to the threshold, we will merge those two bounding boxes into a new one, its coordinate is calculated by using formula <ref type="bibr" coords="4,493.41,465.26,10.69,10.91" target="#b0">(1)</ref>. How the Post-processing work is shown in Figure <ref type="figure" coords="4,314.44,478.81,3.74,10.91" target="#fig_2">3</ref>.</p><formula xml:id="formula_0" coords="4,114.89,512.51,391.75,14.77">ùëì ùëñùëõùëéùëô = (min(ùë• left ; ùë• ‚Ä≤ left ), min(ùë¶ top ; ùë¶ ‚Ä≤ top ), max(ùë• right ; ùë• ‚Ä≤ right ), max(ùë¶ bottom ; ùë¶ ‚Ä≤ bottom ))<label>(1)</label></formula><p>By doing this, we can reduce the number of false bounding boxes predicted by the model and improve the accuracy of the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>We maintain the same dataset partitioning as provided by the organizer, with the information of each dataset used for the Training, Validating, and Testing processes as described in Table <ref type="table" coords="4,500.19,642.48,3.70,10.91" target="#tab_0">1</ref>.</p><p>Most experiments below were conducted on an environment consisting of 4 RTX 2080 Ti 12GB GPUs, along with the following selected parameters and hyperparameters:  At the same time, we use the validation set to evaluate the model and compare the performance between different models based on the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Model</head><p>We use 3 ùëÖùëúùêµùê∏ùëÖùëá ùëé models, 2 published baseline models <ref type="bibr" coords="5,348.81,512.21,12.74,10.91" target="#b4">[5]</ref> trained on the Synthetic + Train dataset, and the remaining model is taken directly from HuggingFace <ref type="bibr" coords="5,409.55,525.76,16.41,10.91" target="#b11">[12]</ref>. We will refer to these models with different names for easy distinction as follows:</p><p>‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏: baseline ùëüùëúùëèùëíùëüùë°ùëé_ùëèùëéùë†ùëí_ùë§ùëñùë°‚Ñé_ùë†ùë¶ùëõùë°‚Ñéùëíùë°ùëñùëê_ùëùùëüùëíùë°ùëüùëéùëñùëõùëñùëõùëî ‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ: baseline ùëüùëúùëèùëíùëüùë°ùëé_ùëúùë¢ùëüùë†_ùë§ùëñùë°‚Ñé_ùë†ùë¶ùëõùë°‚Ñéùëíùë°ùëñùëê_ùëùùëüùëíùë°ùëüùëéùëñùëõùëñùëõùëî ‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ: the model was not trained on any DocILE dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Fast Gradient Method</head><p>For Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ, we fine-tune it from RoBERTa <ref type="bibr" coords="5,341.32,642.48,18.07,10.91" target="#b11">[12]</ref> using the Fast Gradient Method (FGM) <ref type="bibr" coords="5,120.66,656.03,18.06,10.91" target="#b12">[13]</ref> technique on the Synthetic dataset with 30 epochs and on the Train dataset with 500 epochs. The result obtained as shown in Table <ref type="table" coords="5,318.61,669.58,3.79,10.91" target="#tab_1">2</ref>, which is similar to the baseline but this technique helps the model to be more generalized <ref type="bibr" coords="6,311.26,86.97,16.15,10.91" target="#b12">[13]</ref>, so we still keep and apply it with other methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Lion Optimizer</head><p>For all 3 models, we replaced the default optimizer, from AdamW to Lion Optimizer <ref type="bibr" coords="6,89.29,279.83,18.07,10.91" target="#b13">[14]</ref> and trained for an additional 300 epochs on the Train dataset. However, only Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ showed significant improvement, while the other models are mostly unchanged. Nevertheless, we will still use Lion Optimizer for the methods below because it seems to converge much faster than AdamW. Table <ref type="table" coords="6,329.48,320.48,5.07,10.91" target="#tab_2">3</ref> shows the results obtained. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Ensemble</head><p>We perform Ensemble using different methods:</p><p>‚Ä¢ Average Ensemble <ref type="bibr" coords="6,200.97,511.75,12.84,10.91" target="#b5">[6]</ref> ‚Ä¢ Max-Voting Ensemble <ref type="bibr" coords="6,217.04,526.65,12.84,10.91" target="#b5">[6]</ref> ‚Ä¢ Affirmative Ensemble <ref type="bibr" coords="6,215.41,541.56,12.84,10.91" target="#b6">[7]</ref> For each method, we ensemble the following models:</p><p>‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ trained with FGM technique and Lion Optimizer ‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ trained with Lion Optimizer ‚Ä¢ Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏ without any changes Table <ref type="table" coords="6,125.63,641.90,4.97,10.91" target="#tab_3">4</ref> demonstrates that Affirmative Ensemble produces significantly better results compared to commonly used methods like Max-Voting and Average. Therefore, we will employ the Affirmative Ensemble technique on our three models to predict the output. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Post-Processing</head><p>We performed the Post-Processing method mentioned in Section 2.3, on the predicted output of each of the 3 models with different percentage thresholds of the document width. E.g. For a document with a width is 2000px, the 14.5% threshold means that it will merge two bounding boxes whose distance is below 14.5% of 2000px or 290px. As shown in Table <ref type="table" coords="7,185.83,473.51,3.76,10.91" target="#tab_4">5</ref>, the threshold of 14.5% of the document width gives the highest result when evaluated on the validation set. From now on, we will use 14.5% as the default threshold. Combining this Post Processing method with the methods we mentioned in Section 2 significantly improves the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Pseudo-Labeling</head><p>Due to the large number of documents, we will do this technique on each chunk from provided chunks dataset. Starting with the chunk 0 dataset, we pre-process it as follows:</p><p>‚Ä¢ Remove documents belonging to clusters = -1, i.e., documents whose layouts do not appear in the Train dataset. ‚Ä¢ Remove documents too big, i.e. documents with a size larger than 3000 pixels in any dimension. ‚Ä¢ Remove rotated documents. We then ensemble the 3 models trained on the Train dataset, combining with the Post Processing. Afterward, we predict on the unlabeled chunk 0 dataset to generate pseudo annotations for that, which we call pseudo 0 . After that, we train 3 models on this dataset with the following hyperparameters:</p><p>‚Ä¢ Epoch: 30 ‚Ä¢ Learning Rate: 1e-5</p><p>Later, we use the Train dataset to train all 3 models more with the following hyperparameters:</p><p>‚Ä¢ Epoch: 300 ‚Ä¢ Learning rate: 5e-6 The addition of Pseudo-Labeling slightly improved our results as shown in Table <ref type="table" coords="8,455.28,602.18,3.66,10.91" target="#tab_5">6</ref>. However, this method was implemented when the competition was in its final days, which only allowed us to perform it on one chunk of data. Nevertheless, we believe that continuing to use the remaining chunks will continue to improve the final results.   Table <ref type="table" coords="9,126.36,417.43,4.97,10.91" target="#tab_8">8</ref> shows our performance of 3 models with the Ensemble Method, they are trained with and without the Pseudo-Labeling technique. From the predicted result, we do Post-Processing and evaluate them on the validation dataset. Overall, our results increased significantly compared to the baseline, +0.082 on the Valset and +0.073 on the Testset, which is shown in Table <ref type="table" coords="9,317.06,587.64,3.68,10.91" target="#tab_9">9</ref>. However, we believe there are still many things we can do to further improve the results:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Result</head><p>‚Ä¢ Use more unlabeled data. Currently, only a very small fraction (10k out of almost 1M) of the unlabeled data was used. ‚Ä¢ Use models incorporating layout features such as LayoutLMv3, LiLT, etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have presented a solution for the tasks required in Track 1 KILE of DocILE 2023. Our improvements to the baseline <ref type="bibr" coords="10,264.99,224.93,12.69,10.91" target="#b4">[5]</ref> have demonstrated their effectiveness. This result is significantly higher than the initial performance and demonstrates the potential of our method in addressing issues related to information extraction from business documents. We hope that our solution will contribute to the development of the field of information extraction from business documents, and we look forward to further researching and improving our method in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,371.17,282.40,8.93;2,89.29,190.62,416.67,167.98"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pipeline of localizing Key Information and extracting them</figDesc><graphic coords="2,89.29,190.62,416.67,167.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,555.46,225.71,8.93;3,89.29,84.18,416.70,458.71"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pipeline of our approach to this competition.</figDesc><graphic coords="3,89.29,84.18,416.70,458.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.29,165.30,417.29,8.93;5,89.29,177.30,255.57,8.87;5,89.29,84.19,416.62,74.52"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Post-Processing merges two bounding boxes that have the same field type (same border color) and their distance is below a threshold into one bounding box.</figDesc><graphic coords="5,89.29,84.19,416.62,74.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,89.29,195.57,225.47,8.93;8,89.29,84.19,416.70,98.82"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Pipeline of pre-processing unlabeled dataset.</figDesc><graphic coords="8,89.29,84.19,416.70,98.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,89.29,572.53,315.30,8.93;8,89.29,414.81,416.68,145.15"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Pipeline of generating pseudo-labeled dataset from trained models</figDesc><graphic coords="8,89.29,414.81,416.68,145.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,210.07,322.97,228.24"><head>Table 1</head><label>1</label><figDesc>Number of documents and annotations in each dataset</figDesc><table coords="5,107.28,239.47,304.68,198.84"><row><cell>Dataset</cell><cell cols="2">Document Number Annotation Number</cell></row><row><cell>Train</cell><cell>5,180</cell><cell>65,651</cell></row><row><cell>Validation</cell><cell>500</cell><cell>5,862</cell></row><row><cell>Test</cell><cell>1,000</cell><cell>-</cell></row><row><cell>Synthetic</cell><cell>100,000</cell><cell>1,117,000</cell></row><row><cell>Unlabeled</cell><cell>932,000</cell><cell>-</cell></row><row><cell>‚Ä¢ Train batch size = 4</cell><cell></cell><cell></cell></row><row><cell>‚Ä¢ Test batch size = 4</cell><cell></cell><cell></cell></row><row><cell cols="2">‚Ä¢ Gradient Accumulation Steps = 4</cell><cell></cell></row><row><cell>‚Ä¢ Weight decay = 0.01</cell><cell></cell><cell></cell></row><row><cell>‚Ä¢ Data Loader workers = 32</cell><cell></cell><cell></cell></row><row><cell>‚Ä¢ Training Epoch = 500</cell><cell></cell><cell></cell></row><row><cell>‚Ä¢ Learning rate = 1e-5</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,127.07,320.89,81.83"><head>Table 2</head><label>2</label><figDesc>Result obtained from training Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ with Fast Gradient Method</figDesc><table coords="6,215.68,158.69,163.91,50.21"><row><cell>Model</cell><cell>AP</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ</cell><cell>0.562</cell></row><row><cell cols="2">Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ 0.557</cell></row><row><cell cols="2">Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏ 0.566</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,349.49,290.60,81.83"><head>Table 3</head><label>3</label><figDesc>Result obtained from training 3 ùëÖùëúùêµùê∏ùëÖùëá ùëé with Lion Optimizer</figDesc><table coords="6,215.68,381.10,163.91,50.21"><row><cell>Model</cell><cell>AP</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ</cell><cell>0.562</cell></row><row><cell cols="2">Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ 0.566</cell></row><row><cell cols="2">Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏ 0.565</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,249.07,81.83"><head>Table 4</head><label>4</label><figDesc>Result obtained from Ensembling 3 ùëÖùëúùêµùê∏ùëÖùëá ùëé models</figDesc><table coords="7,257.21,122.10,80.85,50.21"><row><cell>Method</cell><cell>AP</cell></row><row><cell>Average</cell><cell>0.580</cell></row><row><cell cols="2">Max-Voting 0.576</cell></row><row><cell cols="2">Affirmative 0.607</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,289.25,417.00,165.51"><head>Table 5</head><label>5</label><figDesc>Result obtained from changing post-processing threshold, i.e. the distance between the two central bounding boxes relative to the width of the document</figDesc><table coords="7,143.63,332.82,307.45,121.94"><row><cell></cell><cell></cell><cell>AP</cell><cell></cell></row><row><cell>Threshold (%)</cell><cell>Rùëúùêµùê∏ùëÖùëá ùëé</cell><cell>Rùëúùêµùê∏ùëÖùëá ùëé</cell><cell>Rùëúùêµùê∏ùëÖùëá ùëé</cell></row><row><cell></cell><cell>_ùëÇùëà ùëÖùëÜ</cell><cell cols="2">_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ _ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏</cell></row><row><cell>12</cell><cell>0.606</cell><cell>0.603</cell><cell>0.606</cell></row><row><cell>13</cell><cell>0.606</cell><cell>0.604</cell><cell>0.607</cell></row><row><cell>14</cell><cell>0.606</cell><cell>0.604</cell><cell>0.607</cell></row><row><cell>14.5</cell><cell>0.607</cell><cell>0.605</cell><cell>0.608</cell></row><row><cell>15</cell><cell>0.607</cell><cell>0.603</cell><cell>0.607</cell></row><row><cell>16</cell><cell>0.603</cell><cell>0.599</cell><cell>0.603</cell></row><row><cell>17</cell><cell>0.598</cell><cell>0.596</cell><cell>0.603</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,88.99,90.49,326.76,93.78"><head>Table 6</head><label>6</label><figDesc>Result obtained from training models with Pseudo-label</figDesc><table coords="9,179.02,122.10,236.73,62.16"><row><cell>Model</cell><cell cols="2">AP Train Data + chunk 0</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ</cell><cell>0.562</cell><cell>0.568</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ</cell><cell>0.566</cell><cell>0.57</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏</cell><cell>0.566</cell><cell>0.576</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,88.89,235.26,417.09,51.56"><head>Table 7</head><label>7</label><figDesc>shows our performance on the validation dataset of each model when combined with Fast Gradient Method, Lion Optimizer, and Pseudo-Labeling technique. The value of ùëÖùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ in the Baseline column indicates the result of training RoBERTa with the Fast Gradient Method technique.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,88.99,304.91,362.97,93.78"><head>Table 7</head><label>7</label><figDesc>Performance of different models on the DocILE competition task</figDesc><table coords="9,142.81,336.52,309.15,62.16"><row><cell>Model</cell><cell cols="3">AP Baseline + Lion Optimizer + chunk 0</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùëÇùëà ùëÖùëÜ</cell><cell>0.562</cell><cell>0.562</cell><cell>0.568</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùëÇùëà ùëÖùëÜ</cell><cell>0.557</cell><cell>0.566</cell><cell>0.57</cell></row><row><cell>Rùëúùêµùê∏ùëÖùëá ùëé_ùê∑ùëÇùê∂ùêºùêøùê∏_ùêµùê¥ùëÜùê∏</cell><cell>0.566</cell><cell>0.565</cell><cell>0.576</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,88.99,471.07,354.69,81.83"><head>Table 8</head><label>8</label><figDesc>Performance of different models on the DocILE competition task</figDesc><table coords="9,151.59,502.69,292.09,50.21"><row><cell>Model</cell><cell>Method</cell><cell cols="2">AP + Ensemble + Post-Processing</cell></row><row><cell>3 ùëÖùëúùêµùê∏ùëÖùëá ùëé</cell><cell>-+ Pseudo-Labeling</cell><cell>0.608 0.612</cell><cell>0.644 0.648</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="10,88.99,90.49,284.87,69.88"><head>Table 9</head><label>9</label><figDesc>Performance of different models on the DocILE competition task</figDesc><table coords="10,221.41,122.10,152.46,38.26"><row><cell></cell><cell cols="2">Baseline Ours Change</cell></row><row><cell>Valset</cell><cell>0.566</cell><cell>0.648 +0.082</cell></row><row><cell>Testset</cell><cell>0.539</cell><cell>0.612 +0.073</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,351.30,394.53,10.91;10,112.66,364.85,393.32,10.91;10,112.66,378.40,394.53,10.91;10,112.66,391.95,393.33,10.91;10,112.66,405.50,393.33,10.91;10,112.66,419.05,267.69,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,227.92,364.85,278.06,10.91;10,112.66,378.40,64.76,10.91">Overview of DocILE 2023: Document Information Localization and Extraction</title>
		<author>
			<persName coords=""><forename type="first">≈†</forename><surname>≈†imsa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>U≈ôiƒç√°≈ô</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>≈†ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koci√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Skalick√Ω</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Coustaty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,375.83,391.95,130.16,10.91;10,112.66,405.50,258.02,10.91;10,403.07,405.50,102.92,10.91;10,112.66,419.05,233.99,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>LNCS Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="10,112.66,432.60,394.53,10.91;10,112.66,446.14,393.32,10.91;10,112.66,459.69,394.53,10.91;10,112.66,473.24,393.53,10.91;10,112.66,486.79,103.82,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,226.61,446.14,279.37,10.91;10,112.66,459.69,45.25,10.91">DocILE Benchmark for Document Information Localization and Extraction</title>
		<author>
			<persName coords=""><forename type="first">≈†</forename><surname>≈†imsa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>≈†ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>U≈ôiƒç√°≈ô</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koci√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Skalick√Ω</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Coustaty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,182.79,459.69,324.39,10.91;10,112.66,473.24,53.03,10.91">17th International Conference on Document Analysis and Recognition, ICDAR 2021</title>
		<title level="s" coord="10,383.74,473.24,122.45,10.91;10,112.66,486.79,31.19,10.91">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>San Jos√©, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">August 21-26, 2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,500.34,365.95,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><surname>Mindee</surname></persName>
		</author>
		<ptr target="https://github.com/mindee/doctr" />
		<title level="m" coord="10,151.05,500.34,147.22,10.91">doctr: Document text recognition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,513.89,394.53,10.91;10,112.30,527.44,393.68,10.91;10,112.66,540.99,107.17,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="10,173.53,527.44,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,554.54,394.52,10.91;10,112.66,568.09,394.04,10.91;10,112.66,581.64,68.19,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">≈†</forename><surname>≈†imsa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>≈†ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>U≈ôiƒç√°≈ô</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koci√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Skalick·ª≥</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Coustaty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<ptr target="https://github.com/rossumai/docile/tree/main/baselines" />
		<title level="m" coord="10,226.28,568.09,69.18,10.91">Docile baselines</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,595.19,394.04,10.91;10,112.66,608.74,278.49,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sanagapati</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/code/pavansanagapati/ensemble-learning-techniques-tutorial" />
		<title level="m" coord="10,182.19,595.19,176.08,10.91">Ensemble learning techniques tutorial</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,622.28,395.01,10.91;10,112.66,635.83,177.63,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,237.06,622.28,173.40,10.91">Ensemble methods for object detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Casado-Garc√≠a</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heras</surname></persName>
		</author>
		<ptr target="https://github.com/ancasag/ensembleObjectDetection" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,649.38,393.32,10.91;11,112.66,86.97,394.53,10.91;11,112.39,100.52,99.64,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,187.02,649.38,318.96,10.91;11,112.66,86.97,109.92,10.91">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName coords=""><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,246.05,86.97,226.40,10.91">Workshop on challenges in representation learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,393.33,10.91;11,112.66,127.61,356.18,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="11,243.00,114.06,262.98,10.91;11,112.66,127.61,313.76,10.91">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<editor>I.</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,195.36,393.33,10.91;11,112.66,208.91,395.17,10.91;11,112.66,222.46,394.96,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,306.42,195.36,199.57,10.91;11,112.66,208.91,226.91,10.91">Virtual adversarial training: A regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2018.2858821</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,347.43,208.91,160.40,10.91;11,112.66,222.46,125.64,10.91">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,236.01,393.33,10.91;11,112.26,249.56,394.93,10.91;11,112.66,263.11,394.53,10.91;11,112.66,276.66,394.03,10.91;11,112.66,290.20,229.49,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,390.46,236.01,115.52,10.91;11,112.26,249.56,129.39,10.91">Semi-supervised learning with deep generative models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2014/file/d523773c6b194f37b938d340d5d02232-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="s" coord="11,212.34,263.11,237.20,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="2014">2014</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,303.75,394.53,10.91;11,112.66,317.30,395.01,10.91;11,112.66,330.85,118.54,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzm√°n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<ptr target="https://huggingface.co/xlm-roberta-base" />
		<title level="m" coord="11,330.56,317.30,76.97,10.91">Xlm-roberta-base</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,344.40,393.33,10.91;11,112.66,357.95,237.70,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07725</idno>
		<title level="m" coord="11,269.99,344.40,236.00,10.91;11,112.66,357.95,55.98,10.91">Adversarial training methods for semi-supervised text classification</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,371.50,394.53,10.91;11,112.66,385.05,393.33,10.91;11,112.66,398.60,107.17,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="11,206.87,385.05,216.91,10.91">Symbolic discovery of optimization algorithms</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.06675</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
