<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,364.98,15.42;1,89.29,106.66,345.48,15.42">NLPIR-UNED at CheckThat! 2023: Ensemble of Classifiers for Check-Worthiness Estimation</title>
				<funder ref="#_8DHtQxs">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
				<funder ref="#_KzYVXkB">
					<orgName type="full">MCI/AEI/FEDER, UE)</orgName>
				</funder>
				<funder ref="#_qJe26As">
					<orgName type="full">NextGenerationEU/PRTR)</orgName>
				</funder>
				<funder ref="#_avKCzu9 #_EF4j9XZ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,134.97,107.06,11.96"><forename type="first">Juan</forename><forename type="middle">R</forename><surname>Martinez-Rico</surname></persName>
							<email>jrmartinezrico@invi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dpto. Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.80,134.97,75.93,11.96"><forename type="first">Lourdes</forename><surname>Araujo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dpto. Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Instituto Mixto de</orgName>
								<orgName type="institution">Investigación -Escuela Nacional de Sanidad (IMIENS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.01,134.97,101.54,11.96"><forename type="first">Juan</forename><surname>Martinez-Romo</surname></persName>
							<email>juaner@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dpto. Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia (UNED)</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Instituto Mixto de</orgName>
								<orgName type="institution">Investigación -Escuela Nacional de Sanidad (IMIENS)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,364.98,15.42;1,89.29,106.66,345.48,15.42">NLPIR-UNED at CheckThat! 2023: Ensemble of Classifiers for Check-Worthiness Estimation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">D3C18042CE58F580B7F74A17C64D058E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Check-worthiness Classification</term>
					<term>Transformer Models</term>
					<term>Ensemble of Classifiers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article outlines the NLPIR-UNED team's strategies for Task 1B in the CLEF 2023 CheckThat! Lab. The goal of this task is to determine if a text fragment from a tweet or a debate/speech is worth fact-checking. Our team devised three main approaches based on ensemble models for this binary classification task. For the English version of subtask 1B, which involves classifying text fragments from debates/speeches, we utilized an ensemble classifier composed of three transformer models that were fed different sentences from the debate/speech. On the other hand, for the Spanish version of subtask 1B, which requires classifying tweets, we have tried two more strategies, an ensemble classifier composed of three different transformer models in Spanish that receive the same tweet, and the one that we finally use: an ensemble classifier that combined a transformer model and two feed-forward neural networks (FFNN). The transformer model processes the tweet's text, while the two FFNNs receive as input TF-IDF vectors and LIWC features extracted from the text, respectively. With these approaches, our team achieved the fourth position in subtask 1B English and the same position for subtask 1B Spanish.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fake news is a growing problem that has been amplified by the rise of social media and the ease of spreading misinformation online. This phenomenon can have serious consequences, such as influencing political elections, spreading harmful health information, and causing social unrest. Traditional fact-checking methods are often slow and labor-intensive, making them ineffective at keeping up with the speed at which false information can spread. This has led to the development of automated methods to detect and combat fake news, such as machine learning algorithms that can quickly analyze large volumes of data and identify suspicious patterns. These automated methods have the potential to provide a more efficient and effective approach to combating fake news.</p><p>One of the fundamental tasks to perform if we want to detect fake news in news or message flows on a social network is the selection of the statements to check. This is precisely what task 1 of the CheckThat! Lab <ref type="bibr" coords="2,199.51,86.97,12.84,10.91" target="#b0">[1]</ref> aims to do. Our team has focused on variant B of this task, which contemplates only the use of textual information, and in the English and Spanish languages. For the English version the organizers provide a dataset generated from the transcript of a debate, while for the Spanish version the dataset is composed of a series of tweets. In both cases each instance is annotated with the values Yes if the sentence/tweet contains a factual statement and may be harmful, or No otherwise.</p><p>We have organized the rest of the article as follows: in Section 2 we make a brief review of the different approaches carried out in recent years to the task of estimating the check-worthiness of a statement, in Section 3 we explain our different approaches to this task, Section 4 discuss the results obtained, and Section 5 contains our conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The task of estimating check-worthiness of a sentence has had different approaches as the available models and tools have evolved. The approaches considered include word embeddings, bag-of-words representations, and heuristic rules to classify claims, and multilayer perceptron or support vector machine models <ref type="bibr" coords="2,247.28,308.18,11.58,10.91" target="#b1">[2]</ref>, recurrent neural networks with attention, combining word2vec embeddings, part-of-speech tags, and syntactic dependencies <ref type="bibr" coords="2,413.15,321.73,11.55,10.91" target="#b2">[3]</ref>, learning-to-rank approaches based on the MART algorithm, using word embeddings, named entities, part-ofspeech tags, sentiment labels, and topics as features <ref type="bibr" coords="2,326.67,348.83,11.58,10.91" target="#b3">[4]</ref>, k-nearest neighbors classifiers with character n-gram representations, considering linguistic lexicons and named entities <ref type="bibr" coords="2,477.92,362.38,11.59,10.91" target="#b4">[5]</ref>, or support vector machines and random forests classifiers with information retrieval nutritional labels as representations <ref type="bibr" coords="2,200.98,389.48,11.43,10.91" target="#b5">[6]</ref>.</p><p>Subsequently, more sophisticated representation models have been applied, such as training a feed-forward neural network with Standard Universal Sentence Encoder embeddings and using different variations of embeddings and training epochs <ref type="bibr" coords="2,363.38,430.13,11.43,10.91" target="#b6">[7]</ref>.</p><p>Finally, with the generalization of transformer models as a basic tool in almost any task related to general language processing, most approaches have used this strategy <ref type="bibr" coords="2,436.92,457.22,11.28,10.91" target="#b7">[8]</ref>, either using pre-trained models in generic documents <ref type="bibr" coords="2,269.99,470.77,11.24,10.91" target="#b8">[9,</ref><ref type="bibr" coords="2,283.64,470.77,12.23,10.91" target="#b9">10]</ref>, in other languages <ref type="bibr" coords="2,385.32,470.77,16.08,10.91" target="#b10">[11]</ref>, or in a specific domain such as health <ref type="bibr" coords="2,157.68,484.32,16.41,10.91" target="#b11">[12]</ref>. The approaches that have appeared more recently and have a superior performance than the solo transformer models, are the ensembles of classifiers <ref type="bibr" coords="2,453.90,497.87,16.41,10.91" target="#b12">[13]</ref>. These models typically include two or more different transformer models, or transformers pre-trained in different documents, or a combination of transformers and other types of classifiers such as feed-forward neural networks (FFNN). In our proposal, we use these two types of approaches: an ensemble with several transformers, and an ensemble composed of a transformer and two FFNNs that allows incorporating lexical and text analysis features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approaches to Check-Worthiness Estimation</head><p>In this 2023 edition of the CheckThat! Lab, the goal of subtask 1B is to determine if a given tweet is worth checking (binary classification), taking into account whether this tweet contains a factual statement that can be verified and whether it could be harmful. This task is offered in three languages: English, Spanish and Arabic. The organizers provide three different datasets for each language with which the models can be developed, in addition to the test dataset used for the competition. In Table <ref type="table" coords="3,226.46,200.62,5.17,10.91" target="#tab_0">1</ref> we can see the number of instances of each dataset for the languages in which our team has participated.</p><p>To tackle this subtask, our team has evaluated three strategies, all based on ensemble classifiers. The first of them is an ensemble classifier composed of a transformer model, a feed forward neural network (FFNN) whose inputs are TF-IDF vectors, and a FFNN whose inputs are text analysis indicators. Here, the objective is to complement the latent features that a transformer model is able to extract from plain text, with other types of features such as TF-IDF vectors extracted from that same text, and the features provided by the text analysis tool Linguistic Inquiry and Word Count (LIWC) <ref type="bibr" coords="3,237.58,309.01,16.25,10.91" target="#b13">[14]</ref>.</p><p>The other two strategies are also ensemble classifiers but this time they contain three transformer models although used differently. In the subtask proposed for the English language, the dataset is composed of sentences extracted from a debate and in the first column appears an identifier that, after carefully examining the instances of training and test, we have assumed is the order in which the sentences appeared in the debate. That is why we wanted to explore the possibility of taking advantage of this information, making the ensemble classifier receive in its input 3 the instance to be evaluated, and in its inputs 2 and 1 the two instances immediately prior to the current one existing in the dataset, taking into account that there are gaps we assume generated when making the training-dev-test partition. Our hypothesis is that providing context information (previous sentences) to the sentence to be evaluated can be useful in determining the check-worthiness of that sentence.</p><p>For the subtask proposed in Spanish the dataset is composed of tweets, which we cannot identify as related following any type of order. That is why we have chosen to use an ensemble composed of three different transformer models pre-trained all of them in Spanish, hoping that the different behaviors that each of them may have complement each other, achieving a superior performance to each of them separately.</p><p>We detail each of these approaches below. All used pre-trained transformer models have been downloaded from https://huggingface.co/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Transformer-FFNN Ensemble</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Method</head><p>To check whether different types of input generated from the same text can complement each other and lead to greater efficiency in detecting whether that text deserves to be verified, we need to be able to handle these three types of input simultaneously for each instance of the dataset. Therefore, we have developed an ensemble model (Figure <ref type="figure" coords="3,378.28,663.84,4.08,10.91" target="#fig_0">1</ref>) composed of a transformer that processes the text as a sequence, a FFNN classifier that admits as input that text in the form of a TF-IDF vector, and a second FFNN classifier that has as inputs the discrete features generated by the LIWC text analysis tool (93 features for the English language and 90 features for the Spanish language). The hidden layers of the FFNNs and the first token of the last hidden layer of the transformer (classification token) are concatenated and form the first layer of the ensemble classifier. Behind this concatenation layer are two hidden layers and one output layer.</p><p>It is also possible to disable one of the hidden layers by configuration. Before training the ensemble classifier, the transformer and the two FFNN models are trained separately on the same dataset and stored in binary files. These models are then loaded in evaluation mode in the ensemble classifier to prevent their parameters from being modified during ensemble training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Training Strategy</head><p>To determine the configuration with the best performance, the system was configured to use deterministic algorithms and the tests were repeated for 10 different random seeds, obtaining the average of the precision, recall, and F1 measures. An early stopping mechanism has also been implemented. This mechanism stores the updated state of parameters after each epoch and stops training when there have been no improvements in the F1 measure over the dev dataset in the last n epochs (default value 2), then selecting the saved configuration with the best F1 measure during that interval. After performing a grid search for each component separately and for the ensemble classifier, the following hyperparameters have been selected for the English language:</p><p>• FFNN hidden layer size: 1000.</p><p>• FFNN seed value: 0.</p><p>• FFNN max. epochs: 250.</p><p>• FFNN (TF-IDF) activation function: relu.</p><p>• FFNN (LIWC) activation function: sigmoid. And for the Spanish language the same hyperparameters have been used except for the following:</p><p>• FFNN seed value: 96.</p><p>• Transformer pre-trained model: bertin-project/bertin-roberta-base-spanish <ref type="bibr" coords="5,443.90,281.32,16.25,10.91" target="#b16">[17]</ref>.</p><p>• Transformer seed value: 70.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ensemble of Transformers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Method</head><p>In the English subtask, as discussed above, we wanted to take advantage of what appears to be a flow of sentences to provide context for the sentence to be evaluated. For this, we have developed an ensemble classifier (Figure <ref type="figure" coords="5,269.09,393.22,4.11,10.91" target="#fig_1">2</ref>) composed of three transformer models so that each one can receive a different sentence. During the processing of the training and test datasets, we look for the two instances that have the identifiers immediately before i -n, i -n -m to the instance i to evaluate. These three sentences form the input of the ensemble classifier using the class value of the instance i. As a pre-trained model, we use the same in each of the three transformer components: bert-base-uncased.</p><p>For the Spanish subtask, since the datasets contain tweets, we have assumed that they had no relationship between them by adopting the strategy of providing the same sentence (tweet) in the three inputs of the ensemble classifier, and use a different pre-trained model on each transformer component. With this, we hoped that the different pre-trainings that each one has had are somehow complementary and allow us to determine more precisely if the sentence to evaluate is worth checking. Specifically, we have used the following models:</p><p>• Transformer 1: PlanTL-GOB-ES/roberta-large-bne <ref type="bibr" coords="5,336.65,566.68,16.25,10.91" target="#b14">[15]</ref>. • Transformer 2: dccuchile/bert-base-Spanish-wwm-cased <ref type="bibr" coords="5,362.90,581.33,16.25,10.91" target="#b15">[16]</ref>.</p><p>• Transformer 3: bertin-project/bertin-roberta-base-spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Training Strategy</head><p>The hyperparameters used in both languages were as follows:</p><p>• Transformer max. sequence lenght: 128.</p><p>[CLS] First Token Last Hidden Layer • Transformer max. epochs: 10.</p><p>• Transformer seed value: 63.</p><p>• Ensemble activation function: relu.</p><p>• Ensemble hidden layers: 2.</p><p>• Ensemble dropout: 0.</p><p>• Ensemble max. epochs: 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>This section describes the results obtained with the three strategies described. The F1 score on the positive class is the evaluation measure used by the organizers in the competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">English Subtask</head><p>The organizers provided three datasets for both languages: training, dev-test and test. Since the values of F1 measure obtained for the English subtask with the test dataset were very high even for the n-gram baseline, we also performed the evaluation joining the dev-test and test datasets. In all cases the training has been done using only the training dataset. Table <ref type="table" coords="6,470.43,559.88,5.04,10.91" target="#tab_2">2</ref> shows the averaged results of the models after 10 runs with different random seeds. The last column shows the F1 measure calculated on the test dataset, along with the reference values provided by the baselines. As we can see, the FFNN with input in the form of TF-IDF vectors is not able to overcome the baseline n-gram. On the other hand, the transformer model bert-base-uncased outperforms the two ensemble classifiers, indicating that, at least in this test dataset, the combination of models and inputs does not bring any improvement to the classifier's performance. In principle, ensemble models would be expected to outperform the solo transformer model as they should be able to select the best information present in each of their three inputs to evaluate a given sentence. It is possible that the context search that we intended to use by looking for sentences before the current one is not working in this test dataset because there is too much distance between them. Remember that we have assumed that the identifier of each sentence is the order it has within the debate. Thus, having partitioned the debate by randomly extracting sentences to create the train, test and dev-test datasets, the sentences are no longer consecutive in these datasets. Regarding the other type of ensemble classifier, we can also assume that in this test dataset the inputs of TF-IDF vectors and LIWC features do not provide enough information to improve the behavior of the ensemble model.</p><p>If we look at the evaluation carried out on the dev-test + test dataset, we see that in this case the two ensemble models surpass to the transformer model alone, although by a small margin. For the ensemble model that searches for previous sentences, performance may be improving as two datasets have been rejoined, making the distances between the current sentence and the two immediately preceding sentences smaller and contributing to this context information more effectively.</p><p>For the main submission, we selected the ensemble model that seeks context information in two previous sentences (shown in Table <ref type="table" coords="7,271.38,551.94,5.12,10.91" target="#tab_2">2</ref> as Ensemble of Transformers). Although it does not have the highest average F1 score, the differences with the other models are minimal, and we wanted to see how this approach performs in the competition. With this configuration we have achieved the fourth best result among the eleven participating teams with an F1 measure of 0.851 (Table <ref type="table" coords="7,144.55,606.14,3.56,10.91" target="#tab_3">3</ref>), being 0.898 the value obtained by the team classified in first position and 0.462 the one obtained by the baseline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Spanish Subtask</head><p>Table <ref type="table" coords="8,115.90,277.14,5.10,10.91" target="#tab_4">4</ref> shows the results obtained for the subtask in Spanish. These results are also averaged for ten random seeds in two different evaluation datasets: the test dataset (last column) and the union of the test and dev-test + test datasets (rest of columns).</p><p>Here, because the datasets contain tweets, we were unable to apply context information search. Instead, we have configured the ensemble composed of three different transformer models. The first thing to note, looking at the results, is that in both datasets of evaluation the ensemble models clearly surpass the transformer working alone, the FFNN, and the baselines. This is the expected behavior, and that in the English subtask has not been seen.</p><p>Analyzing the two ensemble models, we see that the one composed of three different transformer models (roberta-large, roberta-base, bert-base) also pre-trained with different data in Spanish, get to obtain the best F1 measure both in the test dataset (F1 = 0.692) and in the test + dev-test dataset (F1 = 0.690), so we deduce that the latent features extracted by each of them are complementary and help to improve the ensemble classifier as a whole. The ensemble model that uses a single transformer and two FFNNs obtains somewhat lower results (F1 = 0.684 in the test dataset), but surpasses the transformer alone. This indicates that the features based on text analysis extracted by the LIWC tool, along with the TF-IDF vectors extracted from the tweet text, also complement in some way the latent features extracted by the transformer model.</p><p>For the main submission of this subtask in Spanish, we have considered the two ensemble models. Again, in this case the performance differences between the two have been small so we have chosen to send the results of the model that uses a single transformer, shown in Table <ref type="table" coords="8,489.27,534.58,4.97,10.91" target="#tab_4">4</ref> as Ensemble Transformer-FFNN, thus sending a totally different configuration in each version of subtask 1B. With this model, we have managed to place ourselves in the fourth position with an F1 measure of 0.589 (Table <ref type="table" coords="8,221.12,575.23,3.51,10.91" target="#tab_5">5</ref>), being 0.641 the F1 measure obtained by the winning team and 0.172 the one obtained by the reference baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future Work</head><p>To tackle the task of estimating the check-worthiness of a sentence or tweet, in this edition of the CheckThat! Lab our team has evaluated several strategies that involve the use of ensemble classifiers. One of them, has been based on the use of an ensemble classifier containing a transformer model, a feed-forward neural network (FFNN) with TF-IDF vectors at the input, and a second FFNN with features extracted by the text analysis tool LIWC. This model, as we expected, has been able to surpass the solo transformer models in the Spanish subtask and is the one we have used to make the main submission in this language, obtaining the fourth best result (F1 = 0.589) among the seven participants. In this same subtask we have also evaluated an ensemble model that contained three different transformer models in Spanish, obtaining similar results.</p><p>In subtask in English language, the differences between the results obtained by the ensemble models and the transformer models alone have been much smaller, the latter surpassing the ensemble in the test dataset. The main difference between both subtasks is the content of the datasets: sentences of a debate in the subtask in English, and tweets in the subtask in Spanish. This, in principle should not be the reason for this similarity in performance since ensemble models usually perform better than solo transformers. Still, we have selected the ensemble classifier composed of three transformer models fed with the current sentence and two previous sentences to provide context information. With this configuration, our team has obtained the fourth best F1 measure (0.851) among the eleven participating teams. We think that this model can give good results when, for example, we are analyzing a text to identify the sentences that are worth checking, because in this case we could select the two sentences immediately prior to the current one, unlike what happens with the datasets of this subtask where not all the sentences of the debate are available.</p><p>In the future, we intend to further explore alternative methods of integrating diverse models into an ensemble classifier, thereby expanding the range of features utilized in identifying sentences that need to be verified.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,279.23,163.55,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Transformer-FFNN ensemble.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,273.26,416.70,8.96;6,89.29,285.21,47.20,8.96"><head>[Figure 2 :</head><label>2</label><figDesc>Figure 2: Ensemble of Transformers (i: current instance, i-n: a previous instance, i-n-m: another instance prior to i-n)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,299.05,69.87"><head>Table 1</head><label>1</label><figDesc>Size of provided datasets.</figDesc><table coords="3,207.23,122.10,180.81,38.25"><row><cell cols="2">Language train</cell><cell cols="3">dev dev-test test</cell></row><row><cell>English</cell><cell cols="2">16876 5625</cell><cell>1034</cell><cell>318</cell></row><row><cell>Spanish</cell><cell cols="2">7490 2500</cell><cell>5000</cell><cell>5000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,107.28,101.61,233.53,113.42"><head></head><label></label><figDesc>• Transformer pre-trained model: bert-base-uncased.</figDesc><table coords="5,107.28,116.26,187.57,98.78"><row><cell>• Transformer max. sequence lenght: 128.</cell></row><row><cell>• Transformer max. epochs: 10.</cell></row><row><cell>• Transformer seed value: 63.</cell></row><row><cell>• Ensemble activation function: relu.</cell></row><row><cell>• Ensemble hidden layers: 2.</cell></row><row><cell>• Ensemble dropout: 0.</cell></row><row><cell>• Ensemble max. epochs: 10.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,90.49,416.99,139.39"><head>Table 2</head><label>2</label><figDesc>English Subtask: Average results on dev-test + test and test datasets. The primary submission appears in bold.</figDesc><table coords="7,105.99,131.84,26.18,8.87"><row><cell>Model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,252.12,410.80,69.87"><head>Table 3</head><label>3</label><figDesc>English Subtask: Results on competition test dataset.</figDesc><table coords="7,95.48,283.74,404.31,38.25"><row><cell>Submission</cell><cell cols="3">Accuracy Precision Recall</cell><cell>F1</cell></row><row><cell>Primary (Ensemble of Transformers)</cell><cell>0.909</cell><cell>0.954</cell><cell cols="2">0.769 0.851</cell></row><row><cell>Contrastive (Transformer + LIWC + TF-IDF FFNN)</cell><cell>0.937</cell><cell>0.978</cell><cell>0.833</cell><cell>0.900</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,90.49,417.00,139.38"><head>Table 4</head><label>4</label><figDesc>Spanish Subtask: Average results on dev-test + test and test datasets. The primary submission appears in bold.</figDesc><table coords="8,95.42,131.84,26.18,8.87"><row><cell>Model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,88.99,90.49,414.85,69.87"><head>Table 5</head><label>5</label><figDesc>Spanish Subtask: Results on competition test dataset.</figDesc><table coords="9,95.27,122.10,46.87,8.87"><row><cell>Submission</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially supported by the <rs type="funder">Spanish Ministry of Science and Innovation</rs> within the <rs type="projectName">DOTT-HEALTH</rs> Project (<rs type="funder">MCI/AEI/FEDER, UE)</rs> under Grant <rs type="grantNumber">PID2019-106942RB-C32</rs> and <rs type="projectName">OBSER-MENH</rs> Project (<rs type="grantNumber">MCIN/AEI/10.13039/501100011033</rs> and <rs type="funder">NextGenerationEU/PRTR)</rs> under Grant <rs type="grantNumber">TED2021-130398B-C21</rs> as well as project <rs type="projectName">RAICES</rs> (<rs type="grantNumber">IMIENS 2022</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_8DHtQxs">
					<orgName type="project" subtype="full">DOTT-HEALTH</orgName>
				</org>
				<org type="funded-project" xml:id="_KzYVXkB">
					<idno type="grant-number">PID2019-106942RB-C32</idno>
					<orgName type="project" subtype="full">OBSER-MENH</orgName>
				</org>
				<org type="funding" xml:id="_qJe26As">
					<idno type="grant-number">MCIN/AEI/10.13039/501100011033</idno>
				</org>
				<org type="funded-project" xml:id="_avKCzu9">
					<idno type="grant-number">TED2021-130398B-C21</idno>
					<orgName type="project" subtype="full">RAICES</orgName>
				</org>
				<org type="funding" xml:id="_EF4j9XZ">
					<idno type="grant-number">IMIENS 2022</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,656.03,394.52,10.91;9,112.66,669.58,393.64,10.91;10,112.66,86.97,393.33,10.91;10,112.66,100.52,394.52,10.91;10,112.66,114.06,58.60,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,332.76,669.58,173.54,10.91;10,112.66,86.97,306.89,10.91">Overview of the CLEF-2023 CheckThat! Lab Task 1 on Check-Worthiness in Multimodal and Multigenre Content</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hakimov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,440.75,86.97,65.24,10.91;10,112.66,100.52,327.90,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,393.33,10.91;10,112.66,141.16,394.53,10.91;10,112.66,154.71,22.69,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,261.81,127.61,244.18,10.91;10,112.66,141.16,177.70,10.91">A hybrid recognition system for check-worthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,313.27,141.16,128.14,10.91">CEUR workshop proceedings</title>
		<imprint>
			<biblScope unit="volume">2125</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,168.26,393.33,10.91;10,112.66,181.81,393.33,10.91;10,112.66,195.36,324.28,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,331.05,168.26,174.94,10.91;10,112.66,181.81,393.33,10.91;10,112.66,195.36,210.45,10.91">The Copenhagen Team Participation in the Check-Worthiness Task of the Competition of Automatic Identification and Verification of Claims in Political Debates of the CLEF-2018</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,325.83,195.36,71.39,10.91">CheckThat! Lab</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,208.91,395.17,10.91;10,112.14,222.46,151.16,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,253.51,208.91,254.32,10.91;10,112.14,222.46,106.36,10.91">bigIR at CLEF 2018: Detection and Verification of Check-Worthy Political Claims</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,236.01,394.61,10.91;10,112.66,249.56,298.52,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<title level="m" coord="10,346.06,236.01,161.21,10.91;10,112.66,249.56,258.80,10.91">UPV-INAOE-Autoritas -Check That: Preliminary Approach for Checking Worthiness of Claims</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,393.33,10.91;10,112.66,276.66,66.08,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,344.64,263.11,84.58,10.91">IRIT at CheckThat!</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Agez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lespagnol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Petitcol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,458.71,263.11,47.28,10.91;10,112.66,276.66,22.60,10.91">Cappellato et al</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,290.20,393.65,10.91;10,112.66,303.75,89.57,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,275.16,290.20,231.15,10.91;10,112.66,303.75,44.78,10.91">TheEarthIsFlat&apos;s Submission to CLEF&apos;19 CheckThat! Challenge</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Favano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Carman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,317.30,393.33,10.91;10,112.66,330.85,395.17,10.91;10,112.66,344.40,394.04,10.91;10,112.66,357.95,66.21,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,271.01,317.30,234.98,10.91;10,112.66,330.85,249.47,10.91">Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_226.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,371.01,330.85,136.82,10.91;10,112.66,344.40,199.10,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,371.50,393.33,10.91;10,112.33,385.05,393.65,10.91;10,112.66,398.60,393.32,10.91;10,112.66,412.15,357.71,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,321.08,371.50,184.91,10.91;10,112.33,385.05,192.59,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,330.38,385.05,175.60,10.91;10,112.66,398.60,393.32,10.91;10,112.66,412.15,102.30,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="10,112.66,425.70,395.17,10.91;10,112.66,439.25,393.33,10.91;10,112.66,452.79,215.64,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692[cs</idno>
		<ptr target="http://arxiv.org/abs/1907.11692" />
		<title level="m" coord="10,141.36,439.25,277.91,10.91">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,466.34,393.33,10.91;10,112.66,479.89,244.72,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Antoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00104</idno>
		<title level="m" coord="10,251.38,466.34,254.60,10.91;10,112.66,479.89,62.22,10.91">Arabert: Transformer-based model for arabic language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,493.44,393.32,10.91;10,112.33,506.99,211.69,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,270.60,493.44,235.39,10.91;10,112.33,506.99,29.12,10.91">BERTweet: A pre-trained language model for English Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10200</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,520.54,393.33,10.91;10,112.66,534.09,150.01,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Buliga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Raschip</surname></persName>
		</author>
		<title level="m" coord="10,223.87,520.54,282.12,10.91;10,112.66,534.09,118.09,10.91">Zorros at CheckThat! 2022: Ensemble Model for Identifying Relevant Claims in Tweets</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,547.64,393.32,10.91;10,112.66,561.19,214.69,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,349.13,547.64,156.85,10.91;10,112.66,561.19,103.23,10.91">The development and psychometric properties of LIWC</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="10,112.66,574.74,394.53,10.91;10,112.66,588.29,393.33,10.91;10,112.66,601.84,393.33,10.91;10,112.66,615.39,393.33,10.91;10,112.66,628.93,174.28,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,288.92,588.29,144.33,10.91">MarIA: Spanish Language Models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Fandiño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Estapé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pàmies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Palao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Ocampo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">P</forename><surname>Carrino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Oller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Penagos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<idno type="DOI">10.26342/2022-68-3</idno>
		<ptr target="https://upcommons.upc.edu/handle/2117/367156#.YyMTB4X9A-0.mendeley.doi:10.26342/2022-68-3" />
	</analytic>
	<monogr>
		<title level="j" coord="10,441.76,588.29,64.23,10.91;10,112.66,601.84,94.89,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<date type="published" when="2022">2022</date>
			<publisher>Sociedad Española para el Procesamiento del Lenguaje Natural</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,642.48,393.65,10.91;10,112.66,656.03,270.34,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,388.86,642.48,117.45,10.91;10,112.66,656.03,119.33,10.91">Spanish Pre-Trained BERT Model and Evaluation Data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cañete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chaperon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,255.24,656.03,97.80,10.91">PML4DC at ICLR 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,669.58,393.33,10.91;11,112.66,86.97,393.33,10.91;11,112.66,100.52,394.03,10.91;11,112.66,114.06,96.92,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,425.30,669.58,80.68,10.91;11,112.66,86.97,304.06,10.91">BERTIN: Efficient Pre-Training of a Spanish Language Model using Perplexity Sampling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D L R Y E G P Y M R Y P V Y P G D P S Y M</forename><surname>Grandury</surname></persName>
		</author>
		<ptr target="http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6403" />
	</analytic>
	<monogr>
		<title level="j" coord="11,425.53,86.97,80.46,10.91;11,112.66,100.52,77.40,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
