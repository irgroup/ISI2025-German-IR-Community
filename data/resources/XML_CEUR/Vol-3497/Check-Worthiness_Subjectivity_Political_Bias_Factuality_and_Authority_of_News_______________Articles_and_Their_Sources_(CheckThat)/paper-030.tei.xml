<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,402.13,15.42;1,89.29,106.66,352.40,15.42;1,89.29,128.58,76.47,15.43;1,165.76,125.54,5.85,10.48;1,89.29,150.91,265.98,11.96">Thesis Titan at CheckThat! 2023: Language-Specific Fine-tuning of mDeBERTaV3 for Subjectivity Detection ⋆ Notebook for the CheckThat! Lab Task 2 at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,96.39,11.96"><forename type="first">Folkert</forename><forename type="middle">Atze</forename><surname>Leistra</surname></persName>
							<email>f.a.leistra@student.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Rijksuniversiteit Groningen</orgName>
								<address>
									<addrLine>Oude Kijk in&apos;t Jatstraat 16</addrLine>
									<postCode>9712 EK</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.85,176.82,83.18,11.96"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
							<email>t.caselli@rug.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Rijksuniversiteit Groningen</orgName>
								<address>
									<addrLine>Oude Kijk in&apos;t Jatstraat 16</addrLine>
									<postCode>9712 EK</postCode>
									<settlement>Groningen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,402.13,15.42;1,89.29,106.66,352.40,15.42;1,89.29,128.58,76.47,15.43;1,165.76,125.54,5.85,10.48;1,89.29,150.91,265.98,11.96">Thesis Titan at CheckThat! 2023: Language-Specific Fine-tuning of mDeBERTaV3 for Subjectivity Detection ⋆ Notebook for the CheckThat! Lab Task 2 at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">2276A4951767A7F3EB8E39CCBEA33EB9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sentence semantic</term>
					<term>Subjectivity detection</term>
					<term>Multilinguality</term>
					<term>mDeBERTaV3</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The detection of subjectivity in natural language plays a crucial role in various applications, such as sentiment analysis, fake news detection, and fact-checking systems. However, effectively and accurately detecting subjectivity across different languages presents substantial challenges due to linguistic variations and cultural nuances. This paper describes the system we developed for 2023 CheckThat! Lab Task 2 on subjectivity detection using a multilingual model, mDeBERTaV3-base. In particular, we use a common multilingual dataset to fine-tune multiple mDeBERTaV3-base models using language specific development data to specialize the systems towards a target language and reduce the impact of the class imbalance in the training data. In this way, we managed to rank first in German, Italian and Turkish, second in Arabic and over a Multilingual dataset, and third in English.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The widespread use of social media has resulted in an unprecedented production of unstructured data (e.g., textual messages, images, multimodal content, among other forms), which is now accessible to a wide range of individuals from diverse backgrounds. The lack of strict forms of control on what is published makes it urgent to be able to reliably distinguish opinions from facts. This ability plays an essential role in differentiating between subjective from objective content. Subjectivity detection has strong ties with opinion mining and is often seen as a subtask of sentiment analysis <ref type="bibr" coords="1,175.34,513.49,11.40,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,189.45,513.49,7.60,10.91" target="#b1">2]</ref>. The development and deployment of subjectivity detection systems would also be beneficial for other tasks such as argument mining <ref type="bibr" coords="1,382.23,527.04,11.46,10.91" target="#b2">[3]</ref>, fake news detection <ref type="bibr" coords="1,491.92,527.04,11.45,10.91" target="#b3">[4]</ref>, and (automated) fact-checking <ref type="bibr" coords="1,227.75,540.59,11.43,10.91" target="#b4">[5]</ref>.</p><p>The CLEF 2023 CheckThat! Lab <ref type="bibr" coords="1,252.07,554.14,12.99,10.91" target="#b5">[6]</ref> offers a valuable platform to address the challenges associated with subjectivity detection. In particular, Task 2 of this edition, "Subjectivity in News Articles" provides an extensive multilingual setting (Arabic, Dutch, English, German, Italian, and Turkish) for the identification of the subjectivity status of sentences extracted from news articles <ref type="bibr" coords="2,124.06,86.97,11.40,10.91" target="#b6">[7]</ref>. The increasing polarization of the public debate is impacting the news production cycle and the way news articles are written <ref type="bibr" coords="2,283.10,100.52,11.35,10.91" target="#b7">[8]</ref>, thus making it even more important to be able to discriminate between the account of events, i.e., what has happened in the world, and their opinions and interpretations.</p><p>The task is framed as a binary classification, whose goal is to assign the subjectivity status (SUBJ for subjective, and OBJ for objective) to a given sentence. Sentences that express the personal perspective of the author are considered subjective, regardless of the truthfulness of the statement <ref type="bibr" coords="2,167.00,181.81,11.48,10.91" target="#b8">[9,</ref><ref type="bibr" coords="2,181.63,181.81,7.65,10.91" target="#b5">6]</ref>. If the sentence presents an objective view of the covered topic, it is considered objective. The subjectivity status is assigned to sentences in isolation. This makes the task more challenging as systems cannot access representations of the full text, or portions of it, and use them to enhance the knowledge of the context of occurrence of each sentence.</p><p>After an initial round of experiments focusing on the use of monolingual pre-trained language models, we shifted to a multi-lingual one, namely mDeBERTaV3-base <ref type="bibr" coords="2,404.04,249.56,16.26,10.91" target="#b9">[10]</ref>. By leveraging the capabilities of a single pre-trained model capable of handling multiple languages, our approach exemplified its effectiveness. To promote reproducibility, we have made all fine-tuned models and the code used to obtain them publicly available at our GitHub repository. <ref type="foot" coords="2,436.72,288.45,3.71,7.97" target="#foot_0">1</ref>The remainder of this contribution is structured as follows: Section 2 provides an overview of the data that we used to fine-tune mDeBERTaV3-base. Section 3 illustrates our approach and the results on the development set that we used to finalize our models. Results and leaderboard ranking for each language are presented in Section 4. In Section 5 we discuss different approaches that we tried, but did not give the expected results. Lastly, Section 6 concludes this paper and outlines directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data</head><p>Table <ref type="table" coords="2,115.69,430.13,5.05,10.91">1</ref> provides an overview of the label distributions for all the languages composing Task 2. Each language is accompanied by its own training, development, and test distribution. Notably, the data sizes and label distributions vary quite largely across the languages. In general, there is a skewed distribution towards the OBJ class, although with varying degrees: Arabic, English, and Italian present the largest data imbalance in favor of the OBJ class, while Turkish has the smallest difference. The imbalance is in large part due to the selected domain, i.e., news articles, where the writing style tend to be flat and adhere to the facts that are being reported. Exceptions to this general pattern occur, with differences due to cultural backgrounds and traditions in media reporting across different countries as well as to the current status of the public debate <ref type="bibr" coords="2,150.52,552.07,16.36,10.91" target="#b10">[11,</ref><ref type="bibr" coords="2,169.59,552.07,12.52,10.91" target="#b11">12,</ref><ref type="bibr" coords="2,184.83,552.07,12.27,10.91" target="#b12">13]</ref>. The data annotation process involved multiple teams responsible for annotating each language.</p><p>The Multilingual data was conceived by the task organizers as an independent language. This means that the training, development, and split distributions have been constructed by mixing data from all other languages regardless of their original splits, resulting in the presence of validation instances of some individual languages in its training set. This has prevented us from directly use the dataset to train a single model and deploy it on all the other languages. To obviate to this issue we developed our multilingual training dataset, Adapted Multilingual (detailed in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>The distribution for the training, validation and test data per language. The Adapted Multilingual has been created by sampling data for all the languages (Arabic, Dutch, English, German, Italian and Turkish). last row in Table <ref type="table" coords="3,166.34,446.24,3.58,10.91">1</ref>). The Adapted Multilingual dataset has been obtained by combining all the training data from each language, excluding the Multilingual dataset from the task organisers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Train</head><p>As a result, we obtained a large unbalanced dataset consisting of 6,028 sentences, with 4,071 labeled as OBJ and 1,957 as SUBJ. To achieve a more balanced dataset, we have retained all the subjective sentences and randomly selected 2,957 objective ones. The Adapted Multilingual dataset has been used to fine-tune mDeBERTaV3-base. Given that we have randomly sampled the OBJ class, we have checked the distribution of each language and to which proportion of the original training data they correspond to. Table <ref type="table" coords="3,317.26,541.09,5.00,10.91" target="#tab_0">2</ref> summarizes the language distribution for the Adapted Multilingual training. Although, roughly speaking, for each language we obtained ≈ 72% of their original training data, the distribution in the Adapted Multilingual mirrors the unbalanced distribution of each language as detailed in Table <ref type="table" coords="3,363.97,581.74,3.74,10.91">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>The adoption of a multilingual approach was mainly guided by the relatively small amount of training data for all languages, excluding Italian and Arabic. However, we wanted to optimize the results per language. This means that while concatenating the training materials will help the model to learn from multiple and more varied examples, we want to avoid the model "forgetting" the specific target language. To this end, we used the language-specific development data during the fine-tuning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>The mDeBERTaV3-base model <ref type="bibr" coords="4,270.18,142.82,17.76,10.91" target="#b9">[10]</ref> is an improved multilingual version of the original DeBERTa <ref type="bibr" coords="4,134.25,156.37,16.41,10.91" target="#b13">[14]</ref>. In this model, the original Masked Language Modeling (MLM) pre-training objective is replaced with Replaced Token Detection (RTD), which is more sample-efficient. The newly introduced gradient-disentangled embedding sharing method has improved the training efficiency resulting in a better pre-trained model with respect to the original version. The model structure has a hidden size of 768, 12 layers and 12 attention heads. mDeBERTaV3-base has been trained on the 2.5T CC100 multi-lingual dataset, with 250k tokens of SentencePiece vocabulary, the same as mT5 <ref type="bibr" coords="4,166.59,237.67,16.25,10.91" target="#b14">[15]</ref>, and for 500k steps. The model has obtained new state-of-the art results on the XNLI benchmark <ref type="bibr" coords="4,199.69,251.22,16.25,10.91" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grid Search</head><p>To optimize the results on each language, we performed random grid searches, consisting of 100 iterations for each model via the software framework provided by Weights and Biases <ref type="bibr" coords="4,137.90,307.08,16.09,10.91" target="#b16">[17]</ref>. Table <ref type="table" coords="4,187.44,307.08,4.97,10.91" target="#tab_1">3</ref> provides a summary of the hyperparameter choices that we considered, including number of fine-tuning epochs, batch size, learning rate, warm-up steps and weight decay. In each grid search experiment we used a maximum tokenization length of 40, obtained as the maximum number of tokens from the Multilingual split. We only experimented with AdamW as optimizer as this optimizer can yield better training loss and the models generalize better in comparison to models trained with Adam <ref type="bibr" coords="4,317.78,374.82,16.25,10.91" target="#b17">[18]</ref>. Fine-tuning To fine-tune our mDeBERTaV3-base models, we have conducted grid searches of 25 iterations for each language using the Adapted Multilingual dataset. On the other hand, we run independent grid searches and fine-tuning on the orginal Multilingual dataset provided by the organizers. The final model that we chose for each language was based on the macro average F1 score that was obtained on the validation set of that language. Moreover, we mainly looked at the macro F1 scores for the epoch in which the validation loss was the lowest, while ensuring that overfitting did not occur on the training set. Table <ref type="table" coords="5,329.45,347.35,4.97,10.91" target="#tab_2">4</ref> shows the final (hyper)parameters that were used for each fine-tuned mDeBERTaV3-base model per language. In general, our models obtained the lowest validation loss with very few training epochs, with a maximum of three on the original Multiligual data. Furthermore, a smaller learning rate with a small amount of weight decay resulted in the most impactful setting. Table <ref type="table" coords="5,353.83,401.54,5.15,10.91" target="#tab_3">5</ref> visualizes the final scores of our models for each language on the development data. We achieved the highest macro F1 score for Turkish (0.9100) and the lowest on Dutch (0.7033). The performances for the other language are relatively similar between 0.80 and 0.83. For the Multilingual data, we obtained the second best score in absolute terms (macro F1 0.8516). On the other hand, the F1 scores for the SUBJ class present more variation, with relatively high scores for English, Turkish, and Multilingual (in line with the macro-F1), while the scores are lower for all the other languages, excluding Dutch. On close inspection, it appears that the distribution of the classes in the development set plays a major role in the behavior of the fine-tuned models. In particular, we observe that for those languages where the class distribution tends to be largely skewed towards the majority class, i.e., OBJ, systems underperform on the SUBJ class. This is the case for Arabic, German, and Italian. For all other languages, the class distribution is either perfectly balanced (e.g., Turkish and Multilingual) or slightly unbalanced (e.g., English and Dutch). As a matter of fact the delta between the macro F1 scores and the F1 score for the SUBJ class is positive, i.e., in favor of the SUBJ class. Assuming that the test data distributions will not differ largely from the development ones, we can expect a similar behaviour of the fine-tune models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>In Table <ref type="table" coords="6,127.67,111.28,3.70,10.91" target="#tab_4">6</ref>, we report the overview of the results on the official test data, including the ranking. Our models obtained the top results in each language, ranking first for Dutch, German, Italian and Turkish, second for Arabic and Multilingual, and third for English. In general, at test time, we observe the same behaviour in terms of differences between the macro F1 score and the SUBJ F1 that were present in the development data. This clearly indicates that, besides the class imbalance of the training, the language specific development data play a key role in the fine-tuning process both in specializing the model for a specific language and for balancing their performances on the two classes. By observing the leaderboard, the differences across the top ranking systems on each language vary a lot, ranging between 0.1 point for Arabic, English, and the Multilingual dataset, up to 0.8 for German. Without having access to the code and the description of the other participants, we can only speculate that these differences could be due to the optimisation of the various models and the way they have been trained. A further remarkable result concerns Turkish. For this language we obtained a very high macro F1 score (0.90), only 0.3 points higher than the second best system. While representing roughly the same amount of training data as English, Dutch, and German (i.e., 14% of theAdapted Multilingual), previous work <ref type="bibr" coords="6,215.26,502.29,16.30,10.91" target="#b18">[19,</ref><ref type="bibr" coords="6,233.62,502.29,13.95,10.91" target="#b19">20]</ref> has highlighted how Turkish presents a battery of linguistic devices (evidentiality markers, prepositions, modality suffixes, modal adjectives and adverbs, among others) that mark in an overt manner the subjectivity status of a sentence, apparently making its identification easier when compared to other languages. Although to a lesser extent, a similar behavior (especially for connectives) can be observed for Dutch, an aspect that can help to explain the very good results on the SUBJ class in this language as well.</p><p>By plotting the predictions across multiple language specific contingency matrices, we observe that, for all languages except Dutch and Arabic, the fine-tuned models tend to over-predict the OBJ label, following the data distribution of the training data. On the other hand, for Turkish, the model performs really well only misclassifying 12 times OBJ as SUBJ and 12 times SUBJ as OBJ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">What did not work</head><p>In this section, we discuss two other approaches that we tried but did not give the expected results. We focused in modelling by using different algorithms and paradigms rather than attempting to extend the training materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different Models</head><p>We have experimented with fine-tuning various models, both multilingual as well as monolingual models for the Dutch language. The multilingual models that we experimented with were the cased and uncased version of mBERT <ref type="bibr" coords="7,414.62,194.24,16.41,10.91" target="#b20">[21]</ref>. Regarding the monolingual models, our experimentation involved BERTje <ref type="bibr" coords="7,356.79,207.78,17.83,10.91" target="#b21">[22]</ref> and RobBERT <ref type="bibr" coords="7,440.61,207.78,16.17,10.91" target="#b22">[23]</ref>. Although all of these models demonstrated reasonable performance on our validation data, we decided against them. Regarding the multilingual models, mDeBERTaV3-base consistently outperformed mBERT across all validation data. The monolingual Dutch models achieved similar performance as mDeBERTaV3-base. However, the main advantage of mDeBERTaV3-base here is the ability of training on larger quantities of data resulting in more room for improvements.</p><p>BiLSTM To explore a different architecture, we extracted the embedding representations from the last four layers of mDeBERTaV3-base without fine-tuning any parameters. These contextual embeddings were then concatenated and utilized as input for a BiLSTM model, on top of which we performed random grid searches. The results did not exhibit any improvements compared to fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>With this contribution, we focused on fine-tuning a mDeBERTaV3-base model that could be used with relative ease across multiple languages for the detection of subjectivity in newspaper sentences. We have shown that fine-tuning mDeBERTaV3-base on an adapted multilingual dataset using language specific development sets to maximise the language specific information is a powerful approach. resulting in good results. Notably, we obtained the first place in four languages and never ranked lower than third. Furthermore, our results indicates that language specific development sets data can also help to address class imbalance challenges.</p><p>Future work will explore different strategies to create the multilingual training data. In our approach, we have randomly down-sampled the OBJ class and kept all the data for the SUBJ class. We believe this approach can be revised and possibly lead to enhanced performance by working both on the training and the development distributions. For instance, an alternative could be to down-sample only languages which present a very skewed distribution between the classes (e.g., Arabic and Italian) and leave the rest as is. As a complementary step, we could develop balanced development data for each language as they play a key role during fine-tuning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,145.64,417.00,273.90"><head>Table 2</head><label>2</label><figDesc>Sentences labeled as OBJ in the Adapted Multilingual dataset, the coverage per language (percentages in parentheses), and the coverage with respect to the original monolingual training data.</figDesc><table coords="3,158.85,145.64,277.58,273.90"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Validation</cell><cell>Test</cell></row><row><cell></cell><cell cols="5">OBJ SUBJ OBJ SUBJ OBJ SUBJ</cell></row><row><cell>Arabic</cell><cell>905</cell><cell cols="2">280 227</cell><cell cols="2">70 363</cell><cell>82</cell></row><row><cell>Dutch</cell><cell>489</cell><cell cols="2">311 107</cell><cell cols="2">93 263</cell><cell>237</cell></row><row><cell>English</cell><cell>532</cell><cell cols="2">298 106</cell><cell cols="2">113 116</cell><cell>127</cell></row><row><cell>German</cell><cell>492</cell><cell cols="2">308 123</cell><cell cols="2">77 194</cell><cell>97</cell></row><row><cell>Italian</cell><cell>1231</cell><cell cols="2">382 167</cell><cell cols="2">60 323</cell><cell>117</cell></row><row><cell>Turkish</cell><cell>422</cell><cell cols="2">378 100</cell><cell cols="2">100 111</cell><cell>129</cell></row><row><cell>Multilingual</cell><cell cols="3">4,371 2,257 300</cell><cell cols="2">300 300</cell><cell>300</cell></row><row><cell cols="3">Adapted Multilingual 2,957 1,957</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">Language</cell><cell cols="3">OBJ % Original</cell></row><row><cell>Arabic</cell><cell cols="2">654 (22.11%)</cell><cell></cell><cell>72.26%</cell></row><row><cell>Dutch</cell><cell cols="2">364 (12.30%)</cell><cell></cell><cell>74.43%</cell></row><row><cell>English</cell><cell cols="2">383 (12.95%)</cell><cell></cell><cell>71.99%</cell></row><row><cell>German</cell><cell cols="2">353 (11.93%)</cell><cell></cell><cell>71.74%</cell></row><row><cell>Italian</cell><cell cols="2">898 (30.36%)</cell><cell></cell><cell>72.94%</cell></row><row><cell>Turkish</cell><cell cols="2">305 (10.31%)</cell><cell></cell><cell>72.27%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,403.83,352.54,105.74"><head>Table 3</head><label>3</label><figDesc>The (hyper)parameters that could be chosen during each of our random grid searches.</figDesc><table coords="4,209.36,435.45,176.56,74.12"><row><cell>Parameter</cell><cell>Values</cell></row><row><cell>Epochs</cell><cell>2, 3, 4, 5, 6, 7, 8</cell></row><row><cell>Batch Size</cell><cell>16, 32, 64</cell></row><row><cell cols="2">Learning Rate 2e-5, 3e-5, 4e-5, 5e-5, 6e-5</cell></row><row><cell cols="2">Warmup Steps 100, 200, 300, 400, 500</cell></row><row><cell cols="2">Weight Decay 0.0, 0.1, 0.2, 0.3, 0.4, 0.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.99,543.78,406.53,129.65"><head>Table 4 (</head><label>4</label><figDesc>Hyper)parameters that were using for mDeBERTaV3 per language.</figDesc><table coords="4,99.76,575.40,395.76,98.03"><row><cell>language</cell><cell cols="3">Batch Size Max Epochs Best epoch</cell><cell cols="3">LR Warmup Steps Weight Decay</cell></row><row><cell>Arabic</cell><cell>16</cell><cell>4</cell><cell>2</cell><cell>5e-5</cell><cell>500</cell><cell>0.0</cell></row><row><cell>Dutch</cell><cell>64</cell><cell>6</cell><cell>1</cell><cell>4e-5</cell><cell>100</cell><cell>0.2</cell></row><row><cell>English</cell><cell>64</cell><cell>3</cell><cell>1</cell><cell>6e-5</cell><cell>200</cell><cell>0.0</cell></row><row><cell>German</cell><cell>16</cell><cell>5</cell><cell>2</cell><cell>4e-5</cell><cell>100</cell><cell>0.2</cell></row><row><cell>Italian</cell><cell>32</cell><cell>2</cell><cell>2</cell><cell>5e-5</cell><cell>300</cell><cell>0.0</cell></row><row><cell>Turkish</cell><cell>64</cell><cell>2</cell><cell>2</cell><cell>6e-5</cell><cell>300</cell><cell>0.1</cell></row><row><cell>Multilingual</cell><cell>64</cell><cell>8</cell><cell>3</cell><cell>3e-5</cell><cell>500</cell><cell>0.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,88.99,90.49,417.17,141.60"><head>Table 5</head><label>5</label><figDesc>Development data results for mDeBERTaV3, trained on Adapted Multilingual dataset and validated per language. We report macro F1, Precision and Recall, as well as the F1 for the SUBJ class.</figDesc><table coords="5,187.61,134.06,220.05,98.03"><row><cell>language</cell><cell cols="3">F1 Precision Recall SUBJ F1</cell></row><row><cell>Arabic</cell><cell>0.8308</cell><cell>0.8937 0.7961</cell><cell>0.7288</cell></row><row><cell>Dutch</cell><cell>0.7033</cell><cell>0.7235 0.7137</cell><cell>0.7256</cell></row><row><cell>English</cell><cell>0.8262</cell><cell>0.8265 0.8260</cell><cell>0.8333</cell></row><row><cell>German</cell><cell>0.8342</cell><cell>0.8394 0.8303</cell><cell>0.7919</cell></row><row><cell>Italian</cell><cell>0.8068</cell><cell>0.7999 0.8151</cell><cell>0.7200</cell></row><row><cell>Turkish</cell><cell>0.9100</cell><cell>0.9107 0.9100</cell><cell>0.9118</cell></row><row><cell cols="2">Multilingual 0.8516</cell><cell>0.8523 0.8517</cell><cell>0.8548</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,88.99,289.33,417.00,153.56"><head>Table 6</head><label>6</label><figDesc>Test results for our fine-tuned models. Scores are directly taken from the official CheckThat! Lab 2023 leaderboard and correspond to macro F1 and SUBJ F1. Rank indicates our position on the leaderboard for each language.</figDesc><table coords="6,219.00,344.86,157.27,98.03"><row><cell>language</cell><cell>F1</cell><cell cols="2">SUBJ F1 Rank</cell></row><row><cell>Arabic</cell><cell>0.78</cell><cell>0.64</cell><cell>#2</cell></row><row><cell>Dutch</cell><cell>0.81</cell><cell>0.80</cell><cell>#1</cell></row><row><cell>English</cell><cell>0.77</cell><cell>0.79</cell><cell>#3</cell></row><row><cell>German</cell><cell>0.82</cell><cell>0.77</cell><cell>#1</cell></row><row><cell>Italian</cell><cell>0.76</cell><cell>0.65</cell><cell>#1</cell></row><row><cell>Turkish</cell><cell>0.90</cell><cell>0.91</cell><cell>#1</cell></row><row><cell cols="2">Multilingual 0.81</cell><cell>0.81</cell><cell>#2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,671.03,218.42,8.97"><p>https://github.com/folkertleistra/mDeBERTaV3-subjectivity</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,651.88,393.33,10.91;7,112.66,665.43,395.01,10.91;8,112.66,86.97,396.29,10.91;8,112.07,102.96,227.91,7.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,352.77,651.88,153.21,10.91;7,112.66,665.43,234.37,10.91">Distinguishing between facts and opinions for sentiment analysis: Survey and challenges</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2017.12.006</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2017.12.006" />
	</analytic>
	<monogr>
		<title level="j" coord="7,354.04,665.43,83.50,10.91">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="65" to="77" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,395.17,10.91;8,112.66,127.61,69.84,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<title level="m" coord="8,143.27,114.06,274.55,10.91">Sentiment analysis: Mining opinions, sentiments, and emotions</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,141.16,393.98,10.91;8,112.41,154.71,38.81,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,210.89,141.16,125.05,10.91">Argument mining: A survey</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,344.44,141.16,119.35,10.91">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="765" to="818" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,168.26,393.33,10.91;8,112.66,181.81,337.29,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,303.46,168.26,202.53,10.91;8,112.66,181.81,83.30,10.91">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,204.32,181.81,171.84,10.91">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,195.36,394.53,10.91;8,112.66,208.91,394.53,10.91;8,112.48,222.46,280.18,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,218.36,208.91,284.28,10.91">Automatic fact-checking using context and discourse information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mihaylova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,112.48,222.46,211.46,10.91">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,236.01,394.53,10.91;8,112.66,249.56,393.33,10.91;8,112.66,263.11,394.62,10.91;8,112.48,276.66,394.70,10.91;8,112.28,290.20,394.91,10.91;8,112.66,303.75,80.57,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,444.71,249.56,61.28,10.91;8,112.66,263.11,374.88,10.91">The clef-2023 checkthat! lab: Checkworthiness, subjectivity, political bias, factuality, and authority</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,189.54,290.20,150.64,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="506" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,317.30,394.53,10.91;8,112.66,330.85,394.53,10.91;8,112.14,344.40,393.85,10.91;8,112.66,357.95,394.52,10.91;8,112.66,371.50,175.52,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,180.33,344.40,325.65,10.91;8,112.66,357.95,30.66,10.91">Overview of the CLEF-2023 CheckThat! lab task 2 on subjectivity in news articles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>-C. No</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Leistra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Turkmen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.71,357.95,341.47,10.91;8,112.66,371.50,48.25,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,385.05,393.33,10.91;8,112.66,398.60,394.62,10.91;8,112.31,412.15,394.86,10.91;8,112.36,425.70,257.56,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,295.56,385.05,210.43,10.91;8,112.66,398.60,71.52,10.91">Polarization in the contemporary political and media landscape</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2020.07.005</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2020.07.005,politicalIdeologies" />
	</analytic>
	<monogr>
		<title level="j" coord="8,192.72,398.60,177.51,10.91">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="223" to="228" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,439.25,393.33,10.91;8,112.66,452.79,393.33,10.91;8,112.66,466.34,232.49,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,435.70,439.25,70.29,10.91;8,112.66,452.79,235.82,10.91">Subjectivita: An italian corpus for subjectivity detection in newspapers</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bolognini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Inajetovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ivasiuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.75,452.79,20.92,10.91">CLEF</title>
		<title level="s" coord="8,474.92,453.81,31.07,9.72;8,112.66,467.36,112.43,9.72">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,479.89,393.33,10.91;8,112.66,493.44,313.71,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09543</idno>
		<title level="m" coord="8,213.83,479.89,292.16,10.91;8,112.66,493.44,183.73,10.91">Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,506.99,394.53,10.91;8,112.66,520.54,132.15,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Coward</surname></persName>
		</author>
		<title level="m" coord="8,168.30,506.99,334.23,10.91">Speaking personally: The rise of subjective and confessional journalism</title>
		<imprint>
			<publisher>Bloomsbury Publishing</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,534.09,395.17,10.91;8,112.66,547.64,392.81,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,221.74,534.09,286.09,10.91;8,112.66,547.64,235.75,10.91">subjectivity&apos;in newspaper reports on &apos;controversial&apos;and &apos;emotional&apos;debates: An appraisal and controversy analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Jakaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,356.59,547.64,80.17,10.91">Language Matters</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="3" to="21" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,561.19,393.33,10.91;8,112.66,574.74,200.12,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,159.48,561.19,346.51,10.91;8,112.66,574.74,59.35,10.91">Valuing subjectivity in journalism: Bias, emotions, and self-interest as tools in arts reporting</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Chong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,180.37,574.74,48.47,10.91">Journalism</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="427" to="443" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,588.29,393.33,10.91;8,112.66,601.84,220.60,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03654</idno>
		<title level="m" coord="8,258.25,588.29,247.74,10.91;8,112.66,601.84,38.60,10.91">DeBERTa: Decoding-enhanced bert with disentangled attention</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,615.39,395.17,10.91;8,112.66,628.93,393.33,10.91;8,112.66,642.48,107.17,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11934</idno>
		<title level="m" coord="8,489.01,615.39,18.83,10.91;8,112.66,628.93,318.65,10.91">Raffel, mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,656.03,394.53,10.91;8,112.30,669.58,373.62,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05053</idno>
		<title level="m" coord="8,112.30,669.58,243.67,10.91">Xnli: Evaluating cross-lingual sentence representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,395.01,10.91;9,112.66,100.52,188.31,10.91" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Biewald</surname></persName>
		</author>
		<ptr target="https://www.wandb.com/,softwareavailablefromwandb.com" />
		<title level="m" coord="9,163.90,86.97,197.33,10.91">Experiment tracking with weights and biases</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,393.58,10.91;9,112.33,127.61,296.49,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="9,217.68,114.06,186.94,10.91">Fixing weight decay regularization in adam</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1711.05101" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,394.53,10.91;9,112.66,154.71,156.95,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,172.42,141.16,325.94,10.91">Reflection of subjectivity and objectivity in turkish newspaper reportage</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,154.71,117.23,10.91">Electronic Turkish Studies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,393.80,10.91;9,112.66,181.81,393.32,10.91;9,112.33,195.36,102.41,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,257.53,168.26,248.93,10.91;9,112.66,181.81,225.35,10.91">Subjectivity and objectivity in turkish causal connectives? results from a first corpus study on çünkü and için</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Çokal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zeyrek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">J</forename><surname>Sanders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,345.74,181.81,160.24,10.91;9,112.33,195.36,34.60,10.91">Discourse Meaning: The View from Turkish</title>
		<imprint>
			<biblScope unit="volume">341</biblScope>
			<biblScope unit="page">223</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,393.33,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,393.32,10.91;9,112.66,249.56,393.33,10.91;9,112.66,263.11,394.03,10.91;9,112.66,276.66,185.51,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,323.15,208.91,182.83,10.91;9,112.66,222.46,186.91,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423.doi:10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="9,327.87,222.46,178.11,10.91;9,112.66,236.01,393.32,10.91;9,112.66,249.56,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="9,112.66,290.20,393.70,10.91;9,112.66,303.75,361.70,10.91" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Van Cranenburgh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Noord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.09582</idno>
		<ptr target="http://arxiv.org/abs/1912.09582" />
		<title level="m" coord="9,460.65,290.20,45.71,10.91;9,112.66,303.75,83.62,10.91">BERTje: A Dutch BERT Model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,317.30,394.52,10.91;9,112.66,330.85,393.33,10.91;9,112.66,344.40,394.03,10.91;9,112.66,357.95,389.43,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,273.61,317.30,228.56,10.91">RobBERT: a Dutch RoBERTa-based Language Model</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Delobelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Berendt</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.292</idno>
		<ptr target="https://www.aclweb.org/anthology/2020.findings-emnlp.292.doi:10.18653/v1/2020.findings-emnlp.292" />
	</analytic>
	<monogr>
		<title level="m" coord="9,127.30,330.85,378.69,10.91;9,112.66,344.40,128.97,10.91">Findings of the Association for Computational Linguistics: EMNLP 2020, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3255" to="3265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,393.58,10.91;9,112.66,385.05,394.53,10.91;9,112.66,398.60,22.69,10.91" xml:id="b23">
	<monogr>
		<title level="m" coord="9,397.38,371.50,108.86,10.91;9,112.66,385.05,290.22,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum, CLEF 2023</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michalis</forename><surname>Vlachos</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
