<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.70,15.42;1,89.29,106.66,388.55,15.42;1,89.29,128.58,166.39,15.43;1,89.29,150.91,231.64,11.96">CUCPLUS at CheckThat! 2023: Text Combination and Regularized Adversarial Training for News Media Factuality Evaluation Notebook for the CheckThat! Lab at CLEF 2023</title>
				<funder>
					<orgName type="full">Fundamental Research Funds for the Central Universities</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,54.10,11.96"><forename type="first">Chenxin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Communication University of China</orgName>
								<address>
									<postCode>100024</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,156.03,176.82,52.15,11.96"><forename type="first">Ruijin</forename><surname>Xue</surname></persName>
							<email>xueruijin@cuc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Communication University of China</orgName>
								<address>
									<postCode>100024</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,220.83,176.82,59.79,11.96"><forename type="first">Chichen</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Communication University of China</orgName>
								<address>
									<postCode>100024</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.25,176.82,58.16,11.96"><forename type="first">Weijian</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Communication University of China</orgName>
								<address>
									<postCode>100024</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,394.39,176.82,46.28,11.96"><forename type="first">Xiao</forename><surname>Han</surname></persName>
							<email>hanxiao@cuc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Communication University of China</orgName>
								<address>
									<postCode>100024</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.70,15.42;1,89.29,106.66,388.55,15.42;1,89.29,128.58,166.39,15.43;1,89.29,150.91,231.64,11.96">CUCPLUS at CheckThat! 2023: Text Combination and Regularized Adversarial Training for News Media Factuality Evaluation Notebook for the CheckThat! Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">20D0BACC3FE44C0D07CC406F763386C4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Factuality</term>
					<term>Media-level</term>
					<term>RoBERTa</term>
					<term>Regularized Adversarial Training</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The increasing usage of social media and digital technology has revolutionized the dissemination of news and information, making it easier to share a vast array of events and information. However, the credibility of news shared on social media continues to be a concern, as it often includes misleading and inaccurate information. Nonetheless, the traditional news media still plays a critical role in publicizing event information. The point of view on how to combat fake news has shifted towards the evaluation of news media credibility. Warning the source of false news increases the possibility of identifying and addressing it early on during the news release and early communication stages. This study describes our performance in the CheckThat! Lab Task 4 Factuality of Reporting of News Media. For the text feature of news, we conducted targeted preprocessing activities and utilized diverse article phrases to determine media credibility levels. Additionally, we adopted RoBERTa and regularized adversarial training to minimize the impact of redundant data and improve model robustness. Our official submission to the English version of CLEF-2023 CheckThat! Lab Task 4 was ranked first with a MAE score of 0.295.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>News media plays a vital role in disseminating important information to the public, but there is a growing concern regarding the biases of different media outlets when reporting specific events <ref type="bibr" coords="1,120.20,492.36,11.32,10.91" target="#b0">[1]</ref>. Therefore, it is crucial to ensure the authenticity of news reports, although research in this area is currently lacking. False information and fake news detection is primarily related to solving this issue. Researchers in the field of natural language processing have attempted various techniques <ref type="bibr" coords="1,178.06,533.01,11.59,10.91" target="#b1">[2]</ref>, such as stance detection <ref type="bibr" coords="1,310.43,533.01,11.58,10.91" target="#b2">[3]</ref>, rumor detection <ref type="bibr" coords="1,406.01,533.01,11.59,10.91" target="#b3">[4]</ref>, and fact-checking organizations such as Snopes, FactCheck and Politifact <ref type="bibr" coords="1,336.66,546.56,11.46,10.91" target="#b4">[5]</ref>. However, the fact-checking speed of the methods is far from adequate as they cannot keep up with the speed of information transmission. Consequently, they fail to effectively prevent the early-stage dissemination of false news. Furthermore, delayed fact-checking is often distrusted. Hence, the approach of combating false news is now centered on its release sources. This involves assessing the credibility of news media and warning them of the presence of false news. With early warning, it is more likely to identify false news during the news release stage and early dissemination, and take appropriate measures.</p><p>To continue to focus on media credibility assessments, we attended the CheckThat! Lab at CLEF 2023 <ref type="bibr" coords="2,152.06,154.71,11.59,10.91" target="#b5">[6]</ref>. The CheckThat! Lab has held workshop for five tasks. We participate the English version of Task 4 <ref type="bibr" coords="2,203.16,168.26,12.78,10.91" target="#b6">[7]</ref> which requires to determine the level of factuality of a document or a news outlet. Our official submission was ranked first with a MAE score of 0.295.</p><p>Our main contributions can be summarized as follows:</p><p>â€¢ We analyzed the performance of the existing PLM models including RoBERTa <ref type="bibr" coords="2,472.98,219.27,11.58,10.91" target="#b7">[8]</ref>, De-BERTa <ref type="bibr" coords="2,148.17,232.81,11.28,10.91" target="#b8">[9]</ref>, and Longfomer <ref type="bibr" coords="2,234.49,232.81,17.76,10.91" target="#b9">[10]</ref> on this task, and finally completed the task with RoBERTa. â€¢ Our observations reveal that news report titles are usually brief and contain the key semantics, whereas the beginning of the article supplements the title, whereas the ending reflects the attitude of the editor or provides a summary of the article. We conducted an experimental comparison of the various input combinations of articles parts to observe differences in the results. â€¢ Furthermore, we also noted that different media outlets vary in terms of the number of articles, length, and topics of focus, which was also a source of inspiration. So we incorporated R-AT <ref type="bibr" coords="2,202.41,343.15,17.91,10.91" target="#b10">[11]</ref> to improve our model's effectiveness.</p><p>The remainder of this paper is organized as follows. In Section 2, we provide relevant work relevant to this study. We will then discuss the method in Section 3. Results of the experiments and a detailed discussion are provided in sections 4,5. Finally, we have summarized the studies in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The existing work on media credibility assessment mainly tests the text content of various news media websites to judge the authenticity of their reports <ref type="bibr" coords="2,351.28,479.89,16.41,10.91" target="#b11">[12]</ref>. Baly et al. <ref type="bibr" coords="2,426.49,479.89,13.00,10.91" target="#b4">[5]</ref> first proposed the media credibility assessment task, because previous work assessed credibility based on a single news, tweet or statement, and here the authors view the text published by news sites as a whole. The author used the ordinal number of age prediction in computer vision regression model for media credibility evaluation and media political bias assessment, and made a lot of experiments to verify the different characteristics of the performance of the results, the author found that the text content is the biggest influence on performance characteristics, using multi-task joint model can improve performance. Indeed, their experimental results on manual fact-checking and classification datasets demonstrate that state-of-the-art text representations can only achieve about 65-71% true prediction accuracy and 70-85% biased prediction accuracy, depending on the dataset.</p><p>Multimedia has become an important carrier for all news media to deliver news and information. A report usually includes multiple modal information, and the study of tampering detection in photos and videos has been deepening into <ref type="bibr" coords="2,335.28,656.03,16.09,10.91" target="#b12">[13]</ref>, so visual features are increasingly added to predict the authenticity <ref type="bibr" coords="2,237.72,669.58,16.43,10.91" target="#b13">[14,</ref><ref type="bibr" coords="2,256.88,669.58,14.03,10.91" target="#b14">15]</ref> of news media reports. In addition to multimodal information such as text and images, it can also detect the relevant features such as the domain name, certificate and hosting properties <ref type="bibr" coords="3,393.69,348.35,16.19,10.91" target="#b15">[16]</ref>, web design <ref type="bibr" coords="3,469.09,348.35,17.86,10.91" target="#b16">[17]</ref> and its linked website <ref type="bibr" coords="3,167.08,361.90,16.09,10.91" target="#b17">[18]</ref>, so as to estimate the credibility of the news media. Baly et al. <ref type="bibr" coords="3,455.28,361.90,17.75,10.91" target="#b18">[19]</ref> further used social context information from the media and explored the impact of news versus social context.</p><p>An alternative method used to assess news media credibility is based on news media website similarity. A more reliable indicator of the similarity of news media sites is to examine how much followers of different news media overlap <ref type="bibr" coords="3,311.00,429.64,16.41,10.91" target="#b19">[20]</ref>. Panayotov et al. <ref type="bibr" coords="3,412.93,429.64,18.06,10.91" target="#b20">[21]</ref> proposed a new model based on graph neural networks that models the audience overlap between media to predict the authenticity and bias of the whole news media. The effect is significantly improved than the previous model.</p><p>Evaluating news media credibility can also be based on prior knowledge, Hardalov et al. <ref type="bibr" coords="3,488.23,483.84,17.76,10.91" target="#b21">[22]</ref> believe that people believe in manual fact checking and therefore propose to perform automatic fact checking by verifying whether the input statement has been checked by a professional fact examiner and returning an article explaining its decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The overall framework of our approach is shown in Figure <ref type="figure" coords="3,368.31,583.11,3.81,10.91" target="#fig_0">1</ref>. It consists four parts: data preprocess, text combination, RoBERTa and regularization adversarial training.</p><p>For Task 4: a level of factuality of a document or a news outlet. We treat it as a classification task. Our input is the collection of the first N articles in the same news outlet (A1, A2, ..., AN). Mosaic of the article that outputs the predicted probability of each confidence level reported(P1, P2, P3).</p><p>Firstly, we used the tools to preprocess the articales and remove the noise words. Secondly, we take some articles as input, set three different input forms and get different input data; then input different forms of text into RoBERTa to output the prediction probability of each credibility level; we also build an adversarial training process using R-AT to help the model fight overfitting and learn more universal features. Finally, we aggregate the prediction results of the models trained by different input forms to obtain the final output results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Preprocess</head><p>Through the observation of the text, we find that some news text only has the title and lacks the content, and the news text contains a large amount of noise data such as URL, special symbols and etc. For title-only news, we copy the title as its content text.</p><p>For noise in news text, we used the clean-text<ref type="foot" coords="4,308.06,243.33,3.71,7.97" target="#foot_0">1</ref> tool to clear line breaks, ASCII codes, URL, email, and punctuation from the title and content, replace all numbers with [number] and convert all uppercase letters to lower case letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Text Combination</head><p>For the news text, the author of the news needs to describe the story by the whole article in as concise language as possible, the title is often the most critical semantic information to let the reader get direct understanding of the article. In addition, we found that the beginning and end of the news tend to provide more important semantic information.</p><p>The first sentence or the first paragraph of the news often serves as the lead language of the whole article, briefly revealing the content of the full text. The last sentence or the last paragraph of the news captures the overall content of the article and gives the final conclusion, which often contains the main point that the author wants to convey.</p><p>Based on the above observations, we used three ways to recombine the text and then input it into the model.</p><p>â€¢ Only title: We try to use only all the headlines to which the media belongs as input, connecting each title with the separator Token [SEP]:</p><formula xml:id="formula_0" coords="4,219.35,505.65,287.29,14.19">{[ğ¶ğ¿ğ‘†]ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ 1 [ğ‘†ğ¸ğ‘ƒ ] . . . . . . ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ ğ‘ [ğ‘†ğ¸ğ‘ƒ ]},<label>(1)</label></formula><p>â€¢ Head-tail combination: Since RoBERTa can handle up to 512 Tokens in each sequence (multiple news text splicing), we will only take a part of the news content as a representative of the whole story. Following our observations, we used the Head-Tail Truncation approach to process the input news text content and connect with the title using the separator Token [SEP]:</p><formula xml:id="formula_1" coords="4,139.47,611.45,367.17,14.19">{[ğ¶ğ¿ğ‘†]ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ 1 [ğ‘†ğ¸ğ‘ƒ ]ğ´ â„ğ‘’ğ‘ğ‘‘ 1 + ğ´ ğ‘¡ğ‘ğ‘–ğ‘™ 1 [ğ‘†ğ¸ğ‘ƒ ] . . . . . . [ğ‘†ğ¸ğ‘ƒ ]ğ´ â„ğ‘’ğ‘ğ‘‘ ğ‘ + ğ´ ğ‘¡ğ‘ğ‘–ğ‘™ ğ‘ [ğ‘†ğ¸ğ‘ƒ ]},<label>(2)</label></formula><p>â€¢ Only tail: we found that the text tail truncation way can achieve and close to only title performance, but predict the correct results and only title correct result only less overlap, we think may be tail truncation to obtain the conclusion of the article, so as to better predict some suspected of title fraud, so we extra built using the title and text content end as input:</p><formula xml:id="formula_2" coords="5,151.74,139.40,354.90,14.19">{[ğ¶ğ¿ğ‘†]ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ 1 [ğ‘†ğ¸ğ‘ƒ ]ğ´ ğ‘¡ğ‘ğ‘–ğ‘™ 1 [ğ‘†ğ¸ğ‘ƒ ] . . . . . . [ğ‘†ğ¸ğ‘ƒ ]ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ ğ‘ [ğ‘†ğ¸ğ‘ƒ ]ğ´ ğ‘¡ğ‘ğ‘–ğ‘™ ğ‘ [ğ‘†ğ¸ğ‘ƒ ]},<label>(3)</label></formula><p>where ğ´ ğ‘¡ğ‘–ğ‘¡ğ‘™ğ‘’ ğ‘– is the title of each new, ğ´ â„ğ‘’ğ‘ğ‘‘ ğ‘– is the truncated text of the starting part of each news content, ğ´ ğ‘¡ğ‘ğ‘–ğ‘™ ğ‘– is the truncated text of the end part of each news content, and [CLS] is the special token corresponding to the feature vector used for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Factuality Assessment</head><p>We used the basic language model of RoBERTa to assess news outlet credibility. The predicted score for each confidence level is obtained by passing the output of [CLS] token from RoBERTa to the pooling layer, and then passing through the two linear layers and dropout activated by the GELU to obtain the final output. The sizes of the two linear layers are (1024,128) and (128,3) respectively.</p><p>Since we observed that in the training set and validation set, high confidence media accounted for the majority of the overall proportion, mixed credibility and low confidence media accounted for less, so we used the Focal Loss <ref type="bibr" coords="5,249.76,338.34,18.07,10.91" target="#b22">[23]</ref> alleviate class imbalance problem, the loss function reduces the weight of a large number of simple samples in training, let the model pay more attention to difficult, misassigned samples. We assigned a value to the ğ›¼ coefficient for each category in Focal Loss, such as a 0.35 ğ›¼ for high confidence.</p><formula xml:id="formula_3" coords="5,220.72,401.20,285.92,13.65">ğ¿ğ‘œğ‘ ğ‘  1 = -ğ›¼ Ã— (1 -ğ‘) ğ›¾ Ã— ğ‘™ğ‘œğ‘”(ğ‘),<label>(4)</label></formula><p>where ğ‘ is the predicted probability corresponding to the true credibility level of the sample, ğ›¼ is the weight coefficient corresponding to each category to control the relative importance of the loss of different categories, ğ›¾ represents the gap between the difficult sample and the simple sample. Its values higher, the loss of the difficult sample more important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Regularized Adversarial Training</head><p>Although the input text was preprocessed by the data, there is still a large amount of information irrelevant to the credibility of the media reports, so we used adversarial training to enhance the generalization ability of the model and avoid serious overfitting of the model because of learning information irrelevant to the true label.</p><p>Adversarial training is a commonly used training strategy to enhance the robustness of the model, but it is easy to reduce the performance of the model due to the inconsistency between training stage and testing stage. Therefore, Shiwen Ni et al. proposed a training strategy to regularize the output of adversarial training through dropout, R-AT, which makes the output probability distribution of different sub-models generated by dropout remain consistent under the same adversarial sample.</p><p>Specifically, R-AT dynamically perturbs the input embedding vector to generate adversarial samples and then passes the adversarial samples to two dropout sub-models to generate two probability distributions. Ultimately, R-AT minimizes the bidirectional KL divergence of the two output distributions as predicted by a regularization model.</p><p>We replaced the original cross-entropy loss of R-AT with the Focal Loss, and in each training step, we first performed a forward propagation and backpropagation of a clean sample.</p><p>Then following the R-AT setting, we using the rapid gradient method (FGM) proposed by Miyato et al. <ref type="bibr" coords="6,150.35,154.71,18.07,10.91" target="#b23">[24]</ref> to perturb the word embedding layer of the model, and then conduct two forward propagation to obtain two confrontation samples, and calculate the corresponding classification loss and KL divergence of the two confrontation samples:</p><formula xml:id="formula_4" coords="6,203.67,204.85,302.97,16.48">ğ¿ğ‘œğ‘ ğ‘  ğ´ğ‘‡ 1 = -ğ›¼ Ã— (1 -ğ‘ ğ´ğ‘‡ 1 ) ğ›¾ Ã— ğ‘™ğ‘œğ‘”(ğ‘ ğ´ğ‘‡ 1 ),<label>(5)</label></formula><formula xml:id="formula_5" coords="6,203.67,238.43,302.97,16.48">ğ¿ğ‘œğ‘ ğ‘  ğ´ğ‘‡ 2 = -ğ›¼ Ã— (1 -ğ‘ ğ´ğ‘‡ 2 ) ğ›¾ Ã— ğ‘™ğ‘œğ‘”(ğ‘ ğ´ğ‘‡ 2 ),<label>(6)</label></formula><formula xml:id="formula_6" coords="6,207.86,272.42,294.93,24.43">ğ¿ğ‘œğ‘ ğ‘  ğ¾ğ¿ = ğ· ğ¾ğ¿ (ğ‘ƒ ||ğ‘„) + ğ· ğ¾ğ¿ (ğ‘„||ğ‘ƒ ) 2 . (<label>7</label></formula><formula xml:id="formula_7" coords="6,502.78,279.07,3.86,10.91">)</formula><p>The loss function of the second backpropagation is finally obtained:</p><formula xml:id="formula_8" coords="6,149.61,324.42,357.03,14.19">ğ¿ğ‘œğ‘ ğ‘  2 = ğ¿ğ‘œğ‘ ğ‘  1 + ğ‘˜ Ã— (ğ¿ğ‘œğ‘ ğ‘  ğ´ğ‘‡ 1 + ğ¿ğ‘œğ‘ ğ‘  ğ´ğ‘‡ 2 ) + (1 -ğ‘˜) Ã— ğ¿ğ‘œğ‘ ğ‘  ğ¾ğ¿ ,<label>(8)</label></formula><p>where ğ‘ ğ´ğ‘‡ ğ‘– is the result of the output of the model after using FGM, ğ· ğ¾ğ¿ is the KL distance between two vectors. We rewrite the original loss function of R-AT, rewriting the original fixed weight parameter as an adaptive hyperparameter ğ‘˜ , which is used to adjust the weight of multiple different loss functions during the second forward propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Task Description</head><p>The task was organized as CLEF 2023 -CheckThat! Lab. In task 4 of CheckThat! Lab, the core idea of task is to determine the level of factuality of a document or a news outlet. The task is defined as follows.</p><p>The Task 4 ask to predict the factuality of reporting at the media level, given the URL to a news outlet (e.g., www.cnn.com): low, mixed, and high. This is a English version task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Data</head><p>CLEF 2023 -CheckThat! Lab provides the data for conducting the factuality level prediction of news outlet, which includes the training set and the validation set to train the model, and later releases the test set to evaluate the model. The evaluation index provided by the competition is MAE (average absolute error). The result is smaller of MAE score, the gap between the prediction label and the real label is smaller, that is, the prediction result of model is more accurate. where Ì‚ï¸€ ğ‘¦ ğ‘– is the prediction label, ğ‘¦ ğ‘– is the real label, and ğ‘› is the number of media. The official provided data is provided in TSV and JSON format. The TSV file contains three columns of news source, JSON file path and label. The JSON file path points to the JSON file containing the list of articles. A JSON file is named after the media name and contains the news source website, article list, tag text (e. g., high, mixed, low), and tags (digital format, e. g., 2,1,0). The article list contains the title and the content. The distribution of tags in the training and validation sets is shown in Table <ref type="table" coords="7,233.66,266.14,3.66,10.91" target="#tab_0">1</ref>. In both datasets, sites with tag 2, followed by those with tag 1 and those with tag 0 were the least, and the distribution was roughly 1:2:5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğ‘€ ğ´ğ¸</head><formula xml:id="formula_9" coords="6,272.81,653.70,233.83,25.70">= âˆ‘ï¸€ğ‘› ğ‘–=1 | Ì‚ï¸€ ğ‘¦ ğ‘– -ğ‘¦ ğ‘– | ğ‘› ,<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Baseline</head><p>CLEF 2023 -CheckThat! Lab provided four baseline Model: Mid-label, Majority, Random, and Ngram. However, their baseline is not a learnable model, and to better validate the effectiveness of our pre-and-back truncation approach and R-AT, we additionally designed a baseline method for comparison. The method uses RoBERTa-Large as backbone, adds a pooling layer, two fully connected layers activated by the GeLU function and a softmax layer after the features extracted by backbone. Loss function is Focal Loss for multiple class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Experimental Setting</head><p>We use the Adam optimizer with a learning rate of 5e-4 and adjusted the learning rate with Cosine Annealing. The Weight decay is 5e-3. In experiments, we use Average Pooling. The loss function is Focal Loss for multiple class with ğ›¾ = 2, ğ›¼ = [0.1, 0.5, 0.4]. The epoch is 50, the batch size is 8 and the maximum length for the text input is 512.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Official Submission</head><p>The baseline methods' results for the validation set are shown in Table <ref type="table" coords="7,400.01,567.13,3.66,10.91" target="#tab_1">2</ref>. The Ngram model get the best performance with a MAE score of 0.392.</p><p>Our official submission to the English version of CLEF-2023 CheckThat! Lab Task 4 was ranked first with a MAE score of 0.295. The leaderborad is shown as Table <ref type="table" coords="7,422.43,607.78,3.74,10.91">3</ref>.</p><p>This good performance is partly due to our model fusion, and we use four models to vote. Each model takes the RoBERTa-Large as the backbone and adopts the multi-classification Focal Loss, doing the same data preprocessing for the input of each model. The four models differ in the content of input, whether R-AT and whether Mean Pooling. Details of the model are as follows:</p><p>â€¢ Model 1: The input is the title of the article in the website.</p><p>â€¢ Model 2: The input is the title of the article in the website, and use R-AT to normalize the confrontation training through dropout. â€¢ Model 3: The input is the title and content of the article in the website, where the content of the first 150 after 100. An Average Pooling layer is connected after the features extracted by RoBERTa-Large. â€¢ Model 4: The input is the title and content of the article in the website, where the content is intercepted after 300. An Average Pooling layer is connected after the features extracted by RoBERTa-Large.</p><p>Through the method of model ensemble, the final performance improve, which indicates that different inputs and model structures will make the model have different focuses and biases in predicting media factuality level. Using model voting can more comprehensively predict news outlet credibility, and resulting in higher accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Text Combination</head><p>To prove the content of the input can affect the prediction results of the model, as well as to obtain the combinations of inputs with more accurate prediction effects, we conducted the combined experiments on the input content. For all experiment, we adopt RoBERTa-Large as  <ref type="table" coords="9,305.85,453.27,3.81,10.91" target="#tab_2">4</ref>, Titile-Only represents using only the title as input, F100_B300 represents 100 and 300 intercepted news content, others in the same way. According to the experimental results, we can see that the effect of using only the title or intercepting the last 300 is the best, and the effect of intercepting the first 100 and the last 150 and the last 200 is not better. This also confirms that the title has the core semantics of the news, and the beginning and end of the content are often the summary of the news. Therefore, it is feasible for us to only use the title or properly intercept the content of the article, and we can use this method to deal with the long text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">R-AT with Different Weights</head><p>We studied the effect of weights in the R-AT loss function, following the recommendations in the R-AT origin paper <ref type="bibr" coords="9,186.46,610.99,15.93,10.91" target="#b9">[10]</ref>, and we adopted a consistent 0.5 Dropout rate for two outputs, which only adjusted the weight proportion of multiple loss functions computed at the second output.</p><p>Since we rewrite the original R-AT loss function as an adaptive R-AT loss function, we only need to adjust k here to change the proportion of the loss function and KL Loss during the second forward propagation in the loss function. The experimental results are shown in Table <ref type="table" coords="10,297.35,258.80,3.66,10.91" target="#tab_3">5</ref>. When k is zero, it represents only using FGM as adversarial training, and with ğ‘˜ increased, the proportion of Focal Loss in the second forward spread increased, and correspondingly, the proportion of KL Loss decreased. It can be found that the best effect is achieved when the hyperparameters ğ‘˜ is 0.3.</p><p>Finally" we selected the output aggregation of the four models as our final submission. The models we choose are F0_300(k=0), F200_100(k=0.3), Title-Only(k=0.01) and Title-Only(k=0.3), we input the news reports of each media into four models , resulting in a list of four model outputs, and we select the mode in the list as the final prediction for each media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>In this paper, we propose a model based on regularization adversarial training to evaluate media credibility levels. This model can alleviate the redundancy caused by the large numbers of news in the data set unrelated to the media coverage, effectively avoid the serious overfitting phenomenon caused by learning the information unrelated to the real label, and enhance the generalization ability of the model.</p><p>Testing media credibility is a challenging task. In the case of limited data sets, many media coverage fields and wide information, it is difficult to avoid the impact of data set bias and improve the model performance. In future work, we plan to experiment with more pre-process techniques, better model the social environment, adopt a more perfect large-scale pre-training language model and adversarial training strategies to improve the performance of the model in the real environment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,297.20,204.37,8.93;3,89.29,84.19,416.71,200.44"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall framework of our approach.</figDesc><graphic coords="3,89.29,84.19,416.71,200.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,88.99,90.49,279.81,67.65"><head>Table 1</head><label>1</label><figDesc>Label distribution of the datasets</figDesc><table coords="7,226.48,119.88,142.32,38.25"><row><cell>Factuality Level</cell><cell>0</cell><cell>1</cell><cell>2</cell></row><row><cell>train</cell><cell cols="3">121 233 593</cell></row><row><cell>dev</cell><cell>16</cell><cell>32</cell><cell>72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.99,90.49,253.26,229.29"><head>Table 2</head><label>2</label><figDesc>Baseline Results on the dev set</figDesc><table coords="8,88.99,119.88,253.26,199.89"><row><cell cols="2">Baseline MAE</cell></row><row><cell cols="2">Mid-label 0.733</cell></row><row><cell cols="2">Majority 0.533</cell></row><row><cell cols="2">Random 0.800</cell></row><row><cell>Ngram</cell><cell>0.392</cell></row><row><cell>Table 3</cell><cell></cell></row><row><cell>Leaderboard</cell><cell></cell></row><row><cell>Team</cell><cell>MAE</cell></row><row><cell>CUCPLUS</cell><cell>0.295</cell></row><row><cell cols="2">NLPIR-UNED 0.344</cell></row><row><cell>Accenture</cell><cell>0.467</cell></row><row><cell>UBCS</cell><cell>0.541</cell></row><row><cell>Awakened</cell><cell>0.705</cell></row><row><cell>Random</cell><cell>0.943</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,88.99,90.49,417.20,373.69"><head>Table 4</head><label>4</label><figDesc>Results of different input</figDesc><table coords="9,259.40,122.10,76.47,277.36"><row><cell>Input</cell><cell>MAE</cell></row><row><cell cols="2">Title-Only 0.402</cell></row><row><cell cols="2">F100_B200 0.459</cell></row><row><cell cols="2">F200_B100 0.451</cell></row><row><cell cols="2">F100_B250 0.434</cell></row><row><cell cols="2">F250_B100 0.451</cell></row><row><cell cols="2">F100_B150 0.443</cell></row><row><cell cols="2">F150_B100 0.410</cell></row><row><cell cols="2">F150_B200 0.418</cell></row><row><cell cols="2">F200_B150 0.418</cell></row><row><cell cols="2">F50_B250 0.434</cell></row><row><cell cols="2">F250_B50 0.426</cell></row><row><cell cols="2">F50_B150 0.434</cell></row><row><cell cols="2">F150_B50 0.426</cell></row><row><cell cols="2">F175_B175 0.443</cell></row><row><cell>F0_B300</cell><cell>0.402</cell></row><row><cell>F300_B0</cell><cell>0.475</cell></row><row><cell>F0_B100</cell><cell>0.418</cell></row><row><cell>F100_B0</cell><cell>0.451</cell></row><row><cell>F0_B200</cell><cell>0.410</cell></row><row><cell>F200_B0</cell><cell>0.484</cell></row><row><cell>F0_B400</cell><cell>0.426</cell></row><row><cell>F400_B0</cell><cell>0.427</cell></row></table><note coords="9,89.29,426.17,416.90,10.91;9,89.29,439.72,385.74,10.91;9,100.20,453.27,202.75,10.91"><p><p>backbone of models, and the extracted features of backbone are fed into two linear layers for classification and prediction. We use Focal Loss for multiple class as our Loss function.</p>The experimental results are shown in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,88.99,90.49,241.77,141.60"><head>Table 5 R</head><label>5</label><figDesc>-AT with Different Weights</figDesc><table coords="10,264.52,122.10,66.24,109.98"><row><cell cols="2">Weights MAE</cell></row><row><cell>k = 0</cell><cell>0.418</cell></row><row><cell cols="2">k = 0.01 0.393</cell></row><row><cell cols="2">k = 0.05 0.418</cell></row><row><cell>k = 0.1</cell><cell>0.402</cell></row><row><cell>k = 0.3</cell><cell>0.377</cell></row><row><cell>k = 0.5</cell><cell>0.410</cell></row><row><cell>k = 0.7</cell><cell>0.385</cell></row><row><cell>k = 0.9</cell><cell>0.393</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,92.57,671.03,130.04,8.97"><p>https://github.com/jfilter/clean-text</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Acknowledgments</head><p>We would like to thank the organizers and other participants in the challenge. We are thankful to <rs type="institution">Key Laboratory of Intelligent Convergence Media, Ministry of Education, Communication University of China</rs>. Finally, thanks to all the anonymous reviewers for their suggestions.</p><p>Part of this work is supported by "the <rs type="funder">Fundamental Research Funds for the Central Universities</rs>".</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,111.28,394.61,10.91;11,112.66,124.83,393.98,10.91;11,112.41,138.38,23.60,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,260.82,111.28,246.46,10.91;11,112.66,124.83,165.70,10.91">Automated identification of media bias in news articles: an interdisciplinary literature review</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hamborg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Donnay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,288.48,124.83,187.71,10.91">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,151.93,395.17,10.91;11,112.66,165.48,395.01,10.91;11,112.66,179.03,268.70,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,190.50,151.93,317.33,10.91;11,112.66,165.48,16.10,10.91">Cognition security protection about the mass: A survey of key technologies</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.16196/j.cnki.issn.1673-4793.2022.03.009</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,136.74,165.48,325.76,10.91">Journal of Communication University of China(Science and Technology)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,192.57,395.17,10.91;11,112.66,206.12,393.33,10.91;11,112.33,219.67,395.33,10.91;11,112.66,233.22,323.23,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,260.46,192.57,247.37,10.91;11,112.66,206.12,48.93,10.91">Stance detection in fake news a combined feature representation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5510</idno>
		<ptr target="https://aclanthology.org/W18-5510.doi:10.18653/v1/W18-5510" />
	</analytic>
	<monogr>
		<title level="m" coord="11,184.81,206.12,321.17,10.91;11,112.33,219.67,231.88,10.91">Proceedings of the First Workshop on Fact Extraction and VERification (FEVER), Association for Computational Linguistics</title>
		<meeting>the First Workshop on Fact Extraction and VERification (FEVER), Association for Computational Linguistics<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,246.77,394.53,10.91;11,112.66,260.32,122.55,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,263.83,246.77,238.55,10.91">Exploiting context for rumour detection in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,127.29,260.32,78.05,10.91">Social Informatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,273.87,393.33,10.91;11,112.66,287.42,267.87,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01765</idno>
		<title level="m" coord="11,361.00,273.87,144.99,10.91;11,112.66,287.42,137.91,10.91">Predicting factuality of reporting and bias of news media sources</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,300.97,394.53,10.91;11,112.66,314.52,393.33,10.91;11,112.66,328.07,394.62,10.91;11,112.48,341.62,394.70,10.91;11,112.28,355.17,394.91,10.91;11,112.66,368.71,80.57,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,444.57,314.52,61.41,10.91;11,112.66,328.07,374.88,10.91">The clef-2023 checkthat! lab: Checkworthiness, subjectivity, political bias, factuality, and authority</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>BarrÃ³n-CedeÃ±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>StruÃŸ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,189.54,355.17,150.64,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="506" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,382.26,394.52,10.91;11,112.66,395.81,393.33,10.91;11,112.66,409.36,394.53,10.91;11,112.66,422.91,175.52,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,112.66,395.81,393.33,10.91;11,112.66,409.36,24.85,10.91">Overview of the CLEF-2023 CheckThat! lab task 4 on factuality of reporting of news media</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Panayotov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,161.23,409.36,345.96,10.91;11,112.66,422.91,48.25,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,436.46,395.17,10.91;11,112.66,450.01,395.01,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="11,137.85,450.01,241.29,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,463.56,393.33,10.91;11,112.66,477.11,168.38,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03654</idno>
		<title level="m" coord="11,261.90,463.56,244.09,10.91;11,112.66,477.11,38.60,10.91">Deberta: Decoding-enhanced bert with disentangled attention</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,490.66,395.01,10.91;11,112.66,506.65,97.35,7.90" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m" coord="11,270.90,490.66,205.60,10.91">Longformer: The long-document transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,517.76,395.16,10.91;11,112.66,531.30,394.53,10.91;11,112.28,544.85,395.38,10.91;11,112.66,558.40,297.51,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,238.39,517.76,269.43,10.91;11,112.66,531.30,37.03,10.91">Regularized adversarial training for natural language understanding</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R-At</forename></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.findings-emnlp.480" />
	</analytic>
	<monogr>
		<title level="m" coord="11,174.93,531.30,332.26,10.91;11,112.28,544.85,190.08,10.91">Findings of the Association for Computational Linguistics: EMNLP 2022, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6427" to="6440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,571.95,395.01,10.91;11,112.66,585.50,290.64,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,212.07,571.95,98.79,10.91">A survey of fake news</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zafarani</surname></persName>
		</author>
		<idno type="DOI">10.1145/3395046</idno>
		<ptr target="https://doi.org/10.1145%2F3395046.doi:10.1145/3395046" />
	</analytic>
	<monogr>
		<title level="j" coord="11,320.43,571.95,116.98,10.91">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,599.05,394.53,10.91;11,112.66,612.60,265.82,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,268.23,599.05,234.33,10.91">Media forensics on social media platforms: a survey</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pasquini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Amerini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Boato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,112.66,612.60,186.96,10.91">EURASIP Journal on Information Security</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,626.15,393.33,10.91;11,112.66,639.70,393.33,10.91;11,112.66,653.25,375.13,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,396.69,626.15,109.29,10.91;11,112.66,639.70,160.38,10.91">Spotfake: A multi-modal framework for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kumaraguru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Satoh</surname></persName>
		</author>
		<idno type="DOI">10.1109/BigMM.2019.00-44</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,325.49,639.70,180.50,10.91;11,112.66,653.25,132.11,10.91">IEEE Fifth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,666.80,393.33,10.91;12,112.66,86.97,394.51,10.91;12,112.66,102.96,110.72,7.90" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,209.90,666.80,296.09,10.91;12,112.66,86.97,99.31,10.91">Predicting image credibility in fake news over social media using multi-modal approach</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-021-06086-4</idno>
	</analytic>
	<monogr>
		<title level="j" coord="12,224.35,86.97,167.45,10.91">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,114.06,395.17,10.91;12,112.66,127.61,329.89,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hounsel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Borgolte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Feamster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.07684</idno>
		<title level="m" coord="12,417.09,114.06,90.74,10.91;12,112.66,127.61,200.17,10.91">Identifying disinformation websites using infrastructure features</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,141.16,395.17,10.91;12,112.66,154.71,393.33,10.91;12,112.14,168.26,395.53,10.91;12,112.66,181.81,155.44,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,471.14,141.16,36.69,10.91;12,112.66,154.71,213.86,10.91">A topicagnostic approach for identifying fake news pages</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Elghafari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<idno type="DOI">10.1145/3308560.3316739</idno>
		<ptr target="https://doi.org/10.1145%2F3308560.3316739.doi:10.1145/3308560.3316739" />
	</analytic>
	<monogr>
		<title level="m" coord="12,348.01,154.71,157.98,10.91;12,112.14,168.26,123.55,10.91">Companion Proceedings of The 2019 World Wide Web Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,195.36,393.33,10.91;12,112.66,208.91,60.04,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="12,290.95,195.36,215.04,10.91;12,112.66,208.91,29.07,10.91">Credibility assessment in the news : Do we need to read</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Fairbanks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Knauf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">B</forename><surname>Georgia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,222.46,393.33,10.91;12,112.26,236.01,394.93,10.91;12,112.66,249.56,122.77,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dinkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04518</idno>
		<title level="m" coord="12,459.87,222.46,46.11,10.91;12,112.26,236.01,390.58,10.91">What was written vs. who read it: News media profiling using text analysis and social media context</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,263.11,393.33,10.91;12,112.66,276.66,157.64,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aupetit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02000</idno>
		<title level="m" coord="12,328.44,263.11,177.55,10.91;12,112.66,276.66,28.12,10.91">Unsupervised user stance detection on twitter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,290.20,393.33,10.91;12,112.66,303.75,237.61,10.91" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Sencar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nabeel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05533</idno>
		<title level="m" coord="12,364.67,290.20,141.32,10.91;12,112.66,303.75,108.03,10.91">Greener: Graph neural networks for news media profiling</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,317.30,393.33,10.91;12,112.66,330.85,334.36,10.91" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chernyavskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ilvovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.04447</idno>
		<title level="m" coord="12,393.08,317.30,112.91,10.91;12,112.66,330.85,203.96,10.91">Crowdchecked: Detecting previously fact-checked claims in social media</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,344.40,394.61,10.91;12,112.66,357.95,395.01,10.91;12,112.66,371.50,143.58,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,327.53,344.40,159.84,10.91">Focal loss for dense object detection</title>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.324</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,136.67,357.95,269.07,10.91">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,385.05,393.33,10.91;12,112.66,398.60,185.48,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07725</idno>
		<title level="m" coord="12,269.51,385.05,236.48,10.91;12,112.66,398.60,55.98,10.91">Adversarial training methods for semi-supervised text classification</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
