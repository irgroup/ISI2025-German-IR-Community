<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,405.65,15.42;1,89.29,106.66,399.64,15.42;1,89.29,128.58,153.53,15.43">DSHacker at CheckThat! 2023: Check-Worthiness in Multigenre and Multilingual Content With GPT-3.5 Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,156.89,114.21,11.96"><forename type="first">Arkadiusz</forename><surname>Modzelewski</surname></persName>
							<email>arkadiusz.modzelewski@pja.edu.pl</email>
							<affiliation key="aff0">
								<orgName type="institution">Polish-Japanese Academy of Information Technology</orgName>
								<address>
									<addrLine>86 Koszykowa St</addrLine>
									<postCode>02-008</postCode>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.65,156.89,88.47,11.96"><forename type="first">Witold</forename><surname>Sosnowski</surname></persName>
							<email>witold.sosnowski@pja.edu.pl</email>
							<affiliation key="aff0">
								<orgName type="institution">Polish-Japanese Academy of Information Technology</orgName>
								<address>
									<addrLine>86 Koszykowa St</addrLine>
									<postCode>02-008</postCode>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.57,156.89,85.19,11.96"><forename type="first">Adam</forename><surname>Wierzbicki</surname></persName>
							<email>adam.wierzbicki@pja.edu.pl</email>
							<affiliation key="aff0">
								<orgName type="institution">Polish-Japanese Academy of Information Technology</orgName>
								<address>
									<addrLine>86 Koszykowa St</addrLine>
									<postCode>02-008</postCode>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,405.65,15.42;1,89.29,106.66,399.64,15.42;1,89.29,128.58,153.53,15.43">DSHacker at CheckThat! 2023: Check-Worthiness in Multigenre and Multilingual Content With GPT-3.5 Data Augmentation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">49102EB6308B0953BF87FFB30D03B319</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Check-Worthiness</term>
					<term>Fact-Checking</term>
					<term>XLM-RoBERTa</term>
					<term>GPT</term>
					<term>Data Augmentation</term>
					<term>Multilingual</term>
					<term>Multigenre</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article showcases our approach to check-worthiness detection, a task within the CheckThat! Lab of the 2023 CLEF Conference. This task aimed to design a system capable of determining if a claim, provided in diverse data formats such as tweets, debate snippets, and speech transcriptions, necessitates fact-checking. Our method combined a unified framework for processing content in three languages -English, Spanish and Arabic. At the heart of our system is the XLM-RoBERTa, a pre-trained multilingual model. To enhance its performance, we applied data augmentation strategies using GPT-3.5 provided by OpenAI, which included generating paraphrases and translating text fragments to create a rich dataset. The system's effectiveness is evidenced by its performance against baseline results in all languages, notably winning first place with an F1 score of 0.641 in the Spanish category. Additionally, our exploration sheds light on the attributes of the model's performance in processing different languages, highlighting its exceptional performance in Spanish and indicating room for improvement in handling complex Arabic language structures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>At a time when disinformation spreads rapidly through various channels, natural language processing (NLP) is becoming a powerful ally in the automatic identification and verification of claims. By extracting relevant information from claims, NLP plays a crucial role in capturing intent and context -essential attributes in assessing the veracity of a claim.</p><p>Language models, especially those rooted in deep learning, are an essential subset of NLP technologies that have shown great potential in claim identification and verification. Essentially adept at generating human-like text, language models are trained to assess the probability of word sequences, making them highly flexible and adept at understanding the complexities of natural language.</p><p>One of the remarkable advancements in language models is the adoption of Transformer architectures <ref type="bibr" coords="1,151.00,580.83,11.57,10.91" target="#b0">[1]</ref>, which has led to significant improvements in various NLP tasks, including claim verification <ref type="bibr" coords="2,170.60,86.97,11.53,10.91" target="#b1">[2]</ref>. The Transformer's attention mechanism allows it to focus on different parts of the input text, which is crucial in understanding the context and relationships within the text <ref type="bibr" coords="2,125.98,114.06,11.43,10.91" target="#b0">[1]</ref>.</p><p>Additionally, Transformer-based language models, such as BERT <ref type="bibr" coords="2,387.09,127.61,12.72,10.91" target="#b2">[3]</ref> and GPT <ref type="bibr" coords="2,443.77,127.61,11.31,10.91" target="#b3">[4]</ref>, have been fine-tuned for fact-checking tasks <ref type="bibr" coords="2,245.71,141.16,11.58,10.91" target="#b4">[5]</ref>. Fine-tuning involves training the model on a specific dataset related to the task at hand, allowing it to specialize and improve its performance in that particular task <ref type="bibr" coords="2,156.51,168.26,11.43,10.91" target="#b5">[6]</ref>.</p><p>Furthermore, GPT-3, one of the latest and largest language models by OpenAI, has demonstrated the potential for few-shot learning, where the model is presented with a few examples and can generalize to perform tasks even with minimal data <ref type="bibr" coords="2,358.96,208.91,11.43,10.91" target="#b6">[7]</ref>.</p><p>Now that we know how important it is to use NLP and language models to determine whether claims are true or false, let us discuss our approach to check-worthiness detection. Nowadays, information spreads quickly and sometimes can be harmful or disinformative. Our research is about making a system that can automatically check the reliability of claims. The following sections will discuss the challenge we took at CLEF 2023 Labs and how we made a system that can do this in English, Spanish, and Arabic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Problem Overview</head><p>Claims, particularly those that include misinformation and disinformation, can spread rapidly through various social media platforms and find their way into debates and public speeches. The harmful impact of such claims cannot be underestimated, as they have the potential to mislead and manipulate public opinion. Therefore, determining the check-worthiness of claims that represent different genres and characteristics is often crucial. Traditionally determining the check-worthiness of claims relies on the expertise of professional fact-checkers, debunkers, or human annotators. However, this manual assessment process can be resource-intensive and costly. In this regard, it is essential to develop automated systems for claim identification and verification, which can act as supportive technology for fact-checking organizations and journalism. By utilizing automated systems, we can improve the speed and accuracy of claim evaluation, reducing the reliance on manual assessments. Therefore, CheckThat! Lab (held in the framework of CLEF 2023<ref type="foot" coords="2,214.61,487.22,3.71,7.97" target="#foot_0">1</ref> ) organizers introduced a task aimed at developing a solution that could assist specialists in check-worthiness identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Task Description</head><p>CheckThat! Lab organizers introduced five different tasks at CLEF 2023. Our research focused on claims check-worthiness identification, and therefore we participated in Task 1: Check-Worthiness in Multimodal and Multigenre Content. This task aimed to ascertain the need for fact-checking a claim presented in a text snippet. In this task, we had two kinds of data, which were translated into two subtasks:</p><p>• Subtask 1A (Multimodal): check-worthiness assessment in a multimodal approach on tweets that included both a text snippet and an image.</p><p>• Subtask 1B (Multigenre): check-worthiness assessment in a multigenre approach on a text representing a tweet or a debate/speech transcription snippet.</p><p>Both subtasks were offered in multiple languages, namely subtask 1A in Arabic and English, whereas subtask 1B in Arabic, English, and Spanish. We focused entirely on detecting checkworthy text snippets in a multilingual and multigenre approach. Accordingly, we participated in subtask 1B. For a more comprehensive understanding of the task, we recommend referring to the paper that provides a detailed description of Task 1 <ref type="bibr" coords="3,348.27,176.08,11.43,10.91" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Our Contribution</head><p>Our goal was to develop a single predictive system to assess check-worthiness in three languages.</p><p>In this regard, we focused on employing a multilingual pre-trained XLM-RoBERTa-large model <ref type="bibr" coords="3,89.29,252.69,13.00,10.91" target="#b8">[9]</ref> as the core of the proposed system. The multilingual XLM-RoBERTa-large model was fine-tuned utilizing the available data and additional datasets obtained in data augmentation. We augmented the dataset by employing GPT-3.5<ref type="foot" coords="3,304.20,278.04,3.71,7.97" target="#foot_1">2</ref> to translate and paraphrase the existing data.</p><p>Our model improved upon baseline models for all languages. Notably, our system achieved the highest performance in the Spanish language, surpassing all other proposed approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Identifying and detecting disinformation and misinformation have emerged as highly significant research areas. Now, researchers focus on tackling specific challenges related to identifying disinformation, misinformation, and fake news. One of these challenges is, for instance, the recognition of check-worthiness in claims <ref type="bibr" coords="3,279.76,405.95,16.29,10.91" target="#b9">[10]</ref>. Hassan et al. <ref type="bibr" coords="3,362.68,405.95,17.91,10.91" target="#b10">[11]</ref> prepared a U.S. presidential debate dataset and developed classification models to distinguish between three different categories: check-worthy factual claims, non-factual claims, and unimportant factual claims. In their research, they experimented with three different classical machine learning models, namely Multinomial Naive Bayes Classifier, Support Vector Classifier, and Random Forest Classifier <ref type="bibr" coords="3,487.56,460.14,16.08,10.91" target="#b10">[11]</ref>. Jaradat et al. <ref type="bibr" coords="3,146.95,473.69,17.91,10.91" target="#b11">[12]</ref> created ClaimRank, an online system for detecting check-worthy claims that supported English and Arabic. ClaimRank, in its system architecture, reused the neural network model proposed by <ref type="bibr" coords="3,175.48,500.79,16.09,10.91" target="#b12">[13]</ref>. In addition to using classical machine learning to detect check-worthy claims, some studies proposed the latest pre-trained models. One such solution was the proposal by Kartal and Kutlu <ref type="bibr" coords="3,178.80,527.89,17.91,10.91" target="#b13">[14]</ref> to use the BERT model and various features to prioritize claims based on their check-worthiness. Features used by the authors included domain-specific controversial topics, word embeddings, part-of-speech tags, and others <ref type="bibr" coords="3,346.08,554.99,16.25,10.91" target="#b13">[14]</ref>. Check-worthiness detection is also the subject of research within Checkthat! Labs from previous years <ref type="bibr" coords="3,159.70,582.09,16.56,10.91" target="#b14">[15,</ref><ref type="bibr" coords="3,179.82,582.09,12.59,10.91" target="#b15">16,</ref><ref type="bibr" coords="3,195.97,582.09,12.59,10.91" target="#b16">17,</ref><ref type="bibr" coords="3,212.11,582.09,12.59,10.91" target="#b17">18,</ref><ref type="bibr" coords="3,228.26,582.09,12.42,10.91" target="#b18">19]</ref>. NUS-IDS team was one of the top performing teams in subtask related to detecting check-worthiness of tweets in 2022 <ref type="bibr" coords="3,389.89,595.64,16.41,10.91" target="#b18">[19]</ref>. The NUS-IDS team utilized the multilingual system that effectively took advantage of labeled data in all available languages in provided datasets <ref type="bibr" coords="3,233.40,622.73,16.42,10.91" target="#b19">[20]</ref>. AI Rational team in the same subtask employed a pretrained RoBERTa model with data augmentation <ref type="bibr" coords="3,301.09,636.28,16.09,10.91" target="#b20">[21]</ref>. One other team is also worth highlighting. PoliMi-FlatEarthers team fine-tuned a generative pre-trained GPT-3 model with all data in English <ref type="bibr" coords="4,126.23,86.97,16.42,10.91" target="#b21">[22]</ref>. They obtained the third-best performance when applying it to the English test dataset. The zero-shot application of the model to other languages was less successful <ref type="bibr" coords="4,474.03,100.52,16.25,10.91" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset</head><p>The dataset utilized in the Subtask 1B enclosed various genres and languages. The genres that these data represented were tweets and text snippets from transcriptions of debates and public speeches. Three languages were available: English, Spanish and Arabic. In addition, we enriched the data using an augmentation technique that involved the use of GPT-3.5.</p><p>The English dataset comprised snippets of transcriptions from debates and public speeches, while the Arabic and Spanish datasets included tweets accompanied by relevant metadata. Our approach focused solely on detecting check-worthiness using text data. As such, we did not use any tweets' metadata. The dataset for each language was divided into train, dev and dev_test dataset. All observations included ground truth labels. During the final phase of the Checkthat! Lab, we got additional unlabeled test dataset. It was the final dataset for which we had to generate predictions and submit them for evaluation. For a comprehensive description of the subtask dataset, please refer to the paper by Alam et al. <ref type="bibr" coords="4,337.71,308.16,11.43,10.91" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Preparation and Augmentation</head><p>As mentioned in Section 3, the datasets provided for Spanish and Arabic contained tweets and corresponding metadata fields, but in the preprocessing step, we decided to discard any additional metadata. We only utilized messages included in tweets and text snippets in English that represented transcripts of debates or public speeches. We employed textual data alongside a binary target label, where the positive class denoted a check-worthiness of the claim.</p><p>In the data preparation phase, data augmentation was performed using a variant of OpenAI's GPT-3.5 named gpt-3.5-turbo, which is considered highly efficient and cost-effective. Custom prompts were created for generating text translations and paraphrases, thereby enriching the dataset.</p><p>Prompts that we utilized in order to produce synthetic paraphrases are as follows:</p><p>• English: "Please generate a paraphrase without any additional text or explanation for the following text: &lt;text&gt;" • Spanish: "Please generate a paraphrase in Spanish without any additional text or explanation for the following text: &lt;text&gt;" • Arabic: "Please generate a paraphrase in Arabic without any additional text or explanation for the following text: &lt;text&gt;" We adopted a similar approach for creating synthetic translations:</p><p>• English: "Please translate the following text from English to Spanish without any additional text or explanation: &lt;text&gt;"</p><p>• Spanish:</p><p>-"Please translate the following text from Spanish to English without any additional text or explanation: &lt;text&gt;" -"Please translate the following text from Spanish to Arabic without any additional text or explanation: &lt;text&gt;"</p><p>• Arabic: "Please translate the following text from Arabic to Spanish without any additional text or explanation: &lt;text&gt;"</p><p>Due to resource constraints, we adopted specific rules for translation between languages to ensure quality:</p><p>1. The datasets being translated should share the same genre to maintain contextual consistency. 2. The languages involved in translation should belong to the same language family, aiding in generating natural translations due to structural similarities.</p><p>We identified English and Spanish as belonging to the Indo-European language family <ref type="bibr" coords="5,487.33,306.26,16.27,10.91" target="#b22">[23]</ref>. Table <ref type="table" coords="5,115.79,319.81,5.07,10.91" target="#tab_0">1</ref> outlines the translation process and justifications. The most significant challenges arose when generating translations from Spanish to Arabic and from Arabic to Spanish. In these instances, many observations lacked complete translation into the target language as specified. Nonetheless, we decided to include all the generated data in the training set.</p><p>After performing data augmentation, we proceeded to remove duplicates from both the original and augmented datasets. While exploring the data, we observed that certain observations were present in both the train and dev datasets. To ensure the effectiveness of fine-tuning the pre-trained models, it was imperative to eliminate these duplicate instances.</p><p>In the hyperparameter tuning phase, we augmented the training dataset exclusively. However, for building the final model, we utilized all the labeled data at our disposal, which included the training, dev, and dev_test datasets. We applied augmentation techniques to each of these datasets for the training of the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model</head><p>The primary goal of this stage was to develop a model capable of detecting check-worthy claims. For that, we adopted a unified approach creating a single model for check-worthiness detection across three given languages. In this regard, we utilized the multilingual RoBERTa-large <ref type="bibr" coords="6,492.99,86.97,13.00,10.91" target="#b8">[9]</ref> encoder, a pre-trained model provided by HuggingFace, known as XLM-RoBERTa-large <ref type="foot" coords="6,472.54,99.50,3.54,7.10" target="#foot_2">3</ref>The input text was initially tokenized, resulting in an array of tokens, with special tokens such as [CLS] denoting the start, [EOS] representing the end, and [SEP] separating sentences. This tokenized array was then processed through the XLM-RoBERTa-large model, generating an array of embeddings corresponding to the input tokens. Subsequently, the embedding array was passed through a fully connected layer, which was followed by a normalization step. During the training phase, the normalized output served as input along with the relevant labels for the binary cross-entropy loss function, enabling the loss calculation.</p><p>We predicted the final class label during inference by selecting the highest value from the normalized output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experimental Setup</head><p>We started our experiment by creating the training dataset, we combined all the provided train datasets from all available languages: English, Spanish, and Arabic. Moreover, we incorporated text snippets generated by GPT-3.5, as previously described in the Subsection 4.1. Next, we formed the validation dataset by combining the respective dev datasets for each language.</p><p>Once we established the training and validation datasets, we tokenized the text snippets and adjusted their length to 128 tokens by either truncating or padding them. Next, we focused on finding the best hyperparameters for training the model. This involved exploring different values for the batch size (ranging from 4 to 8), learning rate (ranging from 1e-7 to 1e-4), and weight decay (ranging from 1e-4 to 0.1). Additionally, we implemented a linear warmup for the initial 6% of the training steps. The hyperparameter search was conducted using the combined validation sets for all languages. Through this process, we identified the optimal hyperparameters as follows: a batch size of 8, a learning rate of 7.48e-06, and a weight decay of 2.65e-4. During the fine-tuning phase of the experiment, models with the highest F1 score for the positive class were considered the best.</p><p>With the optimal hyperparameters determined, our final approach involved training the model on the combined train, dev datasets, and all augmented data. In the end, we prepared the final predictions on the test dataset. The test dataset was utilized for the final evaluation and determination of our score, as showcased on the leaderboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>We present our official results and position on the final leaderboard in Table <ref type="table" coords="6,424.18,561.15,3.66,10.91" target="#tab_2">3</ref>. As shown in the table, our model achieved remarkable performance in the Spanish language.</p><p>Table <ref type="table" coords="6,127.66,588.25,5.17,10.91" target="#tab_1">2</ref> shows the comparison between our dev_test results and our results on the official leaderboard. It is evident that the dev_test results are not fully representative of the final leaderboard performance. For instance, while the model exhibited exceptionally high performance in English in the dev_test with a score of 0.946, it did not reflect similarly in the leaderboard with a score of 0.819. This could be due to the differences in data distribution between the dev_test set and the final test set used for the leaderboard. It underlines the importance of ensuring that the model is well-generalized and not overfitting to a specific dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Performance in Spanish</head><p>In the Spanish language, our model significantly exceeded the baseline and surpassed all the competing teams in terms of F1 score. The F1 score over the positive class was recorded at 0.641, which is almost four times higher than the baseline score of 0.172. This clearly demonstrates the effectiveness of our model in accurately assessing the check-worthiness of multigenre content in Spanish. This superior performance can be attributed to several factors including the robustness of the underlying model, quality of the training data and the fine-tuning strategies we employed. Moreover, it indicates that our model is well-suited for the Spanish language and is capable of capturing the nuances and contextual information necessary for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance in English</head><p>Moving on to the English language, our model also performed significantly better than the baseline with an F1 score of 0.819. However, it was outperformed by other teams and secured the 9th position. Despite this, the large margin between our score and the baseline score of 0.462 reflects that our model is capable of effectively identifying check-worthy statements in English. Further optimization and tuning could potentially improve the ranking among other competitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Performance in Arabic</head><p>In Arabic, our model's performance was slightly above the baseline, achieving an F1 score of 0.633 compared to the baseline score of 0.625. This relatively modest improvement over the baseline suggests that there might be certain challenges that our model faces when processing Arabic content. We hypothesize that GPT-3.5, which is the backbone of our model, performs worse in generating synthetic Arabic texts compared to English and Spanish. The Arabic language has complex morphological structures and right-to-left script, which might pose challenges for the model. Further investigation is needed to identify the specific areas where the model can be optimized for better performance in Arabic. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Limitations</head><p>While our study presents promising results, there are several limitations that need to be acknowledged. One of the critical limitations of this study was the lack of investigation into the effects of data augmentation on the model. Due to budget and time constraints, we did not conduct experiments to compare the model's performance with and without data augmentation techniques. Data augmentation, being one of the key aspects of the model, warrants further investigation to understand its actual contribution to the performance of the model in check-worthiness detection. Another limitation was not exploring the multilinguality aspect in-depth. Our study used a single model with a dataset that combined training data from different languages. However, we did not compare its performance with dedicated models that were trained on specific languages. Such an analysis would have been insightful in understanding the pros and cons of using a single multilingual model versus multiple monolingual models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Future Work</head><p>Given the aforementioned limitations, future work should involve:</p><p>• Investigating Data Augmentation: A systematic investigation into the effects of data augmentation on model performance. Comparing the model with and without data augmentation will be instrumental in understanding its role in improving checkworthiness detection. • Exploring Multilinguality: Conducting experiments to compare the performance of a single model trained on combined datasets from different languages with models trained on language-specific datasets. This will help in identifying the best approach for multilingual check-worthiness detection. • Handling Biases: Ensuring that the systems are unbiased and fair. Further research could explore techniques for identifying and mitigating biases within the models. • Explainability and Interpretability: Building transparent models that can provide justifications for their predictions.</p><p>These future research directions will not only address the limitations of the current study but will also pave the way for more sophisticated and efficient check-worthiness detection systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>In this study, as part of CheckThat! 2023 Lab's Subtask 1B, we implemented a multilingual XLM-RoBERTa-large model with GPT-3.5-based data augmentation to assess the check-worthiness of statements in multilingual and multigenre content. Our model exhibited remarkable performance, particularly in Spanish, where it surpassed all competitors with an F1 score of 0.641. Although the performance was commendable in English, it ranked 9th. In Arabic, the improvement was modest, hinting at challenges faced by the model in processing complex Arabic structures.</p><p>In summary, the study signifies a substantial step in automated fact-checking systems, particularly for the Spanish language, by employing pre-trained multilingual models with data augmentation. Future research should focus on overcoming limitations and refining performance across languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,348.82,377.86,85.18"><head>Table 1</head><label>1</label><figDesc>Translation between languages and its reasoning</figDesc><table coords="5,128.42,376.86,338.44,57.14"><row><cell cols="2">Original Language Destination Language</cell><cell>Justification</cell></row><row><cell>Arabic</cell><cell>Spanish</cell><cell>Same genre</cell></row><row><cell>Spanish</cell><cell>Arabic</cell><cell>Same genre</cell></row><row><cell>English</cell><cell>Spanish</cell><cell>Indo-European language family</cell></row><row><cell>Spanish</cell><cell>English</cell><cell>Indo-European language family</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,129.52,290.11,81.83"><head>Table 2</head><label>2</label><figDesc>Our dev_test results compared with our results on official Leaderboard</figDesc><table coords="7,221.56,161.14,152.15,50.21"><row><cell cols="3">Language Dev_Test Leaderboard</cell></row><row><cell>Arabic</cell><cell>0.483</cell><cell>0.633</cell></row><row><cell>English</cell><cell>0.946</cell><cell>0.819</cell></row><row><cell>Spanish</cell><cell>0.688</cell><cell>0.641</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.99,90.49,407.35,123.17"><head>Table 3</head><label>3</label><figDesc>Official results and ranks in Subtask 1B: Check-Worthiness in Multigenre Content</figDesc><table coords="8,98.92,122.05,397.42,91.60"><row><cell></cell><cell>Arabic</cell><cell></cell><cell></cell><cell>English</cell><cell></cell><cell></cell><cell>Spanish</cell><cell></cell></row><row><cell>Rank</cell><cell>Team</cell><cell>F1</cell><cell>Rank</cell><cell>Team</cell><cell>F1</cell><cell>Rank</cell><cell>Team</cell><cell>F1</cell></row><row><cell>1</cell><cell>ES-VRAI</cell><cell>0.809</cell><cell>1</cell><cell>OpenFact</cell><cell>0.898</cell><cell>1</cell><cell>DSHacker</cell><cell>0.641</cell></row><row><cell>2</cell><cell>Accenture</cell><cell>0.733</cell><cell>2</cell><cell cols="2">Fraunhofer SIT 0.878</cell><cell>2</cell><cell>ES-VRAI</cell><cell>0.627</cell></row><row><cell>3</cell><cell>Z-Index</cell><cell>0.71</cell><cell>3</cell><cell>Accenture</cell><cell>0.86</cell><cell>3</cell><cell cols="2">CSECU-DSG 0.599</cell></row><row><cell>5</cell><cell cols="2">DSHacker 0.633</cell><cell>9</cell><cell>DSHacker</cell><cell>0.819</cell><cell>4</cell><cell cols="2">NLPIR-UNED 0.589</cell></row><row><cell>-</cell><cell>Baseline</cell><cell>0.625</cell><cell>-</cell><cell>Baseline</cell><cell>0.462</cell><cell>-</cell><cell>Baseline</cell><cell>0.172</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,671.02,121.00,8.97"><p>https://clef2023.clef-initiative.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,92.57,671.04,345.19,8.97"><p>OpenAI. Available on OpenAI Platform: https://platform.openai.com/ (accessed April 25, 2023)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,92.57,671.02,150.49,8.97"><p>https://huggingface.co/xlm-roberta-large</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,353.26,395.17,10.91;9,112.66,366.81,393.33,10.91;9,112.33,380.36,29.19,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,484.04,353.26,23.79,10.91;9,112.66,366.81,143.41,10.91">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,264.71,366.81,228.49,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Polosukhin</note>
</biblStruct>

<biblStruct coords="9,112.66,393.91,393.53,10.91;9,112.66,407.46,317.13,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<title level="m" coord="9,368.24,393.91,137.95,10.91;9,112.66,407.46,135.31,10.91">Fever: a large-scale dataset for fact extraction and verification</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,421.01,393.33,10.91;9,112.66,434.55,363.59,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="9,353.43,421.01,152.55,10.91;9,112.66,434.55,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,448.10,395.17,10.91;9,112.66,461.65,190.20,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m" coord="9,383.02,448.10,124.82,10.91;9,112.66,461.65,158.28,10.91">Improving language understanding by generative pre-training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,475.20,393.33,10.91;9,112.66,488.75,393.33,10.91;9,112.66,502.30,201.16,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,187.63,475.20,318.35,10.91;9,112.66,488.75,116.86,10.91">Automatic fact-checking with document-level annotations using bert and multiple instance learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sathe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,252.89,488.75,253.10,10.91;9,112.66,502.30,112.88,10.91">Proceedings of the Fourth Workshop on Fact Extraction and VERification (FEVER)</title>
		<meeting>the Fourth Workshop on Fact Extraction and VERification (FEVER)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="101" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,515.85,393.33,10.91;9,112.66,529.40,393.33,10.91;9,112.66,542.95,107.17,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06305</idno>
		<title level="m" coord="9,407.34,515.85,98.64,10.91;9,112.66,529.40,320.22,10.91">Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,556.50,394.53,10.91;9,112.66,570.05,393.32,10.91;9,112.66,583.60,266.90,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,274.48,570.05,169.72,10.91">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,452.29,570.05,53.69,10.91;9,112.66,583.60,172.82,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,597.15,394.53,10.91;9,112.66,610.69,393.64,10.91;9,112.66,624.24,393.33,10.91;9,112.66,637.79,394.52,10.91;9,112.66,651.34,58.60,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,332.76,610.69,173.54,10.91;9,112.66,624.24,304.01,10.91">Overview of the CLEF-2023 CheckThat! lab task 1 on check-worthiness in multimodal and multigenre content</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hakimov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,439.56,624.24,66.43,10.91;9,112.66,637.79,327.90,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,394.53,10.91;10,112.66,100.52,393.33,10.91;10,112.66,114.06,393.32,10.91;10,112.66,127.61,144.26,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,271.58,100.52,234.41,10.91;10,112.66,114.06,20.10,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,155.39,114.06,350.59,10.91;10,112.66,127.61,46.58,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,141.16,394.53,10.91;10,112.66,154.71,394.53,10.91;10,112.28,168.26,394.11,10.91;10,112.66,181.81,393.33,10.91;10,112.66,195.36,395.17,10.91;10,112.66,208.91,393.58,10.91;10,112.66,222.46,395.17,10.91;10,112.66,236.01,394.51,10.91;10,112.66,252.00,123.08,7.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,462.00,168.26,44.39,10.91;10,112.66,181.81,393.33,10.91;10,112.66,195.36,130.46,10.91">Overview ofnbsp;thenbsp;clef-2022 checkthat! lab onnbsp;fighting thenbsp;covid-19 infodemic andnbsp;fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-13643-6_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-13643-6_29.doi:10.1007/978-3-031-13643-6_29" />
	</analytic>
	<monogr>
		<title level="m" coord="10,269.65,195.36,238.18,10.91;10,112.66,208.91,393.58,10.91;10,112.66,222.46,18.52,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="495" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,393.33,10.91;10,112.66,276.66,393.32,10.91;10,112.66,290.20,205.01,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,260.82,263.11,245.17,10.91;10,112.66,276.66,31.08,10.91">Detecting check-worthy factual claims in presidential debates</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,166.69,276.66,339.29,10.91;10,112.66,290.20,106.10,10.91">Proceedings of the 24th acm international on conference on information and knowledge management</title>
		<meeting>the 24th acm international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,303.75,393.32,10.91;10,112.66,317.30,393.33,10.91;10,112.66,330.85,395.17,10.91;10,112.66,344.40,97.63,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,408.35,303.75,97.64,10.91;10,112.66,317.30,184.64,10.91">Claimrank: Detecting check-worthy claims in arabic and english</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,319.98,317.30,186.00,10.91;10,112.66,330.85,395.17,10.91;10,112.66,344.40,20.39,10.91">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,357.95,393.33,10.91;10,112.66,371.50,393.32,10.91;10,112.66,385.05,394.52,10.91;10,112.66,398.60,80.57,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,429.49,357.95,76.50,10.91;10,112.66,371.50,288.18,10.91">A context-aware approach for detecting worth-checking claims in political debates</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,423.80,371.50,82.18,10.91;10,112.66,385.05,390.04,10.91">Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing, RANLP 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,412.15,393.33,10.91;10,112.66,425.70,364.52,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,211.78,412.15,294.21,10.91;10,112.66,425.70,91.08,10.91">Re-think before you share: A comprehensive study on prioritizing check-worthy claims</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,212.06,425.70,233.19,10.91">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,439.25,394.53,10.91;10,112.66,452.79,393.33,10.91;10,112.66,466.34,393.32,10.91;10,112.66,479.89,393.59,10.91;10,112.28,493.44,394.90,10.91;10,112.66,506.99,80.57,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,327.66,452.79,178.32,10.91;10,112.66,466.34,270.00,10.91">Overview of the clef-2018 checkthat! lab on automatic identification and verification of political claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martino</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,405.41,466.34,100.57,10.91;10,112.66,479.89,393.59,10.91;10,112.28,493.44,101.10,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 9th International Conference of the CLEF Association, CLEF 2018</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">September 10-14, 2018. 2018</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,520.54,394.53,10.91;10,112.66,534.09,393.33,10.91;10,112.39,547.64,393.59,10.91;10,112.66,561.19,394.52,10.91;10,112.66,574.74,354.94,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,181.19,534.09,324.79,10.91;10,112.39,547.64,94.95,10.91">Overview of the clef-2019 checkthat! lab: automatic identification and verification of claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,235.68,547.64,270.30,10.91;10,112.66,561.19,351.29,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 10th International Conference of the CLEF Association, CLEF 2019</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">September 9-12, 2019. 2019</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="301" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,588.29,394.53,10.91;10,112.66,601.84,393.33,10.91;10,112.66,615.39,393.33,10.91;10,112.66,628.93,394.53,10.91;10,112.66,642.48,123.33,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,164.67,601.84,341.32,10.91;10,112.66,615.39,101.64,10.91">Checkthat! at clef 2020: Enabling the automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,235.67,615.39,270.32,10.91;10,112.66,628.93,117.89,10.91">Advances in Information Retrieval: 42nd European Conference on IR Research, ECIR 2020</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">April 14-17, 2020. 2020</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="499" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,656.03,394.53,10.91;10,112.66,669.58,393.33,10.91;11,112.66,86.97,394.62,10.91;11,112.66,100.52,393.33,10.91;11,112.66,114.06,394.53,10.91;11,112.66,127.61,195.45,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,318.27,669.58,187.72,10.91;11,112.66,86.97,371.63,10.91">Overview of the clef-2021 checkthat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,112.66,100.52,393.33,10.91;11,112.66,114.06,215.25,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 21-24, 2021. 2021</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="264" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,141.16,394.52,10.91;11,112.33,154.71,393.65,10.91;11,112.66,168.26,393.33,10.91;11,112.66,181.81,393.59,10.91;11,112.28,195.36,394.90,10.91;11,112.66,208.91,55.16,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,303.81,154.71,202.17,10.91;11,112.66,168.26,259.42,10.91">Overview of the clef-2022 checkthat! lab on fighting the covid-19 infodemic and fake news detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,400.69,168.26,105.30,10.91;11,112.66,181.81,393.59,10.91;11,112.28,195.36,101.56,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="495" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,222.46,393.33,10.91;11,112.66,236.01,150.96,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,256.70,222.46,92.78,10.91">Nus-ids at checkthat!</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Gollapalli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,378.22,222.46,127.77,10.91;11,112.66,236.01,119.04,10.91">identifying check-worthiness of tweets using checkthat</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,249.56,395.17,10.91;11,112.66,263.11,161.97,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,167.25,249.56,340.58,10.91;11,112.66,263.11,16.17,10.91">Ai rational at checkthat! 2022: using transformer models for tweet classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Savchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,136.80,263.11,105.91,10.91">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,276.66,393.33,10.91;11,112.66,290.20,147.05,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,305.80,276.66,145.14,10.91">Polimi-flatearthers at checkthat!</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agresti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hashemian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Carman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,480.39,276.66,25.60,10.91;11,112.66,290.20,115.13,10.91">Gpt-3 applied to claim detection</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,303.75,393.33,10.91;11,112.28,317.30,132.67,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,254.91,303.75,201.56,10.91">The early history of indo-european languages</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">V</forename><surname>Gamkrelidze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">V</forename><surname>Ivanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,465.10,303.75,40.89,10.91;11,112.28,317.30,43.66,10.91">Scientific American</title>
		<imprint>
			<biblScope unit="volume">262</biblScope>
			<biblScope unit="page" from="110" to="117" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
