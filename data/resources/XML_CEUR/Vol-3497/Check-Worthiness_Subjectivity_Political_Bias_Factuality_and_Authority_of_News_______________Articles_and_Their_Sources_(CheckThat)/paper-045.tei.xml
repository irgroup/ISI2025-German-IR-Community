<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,324.48,15.42;1,89.29,106.66,333.74,15.42">Accenture at CheckThat! 2023: Impacts of Back-translation on Subjectivity Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,47.01,11.96"><forename type="first">Sieu</forename><surname>Tran</surname></persName>
							<email>sieu.tran@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,148.94,134.97,73.62,11.96"><forename type="first">Paul</forename><surname>Rodrigues</surname></persName>
							<email>paul.rodrigues@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,235.21,134.97,84.88,11.96"><forename type="first">Benjamin</forename><surname>Strauss</surname></persName>
							<email>b.strauss@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.09,134.97,86.91,11.96"><forename type="first">Evan</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
							<email>emwillia@andrew.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,324.48,15.42;1,89.29,106.66,333.74,15.42">Accenture at CheckThat! 2023: Impacts of Back-translation on Subjectivity Detection</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">41A5EA37691713EDC03736B0FEF67CED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>subjectivity detection</term>
					<term>opinion detection</term>
					<term>news analysis</term>
					<term>data-driven journalism</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper discusses the CLEF CheckThat! Lab Task 2 on Subjectivity in News Articles, and our approach on using back-translation to augment the minority classes in Arabic, English, Turkish, German, Italian, and Dutch to distinguish subjective and objective statements. While we find that back-translation works well for other tasks in the fact-checking pipeline, we find that it does not work as well for subjectivity detection. This paper begins to examine several reasons why back-translation as an NLP data augmentation strategy could inhibit subjectivity detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Subjectivity detection, a subtask of sentiment analysis, aims to differentiate neutral content or facts from opinion within text <ref type="bibr" coords="1,221.46,384.16,11.27,10.91" target="#b0">[1]</ref>. As sentiment analysis is often concerned with the opinions of users, the removal of neutral or objective text is a common pre-processing step, particularly in polarity-detection settings <ref type="bibr" coords="1,206.45,411.26,11.27,10.91" target="#b1">[2]</ref>. However, recent work has explored the usefulness of subjectivity detection systems outside sentiment-oriented tasks, such as in augmenting fake news detection systems <ref type="bibr" coords="1,128.24,438.36,11.48,10.91" target="#b2">[3,</ref><ref type="bibr" coords="1,142.63,438.36,7.52,10.91" target="#b3">4,</ref><ref type="bibr" coords="1,153.07,438.36,7.65,10.91" target="#b4">5]</ref>. <ref type="bibr" coords="1,168.30,438.36,12.99,10.91" target="#b3">[4]</ref> use subjectivity lexicons to help differentiate and classify real and fake news in English and Brazilian Portuguese, but found that simpler BOW methods outperformed their lexicons. <ref type="bibr" coords="1,153.94,465.46,12.68,10.91" target="#b2">[3]</ref> perform statistical analyses to demonstrate a relationship between subjective language and fake news. <ref type="bibr" coords="1,198.21,479.01,12.68,10.91" target="#b4">[5]</ref> demonstrated that fine-tuned transformer-base models can perform very well on sentence-level subjectivity detection tasks.</p><p>Building on these new developments, Task 2 of the CheckThat! Lab at CLEF 2023 provides participants with annotated news sentence subjectivity detection datasets in Arabic, English, Turkish, German, Italian, and Dutch <ref type="bibr" coords="1,263.27,533.21,11.58,10.91" target="#b5">[6]</ref>. In news articles, particularly in biased settings, subjectivity detection and annotation is a challenging task, as sentences can contain both objective claims and subjective framing. For example, in the English validation dataset for Task 2, the sentence, "Wing is also the co-author of several Leftist indoctrination books for children, including one entitled What Is White Privilege?" is labeled as 'Objective', rather than 'Subjective'. As the sentence contains specific, falsifiable claims, this seems to be a reasonable labeling. However, the characterization of the books as tools of 'Leftist indoctrination', is clearly a subjective editorialization on the part of the author. This highlights the inherent ambiguity present in the task and underscores a core challenge that the annotators, and the models both face in learning a clear decision boundary.</p><p>In this work, we describe the back-translation augmentation strategies and models employed by Team Accenture's submissions to Task 2. Team Accenture's back-translation and transformer approach yielded the 3rd highest submissions in Arabic, 4th in Turkish, 5th in Dutch, and 8th in German and English. While back-translation has been shown to be an effective means of NLP data augmentation to improve checkworthiness identification <ref type="bibr" coords="2,392.11,222.46,11.53,10.91" target="#b6">[7]</ref>, we speculate that the approach may reduce the the ability of models to generalize in a subjectivity detection task and explore some reasons why this may be the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Exploratory Analysis</head><p>Table <ref type="table" coords="2,115.20,308.18,4.97,10.91" target="#tab_0">1</ref> shows the number of samples and unique word counts for each of the datasets provided. We see that Italian had the largest number of samples in training <ref type="bibr" coords="2,378.39,321.73,11.75,10.91" target="#b0">(1,</ref><ref type="bibr" coords="2,390.14,321.73,15.67,10.91">613)</ref>. However, Arabic had the highest count of unique words <ref type="bibr" coords="2,248.43,335.28,16.62,10.91" target="#b11">(12,</ref><ref type="bibr" coords="2,265.05,335.28,16.62,10.91">181)</ref>, while German (4,622) and Dutch (3,944) had the lowest. Assuming consistent data collection methodology and annotation standards across languages, we would hypothesize that a larger quantity of unique words would yield higheraccuracy models. The sample size of all languages in this task is relatively small compared to the other tasks in the CheckThat Lab.</p><p>As shown in Figure <ref type="figure" coords="2,191.41,403.03,3.81,10.91" target="#fig_0">1</ref>, all of the datasets provided by the CheckThat! organizers had label bias which skewed each dataset towards sentences labeled as 'objective'.  Transformer models utilize WordPiece tokenization schemes that are dependant on the model being evaluated. At the time of pre-training, the WordPiece algorithm determines which pieces of words will be retained, and which will be discarded. An Unknown (UNK) token is utilized as a placeholder in the lexicon, and used to represent WordPiece tokens received in novel input that did not get utilized at model creation.</p><p>The proportion of out-of-vocabulary tokens are have been shown to inversely correlates to overall accuracy <ref type="bibr" coords="3,162.76,461.64,11.28,10.91" target="#b7">[8]</ref>, so we explore proportions of UNK in each dataset to ensure our models are not excluding too many tokens from any language. We present our analysis in Table <ref type="table" coords="3,472.53,475.19,3.79,10.91" target="#tab_1">2</ref>. Most notably, Arabic training set has the highest WordPiece count of 43,601. Since the unknown token rates are mostly negligible between all languages, we expect count and diversity of Wordpiece would influence model performance the most. Unexpectedly, the RoBERTa tokenizers we used did not return UNK tokens on any dataset provided by the CLEF CheckThat! organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Transformer Architectures and Pre-Trained Models</head><p>In this work, we utilize BERT and RoBERTa models. The Bidirectional Encoder Representation Transformer (BERT) is a transformer-based architecture that was introduced in 2018 <ref type="bibr" coords="3,462.91,601.56,11.34,10.91" target="#b8">[9]</ref>. BERT has had a substantial impact on the field of NLP, and achieved state of the art results on 11 NLP benchmarks at the time of its release. RoBERTa, introduced by <ref type="bibr" coords="3,370.83,628.66,4.07,10.91">[</ref>  data <ref type="bibr" coords="4,110.96,380.34,16.25,10.91" target="#b9">[10]</ref>.</p><p>For the Arabic Dataset, we used lanwuwei/GigaBERT-v4-Arabic-and-English <ref type="bibr" coords="4,453.07,393.89,16.41,10.91" target="#b10">[11]</ref>, which was trained on a large-scale corpus (Arabic version of OSCAR, an Arabic Wikipedia dump, and Gigaword) with ‚àº10B tokens. The model showing state-of-the-art zero-shot transfer performance from English to Arabic on information extraction tasks. The Arabic model contains a vocabulary of length ‚àº21,000 and ‚àº26,000 for English and Arabic respectively. For English, we used roberta-large <ref type="bibr" coords="4,236.69,461.64,16.09,10.91" target="#b9">[10]</ref>. The English RoBERTa model contains 50,265 WordPieces. For Turkish, German, and Italian, we used dbmdz/bert-base-turkish-cased <ref type="bibr" coords="4,410.19,475.19,16.11,10.91" target="#b11">[12]</ref>, dbmdz/bert-basegerman-uncased <ref type="bibr" coords="4,161.47,488.73,16.09,10.91" target="#b12">[13]</ref>, and dbmdz/bert-base-italian-xxl-uncased <ref type="bibr" coords="4,359.83,488.73,16.09,10.91" target="#b13">[14]</ref>, respectively. The vocabulary sizes of the Turkish, German, and Italian models are respectively 32,000, 31,102, and 32,102. For Dutch, we used GroNLP/bert-base-dutch-cased <ref type="bibr" coords="4,314.47,515.83,16.30,10.91" target="#b14">[15]</ref>, which has a vocabulary size of 30,073. The foundation model for each language was selected based on models we have used in the past. Recognizing that this was a problem that should not benefit from case signaling, we chose the uncased variant for any new model.</p><p>For experimentation and comparison to roberta-large, we also fine-tune the pre-trained model on subjectivity/style classification task, cffl/bert-base-styleclassification-subjective-neutral <ref type="bibr" coords="4,487.30,583.58,16.29,10.91" target="#b15">[16]</ref>. This BERT-based model has been fine-tuned on the Wiki Neutrality Corpus (WNC) -a parallel corpus of 180,000 biased and neutralized sentence pairs along with contextual sentences and metadata. The model can be used to classify text as subjectively biased vs. neutrally toned. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Augmentation</head><p>For each language, augmentation and training were done via back-translation into the respective language using AWS translation. We back-translated the minority class in each dataset, which is always the subjective documents. We appended back-translated subjective documents to the training set. In our 2021 experiment <ref type="bibr" coords="5,253.72,378.66,11.51,10.91" target="#b6">[7]</ref>, we found that this form of augmentation resulted in a significant increase in recall and F1-score for the positive class. We did not use any dataset outside the one provided by the organizers for data augmentation.</p><p>In this work, we fine-tune lanwuwei/GigaBERT-v4-Arabic-and-English at different levels of data augmentation and compare performances on the gold test set provided by the organizer.</p><p>Table <ref type="table" coords="5,126.05,446.41,4.97,10.91" target="#tab_2">3</ref> shows the BLEU score for each back-translation scheme. Table <ref type="table" coords="5,405.46,446.41,4.97,10.91" target="#tab_3">4</ref> show training sample size before and after data augmentation and Table <ref type="table" coords="5,311.68,459.96,5.00,10.91">5</ref> shows the number of new tokens acquired after back-translation for each language. The higher the score, the more consistent or similar the translation to the original text. For Arabic and Italian, BLEU scores decrease as more pivot languages are used for back-translation, as we would expect. As a perfect translation would not provide variation in the training samples, and a low BLEU score may not provide consistent variation, this may suggest there is a sweet spot to BLEU score in a NLP data augmentation task to provide diverse word selection but consistent translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classification</head><p>For all BERT and RoBERTa models utilized across all languages, we added an additional meanpooling layer and dropout layer on top of the model prior to the final classification layer. Adding these additional layers has been shown to help prevent over-fitting while fine-tuning. We used an Adam optimizer with a learning rate of 2ùëí -5 and an epsilon of 1.5ùëí -8. We use a binary cross-entropy loss function, 4 epochs, and a batch size of 32. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Table <ref type="table" coords="6,114.99,540.04,4.97,10.91" target="#tab_4">6</ref> and 7 contains all model performance on the test set provided by the organizers. We find that our Arabic model has an accuracy of 0.800 with a weighted average F1-score of 0.816. Our English model had an accuracy of 0.696 with a weighted average F1-score of 0.687. For Turkish, we had an accuracy of 0.788 and a weighted average F1-score of 0.784. German received an accuracy of 0.337 and an F1-score of 0.174. Italian had an accuracy of 0.689 and F1 of 0.706. Finally, our Dutch model had an accuracy of 0.646 and a weighted F1-score of 0.618. Table <ref type="table" coords="6,127.10,621.33,5.09,10.91" target="#tab_5">8</ref> and 9 shows Arabic model's performance on the gold test set with different level of data augmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We observe that a specialized style-classification model outperformed the RoBERTa-large model quite significantly as seen in Table <ref type="table" coords="8,280.19,546.60,10.35,10.91" target="#tab_7">10</ref> and 11. This is likely because for a subjectivity classification task there is a heavy emphasis on vocabulary and terminology, which is a lacking in the relatively small training set provided. The raw RoBERTa did not have enough training vocabulary to outperform a specialized model. We also observe a diminishing return when over augment with the Arabic training set. As mentioned before, vocabulary plays a key role and augmenting with several pivot languages may have affected the data quality, potentially removing keywords that determine subjectivity. Look at the example below of a document labeled subjective after only one translation from Arabic to English:</p><p>"Are there any resolutions that the Security Council may issue to ensure that Egypt's water share in the Nile River will not be affected?"</p><p>The second round of back-translation (Arabic &gt; English &gt; Spanish &gt; English) then produces:</p><p>"Is there a resolution that the Security Council can issue to ensure that Egypt's water quota in the Nile River is not affected?" And the third (Arabic &gt; English &gt; French &gt; English) produces: "Are there resolutions that the Security Council could adopt to ensure that Egypt's share of water in the Nile is not affected?" By the second or third translation, the tone of the statement has shifted towards much more objective. This results in much lower model performance. We can see the results of these experiments in Table <ref type="table" coords="9,185.32,554.96,3.74,10.91" target="#tab_5">8</ref>.</p><p>Due to extremely low sample size on the subjective class, we augmented Arabic and Italian training data three times. Table <ref type="table" coords="9,237.15,582.06,10.35,10.91" target="#tab_8">12</ref> shows the average cosine similarity score between each translation results to the original and the weighted average sentiment score of the pivoting English back-translation based on the Vader Lexicon <ref type="bibr" coords="9,332.17,609.16,16.41,10.91" target="#b16">[17]</ref>. For Arabic, there was no notable difference between the scores. However, for Italian, cosine similarity shows small decreases as more layers of back-translation are added, indicating a small level of semantic drift. Additionally, mean sentiment score decreases indicating subjectivity-level of the lexicon decreases as well.</p><p>Our paper suggests there may be a 'sweet spot' in BLEU score for data agumentation for </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,647.03,196.17,8.93;2,144.30,439.15,306.68,195.32"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Label distribution across training sets</figDesc><graphic coords="2,144.30,439.15,306.68,195.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,374.90,628.66,131.09,10.91;3,89.29,642.21,416.69,10.91;3,89.29,655.75,416.70,10.91;3,89.29,669.30,416.69,10.91"><head></head><label></label><figDesc>10], modified various parts of BERTs training process. These modifications include more training data, more pre-training steps with bigger batches over more data, removing BERT's Next Sentence Prediction, training on longer sequences, and dynamically changing the masking pattern applied to the training</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,338.16,263.15"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="3,89.29,102.49,337.86,251.14"><row><cell>Dataset Descriptions</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Language Modeling set # of samples Unique word count</cell></row><row><cell>Arabic</cell><cell>Train</cell><cell>1,185</cell><cell>12,181</cell></row><row><cell></cell><cell>Test</cell><cell>445</cell><cell>6,225</cell></row><row><cell></cell><cell>Validation</cell><cell>297</cell><cell>4,631</cell></row><row><cell>Dutch</cell><cell>Train</cell><cell>800</cell><cell>3,944</cell></row><row><cell></cell><cell>Test</cell><cell>500</cell><cell>2,615</cell></row><row><cell></cell><cell>Validation</cell><cell>200</cell><cell>1,462</cell></row><row><cell>English</cell><cell>Train</cell><cell>830</cell><cell>4,126</cell></row><row><cell></cell><cell>Test</cell><cell>243</cell><cell>2,043</cell></row><row><cell></cell><cell>Validation</cell><cell>219</cell><cell>1,846</cell></row><row><cell>German</cell><cell>Train</cell><cell>800</cell><cell>4,622</cell></row><row><cell></cell><cell>Test</cell><cell>291</cell><cell>2,384</cell></row><row><cell></cell><cell>Validation</cell><cell>200</cell><cell>1,633</cell></row><row><cell>Italian</cell><cell>Train</cell><cell>1,613</cell><cell>7,372</cell></row><row><cell></cell><cell>Test</cell><cell>440</cell><cell>3,563</cell></row><row><cell></cell><cell>Validation</cell><cell>227</cell><cell>1,649</cell></row><row><cell>Turkish</cell><cell>Train</cell><cell>800</cell><cell>4,914</cell></row><row><cell></cell><cell>Test</cell><cell>240</cell><cell>1,886</cell></row><row><cell></cell><cell>Validation</cell><cell>200</cell><cell>1,624</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,367.88,263.15"><head>Table 2</head><label>2</label><figDesc>Unknown Token Distribution in Data for Each Language.</figDesc><table coords="4,138.40,122.10,318.47,231.53"><row><cell cols="5">Language Tokenizer Type Modeling Set WordPiece Unknown Token</cell></row><row><cell>Arabic</cell><cell>BERT-based</cell><cell>Training</cell><cell>43,601</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>16,050</cell><cell>8</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>11,286</cell><cell>3</cell></row><row><cell>Dutch</cell><cell>BERT-based</cell><cell>Training</cell><cell>19,033</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>10,997</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>4,902</cell><cell>0</cell></row><row><cell>English</cell><cell>RoBERTa-based</cell><cell>Training</cell><cell>24,147</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>7,674</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>6,935</cell><cell>0</cell></row><row><cell>German</cell><cell>BERT-based</cell><cell>Training</cell><cell>21,318</cell><cell>7</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>8,293</cell><cell>7</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>5,267</cell><cell>4</cell></row><row><cell>Italian</cell><cell>BERT-based</cell><cell>Training</cell><cell>41,767</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>14,978</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>5,277</cell><cell>0</cell></row><row><cell>Turkish</cell><cell>BERT-based</cell><cell>Training</cell><cell>16,593</cell><cell>5</cell></row><row><cell></cell><cell></cell><cell>Testing</cell><cell>4,795</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>4,008</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.98,90.49,326.45,175.54"><head>Table 3</head><label>3</label><figDesc>Average Sentence BLEU Score for Each Back-translation Scheme</figDesc><table coords="5,179.85,120.27,235.59,145.76"><row><cell></cell><cell></cell><cell>Average Sentence</cell></row><row><cell>Language</cell><cell>Back-translation</cell><cell>BLEU Score</cell></row><row><cell>Arabic</cell><cell>AR &gt; EN &gt; AR</cell><cell>0.224</cell></row><row><cell></cell><cell>AR &gt; EN &gt; ES &gt; EN &gt; AR</cell><cell>0.156</cell></row><row><cell></cell><cell>AR &gt; EN &gt; FR &gt; EN &gt; AR</cell><cell>0.135</cell></row><row><cell>Dutch</cell><cell>NL &gt; EN &gt; NL</cell><cell>0.434</cell></row><row><cell>English</cell><cell>EN &gt; ES &gt; EN</cell><cell>0.428</cell></row><row><cell>German</cell><cell>DE &gt; EN &gt; DE</cell><cell>0.357</cell></row><row><cell>Italian</cell><cell>IT &gt; EN &gt; IT</cell><cell>0.456</cell></row><row><cell></cell><cell>IT &gt; EN &gt; ES &gt; EN &gt; IT</cell><cell>0.353</cell></row><row><cell></cell><cell>IT &gt; EN &gt; FR &gt; EN &gt; IT</cell><cell>0.313</cell></row><row><cell>Turkish</cell><cell>TR &gt; EN &gt; TR</cell><cell>0.105</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,90.49,386.97,398.53"><head>Table 4</head><label>4</label><figDesc>Training Sample Size Before and After Data Augmentation</figDesc><table coords="6,88.99,120.77,386.97,368.24"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Orginial Dataset</cell><cell>Augmented Dataset</cell></row><row><cell></cell><cell cols="2">Language Label</cell><cell cols="2">Sample Count</cell><cell>Sample Count</cell></row><row><cell></cell><cell>Arabic</cell><cell cols="2">SUBJ 280</cell><cell></cell><cell>840</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 905</cell><cell></cell><cell>905</cell></row><row><cell></cell><cell>Dutch</cell><cell cols="2">SUBJ 311</cell><cell></cell><cell>622</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 489</cell><cell></cell><cell>489</cell></row><row><cell></cell><cell>English</cell><cell cols="2">SUBJ 298</cell><cell></cell><cell>596</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 532</cell><cell></cell><cell>532</cell></row><row><cell></cell><cell>German</cell><cell cols="2">SUBJ 308</cell><cell></cell><cell>616</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 492</cell><cell></cell><cell>492</cell></row><row><cell></cell><cell>Italian</cell><cell cols="2">SUBJ 382</cell><cell></cell><cell>1146</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 1231</cell><cell></cell><cell>1231</cell></row><row><cell></cell><cell>Turkish</cell><cell cols="2">SUBJ 378</cell><cell></cell><cell>756</cell></row><row><cell></cell><cell></cell><cell cols="2">OBJ 422</cell><cell></cell><cell>422</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">New Tokens in Machine Translated Text</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Unique tokens</cell><cell>Unique tokens</cell><cell>New Tokens</cell></row><row><cell>Language</cell><cell cols="2">Back-translation</cell><cell></cell><cell>in source</cell><cell>in MT</cell><cell>in MT</cell></row><row><cell>Arabic</cell><cell cols="2">AR &gt; EN &gt; AR</cell><cell></cell><cell>4717</cell><cell>4384</cell><cell>2166</cell></row><row><cell></cell><cell cols="4">AR &gt; EN &gt; ES &gt; EN &gt; AR 4717</cell><cell>4361</cell><cell>2456</cell></row><row><cell></cell><cell cols="4">AR &gt; EN &gt; FR &gt; EN &gt; AR 4717</cell><cell>4373</cell><cell>2541</cell></row><row><cell>Dutch</cell><cell cols="2">NL &gt; EN &gt; NL</cell><cell></cell><cell>2406</cell><cell>2323</cell><cell>732</cell></row><row><cell>English</cell><cell cols="2">EN &gt; ES &gt; EN</cell><cell></cell><cell>2590</cell><cell>2527</cell><cell>787</cell></row><row><cell>German</cell><cell cols="2">DE &gt; EN &gt; DE</cell><cell></cell><cell>2432</cell><cell>2361</cell><cell>808</cell></row><row><cell>Italian</cell><cell cols="2">IT &gt; EN &gt; IT</cell><cell></cell><cell>3309</cell><cell>3209</cell><cell>928</cell></row><row><cell></cell><cell cols="3">IT &gt; EN &gt; ES &gt; EN &gt; IT</cell><cell>3309</cell><cell>3199</cell><cell>1134</cell></row><row><cell></cell><cell cols="3">IT &gt; EN &gt; FR &gt; EN &gt; IT</cell><cell>3309</cell><cell>3206</cell><cell>1238</cell></row><row><cell>Turkish</cell><cell cols="2">TR &gt; EN &gt; TR</cell><cell></cell><cell>2967</cell><cell>2813</cell><cell>1533</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.98,90.49,327.97,472.38"><head>Table 6</head><label>6</label><figDesc>Accenture's Results From the CheckThat! 2023 Lab Task 2</figDesc><table coords="7,88.98,119.88,327.97,442.98"><row><cell>Language</cell><cell>Class</cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>Arabic</cell><cell>OBJ</cell><cell>0.936</cell><cell>0.810</cell><cell>0.869</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.473</cell><cell>0.756</cell><cell>0.582</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.705</cell><cell>0.783</cell><cell>0.725</cell></row><row><cell></cell><cell cols="2">weighted avg 0.851</cell><cell>0.800</cell><cell>0.816</cell></row><row><cell>English</cell><cell>OBJ</cell><cell>0.630</cell><cell>0.879</cell><cell>0.734</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.827</cell><cell>0.528</cell><cell>0.644</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.728</cell><cell>0.703</cell><cell>0.689</cell></row><row><cell></cell><cell cols="2">weighted avg 0.733</cell><cell>0.696</cell><cell>0.687</cell></row><row><cell>Turkish</cell><cell>OBJ</cell><cell>0.841</cell><cell>0.667</cell><cell>0.744</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.757</cell><cell>0.892</cell><cell>0.819</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.799</cell><cell>0.779</cell><cell>0.781</cell></row><row><cell></cell><cell cols="2">weighted avg 0.796</cell><cell>0.788</cell><cell>0.784</cell></row><row><cell>German</cell><cell>OBJ</cell><cell>1.000</cell><cell>0.005</cell><cell>0.010</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.335</cell><cell>1.000</cell><cell>0.501</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.667</cell><cell>0.503</cell><cell>0.256</cell></row><row><cell></cell><cell cols="2">weighted avg 0.778</cell><cell>0.337</cell><cell>0.174</cell></row><row><cell>Italian</cell><cell>OBJ</cell><cell>0.866</cell><cell>0.681</cell><cell>0.763</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.446</cell><cell>0.709</cell><cell>0.548</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.656</cell><cell>0.695</cell><cell>0.655</cell></row><row><cell></cell><cell cols="2">weighted avg 0.754</cell><cell>0.689</cell><cell>0.706</cell></row><row><cell>Dutch</cell><cell>OBJ</cell><cell>0.877</cell><cell>0.380</cell><cell>0.531</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.578</cell><cell>0.941</cell><cell>0.716</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.728</cell><cell>0.661</cell><cell>0.623</cell></row><row><cell></cell><cell cols="2">weighted avg 0.735</cell><cell>0.646</cell><cell>0.618</cell></row><row><cell>Table 7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Accenture's Results from the CheckThat! 2023 Lab Task 2</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Language Accuracy</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Arabic</cell><cell>0.800</cell><cell></cell><cell></cell></row><row><cell></cell><cell>English</cell><cell>0.696</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Turkish</cell><cell>0.788</cell><cell></cell><cell></cell></row><row><cell></cell><cell>German</cell><cell>0.337</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Italian</cell><cell>0.689</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Dutch</cell><cell>0.646</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,88.99,90.49,397.57,238.44"><head>Table 8</head><label>8</label><figDesc>BERT-based Arabic Model Performance at Different Level of Data Augmentation.</figDesc><table coords="8,108.71,122.10,377.85,206.82"><row><cell>Augmentation</cell><cell>Class</cell><cell cols="4">Sample size Precision Recall F1-score</cell></row><row><cell>No augmentation</cell><cell>OBJ</cell><cell>905</cell><cell>0.932</cell><cell>0.835</cell><cell>0.881</cell></row><row><cell></cell><cell>SUBJ</cell><cell>280</cell><cell>0.500</cell><cell>0.732</cell><cell>0.594</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.716</cell><cell>0.783</cell><cell>0.737</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.853</cell><cell>0.816</cell><cell>0.828</cell></row><row><cell>AR &gt; EN &gt; AR</cell><cell>OBJ</cell><cell>905</cell><cell>0.949</cell><cell>0.826</cell><cell>0.884</cell></row><row><cell></cell><cell>SUBJ</cell><cell>560</cell><cell>0.512</cell><cell>0.805</cell><cell>0.626</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.731</cell><cell>0.816</cell><cell>0.755</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.869</cell><cell>0.823</cell><cell>0.836</cell></row><row><cell>AR &gt; EN &gt; AR, and</cell><cell>OBJ</cell><cell>905</cell><cell>0.935</cell><cell>0.838</cell><cell>0.884</cell></row><row><cell>AR &gt; EN &gt; ES &gt; EN &gt; AR</cell><cell>SUBJ</cell><cell>840</cell><cell>0.508</cell><cell>0.744</cell><cell>0.604</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.722</cell><cell>0.791</cell><cell>0.744</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.857</cell><cell>0.820</cell><cell>0.832</cell></row><row><cell>AR &gt; EN &gt; AR,</cell><cell>OBJ</cell><cell>905</cell><cell>0.936</cell><cell>0.810</cell><cell>0.869</cell></row><row><cell cols="2">AR &gt; EN &gt; ES &gt; EN &gt; AR, and SUBJ</cell><cell>1,120</cell><cell>0.473</cell><cell>0.756</cell><cell>0.582</cell></row><row><cell>AR &gt; EN &gt; FR &gt; EN &gt; AR</cell><cell>macro avg</cell><cell></cell><cell>0.705</cell><cell>0.783</cell><cell>0.725</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.851</cell><cell>0.800</cell><cell>0.816</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.99,351.18,331.96,130.84"><head>Table 9</head><label>9</label><figDesc>BERT-based Arabic Model Performance at Different Level of Data Augmentation.</figDesc><table coords="8,213.13,382.80,169.01,99.23"><row><cell>Augmentation</cell><cell>Accuracy</cell></row><row><cell>No augmentation</cell><cell>0.816</cell></row><row><cell>AR &gt; EN &gt; AR</cell><cell>0.823</cell></row><row><cell>AR &gt; EN &gt; AR, and</cell><cell>0.820</cell></row><row><cell>AR &gt; EN &gt; ES &gt; EN &gt; AR</cell><cell></cell></row><row><cell>AR &gt; EN &gt; AR,</cell><cell>0.800</cell></row><row><cell>AR &gt; EN &gt; ES &gt; EN &gt; AR, and</cell><cell></cell></row><row><cell>AR &gt; EN &gt; FR &gt; EN &gt; AR</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,88.99,90.49,411.52,234.53"><head>Table 10</head><label>10</label><figDesc>Performance Comparison Between RoBERTa and BERT-based Specialized Style Classification Model</figDesc><table coords="9,88.99,122.10,396.87,202.91"><row><cell>Model</cell><cell>Class</cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>RoBERTa-large</cell><cell>OBJ</cell><cell>0.630</cell><cell>0.879</cell><cell>0.734</cell></row><row><cell></cell><cell>SUBJ</cell><cell>0.827</cell><cell>0.528</cell><cell>0.644</cell></row><row><cell cols="2">macro avg</cell><cell>0.728</cell><cell>0.703</cell><cell>0.689</cell></row><row><cell cols="3">weighted avg 0.733</cell><cell>0.696</cell><cell>0.687</cell></row><row><cell>cffl/bert-base-styleclassification-</cell><cell>OBJ</cell><cell>0.844</cell><cell>0.655</cell><cell>0.738</cell></row><row><cell>subjective-neutral</cell><cell>SUBJ</cell><cell>0.739</cell><cell>0.890</cell><cell>0.807</cell></row><row><cell cols="2">macro avg</cell><cell>0.792</cell><cell>0.773</cell><cell>0.773</cell></row><row><cell cols="3">weighted avg 0.789</cell><cell>0.778</cell><cell>0.774</cell></row><row><cell>Table 11</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Performance comparison between RoBERTa and BERT-based specialized style classication model</cell></row><row><cell>Model</cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell></row><row><cell cols="2">RoBERTa-large</cell><cell></cell><cell>0.696</cell><cell></cell></row><row><cell cols="4">cffl/bert-base-styleclassification-subjective-neutral 0.778</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,88.98,90.49,417.00,194.36"><head>Table 12</head><label>12</label><figDesc>Average Cosine Similarity of Italian Back-translation Compared to the Original and Weighted Average English Vader Sentiment Score -translation, where a perfect translation would not add sufficient noise to the training data and a poor translation would not add sufficient context. We would recommend exploration of the BLEU score space as an optimization problem in future work.</figDesc><table coords="10,120.69,134.06,353.90,86.07"><row><cell>Language</cell><cell>Back-translation</cell><cell cols="2">Avg. Cosine Similarity Avg. Sentiment Score</cell></row><row><cell>Arabic</cell><cell>AR &gt; EN &gt; AR</cell><cell>0.536</cell><cell>0.022</cell></row><row><cell></cell><cell cols="2">AR &gt; EN &gt; ES &gt; EN &gt; AR 0.513</cell><cell>0.025</cell></row><row><cell></cell><cell cols="2">AR &gt; EN &gt; FR &gt; EN &gt; AR 0.511</cell><cell>0.055</cell></row><row><cell>Italian</cell><cell>IT &gt; EN &gt; IT</cell><cell>0.562</cell><cell>0.097</cell></row><row><cell></cell><cell>IT &gt; EN &gt; ES &gt; EN &gt; IT</cell><cell>0.492</cell><cell>0.074</cell></row><row><cell></cell><cell>IT &gt; EN &gt; FR &gt; EN &gt; IT</cell><cell>0.466</cell><cell>0.032</cell></row></table><note coords="10,89.29,246.84,17.34,10.91"><p>back</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Conclusion</head><p>We have described the back-translation augmentation strategies and models employed by Team Accenture's submissions to Task 2. Team Accenture's back-translation and foundation model approach yielded the 3rd highest submissions in Arabic, 4th in Turkish, 5th in Dutch, and 8th in German and English. In future work, we hope to explore in more detail to what extent back-translation data augmentation can inhibit subjectivity detection systems.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,445.39,393.33,10.91;10,112.66,458.94,322.86,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,321.80,445.39,154.55,10.91">Sentiment analysis is a big suitcase</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thelwall</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIS.2017.4531228</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,484.45,445.39,21.53,10.91;10,112.66,458.94,84.97,10.91">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="74" to="80" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,472.49,393.33,10.91;10,112.66,486.04,393.98,10.91;10,112.66,499.59,28.67,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,352.77,472.49,153.21,10.91;10,112.66,486.04,251.28,10.91">Distinguishing between facts and opinions for sentiment analysis: Survey and challenges</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,374.38,486.04,88.11,10.91">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="65" to="77" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,513.13,393.61,10.91;10,112.66,526.68,393.33,10.91;10,112.66,540.23,141.31,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,384.73,513.13,121.54,10.91;10,112.66,526.68,124.03,10.91">Analysis of the subjectivity level in fake news fragments</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L M</forename><surname>Jeronimo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Campelo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,259.86,526.68,246.12,10.91;10,112.66,540.23,52.52,10.91">Proceedings of the Brazilian Symposium on Multimedia and the Web</title>
		<meeting>the Brazilian Symposium on Multimedia and the Web</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,553.78,395.17,10.91;10,112.66,567.33,367.68,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,457.54,553.78,50.29,10.91;10,112.66,567.33,218.60,10.91">Characterization of fake news based on subjectivity lexicons</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Jeronimo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Carmpelo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Costa</forename><surname>Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,343.41,567.33,58.07,10.91">J. Data Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="419" to="441" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,580.88,393.70,10.91;10,112.66,594.43,393.98,10.91;10,112.41,607.98,17.62,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,311.58,580.88,194.78,10.91;10,112.66,594.43,290.09,10.91">Combating fake news with transformers: A comparative analysis of stance detection and subjectivity analysis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kasnesis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Toumanidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Z</forename><surname>Patrikakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,410.92,594.43,53.40,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">409</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,621.53,394.53,10.91;10,112.66,635.08,394.53,10.91;10,112.14,648.63,393.85,10.91;11,112.66,86.97,394.52,10.91;11,112.66,100.52,175.52,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,180.33,648.63,325.65,10.91;11,112.66,86.97,30.66,10.91">Overview of the CLEF-2023 CheckThat! lab task 2 on subjectivity in news articles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>-C. No</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>K√∂hler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Leistra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Turkmen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,165.71,86.97,341.47,10.91;11,112.66,100.52,48.25,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,393.33,10.91;11,112.66,127.61,394.53,10.91;11,112.66,141.16,122.77,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.05684</idno>
		<title level="m" coord="11,276.86,114.06,229.12,10.91;11,112.66,127.61,389.62,10.91">Accenture at CheckThat! 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,154.71,393.57,10.91;11,112.66,168.26,393.33,10.91;11,112.66,181.81,214.54,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,230.15,154.71,228.95,10.91">Learning autocompletion from real-world datasets</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Aye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,112.66,168.26,393.33,10.91;11,112.66,181.81,100.08,10.91">IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="131" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,195.36,393.33,10.91;11,112.66,208.91,363.59,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="11,323.15,195.36,182.83,10.91;11,112.66,208.91,181.08,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,222.46,395.17,10.91;11,112.66,236.01,393.33,10.91;11,112.33,249.56,296.49,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,140.00,236.01,263.30,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1907.11692" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,263.11,393.53,10.91;11,112.28,276.66,313.55,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="11,273.55,263.11,232.64,10.91;11,112.28,276.66,131.51,10.91">An empirical study of pre-trained transformers for Arabic information extraction</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14519</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,290.20,395.01,10.91;11,112.66,303.75,190.14,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,166.51,290.20,151.73,10.91">BERTurk -BERT models for turkish</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3770924</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3770924.doi:10.5281/zenodo.3770924" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,317.30,395.01,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>M√∂ller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10906</idno>
		<title level="m" coord="11,247.67,317.30,131.37,10.91">German&apos;s next language model</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,330.85,395.01,10.91;11,112.41,344.40,190.14,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4263142</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4263142.doi:10.5281/zenodo.4263142" />
		<title level="m" coord="11,166.68,330.85,150.72,10.91">Italian BERT and ELECTRA models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,357.95,394.61,10.91;11,112.28,371.50,223.96,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Van Cranenburgh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.09582</idno>
		<title level="m" coord="11,477.91,357.95,29.36,10.91;11,112.28,371.50,93.49,10.91">Bertje: A Dutch BERT model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,385.05,395.01,10.91;11,112.66,401.04,97.35,7.90" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="11,282.14,385.05,191.49,10.91">Axiomatic attribution for deep networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01365</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,412.15,393.33,10.91;11,112.66,425.70,393.32,10.91;11,112.66,439.25,395.00,10.91;11,112.66,452.79,161.38,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,206.21,412.15,299.77,10.91;11,112.66,425.70,73.62,10.91">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
		<idno type="DOI">10.1609/icwsm.v8i1.14550</idno>
		<ptr target="https://ojs.aaai.org/index.php/ICWSM/article/view/14550.doi:10.1609/icwsm.v8i1.14550" />
	</analytic>
	<monogr>
		<title level="m" coord="11,194.09,425.70,311.89,10.91;11,112.66,439.25,27.90,10.91">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="216" to="225" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
