<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,381.11,15.42;1,88.69,106.66,112.26,15.43">TUDublin at CheckThat! 2023: ChatGPT for Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,91.88,11.96"><forename type="first">Elena</forename><surname>Shushkevich</surname></persName>
							<email>elena.n.shushkevich@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Technological University Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,199.80,134.97,59.56,11.96"><forename type="first">John</forename><surname>Cardiff</surname></persName>
							<email>john.cardiff@tudublin.ie</email>
							<affiliation key="aff0">
								<orgName type="institution">Technological University Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,381.11,15.42;1,88.69,106.66,112.26,15.43">TUDublin at CheckThat! 2023: ChatGPT for Data Augmentation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">BC8ACA945F983259653BD145C8EBFDFF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Subjectivity detection</term>
					<term>AI-generated news</term>
					<term>ChatGPT</term>
					<term>Large Language Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work describes the approach of the TUDublin team at the CheckThat! 2023 Task 2: Subjectivity in News Articles. This task is aimed to discern whether a sentence in a news article conveys the subjective perspective of its author or provides an objective viewpoint on the subject being discussed. Our team worked with English and Italian datasets. We applied mBERT, XLM-RoBERTa, SBERT models, and an ensemble of them. To improve the results, we employ ChatGPT for the news generation. Using such AI-generated news, we balanced the datasets and expanded them, which allowed us to increase the results by 9% macro F1-score for English and 3% macro F1-score for Italian (validation datasets).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Subjectivity detection is a task of natural language processing that aims to identify 'factual' or 'neutral' content in textual data <ref type="bibr" coords="1,250.50,382.17,11.58,10.91" target="#b0">[1]</ref>. It plays a crucial role in various domains, including sentiment analysis, opinion mining, and information retrieval. The ability to differentiate subjective and objective expressions enables more accurate understanding and analysis of text, allowing researchers, businesses, and organizations to gain valuable insights from large volumes of textual data. The importance of subjectivity detection lies in its practical applications. In today's digital era, where information overload and fake news proliferate, it is crucial to distinguish between subjective opinions and objective facts. Subjectivity detection enables the identification of biased or subjective content, allowing individuals, businesses, and organizations to make informed decisions based on reliable information.</p><p>This paper presents the experience of the TUDublin team in participating in the CheckThat!-2023 Task 2, which focused on subjectivity detection in news articles. The primary objective of the task was to determine whether a given message was objective or subjective. The article is structured into six sections to provide a comprehensive overview of the team's approach and findings.</p><p>Section 1 serves as the introduction, providing background information on the problem and the significance of subjectivity detection in news articles. In Section 2, we explore relevant research conducted in the field, highlighting prior works. Section 3 details the dataset utilized for the study, along with our approach of augmenting the original dataset using ChatGPT 4 <ref type="foot" coords="2,464.41,98.76,3.71,7.97" target="#foot_0">1</ref> . Section 4 outlines the preprocessing steps employed and describes the models used for subjectivity detection. Section 5 presents the training phase results, as well as the team's performance in the challenge, followed by an analysis of the achieved results. Finally, in Section 6, we summarize the conclusions from the work and outline potential avenues for further improvements to the subjectivity detection model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Subjectivity detection is a popular task in natural language processing, where researchers use various methodologies and techniques to differentiate between subjective and objective content. In <ref type="bibr" coords="2,144.25,253.99,13.00,10.91" target="#b1">[2]</ref> authors introduced a machine learning-based approach that utilized lexical and syntactic features for sentiment analysis, including subjectivity detection. In <ref type="bibr" coords="2,455.92,267.54,12.95,10.91" target="#b2">[3]</ref> authors proposed a bootstrapping algorithm that acquired subjective patterns using syntactic patterns. Recent advancements include the use of deep learning models like convolutional neural network architecture <ref type="bibr" coords="2,143.69,308.18,12.68,10.91" target="#b3">[4]</ref> and BERT model <ref type="bibr" coords="2,231.72,308.18,11.28,10.91" target="#b4">[5]</ref>, showcasing improved performance in subjectivity detection tasks in comparison with classic techniques. These studies highlight the ongoing evolution of subjectivity detection techniques, incorporating lexical, syntactic, and contextual information to accurately identify subjectivity in text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">CheckThat!-2023 dataset</head><p>The CheckThat!-2023 Task 2 (Subjectivity detection) <ref type="bibr" coords="2,337.12,428.42,11.48,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,352.59,428.42,9.03,10.91" target="#b6">7]</ref> introduced datasets in various languages, including Arabic, Dutch, English, German, Italian, and Turkish. However, for our experiments, we focused solely on the English and Italian datasets. Each dataset consists of three labels: sentence_id (representing the unique identifier for a sentence within a news article), sentence (containing the textual content of the sentence), and label (denoting 'OBJ' for objective messages and 'SUBJ' for subjective messages). The statistics of both datasets are presented in the Table <ref type="table" coords="2,190.83,509.72,3.74,10.91" target="#tab_0">1</ref>. The Italian training dataset stands out for its size, being twice as large as the English training dataset. Both datasets are unbalanced: there is a clear discrepancy in the distribution of objective and subjective messages, with a notable overrepresentation of objective messages compared to subjective ones. This discrepancy is particularly pronounced in the case of the Italian training dataset, where the number of objective news instances is three times greater than the number of subjective news instances. This imbalance poses a challenge when training models, as it may impact the overall performance and accuracy of subjectivity detection tasks on these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Expansion of the datasets using ChatGPT 4</head><p>Considering the potential impact of the inherent dataset imbalance on the classification results, we made a strategic decision to address this issue by balancing and augmenting both the English and Italian datasets using AI-generated messages. Our hypothesis is that AI-generated sentences can closely approximate, though not replicate, the human-generated messages collected by the datasets creators. As it was repeatedly demonstrated <ref type="bibr" coords="3,329.91,245.09,11.47,10.91" target="#b7">[8,</ref><ref type="bibr" coords="3,344.10,245.09,7.64,10.91" target="#b8">9]</ref>, a dataset expansion can enhance classification outcomes, and we believe it will prove beneficial in our specific case as well.</p><p>To achieve dataset balance, we employed ChatGPT 4, providing it with the training datasets for both English and Italian. We instructed ChatGPT to generate messages that closely resemble the original ones, both in terms of subjectivity and objectivity, but not identical to them. Some examples of the ChatGPT-generated sentences are presented in the Table . 2.</p><p>As a result, we expanded the number of messages in the training datasets. For the English training dataset, we expanded it from 830 to 1546 messages (773 objective, 773 subjective). Similarly, the Italian training dataset was expanded from 1613 to 2118 messages (1059 objective, 1059 subjective). The comparison between the original and the expanded datasets is visually depicted in Figure <ref type="figure" coords="3,172.29,380.58,3.74,10.91" target="#fig_0">1</ref>.</p><p>This approach allows us to address the dataset imbalance and potentially improve the classification results by incorporating a wider range of artificially generated data while maintaining the essence of the original messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Modeling</head><p>This section describes the two stages of our model creation: the preprocessing and the modeling steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Preprocessing</head><p>During the preprocessing stage, we meticulously followed a set of steps to ensure the data was appropriately prepared. These steps included:</p><p>• Converting all characters to lowercase: To ensure consistency and remove any potential case-related discrepancies, we transformed all characters in the dataset to lowercase. • Removing non-alphabetic and non-numeric characters: To focus solely on the textual content, we eliminated any characters that did not belong to the English and Italian alphabet or numeric values. • Removing stopwords, as they do not typically carry significant meaning and can hinder classification accuracy. Responsibilities to keep infections at bay place significant pressure on local government, potentially detracting attention from efforts to boost public investment, even when adequate funding is accessible. SUBJ ChatGPT</p><p>• Identifying emotional messages: Messages that contained symbols like "!!!, " "..., " or "???" often indicate an emotional tone. As part of our preprocessing, we marked these messages as "EMOTIONAL" to capture the distinct emotional content for further analysis, as we believe that more emotional messages tend to be more subjective. • Identifying first-person messages: we marked messages that contained the pronoun "I" (or its equivalent "Io" in the Italian dataset) as "FIRST." This helped us distinguish these messages for further analysis because we expected them to be more subjective in nature.</p><p>By implementing these preprocessing steps, we aimed to ensure data uniformity, eliminate noise, and highlight specific characteristics within the dataset that could provide valuable insights during subsequent stages of analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Modeling</head><p>For our subjectivity detection task, we employed several models: • mBERT <ref type="bibr" coords="5,153.93,451.35,11.70,10.91" target="#b4">[5]</ref>: The multilingual BERT (mBERT) model played a crucial role in our experiments. With support for 104 languages, mBERT features a 12-layer architecture, 768 hidden units, 12 attention heads, and around 110 million parameters. Trained on a wide range of Wikipedia articles from diverse languages, mBERT excels in capturing linguistic patterns and contextual information. We leveraged its power to analyze subjectivity in text. For the experiments, we used the batch size of 16, 512-token input, and 0.3 dropout. • SBERT <ref type="bibr" coords="5,151.18,533.37,16.55,10.91" target="#b9">[10]</ref>: We also utilized SBERT, a modified version of BERT that incorporates a siamese and triplet network structure. SBERT facilitates the creation of semantically meaningful sentence embeddings, enabling efficient comparisons using cosine similarity. Its streamlined design allows for faster processing without compromising the quality of results. For the experiments, we used the batch size of 16, 128-token input, and 0.5 dropout. • XLM-RoBERTa <ref type="bibr" coords="5,185.55,615.39,16.27,10.91" target="#b10">[11]</ref>: Another essential model in our arsenal was XLM-RoBERTa, a crosslingual sentence encoder renowned for achieving state-of-the-art performance on various cross-lingual understanding benchmarks. Trained on a vast corpus of filtered Common-Crawl data spanning 100 languages, XLM-RoBERTa provides robust linguistic representations that excel in capturing nuances across different languages. We used the batch size of 16, 128-token input, and 0.5 dropout. • An ensemble of these models, combining their predictions to enhance the accuracy and reliability of our subjectivity detection. The ensemble approach is very popular and often allows to improve the results of classification <ref type="bibr" coords="6,321.04,128.97,16.46,10.91" target="#b11">[12,</ref><ref type="bibr" coords="6,340.22,128.97,12.35,10.91" target="#b12">13]</ref>. This ensemble approach allowed us to capture consensus among the models by considering a label as correct only if it was agreed upon by the majority of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>The results of experiments achieved on the English validation dataset are presented in the Table <ref type="table" coords="6,115.79,228.24,3.74,10.91" target="#tab_2">3</ref>. The best and similar results were obtained by the mBERT model and the ensemble of all models, so we continue the experiments with the mBERT model.</p><p>The results of the experiments on the Italian validation dataset are presented in the Table <ref type="table" coords="6,500.19,396.89,3.74,10.91" target="#tab_3">4</ref>. Similarly to the English dataset, we observed that on the Italian dataset the MBERT model consistently achieved the most favorable results. Notably, the ensemble approach yielded the same results as the mBERT model alone. Based on these findings, we made the informed decision to proceed with further experiments utilizing the mBERT model.</p><p>We conducted the experiments using the mBERT model on the expanded by AI-generated news datasets (both English and Italian), and the comparison of the results is demonstrated in the Table <ref type="table" coords="6,133.04,617.50,3.74,10.91" target="#tab_4">5</ref>.</p><p>In comparison to the results obtained using the original datasets, we observed a noticeable improvement in performance when employing the balanced and expanded datasets, which were augmented using AI-generated news. Specifically, the macro F1-score exhibited a significant increase of 9% for the English dataset and 3% for the Italian dataset. These improvements underscore the effectiveness of dataset expansion in enhancing the subjectivity detection task.</p><p>Building upon these findings, we opted to submit our experimental runs utilizing the mBERT model on the expanded datasets. The resulting performance on the test datasets is presented in the Table <ref type="table" coords="7,133.04,304.67,3.74,10.91" target="#tab_5">6</ref>. Regrettably, the achieved results fell short of our expectations, indicating that further improvements are necessary in this area. Such low results could be explained by the not enough finetuned mBERT. The results on the test set using the ChatGPT-generated data should be compared with the results on the test set with the original dataset as the training one. Furthermore, in future endeavors, it is imperative to enhance the fine-tuning process for the primary model employed in binary classification. Nevertheless, despite the unsatisfactory outcome, it is worth highlighting that the innovative approach of augmenting datasets with ChatGPT-generated texts has shown promising results in the improvement of both English and Italian training datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this study, we conducted comprehensive experiments on the CheckThat!-2023 Task 2, focusing on subjectivity detection in news articles. Three transformer models, namely mBERT, SBERT, and XLM-RoBERTa, along with an ensemble of these models, were employed to analyze the subjectivity within the dataset. Among these models, mBERT consistently yielded the highest performance.</p><p>To address the issue of dataset imbalance, we leveraged ChatGPT to generate additional data, which proved instrumental in achieving a balanced and expanded dataset. The incorporation of AI-generated news significantly improved the classification results for both the English and Italian datasets, showcasing a noteworthy improvement of 9% and 3% in macro F1-score, respectively.</p><p>These findings highlight the potential of employing novel approaches, such as AI-generated news, to enhance subjectivity detection in news articles. In future, we plan to continue research and exploration of AI-generated news to uncover its potential applications and possibilities in the field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,415.25,277.93,8.93;5,160.98,84.19,273.33,318.50"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison between the original and expanded datasets.</figDesc><graphic coords="5,160.98,84.19,273.33,318.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,538.73,416.99,69.87"><head>Table 1</head><label>1</label><figDesc>Statistics of the CheckThat!-2023 datasets for English and Italian, in the training/validation and test sets</figDesc><table coords="2,95.60,570.34,404.08,38.25"><row><cell cols="3">Language Objective messages Subjective messages</cell><cell>Total</cell><cell>Messages in the Test dataset</cell></row><row><cell>English</cell><cell>532/106</cell><cell>298/113</cell><cell>830/219</cell><cell>243</cell></row><row><cell>Italian</cell><cell>1231/167</cell><cell>382/60</cell><cell>1613/227</cell><cell>440</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,410.76,318.07"><head>Table 2</head><label>2</label><figDesc>Examples of sentances from the original dataset vs ChatGPT-generated messages</figDesc><table coords="4,343.69,122.35,134.33,9.25"><row><cell>Message Label</cell><cell>Origin</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,254.80,372.70,93.78"><head>Table 3</head><label>3</label><figDesc>Results on the English dataset</figDesc><table coords="6,133.59,286.42,328.10,62.16"><row><cell>Model</cell><cell>Accuracy/Macro F1-score</cell></row><row><cell>mBERT</cell><cell>0.493/0.492</cell></row><row><cell>SBERT</cell><cell>0.470/0.463</cell></row><row><cell>XLM-RoBERTa</cell><cell>0.447/0.447</cell></row><row><cell>Ensemble of mBERT, SBERT, XLM-RoBERTa models</cell><cell>0.493/0.492</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,425.89,372.70,91.56"><head>Table 4</head><label>4</label><figDesc>Results on the Italian dataset</figDesc><table coords="6,133.59,455.29,328.10,62.16"><row><cell>Model</cell><cell>Accuracy/Macro F1-score</cell></row><row><cell>mBERT</cell><cell>0.458/0.455</cell></row><row><cell>SBERT</cell><cell>0.414/0.407</cell></row><row><cell>XLM-RoBERTa</cell><cell>0.401/0.401</cell></row><row><cell>Ensemble of mBERT, SBERT, XLM-RoBERTa models</cell><cell>0.458/0.455</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,90.49,338.58,134.12"><head>Table 5</head><label>5</label><figDesc>Comparison of mBERT results with and without ChatGPT-generated news articles</figDesc><table coords="7,167.71,122.10,259.86,102.51"><row><cell>Model</cell><cell>Accuracy/Macro F1-score</cell></row><row><cell>English</cell><cell></cell></row><row><cell>mBERT</cell><cell>0.493/0.492</cell></row><row><cell>mBERT + ChatGPT-generated data</cell><cell>0.580/0.578</cell></row><row><cell>Italian</cell><cell></cell></row><row><cell>mBERT</cell><cell>0.458/0.455</cell></row><row><cell>mBERT + ChatGPT-generated data</cell><cell>0.520/0.481</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,88.99,330.81,266.05,69.87"><head>Table 6</head><label>6</label><figDesc>Results on the test datasets for English and Italian</figDesc><table coords="7,240.23,362.43,114.81,38.25"><row><cell cols="2">Language Macro F1-score</cell></row><row><cell>English</cell><cell>0.40</cell></row><row><cell>Italian</cell><cell>0.46</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,671.02,89.05,8.97"><p>https://chat.openai.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,226.89,393.33,10.91;8,112.66,240.44,393.32,10.91;8,112.33,253.99,284.13,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,395.14,226.89,110.85,10.91;8,112.66,240.44,224.99,10.91">Bayesian network based extreme learning machine for subjectivity detection</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ragusa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gastaldo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zunino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="DOI">10.1016/J.JFRANKLIN.2017.06.007</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,345.90,240.44,142.39,10.91">Journal of The Franklin Institute</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="page" from="1780" to="1797" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,267.54,395.16,10.91;8,112.66,281.08,333.58,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,185.18,267.54,322.64,10.91;8,112.66,281.08,143.49,10.91">A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.3115/1218955.1218990</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,294.63,393.33,10.91;8,112.66,308.18,395.00,10.91;8,112.41,321.73,38.81,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,193.98,294.63,236.74,10.91">Learning extraction patterns for subjective expressions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.94,294.63,53.05,10.91;8,112.66,308.18,348.39,10.91">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,335.28,393.33,10.91;8,112.66,348.83,395.00,10.91;8,112.41,362.38,48.96,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,148.21,335.28,253.30,10.91">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,423.95,335.28,82.04,10.91;8,112.66,348.83,354.16,10.91">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,375.93,393.33,10.91;8,112.66,389.48,393.33,10.91;8,112.66,403.03,393.32,10.91;8,112.66,416.58,393.33,10.91;8,112.66,430.13,394.03,10.91;8,112.66,443.67,185.51,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,323.15,375.93,182.83,10.91;8,112.66,389.48,186.91,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423.doi:10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="8,327.87,389.48,178.11,10.91;8,112.66,403.03,393.32,10.91;8,112.66,416.58,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,457.22,395.17,10.91;8,112.66,470.77,394.53,10.91;8,112.66,484.32,395.17,10.91;8,112.66,497.87,394.52,10.91;8,112.14,511.42,395.05,10.91;8,112.33,524.97,120.27,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,239.52,484.32,268.31,10.91;8,112.66,497.87,95.64,10.91">Overview of the CLEF-2023 CheckThat! lab task 2 on subjectivity in news articles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Leistra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mehmet Deniz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.14,511.42,390.50,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF 2023</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michalis</forename><surname>Vlachos</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,538.52,394.53,10.91;8,112.33,552.07,394.85,10.91;8,112.14,565.62,395.05,10.91;8,112.66,579.17,394.53,10.91;8,112.66,592.72,394.53,10.91;8,112.66,606.27,395.17,10.91;8,112.66,619.81,393.33,10.91;8,112.33,633.36,81.51,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,179.18,565.62,328.01,10.91;8,112.66,579.17,307.13,10.91">Overview of the CLEF-2023 CheckThat! Lab checkworthiness, subjectivity, political bias, factuality, and authority of news articles and their source</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,233.97,606.27,273.86,10.91;8,112.66,619.81,393.33,10.91;8,112.33,633.36,27.43,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,112.66,646.91,393.33,10.91;9,112.66,86.97,393.32,10.91;9,112.66,100.52,329.06,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,236.37,646.91,269.61,10.91;9,112.66,86.97,125.84,10.91">Detecting fake news about covid-19 on small datasets with machine learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shushkevich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cardiff</surname></persName>
		</author>
		<idno type="DOI">10.23919/FRUCT53335.2021.9599970</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,261.58,86.97,244.40,10.91;9,112.66,100.52,28.48,10.91">2021 30th Conference of Open Innovations Association FRUCT</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="253" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,393.33,10.91;9,112.66,127.61,393.33,10.91;9,112.66,141.16,395.01,10.91;9,112.66,154.71,364.34,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,296.69,114.06,209.30,10.91;9,112.66,127.61,266.54,10.91">Bert-based classifiers for fake news detection on short and long texts with noisy data: A comparative analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shushkevich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cardiff</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16270-1_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16270-1_22" />
	</analytic>
	<monogr>
		<title level="m" coord="9,401.90,127.61,104.09,10.91;9,112.66,141.16,254.50,10.91">Proceedings of the 25th International Conference on Text, Speech, and Dialogue</title>
		<meeting>the 25th International Conference on Text, Speech, and Dialogue<address><addrLine>TSD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="263" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,394.53,10.91;9,112.66,181.81,122.77,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m" coord="9,219.42,168.26,283.17,10.91">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,394.53,10.91;9,112.66,208.91,393.33,10.91;9,112.66,222.46,393.32,10.91;9,112.66,236.01,394.62,10.91;9,112.66,249.56,386.47,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,271.58,208.91,234.41,10.91;9,112.66,222.46,20.10,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.747.doi:10.18653/v1/2020.acl-main.747" />
	</analytic>
	<monogr>
		<title level="m" coord="9,155.39,222.46,350.59,10.91;9,112.66,236.01,238.14,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,395.17,10.91;9,112.66,276.66,395.17,10.91;9,112.66,290.20,395.17,10.91;9,112.66,303.75,395.01,10.91;9,112.66,317.30,187.11,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,287.37,263.11,220.47,10.91;9,112.66,276.66,299.94,10.91">2tmn at constraint@AAAI2021: Exploiting CT-BERT and ensembling learning for COVID-19 fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Glazkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Glazkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Trifonov</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-73696-5_12</idno>
		<ptr target="https://doi.org/10.1007%2F978-3-030-73696-5_12.doi:10.1007/978-3-030-73696-5_12" />
	</analytic>
	<monogr>
		<title level="m" coord="9,437.02,276.66,70.81,10.91;9,112.66,290.20,310.24,10.91">Combating Online Hostile Posts in Regional Languages during Emergency Situation</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="116" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,394.62,10.91;9,112.66,344.40,306.03,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02359</idno>
		<title level="m" coord="9,265.43,330.85,241.85,10.91;9,112.66,344.40,176.21,10.91">Exploring text-transformers in aaai 2021 shared task: Covid-19 fake news detection in english</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
