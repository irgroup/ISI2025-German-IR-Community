<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,388.55,15.42;1,88.59,106.66,402.80,15.42">Accenture at CheckThat! 2023: Identifying Claims with Societal Impact using NLP Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,47.01,11.96"><forename type="first">Sieu</forename><surname>Tran</surname></persName>
							<email>sieu.tran@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,148.94,134.97,73.62,11.96"><forename type="first">Paul</forename><surname>Rodrigues</surname></persName>
							<email>paul.rodrigues@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,235.21,134.97,84.88,11.96"><forename type="first">Benjamin</forename><surname>Strauss</surname></persName>
							<email>b.strauss@accenturefederal.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>1201 New York Ave NW</addrLine>
									<postCode>20005</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.09,134.97,86.91,11.96"><forename type="first">Evan</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
							<email>emwillia@andrew.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,388.55,15.42;1,88.59,106.66,402.80,15.42">Accenture at CheckThat! 2023: Identifying Claims with Societal Impact using NLP Data Augmentation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">3EBF35C3A8338970755CB63A5DD39844</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>data augmentation</term>
					<term>check-worthy detection</term>
					<term>misinformation detection</term>
					<term>claim detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper discusses the results of the Accenture Team in the 2023 CheckThat Lab! focusing on checkworthiness classification on multigenre text. Check-worthiness classification is similar to misinformation detection or claim detection, but informed by the potential societal impact of the claims. We utilized high quality back-translation to augment the minority classes in labeled English, Arabic, and Spanish datasets and fine-tune pre-trained foundation models for each of the languages. This method placed 2nd in Arabic, 3rd in English, and 5th in Spanish. We further show that high-quality translation is preferable for data augmentation to translation with lower BLEU scores, and that using NLP data augmentation to increase the minority class in quantities over the minority class shows promise on this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fact-checkers and journalists must continually evaluate their information environment and make determinations of which claims are most worthy of their effort to verify and disseminate. As CLEF's CheckThat! labs have shown over the last several years, this task is challenging. In previous iterations of this lab, annotators were asked to label check-worthiness using the three following criterion <ref type="bibr" coords="1,175.71,446.73,11.36,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,189.80,446.73,7.69,10.91" target="#b1">2]</ref>:</p><p>• Do you think the claim in the text is of interest to the public?</p><p>• To what extent do you think the claim can negatively affect the reputation of an entity, country, etc.? • Do you think journalists will be interested in covering the spread of the claim or the information discussed by the claim?</p><p>The claim "all leopards are pink" is easily falsifiable, but annotators would likely agree that it does not meet any of the three criterion above and should therefore not be considered check-worthy.</p><p>In contrast to misinformation detection or claim detection tasks, in order to approximate the Methods for automated check-worthiness identification have been evaluated for years across numerous languages by CLEF's CheckThat! Lab <ref type="bibr" coords="2,306.84,312.20,11.38,10.91" target="#b1">[2,</ref><ref type="bibr" coords="2,320.94,312.20,7.48,10.91" target="#b2">3,</ref><ref type="bibr" coords="2,331.15,312.20,7.58,10.91" target="#b3">4]</ref>. This task is particularly challenging due to the lack of context around individual observations. For example, in the gold test-set labels of this year's challenge, "He has never offered a plan" was labeled as check-worthy, while "he's been a professor for a long time at a great school" is not. In both cases, without any additional context, the subject is unknown, while the predicate in the first case hints at a subject that would be of interest to the public.</p><p>Additionally, mimicking reality, where the vast majority of content one might be exposed to online or on social media is not worthy of distribution and therefore not check-worthy, class imbalance has been a common feature of this task. In previous years, our team experimented with back-translation <ref type="bibr" coords="2,230.10,434.14,12.99,10.91" target="#b4">[5]</ref> and contextually-sensitive augmentation <ref type="bibr" coords="2,434.56,434.14,13.00,10.91" target="#b5">[6]</ref> to rebalance classes. Back-translation uses synthetic data, translated from source data through an intermediary language and then back to the source language to amplify training data. <ref type="bibr" coords="2,471.74,461.24,13.00,10.91" target="#b6">[7]</ref> Our back-translation-augmented performance was more consistent across language tasks than our contextually-sensitive augmentation performance, so we elect to exclusively use back-translation augmentation in the 2023 CheckThat! lab.</p><p>In this work, we describe the methodology of our 2023 CheckThat 1B submissions for Arabic, English, and Spanish language submissions. Task 1B focused on checkworthiness detection for multigenre language data. Our submission resulted in the 3rd highest F1 score in English, the 2nd highest F1 score in Arabic, and the 5th highest F1 score in Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Exploratory Analysis</head><p>Table <ref type="table" coords="2,116.90,614.71,5.17,10.91" target="#tab_0">1</ref> shows the number of samples and unique tokens for each of the datasets provided. We see that English had the largest number of samples in training (16,876) while Arabic had the least (6,059). However, Arabic had the highest count of unique words (40,539), due to its morphological structure, and English had the lowest <ref type="bibr" coords="2,324.84,655.36,16.30,10.91" target="#b9">(10,</ref><ref type="bibr" coords="2,341.14,655.36,16.30,10.91">326)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Label Balance</head><p>Each of the datasets provided by the CheckThat! organizers had label bias which skewed the datasets towards texts that were not considered check-worthy. The Spanish dataset had the highest percentage of check-worthy texts (29%), followed by Arabic (29%), and then English (24%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">WordPiece Analysis</head><p>Transformer models utilize WordPiece tokenization schemes that differ and are dependant on the model. At the time of pre-training, the WordPiece algorithm determines which pieces of words will be retained, and which will be discarded. An "unknown" (UNK) token is utilized as a placeholder in the lexicon, and used to represent WordPiece tokens received in novel input that did not get utilized at model creation. We expect language samples which have a high amount of tokens processed as UNK would perform poorly. We present our analysis in Table <ref type="table" coords="3,250.72,463.79,3.81,10.91" target="#tab_1">2</ref>. Most notably, Spanish training set contains over 470K WordPieces, the largest number across all three languages, second by just over 350K for English. In addition, Arabic training set produced a low rate of unknown tokens (0.30%). Unexpectedly, the RoBERTa tokenizers we used did not return UNK tokens on any dataset provided by the CLEF CheckThat! organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Transformer Architectures and Pre-Trained Models</head><p>In this work, we utilize BERT and RoBERTa models. The Bidirectional Encoder Representation Transformer (BERT) is a transformer-based architecture that was introduced in 2018 <ref type="bibr" coords="3,462.91,590.16,11.34,10.91" target="#b7">[8]</ref>. BERT has had a substantial impact on the field of NLP, and achieved state of the art results on 11 NLP benchmarks at the time of its release. RoBERTa, introduced by <ref type="bibr" coords="3,374.33,617.26,11.56,10.91" target="#b8">[9]</ref>, modified various parts of BERTs training process. These modifications include more training data, more pre-training steps with bigger batches over more data, removing BERT's Next Sentence Prediction, training on longer sequences, and dynamically changing the masking pattern applied to the training data <ref type="bibr" coords="4,110.96,86.97,11.43,10.91" target="#b8">[9]</ref>.</p><p>For the Arabic Dataset, we used lanwuwei/GigaBERT-v4-Arabic-and-English <ref type="bibr" coords="4,453.07,100.52,16.41,10.91" target="#b9">[10]</ref>, which was trained on a large-scale corpus (Arabic version of OSCAR, an Arabic Wikipedia dump, and Gigaword) with ∼10B tokens. The model showing state-of-the-art zero-shot transfer performance from English to Arabic on information extraction tasks. The Arabic model contains a vocabulary of length ∼21,000 and the English model has a vocabulary length of ∼26,000. For Spanish, we used bertin-project/bertin-roberta-base-spanish <ref type="bibr" coords="4,352.28,168.26,16.28,10.91" target="#b10">[11]</ref>. The Spanish RoBERTa model contains a vocabulary of length 50,261.</p><p>For English, we used roberta-large <ref type="bibr" coords="4,256.41,195.36,11.54,10.91" target="#b8">[9]</ref>. The English RoBERTa model contains 50,265 Word-Pieces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Augmentation</head><p>The organizers provided a training and a development set for each language. We use the provided training set and development set to create internal training and validation sets for experimentation. We use the test set provided by organizers as a hold-out test set.</p><p>For each language, augmentation and training were done with via back-translation using AWS translation. We appended back-translated check-worthy texts to the training set. In our 2021 experiment <ref type="bibr" coords="4,164.54,356.25,11.31,10.91" target="#b5">[6]</ref>, we found that this form of augmentation resulted in a significant increase in recall and F1-score for check-worthy texts. For Arabic and Spanish, we used English as the pivot language which has demonstrated success in previous CheckThat Labs <ref type="bibr" coords="4,442.89,383.35,11.48,10.91" target="#b4">[5,</ref><ref type="bibr" coords="4,457.48,383.35,7.65,10.91" target="#b5">6]</ref>. For the English training set, due to significant sample imbalance, we augmented the positive-label data twice: the first using Arabic as the pivot language (i.e., English &gt; Arabic &gt; English) and the second using Arabic and Spanish as pivots (i.e., English &gt; Arabic &gt; English &gt; Spanish &gt; English).</p><p>In this work, we experiment with different quality of translation to observe how quality of augmented data improve the final model performance. Due to limited time and resources, we focused our translation experimentation on the Arabic dataset. We use the open-source translation models helsinki-nlp/opus-mt-ar-en and helsinki-nlp/opus-mt-en-ar <ref type="bibr" coords="4,434.53,478.19,17.96,10.91" target="#b11">[12]</ref> to translate to and from English, respectively.</p><p>Table <ref type="table" coords="4,127.39,505.29,5.15,10.91" target="#tab_3">3</ref> shows the BLEU score for each back-translation scheme. The higher the score, the more consistent or similar the translation to the original text. Arabic (0.3895) and the second back-translation for English (0.3400) show the highest level of divergence from the original text. We hypothesize this leads to more diverse data and better performing models.</p><p>Table <ref type="table" coords="4,126.70,559.49,5.01,10.91">4</ref> shows the number of unique tokens in the source data, the number of unique tokens in the translated augmentation data, and the difference-the number of unique tokens that was added in the translated data that was not originally in the source data. Machine translation added 6315 novel tokens to our Arabic training data, 2743 to our English training data, and 5208 to our Spanish training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classification</head><p>For both BERT and RoBERTa, we added an additional mean-pooling layer and dropout layer on top of the model prior to the final classification layer. Adding these additional layers has been shown to help prevent over-fitting while fine-tuning. We used an Adam optimizer with a learning rate of 2𝑒 -5 and an epsilon of 1.5𝑒 -8. We use a binary cross-entropy loss function, 4 epochs, and a batch size of 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Table <ref type="table" coords="5,115.43,457.67,5.00,10.91" target="#tab_4">5</ref> contains all model performance on the test set provided by the organizers. We received a weighted average F1-score of 0.687 for Arabic, 0.910 for English, and 0.912 for Spanish. The official scoring of the shared task had 0.733 for Arabic yielding 2nd place, 0.860 for English yielding 3rd place, and 0.509 for Spanish yielding 5th place. Table <ref type="table" coords="5,128.81,511.87,5.17,10.91" target="#tab_5">6</ref> contains Arabic model performance with various quality and quantity of backtranslation augmentation on the gold test set. We received a weighted average F1-score of 0.600 with no augmentation and a 0.601 with HelsinkiNLP back-translation, showing very little aggregate improvement with this translation system. AWS back-translation provided a weighted average F1-score of 0.687, showing that higher quality back-translation provides better classification results downstream. Combining AWS and Helsinki back-translation provided a score of 0.727, showing quantity of samples (increasing quantity of the initial minority class over the majority class) increases performance as well. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper discussed the results of the Accenture team in the 2023 CheckThat Lab, Task 1B, focused on labeling the check-worthiness of Arabic, English, and Spanish multi-genre content.</p><p>We utilized high quality back-translation as a method of training data augmentation for the tweets, debates, and transcripts in the challenge and placed 2nd in Arabic, 3rd in English, and 5th in Spanish. We showed, on Arabic, that a better performing translation system improves performance in the downstream task. Additionally, we showed that a strategy of rebalancing the training data, by using NLP data augmentation to flip the minority class to the positive class may be beneficial in this task. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,90.49,416.99,205.52"><head>Table 1 Dataset descriptions Language Modeling set # of samples Unique word count</head><label>1</label><figDesc></figDesc><table coords="2,89.29,139.53,416.69,156.47"><row><cell></cell><cell>Train</cell><cell>6,059</cell><cell>40,539</cell></row><row><cell>Arabic</cell><cell>Test</cell><cell>500</cell><cell>6,574</cell></row><row><cell></cell><cell>Validation</cell><cell>1,274</cell><cell>12,775</cell></row><row><cell></cell><cell>Train</cell><cell>16,876</cell><cell>10,326</cell></row><row><cell>English</cell><cell>Test</cell><cell>318</cell><cell>980</cell></row><row><cell></cell><cell>Validation</cell><cell>5,625</cell><cell>6,602</cell></row><row><cell></cell><cell>Train</cell><cell>7,488</cell><cell>33,400</cell></row><row><cell>Spanish</cell><cell>Test</cell><cell>5,000</cell><cell>18,323</cell></row><row><cell></cell><cell>Validation</cell><cell>2,460</cell><cell>14,444</cell></row><row><cell cols="4">function that generated check-worthiness labels, a successful model must attend to signals in</cell></row><row><cell cols="3">text that suggest both public interest and societal impact.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,88.99,90.49,225.41,40.49"><head>Table 2</head><label>2</label><figDesc>Unknown token distribution in data for each language.</figDesc><table coords="3,95.27,122.05,44.24,8.93"><row><cell>Language</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,95.27,122.05,454.47,122.79"><head>Tokenizer Type Modeling Set WordPiece Unknown Token Unknown Percent (%)</head><label></label><figDesc></figDesc><table coords="3,95.27,139.53,414.02,105.31"><row><cell></cell><cell></cell><cell>Training</cell><cell>324,625</cell><cell>985</cell><cell>0.30</cell></row><row><cell>Arabic</cell><cell>BERT</cell><cell>Testing</cell><cell>28,702</cell><cell>163</cell><cell>0.57</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>68,987</cell><cell>184</cell><cell>0.27</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>357,526</cell><cell>0</cell><cell>0</cell></row><row><cell>English</cell><cell>RoBERTa-based</cell><cell>Testing</cell><cell>5,013</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>117,319</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>476,395</cell><cell>0</cell><cell>0</cell></row><row><cell>Spanish</cell><cell>RoBERTa-based</cell><cell>Testing</cell><cell>192,471</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>140,179</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,88.98,90.49,397.76,209.44"><head>Table 3</head><label>3</label><figDesc>Average Sentence BLEU Score for Each Back-translation Scheme</figDesc><table coords="5,88.99,122.05,397.75,177.87"><row><cell></cell><cell cols="3">Language Back-translation</cell><cell cols="2">Average Sentence BLEU Score</cell></row><row><cell></cell><cell>Arabic</cell><cell>AR &gt; EN &gt; AR</cell><cell></cell><cell>0.390</cell></row><row><cell></cell><cell>English</cell><cell>EN &gt; AR &gt; EN</cell><cell></cell><cell>0.455</cell></row><row><cell></cell><cell>English</cell><cell cols="3">EN &gt; AR &gt; EN &gt; ES &gt; EN 0.340</cell></row><row><cell></cell><cell>Spanish</cell><cell>ES &gt; EN &gt; ES</cell><cell></cell><cell>0.551</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">New Tokens in Machine Translated Text</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Unique tokens</cell><cell>Unique tokens</cell><cell>New Tokens</cell></row><row><cell cols="3">Language Back-translation</cell><cell cols="2">in source</cell><cell>in MT</cell><cell>in MT</cell></row><row><cell>Arabic</cell><cell cols="2">AR &gt; EN &gt; AR</cell><cell>16132</cell><cell></cell><cell>14491</cell><cell>6315</cell></row><row><cell>English</cell><cell cols="2">EN &gt; AR &gt; EN</cell><cell>9621</cell><cell></cell><cell>9154</cell><cell>2252</cell></row><row><cell>English</cell><cell cols="3">EN &gt; AR &gt; EN &gt; ES &gt; EN 9621</cell><cell></cell><cell>9335</cell><cell>2743</cell></row><row><cell>Spanish</cell><cell cols="2">ES &gt; EN &gt; ES</cell><cell>20524</cell><cell></cell><cell>19450</cell><cell>5208</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,88.98,90.49,335.84,263.94"><head>Table 5</head><label>5</label><figDesc>Accenture results from CheckThat! 2023 Task 1</figDesc><table coords="6,170.45,119.83,254.37,234.59"><row><cell cols="2">Language Class</cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>Arabic</cell><cell>No</cell><cell>0.409</cell><cell>0.821</cell><cell>0.546</cell></row><row><cell></cell><cell>Yes</cell><cell>0.913</cell><cell>0.613</cell><cell>0.733</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.661</cell><cell>0.717</cell><cell>0.640</cell></row><row><cell></cell><cell cols="2">weighted avg 0.789</cell><cell>0.664</cell><cell>0.687</cell></row><row><cell>English</cell><cell>No</cell><cell>0.903</cell><cell>0.971</cell><cell>0.936</cell></row><row><cell></cell><cell>Yes</cell><cell>0.935</cell><cell>0.796</cell><cell>0.860</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.919</cell><cell>0.884</cell><cell>0.898</cell></row><row><cell></cell><cell cols="2">weighted avg 0.914</cell><cell>0.912</cell><cell>0.910</cell></row><row><cell>Spanish</cell><cell>No</cell><cell>0.935</cell><cell>0.982</cell><cell>0.958</cell></row><row><cell></cell><cell>Yes</cell><cell>0.715</cell><cell>0.395</cell><cell>0.509</cell></row><row><cell></cell><cell>macro avg</cell><cell>0.825</cell><cell>0.689</cell><cell>0.733</cell></row><row><cell></cell><cell cols="2">weighted avg 0.912</cell><cell>0.922</cell><cell>0.912</cell></row><row><cell></cell><cell cols="2">Language Accuracy</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Arabic</cell><cell>0.664</cell><cell></cell><cell></cell></row><row><cell></cell><cell>English</cell><cell>0.912</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Spanish</cell><cell>0.922</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,88.98,90.49,417.00,336.47"><head>Table 6</head><label>6</label><figDesc>Accenture results from experimentation with different translation quality to improve BERT-based Arabic model</figDesc><table coords="7,105.26,131.79,384.77,295.17"><row><cell>Augmentation</cell><cell>Class</cell><cell cols="4">Training Sample Precision Recall F1-score</cell></row><row><cell>No augmentation</cell><cell>No</cell><cell>4,301</cell><cell>0.363</cell><cell>0.935</cell><cell>0.523</cell></row><row><cell></cell><cell>Yes</cell><cell>1,758</cell><cell>0.956</cell><cell>0.464</cell><cell>0.620</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.660</cell><cell>0.700</cell><cell>0.574</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.810</cell><cell>0.580</cell><cell>0.600</cell></row><row><cell>Back-translation</cell><cell>No</cell><cell>4,301</cell><cell>0.347</cell><cell>0.821</cell><cell>0.488</cell></row><row><cell>with HelinskiNLP</cell><cell>Yes</cell><cell>3,516</cell><cell>0.895</cell><cell>0.496</cell><cell>0.638</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.621</cell><cell>0.659</cell><cell>0.563</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.760</cell><cell>0.576</cell><cell>0.601</cell></row><row><cell>Back-translation</cell><cell>No</cell><cell>4,301</cell><cell>0.409</cell><cell>0.821</cell><cell>0.546</cell></row><row><cell cols="2">with AWS translation Yes</cell><cell>3,516</cell><cell>0.913</cell><cell>0.613</cell><cell>0.733</cell></row><row><cell></cell><cell>macro avg</cell><cell></cell><cell>0.661</cell><cell>0.717</cell><cell>0.640</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.789</cell><cell>0.664</cell><cell>0.687</cell></row><row><cell>Back-translation</cell><cell>No</cell><cell>4,301</cell><cell>0.447</cell><cell>0.780</cell><cell>0.568</cell></row><row><cell cols="2">with AWS translation Yes</cell><cell>5,274</cell><cell>0.905</cell><cell>0.684</cell><cell>0.779</cell></row><row><cell>and HelinskiNLP</cell><cell>macro avg</cell><cell></cell><cell>0.676</cell><cell>0.732</cell><cell>0.674</cell></row><row><cell></cell><cell>weighted avg</cell><cell></cell><cell>0.792</cell><cell>0.708</cell><cell>0.727</cell></row><row><cell cols="2">Augmentation</cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell></row><row><cell cols="2">No augmentation</cell><cell></cell><cell></cell><cell>0.580</cell><cell></cell></row><row><cell cols="3">Back-translation with HelinskiNLP</cell><cell></cell><cell>0.576</cell><cell></cell></row><row><cell cols="3">Back-translation with AWS translation</cell><cell></cell><cell>0.664</cell><cell></cell></row><row><cell cols="5">Back-translation with AWS translation and HelinskiNLP 0.708</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,558.92,394.53,10.91;6,112.28,572.47,394.91,10.91;6,112.66,586.02,393.58,10.91;6,112.28,599.57,245.06,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,268.63,572.47,238.55,10.91;6,112.66,586.02,67.48,10.91">Experimental ir meets multilinguality, multimodality, and interaction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,204.51,586.02,301.73,10.91;6,112.28,599.57,106.35,10.91">Proceedings of the Eleventh International Conference of the CLEF Association (CLEF 2020)</title>
		<meeting>the Eleventh International Conference of the CLEF Association (CLEF 2020)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,613.11,394.53,10.91;6,112.66,626.66,394.62,10.91;6,112.28,640.21,393.71,10.91;6,112.66,653.76,393.33,10.91;7,112.66,453.66,393.33,10.91;7,112.41,467.21,138.60,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,367.11,626.66,140.17,10.91;6,112.28,640.21,296.33,10.91">Overview of CheckThat! 2020: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,432.44,640.21,73.54,10.91;6,112.66,653.76,393.33,10.91;7,112.66,453.66,128.58,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 11th International Conference of the CLEF Association, CLEF 2020</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25, 2020. 2020</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="215" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,480.76,394.53,10.91;7,112.66,494.31,393.64,10.91;7,112.66,507.86,394.61,10.91;7,112.66,521.41,393.33,10.91;7,112.66,534.96,394.53,10.91;7,112.66,548.51,195.45,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,320.98,494.31,185.31,10.91;7,112.66,507.86,374.20,10.91">Overview of the CLEF-2021 CheckThat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,521.41,393.33,10.91;7,112.66,534.96,215.25,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 21-24, 2021. 2021</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="264" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,562.06,394.53,10.91;7,112.66,575.61,393.32,10.91;7,112.66,589.15,194.39,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<title level="m" coord="7,266.31,575.61,239.67,10.91;7,112.66,589.15,162.47,10.91">Overview of the CLEF-2022 CheckThat! lab task 1 on identifying relevant claims in tweets</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,602.70,393.33,10.91;7,112.66,616.25,393.57,10.91;7,112.33,629.80,29.19,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.02431</idno>
		<title level="m" coord="7,271.01,602.70,234.98,10.91;7,112.66,616.25,244.33,10.91">Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,643.35,393.33,10.91;7,112.66,656.90,394.53,10.91;8,112.66,86.97,173.79,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.05684</idno>
		<title level="m" coord="7,278.95,643.35,227.04,10.91;7,112.66,656.90,389.62,10.91">Accenture at CheckThat! 2021: interesting claim identification and ranking with contextually sensitive lexical training data augmentation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,100.52,393.33,10.91;8,112.66,114.06,393.53,10.91;8,112.66,127.61,393.33,10.91;8,112.66,141.16,395.01,10.91;8,112.66,154.71,138.14,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,272.30,100.52,233.68,10.91;8,112.66,114.06,78.20,10.91">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1009</idno>
		<ptr target="https://aclanthology.org/P16-1009.doi:10.18653/v1/P16-1009" />
	</analytic>
	<monogr>
		<title level="m" coord="8,217.21,114.06,288.98,10.91;8,112.66,127.61,121.73,10.91">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="8,112.66,168.26,393.33,10.91;8,112.66,181.81,363.59,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="8,353.43,168.26,152.55,10.91;8,112.66,181.81,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,195.36,394.53,10.91;8,112.30,208.91,393.69,10.91;8,112.66,222.46,107.17,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="8,171.55,208.91,260.79,10.91">Roberta: A robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,236.01,393.53,10.91;8,112.28,249.56,313.55,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="8,273.55,236.01,232.64,10.91;8,112.28,249.56,131.51,10.91">An empirical study of pre-trained transformers for Arabic information extraction</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14519</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,263.11,393.32,10.91;8,112.66,276.66,393.32,10.91;8,112.66,290.20,395.01,10.91;8,112.66,303.75,335.90,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,309.98,276.66,196.00,10.91;8,112.66,290.20,146.49,10.91">Efficient pre-training of a Spanish language model using perplexity sampling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>La Rosa Y Eduardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ponferrada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manu</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pablo</forename><surname>González De Prado Salas Y María</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Grandury</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bertin</surname></persName>
		</author>
		<ptr target="http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6403" />
	</analytic>
	<monogr>
		<title level="j" coord="8,268.02,290.20,164.51,10.91">Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,317.30,394.53,10.91;8,112.66,330.85,393.32,10.91;8,112.33,344.40,195.70,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,236.90,317.30,265.27,10.91">OPUS-MT -Building open translation services for the World</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Thottingal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.20,330.85,378.79,10.91;8,112.33,344.40,86.68,10.91">Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
