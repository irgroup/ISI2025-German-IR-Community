<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,410.43,15.42;1,89.29,106.66,382.63,15.42;1,89.29,128.58,143.64,15.43">CSECU-DSG at CheckThat! 2023: Transformer-based Fusion Approach for Multimodal and Multigenre Check-Worthiness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,88.87,156.89,54.55,11.96"><forename type="first">Abdul</forename><surname>Aziz</surname></persName>
							<email>aziz.abdul.cu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Chittagong</orgName>
								<address>
									<postCode>Chattogram-4331</postCode>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,165.05,156.89,98.24,11.96"><forename type="first">Md</forename><forename type="middle">Akram</forename><surname>Hossain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Chittagong</orgName>
								<address>
									<postCode>Chattogram-4331</postCode>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.27,156.89,92.64,11.96"><forename type="first">Abu</forename><forename type="middle">Nowshed</forename><surname>Chy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Chittagong</orgName>
								<address>
									<postCode>Chattogram-4331</postCode>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,410.43,15.42;1,89.29,106.66,382.63,15.42;1,89.29,128.58,143.64,15.43">CSECU-DSG at CheckThat! 2023: Transformer-based Fusion Approach for Multimodal and Multigenre Check-Worthiness</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">C8F82D4EB5275158E60D8AE189E896F6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>multimodal fact-checking</term>
					<term>automatic fact-checking</term>
					<term>multigenre check-worthiness</term>
					<term>multimodal checkworthiness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Check-worthiness is identifying verifiable factual claims present or not in content. It might be beneficial to automatically verify the political discourses, social media posts, and newspaper content. However, the multifaceted nature and hidden meaning of the content make it difficult to automatically identify the factual claims. To address these challenges, CheckThat! 2023 introduced a task to build automatic Check-worthiness classifiers in tweets with multimodal and multigenre settings. This paper presented our participation in CheckThat! 2023 Task 1. We perform fine-tuning on language-specific and vision pretrained transformer models to extract the visual-contextualized or contextualized features representation for the multimodal and multigenre check-worthiness task. We add a BiLSTM layer on top of the contextual features and concatenate it with the other visual or contextualized features to get an enrich unified representation. Later, we employ a multi-sample dropout strategy to predict a more accurate class label. Experimental results show that our proposed method achieved competitive performance among the participants and obtained 1st place in the multimodal Arabic check-worthiness task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays, people frequently deliver their ideas, beliefs, visions, and breaking news using manifold social media platforms including Instagram, Reddit, Twitter, and Facebook based on their real-time behavior and useful features. Therefore, such platforms have increasingly evolved the skyrocketed means of discovering various information including public views, health situations, political mindsets, and customer choices. Disinformation is also shared on social media using these platforms. Thus, automated fact-checking is one of the most prominent tasks in recent years. Various works <ref type="bibr" coords="1,251.11,535.58,11.28,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,265.12,535.58,7.44,10.91" target="#b1">2,</ref><ref type="bibr" coords="1,275.29,535.58,7.44,10.91" target="#b2">3,</ref><ref type="bibr" coords="1,285.45,535.58,7.44,10.91" target="#b3">4,</ref><ref type="bibr" coords="1,295.62,535.58,8.91,10.91" target="#b4">5]</ref> have been introduced based on fact-checking in various formats including textual and multimodal. Most of the prior works utilise the traditional transformer-based approach <ref type="bibr" coords="1,272.02,562.67,11.48,10.91" target="#b5">[6,</ref><ref type="bibr" coords="1,286.66,562.67,9.03,10.91" target="#b6">7]</ref> for checking the worthiness of factual claims. Alam et al. <ref type="bibr" coords="1,139.04,576.22,12.71,10.91" target="#b7">[8]</ref> introduce a shared task at CheckThat! 2023 <ref type="bibr" coords="1,347.47,576.22,12.71,10.91" target="#b8">[9]</ref> to check-worthiness of tweets in both multimodal and multigenre (multiple languages) settings. To tackle this task we used a transformer-based fusion approach with the BiLSTM module on top of the language model and the multi-sample dropout strategy. Our system ranked first in the multimodal Arabic task and achieved competitive performance in other tasks.</p><p>We organize the rest of the paper as follows: Section 2 describes our proposed system in the CheckThat! 2023 to automatically identify the worthiness of tweets, in Section 3, we present our proposed system design with parameter settings and conduct the results and performance analysis. Finally, we conclude with some future directions in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed Framework</head><p>Transformers models learn the necessary information about the relationship between words effectively. We employed the pre-trained transformers model with the BiLSTM module and a training strategy to identify the factual claim worthiness of tweets in multimodal and multigenre settings. The overview of our proposed transformer-based framework is depicted in Figure <ref type="figure" coords="2,496.24,267.54,3.74,10.91" target="#fig_0">1</ref>. Given a tweet containing a textual claim (and corresponding image for the multimodal tasks), we fed them into two transformer models. Our model identifies the data whether the task is multimodal or not, if multimodal (text and image inputs) our model uses language-specific BERT and ConvNEXT model to encode contextual-visual representation otherwise (only text input) our model uses language-specific BERT and the XLM-RoBERTa model to encode diverse contextual representation for multigenre tasks. We sum both models' contextual features for the multigenre task and fed them to a BiLSTM module. In multimodal tasks, we employ the BiLSTM module on top of the contextual representation only to handle the long-term contextual dependency present on tweets. Then, we concatenate visual-contextual features in a unified architecture for multimodal representation. These unified features vector fed to the multi-sample dropout strategy to speed up training and improve the robustness of our proposed model. We leverage the different dropout sample outputs using the arithmetic mean technique to get the final label of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Transformer Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Twitter XLM-RoBERTa</head><p>Facebook AI launched the XLM-RoBERTa <ref type="bibr" coords="3,271.89,251.63,17.75,10.91" target="#b9">[10]</ref> as an upgrade to their initial XLM-100 model. It is a scaled cross-lingual sentence encoder. Using self-supervised training approaches, it offers stateof-the-art performances in cross-lingual understanding where a model is taught in one language and then applied to multiple languages with no additional training data. This model showed increased performance on numerous NLP applications. XLM-RoBERTa creates the possibility for a one-model-for-many-languages approach rather than a single model per language. Here, we use HuggingFace's implementation of the Twitter XLM-RoBERTa-base model <ref type="bibr" coords="3,423.84,332.93,17.76,10.91" target="#b10">[11]</ref> for multigenre tasks. It is composed of 12 layers (i.e. transformer block), the dimension of hidden size is 768 and the number of the self-attention head is 12. We use this model for all language-specific tasks as the 2nd model to capture diverse contextual representation along with the language-specific BERT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">BERTweet</head><p>RoBERTa is an extension to the original BERT model which is named as a robustly optimized BERT pre-training approach. It focuses on the key hyper-parameters choices and removing the next sentence prediction (NSP) objective. Besides, it is training with much larger mini-batches and learning rates. BERTweet <ref type="bibr" coords="3,228.38,477.03,18.07,10.91" target="#b11">[12]</ref> is trained based on the RoBERTa pre-training procedure. BERTweet consists of 850M English Tweets. We use base sized BERTweet model for both multimodal and language-specific English tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">AraBERT</head><p>AraBERT <ref type="bibr" coords="3,134.85,552.98,18.07,10.91" target="#b12">[13]</ref> is a version of BERT that is gaining popularity for effective contextual representation of textual contents in various Arabic tasks including natural language inference in language-specific characteristics, named entity recognition in Arabic corpora. It is pre-trained on the Arabic language which used workpiece vocabulary. In our approach, we employ the huggingface implementation of the AraBERTV2 base-sized model for all Arabic tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Spanish BERT</head><p>BERT stands for bidirectional encoder representations from transformers and is a new method of pre-training sentence representations which achieves state-of-the-art results on many NLP tasks including question-answering, and text classification. BETO <ref type="bibr" coords="4,379.37,86.97,17.77,10.91" target="#b13">[14]</ref> is a BERT model trained on a big Spanish corpus. For the Spanish task, we used BETO (Spanish BERT) a size similar to a BERT-base model that trained with the whole word masking technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">ConvNEXT</head><p>ConvNEXT <ref type="bibr" coords="4,145.05,163.39,18.07,10.91" target="#b14">[15]</ref> is a pure convolutional model and builds inspired by the design of Vision Transformers (ViT). It is a hierarchical transformer model that reintroduced various convolution network priors, creating the transformer as a generic vision backbone and achieving notable performance on a wide variety of vision tasks. These motivate us to use the ConvNEXT vision transformer model in our proposed method. We employed the ConvNEXT base-sized model as the image encoder which trained on ImageNet-1k at resolution 224x224.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">System Architecture</head><p>We jointly finetune two transformer models for all tasks. In the multimodal task, we used a language-specific pre-train BERT transformer model and a pre-train ConvNEXT vision transformer model for contextual and visual representation. We utilize the BiLSTM module on top of the contextual representation to learn the long-term contextual representation, respectively. Then, we concatenate these feature vectors in a unified architecture to get a visual-contextual representation. This feature vector is then fed to the multi-sample dropout strategy to get the final label of each multimodal task.</p><p>In multigenre tasks, we used a language-specific BERT model and Twitter XLM-RoBERTa for language-specific contextual representation. It helps the model to capture diverse contextual feature representations present in tweets. We sum two models' sequence outputs and fed them to a BiLSTM module to capture the effective contextual information. Later, we employ a multi-sample dropout strategy on top of the BiLSTM module output which predicts the final label for each task of multigenre tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Training Strategies</head><p>Different training strategies improved the performance of the transformers model. In this paper, we use a training strategy named multi-sample dropout <ref type="bibr" coords="4,350.59,506.73,18.07,10.91" target="#b15">[16]</ref> technique. The multi-sample dropout technique improves the generalization ability and accelerates the training of the base model <ref type="bibr" coords="4,119.51,533.83,16.26,10.91" target="#b15">[16]</ref>. To improve the accuracy of the transformer-based trained network, we utilise the multi-sample dropout technique. We choose 3 number of the dropout samples based on the validation data performance. In multi-sample dropouts, we duplicate the features vector of the transformer model after the dropout layer, while sharing the weights among these duplicated fully connected layers. We calculate the loss for each sample and then the losses are averaged to obtain the final loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset Description</head><p>The organizers used a benchmark dataset <ref type="bibr" coords="5,278.19,132.25,18.00,10.91" target="#b16">[17]</ref> published in ECIR-2023 to evaluate the performance of the participants' systems at the CheckThat! 2023 shared task <ref type="bibr" coords="5,403.10,145.80,11.35,10.91" target="#b7">[8]</ref>. Organizers provide different datasets for multimodal Arabic, multimodal English, and language-specific dataset including English, Arabic and Spanish languages. Dataset texts/images are taken from English, Arabic and Spanish tweets. The dataset statistics of subtask 1A: check-worthiness of multimodal content and subtask 1B: check-worthiness of multigenre unimodal content are presented in Table <ref type="table" coords="5,115.79,213.54,3.74,10.91" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Preprocessing</head><p>To preprocess the given tweet text we employ various preprocessing techniques. In English tweets, we expand the contraction (e.g. "isn't", "can't", and "aren't") into their normalized form for effective representation. The URLs and special characters do not contain any causal indicative information which may be useful for this task, we discard them from the tweet texts. We utilize a publicly available Python library emot to demojize (i.e. convert emojis into text) all the available emoji in the tweet texts. Moreover, all the words, characters, and punctuation floodings are replaced with a single one. For example, "It's crooked she's she's guilty of a very very serious crime." is becoming "It's crooked she's guilty of a very serious crime." after removing punctuation flooding and consecutive words. We preprocess Arabic text using the publicly available AraBERT model's ArabertPreprocessor<ref type="foot" coords="6,413.12,112.31,3.71,7.97" target="#foot_0">1</ref>  <ref type="bibr" coords="6,420.06,114.06,16.32,10.91" target="#b12">[13]</ref>. To preprocess Spanish tweets we utilise publicly available python text normalization library cucco<ref type="foot" coords="6,456.75,125.86,3.71,7.97" target="#foot_1">2</ref> where we utilise a list of normalizations including replace_urls, remove_extra_whitespaces, replace_emojis, replace_hyphens, replace_punctuation, replace_symbols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experimental Settings</head><p>We now describe the details of our experimental settings and the hyper-parameter settings with the finetuning strategy that we have employed to design our proposed system for the CheckThat! 2023 shared task 1. We finetune state-of-the-art Huggingface <ref type="bibr" coords="6,288.71,423.44,17.99,10.91" target="#b17">[18]</ref> transformer models including Twitter XLM-RoBERTa<ref type="foot" coords="6,130.21,435.24,3.71,7.97" target="#foot_2">3</ref> , AraBERT<ref type="foot" coords="6,180.12,435.24,3.71,7.97" target="#foot_3">4</ref> , BERTweet <ref type="foot" coords="6,233.98,435.24,3.71,7.97" target="#foot_4">5</ref> , Spanish BERT<ref type="foot" coords="6,303.85,435.24,3.71,7.97" target="#foot_5">6</ref> and ConvNEXT<ref type="foot" coords="6,378.47,435.24,3.71,7.97" target="#foot_6">7</ref> model for this task. We used all models as the base size in this work. We concatenate the training and development data during the model training phase. We used the CUDA-enabled GPU of the Google Colaboratory <ref type="bibr" coords="6,487.94,464.09,18.04,10.91" target="#b18">[19]</ref> platform and set the manual seed = 42 to generate reproducible results. We obtained the optimal parameter settings of our proposed model based on the performance of the development set which is articulated in Table <ref type="table" coords="6,218.16,504.74,3.74,10.91" target="#tab_1">2</ref>. We use a multi-sample dropout training strategy on top of the unified representation of multimodal and multigenre tasks. To determine the optimal dropout values, we searched over the set {0.1, 0.2, • • •, 0.9} and found the best dropout range was 0.1 to 0.3 based on our experimental results on the development set. We used the default settings for the other parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Evaluation Measure</head><p>The CheckThat! 2023 shared task 1: check-worthiness in multimodal and multigenre content organizers employed a standard evaluation metric F1-score over the positive class as the primary evaluation metric to evaluate the participants' system on tweet data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Comparative performances with other selected participants (Sub-task 1B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Results and Analysis</head><p>In this section, we analyze the performance of our proposed CSECU-DSG system in the Check-That! 2023 worthiness identification of tweet shared task. The comparative performance of our proposed CSECU-DSG system on subtask 1A test data against other top-performing participants' systems is presented in Table <ref type="table" coords="7,227.65,609.50,3.81,10.91" target="#tab_2">3</ref>. We have seen that our proposed method achieved a 0.399 score and ranked 1st in the multimodal Arabic task based on F1-score over the positive class. Moreover, our system achieved competitive performance on multimodal English task. This validates the effectiveness of our proposed method in multimodal check-worthiness tasks.</p><p>The comparative performance of our proposed CSECU-DSG system on subtask 1B languagespecific test data including English, Arabic and Spanish against other top-performing participants' systems are presented in Table <ref type="table" coords="8,276.63,114.06,3.81,10.91">4</ref>. In language-specific tasks, our method achieved relatively lower performance as we are not effectively tuning the hyperparameters of our method. However, our method achieved 3rd and 4th place in Spanish and Arabic check-worthiness tasks, respectively. This validates the potency and applicability of our proposed method in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Directions</head><p>In this paper, we present an approach to automatically identify the worthiness of factual claims present in tweets in multimodal and multigenre settings using fine-tuned transformers models fusion architecture. We employ a BiLSTM module on top of the language model to handle the long-term dependencies present in tweets. Moreover, we use the multi-sample dropout training strategy to speed up training and get better generalization ability. Experimental results demonstrated the efficacy of our proposed transformer-based method, where the fusion of transformer variants with the BiLSTM module and multi-sample dropout prediction helped us to obtain competitive performance and ranked 1st in 1A Arabic and 3rd in 1B Spanish in the CheckThat! 2023 shared task.</p><p>Further research will be conducted on other SOTA transformers models with a unified architecture of two or more. However, the classes of the dataset are imbalanced, so the weighted average fusion strategy of different models may be exploiting better context for check-worthiness from multimodal and multigenre tweets effectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,570.07,416.69,8.93;2,89.29,582.08,37.53,8.87"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview diagram of our proposed method for multimodal and multigenre check-worthiness of tweets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,240.10,417.98,282.06"><head>Table 1</head><label>1</label><figDesc>Dataset statistics of CheckThat! 2023 shared task 1 according to each label on the corresponding task.</figDesc><table coords="5,158.24,271.72,276.30,250.45"><row><cell>Task</cell><cell>Label</cell><cell>Train</cell><cell cols="3">Dev Dev-Test Test</cell></row><row><cell cols="4">Subtask 1A: Check-Worthiness of multimodal content</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Yes</cell><cell>776</cell><cell>113</cell><cell>220</cell><cell>203</cell></row><row><cell>Multimodal-Arabic</cell><cell>No</cell><cell>1,421</cell><cell>207</cell><cell>402</cell><cell>792</cell></row><row><cell></cell><cell>Total</cell><cell>2,197</cell><cell>320</cell><cell>622</cell><cell>995</cell></row><row><cell></cell><cell>Yes</cell><cell>820</cell><cell>87</cell><cell>174</cell><cell>277</cell></row><row><cell>Multimodal-English</cell><cell>No</cell><cell>1,536</cell><cell>184</cell><cell>374</cell><cell>459</cell></row><row><cell></cell><cell>Total</cell><cell>2,356</cell><cell>271</cell><cell>548</cell><cell>736</cell></row><row><cell cols="5">Subtask 1B: Check-Worthiness of multigenre unimodal content</cell><cell></cell></row><row><cell></cell><cell>Yes</cell><cell>1,758</cell><cell>485</cell><cell>411</cell><cell>123</cell></row><row><cell>Unimodal-Arabic</cell><cell>No</cell><cell>4,301</cell><cell>789</cell><cell>682</cell><cell>377</cell></row><row><cell></cell><cell>Total</cell><cell cols="2">6,059 1,274</cell><cell>1,093</cell><cell>500</cell></row><row><cell></cell><cell>Yes</cell><cell cols="2">4,058 1,355</cell><cell>238</cell><cell>108</cell></row><row><cell>Unimodal-English</cell><cell>No</cell><cell cols="2">12,818 4,270</cell><cell>794</cell><cell>210</cell></row><row><cell></cell><cell>Total</cell><cell cols="2">16,876 5,625</cell><cell>1,032</cell><cell>318</cell></row><row><cell></cell><cell>Yes</cell><cell>2,208</cell><cell>299</cell><cell>704</cell><cell>509</cell></row><row><cell>Unimodal-Spanish</cell><cell>No</cell><cell cols="2">5,280 2,161</cell><cell>4,296</cell><cell>4,491</cell></row><row><cell></cell><cell>Total</cell><cell cols="2">7,488 2,460</cell><cell>5,000</cell><cell>5,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,260.10,306.89,142.16"><head>Table 2</head><label>2</label><figDesc>Model settings for CheckThat! 2023 shared task 1 of our proposed method.</figDesc><table coords="6,210.33,260.10,174.61,98.03"><row><cell></cell><cell>Optimal Value</cell></row><row><cell>Learning rate</cell><cell>3e-5</cell></row><row><cell>Max-len</cell><cell>128</cell></row><row><cell>Number of epochs</cell><cell>5</cell></row><row><cell>Batch size</cell><cell>4</cell></row><row><cell>Manual seed</cell><cell>42</cell></row><row><cell>BiLSTM hidden state</cell><cell>256</cell></row><row><cell>Dropout</cell><cell>0.1, 0.2, 0.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,163.10,343.81,306.71"><head>Table 3</head><label>3</label><figDesc>Comparative results with other selected participants (Sub-task 1A).</figDesc><table coords="7,162.48,163.10,270.32,306.71"><row><cell>Team</cell><cell cols="2">Multimodal Arabic</cell><cell>Multimodal English</cell></row><row><cell>CSECU-DSG</cell><cell cols="2">0.399</cell><cell>0.628</cell></row><row><cell cols="4">Top performing team and baseline performance based on F1-score</cell></row><row><cell>Fraunhofer SIT [20]</cell><cell>-</cell><cell></cell><cell>0.712</cell></row><row><cell>ZHAW-CAI [21]</cell><cell>-</cell><cell></cell><cell>0.708</cell></row><row><cell>marvinpeng</cell><cell cols="2">0.312</cell><cell>0.697</cell></row><row><cell>Z-Index [22]</cell><cell cols="2">0.301</cell><cell>0.495</cell></row><row><cell>Baseline</cell><cell cols="2">0.299</cell><cell>0.474</cell></row><row><cell>Team</cell><cell cols="2">Arabic English</cell><cell>Spanish</cell></row><row><cell>CSECU-DSG</cell><cell>0.662</cell><cell>0.834</cell><cell>0.599</cell></row><row><cell cols="4">Top performing team and baseline performance based on F1-score</cell></row><row><cell>ES-VRAI [23]</cell><cell>0.809</cell><cell>0.843</cell><cell>0.627</cell></row><row><cell>OpenFact [24]</cell><cell>-</cell><cell>0.898</cell><cell>-</cell></row><row><cell>DSHacker [25]</cell><cell>0.633</cell><cell>0.819</cell><cell>0.641</cell></row><row><cell>Fraunhofer SIT [20]</cell><cell>-</cell><cell>0.878</cell><cell>-</cell></row><row><cell>Baseline</cell><cell>0.625</cell><cell>0.462</cell><cell>0.172</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,92.57,605.23,134.77,8.97"><p>https://github.com/aub-mind/arabert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,92.57,616.19,112.25,8.97"><p>https://pypi.org/project/cucco/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,92.57,627.15,213.39,8.97"><p>https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,92.57,638.11,202.32,8.97"><p>https://huggingface.co/aubmindlab/bert-base-arabertv2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,92.57,649.07,157.18,8.97"><p>https://huggingface.co/vinai/bertweet-base</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,92.57,660.03,233.41,8.97"><p>https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,92.57,670.99,188.85,8.97"><p>https://huggingface.co/facebook/convnext-base-224</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,434.55,393.33,10.91;8,112.66,448.10,393.33,10.91;8,112.66,461.65,332.30,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,344.18,434.55,161.80,10.91;8,112.66,448.10,215.43,10.91">Truth of varying shades: Analyzing language in fake news and political fact-checking</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,350.89,448.10,155.10,10.91;8,112.66,461.65,234.31,10.91">Proceedings of the 2017 conference on empirical methods in natural language processing</title>
		<meeting>the 2017 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2931" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,475.20,394.53,10.91;8,112.66,488.75,393.33,10.91;8,112.66,502.30,393.33,10.91;8,112.66,515.85,107.17,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.05542</idno>
		<title level="m" coord="8,248.43,488.75,257.55,10.91;8,112.66,502.30,238.31,10.91">Overview of the clef-2018 checkthat! lab on automatic identification and verification of political claims. task 1</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,529.40,393.33,10.91;8,112.66,542.95,394.62,10.91;8,112.66,556.50,245.46,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,449.74,529.40,56.25,10.91;8,112.66,542.95,394.62,10.91;8,112.66,556.50,76.27,10.91">Overview of the clef-2019 checkthat! lab: Automatic identification and verification of claims. task 1: Check-worthiness</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martino</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,202.39,556.50,100.80,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2380</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,570.05,394.52,10.91;8,112.66,583.60,393.33,10.91;8,112.66,597.15,394.52,10.91;8,112.66,610.69,80.57,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,274.72,583.60,231.27,10.91;8,112.66,597.15,263.54,10.91">Overview of the clef-2021 checkthat! lab task 1 on check-worthiness estimation in tweets and political debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,403.33,597.15,99.33,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="369" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,624.24,393.32,10.91;8,112.66,637.79,300.69,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,277.21,624.24,163.77,10.91">A survey on automated fact-checking</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,449.33,624.24,56.66,10.91;8,112.66,637.79,216.75,10.91">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="178" to="206" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,651.34,393.33,10.91;8,112.66,664.89,328.40,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vijjali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Potluri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Teki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13253</idno>
		<title level="m" coord="8,290.91,651.34,215.08,10.91;8,112.66,664.89,145.96,10.91">Two stage transformer model for covid-19 fake news detection and fact checking</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.32,10.91;9,112.66,100.52,393.57,10.91;9,112.33,114.06,29.19,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.02431</idno>
		<title level="m" coord="9,273.61,86.97,232.37,10.91;9,112.66,100.52,244.33,10.91">Accenture at checkthat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,127.61,394.52,10.91;9,112.66,141.16,393.64,10.91;9,112.66,154.71,393.33,10.91;9,112.66,168.26,394.52,10.91;9,112.66,181.81,58.60,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,332.76,141.16,173.54,10.91;9,112.66,154.71,304.01,10.91">Overview of the CLEF-2023 CheckThat! lab task 1 on check-worthiness in multimodal and multigenre content</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hakimov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,439.56,154.71,66.43,10.91;9,112.66,168.26,327.90,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,394.53,10.91;9,112.33,208.91,394.85,10.91;9,112.14,222.46,395.05,10.91;9,112.66,236.01,394.53,10.91;9,112.66,249.56,394.53,10.91;9,112.66,263.11,395.17,10.91;9,112.66,276.66,393.33,10.91;9,112.33,290.20,81.51,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,179.18,222.46,328.01,10.91;9,112.66,236.01,307.13,10.91">Overview of the CLEF-2023 CheckThat! Lab checkworthiness, subjectivity, political bias, factuality, and authority of news articles and their source</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,233.97,263.11,273.86,10.91;9,112.66,276.66,393.33,10.91;9,112.33,290.20,27.43,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,112.66,303.75,394.53,10.91;9,112.66,317.30,393.33,10.91;9,112.66,330.85,201.68,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<title level="m" coord="9,271.58,317.30,234.41,10.91;9,112.66,330.85,19.96,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,344.40,393.33,10.91;9,112.66,357.95,231.59,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<idno>arXiv-2104</idno>
		<title level="m" coord="9,339.77,344.40,166.22,10.91;9,112.66,357.95,75.90,10.91">Xlm-t: A multilingual language model toolkit for twitter</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,393.32,10.91;9,112.33,385.05,393.65,10.91;9,112.66,398.60,230.27,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,270.60,371.50,235.39,10.91;9,112.33,385.05,28.53,10.91">BERTweet: A pre-trained language model for English Tweets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,162.88,385.05,343.10,10.91;9,112.66,398.60,157.27,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,412.15,393.33,10.91;9,112.66,425.70,393.32,10.91;9,112.41,439.25,118.68,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,251.38,412.15,254.60,10.91;9,112.66,425.70,61.22,10.91">Arabert: Transformer-based model for arabic language understanding</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Antoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,196.95,425.70,309.04,10.91;9,112.41,439.25,26.27,10.91">LREC 2020 Workshop Language Resources and Evaluation Conference 11-16</title>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,452.79,393.32,10.91;9,112.66,466.34,266.40,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,395.98,452.79,110.00,10.91;9,112.66,466.34,115.82,10.91">Spanish pre-trained bert model and evaluation data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cañete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chaperon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,251.30,466.34,97.80,10.91">PML4DC at ICLR 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,479.89,393.33,10.91;9,112.66,493.44,369.67,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2201.03545" />
		<title level="m" coord="9,369.75,479.89,102.79,10.91">A convnet for the 2020s</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,506.99,393.60,10.91;9,112.66,520.54,146.44,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Inoue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09788</idno>
		<title level="m" coord="9,157.27,506.99,316.07,10.91">Multi-sample dropout for accelerated training and better generalization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,534.09,394.53,10.91;9,112.66,547.64,393.33,10.91;9,112.66,561.19,394.62,10.91;9,112.48,574.74,394.70,10.91;9,112.28,588.29,394.91,10.91;9,112.66,601.84,80.57,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,444.71,547.64,61.28,10.91;9,112.66,561.19,374.88,10.91">The clef-2023 checkthat! lab: Checkworthiness, subjectivity, political bias, factuality, and authority</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,189.54,588.29,150.64,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="506" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,615.39,394.53,10.91;9,112.66,628.93,393.33,10.91;9,112.66,642.48,227.94,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="9,211.89,628.93,294.09,10.91;9,112.66,642.48,45.66,10.91">HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,656.03,393.33,10.91;9,112.66,669.58,377.95,10.91" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,207.61,656.03,298.38,10.91;9,112.66,669.58,317.03,10.91">Google colaboratory, Building machine learning and deep learning models on google cloud platform: a comprehensive guide for beginners</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bisong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bisong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="59" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.66,100.52,393.33,10.91;10,112.66,114.06,91.04,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,243.65,86.97,129.09,10.91;10,400.89,86.97,105.10,10.91;10,112.66,100.52,393.33,10.91;10,112.66,114.06,91.04,10.91">Enhancing the detection of multimodal and multigenre check-worthiness using optical character recognition and model souping, ????</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Frick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-E</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Fraunhofer SIT at CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,127.61,393.32,10.91;10,112.66,141.16,100.24,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,288.12,127.61,108.55,10.91">Zhaw-cai at CheckThat!</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Däniken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deriu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cieliebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,426.04,127.61,79.94,10.91;10,112.66,141.16,72.69,10.91">Ensembling using kernel averaging</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,154.71,393.33,10.91;10,112.66,168.26,233.69,10.91" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="10,335.73,154.71,98.84,10.91;10,463.20,154.71,42.79,10.91;10,112.66,168.26,233.69,10.91">Unimodal and multimodal checkworthiness classification, ????</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tarannum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R H</forename><surname>Noori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Z-Index at CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,181.81,395.16,10.91;10,112.66,195.36,394.52,10.91;10,112.66,208.91,18.98,10.91" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="10,281.58,181.81,99.12,10.91;10,410.37,181.81,97.46,10.91;10,112.66,195.36,394.52,10.91;10,112.66,208.91,18.98,10.91">Analyzing checkworthiness in multimodal and multigenre contents through fusion and sampling approaches, ????</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Sadouk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebbak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">E</forename><surname>Zekiri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Es-vrai at CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,222.46,394.53,10.91;10,112.14,236.01,393.84,10.91;10,112.66,249.56,383.20,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sawiński</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wecel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ksieżniak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stróżyna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lewoniewski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Stolarski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Abramowicz</surname></persName>
		</author>
		<title level="m" coord="10,188.49,236.01,105.29,10.91;10,322.70,236.01,183.28,10.91;10,112.66,249.56,355.90,10.91">Head-to-head gpt vs. bert -a comparative study of transformers language models for the detection of check-worthy claims</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Openfact at CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,263.11,395.17,10.91;10,111.60,276.66,395.59,10.91;10,112.66,290.20,18.98,10.91" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="10,330.26,263.11,177.57,10.91;10,111.60,276.66,390.37,10.91">DSHacker at CheckThat! 2023: Check-Worthiness in Multigenre and Multilingual Content With GPT-3.5 Data Augmentation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Modzelewski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Sosnowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wierzbicki</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
