<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,367.03,15.42;1,89.29,106.66,375.93,15.42;1,89.29,128.58,240.29,15.43">ES-VRAI at CheckThat! 2023: Enhancing Model Performance for Subjectivity Detection through Multilingual Data Aggregation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.89,101.77,11.96"><forename type="first">Hamza</forename><forename type="middle">Tarik</forename><surname>Sadouk</surname></persName>
							<email>sadouk.hamza.tarik@gamil.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Militaire Polytechnique</orgName>
								<address>
									<addrLine>El Bahri</addrLine>
									<postBox>PO Box 17</postBox>
									<postCode>16111</postCode>
									<settlement>Bordj, Algiers</settlement>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,209.70,156.89,69.45,11.96"><forename type="first">Faouzi</forename><surname>Sebbak</surname></persName>
							<email>faouzi.sebbak@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Militaire Polytechnique</orgName>
								<address>
									<addrLine>El Bahri</addrLine>
									<postBox>PO Box 17</postBox>
									<postCode>16111</postCode>
									<settlement>Bordj, Algiers</settlement>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.14,156.89,108.60,11.96"><forename type="first">Hussem</forename><forename type="middle">Eddine</forename><surname>Zekiri</surname></persName>
							<email>houssemzekiri@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ecole Militaire Polytechnique</orgName>
								<address>
									<addrLine>El Bahri</addrLine>
									<postBox>PO Box 17</postBox>
									<postCode>16111</postCode>
									<settlement>Bordj, Algiers</settlement>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,367.03,15.42;1,89.29,106.66,375.93,15.42;1,89.29,128.58,240.29,15.43">ES-VRAI at CheckThat! 2023: Enhancing Model Performance for Subjectivity Detection through Multilingual Data Aggregation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">7F6D7B2291793FA77946B54EDAE4A772</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Subjectivity Detection</term>
					<term>Multilingual</term>
					<term>Data aggregation</term>
					<term>BERT-Multilingual</term>
					<term>XLM-RoBERTa</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our participation in the CLEF2023 CheckThat! Lab <ref type="bibr" coords="1,394.77,223.09,9.47,8.97" target="#b0">[1]</ref>, focusing on Task 2, which addresses Subjectivity Detection <ref type="bibr" coords="1,257.16,234.05,9.52,8.97" target="#b1">[2]</ref>. Distinguishing subjective and objective content is pivotal in numerous natural language processing tasks. Our work delves into the challenges and techniques associated with the binary classification problem of discerning personal opinions from impartial stances in textual data. The task encompasses six languages: Arabic, Dutch, English, German, Italian, and Turkish. We adopt a multilingual approach, merging diverse datasets into a comprehensive dataset to train a multilingual model. Through fine-tuning pre-trained language models and employing sampling techniques to tackle class imbalance, we optimize the model's performance. Our methodology combines multilingual data aggregation with fine-tuning and class imbalance handling, resulting in a robust subjectivity detection model. By participating in the CheckThat! Lab, we contribute to advancing the understanding of subjectivity detection in different languages, opening avenues for more accurate sentiment analysis and text classification in various applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In today's digital age, the vast amount of textual data generated through social media, online forums, news articles, and other sources present a significant challenge for automated systems. A crucial task in natural language processing is to accurately discern whether a comment represents the author's personal opinion or conveys an impartial stance on a discussed topic. This binary classification problem requires sophisticated algorithms capable of analyzing text segments, which may consist of sentences or paragraphs, and accurately classifying them as subjective or objective. Understanding the subjectivity of text is essential for numerous applications, including sentiment analysis, information retrieval, content recommendation, and opinion mining. By developing computational approaches to tackle subjectivity detection, we can unlock valuable insights and improve the overall understanding of textual data.</p><p>The utilization of linguistic features, such as syntactic patterns, semantic cues, lexical choices, and stylistic elements, captures the subjective nature of textual content. These features provide valuable clues about the author's emotions, attitudes, and perspectives, enabling a deeper understanding of the text's subjectivity. In addition to linguistic features, contextual information plays a vital role in subjectivity detection. Understanding the surrounding context, including co-occurring words, discourse structure, and dialogue patterns, aids in distinguishing personal opinions from factual statements. By considering the broader context in which the text segment appears, we enhance the system's ability to accurately classify subjective and objective content.</p><p>In recent years, language models and transformer architectures have revolutionized the field of natural language processing, offering powerful tools for capturing linguistic features and contextual information in subjectivity detection. These models, such as BERT (Bidirectional Encoder Representations from Transformers) <ref type="bibr" coords="2,298.88,208.91,11.58,10.91" target="#b2">[3]</ref>, and RoBERTa (Robustly Optimized BERT approach) <ref type="bibr" coords="2,135.94,222.46,11.32,10.91" target="#b3">[4]</ref>, have demonstrated remarkable success in various language understanding tasks. By leveraging the pre-trained representations learned from vast amounts of text data, language models have the ability to encode rich semantic and syntactic information into their embeddings. This enables them to capture intricate linguistic features that are crucial for identifying subjectivity in textual content. The deep contextual understanding provided by transformer architectures allows for the recognition of subtle nuances and linguistic cues that differentiate subjective expressions from objective statements.</p><p>The utilization of language models offers immense potential in uncovering subjective expressions and objective stances in textual data, contributing to the overall understanding and analysis of subjective content. This approach allows us to capture the nuances and intricacies of language usage, enabling our models to better discern subjective elements and provide more precise classifications. By combining these advanced techniques with our comprehensive methodology of multilingual data aggregation, fine-tuning, and class imbalance handling, we create a holistic solution that improves subjectivity detection across languages and facilitates a deeper comprehension of sentiment and perspective in text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Subjectivity Detection (SD) is a process aimed at differentiating between objective and subjective information. Historically, two primary methods have been employed: syntactic and semantic.</p><p>Semantic approaches tackle subjectivity detection by utilizing statistical or neural text representation techniques <ref type="bibr" coords="2,177.97,511.42,13.57,10.91" target="#b4">[5,</ref><ref type="bibr" coords="2,194.26,511.42,7.51,10.91" target="#b5">6]</ref>, necessitating labeled training data. These methods may incorporate domain-specific assumptions or employ guidelines for the annotation process to acquire the required training data <ref type="bibr" coords="2,189.70,538.52,11.43,10.91" target="#b6">[7]</ref>.</p><p>Syntactic methods primarily rely on identifying keywords <ref type="bibr" coords="2,370.68,552.07,12.99,10.91" target="#b7">[8]</ref> or employing lexicons <ref type="bibr" coords="2,492.22,552.07,11.58,10.91" target="#b8">[9]</ref>. However, these techniques are often specific to particular languages and may lose information during translation. Additionally, lexicon-based approaches require external databases, which can limit their applicability in various scenarios.</p><p>While semantic methods offer advantages such as language independence and applicability to multiple languages, they also present challenges. The perception of subjectivity is inherently subjective, leading to interpretation bias, ambiguity in annotation, and difficulties in handling edge cases <ref type="bibr" coords="2,138.59,646.91,16.25,10.91" target="#b9">[10]</ref>.</p><p>Table1 summarizes the methods used in subjectivity detection. In this work, we leverage the power of language models and transformer architectures to address linguistic features and contextual information in subjectivity detection. By incorporating these state-of-the-art techniques into our computational models, we aim to advance the accuracy and robustness of subjectivity classification systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data overview</head><p>This task is provided in seven languages: Arabic, Dutch, English, German, Italian, and Turkish <ref type="bibr" coords="3,89.29,516.45,11.28,10.91" target="#b1">[2]</ref>. In our work, we adopt a multilingual method by merging all available datasets into one and then training a multilingual model. All details in Table <ref type="table" coords="3,334.72,530.00,3.74,10.91">2</ref>.</p><p>Upon examining Table <ref type="table" coords="3,204.94,543.55,3.78,10.91">2</ref>, it becomes apparent that class imbalance is present, which poses a particular concern. To address this issue, we have implemented a range of techniques as detailed subsequently.</p><p>Upsampling is a method used to tackle imbalanced data by increasing the number of samples in the minority class. It can improve performance for underrepresented classes but has drawbacks like overfitting due to duplicated or similar instances, leading to limited generalization on unseen data.</p><p>Downsampling is a method used to handle imbalanced data by decreasing the number of instances in the majority class. It aims to achieve balance by randomly removing samples from the majority class. However, downsampling has limitations, including the loss of valuable information and smaller dataset size, which may not be ideal for training complex models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed approach</head><p>In our work, we have adopted a multilingual approach to data aggregation, consolidating diverse datasets from multiple languages into a comprehensive dataset and training a multilingual model. By merging datasets from different languages, we harness the inherent linguistic variations and semantic richness present across languages. This approach enhances the model's ability to capture a wide range of linguistic patterns and effectively handle cross-lingual tasks, facilitating better generalization across different language domains. By including multiple languages in the training data, the model becomes more adaptable, robust, and capable of handling diverse textual inputs.</p><p>However, certain languages often suffer from limited available resources, known as lowresource languages, leading to suboptimal results when training models individually due to data scarcity and lack of linguistic resources. To address this challenge, our multilingual data aggregation strategy proves advantageous. By merging datasets across languages, the model can learn from the patterns and structures present in resource-rich languages and transfer that knowledge to low-resource languages. This cross-lingual transfer mitigates data scarcity issues and enhances the model's performance on low-resource languages, resulting in more accurate and reliable outcomes.</p><p>Our approach involves not only merging diverse datasets from various languages into a single comprehensive dataset but also fine-tuning pre-trained language models and employing sampling techniques to address the class imbalance. By fine-tuning pre-trained language models, we leverage their existing linguistic understanding and adapt them to the specific subjectivity detection task. Additionally, we employ sampling techniques to ensure a balanced representation of subjective and objective instances. We used both Upsampling and Downsampling in a comparative study to assess which technique was more suitable for the desired task. This comprehensive methodology combining multilingual data aggregation, fine-tuning, and class imbalance handling results in a robust and accurate subjectivity detection model capable of effectively classifying subjective and objective content in different languages, contributing to a deeper understanding of textual sentiment and perspective. In this perspective, we used two multilingual models: BERT-Multilingual <ref type="bibr" coords="4,199.29,524.97,13.00,10.91" target="#b2">[3]</ref> is a pretrained language model that can be finetuned on various downstream natural language processing tasks, including named entity recognition, sentiment analysis, and question answering, across multiple languages. It is trained on a large corpus of monolingual text from 104 languages, including low-resource languages, making it a valuable tool for cross-lingual transfer learning. The model uses a transformer architecture and employs a masked language modeling objective during pretraining. BERT-Multilingual has achieved state-of-the-art results on many benchmark NLP tasks, making it a widely used and highly influential model in the NLP community.</p><p>XLM-RoBERTa <ref type="bibr" coords="4,176.56,633.36,12.69,10.91" target="#b3">[4]</ref> is a cross-lingual language model and is an extension of RoBERTa. XLM-RoBERTa is pre-trained on monolingual and multilingual datasets, including 100 languages, using masked language modeling (MLM) and translation language modeling (TLM) objectives. The model employs a larger batch size and more data augmentation techniques, such as noise and token shuffling, to improve performance. XLM-RoBERTa outperforms previous state-ofthe-art models on several cross-lingual benchmarks, such as XNLI and the MLQA multilingual question-answering dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and discussion</head><p>In this study, we evaluated six different model configurations for classifying subjective and objective claims in a multilingual dataset containing Arabic, Dutch, English, German, Italian, and Turkish languages. The dataset was imbalanced, with a larger number of objective sentences compared to subjective sentences. To tackle the class imbalance issue, we employed Oversampling and Downsampling techniques in four out of the six configurations. Table <ref type="table" coords="5,452.49,377.40,5.16,10.91" target="#tab_1">3</ref> shows the results obtained on a fraction of the Development dataset (50% of the Development dataset was used for hyperparameter optimization). We found that the following hyperparameters produced the best results: number of epochs= 4; learning rate= 1e-5; batch size= 16.</p><p>The results presented in this study were obtained prior to the release of the Test dataset, with the objective of identifying the most appropriate configuration to be employed during the evaluation phase. This pre-release assessment aimed to discern the optimal setup for subsequent evaluations and ensure the reliability and validity of the findings. For the finetuned models with different sampling techniques, we use the following contractions: Upon analysis of Table <ref type="table" coords="5,204.29,605.34,3.74,10.91" target="#tab_1">3</ref>, we have derived the following observations:</p><p>• BM2 performs best in terms of accuracy, F1-Score, F1-Macro, Precision Macro, and Recall Macro. This indicates that handling the class imbalance using Oversampling helps improve the model's performance.</p><p>• BM3 yields better results than the baseline BM1 model, although it underperforms compared to the BM2 approach. This suggests that Oversampling is more effective at addressing the class imbalance in this case. • XR models generally underperform when compared to BM models. It is possible that the XR architecture is less suited to this specific task or dataset or that additional hyperparameter tuning is required to improve its performance. • Similar to BM, XR models also benefit from Oversampling, showing an increase in performance compared to the baseline XR1. However, the improvement is not as significant as that observed for BM1. • During the evaluation cycle, we employed BM2, which yielded F1-Macro of 0.78. Unfortunately, due to technical problems, we were unable to produce the required results within the evaluation cycle deadline. Consequently, despite achieving a commendable fourthplace result, we did not secure a position on the leaderboard. Notably, the first-place position was attained with a slightly higher F1-Macro of 0.82.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Our work focuses on a multilingual approach to data aggregation, merging diverse datasets from multiple languages to train a comprehensive multilingual model. By leveraging linguistic variations and semantic richness across languages, the model captures a wide range of patterns and excels in cross-lingual tasks, enhancing generalization. We employ sampling techniques and fine-tune pre-trained language models to address class imbalance. Two models are used BERT-Multilingual and XLM-RoBERTa. BERT-Multilingual achieves the highest performance, demonstrating significant improvements across multiple metrics. Oversampling effectively addresses class imbalance and further enhances its performance. Downsampling also yields better results but is outperformed by Oversampling. XLM-RoBERTa models generally underperform compared to BERT-Multilingual and may require additional hyperparameter tuning. While both models benefit from Oversampling, BERT-Multilingual achieves a commendable fourth-place position in the evaluation, securing high accuracy and F1-Macro. Unfortunately, technical issues prevented the submission of final results within the deadline, narrowly missing the first-place position achieved by a slightly higher F1-Macro. Overall, our approach yields a robust and accurate subjectivity detection model, facilitating sentiment analysis and enhancing textual understanding across languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,107.28,508.31,121.80,10.91;5,107.28,523.21,196.01,10.91;5,107.28,538.12,201.11,10.91;5,107.28,553.02,103.49,10.91;5,107.28,567.92,177.71,10.91;5,107.28,582.83,182.63,10.91"><head>•</head><label></label><figDesc>BM1: BERT-Multilingual; • BM2: BERT-Multilingual + Oversampling; • BM3: BERT-Multilingual + Downsampling; • XR1: XLM-RoBERTa; • XR2: XLM-RoBERTa + Oversampling; • XR3: XLM-RoBERTa + Downsampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,452.06,288.80"><head>Table 1</head><label>1</label><figDesc>Taxonomy of Subjectivity Detection Methods</figDesc><table coords="3,88.99,132.57,452.06,246.71"><row><cell>Method</cell><cell>Description</cell><cell></cell><cell></cell><cell>Advantage</cell><cell>Disadvantage</cell></row><row><cell cols="4">Syntactic Identify keywords or use lexicons to deter-</cell><cell cols="2">Easy to implement</cell><cell>Language-specific and can</cell></row><row><cell></cell><cell>mine subjectivity.</cell><cell></cell><cell></cell><cell>and fast.</cell><cell>lose information during</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>translation.</cell></row><row><cell cols="4">Semantic Use statistical or neural text representation</cell><cell cols="2">More accurate than</cell><cell>Requires labeled training</cell></row><row><cell></cell><cell cols="3">techniques to determine subjectivity.</cell><cell cols="2">syntactic methods.</cell><cell>data and can be prone to in-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>terpretation bias.</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Dataset description for subjectivity detection</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell></cell><cell>Development</cell></row><row><cell></cell><cell></cell><cell cols="4">Subjective Objective Subjective Objective</cell></row><row><cell></cell><cell>Arabic</cell><cell>280</cell><cell>905</cell><cell>70</cell><cell>227</cell></row><row><cell></cell><cell>Dutch</cell><cell>311</cell><cell>489</cell><cell>93</cell><cell>107</cell></row><row><cell></cell><cell>English</cell><cell>298</cell><cell>532</cell><cell>113</cell><cell>106</cell></row><row><cell></cell><cell>German</cell><cell>308</cell><cell>492</cell><cell>77</cell><cell>123</cell></row><row><cell></cell><cell>Italian</cell><cell>382</cell><cell>1281</cell><cell>60</cell><cell>167</cell></row><row><cell></cell><cell>Turkish</cell><cell>378</cell><cell>422</cell><cell>100</cell><cell>100</cell></row><row><cell></cell><cell>Total</cell><cell>1957</cell><cell>4072</cell><cell>513</cell><cell>830</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,90.49,388.62,109.09"><head>Table 3</head><label>3</label><figDesc>Model performance comparison for multilingual subjectivity detection</figDesc><table coords="5,115.17,118.53,362.44,81.05"><row><cell cols="2">Model Accuracy</cell><cell>F1</cell><cell cols="5">Precision Recall F1-Macro MacroP MacroR</cell></row><row><cell>BM1</cell><cell>0.7817</cell><cell>0.7698</cell><cell>0.8141</cell><cell>0.7300</cell><cell>0.7811</cell><cell>0.7847</cell><cell>0.7817</cell></row><row><cell>BM2</cell><cell>0.8167</cell><cell>0.8161</cell><cell>0.8188</cell><cell>0.8133</cell><cell>0.8167</cell><cell>0.8167</cell><cell>0.8167</cell></row><row><cell>BM3</cell><cell>0.7700</cell><cell>0.7738</cell><cell>0.7613</cell><cell>0.7867</cell><cell>0.7699</cell><cell>0.7703</cell><cell>0.7700</cell></row><row><cell>XR1</cell><cell>0.7550</cell><cell>0.7361</cell><cell>0.7977</cell><cell>0.6833</cell><cell>0.7537</cell><cell>0.7603</cell><cell>0.7550</cell></row><row><cell>XR2</cell><cell>0.7800</cell><cell>0.7815</cell><cell>0.7763</cell><cell>0.7867</cell><cell>0.7800</cell><cell>0.7800</cell><cell>0.7800</cell></row><row><cell>XR3</cell><cell>0.7500</cell><cell>0.7525</cell><cell>0.7451</cell><cell>0.7600</cell><cell>0.7500</cell><cell>0.7501</cell><cell>0.7500</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,587.66,394.53,10.91;6,112.33,601.21,394.85,10.91;6,112.14,614.76,395.05,10.91;6,112.66,628.31,394.53,10.91;6,112.66,641.86,394.53,10.91;6,112.66,655.41,395.17,10.91;7,112.66,86.97,393.33,10.91;7,112.33,100.52,81.51,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,179.18,614.76,328.01,10.91;6,112.66,628.31,307.13,10.91">Overview of the CLEF-2023 CheckThat! Lab checkworthiness, subjectivity, political bias, factuality, and authority of news articles and their source</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Azizov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,233.97,655.41,273.86,10.91;7,112.66,86.97,393.33,10.91;7,112.33,100.52,27.43,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and In-teraction</note>
</biblStruct>

<biblStruct coords="7,112.66,114.06,394.53,10.91;7,112.66,127.61,394.53,10.91;7,112.14,141.16,393.85,10.91;7,112.66,154.71,394.52,10.91;7,112.66,168.26,175.52,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,180.33,141.16,325.65,10.91;7,112.66,154.71,30.66,10.91">Overview of the CLEF-2023 CheckThat! lab task 2 on subjectivity in news articles</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>-C. No</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Leistra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Turkmen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.71,154.71,341.47,10.91;7,112.66,168.26,48.25,10.91">Working Notes of CLEF 2023-Conference and Labs of the Evaluation Forum, CLEF &apos;2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,181.81,393.33,10.91;7,112.66,195.36,363.59,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,353.43,181.81,152.55,10.91;7,112.66,195.36,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,208.91,394.53,10.91;7,112.66,222.46,393.33,10.91;7,112.66,236.01,252.60,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<title level="m" coord="7,312.59,222.46,193.39,10.91;7,112.66,236.01,70.89,10.91">Unsupervised cross-lingual representation learning at scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,249.56,395.17,10.91;7,112.66,263.11,296.31,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno>arXiv preprint cs/0409058</idno>
		<title level="m" coord="7,185.01,249.56,322.82,10.91;7,112.66,263.11,141.77,10.91">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,276.66,393.33,10.91;7,112.66,290.20,218.13,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.2188</idno>
		<title level="m" coord="7,308.26,276.66,197.73,10.91;7,112.66,290.20,40.93,10.91">A convolutional neural network for modelling sentences</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,303.75,394.62,10.91;7,112.28,317.30,393.71,10.91;7,112.66,330.85,393.59,10.91;7,112.28,344.40,394.91,10.91;7,112.66,357.95,70.43,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,451.34,303.75,55.94,10.91;7,112.28,317.30,263.19,10.91">Subjectivita: An italian corpus for subjectivity detection in newspapers</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bolognini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Inajetovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ivasiuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,401.72,317.30,104.26,10.91;7,112.66,330.85,393.59,10.91;7,112.28,344.40,102.63,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 21-24, 2021. 2021</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,371.50,393.33,10.91;7,112.66,385.05,393.33,10.91;7,112.66,398.60,394.53,10.91;7,112.66,412.15,123.33,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,194.33,371.50,311.66,10.91;7,112.66,385.05,20.14,10.91">Creating subjective and objective sentence classifiers from unannotated texts</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,157.58,385.05,348.41,10.91;7,112.66,398.60,118.10,10.91">Computational Linguistics and Intelligent Text Processing: 6th International Conference, CICLing 2005</title>
		<meeting><address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">February 13-19, 2005. 2005</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="486" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,425.70,394.62,10.91;7,112.66,439.25,394.53,10.91;7,112.66,452.79,80.57,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,203.74,425.70,282.02,10.91">A subjectivity detection-based approach to sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sagnika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,439.25,345.89,10.91">Machine Learning and Information Processing: Proceedings of ICMLIP 2019</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,466.34,393.33,10.91;7,112.66,479.89,394.62,10.91;7,112.66,493.44,393.33,10.91;7,112.66,506.99,394.53,10.91;7,112.39,520.54,212.54,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,428.47,466.34,77.52,10.91;7,112.66,479.89,371.81,10.91">On the definition of prescriptive annotation guidelines for language-agnostic subjectivity detection</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Antici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Korre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Muti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,493.44,355.52,10.91;7,112.66,506.99,390.12,10.91">conjunction with the 45th European Conference on Information Retrieval (ECIR 2023)</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">3370</biblScope>
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
	<note>Proceedings of Text2Story-Sixth Workshop on Narrative Extraction From Texts</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
