<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,350.76,15.42;1,89.29,106.66,321.67,15.42;1,89.29,129.00,212.38,11.96">Exploring Approaches to Answer Biomedical Questions: From Pre-processing to GPT-4 Notebook for the BioASQ Lab at CLEF 2023</title>
				<funder ref="#_B9qYuTM">
					<orgName type="full">IITP</orgName>
				</funder>
				<funder>
					<orgName type="full">Korea Health Industry Development Institute</orgName>
					<orgName type="abbreviated">KHIDI</orgName>
				</funder>
				<funder ref="#_jeYs75f">
					<orgName type="full">National Research Foundation of Korea</orgName>
				</funder>
				<funder>
					<orgName type="full">Korea Health Technology R&amp;D</orgName>
				</funder>
				<funder ref="#_KMWfZUx">
					<orgName type="full">Ministry of Health &amp; Welfare, Republic of Korea</orgName>
				</funder>
				<funder ref="#_Fv7DZQW">
					<orgName type="full">MSIT (Ministry of Science and ICT), Korea</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,65.06,11.96"><forename type="first">Hyunjae</forename><surname>Kim</surname></persName>
							<email>hyunjae-kim@korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.00,154.90,71.29,11.96"><forename type="first">Hyeon</forename><surname>Hwang</surname></persName>
							<email>hwang@korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.93,154.90,63.29,11.96"><forename type="first">Chaeeun</forename><surname>Lee</surname></persName>
							<email>chaeeunlee1997@korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.86,154.90,49.59,11.96"><forename type="first">Minju</forename><surname>Seo</surname></persName>
							<email>minjuseo@korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,389.10,154.90,63.52,11.96"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
							<email>wonjin.yoon@childrens.harvard.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Computational Health Informatics Program</orgName>
								<orgName type="institution">Boston Children&apos;s Hospital</orgName>
								<address>
									<postCode>02115</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Harvard Medical School</orgName>
								<address>
									<postCode>02115</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.10,168.85,63.89,11.96"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
							<email>kangj@korea.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">AIGEN Sciences</orgName>
								<address>
									<postCode>04778</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,350.76,15.42;1,89.29,106.66,321.67,15.42;1,89.29,129.00,212.38,11.96">Exploring Approaches to Answer Biomedical Questions: From Pre-processing to GPT-4 Notebook for the BioASQ Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">D7377EBFDDA6BF350BBFDC53B4F44273</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BioASQ 11b</term>
					<term>BioLinkBERT</term>
					<term>GPT-4</term>
					<term>Data Augmentation</term>
					<term>Ensemble</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Biomedical question answering (QA) plays a crucial role in assisting researchers, healthcare professionals, and even patients in accessing and retrieving accurate and up-to-date information from the vast amount of biomedical knowledge available in literature. To enhance the efficiency of knowledge discovery and information retrieval, we investigate the efficacy of various pre-processing, model training, data augmentation, and ensemble methods and evaluate a range of advanced pre-trained models such as BioLinkBERT and GPT-4. Additionally, we explore data augmentation and ensemble methods to further improve system performance. In our participation in BioASQ Task 11b-Phase B, our systems achieved a top ranking in all four batches for the yes/no type of questions, in one out of four batches for factoid questions, and in two out of four batches for list-type questions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Biomedical question answering (QA) is a pivotal tool, empowering researchers, healthcare professionals, and patients to access accurate, up-to-date information from the vast pool of biomedical knowledge in the literature. The BioASQ challenge <ref type="bibr" coords="1,365.14,490.37,12.69,10.91" target="#b0">[1]</ref> has actively fostered collaborative efforts across the scientific community to push the boundaries of cutting-edge biomedical QA research for over a decade. Yoon et al. <ref type="bibr" coords="1,275.16,517.46,12.70,10.91" target="#b1">[2]</ref> made a significant contribution to the biomedical QA field by utilizing the pre-trained model BioBERT <ref type="bibr" coords="1,320.82,531.01,11.28,10.91" target="#b2">[3]</ref>, instead of traditional word embedding models, in their milestone study. This approach has paved the way for numerous other systems and approaches in this field.</p><p>In this paper, we explore understudied or recently proposed pre-processing techniques, new pre-trained models, training objectives, data augmentation, and ensemble approaches in the BioASQ Task 11b <ref type="bibr" coords="2,189.66,114.06,11.58,10.91" target="#b3">[4]</ref>. We first revisit existing pre-processing methods to analyze what type of question each method is suitable for. We use BioLinkBERT <ref type="bibr" coords="2,396.74,127.61,13.00,10.91" target="#b4">[5]</ref> as a new embedding model in the BioASQ challenge and show that it outperforms existing language models such as BioBERT and PubMedBERT <ref type="bibr" coords="2,230.31,154.71,11.55,10.91" target="#b5">[6]</ref>. We adopt a sequence tagging approach <ref type="bibr" coords="2,428.13,154.71,11.46,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,442.32,154.71,9.02,10.91" target="#b7">8]</ref> to train listtype QA models, which is the first attempt in the challenge. In addition, we investigate the potential performance improvement in BioASQ by employing data augmentation techniques using SQuAD <ref type="bibr" coords="2,155.05,195.36,11.59,10.91" target="#b8">[9]</ref>, a human-labeled factoid dataset consisting of Wikipedia documents, and LIQUID <ref type="bibr" coords="2,127.38,208.91,16.40,10.91" target="#b9">[10]</ref>, an automated framework that generates list-type questions and corresponding answers from PubMed abstracts. We examine whether the utilization of an ensemble method can further optimize the performance. Finally, we evaluate the capability of the state-of-the-art pre-trained model, GPT-4 <ref type="bibr" coords="2,205.37,249.56,16.25,10.91" target="#b10">[11]</ref>, on the list-type questions in a one-shot manner.</p><p>We selected the best combination of approaches from pre-processing to the use of GPT-4, through experiments on the BioASQ-10b dataset <ref type="bibr" coords="2,308.98,276.66,17.96,10.91" target="#b11">[12]</ref> for each question type. We participated in the BioASQ Task 11b-Phase B <ref type="bibr" coords="2,236.90,290.20,17.96,10.91" target="#b12">[13]</ref> to evaluate our systems on the official leaderboard. Our systems delivered remarkable performance across various question types, leading to impressive rankings. In the yes/no type, our systems achieved first place across all four batches, while in the factoid type, we attained the highest rank in one out of four batches. Additionally, we secured the highest rank in two out of four batches for the list type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task Description</head><p>In BioASQ 11B-phase b <ref type="bibr" coords="2,191.10,403.03,16.08,10.91" target="#b12">[13]</ref>, models are required to provide answers to a given question, denoted as ùëû. These answers are inferred from a collection of snippets, represented as ùë† 1 , . . . , ùë† ùêΩ , which are extracted from PubMed abstracts. The format of answers depends on the question types. For this year's competition, we focused only on the following three question types that require exact answers, excluding questions requiring ideal answers.</p><p>Yes/no. For this type of question, the model should answer "yes" or "no" to a question based on the given snippets. An example question of this type is: "Is capmatinib effective for glioblastoma?" Answering yes/no questions often requires considering multiple snippets collectively rather than relying on a single snippet alone.</p><p>Factoid. Factoid-type questions are mainly concerned with the confirmation or summarization of factual information and require a single concise answer (e.g., "Which enzyme does Opicapone inhibit?"). The ground-truth answers are usually, but not always, contained in the snippets, which distinguishes it from other QA tasks such as SQuAD, where answers always can be extracted in a given context <ref type="bibr" coords="2,215.66,609.59,11.43,10.91" target="#b8">[9]</ref>.</p><p>List. The list type requires more than one answer to a single question. An example question is: "What laboratory abnormalities are commonly seen in patients with COVID-19?" Although list-type questions have received less attention in academic research compared to factoidtype questions <ref type="bibr" coords="3,157.65,100.52,16.34,10.91" target="#b13">[14]</ref>, they are frequently encountered in practice, especially in the biomedical domain <ref type="bibr" coords="3,126.02,114.06,11.54,10.91" target="#b7">[8]</ref>. Similar to the factoid type, answers may or may not be extracted from the given snippets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>Our system comprises three models, each specifically designed for a particular question type. To identify the optimal choices for each question, we explore five factors to consider in effectively addressing different types of questions: pre-processing techniques (Section 3.1), QA model selection (Section 3.2), training objectives (Section 3.3), data augmentation approaches (Section 3.4), and the use of ensemble methods (Section 3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pre-processing</head><p>Given that the total length of all ùêΩ snippets might exceed the input length limit of language models, it becomes necessary to select which snippets from the given set should be provided to the model as input. We examine two pre-processing techniques: the "single snippet" method and the "full snippet" method.</p><p>Single snippet. One straightforward approach is to treat each snippet as an individual instance, resulting in multiple question-snippet pairs as follows: (ùëû, ùë† 1 ), . . . , (ùëû, ùë† ùêΩ ). For the factoid and list types, only snippets that contain at least one answer string are utilized as training instances. On the other hand, all snippets are used for training for the yes/no type. Although this approach has been commonly used in previous studies because of its simplicity, treating each snippet as a separate instance can be sub-optimal, particularly for the yes/no type. In answering yes/no questions, it is often necessary that multiple snippets are considered collectively and the information present in one snippet should be considered in conjunction with other pieces of information available in other snippets. Furthermore, this method disregards the opportunity to extract valuable information from other snippets that could potentially aid in predicting correct answers.</p><p>Full snippet. The full-snippet method addresses the limitations of the single-snippet approach by concatenating all snippets together to form a single comprehensive evidence context. In cases where the question-context pair exceeds the input length limitation imposed by the language model, the set of given snippets is partitioned into multiple contexts based on sentence boundaries. In other words, each context is created by concatenating the maximum number of snippets, ensuring that the length limit is not exceeded. Separate contexts created in this manner are then treated as individual instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">QA Model</head><p>BioLinkBERT. BioLinkBERT <ref type="bibr" coords="3,229.75,654.84,12.69,10.91" target="#b4">[5]</ref> is a pre-trained language model trained on PubMed abstracts using a new pre-training objective called document relation prediction, where the model predicts whether two different segments are linked,<ref type="foot" coords="4,284.93,85.21,3.71,7.97" target="#foot_0">1</ref> come from a single document, or are randomly selected from different documents. The model outperformed existing biomedical language models such as PubMedBERT in various downstream tasks. Especially the model achieved an accuracy of 94.8 on yes/no questions in a previous BioASQ challenge dataset <ref type="bibr" coords="4,432.57,127.61,16.25,10.91" target="#b14">[15]</ref>. Inspired by this result, we used a BioLinkBERT-large model as our backbone model. For a given question ùëû and context ùëê that consists of one or multiple snippets, the corresponding token representations are encoded as follows:</p><formula xml:id="formula_0" coords="4,176.93,192.77,325.85,12.32">[h [CLS] , h ùëû 1 , . . . , h ùëû ùëá , h [SEP] , h ùëê 1 , . . . , h ùëê ùêø ] = ùê∏(ùëû, ùëê), (<label>1</label></formula><formula xml:id="formula_1" coords="4,502.78,192.77,3.86,10.91">)</formula><p>where ùê∏ is the BioLinkBERT encoder, h [CLS] ‚àà R ùëë and h [SEP] ‚àà R ùëë are the representations of special tokens <ref type="bibr" coords="4,167.97,230.83,16.41,10.91" target="#b15">[16]</ref>, and ùëá and ùêø are the lengths of the question and context, respectively. The token representations are then fed into task-specific layers, which will be described in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-4.</head><p>Recently, foundation models such as ChatGPT <ref type="bibr" coords="4,336.81,286.68,17.76,10.91" target="#b16">[17]</ref> and GPT-4 <ref type="bibr" coords="4,406.20,286.68,17.76,10.91" target="#b10">[11]</ref> have been utilized in various downstream applications. Notably, they have demonstrated comparable or even superior performance compared to supervised models without fine-tuning. These findings serve as compelling evidence that the models possess the capability to deliver accurate answers to questions even in specialized domains such as biomedicine. In this challenge, we selected Open AI's latest model, GPT-4, as our QA system. <ref type="foot" coords="4,280.64,352.68,3.71,7.97" target="#foot_1">2</ref> Unlike BioLinkBERT, GPT-4 is a black-box model; thus, we cannot access the hidden representation to update the model, and we should query the model using instructions <ref type="bibr" coords="4,199.91,381.53,16.09,10.91" target="#b19">[20]</ref>. We used only a single labeled example to provide the model with more comprehensive information on the task and desired output format (see Table <ref type="table" coords="4,467.38,395.08,5.17,10.91">1</ref> for the input prompt we used).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training Objective</head><p>Binary classification. For the yes/no type, the model is trained using a binary classification objective, where the final hidden representation of the [CLS] token, h [CLS] , is fed to a linear layer. The loss is defined as the sum of the negative log probabilities of the true answer class (i.e., yes or no).</p><p>Span prediction. For the factoid type, the token representations of the context are fed into two different linear layers that calculate logit values for the start and end positions of the answer span as follows:</p><formula xml:id="formula_2" coords="4,89.29,553.10,416.69,28.86">ùëß start ùëê 1 , . . . , ùëß start ùëê ùêø = [w ‚ä§ start h ùëê 1 , . . . , w ‚ä§ start h ùëê ùêø ], ùëß end ùëê 1 , . . . , ùëß end ùëê ùêø = [w ‚ä§ end h ùëê 1 , . . . , w ‚ä§ end h ùëê ùêø ]</formula><p>. These logits are used to calculate probability values for each token, indicating the likelihood of it being the start or end of the answer span. The loss is calculated by summing the negative log probabilities of the start and end positions of the ground-truth answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>The designed prompt for GPT-4 to answer list-type questions. {Test Question} and {Test Context} are substituted by real questions and contexts in test batches.</p><p>Your task is to identify a list of answers to the question in the provided context. To help you understand the task, here is an example: Question: Which acetylcholinesterase inhibitors are used for treatment of myasthenia gravis? Context: Pyridostigmine and neostygmine are acetylcholinesterase inhibitors that are used as first-line therapy for symptomatic treatment of myasthenia gravis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: neostigmine, pyridostigmine</head><p>Now, here is the actual question and context for you to find the appropriate list of answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question: {Test Question}</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context: {Test Context}</head><p>Answer:</p><p>Sequence tagging. One conventional approach to solving list-type QA involves considering the top answer predictions of a single-span QA model that surpasses a pre-defined threshold as final predictions. Recent studies <ref type="bibr" coords="5,230.08,447.79,11.23,10.91" target="#b6">[7,</ref><ref type="bibr" coords="5,243.63,447.79,8.88,10.91" target="#b7">8]</ref> have proposed an alternative approach, treating list QA as a sequence tagging problem, where the model classifies each context token into B (beginning), I (inside), or O (outside) tags, similar to named entity recognition. This approach showed better performance in list QA than existing single-span QA models in a range of general and biomedical QA datasets <ref type="bibr" coords="5,145.47,501.99,16.43,10.91" target="#b13">[14,</ref><ref type="bibr" coords="5,164.62,501.99,12.33,10.91" target="#b9">10]</ref>. Inspired by these results, we adopted this approach to train our list-type QA model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Data Augmentation</head><p>We explored two data augmentation approaches to enhance performance in the factoid and list types. <ref type="foot" coords="5,118.81,577.06,3.71,7.97" target="#foot_2">3</ref>SQuAD. For the factoid type, we followed previous studies that leveraged a large-scale singlespan dataset SQuAD <ref type="bibr" coords="5,181.15,621.12,11.23,10.91" target="#b1">[2,</ref><ref type="bibr" coords="5,194.81,621.12,12.50,10.91" target="#b21">22,</ref><ref type="bibr" coords="5,209.73,621.12,12.50,10.91" target="#b22">23,</ref><ref type="bibr" coords="5,224.66,621.12,12.23,10.91" target="#b23">24]</ref>. While the SQuAD dataset is not specifically designed for the GPT-4 <ref type="bibr" coords="6,258.33,382.73,16.46,8.87" target="#b10">[11]</ref> biomedical domain, it shares a fundamental similarity with the factoid-type QA in BioASQ. Both datasets aim to find accurate answers to factual questions within a provided text. We initially pre-trained our models using SQuAD and subsequently fine-tuned them using the BioASQ data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LIQUID.</head><p>A recent study <ref type="bibr" coords="6,210.90,474.16,18.04,10.91" target="#b9">[10]</ref> proposed a data generation model for list QA, called LIQUID, and made the 140k question-answer pairs produced by the model publicly available. <ref type="foot" coords="6,450.01,485.95,3.71,7.97" target="#foot_3">4</ref> We utilized this synthetic data to pre-train our models, and subsequently, we fine-tuned the models using the BioASQ data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Ensemble</head><p>We used different ensemble techniques for the yes/no, factoid, and list types, respectively.</p><p>Yes/No. We employed majority voting, where predictions from each individual model were aggregated, and the final prediction was determined by the majority prediction.</p><p>Factoid. We use a probability-based ensemble method for factoid-type questions. In this approach, we calculate the sum of probability values for each of the top 20 answers predicted List. We counted the number of answers predicted by single models to a given question based on their string form. For each answer, we calculated an ensemble score as the proportion of how many models out of the total number of models predicted the answer. For instance, suppose that model A, model B, and model C predict {"leprosy, " "cirrhosis, " "cholera"}, {"leprosy, " "COVID-19"}, and {"cirrhosis"}, respectively, then the ensemble scores of each prediction as follows: leprosy (2/3), cirrhosis (2/3), cholera (1/3), and COVID-19 (1/3). If the score is higher than the threshold, we included the predicted answer in the final answer set; otherwise, we excluded it. We searched for the best threshold value using the BioASQ 10b dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setups</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>We used the training and test sets of the BioASQ-10b dataset <ref type="bibr" coords="7,356.05,647.39,17.76,10.91" target="#b11">[12]</ref> as our training and validation set, respectively. Systems were evaluated on BioASQ-11b <ref type="bibr" coords="7,345.85,660.94,16.26,10.91" target="#b24">[25]</ref>, which was newly proposed for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Our Systems</head><p>We selected our final systems through a validation process among various combinations of methods (see Section 5.2 for detailed validation results). Table <ref type="table" coords="8,362.88,493.92,5.00,10.91" target="#tab_2">3</ref> presents the optimal selections for the "single" model for each question type. We searched for the best checkpoints of single models by measuring performance on the validation set every epoch. Ensemble models consisted of different single models that were randomly initialized and then selected through the validation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Official Evaluation on BioASQ-11b</head><p>Tables 4, 5, and 6 show that our best models achieved top scores in many batches. Especially, in the yes/no type, our models achieved the highest scores across all batches, to with full-snippet method contribute significantly. In the factoid type, we achieved the highest score in the last batch. Our factoid QA models basically used a similar model structure and training method, but their performance and rankings were very different from batch to batch. This is because we continuously searched for best single models by randomly initializing them, making us to obtain better single models in batches 3 and 4. In addition, we found that the performance of ensemble models depended on the individual performance of single models rather than the quantity of single models. For instance, by ensembling a small number of high-performing models, we were able to achieve second and first place in batches 3 and 4, respectively.</p><p>In the list type, we achieved first place in two batches using supervised model and GPT-4, respectively. For the supervised model, the full-snippet method, data augmentation using LIQUID, and ensemble were all effective to improve the performance (see Section 5.2 for more results). GPT-4 outperformed our supervised models in batch 4 and achieved the best performance. This is very surprising because our supervised models were ensemble models of several single models trained using thousands of human-labeled BioASQ data and 140k artificial QA data, while GPT-4 used only a single question-answer pair.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,90.49,418.52,46.47"><head>Table 2</head><label>2</label><figDesc>Statistics of the BioASQ-10b (the training and validation sets) and BioASQ-11b (the test batches) datasets.</figDesc><table coords="6,138.15,122.05,228.18,14.90"><row><cell>Type</cell><cell>Number of Questions</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,133.91,139.27,324.97,61.21"><head>Training Validation Batch 1 Batch 2 Batch 3 Batch 4</head><label></label><figDesc></figDesc><table coords="6,133.91,156.75,312.73,43.73"><row><cell>Yes/no</cell><cell>1,148</cell><cell>124</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>14</cell></row><row><cell>Factoid</cell><cell>1,252</cell><cell>166</cell><cell>19</cell><cell>22</cell><cell>26</cell><cell>31</cell></row><row><cell>List</cell><cell>816</cell><cell>85</cell><cell>12</cell><cell>12</cell><cell>18</cell><cell>24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,222.74,416.99,151.74"><head>Table 3</head><label>3</label><figDesc>Model components for each question type. We selected the best options using a validation process on BioASQ-10b.</figDesc><table coords="6,109.15,265.34,374.49,109.13"><row><cell>Type</cell><cell cols="2">Pre-processing QA Model</cell><cell>Training Objective</cell><cell>Data Augment.</cell><cell>Ensemble</cell></row><row><cell>Yes/no</cell><cell>Full snippet</cell><cell>BioLinkBERT [5]</cell><cell>Binary classification</cell><cell></cell></row><row><cell cols="2">Factoid Single snippet</cell><cell>BioLinkBERT [5]</cell><cell>Span prediction</cell><cell>SQuAD [9]</cell></row><row><cell>List</cell><cell>Full snippet</cell><cell>BioLinkBERT [5]</cell><cell>Sequence tagging</cell><cell>LIQUID [10]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,417.17,364.62"><head>Table 4</head><label>4</label><figDesc>Performance (macro F1) on BioASQ-11b in the yes/no type. Numbers in parentheses indicate the number of single models constituting the ensemble model.</figDesc><table coords="7,89.29,134.01,416.69,321.10"><row><cell>Batch</cell><cell>Rank</cell><cell>System</cell><cell cols="2">Macro F1 Description</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-5</cell><cell>0.9515</cell><cell>Single</cell></row><row><cell></cell><cell>7</cell><cell>DMIS-KU-1</cell><cell>0.8571</cell><cell>Ensemble (20)</cell></row><row><cell>Batch 1</cell><cell>7</cell><cell>DMIS-KU-2</cell><cell>0.8571</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>7</cell><cell>DMIS-KU-3</cell><cell>0.8571</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>13</cell><cell>DMIS-KU-4</cell><cell>0.8545</cell><cell>Single</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-4</cell><cell>1.0000</cell><cell>Single</cell></row><row><cell></cell><cell>4</cell><cell>DMIS-KU-1</cell><cell>0.9577</cell><cell>Ensemble (20)</cell></row><row><cell>Batch 2</cell><cell>4</cell><cell>DMIS-KU-2</cell><cell>0.9577</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>4</cell><cell>DMIS-KU-3</cell><cell>0.9577</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>10</cell><cell>DMIS-KU-5</cell><cell>0.9143</cell><cell>Single</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-4</cell><cell>1.0000</cell><cell>Single</cell></row><row><cell></cell><cell>3</cell><cell>DMIS-KU-1</cell><cell>0.9545</cell><cell>Ensemble (20)</cell></row><row><cell>Batch 3</cell><cell>5</cell><cell>DMIS-KU-5</cell><cell>0.9111</cell><cell>Single</cell></row><row><cell></cell><cell>11</cell><cell>DMIS-KU-2</cell><cell>0.8693</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>12</cell><cell>DMIS-KU-3</cell><cell>0.8634</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-1</cell><cell>1.0000</cell><cell>Ensemble (20)</cell></row><row><cell></cell><cell>7</cell><cell>DMIS-KU-2</cell><cell>0.9181</cell><cell>Ensemble (10)</cell></row><row><cell>Batch 4</cell><cell>7</cell><cell>DMIS-KU-5</cell><cell>0.9181</cell><cell>Single</cell></row><row><cell></cell><cell>15</cell><cell>DMIS-KU-3</cell><cell>0.9048</cell><cell>Ensemble (10)</cell></row><row><cell></cell><cell>17</cell><cell>DMIS-KU-4</cell><cell>0.8250</cell><cell>Single</cell></row><row><cell cols="5">by individual models. The top five predictions with the highest summed probabilities are then</cell></row><row><cell cols="2">selected as the final answers.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,88.99,90.49,418.66,351.07"><head>Table 5</head><label>5</label><figDesc>Performance (mean reciprocal rank, i.e., MRR) on BioASQ-11b in the factoid type. Numbers in parentheses indicate the number of single models constituting the ensemble model.</figDesc><table coords="8,89.29,134.01,323.93,307.55"><row><cell>Batch</cell><cell>Rank</cell><cell>System</cell><cell>MRR Description</cell></row><row><cell></cell><cell>4</cell><cell cols="2">DMIS-KU-1 0.5526 Ensemble (10)</cell></row><row><cell></cell><cell>4</cell><cell cols="2">DMIS-KU-2 0.5526 Ensemble (10)</cell></row><row><cell>Batch 1</cell><cell>4</cell><cell cols="2">DMIS-KU-5 0.5526 Ensemble (10)</cell></row><row><cell></cell><cell>7</cell><cell cols="2">DMIS-KU-4 0.5439 Ensemble (20)</cell></row><row><cell></cell><cell>9</cell><cell cols="2">DMIS-KU-3 0.5088 Ensemble (10)</cell></row><row><cell></cell><cell>8</cell><cell cols="2">DMIS-KU-1 0.4773 Ensemble (15)</cell></row><row><cell></cell><cell>11</cell><cell cols="2">DMIS-KU-4 0.4697 Ensemble (10)</cell></row><row><cell>Batch 2</cell><cell>13</cell><cell cols="2">DMIS-KU-3 0.4621 Ensemble (15)</cell></row><row><cell></cell><cell>13</cell><cell cols="2">DMIS-KU-5 0.4621 Ensemble (10)</cell></row><row><cell></cell><cell>15</cell><cell cols="2">DMIS-KU-2 0.4561 Ensemble (20)</cell></row><row><cell></cell><cell>2</cell><cell cols="2">DMIS-KU-1 0.5154 Single</cell></row><row><cell></cell><cell>4</cell><cell cols="2">DMIS-KU-2 0.5077 Ensemble (2)</cell></row><row><cell>Batch 3</cell><cell>6</cell><cell cols="2">DMIS-KU-3 0.4981 Single</cell></row><row><cell></cell><cell>13</cell><cell cols="2">DMIS-KU-5 0.4647 Single</cell></row><row><cell></cell><cell>16</cell><cell cols="2">DMIS-KU-4 0.4500 Ensemble (2)</cell></row><row><cell></cell><cell>1</cell><cell cols="2">DMIS-KU-1 0.7323 Ensemble (4)</cell></row><row><cell></cell><cell>2</cell><cell cols="2">DMIS-KU-2 0.7108 Ensemble (4)</cell></row><row><cell>Batch 4</cell><cell>3</cell><cell cols="2">DMIS-KU-3 0.6882 Single</cell></row><row><cell></cell><cell>4</cell><cell cols="2">DMIS-KU-4 0.6570 Single</cell></row><row><cell></cell><cell>5</cell><cell cols="2">DMIS-KU-5 0.6473 Single</cell></row><row><cell cols="4">the 2023 challenge. The statistics of the datasets are listed in Table 2.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,88.99,90.49,416.99,323.18"><head>Table 6</head><label>6</label><figDesc>Performance (F-measure) on BioASQ-11b in the list type. Numbers in parentheses indicate the number of single models constituting the ensemble model. Please refer to Section 3.5 for a description of threshold values.</figDesc><table coords="9,136.02,143.74,320.76,269.93"><row><cell>Batch</cell><cell>Rank</cell><cell>System</cell><cell cols="2">F-Measure Description</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-3</cell><cell>0.7027</cell><cell>Ensemble (20), threshold: 0.6</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-5</cell><cell>0.7027</cell><cell>Ensemble (20), threshold: 0.7</cell></row><row><cell>Batch 1</cell><cell>3</cell><cell>DMIS-KU-4</cell><cell>0.6992</cell><cell>Ensemble (10), threshold: 0.7</cell></row><row><cell></cell><cell>4</cell><cell>DMIS-KU-2</cell><cell>0.6965</cell><cell>Ensemble (10), threshold: 0.6</cell></row><row><cell></cell><cell>5</cell><cell>DMIS-KU-1</cell><cell>0.6937</cell><cell>Ensemble (10), threshold: 0.6</cell></row><row><cell></cell><cell>6</cell><cell>DMIS-KU-3</cell><cell>0.3178</cell><cell>Ensemble (15), threshold: 0.75</cell></row><row><cell></cell><cell>8</cell><cell>DMIS-KU-2</cell><cell>0.3087</cell><cell>Ensemble (15), threshold: 0.75</cell></row><row><cell>Batch 2</cell><cell>9</cell><cell>DMIS-KU-1</cell><cell>0.3080</cell><cell>Ensemble (10), threshold: 0.6</cell></row><row><cell></cell><cell>10</cell><cell>DMIS-KU-5</cell><cell>0.3022</cell><cell>Ensemble (20), threshold: 0.4</cell></row><row><cell></cell><cell>13</cell><cell>DMIS-KU-4</cell><cell>0.2871</cell><cell>Ensemble (20), threshold: 0.4</cell></row><row><cell></cell><cell>4</cell><cell>DMIS-KU-5</cell><cell>0.5477</cell><cell>Ensemble (15), threshold: 0.75</cell></row><row><cell></cell><cell>5</cell><cell>DMIS-KU-4</cell><cell>0.5466</cell><cell>Ensemble (15), threshold: 0.75</cell></row><row><cell>Batch 3</cell><cell>6</cell><cell>DMIS-KU-3</cell><cell>0.5454</cell><cell>Ensemble (20), threshold: 0.7</cell></row><row><cell></cell><cell>7</cell><cell>DMIS-KU-2</cell><cell>0.5437</cell><cell>Ensemble (20), threshold: 0.6</cell></row><row><cell></cell><cell>8</cell><cell>DMIS-KU-1</cell><cell>0.5341</cell><cell>Ensemble (10), threshold: 0.6</cell></row><row><cell></cell><cell>1</cell><cell>DMIS-KU-1</cell><cell>0.7440</cell><cell>GPT-4</cell></row><row><cell></cell><cell>4</cell><cell>DMIS-KU-2</cell><cell>0.6806</cell><cell>Ensemble (20), threshold: 0.6</cell></row><row><cell>Batch 4</cell><cell>5</cell><cell>DMIS-KU-5</cell><cell>0.6787</cell><cell>Ensemble (15), threshold: 0.75</cell></row><row><cell></cell><cell>6</cell><cell>DMIS-KU-3</cell><cell>0.6752</cell><cell>Ensemble (20), threshold: 0.7</cell></row><row><cell></cell><cell>7</cell><cell>DMIS-KU-4</cell><cell>0.6747</cell><cell>Ensemble (15), threshold: 0.75</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,92.57,638.14,117.01,8.97"><p>Citation information were used.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,92.57,649.10,413.41,8.97;4,92.57,660.06,413.68,8.97;4,92.57,671.02,269.07,8.97"><p>Note that we used GPT-4 only in the list type because the model did not outperform supervised models for the yes/no and factoid types in our initial experiments on BioASQ-10b. Please see concurrent works for results of GPT models in yes/no and factoid questions in the biomedical domain<ref type="bibr" coords="4,332.39,671.02,13.50,8.97" target="#b17">[18,</ref><ref type="bibr" coords="4,348.14,671.02,10.13,8.97" target="#b18">19]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,92.57,649.11,413.41,8.97;5,92.57,660.07,413.42,8.97;5,92.57,671.03,340.88,8.97"><p>Due to the high performance of our models in initial experiments, we did not extensively investigate a data augmentation approach for the yes/no question type. However, it would be interesting to investigate the impact and transferability of existing yes/no QA datasets such as PubMedQA<ref type="bibr" coords="5,349.53,671.03,14.72,8.97" target="#b20">[21]</ref> in future research.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,92.57,671.04,133.86,8.97"><p>https://github.com/dmis-lab/LIQUID</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by (1) <rs type="funder">National Research Foundation of Korea</rs> (<rs type="grantNumber">NRF-2023R1A2C3004176</rs>), (2) the <rs type="funder">MSIT (Ministry of Science and ICT), Korea</rs>, under the <rs type="programName">ICT Creative Consilience program</rs> (<rs type="grantNumber">IITP-2023-2020-0-01819</rs>) supervised by the <rs type="funder">IITP</rs> (<rs type="programName">Institute for Information &amp; communications Technology Planning &amp; Evaluation</rs>), and (3) a grant of the <rs type="funder">Korea Health Technology R&amp;D</rs> Project through the <rs type="funder">Korea Health Industry Development Institute (KHIDI)</rs>, funded by the <rs type="funder">Ministry of Health &amp; Welfare, Republic of Korea</rs> (grant number: <rs type="grantNumber">HR20C0021(3</rs>)).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jeYs75f">
					<idno type="grant-number">NRF-2023R1A2C3004176</idno>
				</org>
				<org type="funding" xml:id="_Fv7DZQW">
					<idno type="grant-number">IITP-2023-2020-0-01819</idno>
					<orgName type="program" subtype="full">ICT Creative Consilience program</orgName>
				</org>
				<org type="funding" xml:id="_B9qYuTM">
					<orgName type="program" subtype="full">Institute for Information &amp; communications Technology Planning &amp; Evaluation</orgName>
				</org>
				<org type="funding" xml:id="_KMWfZUx">
					<idno type="grant-number">HR20C0021(3</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 7</head><p>Ablation study of pre-processing methods. See Section 3.1 for detailed descriptions of the single-snippet and full-snippet approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Yes/no Factoid List</head><p>Single snippet 0.9347 0.5132 0.4773 Full snippet 0.9815 0.4762 0.5373</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 8</head><p>Comparision of pre-trained language models. Note that the performance was measured using macro F1 and mean reciprocal rank for the yes/no and factoid types, respectively. Ablation study of data augmentation methods. Note that SQuAD and the synthetic dataset generated by LIQUID <ref type="bibr" coords="10,136.67,357.48,16.46,8.87" target="#b9">[10]</ref> were used as augmenting data for the factoid and list types, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Factoid List</head><p>BioASQ 0.5132 0.5373 + Augment. 0.5294 (+ 0.0162) 0.5731 (+ 0.0358)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation Study on BioASQ-10b</head><p>Effect of pre-processing. Table <ref type="table" coords="10,245.09,462.62,5.00,10.91">7</ref> shows that the effect of the pre-processing method varied depending on the type of question. In the case of yes/no and list question types, the full-snippet approach outperformed the single-snippet method. This is because both question types require a comprehensive understanding of the context to provide accurate answers. However, for the factoid question type, the single-snippet method was found to be more suitable. We speculate that the single-snippet method was effective because most factoid questions can be answered with only the surrounding context of the answer without much additional context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language model selection.</head><p>To find the best-performing encoder on the BioASQ data, we tested several variants of common pre-trained language models in the biomedical domain: BioBERT <ref type="bibr" coords="10,131.88,599.78,11.36,10.91" target="#b2">[3]</ref>, PubMedBERT <ref type="bibr" coords="10,213.93,599.78,11.35,10.91" target="#b5">[6]</ref>, and BioLinkBERT <ref type="bibr" coords="10,313.35,599.78,11.35,10.91" target="#b4">[5]</ref>. As shown in Table <ref type="table" coords="10,416.06,599.78,3.70,10.91">8</ref>, BioLinkBERT was slightly better than PubMedBERT with the same size (110M parameters), and the BioLinkBERTlarge model significantly outperformed the base-sized models.</p><p>Effect of data augmentation. Table <ref type="table" coords="10,270.60,655.63,5.16,10.91">9</ref> shows that augmenting the SQuAD data improves performance on the factoid questions, which is consistent with previous studies <ref type="bibr" coords="10,446.64,669.18,11.36,10.91" target="#b1">[2,</ref><ref type="bibr" coords="10,460.71,669.18,12.55,10.91" target="#b21">22,</ref><ref type="bibr" coords="10,475.98,669.18,12.55,10.91" target="#b22">23,</ref><ref type="bibr" coords="10,491.24,669.18,12.32,10.91" target="#b23">24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 10</head><p>Validation performance of single and ensemble models for the three question types. "Best Single" indicates the highest performance among the single models that constitute the ensemble model. The performance is measured based on Macro F1 scores for the yes/no type, mean reciprocal rank for the factoid type, and F-measures for the list type. In addition, the LIQUID data significantly improved the model performance on the list type, which is consistent with Lee et al. <ref type="bibr" coords="11,242.53,248.44,16.25,10.91" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type</head><p>Effect of ensemble. Table <ref type="table" coords="11,218.39,277.20,9.94,10.91">10</ref> shows validation results for the three question types, highlighting improvements in performance attained through ensembling of multiple models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This study focused on conducting comprehensive experiments, encompassing a range of preprocessing techniques and the utilization of advanced models such as BioLinkBERT and GPT-4.</p><p>In addition, we delved into the exploration of data augmentation and ensemble methods, further refining the performance of our QA system. Our models achieved high performance in BioASQ task 11b -phase B. We hope that our findings and analysis will contribute towards enhancing the performance of biomedical QA systems, ultimately maximizing knowledge discovery and information retrieval efficiency.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,615.66,395.17,10.91;11,112.66,629.21,393.32,10.91;11,112.66,642.76,393.33,10.91;11,112.66,656.31,133.29,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,387.50,629.21,118.48,10.91;11,112.66,642.76,358.40,10.91">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,482.92,642.76,23.07,10.91;11,112.66,656.31,64.57,10.91">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,86.97,393.33,10.91;12,112.66,100.52,393.33,10.91;12,112.66,114.06,232.59,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,310.77,86.97,195.22,10.91;12,112.66,100.52,83.70,10.91">Pre-trained language model for biomedical question answering</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,219.53,100.52,286.45,10.91;12,112.66,114.06,101.82,10.91">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="727" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,127.61,393.33,10.91;12,112.66,141.16,394.53,10.91;12,112.41,154.71,390.52,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,361.64,127.61,144.35,10.91;12,112.66,141.16,251.54,10.91">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<ptr target="https://academic.oup.com/bioinformatics/article-abstract/36/4/1234/5566506" />
	</analytic>
	<monogr>
		<title level="j" coord="12,372.87,141.16,64.30,10.91">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,168.26,394.53,10.91;12,112.66,181.81,393.33,10.91;12,112.66,195.36,393.33,10.91;12,112.66,208.91,393.33,10.91;12,112.66,222.46,306.11,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,234.48,181.81,271.51,10.91;12,112.66,195.36,307.20,10.91">Overview of BioASQ 2023: The eleventh BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lima-L√≥pez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Farr√©-Maduell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,445.02,195.36,60.97,10.91;12,112.66,208.91,393.33,10.91;12,112.66,222.46,252.02,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<meeting>the Fourteenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="12,112.66,236.01,395.17,10.91;12,112.66,249.56,395.17,10.91;12,112.66,263.11,394.53,10.91;12,112.66,276.66,395.01,10.91;12,112.66,290.20,191.55,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,273.58,236.01,234.25,10.91;12,112.66,249.56,46.55,10.91">LinkBERT: Pretraining language models with document links</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.551</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.551.doi:10.18653/v1/2022.acl-long.551" />
	</analytic>
	<monogr>
		<title level="m" coord="12,182.78,249.56,325.05,10.91;12,112.66,263.11,85.65,10.91">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8003" to="8016" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="12,112.66,303.75,394.53,10.91;12,112.66,317.30,394.53,10.91;12,112.28,330.85,338.80,10.91" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,112.66,317.30,390.01,10.91">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<idno>ArXiv preprint abs/2007.15779</idno>
		<ptr target="https://arxiv.org/abs/2007.15779" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,344.40,393.54,10.91;12,112.66,357.95,393.33,10.91;12,112.66,371.50,395.17,10.91;12,112.66,385.05,395.01,10.91;12,112.66,398.60,203.42,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,359.47,344.40,146.72,10.91;12,112.66,357.95,143.73,10.91">A simple and effective model for answering multi-span questions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shoham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.248</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.248.doi:10.18653/v1/2020.emnlp-main.248" />
	</analytic>
	<monogr>
		<title level="m" coord="12,281.26,357.95,224.73,10.91;12,112.66,371.50,395.17,10.91;12,112.66,385.05,31.75,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3074" to="3080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,412.15,393.33,10.91;12,112.66,425.70,253.44,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,310.57,412.15,195.42,10.91;12,112.66,425.70,84.94,10.91">Sequence tagging for biomedical extractive question answering</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lagerberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,206.41,425.70,65.61,10.91">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="3794" to="3801" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,439.25,395.17,10.91;12,112.66,452.79,393.33,10.91;12,112.66,466.34,395.00,10.91;12,112.66,479.89,372.19,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,306.85,439.25,200.98,10.91;12,112.66,452.79,76.67,10.91">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
		<ptr target="https://aclanthology.org/D16-1264.doi:10.18653/v1/D16-1264" />
	</analytic>
	<monogr>
		<title level="m" coord="12,209.84,452.79,296.15,10.91;12,112.66,466.34,284.29,10.91">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,493.44,394.53,10.91;12,112.66,506.99,173.79,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,213.59,493.44,289.11,10.91">Liquid: A framework for list question answering dataset generation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.01691</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,112.66,520.54,395.01,10.91;12,112.66,534.09,27.76,10.91" xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2303.08774" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct coords="12,112.66,547.64,394.53,10.91;12,112.66,561.19,395.17,10.91;12,112.66,574.74,393.33,10.91;12,112.66,588.29,395.01,10.91;12,112.66,601.84,38.81,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,235.51,561.19,272.32,10.91;12,112.66,574.74,259.92,10.91">Overview of bioasq 2022: the tenth bioasq challenge on largescale biomedical semantic indexing and question answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vandorou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Miranda-Escalada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,395.77,574.74,110.22,10.91;12,112.66,588.29,301.62,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="337" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,615.39,393.32,10.91;12,112.66,628.93,393.33,10.91;12,112.66,642.48,107.76,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,349.27,615.39,156.72,10.91;12,112.66,628.93,104.82,10.91">Overview of BioASQ Tasks 11b and Synergy11 in CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,241.61,628.93,264.38,10.91;12,112.66,642.48,77.06,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,656.03,393.33,10.91;12,112.66,669.58,393.33,10.91;13,112.66,86.97,394.53,10.91;13,112.28,100.52,395.00,10.91;13,112.66,114.06,394.97,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,323.62,656.03,182.36,10.91;12,112.66,669.58,87.56,10.91">MultiSpanQA: A dataset for multi-span question answering</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tomko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vasardani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.90</idno>
		<ptr target="https://aclanthology.org/2022.naacl-main.90.doi:10.18653/v1/2022.naacl-main.90" />
	</analytic>
	<monogr>
		<title level="m" coord="12,229.76,669.58,276.22,10.91;13,112.66,86.97,394.53,10.91;13,112.28,100.52,181.16,10.91">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1250" to="1260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,127.61,393.33,10.91;13,112.66,141.16,394.62,10.91;13,112.66,154.71,394.53,10.91;13,112.66,168.26,240.72,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,368.54,127.61,137.44,10.91;13,112.66,141.16,102.27,10.91">Results of the seventh edition of the bioasq challenge</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,239.05,141.16,268.22,10.91;13,112.66,154.71,208.74,10.91">Machine Learning and Knowledge Discovery in Databases: International Workshops of ECML PKDD 2019</title>
		<meeting><address><addrLine>W√ºrzburg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">September 16-20, 2019. 2020</date>
			<biblScope unit="page" from="553" to="568" />
		</imprint>
	</monogr>
	<note>Part II</note>
</biblStruct>

<biblStruct coords="13,112.66,181.81,393.33,10.91;13,112.66,195.36,393.33,10.91;13,112.66,208.91,393.32,10.91;13,112.66,222.46,393.33,10.91;13,112.66,236.01,394.03,10.91;13,112.66,249.56,185.51,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,323.15,181.81,182.83,10.91;13,112.66,195.36,186.91,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423.doi:10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="13,327.87,195.36,178.11,10.91;13,112.66,208.91,393.32,10.91;13,112.66,222.46,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="13,112.66,263.11,325.82,10.91" xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/chatgpt" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Chatgpt blog post</note>
</biblStruct>

<biblStruct coords="13,112.66,276.66,393.70,10.91;13,112.66,290.20,393.33,10.91;13,112.66,303.75,393.53,10.91;13,112.66,317.30,395.01,10.91;13,112.66,330.85,93.72,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,303.02,276.66,203.34,10.91;13,112.66,290.20,278.90,10.91">Evaluation of ChatGPT on biomedical tasks: A zero-shot comparison with fine-tuned generative transformers</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Jahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T R</forename><surname>Laskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2023.bionlp-1.30" />
	</analytic>
	<monogr>
		<title level="m" coord="13,414.86,290.20,91.13,10.91;13,112.66,303.75,393.53,10.91;13,112.66,317.30,113.98,10.91">The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="326" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,344.40,395.17,10.91;13,112.66,357.95,393.33,10.91;13,112.33,371.50,29.19,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ateia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.16108</idno>
		<title level="m" coord="13,228.64,344.40,279.20,10.91;13,112.66,357.95,236.28,10.91">Is chatgpt a biomedical expert?-exploring the zero-shot performance of current gpt models in biomedical tasks</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,385.05,394.53,10.91;13,112.66,398.60,393.32,10.91;13,112.66,412.15,266.90,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,274.48,398.60,169.72,10.91">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,452.29,398.60,53.69,10.91;13,112.66,412.15,172.82,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,425.70,393.33,10.91;13,112.66,439.25,393.33,10.91;13,112.66,452.79,393.33,10.91;13,112.66,466.34,393.33,10.91;13,112.66,479.89,394.51,10.91;13,112.36,495.87,68.18,7.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,303.68,425.70,202.31,10.91;13,112.66,439.25,87.85,10.91">PubMedQA: A dataset for biomedical research question answering</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1259</idno>
		<ptr target="https://aclanthology.org/D19-1259.doi:10.18653/v1/D19-1259" />
	</analytic>
	<monogr>
		<title level="m" coord="13,231.73,439.25,274.25,10.91;13,112.66,452.79,393.33,10.91;13,112.66,466.34,361.86,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2567" to="2577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,506.99,395.17,10.91;13,112.66,520.54,394.52,10.91;13,112.66,534.09,47.34,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,259.17,506.99,248.66,10.91;13,112.66,520.54,269.94,10.91">Exploring biomedical question answering with biomtransformers at bioasq10b challenge: Findings and techniques</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alrowili</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Vijay-Shanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,391.13,520.54,74.67,10.91">CEUR Workshop</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,547.64,393.54,10.91;13,112.66,561.19,276.89,10.91" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kaddari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bouchentouf</surname></persName>
		</author>
		<title level="m" coord="13,267.78,547.64,238.42,10.91;13,112.66,561.19,244.97,10.91">Larsa at bioasq 10b: classical and novel approaches for biomedical document retrieval and question answering</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,574.74,393.33,10.91;13,112.66,588.29,393.33,10.91;13,112.33,601.84,29.19,10.91" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="13,314.08,574.74,191.91,10.91;13,112.66,588.29,393.33,10.91">Ncu-iisr/as-gis: Using bertscore and snippet score to improve the performance of pretrained language model in bioasq 10b phase b</title>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-H</forename><surname>Tsai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,615.39,393.32,10.91;13,112.66,628.93,326.44,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,357.16,615.39,148.82,10.91;13,112.66,628.93,189.95,10.91">BioASQ-QA: A manually curated corpus for Biomedical Question Answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,311.68,628.93,64.68,10.91">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
