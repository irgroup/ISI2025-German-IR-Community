<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,413.00,15.39;1,89.29,106.97,194.50,15.39;1,283.79,103.93,6.25,10.68">Deep Metric Learning for Effective Passage Retrieval in the BioASQ Challenge ‚ãÜ</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,137.48,106.34,10.68"><forename type="first">Andr√©s</forename><surname>Rosso-Mateus</surname></persName>
							<email>andresr@keoworld.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Keo World</orgName>
								<address>
									<settlement>Miami</settlement>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,220.01,137.48,106.60,10.68"><forename type="first">Le√≥n</forename><forename type="middle">A</forename><surname>Mu√±oz-Serna</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Keo World</orgName>
								<address>
									<settlement>Bogot√°</settlement>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.72,137.48,124.44,10.68"><forename type="first">Manuel</forename><surname>Montes-Y-G√≥mez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">LabTL</orgName>
								<orgName type="institution">INAOE</orgName>
								<address>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,151.42,88.13,10.68"><forename type="first">Fabio</forename><forename type="middle">A</forename><surname>Gonz√°lez</surname></persName>
							<email>fagonzalezo@unal.edu.co</email>
							<affiliation key="aff3">
								<orgName type="laboratory">MindLab</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<settlement>Bogot√°</settlement>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,413.00,15.39;1,89.29,106.97,194.50,15.39;1,283.79,103.93,6.25,10.68">Deep Metric Learning for Effective Passage Retrieval in the BioASQ Challenge ‚ãÜ</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">0827B71821F2DBEC792F7E8220D39BB6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Metric Learning</term>
					<term>BioASQ</term>
					<term>Passage Retrieval</term>
					<term>Question Answering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in BioASQ 2023 Challenge for task 11b phase A, document retrieval and snippet retrieval. For document retrieval we have used BM25 scoring function and semantic-similarity as a re-ranking strategy, for passage retrieval our approach makes use of a metric learning method adapted for NLP. Most of the metric learning approaches learn to embed samples in a latent space where a metric (usually Euclidean) captures relationships between samples. The proposed approach directly learns the metric by fusing different similarity measures through a siamese convolutional network. We also present a sampling strategy that selects challenging training samples which leads to an increase in the accuracy of the model. The method is particularly well suited for domain-specific passage retrieval where it is very important to take into account different sources of information. Our approach reached the second position for snippet retrieval task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the biomedical domain, the continuous growth of published documents poses challenges for researchers seeking relevant information. To address this issue, Question Answering (QA) systems have gained attention as they provide concise and natural retrieval of information, offering precise answers and supporting passages. The interest in developing QA systems for the biomedical domain has been increasing <ref type="bibr" coords="1,292.21,511.04,11.59,9.74" target="#b0">[1]</ref>, as evidenced by the growing research and recognition of their potential in improving closed domain information access, representing the next evolution in information retrieval systems. In this paper we are going to describe the methods used for BioASQ 11 challenge phase A (document and passage retrieval) <ref type="bibr" coords="1,443.98,551.68,11.28,9.74" target="#b1">[2]</ref>, but giving focus in the passage retrieval task where a Deep Metric Learning method has been used to solve the related task.</p><p>Metric learning has been broadly used in face identification and other image processing tasks <ref type="bibr" coords="2,89.29,128.74,11.23,9.74" target="#b2">[3,</ref><ref type="bibr" coords="2,102.58,128.74,7.49,9.74" target="#b3">4]</ref>. This approach has a powerful and simple mathematical formulation that allows to produce a compact representation in a metric space that can be used to identify image correspondences. The same idea can be applied to the passage retrieval task where answer passages should share semantic patterns with the question and this can be measured by a metric in an appropriate metric space. This idea has not been explored in depth in the context of passage retrieval, except for the work of <ref type="bibr" coords="2,158.11,196.48,11.28,9.74" target="#b4">[5]</ref>, where a siamese network was used for learning a metric between questions and candidate answers in an open-domain question answering task on a proprietary dataset.</p><p>Our deep metric learning method fuses different similarity measures through a siamese convolutional architecture. The proposed approach learns a metric between questions and passages, bringing semantically related pairs closer together. A sampling strategy is also presented to select both easy and hard negative samples during training, improving model performance.</p><p>The architecture combines aspects of triplet networks and siamese architectures but incorporates multiple question-passage internal similarity measures to capture important semantic features. This provides a complementary view of the relatedness between questions and passages, including structured information that is often available in domain-specific problems.</p><p>The proposed model reached the second position in passage retrieval in all batches even though the document retrieval approach was not very competitive.</p><p>The training dataset used along the whole process is the one suggested for the challenge committee <ref type="bibr" coords="2,139.10,386.17,11.43,9.74" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Overall System Description</head><p>Our approach consists of two main components: the document retrieval and the passage retrieval modules, as shown in Figure <ref type="figure" coords="2,218.90,458.35,3.74,9.74" target="#fig_0">1</ref>.</p><p>The model implementation is publicly available in Github 1 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Document re-ranking</head><p>To address the issue of imprecise results from ES (Elasticsearch), a re-ranking strategy is implemented in a second stage. This re-ranker utilizes a pre-trained cross-encoder <ref type="bibr" coords="3,455.81,414.89,12.77,9.74" target="#b6">[7]</ref> to score the relevancy of all document candidates for a specific query. The re-ranking process selects the top-n documents that exhibit stronger semantic relevance to the query, leveraging the cosine distance in the embedding space. This process is illustrated in Figure <ref type="figure" coords="3,398.37,455.54,3.74,9.74" target="#fig_1">2</ref>. To represent question and document we have used the pre-trained large language model (SBERT) <ref type="bibr" coords="4,128.58,101.64,12.79,9.74" target="#b6">[7]</ref> that has been fine-tuned using a siamese network structure to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity.</p><p>The selected subset of related documents is further analyzed to identify snippets of text that contain the answers to the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Passage Retrieval: A Deep Metric Learning Approach</head><p>A deep metric learning model is trained for this task, creating a metric space where question and passage pairs that are highly related are located close together. This allows for the ranking and exclusion of question-answer passages based on their similarity in the metric space.</p><p>Unlike traditional metric learning methods <ref type="bibr" coords="4,294.37,232.66,11.39,9.74" target="#b2">[3,</ref><ref type="bibr" coords="4,308.47,232.66,7.59,9.74" target="#b3">4]</ref>, which aim to learn embedding spaces for individual samples, our approach focuses on learning a joint question-passage embedding that captures the relationship between pairs. A detailed description of the proposed architecture will be provided in the subsequent section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Deep Metric Learning Model Architecture</head><p>The model architecture, depicted in Figure <ref type="figure" coords="4,280.89,322.64,3.74,9.74" target="#fig_2">3</ref>, works over three text sequences: the question, a positive passage that answers the question, and a negative passage that does not contain a valid answer.</p><p>The first step involves calculating the relatedness between the question and passages using various term-level question-passage similarity measures. These measures are represented as matrices for the positive (ùëû, ùëù + ) and negative (ùëû, ùëù -) pairs. These matrices are then fed into a siamese convolutional model, which identifies internal patterns in the question-passage interactions. These patterns are utilized to compute a measure of semantic relatedness, denoted as ùëëùëñùë† (ùëû,ùëù + ) and ùëëùëñùë† (ùëû,ùëù -) for the positive and negative pairs, respectively.</p><p>The model is trained by minimizing the loss function defined in Equation <ref type="formula" coords="4,447.77,458.13,3.81,9.74" target="#formula_0">1</ref>, where the distances for positive pairs are encouraged to be close to zero, while negative pairs should have a distance greater than a margin ùõº. The batch size is denoted as ùëÅ.</p><formula xml:id="formula_0" coords="4,226.63,517.79,280.01,32.31">1 ùëÅ ùëÅ ‚àë ùëñ [ùëëùëñùë†(ùëû, ùëù + ) -ùëëùëñùë†(ùëû, ùëù -) + ùõº]<label>(1)</label></formula><p>The two main blocks of this model, the input layer and convolutional layer, are described in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Input layer: Similarity Measures Calculation</head><p>The input training samples consist of a question and two passages, one positive and one negative. To represent a question-passage pair, internal semantic interactions are analyzed using three different similarity measures: 1) word embedding with cosine similarity, 2) term co-occurrence, and 3) concept co-occurrence. These measures were introduced in a previous work <ref type="bibr" coords="4,460.35,664.08,11.42,9.74" target="#b7">[8]</ref>, where the interactions are captured through three similarity matrices. These matrices compare each term in the question (ùëû ùëñ ) with each term in the candidate passage (ùëù ùëó ). Below is a brief description of those matrices.</p><p>Cosine similarity: it captures the relatedness of terms using the BioNLP pre-trained word embeddings and measuring their cosine similarity.</p><p>Term and concept co-occurrence measures: in order to capture statistical term by term and biomedical concepts coincidences at sentence level we pre-calculated co-occurrences matrices using the abstracts from BioASQ training data sentences. Our conceptual database is built using UMLS Meta-thesaurus<ref type="foot" coords="5,188.91,530.56,4.06,7.79" target="#foot_1">3</ref> , QuickUMLS tool <ref type="bibr" coords="5,275.50,533.24,12.84,9.74" target="#b8">[9]</ref> as well as Scispacy tool <ref type="bibr" coords="5,397.39,533.24,16.25,9.74" target="#b9">[10]</ref>.</p><p>To visualize the information captured with the three similarity matrices and to emphasize their complementariness, Figure <ref type="figure" coords="5,232.17,560.34,4.97,9.74" target="#fig_4">4</ref> shows some heat maps that indicate the different interactions between a question and a related passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q: Does echinacea increase anaphylaxis risk?</head><p>A: Risk of anaphylaxis in complementary and alternative medicine.</p><p>In the provided example, the concept similarity matrix demonstrates higher semantic similarity values for the question term 'echinacea' and its related answer passages, such as 'complementary', 'alternative', 'medicine', and 'anaphylaxis', indicating significant relationships. The cosine similarity also yields higher values for the question term 'increase' and its corresponding row. Term co-occurrence exhibits similar behavior to concept co-occurrence, but the latter places more emphasis on important terms. In this specific example, concept co-occurrence proves to be the more informative modality, highlighting a significant relationship between 'echinacea' and the terms 'anaphylaxis', 'alternative', and 'medicine'. This relationship suggests that echinacea is associated with adverse anaphylaxis allergic reactions, as documented in the medical literature.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Convolutional Neural Layer</head><p>The result of the question-passage similarity calculation is a tensor with three similarity channels. This tensor is similar to the multi-channel representation used in images. The model being proposed has a siamese architecture with shared weights, where each subnet processes a pair of negative or positive input samples. The output of each subnet provides an estimation of the distance for the corresponding input pair, as is depicted in Figure <ref type="figure" coords="6,381.82,502.85,3.74,9.74" target="#fig_5">5</ref>. The first layer of each subnet is composed of 256 3x3 convolutional with a Relu activation function serving as a feature extraction component. The extracted patterns are subsequently condensed by a global max-pooling layer, which connects to a fully connected layer comprising 128 units with Relu activation. Finally, the estimated distance measure is produced by a sigmoid unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4.">Informative Negative Passage Identification</head><p>In deep metric learning, selecting informative training samples is crucial. Previous works have emphasized this importance <ref type="bibr" coords="7,219.54,178.07,16.56,9.74" target="#b10">[11,</ref><ref type="bibr" coords="7,238.84,178.07,12.42,9.74" target="#b11">12]</ref>. Our approach focuses on discriminating hard negative samples based on the semantic relatedness of question and passage pairs, utilizing cosine similarity over BiosentVec sentence embeddings <ref type="bibr" coords="7,310.64,205.16,16.40,9.74" target="#b12">[13]</ref>. . During training, we first provide the model with easy negative samples and then introduce more challenging hard negative samples. The process of filtering these samples involves representing them in an embedded space using BioSentVec embeddings <ref type="bibr" coords="7,201.11,245.81,16.42,9.74" target="#b12">[13]</ref>, calculating the similarity between question and passage pairs, estimating the densities for positive and negative samples; refer to Figure <ref type="figure" coords="7,422.88,259.36,3.79,9.74" target="#fig_6">6</ref>, and filtering the hard negative samples based on the likelihood of being positive, we determined whether it is hard or easy by comparing ùëù(ùë• ‚àà ùëùùëúùë†ùëñùë°ùëñùë£ùëí) against ùëù(ùë• ‚àà ùëõùëíùëîùëéùë°ùëñùë£ùëí). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>To validate the performance for document retrieval and passage retrieval approaches, we have used the test dataset of BioASQ 10 version. We report results averaging official metrics over the 5 batches of the related dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Document Retrieval Results and Discussion</head><p>The averaged results over the five 10b batches are presented in Table <ref type="table" coords="7,396.29,584.70,3.71,9.74" target="#tab_0">1</ref>. We present the results for BM25 method and the comparison with the same method but using the described semanticsimilarity re-ranking approach which has a slightly better performance over the BM25 initial document set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Passage Retrieval Results</head><p>The results of the passage retrieval task largely depend on the performance obtained in the document retrieval stage. To validate the performance of the proposed Deep Metric Learning for passage retrieval (DMLPR), we used in all experiments the same set of documents and then compare the results against the following baseline methods.</p><p>We have used three different baseline models for comparison in this paper. The first model is the (Bert fine-tuned model), pre-trained on biomedical texts, and fine-tuned for questionanswering tasks using BioASQ dataset <ref type="bibr" coords="8,260.70,278.84,16.15,9.74" target="#b13">[14]</ref>. The second model is a (Siamese model) that uses BioNLP word embeddings <ref type="foot" coords="8,210.25,289.71,4.06,7.79" target="#foot_2">4</ref> to represent the question and passage <ref type="bibr" coords="8,390.79,292.39,16.40,9.74" target="#b14">[15]</ref>. The third model is a conventional (Triplet loss w2v-rep) that also uses BioNLP word embeddings to represent the input sequences <ref type="bibr" coords="8,162.43,319.49,11.30,9.74" target="#b2">[3]</ref>. The fourth model combines a conventional triplet network with the multisimilarity representation (Triplet loss sim-rep), here we use tensors to represent similarities between question-answer pairs. These models were employed to explore and compare their performance against the proposed deep metric learning approach (DMLPR).</p><p>Table <ref type="table" coords="8,128.75,387.23,5.17,9.74" target="#tab_1">2</ref> presents the obtained results. The proposed method outperformed all baseline methods according to the averaged MAP score. With respect to the (Triplet loss sim-rep) an improvement of 10% was observed. It is important to mention that using multiple similarities as input yielded significantly better results compared to using non-interacting sequences, surpassing the (Siamese model) and (Triplet loss w2v-rep) by approximately 65%. The Bert model has moderate performance scores, and the margin concerning the proposed model is wide. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>The proposed method demonstrated a significant improvement over baseline methods. The success of the proposed model can be attributed to several factors. Firstly, the representation based on three similarity matrices proved to be much more effective in capturing the semantic relatedness between question and answer sequences compared to using independent representations. This differs from most current works that solely rely on learned text representations, incorporating domain knowledge in the form of important concepts and calculating a complementary similarity enhances the question-passage Additionally, the combination of a metric learning approach with a CNN applied to text-similarity matrices was a distinctive feature of this work. The results demonstrated that this approach successfully captured the interactions between questions and passages. This strategy is not commonly employed in passage retrieval methods, and the study showcased its highly positive impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The paper makes use of a deep-metric learning approach for biomedical passage retrieval that outperforms baseline methods over BioASQ dataset. The model incorporates a multisimilarity representation, a convolutional neural network (CNN), and a siamese design. The training strategy involves identifying hard and easy negative samples to enhance the model's performance. The results indicate promising outcomes, leading to future research exploring alternative methods to integrate structured knowledge sources and different forms of metric learning approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,342.15,141.69,8.91;3,127.56,84.19,340.16,245.43"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: BioASQ Model Diagram</figDesc><graphic coords="3,127.56,84.19,340.16,245.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,662.78,212.99,8.91;3,212.60,477.15,170.09,173.10"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Semantic search for document re-ranking</figDesc><graphic coords="3,212.60,477.15,170.09,173.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.29,362.32,416.70,8.91;5,89.29,374.27,416.69,8.91;5,89.29,386.23,339.98,8.91;5,141.73,84.19,311.84,270.65"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overall model architecture; the input is composed of a question and a positive and negative passage, it includes a convolutional layer and a loss function that compares the distances between the positive and negative pairs. W means that the CNN sub-model weights are shared.</figDesc><graphic coords="5,141.73,84.19,311.84,270.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,115.26,354.06,109.45,8.90;6,244.33,354.06,106.31,8.90;6,378.57,354.06,92.83,8.90"><head></head><label></label><figDesc>(a) cosine similarity matrix (b) concept co-occ. matrix (c) term co-occ. matrix</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,89.29,370.70,417.79,8.91;6,89.29,382.65,227.20,8.91;6,107.63,227.23,137.51,118.94"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of the similarity matrices for a given question (rows) and passage (columns), aiming to visualize the sequence's internal interactions.</figDesc><graphic coords="6,107.63,227.23,137.51,118.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,89.29,628.46,407.32,8.91;6,89.29,522.49,439.38,93.44"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Convolutional model used in siamese architecture, each sub-net employ this architecture</figDesc><graphic coords="6,89.29,522.49,439.38,93.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,89.29,432.15,387.61,8.91;7,198.43,308.07,198.42,111.55"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Cosine similarity density distribution for BioASQ negative and positive sample pairs</figDesc><graphic coords="7,198.43,308.07,198.42,111.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,88.99,90.67,400.71,60.95"><head>Table 1</head><label>1</label><figDesc>Document Retrieval results for BioASQ 10 (summarized)</figDesc><table coords="8,105.57,118.40,384.14,33.21"><row><cell>Model</cell><cell cols="3">Mean precision Recall F-Measure MAP</cell><cell>GMAP</cell></row><row><cell>BM25</cell><cell>0.2074</cell><cell>0.4724 0.2174</cell><cell cols="2">0.1319 0.0257</cell></row><row><cell cols="2">BM25_v2_semantic_similarity 0.2084</cell><cell>0.4706 0.2186</cell><cell cols="2">0.1332 0.0228</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.99,494.16,417.24,109.05"><head>Table 2</head><label>2</label><figDesc>Passage retrieval results for the proposed baselines and the best models in BioASQ challenge 10b task<ref type="bibr" coords="8,89.29,518.07,16.46,8.91" target="#b15">[16]</ref> </figDesc><table coords="8,126.09,533.73,343.10,69.48"><row><cell>Method</cell><cell cols="5">Mean precision Recall F-Measure MAP GMAP</cell></row><row><cell>Bert</cell><cell>0.172</cell><cell>0.191</cell><cell>0.186</cell><cell>0.144</cell><cell>0.010</cell></row><row><cell>Siamese</cell><cell>0.119</cell><cell>0.156</cell><cell>0.131</cell><cell>0.129</cell><cell>0.002</cell></row><row><cell>Triplet loss sim-rep</cell><cell>0.226</cell><cell>0.262</cell><cell>0.241</cell><cell>0.266</cell><cell>0.021</cell></row><row><cell>Triplet loss w2v-rep</cell><cell>0.107</cell><cell>0.169</cell><cell>0.122</cell><cell>0.131</cell><cell>0.001</cell></row><row><cell>DMLPR</cell><cell>0.243</cell><cell>0.358</cell><cell>0.231</cell><cell cols="2">0.294 0.030</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="2,89.29,500.37,133.59,10.69;2,88.96,521.62,417.02,9.74;2,89.29,535.17,108.40,9.74;2,200.42,532.49,4.06,7.79;2,207.68,535.17,298.30,9.74;2,89.29,548.72,416.70,9.74;2,89.29,562.27,416.98,9.74;2,89.29,575.82,416.68,9.74;2,89.29,589.37,131.42,9.74;2,100.20,602.92,405.79,9.74;2,89.29,616.47,263.01,9.74;2,89.29,659.53,2.78,5.34;2,92.46,660.95,252.42,8.01;2,89.29,670.48,2.78,5.34;2,92.46,671.91,252.50,8.01"><p>2.1. Document RetrievalThe first module focuses on retrieving a set of documents that may contain the answer to a given question. The HayStack 2 framework is employed for document retrieval, using the PubMed papers indexed in the 2023 PubMed Baseline Repository (MBR). The retrieval process involves collecting the 100 most relevant documents based on the BM25 ranking function. The query used for retrieval is the original question, and it is compared with the concatenation of each document's title and abstract.Once the candidate documents are obtained, they are filtered down to a subset of no more than 10 documents using a re-ranking approach as follows.<ref type="bibr" coords="2,89.29,659.53,2.78,5.34" target="#b0">1</ref> DMLPR source code https://github.com/andresrosso/col-un-bioasq11 2 HayStack NLP framework https://haystack.deepset.ai/overview/intro</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="5,92.46,671.94,178.77,8.01"><p>UMLS Meta-thesaurus http://umlsks.nlm.nih.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="8,92.46,671.89,392.18,8.01"><p>BioNLP word vector representation, trained with biomedical and general-domain texts http://bio.nlplab.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6.">Acknowledgments</head><p><rs type="institution">KEO World LLC</rs> provided financial as well as logistical and planning support. <rs type="institution">Mindlab research group</rs> (<rs type="institution">Universidad Nacional de Colombia sede Bogot√°)</rs> with the cooperation of <rs type="institution">INAOE (Instituto Nacional de Astrof√≠sica, √ìptica y Electr√≥nica)</rs> wich also provided technical support for this work.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,545.72,395.17,9.74;9,112.66,559.26,394.52,9.74;9,112.66,572.81,395.16,9.74;9,112.28,586.36,393.72,9.74;9,112.66,599.91,393.31,9.74;9,112.66,613.46,395.01,9.74;9,112.66,627.01,156.50,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,374.18,586.36,131.81,9.74;9,112.66,599.91,358.40,9.74">An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Arti√©res</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-C</forename><forename type="middle">N</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
		<ptr target="http://www.biomedcentral.com/1471-2105/16/138.doi:10.1186/s12859-015-0564-6" />
	</analytic>
	<monogr>
		<title level="j" coord="9,482.91,599.91,23.07,9.74;9,112.66,613.46,66.92,9.74">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,640.56,394.53,9.74;9,112.66,654.11,393.32,9.74;9,112.66,667.66,393.32,9.74;10,112.66,88.09,393.32,9.74;10,112.66,101.64,302.40,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,234.29,654.11,271.69,9.74;9,112.66,667.66,306.98,9.74">Overview of BioASQ 2023: The eleventh BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lima-L√≥pez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Farr√©-Maduell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,445.01,667.66,60.97,9.74;10,112.66,88.09,393.32,9.74;10,112.66,101.64,221.98,9.74">Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<meeting>the Fourteenth International Conference of the CLEF Association<address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">????</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="10,112.66,115.19,393.32,9.74;10,112.66,128.74,393.32,9.74;10,112.66,142.29,136.93,9.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,283.54,115.19,222.44,9.74;10,112.66,128.74,62.72,9.74">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,198.97,128.74,307.01,9.74;10,112.66,142.29,49.16,9.74">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,155.84,393.32,9.74;10,112.66,169.38,268.65,9.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,201.44,155.84,304.54,9.74;10,112.66,169.38,38.24,9.74">Deep metric learning for visual understanding: An overview of recent advances</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,159.61,169.38,147.91,9.74">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="76" to="84" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,182.93,393.32,9.74;10,112.66,196.48,395.16,9.74;10,112.66,210.03,209.57,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,289.72,182.93,216.26,9.74;10,112.66,196.48,141.11,9.74">Large scale question paraphrase retrieval with smoothed deep metric learning</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bonadiman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,281.27,196.48,226.55,9.74;10,112.66,210.03,66.23,9.74">Proceedings of the 5th Workshop on Noisy Usergenerated Text</title>
		<meeting>the 5th Workshop on Noisy Usergenerated Text<address><addrLine>W-NUT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,223.58,393.32,9.74;10,112.66,237.13,326.44,9.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,357.16,223.58,148.82,9.74;10,112.66,237.13,189.95,9.74">BioASQ-QA: A manually curated corpus for Biomedical Question Answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,311.68,237.13,64.68,9.74">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,250.68,394.53,9.74;10,112.66,264.23,395.17,9.74;10,112.66,277.78,395.16,9.74;10,112.66,291.33,132.19,9.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,219.50,250.68,283.09,9.74">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,127.20,264.23,380.63,9.74;10,112.66,277.78,395.16,9.74;10,112.66,291.33,33.90,9.74">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,304.88,393.32,9.74;10,112.66,318.43,393.61,9.74;10,112.66,331.98,117.57,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,400.66,304.88,105.32,9.74;10,112.66,318.43,253.90,9.74">Deep fusion of multiple term-similarity measures for biomedical passage retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rosso-Mateus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y G√≥mez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Gonz√°lez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,374.50,318.43,131.77,9.74;10,112.66,331.98,36.36,9.74">Journal of Intelligent &amp; Fuzzy Systems</title>
		<imprint>
			<biblScope unit="page" from="2239" to="2248" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,345.52,393.32,9.74;10,112.66,359.07,194.88,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,226.36,345.52,279.62,9.74;10,112.66,359.07,43.20,9.74">Quickumls: a fast, unsupervised approach for medical concept extraction</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,179.18,359.07,99.37,9.74">MedIR workshop, sigir</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,372.62,393.53,9.74;10,112.66,386.17,356.70,9.74" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,333.20,372.62,172.98,9.74;10,112.66,386.17,174.44,9.74">Scispacy: Fast and robust models for biomedical natural language processing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07669</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,399.72,393.33,9.74;10,112.66,413.27,395.00,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,248.01,399.72,257.98,9.74;10,112.66,413.27,55.64,9.74">Hard negative mining for metric learning based zero-shot classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Herbin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,191.19,413.27,186.75,9.74">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,426.82,352.09,9.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,206.75,426.82,135.42,9.74">Deep metric learning: a survey</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">≈û</forename><surname>Bilge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,350.63,426.82,46.31,9.74">Symmetry</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1066</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,440.37,394.53,9.74;10,112.66,453.92,395.01,9.74;10,112.41,467.47,18.52,9.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,222.66,440.37,280.53,9.74">Biosentvec: creating sentence embeddings for biomedical texts</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,150.77,453.92,284.16,9.74">IEEE International Conference on Healthcare Informatics (ICHI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,481.02,393.33,9.74;10,112.66,494.57,393.32,9.74;10,112.33,508.11,29.19,9.74" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,366.50,481.02,139.48,9.74;10,112.66,494.57,247.83,9.74">Biobert: pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08746</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,521.66,393.54,9.74;10,112.66,535.21,393.32,9.74;10,112.66,548.76,289.31,9.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,348.95,521.66,157.25,9.74;10,112.66,535.21,166.17,9.74">Applying deep learning to answer selection: A study and an open task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,307.33,535.21,198.64,9.74;10,112.66,548.76,174.39,9.74">2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="813" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,562.31,393.32,9.74;10,112.66,575.86,393.33,9.74;10,112.66,589.41,393.32,9.74;10,112.66,602.96,394.53,9.74;10,112.66,616.51,80.57,9.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,399.69,562.31,106.29,9.74;10,112.66,575.86,393.33,9.74;10,112.66,589.41,41.03,9.74">The tenth edition of the large-scale biomedical semantic indexing and question answering challenge</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,184.54,589.41,321.43,9.74;10,112.66,602.96,87.42,9.74">Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022</title>
		<meeting><address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-04-10">2022. April 10-14, 2022. 2022</date>
			<biblScope unit="page" from="429" to="435" />
		</imprint>
	</monogr>
	<note>Bioasq at clef. Part II</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
