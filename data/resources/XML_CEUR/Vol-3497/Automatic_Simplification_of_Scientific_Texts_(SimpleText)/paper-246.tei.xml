<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,85.05,380.36,15.39;1,89.29,106.97,373.82,15.39;1,89.29,128.89,414.81,15.39;1,89.29,150.80,302.78,15.39">CLEF 2023 SimpletText Tasks 2 and 3: Enhancing Language Comprehension: Addressing Difficult Concepts and Simplifying Scientific Texts Using GPT, BLOOM, KeyBert, Simple T5 and More</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,180.13,56.74,10.68"><forename type="first">Petra</forename><surname>Dadiƒá</surname></persName>
							<email>pdadic@pmfst.hr</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Split</orgName>
								<address>
									<addrLine>33 Ruƒëera Bo≈°koviƒáa St</addrLine>
									<postCode>21000</postCode>
									<settlement>Split</settlement>
									<country key="HR">Croatia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,158.69,180.13,62.11,10.68"><forename type="first">Olga</forename><surname>Popova</surname></persName>
							<email>olga.popova@uca.es</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Cadiz</orgName>
								<address>
									<addrLine>9 Paseo Carlos III. St</addrLine>
									<postCode>11003</postCode>
									<settlement>Cadiz</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,85.05,380.36,15.39;1,89.29,106.97,373.82,15.39;1,89.29,128.89,414.81,15.39;1,89.29,150.80,302.78,15.39">CLEF 2023 SimpletText Tasks 2 and 3: Enhancing Language Comprehension: Addressing Difficult Concepts and Simplifying Scientific Texts Using GPT, BLOOM, KeyBert, Simple T5 and More</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">AEA0413382AB1B0CD230B049C215C528</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CLEF</term>
					<term>Simplification</term>
					<term>Automatic Simplification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper addresses two tasks aimed at enhancing language comprehension. First, we address the problem of identifying complexity in the text. This task consists of two parts: identifying complex terms and explaining them. To accomplish this task, we used a variety of methods. Different approaches are compared using both manual and automated evaluation. The second task deals with text simplification. GPT, Bloom and Simple T5 are compared on a variety of automated metrics. After analyzing performance of different models, we concluded that it is possible to achieve decent results with most of the methods, even when the free and trial versions of the products are used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Understanding and going through a lot of scientific literature is often crucial in domain understanding and quality research. However, understanding scientific texts can be a challenging task. They are often dense, and the researchers are usually not able to keep up, especially in the era where most of the research is interdisciplinary.</p><p>In this paper, we address two interconnected tasks aimed at solving this problem <ref type="bibr" coords="1,443.37,480.92,28.01,9.74">[1] [2]</ref>. Task 2 focuses on the identification and explanation of difficult concepts, aiming to help understanding specialized terminology and technical jargon. By automatically identifying difficult words, deciphering abbreviations, and explaining them in context, this project tries to help researchers understand scientific jargon that falls out of their area of expertise.</p><p>Task 3, on the other hand, revolves around the rewriting of scientific text to simplify complex information. Using natural language processing and machine learning, we hope to simplify passages from scientific abstracts in order to help identify the relevant articles and keep up with the ever-growing library of knowledge accessible through the Internet.</p><p>The outcomes of our research have numerous implications across various domains. By improving language comprehension, we can enhance education and learning experiences, enable more effective information retrieval, and contribute to the standardization of terminology. Moreover, our work holds significance for natural language processing applications such as machine translation and question-answering systems, where accurate understanding and explanation of difficult terms are critical.</p><p>In the subsequent sections of this paper, we delve into the methodologies employed for both Task 2 and Task 3. We present our dataset, describe the techniques utilized, and provide experimental results and evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Field Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Complexity Spotting</head><p>There are different approaches to complexity spotting. Some of the more popular ones are listed below:</p><p>Linguistic Features Approach: Traditional approaches use linguistic features to determine text complexity. These features include word length, sentence length, syntactic complexity (e.g., number of clauses), lexical diversity, and readability formulas (e.g., Flesch-Kincaid readability score) <ref type="bibr" coords="2,114.08,343.82,12.40,9.74" target="#b2">[3]</ref>. Machine learning algorithms, such as decision trees or support vector machines, can be trained on labeled datasets using these features to predict text complexity. Domain-Specific Features Approach: Scientific texts often have domain-specific characteristics that contribute to their complexity. These features can be identified using rule-based or statistical methods. <ref type="bibr" coords="2,178.49,398.02,12.84,9.74" target="#b3">[4]</ref> Corpus-Based Approaches: Corpus-based methods use large-scale text corpora to analyze and model text complexity. These approaches usually measure the frequency and distribution of complex linguistic patterns. They often use statistical models and clustering to predict complexity. <ref type="bibr" coords="2,139.65,452.22,13.73,9.74" target="#b4">[5]</ref> Neural Networks Approach: Deep learning models: recurrent neural networks (RNNs) and transformers can be trained on labeled datasets to use linguistic and contextual features to predict complexity. They have shown very good results as they can assess the difficulty of the terms in context.</p><p>Previously mentioned methods are further explained in this review article. <ref type="bibr" coords="2,435.32,519.96,12.84,9.74" target="#b5">[6]</ref> Ensemble Approaches: Ensemble methods combine multiple models or techniques to improve prediction accuracy.</p><p>Cross-Domain Transfer Learning Approach: Transfer learning techniques, such as pre-trained language models like BERT <ref type="bibr" coords="2,204.40,574.16,16.11,9.74" target="#b6">[7]</ref> or GPT <ref type="bibr" coords="2,249.36,574.16,14.80,9.74" target="#b7">[8]</ref>, are by far the most popular approach nowadays. They have been trained on large amounts of data and can be used to accomplish almost any NLP task. They show the best results with a bit of fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Text Simplification</head><p>Neural Machine Translation (NMT) <ref type="bibr" coords="2,237.85,650.98,14.80,9.74" target="#b8">[9]</ref>: Models trained on parallel corpora consisting of complex and simplified sentences. They learn to generate simplified versions of input sentences by leveraging the alignment between the two languages.</p><p>Seq2Seq Models with Attention Mechanism <ref type="bibr" coords="3,293.29,101.64,20.89,9.74" target="#b9">[10]</ref>: Sequence-to-sequence (Seq2Seq) models equipped with attention mechanisms capture dependencies between words in the source sentence and generate simplified output sentences more accurately.</p><p>Transformer Models: Transformer-based architectures, such as the Transformer model introduced in the "Attention is All You Need" paper <ref type="bibr" coords="3,310.18,155.84,17.97,9.74" target="#b10">[11]</ref>, have been applied to text simplification tasks. These models use self-attention mechanisms to capture contextual information and generate simplified sentences.</p><p>Rule-Based Approaches: Rule-based methods incorporate predefined simplification rules and patterns to transform complex text. These rules can be based on linguistic principles or domain-specific guidelines. Rule-based approaches are often used in combination with other methods to enhance the performance of the simplification models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Description</head><p>Data used for tasks was sent to us by CLEF <ref type="bibr" coords="3,276.38,295.76,15.74,9.74" target="#b0">[1]</ref> as a part of our shared tasks. Data was different for each of the tasks, and it consisted of 3 test sets: small, medium and large. The small dataset is included in the medium one, while the latter is included in the large one.</p><p>For the first task, train data consists of 2 documents. The first is the Citation Network Dataset. The second is Qrels. This file extends the qrels released with a significant increase of the depth of judgments of abstracts per query. Relevance annotations are provided on a 0-2 scale (the higher, the more relevant) for 29 queries associated with the first 15 articles from the Guardian, totalling 203 examples. The test data consisted of 152072 for large dataset, for medium dataset 4797, and 2234 for small dataset.</p><p>For the third task, train data is a parallel corpus of 648 manually simplified sentences. Test data consists of 152072 in large dataset, 4976 in medium dataset, and 2413 in small dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method Description</head><p>We used a variety of methods for each of the tasks. In this section, we will provide a short summary for all methods used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Difficult concept identification</head><p>The goal of this sub-task is to identify the words that might be difficult for people to understand and extract them from the given sentences. Since there are not a lot of papers written on this topic, we decided to use methods used for keyword extraction as there is a strong correlation between keywords and difficult words in the sentences. It is important to note that the definition of difficult words was not provided, so we had to work on what seemed to be logical for us. For us, difficulty often meant scientific jargon and domain specific terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">KeyBERT</head><p>KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords and keyphrases that are most similar to a document. <ref type="bibr" coords="4,451.45,122.21,18.86,9.74" target="#b11">[12]</ref>. Model used was 'all-MiniLM-L6-v2' with English stop words excluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">RAKE</head><p>Rapid Automatic Keyword Extraction (RAKE) is an algorithm to automatically extract keywords from documents. <ref type="bibr" coords="4,168.19,198.25,16.25,9.74" target="#b12">[13]</ref>. Implementation used was from rake nltk package for python <ref type="bibr" coords="4,459.25,198.25,19.00,9.74" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">YAKE</head><p>YAKE is a unsuppervised statistic based model for keyword extraction implemented based on the following paper <ref type="bibr" coords="4,174.29,260.74,18.25,9.74" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4.">Bloom</head><p>BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model. <ref type="bibr" coords="4,269.37,323.23,18.25,9.74" target="#b15">[16]</ref>. Prompt in appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5.">Simple T5</head><p>Simple T5 is a model that enables quickly and simply training T5 models. Some of its features are reduced compared to T5. <ref type="bibr" coords="4,212.76,385.72,16.91,9.74" target="#b16">[17]</ref>. For this task, sentences were labled as 'source text' and terms as 'target'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.6.">TextRank</head><p>TextRank is a graph based model for keyword extraction, implemented based on paper by Mihalcea and Tarau. <ref type="bibr" coords="4,178.00,461.75,17.64,9.74" target="#b17">[18]</ref>. Implementation used the pke package for python. <ref type="bibr" coords="4,424.22,461.75,19.00,9.74" target="#b18">[19]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Difficult concept scoring</head><p>For this sub-task we used data derived from different approaches mentioned in the first sub-task. This section highlights some of the methods used in scoring. We had to use manual interventions to adjust the scores, as the project required the score to be between 0 and 2. Since, as mentioned before, we were given just the vague definitions of difficulty, our adjustment of the results was very subjective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">The Flesch Reading Ease formula</head><p>The Flesch Reading Ease formula in one of the formulas used for assessing reading-ease, higher scores are calculated for material that is easier to read; lower numbers are calculated for texts that are more difficult to read. <ref type="bibr" coords="4,222.76,641.33,17.63,9.74" target="#b19">[20]</ref> 206.835 -1.015 * ( total words total sentences ) -84.6 * ( total syllables total words )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Flesch-Kincaid grade level</head><p>Flesch-Kincaid grade level is one of the formulas used for assessing reading-ease, scores indicate the grade a person would have to be in US education system to understand the text <ref type="bibr" coords="5,458.47,122.21,12.11,9.74" target="#b2">[3]</ref>. </p><formula xml:id="formula_1" coords="5,172.82,152.26,4.40,9.74">0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Task 2.2: Difficult Term Explanation</head><p>The goal of this task was to provide explanation to the terms extracted and scored in the previous tasks. The methods we used in explanations are listed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Bloom</head><p>BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model. <ref type="bibr" coords="5,270.67,545.93,19.11,9.74" target="#b15">[16]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">WordNet</head><p>WordNet <ref type="bibr" coords="5,125.33,595.26,20.89,9.74" target="#b23">[24]</ref> is large English language dictionary that can be used in python as a part of NLTK library <ref type="bibr" coords="5,118.70,608.81,16.80,9.74" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">PyDict</head><p>PyDictionary is a dictionary module for Python.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4.">Wikipedia</head><p>Wikipedia is a Python library that enables users to search and parse Wikipedia pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Task 3</head><p>The goal of the third task was to simplify complicated sentences. We only used 3 models: Bloom, GPT and SimpleT5. As we were relying on our own accounts and had to save on tokens we only used 100 examples with GPT and Bloom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">Bloom</head><p>BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model. <ref type="bibr" coords="6,270.67,248.36,19.11,9.74" target="#b15">[16]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2.">GPT</head><p>GPT is a pretrained transformer large scale language learning model[8]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3.">SimpleT5</head><p>Simple T5 is model that enables quickly and simply training T5 models. Some of its features are reduced compared to T5. <ref type="bibr" coords="6,199.34,360.57,18.23,9.74" target="#b16">[17]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>This project was done as a collaboration between two students as a part of Erasmus+ Blended Intensive Program. Both of us are fairly new in the field of Natural Language Processing and due to equipment limitations we couldn't implement any of the more complex models. We were using our own laptops and the free version of Google Collaboratory environment, which limits the data allocation and session duration for its users. We used a free version of the models and had to keep track of tokens in order to complete all the tasks, and thus we decided to use a reduced number of examples to work with BLOOM and GPT. Keeping that in mind, we tried to represent as many different approaches so, our project would give a good comparison for models that can be implemented with limited resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Difficult words identification and scoring</head><p>For these tasks, our results were scored by selecting a smaller subset of all submitted difficult terms. Afterward the selected terms were scored on three metrics: number of ok terms, number of correctly scored terms and number of terms that satisfy both criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1.">Number of ok terms</head><p>Number of correct terms reflect how many terms are correctly identified as difficult.</p><p>As a team, for this task we submitted 10 runs using a combination of methods. Number of extracted, evaluated and ok terms are shown in a table below. As is visible from the table above different methods returned different number of words so, it is best to take into the account how many of the actual terms were ok. The relation between number of extracted and correct terms is shown below.  A lot of the methods achieved good results. Bloom had the worst results and Simple T5 had the best, scoring 90%. This is somewhat surprising as we expected Bloom to achieve better results. However, this could also be explained with the number of total terms that we submitted, which were only 100 for Bloom and way more for other methods (1109 for keyBERT). The reason for this was the token limitation that forced us to use less examples with Bloom. Since there were fewer examples to evaluate, it seems like none of the examples matched the ones provided by Bloom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2.">Number of correctly scored terms</head><p>The number of correctly scored terms reflects if the complexity of the term is adequately labeled.</p><p>Scoring the terms proved a bit more challenging as it was dependent on the results of the previous task.</p><p>As is shown in the table below, scoring was quite poor across all methods. This is probably due to the fact that the train set consisted of only 203 examples and didn't include any examples of class 0. The Task description stated that participants should score terms "... on a scale 0-2 (2 to be the most difficult terms, while the meaning of terms scored 0 can be derived or guessed)" so we had to adjust the scores to reflect a different scoring system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3.">Correct LIMITS &amp; Correct difficulty scores</head><p>Correct LIMITS &amp; Correct difficulty scores reflects how many terms satisfy both criteria.  All the methods required manual intervention, which could be another source of error. Our scores were adjusted by looking at the output of each of the methods and manually deciding on where to draw a line of most difficult terms.</p><p>The best results were achieved using Flesch Reading Ease formula paired with RAKE and YAKE extraction methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Difficult Term Explanation</head><p>For this task our results were calculated using a combination of BLEU <ref type="bibr" coords="9,409.44,625.36,16.41,9.74" target="#b24">[25]</ref>, ROUGE <ref type="bibr" coords="9,462.59,625.36,23.82,9.74" target="#b25">[26]</ref> and matching scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">Matching scores</head><p>Matching scores are scores that evaluate how many definitions are exactly, partially or semantically equivalent to target definitions. Terms that were identified in the previous tasks were explained in this task using a variety of methods. The following figure shows the number of evaluated explanations that semantically matched target definitions. This task was done on 3 sets of data. Smaller subset of test set, extended version of the test set and non-unique words that also appeared in the train data set.  Most of the methods performed really good on the smaller dataset, achieving a semantic match in most cases. Runs containing Simple T5 proved to be the best method, scoring around 70%. Wiki generally scored better than other methods, excluding SimpleT5, due to the large database it has the access to. All the methods showed the best results with single word terms.</p><p>Blooms variant Bloomz performed the worst with a score of 0, which can be explained with the fact that the Bloom run used only 100 examples due to token restrictions.</p><p>When the tests were repeated with the extended dataset, all of their results improved. The biggest improvement was with Bloomz model that achieved 71% on this test and 0% on the reduced dataset. Simple T5 remained as the best model with 73% semantic match. Runs and their semantic match percentages are shown in the table below. However, since the number of evaluated terms differed significantly, it is also beneficial to take into the account the number of evaluated terms. Even though the semantic match percentage was lower for methods like TextRank + Wiki, the number of semantically matched definition was higher. In both datasets, smaller and larger, extended dataset methods using Word Net were consistently shown as the worst performers. The last dataset on which the examples were evaluated consisted of non-unique words that appeared in the train dataset. Percentages for this dataset mostly followed the ones that were achieved on the extended dataset. With the largest deviation at around 5%. Methods are shown with their semantic matched for all three cases in the figure below. Other than overall definition matching, models also assessed on their performance in abbreviation extension. In this aspect, Bloomz performed the best with a score of 61% semantic match. All runs using Wiki performed similarly, scoring around 10%. This was somewhat expected as abbreviations could have different meaning based on the context and Wikipedia can not decipher which one is correct. More powerful models as Bloomz are scoring better as they are trained to pay attention to the context of the term. The only model that had any exact or partial matches was Simple T5. It had 7 exact and 8 partial matches. All the results are shown in the table below.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.">BLEU &amp; ROUGE</head><p>BLEU is a score that is calculated by comparing the sentences to a number of reference sentences.</p><p>The output of BLEU score is a numerical value between 0 and 1 which denotes how similar are the input sentences to the references. In this task, reference sentences represent the correct explanations for extracted difficult terms. ROUGE score is a set of metric that compared the generated text to reference sentences. For this task 3 values contained in the set were used. Precision is a metric that calculates how close are the predicted definitions to the true definitions. Recall is the metric that calculates the proportion of the correct words used in predicted definitions. Fmeasure is a metric calculated when recall and precision are combined in one metric.  Sentences mostly differed from the reference sentences, which is evident for both BLEU and ROUGE scores. On both scores the combination of SimpleT5 and Wiki scored the highest while the rest of the methods scored similarly low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Sentence simplification</head><p>We only selected 100 sentences to simplify using GPT and Bloom due to token limitations. We simplified 648 sentences using Simple T5. For this task, the most metrics were used. The goal was to evaluate the results on their meaning and complexity, and to identify the instances in which the algorithm didn't change anything between the original and simplified sentence. The best method differed between each metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1.">FKGL</head><p>Flesch-Kincaid Grade Level (FKGL) is a metric used to measure the readability of generated text. It is used here to compare if the simplified sentences are more readable than the original. <ref type="bibr" coords="14,488.37,504.47,3.81,9.74">[</ref> </p><p>In FKGL Simple T5 scored the best, with the score of 13, however the other models were really close with the scores at 12 and 9. </p><p>F1-add is f1 score for the words that were added F1-keep is the equivalent for the words that were kept P-del denotes the precision of deleted words With SARI GPT scored the best with a score of 44, the second was Simple T5 with 40, and the last Bloom with 36. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3.">BLEU</head><p>BLEU is a score that is calculated by comparing the sentences to a number of reference sentences. The output of BLEU score is a numerical value between 0 and 1 which denotes how similar are the input sentences to the references. In this task, reference sentences represent the manually simplified sentences.</p><p>With BLEU Simple T5 did by far the best with a score of 44. The other modes scored 22 and 21. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.4.">Compression ratio</head><p>Compression ratio is a metric that calculates how much a sentence was shortened.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ùëêùëúùëöùëùùëüùëíùë†ùë†ùëñùëúùëõ =</head><p>Number Of Words Original Number Of Words Simplification <ref type="bibr" coords="17,495.06,138.73,11.57,9.74" target="#b7">(8)</ref> Simple T5 was also the model that compressed sentences the most with a compression rate of 89%, GPT also compressed sentences but with a much lower rate of 70%. Bloom did similarly with a compression rate of 68%. All of the models had compression rate around 1 with only slight differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.5.">Levenshtein similarity</head><p>Levenshtein <ref type="bibr" coords="17,145.78,484.93,17.89,9.74" target="#b27">[28]</ref> similarity is a metric that calculates how many insertions or deletions would be needed to transform one text into another.</p><p>Levenshtein similarity was largest for Simple T5 where it was around 0,91. Second was Bloom with the score of 0,71 and the last was GPT with 0,68. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.6.">Lexical complexity score</head><p>Lexical complexity score reflect how complex the simplified text is to understand to the average person. This metric is also useful as a means of determining how much the text was simplified when compared to the original. The only model with any kind of exact match was simple T5 that had 1% match. All of the models has simillar lexical complexity at around 8,6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this report we have explained our approach for identifying, scoring and explaining difficult words. We have also shown 3 different approaches in simplifying whole sentences. We have submitted 10 runs for difficult term identification and scoring, 10 runs for term explanation and 3 for sentence simplification. We used a combination of models for each task, combining using prompts and training.</p><p>Furthermore, we compared the results obtained with all these methods and concluded that it is possible to achieve decent results with some of the methods, mainly Simple T5, which proved to be the best method overall. Still, there is room for improvement. Since our runs were not evaluated by us students, but by the teacher, we couldn't provide deeper understanding of some of the results. It would be beneficial for us to gain insight into how our results were evaluated and which terms were, for example, the most difficult for each of the methods to score. We think that this could be one of topic of future research.</p><p>Another topic that presented itself was, how appropriate was it to use automated metrics to score definitions. This is a topic that could be very interesting to explore since, in our research, semantic matches and automated metrics were scoring models very differently.</p><p>In the end, even though we only used free to use programs and our own equipment we achieved pretty good results, proving that NLP tasks are not only for GPT and can be attempted by anyone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,89.29,357.52,321.41,8.91;8,151.80,84.19,291.69,260.81"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relationship between the number of all evaluated and correct terms</figDesc><graphic coords="8,151.80,84.19,291.69,260.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,89.29,490.72,416.67,8.91;9,151.80,302.97,291.69,175.23"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relationship between the number of all correctly identified terms and correctly scored terms</figDesc><graphic coords="9,151.80,302.97,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,89.29,379.36,416.68,8.91;10,89.29,391.32,212.65,8.91;10,151.80,197.58,291.69,175.23"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Relationship between the number evaluated definitions and number of sentences that semantically match the target in the smaller subset.</figDesc><graphic coords="10,151.80,197.58,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,89.29,632.05,416.69,8.91;11,89.29,644.01,144.81,8.91;11,151.80,449.15,291.69,175.23"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Relationship between the number of evaluated terms and the number of semantically matched definitions in the extended dataset.</figDesc><graphic coords="11,151.80,449.15,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="12,89.29,314.04,418.36,8.91;12,89.29,326.00,90.42,8.91;12,151.80,136.80,291.70,170.68"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Percentages of correctly explained term in smaller dataset, extended test data set and nonunique words dataset.</figDesc><graphic coords="12,151.80,136.80,291.70,170.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="13,89.29,271.94,242.65,8.91;13,151.80,84.19,291.69,175.23"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Percentages of correctly explained abbreviations.</figDesc><graphic coords="13,151.80,84.19,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="13,89.29,648.85,164.61,8.91;13,151.80,461.10,291.69,175.23"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: BLEU scores for explanations.</figDesc><graphic coords="13,151.80,461.10,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="14,89.29,271.94,173.84,8.91;14,151.80,84.19,291.69,175.23"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: ROUGE scores for explanations.</figDesc><graphic coords="14,151.80,84.19,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="15,89.29,271.94,190.97,8.91;15,151.80,84.19,291.69,175.23"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Models with respective FKGL scores</figDesc><graphic coords="15,151.80,84.19,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="16,89.29,271.94,195.17,8.91;16,151.80,84.19,291.69,175.23"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Models with respective SARI scores.</figDesc><graphic coords="16,151.80,84.19,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="16,89.29,605.76,198.48,8.91;16,151.80,418.01,291.69,175.23"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Models with respective BLEU scores.</figDesc><graphic coords="16,151.80,418.01,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="17,89.29,404.90,217.28,8.91;17,151.80,217.15,291.69,175.23"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Models with respective compression rate.</figDesc><graphic coords="17,151.80,217.15,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="18,89.29,271.94,237.53,8.91;18,151.80,84.19,291.69,175.23"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Models with respective Levenshtein similarity.</figDesc><graphic coords="18,151.80,84.19,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13" coords="18,89.29,567.60,219.92,8.91;18,151.80,379.85,291.69,175.23"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Models with respective lexical complexity.</figDesc><graphic coords="18,151.80,379.85,291.69,175.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,89.01,144.37,418.81,289.61"><head></head><label></label><figDesc>Similar to Flesch-Kincaid grade level, Coleman-Liau index calculates the grade a person would have to be to comprehend the text. It uses the number of letters instead of the number of syllables<ref type="bibr" coords="5,126.78,231.52,16.66,9.74" target="#b20">[21]</ref>.Readability test for English text, also uses the US education system as a scale<ref type="bibr" coords="5,430.07,305.36,16.79,9.74" target="#b21">[22]</ref>.</figDesc><table coords="5,89.01,144.37,417.63,289.61"><row><cell>.39  *  (</cell><cell cols="3">total words total sentences</cell><cell cols="3">) + 11.8  *  (</cell><cell>total syllables total words</cell><cell>-15.59)</cell><cell>(2)</cell></row><row><cell cols="3">4.2.3. Coleman-Liau index</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">ùê∂ùêøùêº = 0.0588  *  ùëéùë£ùëî Letters per 100words -0.296  *  ùëéùë£ùëî Sentences per 100words -15.8</cell><cell>(3)</cell></row><row><cell cols="4">4.2.4. Automated readability index</cell><cell></cell><cell></cell></row><row><cell cols="3">4.71  *  (</cell><cell cols="2">characters words</cell><cell cols="2">) + 0.5  *  (</cell><cell>words sentences</cell><cell>) -21.43</cell><cell>(4)</cell></row><row><cell cols="2">0.1579  *  (</cell><cell cols="4">difficult words words</cell><cell>*  100) + 0.0496  *  (</cell><cell>words sentences</cell><cell>)</cell></row></table><note coords="5,89.01,365.44,173.18,9.75;5,89.29,386.02,418.53,9.74;5,89.29,399.57,42.76,9.74"><p><p><p><p>4.2.5. Dale-Chall Readability Score</p>Method that uses the lookup table of 3000 words and calculates the grade based on the formula</p><ref type="bibr" coords="5,108.30,399.57,19.01,9.74" target="#b22">[23]</ref></p>:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.96,158.65,417.22,182.69"><head>Table 1 :</head><label>1</label><figDesc>The table showing the number of all extracted terms, evaluated terms and the number of correct terms.</figDesc><table coords="7,95.68,196.11,403.92,145.23"><row><cell>Extraction Method</cell><cell cols="3">Total Terms Evaluated Terms Terms OK</cell></row><row><cell>keyBERT + The Flesch-Kincaid Grade Level</cell><cell>11099</cell><cell>1109</cell><cell>975</cell></row><row><cell>keyBERT+The Flesch Reading Ease formula</cell><cell>11099</cell><cell>1109</cell><cell>975</cell></row><row><cell>TextRank+The Flesch-Kincaid Grade Level</cell><cell>10056</cell><cell>770</cell><cell>687</cell></row><row><cell>YAKE+The Flesch Reading Ease formula</cell><cell>11112</cell><cell>828</cell><cell>591</cell></row><row><cell>YAKE+Dale-Chall Readability Score</cell><cell>11112</cell><cell>828</cell><cell>591</cell></row><row><cell>RAKE+The Flesch Reading Ease formula</cell><cell>10660</cell><cell>618</cell><cell>505</cell></row><row><cell>RAKE+Automated Readability Index</cell><cell>10660</cell><cell>618</cell><cell>505</cell></row><row><cell>SimpleT5</cell><cell>2234</cell><cell>321</cell><cell>289</cell></row><row><cell>SimpleT5+The Coleman-Liau Index</cell><cell>2234</cell><cell>321</cell><cell>289</cell></row><row><cell>Bloom</cell><cell>100</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,139.20,420.75,316.87,169.14"><head>Table 2 :</head><label>2</label><figDesc>The table showing percentage of correct terms.</figDesc><table coords="7,139.20,444.66,316.87,145.23"><row><cell>Extraction Method</cell><cell>Number of correct terms</cell></row><row><cell>Bloom</cell><cell>0</cell></row><row><cell>SimpleT5+The Coleman-Liau Index</cell><cell>90%</cell></row><row><cell>SimpleT5</cell><cell>90,0%</cell></row><row><cell>RAKE+Automated Readability Index</cell><cell>81,7%</cell></row><row><cell>RAKE+The Flesch Reading Ease formula</cell><cell>81,7%</cell></row><row><cell>YAKE+Dale-Chall Readability Score</cell><cell>71,3%</cell></row><row><cell>YAKE+The Flesch Reading Ease formula</cell><cell>71,3%</cell></row><row><cell>TextRank+The Flesch-Kincaid Grade Level</cell><cell>89,2%</cell></row><row><cell>keyBERT+The Flesch Reading Ease formula</cell><cell>87,9%</cell></row><row><cell>keyBERT + The Flesch-Kincaid Grade Level</cell><cell>87,9%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.96,86.62,417.02,182.69"><head>Table 3 :</head><label>3</label><figDesc>The table showing the number of correctly identified terms, number of correctly scored and terms that satisfy both criteria.</figDesc><table coords="9,113.87,124.07,367.53,145.23"><row><cell>Extraction Method</cell><cell cols="4">Identified Scored Both % both</cell></row><row><cell>Bloom</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>SimpleT5+The Coleman-Liau Index</cell><cell>289</cell><cell>51</cell><cell>44</cell><cell>15,22%</cell></row><row><cell>SimpleT5</cell><cell>289</cell><cell>87</cell><cell>77</cell><cell>26,6%</cell></row><row><cell>RAKE+Automated Readability Index</cell><cell>505</cell><cell>184</cell><cell>157</cell><cell>31,1%</cell></row><row><cell>RAKE+The Flesch Reading Ease formula</cell><cell>505</cell><cell>216</cell><cell>186</cell><cell>36,8%</cell></row><row><cell>YAKE+Dale-Chall Readability Score</cell><cell>591</cell><cell>187</cell><cell>126</cell><cell>21,3%</cell></row><row><cell>YAKE+The Flesch Reading Ease formula</cell><cell>591</cell><cell>302</cell><cell>229</cell><cell>38,7%</cell></row><row><cell>TextRank+The Flesch-Kincaid Grade Level</cell><cell>687</cell><cell>198</cell><cell>179</cell><cell>26,1%</cell></row><row><cell>keyBERT+The Flesch Reading Ease formula</cell><cell>975</cell><cell>298</cell><cell>262</cell><cell>26,9%</cell></row><row><cell>keyBERT + The Flesch-Kincaid Grade Level</cell><cell>975</cell><cell>374</cell><cell>352</cell><cell>36,1%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,99.58,431.67,395.78,169.14"><head>Table 4 :</head><label>4</label><figDesc>The table showing the percentage of correctly explained terms in smaller subset.</figDesc><table coords="10,199.78,455.58,195.72,145.23"><row><cell>Method</cell><cell>Semantic match</cell></row><row><cell>Bloomz</cell><cell>0%</cell></row><row><cell>keyBERT + PyDictionary</cell><cell>43%</cell></row><row><cell>YAKE + WordNet</cell><cell>28%</cell></row><row><cell>RAKE + WordNet</cell><cell>67%</cell></row><row><cell>keyBERT + WordNet</cell><cell>35%</cell></row><row><cell>keyBERT + Wiki</cell><cell>53%</cell></row><row><cell>RAKE+Wiki</cell><cell>67%</cell></row><row><cell>SimpleT5</cell><cell>70 %</cell></row><row><cell>YAKE+Wiki</cell><cell>66%</cell></row><row><cell>TextRank+Wiki</cell><cell>69%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,91.28,178.13,412.39,169.14"><head>Table 5 :</head><label>5</label><figDesc>The table showing the percentage of correctly explained terms on extended dataset .</figDesc><table coords="11,199.78,202.04,195.72,145.23"><row><cell>Extraction method</cell><cell>Semantic match</cell></row><row><cell>SimpleT5</cell><cell>73 %</cell></row><row><cell>keyBERT + Wiki</cell><cell>64%</cell></row><row><cell>RAKE+Wiki</cell><cell>68%</cell></row><row><cell>TextRank+Wiki</cell><cell>69%</cell></row><row><cell>Bloomz</cell><cell>71%</cell></row><row><cell>keyBERT + WordNet</cell><cell>44%</cell></row><row><cell>keyBERT + PyDictionary</cell><cell>51%</cell></row><row><cell>RAKE + WordNet</cell><cell>44%</cell></row><row><cell>YAKE+Wiki</cell><cell>69%</cell></row><row><cell>YAKE + WordNet</cell><cell>44%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,121.04,473.03,352.87,169.14"><head>Table 6 :</head><label>6</label><figDesc>The table showing the percentage of correctly explained abbreviations.</figDesc><table coords="12,199.78,496.94,195.72,145.23"><row><cell>Method</cell><cell>Semantic match</cell></row><row><cell>SimpleT5</cell><cell>39 %</cell></row><row><cell>keyBERT + Wiki</cell><cell>13%</cell></row><row><cell>RAKE+Wiki</cell><cell>14%</cell></row><row><cell>TextRank+Wiki</cell><cell>10%</cell></row><row><cell>Bloomz</cell><cell>61%</cell></row><row><cell>keyBERT + WordNet</cell><cell>27%</cell></row><row><cell>keyBERT + PyDictionary</cell><cell>34%</cell></row><row><cell>RAKE + WordNet</cell><cell>24%</cell></row><row><cell>YAKE+Wiki</cell><cell>11%</cell></row><row><cell>YAKE + WordNet</cell><cell>21%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="14,172.82,504.47,330.79,47.42"><head></head><label></label><figDesc>3].</figDesc><table coords="14,172.82,526.64,249.63,25.26"><row><cell>0.39  *  (</cell><cell>total words total sentences</cell><cell>) + 11.8  *  (</cell><cell>total syllables total words</cell><cell>-15.59)</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Difficult concept identification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Bloom</head><p>Sentence: However, in information-centric networking (ICN) the end-to-end encryption makes the content caching ineffective since encrypted content stored in a cache is useless for any consumer except those who know the encryption key.\n\ Term: content caching.\n\ \n\ Sentence: Quantum circuits for arithmetic functions over Galois fields such as squaring are required to implement quantum cryptanalysis algorithms..\n.\ Term: quantum cryptanalysis.\n\ \n\ Sentence: The XECGA is then used to build the probabilistic model and to sample a new population based on the probabilistic model.\n\ Term: probabilistic model\n\ \n\ Sentence: We also present a subset demonstration of this model, TravelToken, which utilizes QR code that stores and uses travel information in smart contract over Ethereum.\n\ Term: Ethereum\n\ \n\ Sentence: Treating search engines as editorial products with intrinsic biases can help understand the structure of information flows in new media.\n\ Term: intrinsic\n\ \n\ Sentence: Penetration tests have become a valuable tool in the cyber security defence strategy in terms of detecting vulnerabilities.\n\ Term:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. GPT</head><p>"Find up to 5 difficult words:\n\n"+input</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Difficult concept explanation B.1. Bloom</head><p>Term: content caching \n\ Explanation: Content caching is a performance optimization mechanism in which data is delivered from the closest servers for optimal application performance.\n\ \n\ Term: logic qubit \n\ Explanation: A logical qubit is a physical or abstract qubit that performs as specified in a quantum algorithm or quantum circuit subject to unitary transformations, has a long enough coherence time to be usable by quantum logic gates.\n\ \n\ Term: quantum cryptanalysis \n\ Explanation: Quantum cryptanalysis is the study and evaluation of cryptographic algorithms in the presence of a quantum enabled adversary.\n\ \n\ Term: probabilistic model \n\ Explanation: Probabilistic modeling is a statistical technique used to take into account the impact of random events or actions in predicting the potential occurrence of future outcomes. \n\ \n\ Term: cyber-security \n\ Explanation: Ethereum is a decentralized, open-source blockchain with smart contract functionality. Ether is the native cryptocurrency of the platform.\n\ Term: intrinsic \n\ Explanation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. GPT</head><p>"Explain the meaning of these words:\n\n"+input</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Sentence simplification C.1. Bloom</head><p>Sentence: In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research.\n\ Simplification: Current academic and industrial research is interested in autonomous vehicles.\n\ \n\ Sentence: With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too.\n\ Simplification: Drones are increasingly used in the civilian and commercial domain and need to be autonomous.\n\ \n\ Sentence: Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest.\n\ Simplification: Governments set guidelines on the operation ceiling of civil drones. So, road-tracking based navigation is attracting interest.\n\ \n\ Sentence: In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot.\n\ Simplification: Researchers propose data-driven solutions allowing drones to autonomously navigate city streets, learning to fly by imitating an expert pilot.\n\ \n\ Sentence: Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning.\n\ Simplification: The Inception-v3 architecture has better accuracy than many existing models of imitation learning.\n\ \n\ Sentence: Permissions were taken from required authorities who made sure that minimal risk (to pedestrians) is involved in the data collection process.\n\ Simplification:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. GPT</head><p>"Simplify this sentence:\n\n"+input</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="19,112.66,401.37,393.32,9.74;19,112.66,414.91,394.52,9.74;19,112.66,428.46,393.53,9.74;19,112.66,442.01,203.48,9.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="19,463.10,401.37,42.87,9.74;19,112.66,414.91,71.88,9.74">Clef 2023 simpletext track</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,307.59,428.46,152.99,9.74">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="536" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,455.56,394.53,9.74;19,112.66,469.11,393.33,9.74;19,112.66,482.66,395.16,9.74;19,112.66,496.21,393.33,9.74;19,112.33,509.76,393.86,9.74;19,112.66,523.31,225.54,9.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="19,274.33,469.11,231.66,9.74;19,112.66,482.66,139.69,9.74">Overview of the clef 2022 simpletext lab: Automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ara√∫jo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,142.89,509.76,317.03,9.74">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="470" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,536.86,393.53,9.74;19,112.66,550.41,317.31,9.74" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fishburne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chissom</surname></persName>
		</author>
		<title level="m" coord="19,323.02,536.86,183.17,9.74;19,112.66,550.41,104.12,9.74">Derivation of new readability formula for navy enlisted personnel</title>
		<meeting><address><addrLine>Millington, TN</addrLine></address></meeting>
		<imprint>
			<publisher>Navy Research Branch</publisher>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,563.96,395.16,9.74;19,112.66,577.50,36.01,9.74;19,164.67,577.50,342.03,9.74;19,112.26,591.05,397.00,9.74;19,112.39,605.85,122.21,8.14" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="19,320.25,563.96,187.57,9.74;19,112.66,577.50,30.86,9.74">Assessing user-specific difficulty of documents</title>
		<author>
			<persName coords=""><forename type="first">M.-S</forename><surname>Paukkeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ollikainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Honkela</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2012.04.001</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2012.04.001" />
	</analytic>
	<monogr>
		<title level="j" coord="19,164.67,577.50,180.25,9.74">Information Processing Management</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="198" to="212" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,618.15,393.70,9.74;19,112.66,631.70,215.63,9.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="19,163.63,618.15,342.73,9.74;19,112.66,631.70,82.00,9.74">Predicting l2 writing proficiency using linguistic complexity measures: A corpus-based study</title>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,206.82,631.70,76.68,9.74">English Teaching</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,645.25,393.33,9.74;20,112.66,88.09,393.32,9.74;20,112.33,101.64,156.48,9.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="19,348.12,645.25,157.87,9.74;20,112.66,88.09,117.73,9.74">A survey on text classification: From traditional to deep learning</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1145/3495162</idno>
	</analytic>
	<monogr>
		<title level="j" coord="20,238.65,88.09,254.64,9.74">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,115.19,393.32,9.74;20,112.66,128.74,363.59,9.74" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="20,353.51,115.19,152.47,9.74;20,112.66,128.74,181.08,9.74">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="20,112.66,142.29,395.00,9.74;20,112.66,155.84,155.09,9.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="20,152.82,142.29,119.32,9.74">Gpt-3: What&apos;s it good for?</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324920000601</idno>
	</analytic>
	<monogr>
		<title level="j" coord="20,281.17,142.29,140.18,9.74">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="113" to="118" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,169.38,394.53,9.74;20,112.28,182.93,275.03,9.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="20,264.23,169.38,237.95,9.74">Sequence to sequence learning with neural networks</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,112.28,182.93,230.24,9.74">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,196.48,393.32,9.74;20,112.66,210.03,232.93,9.74" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<title level="m" coord="20,259.74,196.48,246.24,9.74;20,112.66,210.03,56.17,9.74">Neural machine translation by jointly learning to align and translate</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="20,112.66,223.58,395.16,9.74;20,112.66,237.13,393.32,9.74;20,112.33,250.68,29.19,9.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="20,484.03,223.58,23.79,9.74;20,112.66,237.13,143.41,9.74">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">≈Å</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,264.69,237.13,228.49,9.74">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Polosukhin</note>
</biblStruct>

<biblStruct coords="20,112.66,264.23,394.61,9.74;20,112.31,277.78,292.04,9.74" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="20,195.74,264.23,220.49,9.74">Keybert: Minimal keyword extraction with bert</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grootendorst</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4461265</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4461265.doi:10.5281/zenodo.4461265" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,291.33,393.32,9.74;20,112.66,304.88,284.55,9.74" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cowley</surname></persName>
		</author>
		<idno type="DOI">10.1002/9780470689646.ch1</idno>
		<title level="m" coord="20,295.41,291.33,210.57,9.74;20,112.66,304.88,47.87,9.74">Automatic Keyword Extraction from Individual Documents</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,318.43,393.32,9.74;20,112.66,331.98,254.00,9.74" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="20,228.48,318.43,277.49,9.74;20,112.66,331.98,122.59,9.74">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,345.52,395.17,9.74;20,112.26,359.07,393.73,9.74;20,112.66,372.62,394.03,9.74;20,112.66,386.17,333.81,9.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="20,455.37,345.52,52.47,9.74;20,112.26,359.07,323.53,9.74">Yake! keyword extraction from single documents using multiple local features</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mangaravite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pasquali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jorge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jatowt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2019.09.013</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2019.09.013" />
	</analytic>
	<monogr>
		<title level="j" coord="20,451.40,359.07,54.58,9.74;20,112.66,372.62,38.26,9.74">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">509</biblScope>
			<biblScope unit="page" from="257" to="289" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,399.72,394.03,9.74;20,112.66,413.27,188.61,9.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="20,218.29,399.72,37.38,9.74">BLOOM</title>
		<idno type="DOI">10.57967/hf/0003</idno>
		<ptr target="https://huggingface.co/bigscience/bloom.doi:10.57967/hf/0003" />
	</analytic>
	<monogr>
		<title level="m" coord="20,112.66,399.72,96.36,9.74">BigScience Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>revision 4ab0472</note>
</biblStruct>

<biblStruct coords="20,112.66,426.82,394.52,9.74;20,112.66,440.37,393.32,9.74;20,112.66,453.92,394.57,9.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="20,112.66,440.37,341.66,9.74">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j" coord="20,462.63,440.37,43.35,9.74;20,112.66,453.92,123.70,9.74">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,467.47,393.57,9.74;20,112.66,481.02,395.16,9.74;20,112.66,494.57,394.03,9.74;20,112.14,508.11,47.37,9.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="20,216.09,467.47,157.17,9.74">TextRank: Bringing order into text</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tarau</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W04-3252" />
	</analytic>
	<monogr>
		<title level="m" coord="20,397.88,467.47,108.35,9.74;20,112.66,481.02,395.16,9.74;20,112.66,494.57,93.41,9.74">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,521.66,395.16,9.74;20,112.66,535.21,394.61,9.74;20,112.66,548.76,394.03,9.74;20,112.66,562.31,44.04,9.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="20,161.75,521.66,283.18,9.74">pke: an open source python-based keyphrase extraction toolkit</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Boudin</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-2015" />
	</analytic>
	<monogr>
		<title level="m" coord="20,468.12,521.66,39.70,9.74;20,112.66,535.21,394.61,9.74;20,112.66,548.76,101.95,9.74">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,575.86,395.01,9.74;20,112.66,589.41,393.32,9.74;20,112.33,602.96,29.19,9.74" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Flesch</surname></persName>
		</author>
		<ptr target="http://www.mang.canterbury.ac.nz/writing_guide/writing/flesch.shtml" />
		<title level="m" coord="20,158.19,575.86,116.63,9.74">How to write plain english</title>
		<imprint>
			<date type="published" when="1979">5 February 2016. 1979</date>
		</imprint>
		<respStmt>
			<orgName>University of Canterbury</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,616.51,394.52,9.74;20,112.48,630.06,198.83,9.74" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="20,221.72,616.51,276.94,9.74">A computer readability formula designed for machine scoring</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Liau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,112.48,630.06,136.09,9.74">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">283</biblScope>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,112.66,643.61,394.52,9.74;20,112.41,657.16,22.69,9.74" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="20,209.71,643.61,122.16,9.74">Automated readability index</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Senter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1967</date>
			<pubPlace>Cincinnati Univ OH</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="20,112.66,670.70,393.32,9.74;21,112.66,88.09,55.14,9.74" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Chall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dale</surname></persName>
		</author>
		<title level="m" coord="20,192.65,670.70,263.73,9.74">Readability revisited: The new Dale-Chall readability formula</title>
		<imprint>
			<publisher>Brookline Books</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,112.66,101.64,394.61,9.74;21,112.31,115.19,156.58,9.74" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="21,170.15,101.64,181.15,9.74">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<ptr target="https://mitpress.mit.edu/9780262561167/" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,112.66,128.74,393.33,9.74;21,112.66,142.29,393.53,9.74;21,112.66,155.84,394.52,9.74;21,112.66,169.38,396.59,9.74;21,112.39,184.18,40.52,8.14" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="21,316.62,128.74,189.36,9.74;21,112.66,142.29,100.58,9.74">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
		<ptr target="https://doi.org/10.3115/1073083.1073135.doi:10.3115/1073083.1073135" />
	</analytic>
	<monogr>
		<title level="m" coord="21,236.77,142.29,269.41,9.74;21,112.66,155.84,163.14,9.74">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,112.66,196.48,395.17,9.74;21,112.66,210.03,395.01,9.74;21,112.41,223.58,263.15,9.74" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="21,156.20,196.48,253.75,9.74">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName coords=""><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W04-1013" />
	</analytic>
	<monogr>
		<title level="m" coord="21,433.60,196.48,74.23,9.74;21,112.66,210.03,270.67,9.74">Text Summarization Branches Out, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,112.66,237.13,395.01,9.74;21,112.41,250.68,270.58,9.74" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="21,112.66,237.13,294.35,9.74">Optimizing statistical machine translation for text simplification</title>
		<ptr target="https://www.aclweb.org/anthology/Q16-1029" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,112.66,264.23,393.32,9.74;21,112.28,277.78,394.46,9.74;21,100.20,291.33,278.73,9.74" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="21,185.73,264.23,181.77,9.74">A normalized levenshtein distance metric</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yujian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2007.1078</idno>
	</analytic>
	<monogr>
		<title level="j" coord="21,375.82,264.23,130.16,9.74;21,112.28,277.78,153.45,9.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1091" to="1095" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Here you can find prompts that were used for Bloom and GPT</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
