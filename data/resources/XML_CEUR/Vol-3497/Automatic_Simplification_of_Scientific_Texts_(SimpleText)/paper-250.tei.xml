<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.78,84.74,413.44,15.42;1,89.29,106.66,62.84,15.43;1,89.29,129.00,227.95,11.96">Text Simplification of Scientific Texts for Non-Expert Readers Notebook for the SimpleText Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,85.71,11.96"><forename type="first">Björn</forename><surname>Engelmann</surname></persName>
							<email>bjoern.engelmann@th-koeln.de</email>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln -University of Applied Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.64,154.90,61.10,11.96"><forename type="first">Fabian</forename><surname>Haak</surname></persName>
							<email>fabian.haak@th-koeln.de</email>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln -University of Applied Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.39,154.90,126.69,11.96"><forename type="first">Christin</forename><forename type="middle">Katharina</forename><surname>Kreutz</surname></persName>
							<email>christin.kreutz@th-koeln.de</email>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln -University of Applied Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,400.72,154.90,68.81,11.96;1,89.29,168.85,54.87,11.96"><forename type="first">Narjes</forename><forename type="middle">Nikzad</forename><surname>Khasmakhi</surname></persName>
							<email>narjes.nikzad_khasmakhi@th-koeln.de</email>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln -University of Applied Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.16,168.85,70.68,11.96"><forename type="first">Philipp</forename><surname>Schaer</surname></persName>
							<email>philipp.schaer@th-koeln.de</email>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln -University of Applied Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.78,84.74,413.44,15.42;1,89.29,106.66,62.84,15.43;1,89.29,129.00,227.95,11.96">Text Simplification of Scientific Texts for Non-Expert Readers Notebook for the SimpleText Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4ADB467C4B4349132519173E267137B7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Text Simplification</term>
					<term>Natural Language Processing</term>
					<term>Transformer Language Models</term>
					<term>ChatGPT</term>
					<term>Prompt Engineering</term>
					<term>Non-Expert Readers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reading levels are highly individual and can depend on a text's language, a person's cognitive abilities, or knowledge on a topic. Text simplification is the task of rephrasing a text to better cater to the abilities of a specific target reader group. Simplification of scientific abstracts helps non-experts to access the core information by bypassing formulations that require domain or expert knowledge. This is especially relevant for, e.g., cancer patients reading about novel treatment options.</p><p>The SimpleText lab hosts the simplification of scientific abstracts for non-experts (Task 3) to advance this field. We contribute three runs employing out-of-the-box summarization models (two based on T5, one based on PEGASUS) and one run using ChatGPT with complex phrase identification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Even with the ever-increasing number of scientific publications, accessing information from scientific texts for non-expert readers remains a problem, e.g., cancer patients investigating possible treatment options <ref type="bibr" coords="1,193.51,451.51,11.35,10.91" target="#b0">[1]</ref>. Complex scientific texts pose challenges for non-expert readers for various reasons: jargon, abbreviations, and technical details hinder accessing such content. Text simplification attempts to mitigate these challenges, making the content more comprehensible to a broader range of readers <ref type="bibr" coords="1,220.29,492.16,12.82,10.91" target="#b1">[2]</ref> by reducing language complexity in terms of vocabulary and sentence structure without distorting its original intent and meaning <ref type="bibr" coords="1,398.68,505.71,11.43,10.91" target="#b2">[3]</ref>.</p><p>Estimating a text's readability is subjective and reader-dependent. For example, substituting complex terms could be considered a good solution for non-native speakers, while shortening and rephrasing the text may be more suitable for children who have limited literacy skills <ref type="bibr" coords="1,490.78,546.36,11.43,10.91" target="#b3">[4]</ref>.</p><p>SimpleText 1 <ref type="bibr" coords="1,158.41,559.91,11.58,10.91" target="#b4">[5]</ref>, now in its third iteration as a part of CLEF <ref type="bibr" coords="1,387.68,559.91,11.48,10.91" target="#b5">[6,</ref><ref type="bibr" coords="1,402.99,559.91,7.65,10.91" target="#b6">7]</ref>, intends to advance simplification of scientific text for non-experts. The lab consists of three tasks: selecting passages to include in a simplified summary (task 1), identifying and explaining difficult concepts for general audiences (task 2), and scientific text simplification (task 3) <ref type="bibr" coords="2,389.76,114.06,11.43,10.91" target="#b4">[5]</ref>. This work exclusively focuses on task 3, which has already been tackled in previous iterations of SimpleText and beyond <ref type="bibr" coords="2,208.07,141.16,11.39,10.91" target="#b7">[8,</ref><ref type="bibr" coords="2,222.19,141.16,7.49,10.91" target="#b8">9,</ref><ref type="bibr" coords="2,232.41,141.16,12.35,10.91" target="#b9">10]</ref>. Recent advancements in language modeling, particularly transformer-based architectures like T5 <ref type="bibr" coords="2,261.89,154.71,17.76,10.91" target="#b10">[11]</ref> and different GPT variants <ref type="bibr" coords="2,398.01,154.71,16.31,10.91" target="#b11">[12,</ref><ref type="bibr" coords="2,416.39,154.71,12.50,10.91" target="#b12">13,</ref><ref type="bibr" coords="2,430.95,154.71,12.23,10.91" target="#b13">14]</ref>, have enabled text simplification methods to incorporate semantic features in addition to lexical and syntactic ones. Notable works <ref type="bibr" coords="2,182.58,181.81,16.40,10.91" target="#b14">[15,</ref><ref type="bibr" coords="2,201.70,181.81,12.53,10.91" target="#b15">16,</ref><ref type="bibr" coords="2,216.95,181.81,8.94,10.91" target="#b7">8]</ref> primarily focus on using T5 models, while Rubio and Martínez <ref type="bibr" coords="2,89.29,195.36,12.84,10.91" target="#b8">[9]</ref> leverage BART <ref type="bibr" coords="2,173.50,195.36,16.12,10.91" target="#b16">[17]</ref>. Additionally, a GPT-2-based text simplification model was proposed in a zero-shot manner <ref type="bibr" coords="2,179.78,208.91,16.37,10.91" target="#b17">[18]</ref>. Recently, ChatGPT <ref type="bibr" coords="2,291.88,208.91,18.03,10.91" target="#b18">[19]</ref> has emerged as a powerful tool that can be used without training.</p><p>In one of our approaches for text simplification for non-experts, we use prompt engineering and complex phrase identification preprocessing with ChatGPT. Further, we contribute approaches based on the T5 and PEGASUS summarization models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>The dataset for task 3 of the SimpleText consists of short texts taken from scientific publications, primarily single sentences, e.g., "The malicious alteration of machine time is a big challenge in computer forensics." (sentence ID G09.1_567125047_1). The SimpleText lab offers a train and a test dataset split. The test split is categorized into small, medium, and large datasets, with the texts from the small being included in the medium and the large split containing all texts from the other two. In our work, we utilized the training set to engineer prompts and implemented our approaches on the large dataset comprising 152.072 source texts. We encountered several issues with the large dataset. The dataset includes duplicated samples. Removing them reduces the number of unique texts in the dataset to 135.540. Some texts (e.g., all sentences of the document with the doc_ID 2787296320) appear up to five times in the dataset. These duplicate entries are identical, with a few exceptions where the query texts differ. Additionally, the dataset frequently contains utf-8 hexcodes within the texts, as shown in Table <ref type="table" coords="2,116.14,484.32,3.79,10.91">4</ref>. The next issue concerns samples where some texts are incomplete, as highlighted in the example mentioned in subsection 3.1. These issues pose challenges for the summarization models described in subsection 3.2. Further, a small number of texts are either empty or contain punctuation marks. This can result in AI hallucination or generating empty simplified texts, as illustrated in Table <ref type="table" coords="2,176.96,538.52,3.80,10.91">1</ref>. The phenomenon of hallucination is an already recognized problem of large language models <ref type="bibr" coords="2,191.79,552.07,16.25,10.91" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodological Approaches to Simplification</head><p>This section outlines the methodology employed in each of our submitted runs. We generated four runs, including one using ChatGPT prompting and three based on out-of-the-box text summarization models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">ChatGPT for Simplification</head><p>In our irgc_task_3_ChatGPT_2stepTurbo run (called ChatGPT in the remainder of this paper), we employed a combination of complex phrase identification and simplification with ChatGPT.</p><p>The architecture of our two-step simplification approach using ChatGPT conjoined with complex phrase identification is depicted in Figure <ref type="figure" coords="3,317.18,344.26,3.74,10.91" target="#fig_0">1</ref>. In brief, we extract keyphrases from the source text before identifying complex phrases. The complex phrases are then labeled in the source text, which is given to ChatGPT with a prompt asking it to simplify the sentences with special focus on the labeled parts.</p><p>In our approach, we avoided performing any preprocessing. However, we conducted some initial testing to gain better insights into the samples and the functionality of ChatGPT. We witnessed that our model sometimes generated information not present in the source texts. We encountered this situation primarily when the sentences in the source text were sparse and a query text was provided in the prompt. For example, by including the query text "digital assistant" along with the text "This approach is ma..." (sentence ID G01.1_3006661050_2), we noted that the text was rephrased as "This way of doing things is commonly used in digital assistants.". To address this issue, we decided not to include the provided query texts in our approach. When we tried to simplify multiple source texts at once using ChatGPT, the model inferred information from consecutive sentences despite the prompt telling the model to treat these texts separately. Consequently, we randomized the order of the source texts.</p><p>For our submitted run, the first step of the approach consists of phrase identification and complex phrase identification. These labeled texts are then provided to the ChatGPT module as a second step for simplification. Finally, the simplified texts are post-processed. Since the complex phrase identification, simplification, and post-processing steps are fundamental components of our approach, we will elaborate on them in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complex Phrase Identification</head><p>One aspect of our simplification approach is to avoid highly complex phrases, i.e., phrases that are difficult to understand for non-experts. We first identify keyphrases from the source text to make this possible. Keyphrases are those phrases of a text which contain core information <ref type="bibr" coords="4,236.06,86.97,16.41,10.91" target="#b20">[21]</ref>. We assume that especially keyphrases are relevant for understanding texts, so we try to express this core information more easily. Since identifying keyphrases is an already established task, we use KBIR-inspec, a pre-trained model which is available on Hugginface<ref type="foot" coords="4,196.95,125.86,3.71,7.97" target="#foot_0">2</ref> .</p><p>However, not all recognized phrases are complex, so we introduce a mechanism to distinguish complex from non-complex phrases. To do this, we evaluate the complexity of all terms in a phrase (Equation <ref type="formula" coords="4,168.46,168.26,4.20,10.91" target="#formula_0">1</ref>) and whether the terms' aggregated complexity value exceeds a manually specified threshold. Since the domain of the task is scientific texts, we evaluate the complexity of terms using the term statistics of two text corpora: a dataset that is comprised of texts from lifestyle forums and one that is comprised of texts from science-focused forums <ref type="bibr" coords="4,434.34,208.91,16.08,10.91" target="#b21">[22]</ref>. We assume that terms whose relative frequency in scientific texts is greater than those from lifestyle texts also tend to be more complex. We obtain our complexity estimate by the difference of the inverse document frequency (idf ) of term 𝑡 from the lifestyle dataset with the idf value of the scientific dataset. The complexity of a phrase &lt; 𝑡 1 , ..., 𝑡 𝑛 &gt; is defined by the function 𝜑:</p><formula xml:id="formula_0" coords="4,134.85,284.80,371.79,26.62">𝜑(&lt; 𝑡 1 , ..., 𝑡 𝑛 &gt;) = max 𝑖∈{1,..,𝑛} {︂ log 𝑁 𝑙𝑓 (︂ 𝑁 𝑙𝑓 𝑑𝑓 𝑙𝑓 (𝑡 𝑖 ) )︂ -log 𝑁𝑠𝑐 (︂ 𝑁 𝑠𝑐 𝑑𝑓 𝑠𝑐 (𝑡 𝑖 ) )︂}︂ .<label>(1)</label></formula><p>Here 𝑑𝑓 𝑙𝑓 (𝑡) is the number of documents from the lifestyle dataset in which the term 𝑡 appears, 𝑑𝑓 𝑠𝑐 (𝑡) for the science dataset respectively. The total number of documents is 𝑁 . We set the complexity threshold to 0.01. So every phrase above this threshold gets tagged as complex. In our case, tagging means annotating phrases using square brackets (e.g., second row in Table <ref type="table" coords="4,497.07,363.08,3.53,10.91">3</ref>). Thus, the more frequently the terms of a phrase occur in scientific texts, and the less frequently they occur in lifestyle texts, the more complex we estimate the phrase to be. To index and analyze the datasets and term statistics, we use the PyTerrier <ref type="bibr" coords="4,362.76,403.73,17.91,10.91" target="#b22">[23]</ref> framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT module</head><p>The ChatGPT simplification module involves simplifying the sentences, with a focus on the labeled complex phrases. In this work, we employ the gpt-3.5-turbo-0301 model accessed via API <ref type="foot" coords="4,193.21,457.67,3.71,7.97" target="#foot_1">3</ref> .</p><p>The model is given a first instruction prompt <ref type="foot" coords="4,304.94,471.22,3.71,7.97" target="#foot_2">4</ref> . The prompt was iteratively engineered by testing, with the goal of circumventing common problems encountered with ChatGPT. In addition to a general description of the task to simplify a list of input texts, the prompt contains further specifications. The prompt includes an instruction to treat a list of input terms separately to prevent information from diffusing between sentences. We further provide information on the number of expected input texts. This asserts that the output will not split input texts with more than one sentence. The essential part of the initial prompt is explaining how complex phrases are marked by square brackets, along with an example. The system is requested to either explain or replace these complex phrases. The list of ten input sentences with the complex phrases tagged by the complex phrase identification module is provided to the system as a separate user-tagged message as a Markdown-formatted list. The marking of complex phrases by square brackets seems to work well with ChatGPT.</p><p>Postprocessing As a first postprocessing step, we remove list tags and split the text generated by ChatGPT into separate simplified texts. This is necessary because ChatGPT does not reliably return a cohesively structured list of results despite the same prompt structure being used. The results were in all cases formatted as a list of texts, but sometimes the lists were enumerated, while some contained dashed or other itemization marks. Furthermore, ChatGPT sometimes separated the list elements by empty lines. Despite the detailed description in the prompt, ChatGPT sometimes did not remove terms in square brackets, and in some of these instances, the square brackets were not removed either. We apply a postprocessing step to cope with these cases, removing all square brackets from all simplified texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Summarization Models for Simplification</head><p>In addition to the ChatGPT run, we also conducted three additional runs using out-of-the-box sequence-to-sequence models popular for summarization tasks. The main reason for employing text summarization techniques is to attempt to simplify the text snippets. In this scenario, we have two runs based on the T5 <ref type="bibr" coords="5,222.81,328.04,17.75,10.91" target="#b10">[11]</ref> model and one run that uses PEGASUS <ref type="bibr" coords="5,412.88,328.04,16.09,10.91" target="#b23">[24]</ref>. For both models we have the exact same processing steps: We instruct the model to summarize all source texts. We do not consider the queries but only the source sentences, so the source_snt. We use batch processing of texts which we want to simplify, set the maximum input length to 512 tokens per example, pad the inputs, and determine outputs to have a maximum length of 100 tokens. This leads to a model occasionally creating multiple sentences in one summarization, each fully summarizing the original text. Therefore, out of these merged simplifications (summarizations), we pick the shortest sentence as the simplified version of the original text.</p><p>In our irgc_task_3_t5 run (called t5 for simplicity) we use the T5 <ref type="bibr" coords="5,411.99,436.44,17.97,10.91" target="#b10">[11]</ref> base model with 220 million parameters available on Huggingface <ref type="foot" coords="5,310.06,448.23,3.71,7.97" target="#foot_3">5</ref> .</p><p>For our irgc_task_3_t5_noaron run (called t5_noaron for simplicity), we use the output from the t5 run but exclude a reoccurring hallucination. In the t5 runs the simplified sentences contain the name of a specific healthcare researcher several times, indicating that person stated the following simplification of the source text, e.g., text ID G04.3_2094757405_4 "aaron carroll: modelling of an infection network between viral and cellular proteins will provide a conceptual framework". In the t5_noaron run we remove this hallucination by removing the expression "aaron carroll: " from all texts produced by the t5 run.</p><p>In our irgc_task_3_pegasusTuner007plus_plus (called pegasus in the remainder of this paper for simplicity) run we use the PEGASUS <ref type="bibr" coords="5,309.71,571.93,17.76,10.91" target="#b23">[24]</ref> summarization model, which is provided by Tuner007<ref type="foot" coords="5,144.96,583.72,3.71,7.97" target="#foot_4">6</ref> as a fine-tuned version of the original PEGASUS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation and Generated Runs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Specifications</head><p>We implemented all approaches in Google Colab <ref type="foot" coords="6,306.28,130.49,3.71,7.97" target="#foot_5">7</ref> . The pegasus and t5 runs were generated on an A100 GPU. Rephrasing the sentences using T5 took approximately 90 minutes, using PEGASUS took approximately 4.5 hours.</p><p>In order to reduce both the cost of ChatGPT calls and the duration of execution, we took the following approaches. A call to ChatGPT was designed to encapsulate a prompt containing ten sentences as one request to reduce overhead. In addition, we split the dataset into 15 chunks to better handle unexpected problems. To reduce execution time, we processed each chunk using 75 processes. This allowed us to reduce the expected total computation time from 60 to 20 hours. We delayed the start of each process because the ChatGPT API has a request limit of 3,500 requests/minute and 90,000 tokens/minute. Therefore, exceeding the rate limit yields an unusable result for the request. According to our estimation, processing ten texts takes about 14 seconds (ten seconds for pre-and post-processing and four seconds for the ChatGPT API call). The ChatGPT API incurred a cost of about $30 for the entirety of our runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>In order to thoroughly analyze the outputs of our runs, we conducted an automatic and an example-based manual evaluation of generated simplifications in comparison to the source texts. These evaluations lead to our final estimation of priorities for the produced runs. The priorities indicate our estimation of the quality of the produced results and which runs' results should be considered in SimpleText's manual evaluation.<ref type="foot" coords="6,341.43,397.01,3.71,7.97" target="#foot_6">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Automatic Evaluation</head><p>In our automatic evaluation, we primarily focused on assessing the readability of the generated text rather than other metrics such as semantic accuracy. We believe that in the context of text simplification, readability measures play a crucial role in evaluating the quality of the output.</p><p>We observed readability measures that only require text snippets and no gold-labeled simplifications. Table <ref type="table" coords="6,159.37,502.29,5.06,10.91">1</ref> indicates the following averaged readability measures for the source texts as well as our four runs on the large dataset. The number of empty texts indicates how many of the texts a run produced did not contain any content. The following measures have all been averaged by the number of texts which are not empty. The compression ratio indicates by how much the original source text's size has been reduced in the simplified variant. The following readability measures have all been implemented using the Python library textstat<ref type="foot" coords="6,448.46,568.28,3.71,7.97" target="#foot_7">9</ref> : The Flesch readability index <ref type="bibr" coords="6,166.91,583.58,17.92,10.91" target="#b24">[25]</ref> quantifies the reading ease of a text based on word and sentence length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Averaged readability scores and their standard deviations for source texts as well as our four run variants. ↓ indicates the measure is better the lower it is, ↑ indicates the measure is better the higher it is. Scores between 30 and 49 indicate difficult text. The new Dale-Chall <ref type="bibr" coords="7,401.14,390.58,18.06,10.91" target="#b25">[26]</ref> score indicates the reading level of a text as a grade corresponding to the familiarity of persons from that grade with a list of the 3000 most common English words. Scores are defined up to a value between 9 and 9.9 which corresponds to the reading level of an average college student. The higher the score, the more difficult a text. The number of difficult words indicates the number of words with ≥ 3 syllables and which are not in a predefined list of easy words. The reading time indicates the seconds required to read a text; each character taking 14.69ms <ref type="bibr" coords="7,463.18,471.87,16.41,10.91" target="#b26">[27]</ref>. The syllable count gives the number of syllables in a text. The lexicon count gives the number of different words in a text. The sentence count indicates how many sentences a text consists of. For these last three measures, one could argue that a simplified text should be shorter in terms of containing fewer syllables, words and sentences compared to the original text which also is in line with previous work <ref type="bibr" coords="7,208.97,539.62,16.15,10.91" target="#b27">[28]</ref>. The artificially constructed example in Table <ref type="table" coords="7,431.40,539.62,5.01,10.91" target="#tab_1">2</ref> shows that this oversimplified assumption does not always hold.</p><p>From our strictly numerical analysis of the runs, we found that all our runs improved the source texts' readability in all measures except for the number of sentences. The t5_noaron run yielded among the best results for many of the observed measures. The ChatGPT run did not produce the numerically best results. It seemed to produce texts with more syllables and lexicals than the T5 models which negatively impacted the reading time as well.</p><p>As a result of our automatic evaluation of readability measures which do only depend on text snippets and not on some form of gold labels, we would expect the t5_noaron run to provide the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Manual Evaluation</head><p>To support our decision-making process on the estimation of the quality of runs we conducted an example-based manual evaluation. We randomly selected texts to assess perceived readability, grammar, and vocabulary and how the simplified texts cope with complex scientific terms. This evaluation process was similar to the human evaluation described by Ermakova et al. <ref type="bibr" coords="8,470.82,148.18,11.43,10.91" target="#b5">[6]</ref>. Table <ref type="table" coords="8,128.33,161.73,5.17,10.91">3</ref> shows an example for a source text along with the tagged text produced by the complex phrase identification module of the ChatGPT approach as well as the texts of the runs.</p><p>Our manual evaluation yielded several interesting observations. The results did not align with the findings of our automatic evaluation. Furthermore, the PEGASUS model produces texts, that are almost identical to the original text, which has been described as a common problem in last year's iteration of SimpleText <ref type="bibr" coords="8,253.44,229.48,16.28,10.91" target="#b28">[29]</ref>. Another finding is that the text produced by the T5 model is significantly shorter and grammatically simpler but omits important information from the source sentence, e.g., the impact on drug discovery. Further, the text still contains scientific formulations ("conceptual framework") and a case of AI hallucination in the form of reporting the text as a quote, which has been partially filtered out in the t5_noaron approach.</p><p>From our perspective, the ChatGPT approach yielded the best results by far. The identification of phrases that need to be replaced or explained for a non-expert reader was successful. The ChatGPT model replaced or explained most of the phrases with some exceptions such as "infection network", which sub-optimally was replaced with "infection pathways". Overall, however, the text produced by the model conveys all essential information from the source sentence in a simpler, concise way.</p><p>Another factor influencing our decision to rank the ChatGPT approach as best performing in the manual evaluation is the ability of the system to cope with the problems in the dataset discussed in section 2 as well as correctly interpreting abbreviations and scientific terms without further context. The example shown in Table <ref type="table" coords="8,293.15,419.17,5.08,10.91">4</ref> illustrates these advantages, showing how the model correctly interprets the utf-8 fragments ("NHPu0027s") as well as interpreting "NHP" as "non-human primates".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Priorities of Runs</head><p>Due to the task description asking to simplify texts for non-experts, we weigh the overall soundness, completeness, and textual quality evaluated in the manual evaluation more than the results of the automatic evaluation. This decision is consolidated by the fact that the priority determines which of the runs will be manually evaluated. Further, the metrics for the automatic evaluation mostly reflect the readability for those with reduced reading capability, such as children, the most common application of text simplification. However, non-experts should be no less capable of reading texts with, e.g., longer words or generally higher complexity, rather the overall scientific specificity needs to be reduced. Accordingly, we give the ChatGPT run the highest priority, followed by the t5_noaron, the pegasus, and the t5 runs in that order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>Examples for the output of our runs, including the complex term identification module of the ChatGPT approach, for an exemplary source sentence (ID G04.3_2094757405_4). In the manual evaluation, we found the ChatGPT run to produce the best simplifications for a non-expert audience. source text Indeed, modelling of an infection network between viral and cellular proteins will provide a conceptual and analytic framework to efficiently formulate new biological hypothesis at the proteome scale and to rationalize drug discovery. tagged text Indeed, modelling of an [infection network] between viral and cellular proteins will provide a conceptual and analytic framework to efficiently formulate new [biological hypothesis] at the [proteome] scale and to rationalize [drug discovery].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT</head><p>Building a model of infection pathways between viral and cellular components can help scientists generate new ideas for drugs at a large scale.</p><p>t5 aaron carroll: modelling of an infection network between viral and cellular proteins will provide a conceptual framework. t5_noaron modelling of an infection network between viral and cellular proteins will provide a conceptual framework.</p><p>pegasus Modelling of an infection network between viral and cellular proteins will provide a conceptual and analytic framework to efficiently formulate new biological hypothesis at the proteome scale and to rationalize drug discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Example for a source text with problematic formatting issues (ID G03.2_2395758311_4). The ChatGPT approach did not only effectively deal with this issue but correctly interpreted the meaning of "NHP" as "non-human primates" from the given context of the source text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>source text</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT</head><p>There are two challenges in analyzing the NHPu0027s surveillance video: the NHPu0027s behaviors are lack of regularity and intention, and serious occlusions are brought by the fences of the cages.</p><p>The irregular behavior of non-human primates and occlusions caused by cages' fences make it challenging to analyze their surveillance video footage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Our research focuses on text simplification, particularly in the context of scientific texts for non-experts. We present one run employing ChatGPT with complex phrase identification and three runs using out-of-the-box summarization models (two based on T5 and one based on PEGASUS). While our automatic evaluation did not rank ChatGPT as the best run, a manual analysis evaluated the texts produced through ChatGPT as the best. Although we did not explicitly evaluate the inclusion of complex phrase identification in the ChatGPT run, we found it to improve the system's effectiveness. The identified complex terms indicate that the datasets for constructing the complex phrase identification system were a reasonable choice.</p><p>During our implementation, we encountered several issues. Labeling complex phrases using square brackets in our approach may pose challenges when the input text already contains square brackets. This problem could be circumvented by implementing an additional preprocessing step. Another challenge is hallucinated content, possibly attributed to the absence of context in data. A possible improvement for the summarization model approaches would be flagging difficult words as ones we want to exclude in the simplified (summarized) variant.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,231.89,390.70,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pipeline of our ChatGPT run including the complex phrase identification component.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.98,130.09,417.00,235.53"><head>Table 2</head><label>2</label><figDesc>Artificially constructed example which has not been taken from the dataset showcasing the non-trivial relation between the length of a simplified text and its source text.</figDesc><table coords="7,95.27,130.09,404.74,235.53"><row><cell>measure</cell><cell>source texts</cell><cell>ChatGPT</cell><cell>t5</cell><cell cols="2">t5_noaron</cell><cell>pegasus</cell></row><row><cell>empty texts ↓</cell><cell>-</cell><cell>3</cell><cell>148</cell><cell>148</cell><cell></cell><cell>1</cell></row><row><cell>compression ↑</cell><cell>-</cell><cell>1.16 ± 0.72</cell><cell>1.53 ± 2.3</cell><cell cols="2">1.55 ± 2.34</cell><cell>1.0 ± 1.6</cell></row><row><cell>Flesch ↑</cell><cell>36.7 ± 23.33</cell><cell cols="2">42.41 ± 21.61 46.4 ± 38.65</cell><cell cols="2">46.3 ± 38.85</cell><cell>38.79 ± 23.28</cell></row><row><cell>Dale-Chall ↓</cell><cell>12.68 ± 2.18</cell><cell>12.35 ± 1.96</cell><cell>12.41 ± 3.05</cell><cell cols="2">12.37 ± 3.05</cell><cell>11.44 ± 2.62</cell></row><row><cell>difficult words ↓</cell><cell>8.51 ± 4.32</cell><cell>7.55 ± 3.33</cell><cell>6.23 ± 2.86</cell><cell>6.2 ± 2.88</cell><cell></cell><cell>7.99 ± 3.83</cell></row><row><cell>reading time ↓</cell><cell>1.94 ± 0.99</cell><cell>1.71 ± 0.68</cell><cell>1.45 ± 0.59</cell><cell cols="2">1.44 ± 0.59</cell><cell>2.24 ± 1.03</cell></row><row><cell>syllable count ↓</cell><cell>39.12 ± 20.07</cell><cell>34.4 ± 13.81</cell><cell cols="4">29.22 ± 12.22 29.11 ± 12.25 45.23 ± 20.86</cell></row><row><cell>lexicon count ↓</cell><cell>22.51 ± 11.05</cell><cell>20.26 ± 8.04</cell><cell>16.88 ± 7.04</cell><cell cols="2">16.8 ± 7.07</cell><cell>26.18 ± 11.73</cell></row><row><cell cols="2">sentence count ↓ 1.05 ± 0.58</cell><cell>1.07 ± 0.29</cell><cell>1.44 ± 0.56</cell><cell>1.44 ± 0.56</cell><cell></cell><cell>1.32 ± 0.62</cell></row><row><cell>type</cell><cell>text</cell><cell></cell><cell></cell><cell cols="3">syllables lexicons sentences</cell></row><row><cell>source</cell><cell cols="3">The WHO reprimands the potentate for</cell><cell>13</cell><cell>8</cell><cell>1</cell></row><row><cell></cell><cell>using UVAs.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">manually simplified The world health organization spoke a</cell><cell>27</cell><cell>17</cell><cell>2</cell></row><row><cell></cell><cell cols="3">warning. The ruler should not be using</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">unmanned areal vehicles (drones).</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="4,92.57,616.24,242.70,8.97"><p>https://huggingface.co/ml6team/keyphrase-extraction-kbir-inspec</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,92.57,627.20,180.82,8.97"><p>https://platform.openai.com/docs/models/gpt-3-5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,92.30,638.16,413.69,8.97;4,92.57,649.96,413.41,7.99;4,92.57,660.91,413.42,7.99;4,92.57,671.87,405.63,7.99"><p>The used prompt is: "You are given 10 texts, TREAT THEM SEPARATELY. Complex technical or scientific terms are indicated by square brackets (e.g. [convolutional neural network]). For each text, replace or explain the terms in square brackets to make it understandable to non-experts and to simplify for non-expert readers. Make sure that you return exactly one enumerated list of 10 simplified texts and that all terms in square brackets are simplified or explained!"</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="5,92.57,659.97,111.29,8.97"><p>https://huggingface.co/t5-base</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="5,92.57,670.93,241.04,8.97"><p>https://huggingface.co/tuner007/pegasus_summarizer/discussions</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="6,92.57,605.29,378.05,8.97;6,92.57,616.24,413.41,8.97;6,92.57,627.20,27.53,8.97"><p>ChatGPT: https://colab.research.google.com/drive/10LyozPzxUlqFxHkXyfjxezO469c1ou9z?usp=sharing Summarization Models: https://colab.research.google.com/drive/1dI0rGH2mPMJ8OdsGnrqAz0HWQzfQCxK0?usp= sharing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="6,92.14,638.16,415.23,8.97;6,92.57,649.12,413.42,8.97;6,92.57,660.08,295.10,8.97"><p>We assumed, that a manual evaluation would be part of the evaluation of the submissions, which is not the case. However, we believe manual evaluations as described in our manual evaluation in section 4.2.2 better reflect the quality of the produced texts than the metrics used in the SimpleText evaluation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7" coords="6,92.57,671.04,118.72,8.97"><p>https://pypi.org/project/textstat/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,172.69,393.33,10.91;10,112.66,186.24,394.04,10.91;10,112.41,199.79,124.81,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,260.03,172.69,245.96,10.91;10,112.66,186.24,193.99,10.91">An exploration on-demand article recommender system for cancer patients information provisioning</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Afsar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Crump</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H</forename><surname>Far</surname></persName>
		</author>
		<idno type="DOI">10.32473/flairs.v34i1.128339</idno>
		<ptr target="https://doi.org/10.32473/flairs.v34i1.128339" />
	</analytic>
	<monogr>
		<title level="m" coord="10,329.54,186.24,53.87,10.91">FLAIRS 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,213.34,395.00,10.91;10,112.66,226.89,236.16,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,256.13,213.34,177.81,10.91">Automated text simplification: A survey</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Al-Thanyyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Azmi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442695</idno>
		<ptr target="https://doi.org/10.1145/3442695" />
	</analytic>
	<monogr>
		<title level="j" coord="10,442.44,213.34,65.22,10.91;10,112.66,226.89,22.48,10.91">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,240.44,393.33,10.91;10,112.66,253.99,394.61,10.91;10,112.66,267.54,174.39,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,228.89,240.44,277.10,10.91;10,112.66,253.99,86.08,10.91">Controllable sentence simplification with a unified text-to-text transfer transformer</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">C</forename><surname>Sheang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.inlg-1.38" />
	</analytic>
	<monogr>
		<title level="m" coord="10,221.03,253.99,43.90,10.91">INLG 2021</title>
		<meeting><address><addrLine>Aberdeen, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="341" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,281.08,393.33,10.91;10,112.66,294.63,394.61,10.91;10,112.66,308.18,285.56,10.91" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,221.45,281.08,284.54,10.91;10,112.66,294.63,240.26,10.91">How to control text simplification? an empirical study of control tokens for meaning preserving controlled simplification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.14993</idno>
		<idno type="arXiv">arXiv:2305.14993</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.14993" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,321.73,393.33,10.91;10,112.66,335.28,394.53,10.91;10,112.66,348.83,228.15,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,449.73,321.73,56.26,10.91;10,112.66,335.28,322.41,10.91">Overview of simpletext -clef-2023 track on automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,457.56,335.28,45.09,10.91">CLEF 2023</title>
		<title level="s" coord="10,112.66,348.83,159.16,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,362.38,394.52,10.91;10,112.66,375.93,394.62,10.91;10,112.66,389.48,395.00,10.91;10,112.66,403.03,270.33,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,311.78,375.93,195.50,10.91;10,112.66,389.48,125.63,10.91">Automatic simplification of scientific texts: Simpletext lab at CLEF-2022</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Poinsu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-99739-7_46</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-99739-7_46" />
	</analytic>
	<monogr>
		<title level="m" coord="10,263.53,389.48,44.69,10.91">ECIR 2022</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13186</biblScope>
			<biblScope unit="page" from="364" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,416.58,394.53,10.91;10,112.66,430.13,393.53,10.91;10,112.66,443.67,395.01,10.91;10,112.41,457.22,270.33,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,171.43,430.13,334.75,10.91;10,112.66,443.67,126.89,10.91">Overview of simpletext 2021 -CLEF workshop on text simplification for scientific information access</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-85251-1_27" />
	</analytic>
	<monogr>
		<title level="m" coord="10,263.26,443.67,45.99,10.91">CLEF 2021</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="432" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,470.77,393.33,10.91;10,112.66,484.32,395.17,10.91;10,111.60,497.87,353.26,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,258.52,470.77,247.47,10.91;10,112.66,484.32,83.30,10.91">Using a pre-trained simplet5 model for text simplification in a limited corpus</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-241.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,220.96,484.32,42.49,10.91">CLEF2022</title>
		<title level="s" coord="10,344.17,484.32,157.45,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2826" to="2831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,511.42,393.33,10.91;10,112.66,524.97,394.53,10.91;10,112.66,538.52,315.05,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,208.87,511.42,297.12,10.91;10,112.66,524.97,50.83,10.91">HULAT-UC3M at simpletext@clef-2022: Scientific text simplification using BART</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-243.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,188.01,524.97,45.30,10.91">CLEF 2022</title>
		<title level="s" coord="10,311.33,524.97,152.01,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2845" to="2851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,552.07,393.33,10.91;10,112.66,565.62,394.61,10.91;10,112.31,579.17,150.74,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,369.39,552.07,136.59,10.91;10,112.66,565.62,148.63,10.91">Source sentence simplification for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Gispert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Stahlberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Waite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2016.12.001</idno>
		<ptr target="https://doi.org/10.1016/j.csl.2016.12.001" />
	</analytic>
	<monogr>
		<title level="j" coord="10,269.47,565.62,100.47,10.91">Comput. Speech Lang</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="221" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,592.72,394.53,10.91;10,112.66,606.27,395.01,10.91;10,112.66,619.81,354.58,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,112.66,606.27,350.58,10.91">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j" coord="10,471.76,606.27,35.91,10.91;10,112.66,619.81,48.65,10.91">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,633.36,394.53,10.91;10,112.66,646.91,394.53,10.91;10,112.66,660.46,394.53,10.91;11,112.66,86.97,394.53,10.91;11,112.66,100.52,395.01,10.91;11,112.66,114.06,187.21,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,112.66,100.52,174.33,10.91">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2005.14165" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,127.61,395.17,10.91;11,112.66,141.16,394.04,10.91;11,112.66,154.71,106.63,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,389.91,127.61,117.93,10.91;11,112.66,141.16,191.95,10.91">Improving language understanding with unsupervised learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://openai.com/research/language-unsupervised" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,168.26,393.33,10.91;11,112.66,181.81,394.04,10.91;11,112.66,195.36,206.77,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="11,424.76,168.26,81.23,10.91;11,112.66,181.81,161.32,10.91">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,208.91,394.53,10.91;11,112.39,222.46,394.89,10.91;11,112.66,236.01,196.93,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,191.57,208.91,244.17,10.91">CYUT team2 simpletext shared task report in CLEF-2022</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-246.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,458.68,208.91,44.06,10.91">CLEF 2022</title>
		<title level="s" coord="11,185.25,222.46,155.40,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2862" to="2866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,249.56,394.53,10.91;11,112.39,263.11,394.89,10.91;11,112.66,276.66,196.93,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,190.90,249.56,246.57,10.91">Is using an AI to simplify a scientific text really worth it?</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Talec-Bernard</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-245.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,458.68,249.56,44.06,10.91">CLEF 2022</title>
		<title level="s" coord="11,185.25,263.11,155.40,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2858" to="2861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,290.20,395.17,10.91;11,112.66,303.75,395.17,10.91;11,112.66,317.30,394.62,10.91;11,112.66,330.85,204.57,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,149.16,303.75,358.68,10.91;11,112.66,317.30,184.68,10.91">BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-main.703" />
	</analytic>
	<monogr>
		<title level="m" coord="11,331.33,317.30,43.37,10.91">ACL 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,344.40,393.32,10.91;11,112.66,357.95,394.53,10.91;11,112.66,371.50,383.15,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,366.14,344.40,139.84,10.91;11,112.66,357.95,120.68,10.91">University of amsterdam at the CLEF 2022 simpletext track</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mostert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sampatsing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Spronk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-3180/paper-242.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,256.23,357.95,45.36,10.91">CLEF 2022</title>
		<title level="s" coord="11,379.69,358.96,127.50,9.72;11,112.66,371.50,21.79,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">3180</biblScope>
			<biblScope unit="page" from="2832" to="2844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,385.05,219.79,10.91" xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chatgpt</surname></persName>
		</author>
		<ptr target="https://chat.openai.com/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,398.60,393.33,10.91;11,112.66,412.15,395.01,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="11,344.23,398.60,161.76,10.91;11,112.66,412.15,54.67,10.91">How language model hallucinations can snowball</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.13534</idno>
		<idno>CoRR abs/2305.13534</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.13534" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,425.70,393.33,10.91;11,112.66,439.25,394.04,10.91;11,112.41,452.79,156.83,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,319.15,425.70,186.83,10.91;11,112.66,439.25,39.41,10.91">Learning rich representation of keyphrases from text</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mahata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bhowmik</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-naacl.67</idno>
		<ptr target="https://doi.org/10.18653/v1/2022.findings-naacl.67" />
	</analytic>
	<monogr>
		<title level="m" coord="11,174.39,439.25,126.42,10.91">NAACL-HLT (Findings) 2022</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="891" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,466.34,393.33,10.91;11,112.66,479.89,395.00,10.91;11,112.66,493.44,168.74,10.91" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Saad-Falcon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.01488</idno>
		<ptr target="https://arxiv.org/abs/2112.01488" />
		<title level="m" coord="11,397.51,466.34,108.48,10.91;11,112.66,479.89,213.70,10.91">Colbertv2: Effective and efficient retrieval via lightweight late interaction</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,506.99,393.33,10.91;11,112.66,520.54,395.00,10.91;11,112.66,534.09,37.91,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,243.98,506.99,262.00,10.91;11,112.66,520.54,37.42,10.91">Declarative experimentation in information retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
		<idno type="DOI">10.1145/3409256.3409829</idno>
		<ptr target="https://doi.org/10.1145/3409256.3409829" />
	</analytic>
	<monogr>
		<title level="m" coord="11,172.88,520.54,47.63,10.91">ICTIR 2020</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,547.64,393.33,10.91;11,112.66,561.19,393.32,10.91;11,112.66,574.74,394.04,10.91;11,112.66,588.29,72.36,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,274.12,547.64,231.86,10.91;11,112.66,561.19,135.08,10.91">PEGASUS: pre-training with extracted gap-sentences for abstractive summarization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v119/zhang20ae.html" />
	</analytic>
	<monogr>
		<title level="m" coord="11,276.32,561.19,47.76,10.91;11,401.29,562.20,104.70,9.72;11,112.66,575.75,76.47,9.72">Proceedings of Machine Learning Research</title>
		<meeting>Machine Learning Research<address><addrLine>PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="11328" to="11339" />
		</imprint>
	</monogr>
	<note>ICML 2020</note>
</biblStruct>

<biblStruct coords="11,112.66,601.84,393.98,10.91;11,112.66,615.39,208.49,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="11,168.97,601.84,120.54,10.91">A new readability yardstick</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F</forename><surname>Flesch</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0057532</idno>
		<ptr target="https://doi.org/10.1037/h0057532" />
	</analytic>
	<monogr>
		<title level="j" coord="11,301.82,601.84,154.32,10.91">The Journal of applied psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="233" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,628.93,393.33,10.91;11,112.66,642.48,317.93,10.91" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dale</surname></persName>
		</author>
		<ptr target="https://books.google.de/books?id=2nbuAAAAMAAJ" />
		<title level="m" coord="11,183.68,628.93,272.33,10.91">Readability Revisited: The New Dale-Chall Readability Formula</title>
		<imprint>
			<publisher>Brookline Books</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,656.03,393.33,10.91;11,112.66,669.58,395.01,10.91;12,112.66,86.97,97.56,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="11,209.65,656.03,296.34,10.91;11,112.66,669.58,100.05,10.91">Data from eye-tracking corpora as evidence for theories of syntactic processing complexity</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Demberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2008.07.008</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2008.07.008" />
	</analytic>
	<monogr>
		<title level="j" coord="11,226.26,669.58,45.58,10.91">Cognition</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="193" to="210" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,100.52,394.53,10.91;12,112.66,114.06,394.62,10.91;12,112.66,127.61,182.26,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,340.39,100.52,162.49,10.91">Controllable sentence simplification</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.577/" />
	</analytic>
	<monogr>
		<title level="m" coord="12,128.90,114.06,47.74,10.91">LREC 2020</title>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4689" to="4698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,141.16,393.33,10.91;12,112.66,154.71,393.33,10.91;12,112.66,168.26,394.03,10.91;12,112.66,181.81,100.54,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="12,457.35,141.16,48.64,10.91;12,112.66,154.71,337.35,10.91">CLEF 2023 simpletext track -what happens if general users search scientific texts?</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-28241-6_62</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-28241-6_62" />
	</analytic>
	<monogr>
		<title level="m" coord="12,482.76,154.71,23.22,10.91;12,112.66,168.26,18.52,10.91">ECIR 2023</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">13982</biblScope>
			<biblScope unit="page" from="536" to="545" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
