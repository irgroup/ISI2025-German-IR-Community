<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,418.67,15.42;1,89.29,106.66,402.50,15.42;1,88.69,128.58,73.15,15.43;1,89.29,150.91,227.95,11.96">SINAI Participation in SimpleText Task 2 at CLEF 2023: GPT-3 in Lexical Complexity Prediction for General Audience Notebook for the SimpleText Lab at CLEF 2023</title>
				<funder ref="#_AAqm2pA">
					<orgName type="full">Andalusian Regional Government</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministry of Consumer Affairs of the Spanish Government</orgName>
				</funder>
				<funder ref="#_yVAW4Uy">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_pvM62gr">
					<orgName type="full">Plan Nacional I+D+i</orgName>
				</funder>
				<funder ref="#_zvgaM3t #_SrKHucA">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_56fDNAN">
					<orgName type="full">FEDER</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,176.82,110.70,11.96"><forename type="first">Jenny</forename><surname>Ortiz-Zambrano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Guayaquil</orgName>
								<address>
									<addrLine>Delta Av. s/n</addrLine>
									<postCode>090510</postCode>
									<settlement>Guayaquil</settlement>
									<country key="EC">Ecuador</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.95,176.82,95.62,11.96"><forename type="first">César</forename><surname>Espin-Riofrio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Guayaquil</orgName>
								<address>
									<addrLine>Delta Av. s/n</addrLine>
									<postCode>090510</postCode>
									<settlement>Guayaquil</settlement>
									<country key="EC">Ecuador</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.08,176.82,104.12,11.96"><forename type="first">Arturo</forename><surname>Montejo-Ráez</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Jaén</orgName>
								<address>
									<addrLine>Las Lagunillas s/n</addrLine>
									<postCode>23071</postCode>
									<settlement>Jaén</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,418.67,15.42;1,89.29,106.66,402.50,15.42;1,88.69,128.58,73.15,15.43;1,89.29,150.91,227.95,11.96">SINAI Participation in SimpleText Task 2 at CLEF 2023: GPT-3 in Lexical Complexity Prediction for General Audience Notebook for the SimpleText Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B5B55F750F9917ED8244818649795424</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Lexical Complexity Prediction</term>
					<term>Auto-regressive models</term>
					<term>GPT-3</term>
					<term>Prompting</term>
					<term>Zero-shot learning</term>
					<term>Few-shot learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper our participation in the CLEF 2023 SimpleText track's Task 2.1 and 2.2 is described. In our approach, we explore zero-shot and few-shot learning strategies over the auto-regressive model GPT-3. Several prompts to achieve those strategies were tested. Our results were ranked among top submitted runs and demonstrated a solid performance for the task of lexical complexity prediction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Reading involves a complex process that goes beyond dealing with words or sections that are difficult for the reader to understand. Therefore, it is necessary to have an adequate understanding of the content of the texts in order to build coherent mental representations and thus fully grasp their meaning <ref type="bibr" coords="1,227.18,442.15,11.43,10.91" target="#b0">[1]</ref>.</p><p>Information technologies make it possible for people to access abundant information in different fields such as education, information, social, health or government and even science. However, this information is not accessible to many, since some people face great reading barriers such as long sentences, technical language or complex linguistic structures that do not allow them to understand the content of the texts, being directly affected people with intellectual disabilities and people with low learning level; including university students, who are people with a high level of education and specialized knowledge in different subjects of study but, even so, could be part of groups of people with reading disabilities <ref type="bibr" coords="1,434.49,550.54,11.43,10.91" target="#b1">[2]</ref>.</p><p>The task of detecting in the content of the documents the words that are difficult or complex to understand for a certain group is called Complex Word Identification. This task is essential in many applications related to Natural Language Processing (NLP), such as Text Simplification <ref type="bibr" coords="2,89.29,127.61,11.43,10.91" target="#b2">[3]</ref>.</p><p>The SimpleText<ref type="foot" coords="2,167.68,139.41,3.71,7.97" target="#foot_0">1</ref> lab at CLEF2023 <ref type="bibr" coords="2,246.34,141.16,12.68,10.91" target="#b3">[4]</ref> aims to generate a concise summary of various scientific documents, based on a popular scientific query, in order to provide the user with an easily understandable overview of a specific topic, as people generally avoid reliable sources, such as scientific literature, due to their complex language and lack of prior knowledge. Instead, they prefer to rely on superficial, web-and social media-generated sources, which are often motivated by commercial or political interests, rather than providing quality information. Can text simplification help to remove some of these access barriers? The purpose of the task is to generate a shortened version of several scientific papers, based on a popular scientific query, in order to provide the user with an easy-to-understand overview of a specific subject.</p><p>The main purpose of this article is to demonstrate the ability of the GPT-3 Transformers-based language model to perform text classification in the realm of lexical simplification achieved by creating and evaluating several prompt variants for few-shot and zero-shot learning examples of short sentences to determine word complexity.</p><p>The paper is organized as follows: first, a brief overview of the state-of-art is provided in lexical complexity prediction and complex word identification (which are synonyms for the same NLP task). Then, large language models are introduced, with special emphasis on autoregressive ones (generative models). This is complemented with a brief description of zero-shot and few-shot learning approaches usually applied with these models. In Section 4, Task 2 in SimpleText track is introduced. Section 5 presents our solution and the results obtained with different variations on prompting. Finally, conclusions and some insights on planned work is provided in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In recent years, Complex Word Identification (CWI) has aroused great interest in the scientific community and in computational linguistics researchers. These initiatives contribute to development and research in the field of simplifying texts and improving the accessibility of information. These proposals include conferences, workshops and specific tasks that seek to address the challenges and promote advances in the field of text simplification. This is evidenced in the development of computational semantic analysis systems, as demonstrated in CWI shared tasks at events such as SemEval 2016 <ref type="bibr" coords="2,253.46,552.07,11.29,10.91" target="#b4">[5]</ref>, NAACL-HTL 2018 <ref type="bibr" coords="2,355.03,552.07,11.29,10.91" target="#b5">[6]</ref>, ALexS at IberLEF 2020 <ref type="bibr" coords="2,474.28,552.07,11.28,10.91" target="#b6">[7]</ref>, the 15th edition of SemEval and the first Lexical Complexity Prediction task <ref type="bibr" coords="2,414.42,565.62,11.48,10.91" target="#b7">[8]</ref>, TSAR-2022 -the workshop on Simplification, Accessibility and Readability of Texts <ref type="bibr" coords="2,388.83,579.17,11.50,10.91" target="#b8">[9]</ref>, the SimpleText task at CLEF in 2021 <ref type="bibr" coords="2,150.81,592.72,17.91,10.91" target="#b9">[10]</ref> and 2022 <ref type="bibr" coords="2,213.61,592.72,16.25,10.91" target="#b10">[11]</ref>, among other initiatives in this regard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">GPT-3 for solving NLP tasks</head><p>State-of-the-art deep learning models such as BERT <ref type="bibr" coords="3,318.95,107.54,16.13,10.91" target="#b11">[12]</ref>, RoBERTa <ref type="bibr" coords="3,385.73,107.54,16.13,10.91" target="#b12">[13]</ref>, GPT-3 <ref type="bibr" coords="3,438.95,107.54,17.79,10.91" target="#b13">[14]</ref> and others outperform traditional approaches. Last generation GPT-3, or Generative Pre-trained Transformer 3, is a transformer-based large language model developed by OpenAI<ref type="foot" coords="3,431.36,132.88,3.71,7.97" target="#foot_1">2</ref> . It contains 175 billion parameters. Due to its extensive language knowledge, enormous processing power, and potential to learn from vast amounts of online text data, GPT-3 can perform a wide variety of general natural language-based tasks with unprecedented ease such as the generation and classification of the text <ref type="bibr" coords="3,203.26,188.83,16.41,10.91" target="#b14">[15]</ref>. The enormous scale of the model allows to generate results with quality, precision and diversity of the generated content. This breakthrough has sparked considerable interest and concern in the NLP field, the machine learning industry in general, the media, the AI ethics communities, and civil society <ref type="bibr" coords="3,335.25,229.48,16.25,10.91" target="#b15">[16]</ref>.</p><p>Although GTP-3 is a generative model, it can take several approaches to get to classify text, which are mainly zero shot classification (in which no examples are provided to the model) to single shot and few shot classification (in which it shows some examples to the model) <ref type="bibr" coords="3,477.51,270.13,16.25,10.91" target="#b14">[15]</ref>.</p><p>In zero-shot learning, no prior training or adjustment to the labeled data is required. Currently, GPT-3 produces results for invisible data, but in order to perform zero-shot classification with GPT-3, we must provide you with a compatible prompt <ref type="bibr" coords="3,337.18,310.77,16.25,10.91" target="#b14">[15]</ref>.</p><p>In few-shot learning, the prompt is composed including some examples of the task to be solved. The ability to learn with few attempts, never before seen in Natural Language Processing (NLP) models, is a prominent feature of GPT-3 <ref type="bibr" coords="3,297.96,351.42,16.25,10.91" target="#b15">[16]</ref>.</p><p>Another </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SimpleText task at CLEF 2023</head><p>The SimpleText track at CLEF faces the challenges of text simplification methods with the purpose of promoting access to scientific information. Provided a corpus of scientific literature abstracts and popular science requests. Three tasks were proposed. First, the content selection task (what is in, or out?) poses a challenge to systems, as they must choose which passages to include in a simplified summary in response to a query, deciding what information should be present, and what information should be omitted. Second, the goal of complexity detection (what is unclear?) is to identify what is unclear in a passage and a query. It seeks to classify the terms or concepts that require additional explanation to understand the passage, including definitions, context, and applications. Third, the text simplification task (rewrite this!) is to simplify passages of scientific abstracts in response to a query, while keeping the essential content intact <ref type="bibr" coords="3,153.93,586.19,16.25,10.91" target="#b10">[11]</ref>.</p><p>We have only participated in task 2, complexity spotting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Task 2: What is unclear?</head><p>Complexity Spotting: Identifying and explaining difficult concepts for general audience. The goal of this task is:</p><p>1. to decide which terms (up to 5) require explanation and contextualization to help a reader to understand a complex scientific text -for example, with regard to a query, terms that need to be contextualized (with a definition, example and/or use-case) 2. to provide short (one/two sentence) explanations/definitions for the detected difficult terms. For the abbreviations, the definition would be the extended abbreviation.</p><p>For each piece of text, participants must submit an ordered list of terms that are difficult, along with scores on a scale of 1 to 3 (where 3 indicates the most difficult terms, and 1 are easiest to deduce or guess), and also provide definitions for these terms. The text fragments (sentences) are considered independently, which means that the repetition of difficult terms in different fragments is allowed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed system</head><p>As stated before, our approach consists in applying zero-shot or few-shot prompting to GPT-3 model, extracting the predictions from the generated sequence. The details of the model are given in Table <ref type="table" coords="4,156.87,357.73,3.81,10.91" target="#tab_0">1</ref>. The model is queried through its Python API and OpenAI playground is a convenient web interface that can be used to generate the needed code in a fast and easy way. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiments with few-shot learning</head><p>We apply three executions with few-shot learning with different prompts. The values of the settings also varied, it was observed that in the determination of the level of complexity (difficult, very difficult or neutral), the model tended to identify terminology beyond its verbatim expression in the text. After the experiments, we show that this approach is important because the model can be adapted to a specific task. Next is the detail of the different prompts tested:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt PRM_FS_TASK2_1_V1:</head><p>To retrieve up to 5 difficult terms in a given passage from a scientific abstract. Rank the list of difficult terms with corresponding scores on the scale 1-3 where 3 is the most difficult term. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt PRM_FS_TASK2_1_V2:</head><p>To decide which terms (up to 5) require explanation and contextualization to help a reader to understand a complex scientific text. Rank the list of difficult terms with corresponding scores on the scale 1-3 where 3 is the most difficult term. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments with zero-shot learning</head><p>In the case of zero-shot learning, no examples are provided in the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt PRM_ZS_TASK2_1_V1:</head><p>To retrieve up to 5 difficult terms in a given passage from a scientific abstract. Rank the list of difficult terms with corresponding scores on the scale 1-3 where 3 is the most difficult term. you have a maximum of 250 tokens you can t go over that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>## Context: drones</head><p>Text: With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>###</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt PRM_ZS_TASK2_1_V2:</head><p>To decide which difficult terms (up to 5) are in the complex scientific text. Rank the list of difficult terms with corresponding scores on the scale 1-3 where 3 is the most difficult term. you have a maximum of 250 tokens you can t go over that.  Robot companionship 3 Definition: Robot companionship is a type of human-robot interaction in which robots are used to provide companionship to humans. Example: A robotic pet can be used to provide companionship to elderly people who live alone. Use Case: Robot companionship can be used to provide comfort and companionship to people who are isolated or have difficulty forming relationships with other people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>## Context: drones</head><p>Text: In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot. ###</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt PRM_ZS_TASK2_2_V1</head><p>Select a number from 1 to 5 terms within the sentence named text, rank them from1 to 3 is the most difficult and finally give the meaning of each difficult term and add an example and an use-case. Use next form (term, difficulty, 'definition, example, use-case'). you have a maximum of 250 tokens you can t go over that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>## Context: drones</head><p>Text: Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames. ###</p><p>The Table <ref type="table" coords="7,149.22,656.03,5.01,10.91" target="#tab_4">3</ref> presents the results generated by applying zero-shot learning, where the model has been able to generate its own results without the need for it to learn from a small number of examples.</p><p>In the example of one of the texts presented by the Table <ref type="table" coords="8,367.30,114.06,5.17,10.91" target="#tab_4">3</ref> for the task 2.1 on first run -PRM_ZS_TASK2_1_V1, the model has identified a total of 5 words (corresponds to the column Term_rank_snt) achieving to generate its response according to the request made. The model has also managed to identify the complex terms of the text (corresponds to the column Term), The model has also been able to provide a complexity value for each term (corresponds to the column Difficulty).</p><p>In the second execution for the generation of results of task 2.1 -PRM_ZS_TASK2_1_V2, the model has not only been able to identify a total of 5 difficult terms from the content of the text, but it has also been able to generate a brief description of the difficult terms; we must emphasize that it had not been specified in the request.</p><p>Finally, taking as a sample one of the examples resulting from the third execution -PRM_ZS_TASK2_2_V1, and as a requirement specified in task 2.2, the model has generated a definition, an example, and a use case to better illustrate the reader about the term identified as difficult. In the run example, the model has identified 4 complex words in the text.</p><p>According to the examples of the analyzed sample, GPT-3 has shown an outstanding ability to recognize the definitions of acronyms, generating coherent definitions, examples and use cases, the issue of identification and recognition of complex words have been addressed with success.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In Tables <ref type="table" coords="8,130.23,403.03,4.97,10.91" target="#tab_5">4</ref> and<ref type="table" coords="8,155.48,403.03,4.97,10.91" target="#tab_6">5</ref> we show the results obtained in our participation at task 2.1 and 2.2 respectively, according to the scores officially released by the organizers. The runs were named against our team ID (SINAI) together with the prompt strategy used from the ones described in previous sections. We have omitted our team ID for simplification.</p><p>Our results in task 2.1 show a significant performance of the proposed approach close to top performing systems. It is interesting to note that, in general, version 1 for the prompt is better and that zero-shot learning prompts are better at detecting a difficult word, while few-shot learning prompts are better at determining a difficulty score. A mixture of both approach could be worth exploring.</p><p>In task 2.2 we obtain high values at semantic match. For providing definitions or explanations over difficult terms, few-shot learning prompting is consistently better than zero-shot learning prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and future work</head><p>We present the results obtained by a auto-regressive language model with 175 billion parameters that demonstrates strong performance in solving tasks 2.1 and 2.2 proposed in SimpleText@CLEF-2023.</p><p>The model demonstrated a solid performance in obtaining the results in the experiments applying zero-shot and few-shot approaches, generating high-quality samples. In addition,   the model shows that learning carried out with few samples has the ability to generalize from limited information. Few-shot learning has been applied to a never-before-performed task where it has been shown to overcome the limitation of large training data sets allowing the model to learn quickly and effectively with few examples. Despite the fact that the model presents several limitations and weaknesses, these results indicate that extremely large language models as GPT-3 can play a crucial role in the development of accessibility related solutions.</p><p>As future work, we plan to explore more strategies on prompting, like Chain-of-Thought or adding more examples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,139.87,364.97,366.11,10.91;3,89.29,378.52,416.98,10.91;3,89.29,392.07,407.44,10.91"><head></head><label></label><figDesc>method of classifying text is by fine-tuning an AI model with one or a few training examples, known as one or few-shot text classification. By providing examples of how to classify text, the model can learn information about object categories based on those examples [15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,256.13,322.83,3.76,7.20"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,399.39,285.29,139.38"><head>Table 1 GPT</head><label>1</label><figDesc></figDesc><table coords="4,104.56,411.39,269.72,127.38"><row><cell>-3 model details</cell><cell></cell></row><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Model</cell><cell>text-davinci-003</cell></row><row><cell>Temperature</cell><cell>0.7</cell></row><row><cell>Max_tokens</cell><cell>250</cell></row><row><cell>Top_p</cell><cell>1</cell></row><row><cell cols="2">Frecuency Penalty 0</cell></row><row><cell>Presence Penalty</cell><cell>0</cell></row><row><cell>Logprobs</cell><cell>5</cell></row><row><cell>Stop</cell><cell>"###"</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,92.68,128.96,320.84,195.06"><head></head><label></label><figDesc>You have a maximum of 250 tokens you can t go over that. (here is an example)</figDesc><table coords="5,92.68,147.89,320.84,176.13"><row><cell>context: quantum computing</cell></row><row><cell>Text: This paper describes a tool that converts Unreal levels to web-ready</cell></row><row><cell>environments in VRML and X3D.</cell></row><row><cell>##</cell></row><row><cell>Term 1: X3D</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Term 2: vrml</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Now it is your turn</cell></row><row><cell>##</cell></row><row><cell>Context: drones</cell></row><row><cell>Text: In an attempt to achieve the above mentioned tasks, we</cell></row><row><cell>propose an imitation learning based, data-driven solution to UAV</cell></row><row><cell>autonomy for navigating through city streets by learning to fly</cell></row><row><cell>by imitating an expert pilot.</cell></row><row><cell>###</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,92.68,401.27,320.84,278.08"><head></head><label></label><figDesc>The Table2presents the results generated by applying few-shot learning, where the model has been able to learn from a very small number of training examples.</figDesc><table coords="5,92.68,401.27,320.84,278.08"><row><cell>Text: This paper describes a tool that converts Unreal levels to</cell></row><row><cell>web-ready environments in VRML and X3D.</cell></row><row><cell>##</cell></row><row><cell>Term 1:3D</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Definition: X3D is an ISO-ratified, file format and run-time</cell></row><row><cell>architecture to represent and communicate 3D scenes and objects.</cell></row><row><cell>X3D fully represents 3-dimensional data.</cell></row><row><cell>Term 2:vrml</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Definition: Virtual Reality Modeling Language (VRML) is a</cell></row><row><cell>standard file format for representing 3-dimensional interactive</cell></row><row><cell>vector graphics, designed particularly with the World Web</cell></row><row><cell>in mind. It has been superseded by X3D.</cell></row><row><cell>Now it is your turn</cell></row><row><cell>##</cell></row><row><cell>Context: drones</cell></row><row><cell>Text: This paper discusses preliminary work regarding robot</cell></row><row><cell>companionship applications by using a miniature humanoid capable</cell></row><row><cell>of fetching different toys based on voice command.</cell></row><row><cell>###</cell></row><row><cell>You have a maximum of 250 tokens you can t go</cell></row><row><cell>over that. (here is an example)</cell></row><row><cell>context: quantum computing</cell></row><row><cell>Text: This paper describes a tool that converts Unreal levels to web-ready</cell></row><row><cell>environments in VRML and X3D.</cell></row><row><cell>##</cell></row><row><cell>Term 1:X3D</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Term 2: vrml</cell></row><row><cell>Difficulty:2</cell></row><row><cell>Now it is your turn</cell></row><row><cell>##</cell></row><row><cell>Context: misinformation</cell></row><row><cell>Text: We find that Italy is the most polarized country, followed</cell></row><row><cell>by France, Germany and lastly Spain.</cell></row><row><cell>###</cell></row><row><cell>Prompt PRM_FS_TASK2_2_V1:</cell></row><row><cell>Select a number from 1 to 5 terms within the sentence named</cell></row><row><cell>text, rank them from 1 to 3 is the most difficult and finally</cell></row><row><cell>give the meaning of each difficult term and add an example and</cell></row><row><cell>an use-case. Use next form (term, difficulty, 'definition,</cell></row><row><cell>example, use-case'). You have a maximum of 250 tokens you can t go</cell></row><row><cell>over that. Here is an example:</cell></row><row><cell>context: quantum computing</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,412.15,221.97"><head>Table 2</head><label>2</label><figDesc>Predictions generated by applying GPT-3 with few-shot learning Voice command technology is used in Amazon's Alexa to control smart home devices. Use Case: Voice command technology can be used to control home appliances, such as lights, thermostats, and security systems.</figDesc><table coords="7,94.14,121.01,407.00,155.44"><row><cell cols="2"># Execution Prompt</cell><cell cols="2">Term_rank_snt Term</cell><cell>Difficulty</cell></row><row><cell>1 -Task 2.1</cell><cell>PRM_FS_TASK2_1_V1</cell><cell>1</cell><cell>UAV</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>Autonomy</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>Imitation Learning</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>Data-Driven</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>5</cell><cell>Expert Pilot</cell><cell>2</cell></row><row><cell>2 -Task 2.1</cell><cell>PRM_FS_TASK2_1_V2</cell><cell>1</cell><cell>Polarized</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>Italy</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>France</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>Germany</cell><cell>1</cell></row><row><cell>3 -Task 2.2</cell><cell>PRM_FS_TASK2_2_V1</cell><cell>1</cell><cell>Voice command</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Definition: Voice command is a type of technol-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ogy that enables a user to control devices or ser-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>vices using voice commands.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Example:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,88.99,98.89,412.16,568.23"><head>Table 3</head><label>3</label><figDesc>The Experiments applying GPT-3 with Zero-shot learning</figDesc><table coords="9,94.13,129.37,407.02,537.75"><row><cell cols="2"># Execution Prompt</cell><cell cols="2">Term_rank_snt Term</cell><cell>Difficulty</cell></row><row><cell>1 -Task 2.1</cell><cell>PRM_ZS_TASK2_1_V1</cell><cell>1</cell><cell>Autonomy</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>Unmanned Aerial</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Vehicles (UAVs)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>Civilian</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>Commercial</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>5</cell><cell>Activities</cell><cell>1</cell></row><row><cell>2 -Task 2.1</cell><cell>PRM_ZS_TASK2_1_V2</cell><cell>1</cell><cell>UAV autonomy:</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>Imitation learning:</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>A type of machine learning algorithm that learns</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>from observing and mimicking an expert.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>Data-driven</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Using data to inform a decision-making process.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>City streets</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Urban roadways.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>5</cell><cell>Expert pilot</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>A highly skilled and experienced pilot.</cell><cell></cell></row><row><cell>3 -Task 2.2</cell><cell>PRM_ZS_TASK2_2_V1</cell><cell>1</cell><cell>Inception model</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Definition: A type of convolutional neural net-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>work, often used for image classification and ob-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ject ecognition.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Example: GoogleNet, a popular Inception model,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>was used to classify images in the ImageNet chal-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>lenge</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Use Case: Drones can use Inception models to</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>identify roads in tomographic reconstructions of</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>input frames.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>2</cell><cell>Image classification</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Definition: The process of recognizing the con-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>tent of an image.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Example: A photo of a dog may be classified as</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>an image of an animal.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Use Case: Drones can use image classification</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>algorithms to identify features in tomographic</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>reconstructions of input frames.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>3</cell><cell>Tomographic reconstructions</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Definition: The process of reconstructing an im-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>age from a series of slices taken from different</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>angles.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Example: A computed tomography (CT) scan is</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>a type of tomographic reconstruction.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Use Case: Drones can use tomographic reconstruc-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>tions to analyze the presence of roads in input</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>frames.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>4</cell><cell>ImageNet challenge</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Definition: A competition to classify images into</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>different categories.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Example: The ImageNet challenge involves classi-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>fying images into categories like animals, plants,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>and vehicles. Use Case: Drones can use the results of the Im-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ageNet challenge to enhance their capabilities in</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>various ways.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,88.99,90.49,418.52,119.32"><head>Table 4</head><label>4</label><figDesc>SINAI results for task 2.1. The ranking reached over the 34 runs submitted by different teams is shown. The results obtained by the best submitted run is at the last row.</figDesc><table coords="10,296.31,133.58,188.64,7.14"><row><cell>TERM</cell><cell>Correct</cell><cell>Correct LIMITS &amp;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="10,88.99,231.79,390.90,147.13"><head>Table 5</head><label>5</label><figDesc>SINAI results for task 2.2.</figDesc><table coords="10,283.77,260.71,196.13,7.14"><row><cell>BLEU</cell><cell>ROUGE ROUGE</cell><cell>ROUGE semantic</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,670.92,165.19,8.97"><p>texttthttp://simpletext-project.com/2023/clef/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,92.57,672.94,92.68,6.49"><p>https://openai.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially supported by <rs type="projectName">WeLee</rs> project (<rs type="grantNumber">1380939</rs>, <rs type="funder">FEDER</rs> <rs type="grantNumber">Andalucía 2014-2020</rs>) funded by the <rs type="funder">Andalusian Regional Government</rs>, and projects <rs type="projectName">CONSENSO</rs> (<rs type="grantNumber">PID2021-122263OB-C21</rs>), <rs type="projectName">MODERATES</rs> (<rs type="grantNumber">TED2021-130145B-I00</rs>), <rs type="projectName">SocialTOX</rs> (<rs type="grantNumber">PDC2022-133146-C21</rs>) funded by <rs type="funder">Plan Nacional I+D+i</rs> from the <rs type="funder">Spanish Government</rs>, and project <rs type="projectName">PRECOM</rs> (<rs type="grantNumber">SUBV-00016</rs>) funded by the <rs type="funder">Ministry of Consumer Affairs of the Spanish Government</rs>.</p><p>We appreciate <rs type="person">Arteaga Burgos Anthony Alexander</rs>, graduate of the <rs type="affiliation">Computer Systems Engineering degree from the University of Guayaquil</rs>, for his valuable contribution to the development of our work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_56fDNAN">
					<idno type="grant-number">1380939</idno>
					<orgName type="project" subtype="full">WeLee</orgName>
				</org>
				<org type="funded-project" xml:id="_AAqm2pA">
					<idno type="grant-number">Andalucía 2014-2020</idno>
					<orgName type="project" subtype="full">CONSENSO</orgName>
				</org>
				<org type="funded-project" xml:id="_zvgaM3t">
					<idno type="grant-number">PID2021-122263OB-C21</idno>
					<orgName type="project" subtype="full">MODERATES</orgName>
				</org>
				<org type="funded-project" xml:id="_SrKHucA">
					<idno type="grant-number">TED2021-130145B-I00</idno>
					<orgName type="project" subtype="full">SocialTOX</orgName>
				</org>
				<org type="funding" xml:id="_pvM62gr">
					<idno type="grant-number">PDC2022-133146-C21</idno>
				</org>
				<org type="funded-project" xml:id="_yVAW4Uy">
					<idno type="grant-number">SUBV-00016</idno>
					<orgName type="project" subtype="full">PRECOM</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,111.28,395.17,10.91;11,112.66,124.83,395.00,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,190.16,111.28,317.67,10.91;11,112.66,124.83,47.20,10.91">Using texts in science education: Cognitive processes and knowledge representation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Van Den Broek</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1182594</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,167.58,124.83,32.59,10.91">Science</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="page" from="453" to="456" />
			<date type="published" when="2010">2010</date>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,138.38,393.33,10.91;11,112.66,151.93,393.33,10.91;11,112.66,165.48,377.43,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,286.89,138.38,219.10,10.91;11,112.66,151.93,280.38,10.91">Hulat-ALexS CWI Task-CWI for Language and Learning Disabilities Applied to University Educational Texts</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alarcón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,420.40,151.93,85.59,10.91;11,112.66,165.48,229.50,10.91">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2020)</title>
		<meeting>the Iberian Languages Evaluation Forum (IberLEF 2020)<address><addrLine>Malaga, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,179.03,393.33,10.91;11,112.66,192.57,393.32,10.91;11,112.66,206.12,242.30,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,188.65,179.03,317.34,10.91;11,112.66,192.57,155.80,10.91">General lexicon-based complex word identification extended with stem n-grams and morphological engines</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rico-Sulayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,291.41,192.57,214.57,10.91;11,112.66,206.12,94.37,10.91">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2020)</title>
		<meeting>the Iberian Languages Evaluation Forum (IberLEF 2020)<address><addrLine>Malaga, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,219.67,393.33,10.91;11,112.66,233.22,230.42,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</author>
		<title level="m" coord="11,324.56,219.67,181.43,10.91;11,112.66,233.22,147.84,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,246.77,395.01,10.91;11,112.66,260.32,179.68,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S16-1085</idno>
		<title level="m" coord="11,218.97,246.77,238.44,10.91">SemEval 2016 Task 11: Complex Word Identification</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="560" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,273.87,394.53,10.91;11,112.28,287.42,393.71,10.91;11,112.33,300.97,394.85,10.91;11,112.28,314.52,395.00,10.91;11,112.66,328.07,298.55,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,112.28,287.42,264.91,10.91">A Report on the Complex Word Identification Shared Task</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Yimam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Štajner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-0507</idno>
		<ptr target="https://aclanthology.org/W18-0507.doi:10.18653/v1/W18-0507" />
	</analytic>
	<monogr>
		<title level="m" coord="11,421.86,287.42,84.13,10.91;11,112.33,300.97,394.85,10.91;11,112.28,314.52,184.10,10.91">Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, Association for Computational Linguistics</title>
		<meeting>the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, Association for Computational Linguistics<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="66" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,341.62,393.32,10.91;11,112.66,355.17,393.58,10.91;11,112.66,368.71,150.10,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,278.98,341.62,227.00,10.91;11,112.66,355.17,77.62,10.91">Overview of ALexS 2020: First workshop on lexical analysis at SEPLN</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ortiz-Zambrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Ráez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,214.41,355.17,291.83,10.91;11,112.66,368.71,21.62,10.91">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2020)</title>
		<meeting>the Iberian Languages Evaluation Forum (IberLEF 2020)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2664</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,382.26,395.17,10.91;11,112.66,395.81,393.33,10.91;11,112.33,409.36,394.94,10.91;11,112.66,422.91,376.29,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,340.03,382.26,167.79,10.91;11,112.66,395.81,56.94,10.91">SemEval-2021 task 1: Lexical complexity prediction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shardlow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.semeval-1.1</idno>
		<ptr target="https://aclanthology.org/2021.semeval-1.1.doi:10.18653/v1/2021.semeval-1.1" />
	</analytic>
	<monogr>
		<title level="m" coord="11,191.60,395.81,314.39,10.91;11,112.33,409.36,66.76,10.91">Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</title>
		<meeting>the 15th International Workshop on Semantic Evaluation (SemEval-2021)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,436.46,394.53,10.91;11,112.14,450.01,394.14,10.91;11,112.33,463.56,393.65,10.91;11,112.66,477.11,136.82,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Štajner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ferrés</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Shardlow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">C</forename><surname>Sheang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<title level="m" coord="11,145.46,450.01,360.81,10.91;11,112.33,463.56,49.14,10.91;11,189.90,463.56,316.08,10.91;11,112.66,477.11,50.01,10.91">Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022</title>
		<meeting>the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022</meeting>
		<imprint>
			<publisher>TSAR</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Proceedings of the Workshop on Text Simplification, Accessibility, and Readability</note>
</biblStruct>

<biblStruct coords="11,112.66,490.66,394.53,10.91;11,112.66,504.21,393.33,10.91;11,112.66,517.76,394.52,10.91;11,112.66,531.30,90.72,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,172.49,504.21,283.98,10.91">Overview of SimpleText CLEF 2021 workshop and pilot tasks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,486.14,504.21,19.85,10.91;11,112.66,517.76,258.45,10.91">12th Conference and Labs of the Evaluation Forum (CLEF 2021)</title>
		<title level="s" coord="11,439.21,517.76,23.93,10.91">CEUR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2936</biblScope>
			<biblScope unit="page" from="2212" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,544.85,394.53,10.91;11,112.66,558.40,393.33,10.91;11,112.66,571.95,395.17,10.91;11,112.66,585.50,393.33,10.91;11,112.33,599.05,393.86,10.91;11,112.66,612.60,225.55,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,274.52,558.40,231.46,10.91;11,112.66,571.95,139.86,10.91">Overview of the clef 2022 simpletext lab: Automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,142.89,599.05,317.04,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Esposti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sebastiani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="470" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,626.15,393.33,10.91;11,112.66,639.70,363.59,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,323.15,626.15,182.83,10.91;11,112.66,639.70,181.08,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,653.25,394.53,10.91;11,112.30,666.80,393.68,10.91;12,112.66,86.97,107.17,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="11,170.54,666.80,263.06,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,112.66,100.52,394.53,10.91;12,112.66,114.06,393.32,10.91;12,112.66,127.61,266.90,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,274.48,114.06,169.72,10.91">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,452.29,114.06,53.69,10.91;12,112.66,127.61,172.82,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,141.16,394.53,10.91;12,112.66,154.71,98.41,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="12,198.27,141.16,304.14,10.91">GPT-3: Building innovative NLP products using large language models</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kublik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saboo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>O&apos;Reilly Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,168.26,395.16,10.91;12,112.66,181.81,326.99,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,155.59,168.26,352.23,10.91;12,112.66,181.81,189.99,10.91">GPT-3 and InstructGPT: technological dystopianism, utopianism, and &quot;Contextual&quot; perspectives in AI ethics and industry</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,310.96,181.81,59.97,10.91">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
