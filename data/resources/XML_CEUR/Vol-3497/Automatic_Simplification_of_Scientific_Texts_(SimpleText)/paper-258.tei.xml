<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,391.39,15.42;1,89.29,106.66,361.75,15.42;1,89.29,129.00,204.43,11.96">A Prompt Engineering Approach to Scientific Text Simplification: CYUT at SimpleText2023 Task3 Notebook for the CYUT Lab at CLEF 2023</title>
				<funder ref="#_P8kRubm">
					<orgName type="full">National Science and Technology Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,154.90,73.89,11.96"><forename type="first">Shih-Hung</forename><surname>Wu</surname></persName>
							<email>shwu@cyut.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="institution">Chaoyang University of Technology</orgName>
								<address>
									<settlement>Taichung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,182.04,154.90,76.76,11.96;1,258.81,154.08,1.88,6.99"><forename type="first">Hong-Yi</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Chaoyang University of Technology</orgName>
								<address>
									<settlement>Taichung</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,391.39,15.42;1,89.29,106.66,361.75,15.42;1,89.29,129.00,204.43,11.96">A Prompt Engineering Approach to Scientific Text Simplification: CYUT at SimpleText2023 Task3 Notebook for the CYUT Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">CD3AE9F2AF51F464B3DD102B6DF7B42A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Simple Text Generation</term>
					<term>Prompt Engineering</term>
					<term>Evaluation of Text Simplification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports our approach to the SimpleText lab. In year 2023, we focus on the Task 3: Rewrite this!, Our system adopts the GPT3.5 and GPT4 generation models to rewrite the original sentences. We used different prompts to guide the model to generate simplified sentence with different guidelines. During system development, we used three metrics to evaluate the results. The official results are also reported.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Understanding scientific texts requires proper background knowledge and academic terminology that makes the scientific texts hard to read. How to simplify the scientific text in an automatic way is the key point of the SimpleText lab.</p><p>The CLEF 2023 SimpleText lab is an evaluation campaign that aims to assess the quality and usability of text simplification systems. Text simplification is the task of rewriting a text in a simpler way, while preserving its meaning and information content. The lab will consist of three challenges of automatic text simplification in the following tasks:</p><p>• TASK 1: What is in (or out)? The goal of task 1 is given a query, a system has to find passages to include in a simplified summary. • TASK 2: What is unclear? Given a passage and a query, a system has to rank terms that are required to be explained for understanding this passage. • TASK 3: Rewrite this! Given a passage from scientific abstracts, a system has to rewrite it into a simplify passage.</p><p>SimpleText aims find the textual expression carrying information that should be simplified, the background information should be provided and the most relevant or helpful. Also system should try to improve the readability of a given short text. The lab provides a common framework and dataset for comparing different approaches and measuring their impact on various aspects of text simplification, such as readability, comprehension, and preservation of meaning.</p><p>In this year, our team focus on Task3. We will describe our approach, how we evaluate our results and the official results in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Techniques in Our Approach</head><p>The deep neural network that can generate natural language texts on various topics and domains. It is based on the transformer architecture, which uses attention mechanisms to learn the relationships between words and sentences. Transformer-based models have achieved stateof-the-art performance for abstractive summarization <ref type="bibr" coords="2,331.68,226.89,12.88,10.91" target="#b0">[1]</ref> [2] <ref type="bibr" coords="2,362.87,226.89,11.47,10.91" target="#b2">[3]</ref>. To our knowledge GPT4 <ref type="bibr" coords="2,493.10,226.89,12.88,10.91" target="#b3">[4]</ref> and T5 are the best ones. T5, or Text-to-Text Transfer Transformer <ref type="bibr" coords="2,387.17,240.44,11.38,10.91" target="#b0">[1]</ref>, is a Transformer based architecture that uses a text-to-text approach. T5 can convert all NLP tasks in a Text-to-Text way with the help of prompt, a leading text to specify the goal that the user want this time. Usually, the prompts are trained tasks. The latest GPT models provide a more flexible way to give prompt in natural language, the use can give detail instruction on new tasks. Thus, how to design good prompt become an important issue on using the models <ref type="bibr" coords="2,389.87,308.18,26.35,10.91">[5] [6]</ref>. In SimpleText 2022, our system adopt the T5 model and get promising generation results <ref type="bibr" coords="2,396.01,321.73,11.40,10.91" target="#b6">[7]</ref>. The major drawback of the GPT4 model is it may not always produce factual or ethical texts, as it may inherit some biases or errors from the data it was trained on. The GPT4 model may also not be able to capture the nuances and contexts of human communication, such as sarcasm, humor, irony, etc. The GPT4 model may also require a lot of computational resources and energy to run and maintain. However, since it is a remarkable achievement in natural language processing and artificial intelligence, we explore its potential on the scientific text simplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Model Comparison</head><p>One of the main differences between T5 and GPT4 is their pre-training objectives. T5 is trained on a large corpus of text using a text-to-text framework, where it learns to map any input text to any output text. This allows T5 to perform a wide range of natural language tasks, such as summarization, translation, question answering, and text generation, by simply changing the output format. GPT4, on the other hand, is trained on a large corpus of text using an autoregressive language modeling objective, where it learns to predict the next word given the previous words. This allows GPT4 to generate fluent and coherent texts from a given prompt or context, but it also limits its ability to perform other natural language tasks that require more than word-level prediction.</p><p>Another difference between T5 and GPT4 is their model architectures. T5 is based on the Transformer encoder-decoder architecture, where it has two separate modules for encoding the input text and decoding the output text. This enables T5 to capture both the semantic and syntactic information from the input text and use it to generate the output text. GPT4 is based on the Transformer decoder-only architecture, where it has a single module for generating the output text from the input text. This simplifies the model design and reduces the computational cost, but it also makes it harder for GPT4 to incorporate external knowledge or information from the input text into the output text.</p><p>T5 and GPT4 are both powerful natural language processing models that can generate highquality texts from various inputs. We tested both models on the dataset with our self-evaluation and find that GPT4 generate better results. Therefore, we use the GPT4 in formal test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Prompt engineering</head><p>Prompt engineering is the process of carefully designing prompts that are provided to machine learning models, especially large language models like GPT-4, in order to guide their responses or behavior. The prompts go with the inputs to the model and the responses can vary greatly depending on how the prompts are crafted.</p><p>There are several techniques that can be used in prompt engineering, including but not limited to:</p><p>1. In-Context Learning <ref type="bibr" coords="3,208.84,250.47,11.43,10.91" target="#b7">[8]</ref>: Learning from the prompt and previous interactions to produce relevant responses. 2. Zero-Shot Prompting <ref type="bibr" coords="3,215.75,278.51,11.69,10.91" target="#b8">[9]</ref>: Providing a task unseen during training, testing the model's ability to use its learnt knowledge to respond. 3. Few-Shot Prompting <ref type="bibr" coords="3,212.46,306.56,11.65,10.91" target="#b4">[5]</ref>: Providing a few examples of the task before giving the actual prompt, helping the model understand the task. 4. Chain-of-Thought (CoT) Prompting <ref type="bibr" coords="3,274.81,334.60,16.23,10.91" target="#b9">[10]</ref>: Conditioning each prompt on the entire preceding conversation, maintaining context throughout a dialogue.</p><p>These techniques enable models to deliver more accurate and contextually relevant responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Datasets</head><p>SimpleText's data use the Citation Network Dataset: DBLP+Citation, ACM Citation network (12th version) as source of scientific documents to be simplified. Scientific textual content and authorship on any topic related to computer science can be extracted from this corpus. Detail description please read the overview paper <ref type="bibr" coords="3,278.66,466.85,16.09,10.91" target="#b10">[11]</ref>. The test set consist of two parts, we refer them as the large data set and the small data set. The large data set contains 152,072 records, and the small data set contains 2,234 records, 335KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our Approach</head><p>In year 2023, we focus on Task3, here we give the detail of prompts used in our runs and the self-evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Prompts Tested During System Development</head><p>Since the generation results can be very different under different prompts. We tried three prompts and two models listed in the following Table <ref type="table" coords="3,326.35,628.93,3.68,10.91" target="#tab_0">1</ref>. It is an essential process to use natural language models effectively and responsibly. We manually ask GPT4 model to improve the original prompt, (simplify the text), and get these prompts. Our system put every test sentence into the text slot and call the API provided by OpenAI. As we can see, GPT4 suggest that prompt GPT-4/small data Simplify these sentences to make them easier to understand while retaining their meaning and avoiding complex language. Be creative in your simplification.</p><p>Please simplify this sentence:{text} should give detailed instruction, such as "easier to understand", "various relevant", "creative simplification", "removing . . . jargon", and "retaining . . . meaning".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Self-Evaluation</head><p>Before sending the generated text to the organizers, we evaluate them with three metrics. Table <ref type="table" coords="4,116.73,466.13,5.17,10.91" target="#tab_1">2</ref> gives the evaluation results of the source dataset and our runs. Flesch reading ease is an index that measures the level of sentences; the higher the score, the easier it is for the reader <ref type="bibr" coords="4,119.51,493.23,16.09,10.91" target="#b11">[12]</ref>. In Table <ref type="table" coords="4,180.33,493.23,3.66,10.91" target="#tab_1">2</ref>, we can see that the reading ease index value for run 2 is the highest. The Flesch-Kincaid grade level (FKGL) is an index that measures the corresponding reader level; the lower the score, the younger the reader <ref type="bibr" coords="4,265.19,520.33,16.14,10.91" target="#b12">[13]</ref>. This is a grade index where a score of 10.x means that a tenth-grader would be able to read the text. Run 2 also has the lowest level, which drops from 14.61 to 9.59. The evaluation results in Table <ref type="table" coords="4,311.90,547.42,5.02,10.91" target="#tab_1">2</ref> show that, with the same model and input data, the prompt affects the results significantly. In the last column of Table <ref type="table" coords="4,427.49,560.97,3.73,10.91" target="#tab_1">2</ref>, we can find the percentage of academic words according to a list provided by Coxhead <ref type="bibr" coords="4,403.02,574.52,16.16,10.91" target="#b13">[14]</ref>. The percentage of academic words drops to 9.65% in run 2. Table <ref type="table" coords="4,125.95,601.62,4.97,10.91">3</ref> shows a generation results example in our evaluation, where FRE is the Flesch Reading Ease, FKGL is the Flesch-Kincaid Grade Level, and length is the number of characters in the sentence. We can see the increase of FRE and decrease of the FKGL and the shorten of the length in all four runs. The generated sentences preserve the meaning of the source sentence in this case. The country name, Greece, in the source sentence is replaced by the adjective, Greek, in all the three GPT4 generated sentences. The last one is a little bit creative, it added "improving The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire confrontation operation centers and firefighting units in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.54">21.3 264 1</head><p>This app will be used by firefighters in Greece to improve the sharing of information and knowledge between wildfire response centers and those working in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="52.53">12.6 165 2</head><p>The app helps Greek firefighters share information and knowledge between wildfire centers and field teams more easily. 54.22 9.9 118 3</p><p>The app helps Greek firefighters share important information and knowledge between operation centers and units fighting wildfires.</p><p>28.84 13.5 130 4</p><p>The app will help Greek firefighters share information and knowledge between operation centers and field units, improving wildfire response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="35.27">13.1 140</head><p>*FRE: Flesch reading ease *FKGL: Flesch-Kincaid grade level wildfire response", which is not in the source sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Official Results</head><p>We participated in the SimpleText challenge under the name "CYUT". The official evaluation result of our runs in the Task3 is listed in the following tables. Where the Max, Min, and Avg are the maximum value, the minimum value, and the average values of all runs in SimpleText2023.</p><p>The major metrics are FKGL and SARI, two public available automatic evaluation metrics, which are not used in the evaluation last year. We also used FKGL at self-evaluation while developing our system, but we never use SARI before. SARI is a metric that evaluates how well automatic text simplification systems rewrite sentences to make them easier to read and understand <ref type="bibr" coords="6,345.73,439.07,16.41,10.91" target="#b14">[15]</ref>. SARI compares the predicted simplified sentences with the original sentences and the human references. SARI calculates the quality of the words that are added, deleted, or kept by the system, based on how they match the human references. SARI is a general metric that can capture the effects of different simplification operations, such as lexical paraphrasing, syntactic restructuring, or information deletion. This year, our first run gives the highest SARI score 47.98 among all participant runs. The corresponding FKGL levels are around 9 grade and the lexical complexity scores are also at the lowest level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Discussions</head><p>In terms of generating sentences for Task 3, the results are much improved from the results in last year. We observed the excess parts of the sentence removed, the academic terminology is replaced with common words and finally the simplified sentence is obtained. The Simplified sentence fully express the meaning of the original sentence. The GPT4 model gives better results on task 3 than T5 model with the help of prompt engineering <ref type="bibr" coords="6,397.21,646.74,11.43,10.91" target="#b4">[5]</ref>.</p><p>Text simplification is the process of transforming a complex text into a simpler one, while preserving its meaning and information content. Current deep neural network models can give better results than old ones. However, evaluating the quality of simplified texts is getting difficult.</p><p>There are different aspects of simplicity, such as lexical, syntactic, semantic, and pragmatic. Lexical simplicity refers to the use of common and familiar words, syntactic simplicity refers to the use of short and simple sentences, semantic simplicity refers to the use of clear and unambiguous meanings, and pragmatic simplicity refers to the use of appropriate and relevant information for the intended audience. However, these aspects are not independent and may interact with each other in complex ways. To balance simplicity with other quality criteria, such as adequacy, coherence, and informativeness, may cause confliction between metrics.</p><p>Automatic metrics, such as readability formulas, lexical diversity measures, or compression ratios, can provide objective and quantitative scores for some aspects of simplicity and quality, may not capture all the nuances and subtleties of human language. Human judgments, such as ratings, rankings, or preferences, can provide subjective and qualitative feedback for various aspects of simplicity and quality, costly but still necessary.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,90.49,399.43,254.17"><head>Table 1</head><label>1</label><figDesc>Prompts used in different runs.</figDesc><table coords="4,111.51,122.10,376.91,222.56"><row><cell cols="2">Run Model/Dataset</cell><cell>Prompt</cell></row><row><cell></cell><cell></cell><cell>Your task is to simplify the following sentences to make them</cell></row><row><cell>1</cell><cell>GPT-3.5/large data</cell><cell>easier to understand. Please note that your response should be flexible enough to allow for various relevant and creative</cell></row><row><cell>2</cell><cell>GPT-4/small data</cell><cell>simplifications, as long as they accurately convey the intended meaning.</cell></row><row><cell></cell><cell></cell><cell>Please simplify this sentence:{text}</cell></row><row><cell></cell><cell></cell><cell>Your task is to simplify the following sentences to make them</cell></row><row><cell></cell><cell></cell><cell>easier to understand. Please provide a clear and concise re-</cell></row><row><cell></cell><cell></cell><cell>sponse that retains the original meaning of each sentence while</cell></row><row><cell>3</cell><cell>GPT-4/small data</cell><cell>removing any unnecessary complexity or jargon. Please note that your response should be flexible enough to allow for various</cell></row><row><cell></cell><cell></cell><cell>relevant and creative simplifications, as long as they accurately</cell></row><row><cell></cell><cell></cell><cell>convey the intended meaning.</cell></row><row><cell></cell><cell></cell><cell>Please simplify this sentence:{text}</cell></row><row><cell>4</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,90.49,408.51,237.37"><head>Table 2</head><label>2</label><figDesc>Flesch-Kincaid readability and the Academic Word Profile in runs.</figDesc><table coords="5,91.50,122.10,406.01,205.76"><row><cell cols="2">Run Model/Dataset</cell><cell cols="2">The Flesch Reading The Flesch-Kincaid Ease Grade Level</cell><cell>Percentage of academic words</cell></row><row><cell>-</cell><cell>source/large data</cell><cell>28.04</cell><cell>14.78</cell><cell>15.64%</cell></row><row><cell>-</cell><cell>source/small data</cell><cell>29.2</cell><cell>14.61</cell><cell>15.26%</cell></row><row><cell>1</cell><cell>GPT-3.5/large data</cell><cell>49.46</cell><cell>11.0</cell><cell>11.42%</cell></row><row><cell>2</cell><cell>GPT-4/small data</cell><cell>58.11</cell><cell>9.59</cell><cell>9.65%</cell></row><row><cell>3</cell><cell>GPT-4/small data</cell><cell>49.04</cell><cell>10.95</cell><cell>11.84%</cell></row><row><cell>4</cell><cell>GPT-4/small data</cell><cell>49.76</cell><cell>10.72</cell><cell>11.95%</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">A Typical Example in our evaluation</cell><cell></cell><cell></cell></row><row><cell>Run</cell><cell>Sentence</cell><cell></cell><cell></cell><cell>FRE FKGL length</cell></row><row><cell>source</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,302.62,281.23"><head>Table 4</head><label>4</label><figDesc>Flesch-Kincaid  Grade Level (the lower the better)</figDesc><table coords="6,88.99,121.78,302.62,249.94"><row><cell>runs</cell><cell cols="2">task3 test task3 train</cell></row><row><cell>CYUT_task_3_run1</cell><cell>9.63</cell><cell>10.22</cell></row><row><cell>CYUT_task_3_run2</cell><cell>8.43</cell><cell>9.18</cell></row><row><cell>CYUT_task_3_run3</cell><cell>10.00</cell><cell>10.48</cell></row><row><cell>CYUT_task_3_run4</cell><cell>9.24</cell><cell>10.29</cell></row><row><cell>Max</cell><cell>13.05</cell><cell>14.63</cell></row><row><cell>Min</cell><cell>7.53</cell><cell>8.08</cell></row><row><cell>Avg</cell><cell>11.29</cell><cell>11.78</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell></row><row><cell>SARI (0-100) (the higher the better)</cell><cell></cell><cell></cell></row><row><cell>runs</cell><cell cols="2">task3 test task3 train</cell></row><row><cell>CYUT_task_3_run1</cell><cell>47.98</cell><cell>35.74</cell></row><row><cell>CYUT_task_3_run2</cell><cell>44.93</cell><cell>34.71</cell></row><row><cell>CYUT_task_3_run3</cell><cell>46.82</cell><cell>36.24</cell></row><row><cell>CYUT_task_3_run4</cell><cell>47.70</cell><cell>36.59</cell></row><row><cell>Max</cell><cell>47.98</cell><cell>89.95</cell></row><row><cell>Min</cell><cell>23.28</cell><cell>27.53</cell></row><row><cell>Avg</cell><cell>35.25</cell><cell>43.53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,302.62,129.65"><head>Table 6</head><label>6</label><figDesc>Lexical complexity score (the lower the better)</figDesc><table coords="7,203.67,122.10,187.95,98.03"><row><cell>runs</cell><cell cols="2">task3 test task3 train</cell></row><row><cell>CYUT_task_3_run1</cell><cell>8.35</cell><cell>8.40</cell></row><row><cell>CYUT_task_3_run2</cell><cell>8.31</cell><cell>8.26</cell></row><row><cell>CYUT_task_3_run3</cell><cell>8.36</cell><cell>8.29</cell></row><row><cell>CYUT_task_3_run4</cell><cell>8.33</cell><cell>8.32</cell></row><row><cell>Max</cell><cell>8.68</cell><cell>8.79</cell></row><row><cell>Min</cell><cell>8.27</cell><cell>8.26</cell></row><row><cell>Avg</cell><cell>8.49</cell><cell>8.63</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This study was supported by the <rs type="funder">National Science and Technology Council</rs> under the grant number <rs type="grantNumber">NSTC 112-2221-E-324-014</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_P8kRubm">
					<idno type="grant-number">NSTC 112-2221-E-324-014</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,567.33,394.53,10.91;7,112.66,580.88,393.33,10.91;7,112.48,594.43,264.75,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,112.66,580.88,363.77,10.91">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,488.38,580.88,17.60,10.91;7,112.48,594.43,170.67,10.91">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,607.98,393.33,10.91;7,112.66,621.53,363.59,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,353.43,607.98,152.55,10.91;7,112.66,621.53,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,635.08,395.17,10.91;7,112.66,648.63,394.53,10.91;7,112.66,662.18,321.31,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<title level="m" coord="7,145.01,648.63,362.18,10.91;7,112.66,662.18,138.52,10.91">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,86.97,266.76,10.91" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Gpt-4 technical report</note>
</biblStruct>

<biblStruct coords="8,112.66,100.52,394.53,10.91;8,112.66,114.06,393.32,10.91;8,112.66,127.61,266.90,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,274.48,114.06,169.72,10.91">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,452.29,114.06,53.69,10.91;8,112.66,127.61,172.82,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,141.16,393.33,10.91;8,112.66,154.71,235.93,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11610</idno>
		<title level="m" coord="8,381.68,141.16,124.30,10.91;8,112.66,154.71,53.73,10.91">Large language models can self-improve</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,168.26,393.33,10.91;8,112.66,181.81,166.35,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,215.62,168.26,229.81,10.91">Cyut team2 simpletext shared task report in clef-2022</title>
		<author>
			<persName coords=""><forename type="first">S.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.94,168.26,53.05,10.91;8,112.66,181.81,134.43,10.91">Proceedings of the Working Notes of CLEF</title>
		<meeting>the Working Notes of CLEF</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,195.36,393.53,10.91;8,112.66,208.91,265.56,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.00234</idno>
		<title level="m" coord="8,448.12,195.36,58.06,10.91;8,112.66,208.91,83.46,10.91">A survey for in-context learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,222.46,394.53,10.91;8,112.66,236.01,395.01,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m" coord="8,112.66,236.01,216.17,10.91">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,249.56,395.17,10.91;8,112.66,263.11,393.33,10.91;8,112.66,276.66,247.37,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,477.65,249.56,30.18,10.91;8,112.66,263.11,292.85,10.91">Chainof-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,415.92,263.11,90.06,10.91;8,112.66,276.66,143.15,10.91">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,290.20,393.33,10.91;8,112.66,303.75,394.52,10.91;8,112.33,317.30,394.86,10.91;8,112.66,330.85,394.53,10.91;8,112.66,344.40,393.58,10.91;8,112.28,357.95,139.70,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,449.73,290.20,56.26,10.91;8,112.66,303.75,318.25,10.91">Overview of simpletext -clef-2023 track on automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,183.76,330.85,323.43,10.91;8,112.66,344.40,393.58,10.91;8,112.28,357.95,85.61,10.91">Avi Arampatzis, Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Asso-ciation (CLEF</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,371.50,393.61,10.91;8,112.33,385.05,29.19,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Flesch</surname></persName>
		</author>
		<title level="m" coord="8,155.76,371.50,234.48,10.91">How to write plain english: Let&apos;s start with the formula</title>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
		<respStmt>
			<orgName>University of Canterbury</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,398.60,393.61,10.91;8,112.66,412.15,393.61,10.91;8,112.66,425.70,113.45,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P</forename><surname>Fishburne</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Chissom</surname></persName>
		</author>
		<title level="m" coord="8,375.87,398.60,130.39,10.91;8,112.66,412.15,393.61,10.91;8,112.66,425.70,81.53,10.91">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,439.25,338.81,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,170.76,439.25,114.43,10.91">A new academic word list</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Coxhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,292.31,439.25,75.23,10.91">TESOL quarterly</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,452.79,393.33,10.91;8,112.66,466.34,393.33,10.91;8,112.66,479.89,127.28,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,371.43,452.79,134.56,10.91;8,112.66,466.34,150.09,10.91">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,273.25,466.34,232.74,10.91;8,112.66,479.89,48.41,10.91">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
