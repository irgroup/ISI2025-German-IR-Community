<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.69,15.42;1,88.78,106.66,44.30,15.43">University of Amsterdam at the CLEF 2023 SimpleText Track</title>
				<funder ref="#_mjCPgNG">
					<orgName type="full">Innovation Exchange Amsterdam</orgName>
				</funder>
				<funder ref="#_QbzkxZv">
					<orgName type="full">Netherlands Organization for Scientific Research (NWO CI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,57.28,11.96"><forename type="first">Roos</forename><surname>Hutter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,157.63,134.97,64.92,11.96"><forename type="first">Jop</forename><surname>Sutmuller</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,233.61,134.97,50.45,11.96"><forename type="first">Mary</forename><surname>Adib</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.34,134.97,50.89,11.96"><forename type="first">David</forename><surname>Rau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,373.69,134.97,57.18,11.96"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
							<email>kamps@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.69,15.42;1,88.78,106.66,44.30,15.43">University of Amsterdam at the CLEF 2023 SimpleText Track</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">94B0015D17BCD479B27B34E45B590662</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Storage and Retrieval</term>
					<term>Natural Language Processing</term>
					<term>Scientific Information Access</term>
					<term>Text Simplification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports on the University of Amsterdam's participation in the CLEF 2023 SimpleText track. Our overall goal is to investigate and remove barriers that prevent the general public from accessing scientific literature, hoping to promote science literacy among the general public. Our specific focus is to investigate the relation between the topical relevance and the text complexity of the retrieved information within the context of the track's setup. Our results suggest that text complexity is an essential aspect to consider for improving non-expert access to scientific information, and opens up new routes to develop effective scientific information access technology tailored to needs of the general public.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The advent of the internet and social media has been revolutionary in changing every aspect of information creation and information consumption. Whereas this comes with unprecedented strengths and new opportunities, it also comes with unprecedented risks due to potential misinformation and disinformation spreading easily.</p><p>The traditional antidote against misinformation is scientifically grounded information, and everyone agrees on the value and importance of science literacy. However, in practice, few non-experts consult scientific sources and rely on shallow information distributed on the web and in social media. One of the main reasons for avoiding the scientific literature is its presumed complexity. The CLEF 2023 SimpleText track investigates the barriers that ordinary citizens face when accessing scientific literature head-on, by making available corpora and tasks to address different aspects of the problem. For details on the exact track setup, we refer to the Track Overview paper CLEF 2023 LNCS proceedings <ref type="bibr" coords="1,323.59,528.62,11.32,10.91" target="#b0">[1]</ref>, as well as the detailed task overviews in the CEUR proceedings <ref type="bibr" coords="1,203.88,542.17,11.36,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,217.96,542.17,7.47,10.91" target="#b2">3,</ref><ref type="bibr" coords="1,228.16,542.17,7.57,10.91" target="#b3">4]</ref>.</p><p>We conduct an extensive analysis of the corpus of scientific abstracts and the three tasks of the track: Task 1 on content selection and avoiding complexity; Task 2 on complexity spotting in extracted sentences from scientific abstracts; and Task 3 on text simplification proper rewriting sentences from these abstracts.</p><p>The rest of this paper is structured as follows. Next, in Section 2 we discuss our experimental setup and the specific runs submitted. Section 3 discusses the results of our runs and provides a detailed analysis of the corpus and results for each task. We end in Section 4 by discussing our results and outlining the lessons learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experimental Setup</head><p>In this section, we will detail our approach for the three CLEF 2023 SimpleText track tasks.</p><p>For details of the exact task setup and results we refer the reader to the detailed overview of the track in Ermakova et al. <ref type="bibr" coords="2,215.20,219.05,11.43,10.91" target="#b0">[1]</ref>. The basic ingredients of the track are: Assessments For Task 1, there are new relevance assessments for 34 queries associated with the 5 articles from The Guardian (G16-G20, 17 queries) and 5 articles from Tech Xplore (T01-T05, 17 queries). For Task 2, evaluation is based on 592 distinct sentences, and 4,167 distinct sentence-term pairs (based on pooling) manually evaluated term limits (does the extracted term cover the entire concept) and difficulty (3 grades ranging from 'no explanation needed' to 'explanation required'). For Task 3, in addition to the train data on 648 sentences, evaluation is based on the manual simplifications of 245 sentences.</p><p>We created runs for all the three tasks of the track, which we will discuss in order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 1 This task requires ranking scientific abstracts in response to a non-expert, general query prompted by a popular science article.</head><p>We submitted ten runs in total, shown in Table <ref type="table" coords="2,318.31,611.50,3.81,10.91" target="#tab_1">1</ref>. We first submitted three runs focusing on regular information retrieval effectiveness. One is a vanilla baseline run on the provided Elastic Search index, using normal keyword query rather than quoted phrase queries (as in the provided examples). The other two are neural crossencoder rerankings of this run, based on zero-shot application of an MSMARCO trained ranker, reranking either the top 100, or the top 1k retrieved abstracts. 3  We submitted seven runs aiming to take the readability and/or credibility of the results into account. The first run simply filters out the most complex abstract per request, using a standard readability measure. The run is aiming to remove about 25% of the results, with the remaining abstracts in the same relevance order as in the original Elastic Search run. The next two runs perform a similar filter based on credibility where we filter both on recency and the number of citations. One run selects abstracts since 2005 with at least 3 citations (removing about 5% of results), and the other abstracts since 2014 with at least 4 citations (removing about 25% of results). The next two runs combine the credibility and readability filters, removing about 30% of results for 2005 and 3 citations filter, and removing about 46% of results for the 2014 and 4 citations filter.</p><p>The final two runs combine the scores of the cross-encoder reranker with readability scores, which may lead to a different order of results in the file. Specifically, the neural crossencoder score is combined with a score based on (14 -FKGL), promoting easy (i.e., low FKGL) abstracts and demoting complex (i.e., high FKGL) abstracts. The second variant still removes those abstracts with complexity higher than FKGL 14, while reranking those with lower FKGL in the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 2 What concept needs to be explained or rewritten in a given sentence, extracted from a scientific abstract.</head><p>We submitted a single run, also shown in Table <ref type="table" coords="3,317.77,634.75,3.81,10.91" target="#tab_1">1</ref>. Based on preliminary experiments, our submission is using an idf-based term weighting to locate the most rare terms. Specifically, we Task 3 Rewrite a sentence from a scientific abstract.</p><p>We submitted two runs shown in Table <ref type="table" coords="4,274.56,380.28,3.67,10.91" target="#tab_1">1</ref>. We use a standard text simplification model, based on the GPT-2 based keep it simple (KiS) model of Laban et al. <ref type="bibr" coords="4,362.79,393.83,11.42,10.91" target="#b4">[5]</ref>. We run a pretrained version of this model available from HuggingFace, <ref type="foot" coords="4,273.27,405.63,3.71,7.97" target="#foot_2">4</ref> in a zero-shot way on both the train and test corpus.</p><p>One of the main challenges of these models which generate the output is the risk of "hallucination," in which the model generates reasonable and credibly looking output that is not grounded on the input text. In preliminary experiments, we observed that was happening in particular on the end of the generation where additional content is generated, including entire extra sentences. We implemented a post-processing of the output that compares the input text to the generated output, and removes those sentences for which there is no direct overlap with the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>In this section, we will present the results of our experiments, in four self-contained subsections following the CLEF 2023 SimpleText Track corpus and tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Task 1: Content Selection</head><p>We discuss our results for Task 1, asking to retrieve scientific articles in response to a query based on a popular science article. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Retrieval effectiveness</head><p>Table <ref type="table" coords="5,116.52,331.45,5.17,10.91" target="#tab_2">2</ref> shows the performance of the Task 1 submissions on the test data. First, comparing the elastic search and neural rerankers, we see that the crossencoders lead to considerable improvement of retrieval effectiveness, on all evaluation measures. In particular, NDCG@10 increases from 0.3911 up to 0.4782. Second, for the credibility filters on the Elastic baseline, we see that promoting recent and more cited papers lead to improvements of retrieval effectiveness.</p><p>In particular, NDCG@10 improves from 0.3911 up to 0.4103. Third, for the readability filters on the Elastic baseline, we see that promoting more accessible papers lead to decrease of retrieval effectiveness. This is entirely expected as the relevance judgments did not consider the complexity of the abstracts: many relevant abstracts may have high text complexity. Fourth, the runs combining neural relevance and readability scores can lead to very similar retrieval effectiveness scores. In particular, the filter variant combining the neural crossencoder on the top 1k Elastic results, obtains an NDCG@10 of 0.4533. Our general conclusion is that the approaches promoting credibility and readability are still effective and obtain a very reasonable performance. The main aim of these runs is not to improve retrieval effectiveness, but to improve the experience of our non-expert user by aiming to retrieve relevant and accessible abstracts in the ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Analysis of retrieved papers</head><p>Some of the runs specifically target to retrieve easier to read abstracts, or are ranked on a combined score factoring in relevance and credibility or readability of the results. But to what extent do our approaches realize this?</p><p>Table <ref type="table" coords="5,128.69,624.66,5.17,10.91" target="#tab_3">3</ref> shows an analysis of the metadata and the text of the top retrieved articles (ti-tle+abstracts) over all topics in the train and test data.</p><p>Looking at credibility, we see that the baseline Elastic search already retrieves recent articles (mean 2012, median 2014) receiving reasonable numbers of citations (mean 13, median of 3). The credibility filters have a minor effect on recency (mean up to 2013, median up to 2015) and an increase in citations (mean up to 21, median up to 6). We also observe that the neural reranking also leads to a higher number of citations (mean up to 25, and median up to 4).</p><p>Looking at readability, we observe a fairly high level of text complexity for basic retrieval approaches, with average and median FKGL around 14 of the retrieved abstracts. The readability and credibility filters lead to limited reduction in text complexity over all 114 requests. The two runs combining the neural relevance scores with the readability scores are effective in significantly lowering the complexity of the retrieved abstracts, with a median FKGL of 11.2 and 12.4.</p><p>To put this into perspective: an FKGL of 11-12 corresponds to the reading level of an average user who finished compulsory education, whereas an FKGL of 14 corresponds to several years of university education. Hence, these approaches are able to rank easier to read results first, while still retrieving a very similar number of relevant results in terms of retrieval effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Task 2: Complexity Spotting</head><p>We continue with Task 2, asking to locate the most difficult concepts in a sentence extracted from a potentially relevant abstract, retrieved in response to a general query prompted by a popular science article. We submitted a single run, using an IDF based approach to find the least common term in the sentence.</p><p>Table <ref type="table" coords="6,127.65,458.84,5.17,10.91" target="#tab_4">4</ref> shows the results of our official submission to Task 2. Our run retrieved a total of 675,090 single word terms for 135,508 unique sentences. A total of 1,295 terms in 592 sentences is evaluated, and a large fraction of highlighted terms (89%) has correct term limits.</p><p>Term difficulty is judged on a scale from 0 (no explanation required), 1 (explanation helps) to 2 (explanation necessary). A fair fraction of terms has a high level of difficulty (27% of the evaluated terms). Of these a high fraction has the correct term limits (78%).</p><p>Our results indicate that while the problem of identifying complex terms is a very hard problem in general, basic features such as IDF are already very useful as a first step and perform unexpectedly competitively. The main reason is the restricted choice of options given the small number of words in each sentence, making IDF a powerful initial filter for candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Task 3: Text Simplification</head><p>We continue with Task 3, asking to perform text simplification proper, by rewriting a sentence extracted from a potentially relevant abstract, retrieved in response to a general query prompted by a popular science article. ⃒ ⃒ We design a framework , which integrates combines collective intelligence and machine intelligence , to help identify misinformation .</p><p>⃒ ⃒ The basic idea is : ( 1 ) automatically index the expertise of users according to their microblog contents posts ; and ( 2 ) match the experts with the same information given to suspected misinformation .</p><p>⃒ ⃒ By sending the suspected misinformation to appropriate experts , we can collect gather the assessments of experts relevant data to judge the credibility of the information , and help refute misinformation . ⃒ ⃒ In this paper , we focus on look at expert finding for misinformation identification . We ask experts to identify the source of the misinformation , and how it is spread .</p><p>⃒ ⃒ We propose a tag-based method approach to index indexing the expertise of microblog users with social tags . Our approach will allow us to identify which posts are most relevant and which are not .</p><p>⃒ ⃒ Experiments on a real world dataset demonstrate show the effectiveness of our method approach for expert finding with respect to misinformation identification in microblogs .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Approaches</head><p>Our experiments are based on the zero-shot application of an existing neural text simplification model from <ref type="bibr" coords="7,145.17,413.68,11.58,10.91" target="#b4">[5]</ref>, called the Keep it Simple (KiS) model. The model is based on GPT-medium, using a straightforward unsupervised training task with an explicit loss in terms of fluency, saliency, and simplicity. We are interested in this model as it is fully trained in an unsupervised way, and could be retrained or fine-tuned for the corpus or other academic texts without the need for huge human training data. Table <ref type="table" coords="7,126.59,481.42,4.98,10.91" target="#tab_5">5</ref> shows an example output simplification, combining the input sentences belonging to the abstract of documents 2111507945 retrieved for query G07.1. We show here deletions and insertions relative to the source input sentences (in this case 8 in total). Many simplifications are revisions of the input, but we also observe that sometimes an entire sentence is inserted (shown as xxx). Modern models such as ours generate the simplification, which may lead to additional output being generated at the end. Recall that the example as shown in Table <ref type="table" coords="7,500.81,549.17,5.17,10.91" target="#tab_5">5</ref> merges 8 separate input sentences in the train data (indicated by ⃒ ⃒ ), making this occur multiple times at the end of three of the inputs.</p><p>For human readers, detecting such sentences by simply inspecting the output is hard, as they are very reasonable completions generated with awareness of the preceding context. We experiment with unsupervised approaches to tackle the generation of spurious generation, by post-processing the output in relation to the original input. Similar to the edits as shown in the table, we process input and output, and remove any sentence that has been inserted without grounding in the input. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Results and Analysis</head><p>Table <ref type="table" coords="8,114.86,237.02,4.97,10.91" target="#tab_6">6</ref> shows the results of applying the KiS model zero-shot on the train (top) and test (bottom) data in terms of the generated output. We make a number of observations. First, we observe reasonable SARI and BLEU scores for the scientific text, with a SARI of 0.36 for train and 0.33 for test sentences. To put this number into perspective, the original paper reports scores in the range of 0.26 to 0.43 on a Wikipedia corpus <ref type="bibr" coords="8,377.88,291.22,11.43,10.91" target="#b5">[6]</ref>.</p><p>Second, we see that our model is able to reduce the text complexity to the 11-12 FKGL range corresponding to the exit level of compulsory education suitable for the average adult reader. While inspection of examples, such as shown in Table <ref type="table" coords="8,368.48,331.87,3.78,10.91" target="#tab_5">5</ref>, show conservative edits it is encouraging that the readability measures are considerably lower than for the original scientific text.</p><p>Third, our post-processing to remove spurious generation has a positive effect throughout, leading to higher SARI and BLEU scores against the reference simplification. As this is affection only a fraction of the sentences, the effect on SARI and BLEU is modest. As we typically remove an entire sentence, the effect on compression rates is high, and it leads to considerable improvements of the Levenshtein similarity.</p><p>Table <ref type="table" coords="8,126.49,440.26,4.97,10.91" target="#tab_7">7</ref> quantifies how often such spurious generation occurs. Over the train data, consisting of 648 sentences, we remove additional sentences unwarranted by the original input in 126 cases. Over the large test data, consisting of 152,072 sentences, we remove additional sentences unwarranted by the original input in 40,449 cases. Over these samples, this affects between 19.4% (train) and 26.6% (test) of the cases. In all these cases we remove this additional content in a post-processing step, ensuring all the output is grounded on input sentences.</p><p>While our post-processing already has a favorable effect on the evaluation measures, we feel that it has great benefits not reflected by these scores. Our post-processing is specifically, and only, removing spurious generation (or "hallucination") of the output. These results highlight and quantify the severity of this problem in generative text simplification models such as our GPT2 model. At the same time, it offers a practical approach to tackle this undesirable aspect head-on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion and Conclusions</head><p>This paper detailed the University of Amsterdam's participation in the CLEF 2023 SimpleText track. We conducted a range of experiments, for each of the three tasks of the track. For Task 1, we observed the effectiveness of zero-shot neural rankers for scientific text. We also found that specific credibility filters privileging recent or highly cited papers can even improve retrieval effectiveness. Readability filters can retain retrieval effectiveness on par with the best relevance rankers. This is an important and surprising finding as these approaches avoid complexity by retrieving only, or first, those abstracts at a readability level assumed to be suitable for a non-expert user. Hence the impact on the end-user in the track's use-case is even greater than indicated by the retrieval effectiveness evaluation.</p><p>For Task 2, we submitted preliminary approaches based on standard term weighting exploiting the corpus statistics or language model of a large scientific corpus. Our main finding was that although complex concept detection is a very hard task in general, it is a very viable and feasible task when the context is restricted to only the terms in a single sentence.</p><p>For Task 3, we experimented with a zero-shot pretrained GPT-2 based text simplification approach, Our main analysis was an extensive analysis of generative text simplification approaches, and to quantify the number and fraction of cases in which a generated output sentence is not warranted by any input sentence token. This is an actionable finding that can be immediately exploited to post-process the output in an unsupervised way, and to remove spuriously generated content. As this involves only a small fraction of the sentences, this leads to a small but consistent improvement of the evaluation scores. In fact, the standard text simplification evaluation measures are remarkably insensitive to hallucinated content, leading only to a minor penalty. However, the spurious content is very difficult spot by end-users, in particular nonexperts, as it is a natural continuation of the previous text-yet at the same time completely unsupported by the original scientific abstract. Hence the impact on the end-user in the track's use-case is again far greater than indicated by the text simplification evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,89.29,241.10,418.53,199.85"><head></head><label></label><figDesc>Corpus The CLEF 2023 SimpleTrack Corpus consists of 4.9 million bibliographic records, including 4.2 million abstracts, and detailed information about authors/affiliations/citations. Context There are 40 popular science articles, with 20 from The Guardian 1 and 20 from Tech Xplore.</figDesc><table /><note coords="2,147.11,288.78,3.71,7.97;2,89.29,312.87,416.69,10.91;2,116.56,326.42,389.43,10.91;2,116.56,339.97,217.02,10.91;2,89.29,362.30,416.69,10.91;2,116.56,375.85,389.63,10.91;2,116.24,389.40,389.74,10.91;2,116.56,402.95,389.42,10.91;2,116.56,416.49,389.42,10.91;2,116.31,430.04,131.41,10.91"><p><p><p>2</p>Requests For Task 1, there are 114 requests with 1-4 queries per context article, 47 requests are based on The Guardian and 67 on TechXplore. Abstracts retrieved for these requests form the corpus for the remaining Tasks 2 and 3.</p>Train Data For Task 1, there are relevance judgments for 29 requests (corresponding to 15 Guardian articles, G01-G15), with 23 queries having more than 10 relevant abstracts. For Task 2, there are 203 train sentences (with ground truth complex terms/concepts) and 2,234 (small), 4,797 (medium), and 152,072 (large) test sentences. For Task 3, there are 648 train sentences with human simplifications, and again 2,234 (small), 4,797 (medium), and 152,072 (large) test sentences.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,88.99,90.49,415.00,217.81"><head>Table 1</head><label>1</label><figDesc>CLEF 2013 SimpleText Track Submissions</figDesc><table coords="3,89.29,122.01,414.70,186.28"><row><cell cols="2">Task Run</cell><cell>Description</cell></row><row><cell>1</cell><cell>UAms_Task_1_Elastic</cell><cell>Vanilla elastic run (queries without quotes)</cell></row><row><cell>1</cell><cell>UAms_Task_1_CE100</cell><cell>Minilm12 full BERT based crossencoder reranker on top 100</cell></row><row><cell>1</cell><cell>UAms_Task_1_CE1k</cell><cell>Minilm12 full BERT based crossencoder reranker on top 1k</cell></row><row><cell>1</cell><cell>UAms_Task_1_ElF_Read25</cell><cell>Elastic filtered on Readability (rel)</cell></row><row><cell>1</cell><cell>UAms_Task_1_ElF_Cred53</cell><cell>Elastic filtered on Credibility (rel)</cell></row><row><cell>1</cell><cell>UAms_Task_1_ElF_Cred44</cell><cell>Elastic filtered on Credibility (rel)</cell></row><row><cell>1</cell><cell cols="2">UAms_Task_1_ElF_Cred53Read Elastic filtered on Credibility and Readability (rel)</cell></row><row><cell>1</cell><cell cols="2">UAms_Task_1_ElF_Cred44Read Elastic filtered on Credibility and Readability (rel)</cell></row><row><cell>1</cell><cell>UAms_Task_1_CE1k_Combine</cell><cell>Neural ranker combining relevance and readability (comb)</cell></row><row><cell>1</cell><cell>UAms_Task_1_CE1k_Filter</cell><cell>Neural ranker combining relevance and readability (comb)</cell></row><row><cell>2</cell><cell>UAms_Task_2_RareIDF</cell><cell>IDF baseline using single word terms only</cell></row><row><cell>3</cell><cell cols="2">UAms_Task_3_Large_KIS150_Clip GPT-2 based text simplification</cell></row><row><cell>3</cell><cell>UAms_Task_3_Large_KIS150</cell><cell>GPT-2 TS with post-processing removing hallucination</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.96,90.49,417.29,258.40"><head>Table 2</head><label>2</label><figDesc>Evaluation of SimpleText Task 1 (Test data)</figDesc><table coords="4,89.29,122.01,416.69,162.15"><row><cell>Run</cell><cell>MRR</cell><cell>Precision</cell><cell></cell><cell></cell><cell>NDCG</cell><cell>Bpref MAP</cell></row><row><cell></cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>5</cell><cell>10</cell><cell>20</cell></row><row><cell>Elastic</cell><cell cols="6">0.6424 0.4353 0.4059 0.2990 0.4165 0.3911 0.3315 0.2502 0.1895</cell></row><row><cell>CE 100</cell><cell cols="6">0.7050 0.5118 0.4912 0.3657 0.5004 0.4782 0.4007 0.2616 0.2011</cell></row><row><cell>CE 1k</cell><cell cols="6">0.6329 0.4765 0.4735 0.3578 0.4502 0.4448 0.3816 0.2797 0.2051</cell></row><row><cell>Read. filter</cell><cell cols="6">0.6076 0.3824 0.3735 0.2833 0.3723 0.3539 0.3105 0.2194 0.1522</cell></row><row><cell cols="7">Cred. filter (2005/3) 0.6429 0.4235 0.4088 0.3010 0.4043 0.3883 0.3292 0.2454 0.1833</cell></row><row><cell cols="7">Cred. filter (2014/4) 0.6888 0.4294 0.4324 0.2951 0.4215 0.4103 0.3300 0.2395 0.1719</cell></row><row><cell>C+R filter (2005/3)</cell><cell cols="6">0.6088 0.3765 0.3676 0.2784 0.3623 0.3469 0.3042 0.2133 0.1456</cell></row><row><cell>C+R filter (2014/4)</cell><cell cols="6">0.6625 0.4118 0.3971 0.2775 0.3902 0.3723 0.3101 0.2123 0.1403</cell></row><row><cell>Rel+Read</cell><cell cols="6">0.5880 0.4412 0.4147 0.3098 0.3854 0.3706 0.3250 0.2700 0.1865</cell></row><row><cell>Rel+Read filter</cell><cell cols="6">0.6403 0.5000 0.4765 0.2941 0.4754 0.4533 0.3334 0.2727 0.1936</cell></row></table><note coords="4,89.29,310.88,416.90,10.91;4,89.29,324.43,416.96,10.91;4,88.96,337.97,87.46,10.91"><p>used all train and test sentences combined as a reference corpus to calculate document (or rather sentence) frequencies, and use this to rank each term in the source sentence by increasing DF (or decreasing IDF).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,88.98,90.49,417.00,193.68"><head>Table 3</head><label>3</label><figDesc>Analysis of SimpleText Task 1 output (over all 114 queries)</figDesc><table coords="5,89.29,122.01,416.70,162.15"><row><cell>Run</cell><cell>Queries Top</cell><cell>Year</cell><cell cols="2">Citations</cell><cell>Length</cell><cell>FKGL</cell></row><row><cell></cell><cell></cell><cell cols="5">Avg Med Avg Med Avg Med Avg Med</cell></row><row><cell>Elastic</cell><cell cols="3">114 10 2012.0 2014 13.1</cell><cell cols="3">3.0 1000.0 995.5 14.0 13.9</cell></row><row><cell>CE 100</cell><cell cols="3">114 10 2011.7 2013 25.2</cell><cell cols="3">4.0 1102.3 1041.5 14.2 14.1</cell></row><row><cell>CE 1k</cell><cell cols="3">114 10 2011.8 2014 21.6</cell><cell cols="3">3.0 1142.3 1047.0 14.2 14.1</cell></row><row><cell>Read. filter</cell><cell cols="3">114 10 2011.6 2013 10.9</cell><cell cols="3">2.0 843.8 894.0 13.8 13.8</cell></row><row><cell>Cred. filter (2005/3)</cell><cell cols="3">114 10 2012.6 2014 13.6</cell><cell cols="3">3.0 1016.4 1010.0 14.0 14.0</cell></row><row><cell>Cred. filter (2014/4)</cell><cell cols="3">114 10 2013.0 2015 20.6</cell><cell cols="3">6.0 1052.0 1055.5 14.1 14.2</cell></row><row><cell>C+R filter (2005/3)</cell><cell cols="3">114 10 2012.2 2014 12.4</cell><cell cols="3">3.0 851.5 898.0 13.9 13.8</cell></row><row><cell>C+R filter (2014/4)</cell><cell cols="3">114 10 2012.7 2015 16.4</cell><cell cols="3">6.0 876.7 936.0 13.9 13.9</cell></row><row><cell>Rel+Read</cell><cell cols="3">114 10 2011.6 2014 16.9</cell><cell cols="3">3.0 992.9 909.0 11.2 11.2</cell></row><row><cell>Rel+Read filter</cell><cell cols="3">114 10 2011.5 2014 20.8</cell><cell cols="3">3.0 1056.8 982.0 12.2 12.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,88.99,90.49,416.99,75.13"><head>Table 4</head><label>4</label><figDesc>Results for the SimpleText Task 2: Selecting rare terms</figDesc><table coords="6,89.29,122.01,416.69,43.60"><row><cell>Run</cell><cell>Total</cell><cell>Evaluated</cell><cell></cell><cell>Score</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">+Limits</cell><cell></cell><cell>+Limits</cell></row><row><cell>UAms_Task_2_RareIDF</cell><cell>675090</cell><cell>1293</cell><cell>1145</cell><cell>309</cell><cell>241</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,88.99,90.49,418.65,105.95"><head>Table 5</head><label>5</label><figDesc>Example of SimpleText Task 3 output versus input: deletions, insertions, and whole sentence insertions</figDesc><table coords="7,89.29,122.23,418.35,74.21"><row><cell cols="2">Topic Document Output</cell></row><row><cell cols="2">G07.1 2111507945 The growth of social media provides a convenient communication scheme way for</cell></row><row><cell cols="2">people to communicate , but at the same time it becomes a hotbed of misinforma-</cell></row><row><cell>tion .</cell><cell>⃒ ⃒ The This wide spread of misinformation over social media is injurious to</cell></row><row><cell cols="2">public interest . It is difficult to separate fact from fiction when talking about social</cell></row><row><cell cols="2">media .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.99,90.49,416.99,99.26"><head>Table 6</head><label>6</label><figDesc>Results for SimpleText Task 3: zero-shot GPT2 text simplification</figDesc><table coords="8,89.29,122.01,416.70,67.73"><row><cell>Run</cell><cell>#Snt</cell><cell>FKGL</cell><cell>SARI</cell><cell>BLEU</cell><cell>Comp.</cell><cell>Split</cell><cell>L.Sim.</cell></row><row><cell>UAms_Task_3_Large_KIS150</cell><cell>648</cell><cell>11.40</cell><cell>36.38</cell><cell>25.82</cell><cell>1.17</cell><cell>1.42</cell><cell>0.79</cell></row><row><cell>UAms_Task_3_Large_KIS150_Clip</cell><cell>648</cell><cell>11.93</cell><cell>36.66</cell><cell>28.68</cell><cell>0.99</cell><cell>1.23</cell><cell>0.85</cell></row><row><cell>UAms_Task_3_Large_KIS150</cell><cell>245</cell><cell>10.51</cell><cell>33.02</cell><cell>14.60</cell><cell>1.27</cell><cell>1.48</cell><cell>0.76</cell></row><row><cell>UAms_Task_3_Large_KIS150_Clip</cell><cell>245</cell><cell>11.13</cell><cell>33.47</cell><cell>16.60</cell><cell>1.02</cell><cell>1.23</cell><cell>0.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,88.99,90.49,416.99,69.87"><head>Table 7</head><label>7</label><figDesc>Results for SimpleText Task 3: Spurious generation</figDesc><table coords="9,89.29,122.01,416.69,38.34"><row><cell>Input</cell><cell># Input Sentences</cell><cell># Spurious Content</cell><cell>Fraction Spurious Content</cell></row><row><cell>Train</cell><cell>648</cell><cell>126</cell><cell>0.1944</cell></row><row><cell>Test Large</cell><cell>152,072</cell><cell>40,449</cell><cell>0.2660</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,660.08,139.34,8.97"><p>https://www.theguardian.com/science</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,108.93,671.04,85.54,8.97"><p>https://techxplore.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,108.93,671.01,192.89,8.97"><p>https://huggingface.co/philippelaban/keep_it_simple</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was conducted as part of the final research projects of the <rs type="institution">Bachelor in Artificial Intelligence at the University of Amsterdam</rs>, This research is funded in part by the <rs type="funder">Netherlands Organization for Scientific Research (NWO CI</rs> # CISC.<rs type="grantNumber">CC.016</rs>), and the <rs type="funder">Innovation Exchange Amsterdam</rs> (<rs type="grantName">POC grant</rs>). Views expressed in this paper are not necessarily shared or endorsed by those funding the research.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QbzkxZv">
					<idno type="grant-number">CC.016</idno>
				</org>
				<org type="funding" xml:id="_mjCPgNG">
					<orgName type="grant-name">POC grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,107.59,642.48,398.40,10.91;9,107.59,656.03,399.60,10.91;9,107.59,669.58,399.60,10.91;10,107.59,86.97,398.40,10.91;10,107.59,100.52,340.18,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,434.58,642.48,71.41,10.91;9,107.59,656.03,310.78,10.91">Overview of the CLEF 2023 SimpleText Lab: Automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,223.77,86.97,282.21,10.91;10,107.59,100.52,105.26,10.91">CLEF&apos;23: Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<title level="s" coord="10,220.10,100.52,155.05,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,114.06,399.69,10.91;10,107.59,127.61,252.71,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,301.80,114.06,205.47,10.91;10,107.59,127.61,188.01,10.91">Overview of the CLEF 2023 SimpleText Task 1: Passage selection for a simplified summary</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,141.16,399.68,10.91;10,107.59,154.71,258.38,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,301.05,141.16,206.22,10.91;10,107.59,154.71,194.57,10.91">Overview of the CLEF 2023 SimpleText Task 2: Identifying and explaining difficult concepts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,168.26,398.40,10.91;10,107.59,181.81,122.52,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<title level="m" coord="10,221.32,168.26,284.67,10.91;10,107.59,181.81,59.09,10.91">Overview of the CLEF 2023 SimpleText Task 3: Scientific text simplification</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,195.36,400.24,10.91;10,107.59,208.91,398.40,10.91;10,107.59,222.46,398.40,10.91;10,107.59,236.01,399.60,10.91;10,107.59,249.56,319.96,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,348.38,195.36,159.44,10.91;10,107.59,208.91,153.97,10.91">Keep it simple: Unsupervised simplification of multi-paragraph text</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Laban</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.498</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.acl-long.498" />
	</analytic>
	<monogr>
		<title level="m" coord="10,284.94,208.91,221.04,10.91;10,107.59,222.46,398.40,10.91;10,107.59,236.01,395.31,10.91">ACL/IJCNLP&apos;21: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6365" to="6378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,263.11,398.39,10.91;10,107.59,276.66,399.69,10.91;10,107.59,290.20,315.14,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,369.61,263.11,136.37,10.91;10,107.59,276.66,142.43,10.91">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00107</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00107.doi:10.1162/tacl\_a\_00107" />
	</analytic>
	<monogr>
		<title level="j" coord="10,257.85,276.66,148.28,10.91">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,107.59,303.75,399.68,10.91;10,107.59,317.30,399.59,10.91;10,107.59,330.85,22.69,10.91" xml:id="b6">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="10,369.48,303.75,137.79,10.91;10,107.59,317.30,194.76,10.91">Working Notes of CLEF 2023: Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="10,309.83,317.30,170.67,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
