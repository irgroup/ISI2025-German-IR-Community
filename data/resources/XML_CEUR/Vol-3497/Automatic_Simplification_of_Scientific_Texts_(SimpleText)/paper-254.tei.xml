<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,70.82,76.25,439.15,16.72;1,509.91,73.20,5.60,11.04;1,70.82,112.61,213.48,10.04">CLEF 2023: Scientific Text Simplification and General Audience 1 Notebook for the SimpleText Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,70.82,167.98,79.37,10.91"><forename type="first">Felix</forename><surname>Ohnesorge</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Kiel</orgName>
								<address>
									<postCode>24118</postCode>
									<settlement>Kiel</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">CLEF</orgName>
								<address>
									<postCode>2023</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,160.22,167.98,113.95,10.91"><forename type="first">Mari</forename><surname>Ángeles Gutiérrez</surname></persName>
							<email>mariangeles.gutierrez@uca.es</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Cádiz</orgName>
								<address>
									<postCode>11003</postCode>
									<settlement>Cádiz</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.53,167.98,59.18,10.91"><forename type="first">Julia</forename><surname>Plichta</surname></persName>
							<email>j.plichta.162@studms.ug.edu.pl</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Gdańsk</orgName>
								<address>
									<postCode>80-309</postCode>
									<settlement>Gdańsk</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,70.82,76.25,439.15,16.72;1,509.91,73.20,5.60,11.04;1,70.82,112.61,213.48,10.04">CLEF 2023: Scientific Text Simplification and General Audience 1 Notebook for the SimpleText Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9A1773426238EEF196DB88464E1FF0FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>Scientific Information Access</term>
					<term>Text Simplification</term>
					<term>Sentence Transformers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This project aimed to enhance comprehension of scientific texts for a general audience through two tasks: Complexity Spotting and Text Simplification. Complexity Spotting involved ranking and explaining difficult concepts using the SimpleT5 model, overcoming challenges like lack of feedback and time constraints. Text Simplification utilized SimpleT5 and GPT-3 models to provide simplified versions, facing challenges such as time limitations, token usage, and limited GPU resources. Evaluation showed SimpleT5 outperforming GPT-3 in key metrics. Finally, the experiment demonstrated the effectiveness of models and potential for future advancements in simplifying scientific text.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Task 2: Complexity Spotting: Identifying and Explaining Difficult Concepts for a General Audience</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of these two tasks of the SimpleText lab, organized as part of the Clef 2023 conference <ref type="bibr" coords="2,161.54,188.38,12.69,10.91" target="#b0">[1]</ref>, was, in this case, to identify and explain difficult concepts in a scientific text to assist readers in understanding complex information. Participants were required to rank the difficulty of up to five terms and provide short explanations for each identified difficult term. The provided passages are treated as independent sentences, allowing for repetition of difficult terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Tasks performed</head><p>The participant used the SimpleT5 model for this task. The workflow followed the following steps:</p><p>a. Train Dataset Preparation -created a train dataset with columns "source_text" and "target_text" and added the prefix "identify difficult term: " to each source_text. b. Model Training -the pretrained SimpleT5 model was trained on the train dataset for five epochs. The best model was selected based on the performance after the second epoch, with a train loss of 0.5293 and a validation loss of 1.324. c. Test Dataset Preparation -prepared a large test dataset and added the prefix "identify difficult term: " to each source_text. d. Predictions -to enhance efficiency, the large dataset was split into 100 chunks.</p><p>Partial predictions were performed, saved in JSON files, and subsequently joined together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Challenges Faced</head><p>The participant faced the following challenges during the task: a. Lack of feedback -Unfortunately, the participant did not receive any feedback on the submitted results, making it difficult to assess the effectiveness of the approach. b. Time constraints -Due to time limitations, the participant was unable to explore alternative models or complete task 2.2 within the given timeframe. c. Time-intensive predictions -Generating predictions for the large dataset took a significant amount of time. For each sentence, the model extracted only one difficult term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In conclusion, the participant made an attempt to tackle the complexity spotting task using the SimpleT5 model. Although the workflow was successfully implemented, the lack of feedback and time constraints hindered further analysis and improvement. Additionally, the time-intensive nature of predictions for the large dataset limited the model's output to only one difficult term per sentence. Future work could involve evaluating alternative models, addressing the challenges faced, and enhancing the performance and efficiency of the complexity spotting task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 3: Text Simplification: Scientific Text Simplification 1. Introduction</head><p>The task focuses on providing simplified versions of text passages, specifically popular science articles and queries matched with abstracts of scientific papers. The evaluation of the simplifications includes assessing complexity, errors, and information distortion <ref type="bibr" coords="3,106.82,364.69,12.69,10.91" target="#b1">[2]</ref>. Text complexity and simplification have been extensively studied in linguistics, education science, and natural language processing. Simplified texts are valuable for non-native speakers, young readers, individuals with reading disabilities, and those with lower levels of education. As Ermakova et al. refers <ref type="bibr" coords="3,396.54,412.21,12.69,10.91" target="#b2">[3]</ref>, text complexity and simplification have been extensively studied in linguistics, education science, and natural language processing. Simplified texts are valuable for non-native speakers, young readers, individuals with reading disabilities, and those with lower levels of education. In 2023, the training and evaluation data have been expanded, and large-scale automatic evaluation measures, along with small-scale human evaluation, are utilized; however, defining the desired output of simplification remains a challenge, as traditional readability scores only consider word and sentence length, while vocabulary-based metrics overlook information distortion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Tasks performed</head><p>The participant employed two models, SimpleT5 and GPT-3, to perform the text simplification task. The workflow followed these steps: a. Prepared a train dataset by merging input and output sentences. b. Added the prefix "simplify: " to each source_text. For SimpleT5: c. Trained a pretrained SimpleT5 model on the train dataset for five epochs. The best model was selected based on the performance after the first epoch, with a train loss of 0.9715 and a validation loss of 1.1263. d. Predicted simplified sentences using the trained model on a small test dataset. For GPT-3: e. Split the test dataset into 20 chunks for efficiency. f. Performed partial predictions using GPT-3 and saved the results in JSON files. g. Joined all JSON files to compile the predictions. Note: The small dataset was chosen to reduce evaluation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Challenges Faced</head><p>The task of scientific text simplification encountered several challenges, including:</p><p>a. Time limitations: The project faced time constraints, which affected various aspects of the experiment, such as dataset preparation, model training, and evaluation. The limited timeframe required balancing efficiency and accuracy in the implementation process. b. Time-intensive predictions: Predicting simplified sentences using models like SimpleT5 and GPT-3 can be time-consuming, especially when dealing with large datasets. Generating predictions for each source sentence from the test dataset proved to be a time-intensive task, resulting in potential delays and longer evaluation times. c. Costly predictions in terms of tokens: Text simplification tasks often involve working with large amounts of text, which requires a significant number of tokens. Models like GPT-3 have token limits, and exceeding these limits incurs additional costs. Managing the token usage and optimizing the predictions within the token constraints were essential to avoid excessive expenses. d. Limited GPU resources in Google Colab: Google Colab, a widely used platform for training and inference, provides limited access to GPUs. This limitation can impact the efficiency and speed of the prediction process, particularly when dealing with resource-intensive models like GPT-3. Managing and optimizing GPU resources was crucial to mitigate the challenges posed by limited availability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation Results</head><p>The evaluation results for both models, GPT-3 and SimpleT5, are as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis of the Results</head><p>Based on the evaluation metrics, it can be observed that SimpleT5 outperformed GPT-3 in terms of SARI, BLEU, compression ratio, sentence splits, Levenshtein similarity, and lexical complexity score. SimpleT5 achieved higher scores in most metrics, indicating better quality in terms of similarity to the reference simplifications, concise output, preserved sentence boundaries, and lower lexical complexity. However, SimpleT5 had a higher FKGL score, suggesting slightly more complex text compared to GPT-3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In conclusion, the task of scientific text simplification presented various challenges, including time limitations, time-intensive predictions, and costly predictions in terms of tokens and limited GPU resources. Despite these challenges, the experiment effectively showcased the effectiveness of models such as SimpleT5 and GPT-3 in simplifying scientific text. Particularly, the SimpleT5 model demonstrated superior performance compared to GPT-3, as evidenced by its higher scores in evaluation metrics. This indicates that SimpleT5 provided better results in terms of generating simplified versions of scientific text passages. The findings highlight the potential of advanced models like SimpleT5 for achieving high-quality simplifications in the scientific domain. To further enhance the task, future work can explore alternative models and techniques to improve efficiency and address the challenges faced. Additionally, considering the use of alternative platforms or cloud-based solutions with increased GPU resources could help mitigate the limitations encountered. By addressing these challenges and exploring new avenues, the field of scientific text simplification can continue to advance and provide valuable simplified versions of complex scientific content.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,106.82,609.78,417.38,10.91;5,106.82,625.62,417.63,10.91;5,106.82,641.46,417.54,10.91;5,106.82,657.42,417.43,10.91;5,106.82,673.26,417.37,10.91;5,106.82,689.10,417.66,10.91;5,106.82,704.94,312.05,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,229.63,625.62,294.82,10.91;5,106.82,641.46,160.41,10.91">Overview of SimpleText -CLEF-2023 track on Automatic Simplification of Scientific Texts</title>
		<author>
			<persName coords=""><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hosein</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,407.98,673.26,116.21,10.91;5,106.82,689.10,417.66,10.91;5,106.82,704.94,241.46,10.91">Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<editor>
			<persName><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Theodora</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefanos</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohammad</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michalis</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guglielmo</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference of the CLEF Association<address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="6,106.82,73.64,417.51,10.91;6,106.82,89.62,417.32,10.91;6,106.82,105.46,153.99,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,106.82,89.62,337.27,10.91">Reference-Less Quality Estimation of Text Simplification Systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P.-E</forename><surname>Mazaré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><forename type="middle">V</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="http://arxiv.org/abs/1901.10746" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.82,152.02,417.38,10.91;6,106.82,167.98,417.45,10.91;6,106.82,183.82,278.93,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,221.33,167.98,231.84,10.91">CLEF 2023 SimpleText Track: What Happens if</title>
		<author>
			<persName coords=""><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Olivier</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hosein</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-28241-6_62</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,456.17,167.98,68.10,10.91;6,106.82,183.82,108.68,10.91">General Users Search Scientific Texts</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
