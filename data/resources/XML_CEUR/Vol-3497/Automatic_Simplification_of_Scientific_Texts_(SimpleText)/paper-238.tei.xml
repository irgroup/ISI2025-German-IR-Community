<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,361.11,15.42;1,89.29,106.66,343.76,15.42">Overview of the CLEF 2023 SimpleText Task 1: Passage Selection for a Simplified Summary</title>
				<funder ref="#_89KUyTR">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,62.33,11.96"><forename type="first">Éric</forename><surname>Sanjuan</surname></persName>
							<email>eric.sanjuan@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Avignon Université</orgName>
								<address>
									<settlement>LIA</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.27,134.97,72.03,11.96"><forename type="first">Stéphane</forename><surname>Huet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Avignon Université</orgName>
								<address>
									<settlement>LIA</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.94,134.97,57.18,11.96"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.12,134.97,79.43,11.96"><forename type="first">Liana</forename><surname>Ermakova</surname></persName>
							<email>liana.ermakova@univ-brest.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">Université de Bretagne Occidentale</orgName>
								<address>
									<settlement>HCTI</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,361.11,15.42;1,89.29,106.66,343.76,15.42">Overview of the CLEF 2023 SimpleText Task 1: Passage Selection for a Simplified Summary</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">E9A547624FDABD995832184CA0BC6662</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>information retrieval</term>
					<term>scientific documents</term>
					<term>text simplification</term>
					<term>scientific information retrieval</term>
					<term>non-expert queries</term>
					<term>press outlets</term>
					<term>query-document relationships (Q-rels)</term>
					<term>popularized science</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an overview of the CLEF 2023 SimpleText Task 1: Content Selection, asking systems to retrieve scientific abstracts in response to a query prompted by a popular science article. Overall, the SimpleText track provides an evaluation platform for the automatic simplification of scientific texts. We discuss the details of the task set-up. First, the SimpleText Corpus with over 4 million academic papers and abstracts. Second, the Topics based on 40 popular science articles in the news and the 114 Queries prompted by them. Third, the Formats of requests and results, the Evaluation labels and Evaluation measures used. Fourth, the Results of the runs submitted by our participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper presents an overview of the first task in the SimpleText track on automatic simplification of scientific texts following up on the CLEF 2021 SimpleText Workshop <ref type="bibr" coords="1,472.70,418.76,13.00,10.91" target="#b0">[1]</ref> and CLEF 2022 SimpleText Track <ref type="bibr" coords="1,219.19,432.31,11.41,10.91" target="#b1">[2]</ref>. The main goal of the SimpleText track is to provide data and benchmarks to advance research in this area. This paper focuses on Task 1: What is in (or out)? Selecting passages to include in a simplified summary. This task is part of a pipeline with the two other SimpleText tasks, namely Task 2: What is unclear? Difficult concept identification and explanation and Task 3: Rewrite this! Given a query, simplify passages from scientific abstracts. For a comprehensive understanding of the other tasks, the overview papers of Task 2 <ref type="bibr" coords="1,473.79,500.06,12.91,10.91" target="#b2">[3]</ref> and Task 3 <ref type="bibr" coords="1,120.29,513.61,11.43,10.91" target="#b3">[4]</ref>, as well as the Track overview paper <ref type="bibr" coords="1,300.82,513.61,11.43,10.91" target="#b4">[5]</ref>, provide detailed information and insights. primary challenge is the difficulty in comprehending scientific literature, which arises from its reliance on specialized knowledge and the utilization of complex terminology. As a result, non-experts may face obstacles when attempting to understand and interpret scientific papers. Retrieval of relevant yet credible and understandable scientific documents is still a challenge as search engines virtually ignore documents' difficulty.</p><p>The rest of the paper is organized as follows. Section 2 provides details on the datasets utilized and the evaluation metrics employed in the study. Section 3 offers an overview of the retrieval approaches adopted by the participants, specifically focusing on the scientific text. In Section 4, the official submissions' results are presented and discussed. Finally, Section 5 summarizes the findings and outlines potential directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SimpleText Task 1 Test Collection</head><p>This section provides an overview of the resulting test collection, detailing the corpus, the topics and queries, the input and output format, as well as the used evaluation measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Corpus: DBLP abstracts</head><p>The corpus utilized in this task is the Citation Network Dataset: DBLP+Citation, ACM Citation network (12th version released in 2020<ref type="foot" coords="2,264.92,342.61,3.71,7.97" target="#foot_1">1</ref> ) <ref type="bibr" coords="2,272.82,344.36,11.10,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,286.70,344.36,9.03,10.91" target="#b6">7]</ref> containing 4,894,081 papers (2020-04-09) with abstract content and field of subjects, made available from Microsoft academic services <ref type="bibr" coords="2,472.49,357.91,12.65,10.91" target="#b7">[8]</ref>. An ElasticSearch index is provided to participants with access through an API. A JSON dump of the index is also released. Besides, document bibliographic information and abstract content in the form of an inverted positional index, can be retrieved from OpenAlex<ref type="foot" coords="2,392.66,396.80,3.71,7.97" target="#foot_2">2</ref>  <ref type="bibr" coords="2,396.86,398.56,12.69,10.91" target="#b8">[9]</ref> using their document ids as work references (W).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Topics: Press articles</head><p>Topics are a selection of press articles from the tech section of The Guardian newspaper (topics G01 to G20) and the Tech Xplore website (topics T01 to T20). URLs to original articles and textual content of each topic are provided to participants. All abstracts extracted from the document collection by participants are expected to be relevant to subjects addressed in the press articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Queries as facets</head><p>Between one and four keywords queries are provided with each topic. It has been manually checked that each query allows retrieving relevant passages that could be inserted as citations in the press article. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Qrels</head><p>Quality relevance of abstracts w.r.t. topics is given in Simpletext_2023_task1_train.qrels, distributed to participants. This file extends the qrels released last year with a significant increase of the depth of judgments of abstracts per query (Table <ref type="table" coords="3,345.66,262.77,3.81,10.91" target="#tab_0">1</ref>, lines 1 and 2). Thus, the average number of assessed abstracts by query has raised from 6.8 to 44.9. Relevance annotations are provided on a 0-2 scale (the higher the more relevant) for 29 queries associated with the first 15 articles from the Guardian. <ref type="foot" coords="3,209.26,301.66,3.71,7.97" target="#foot_3">3</ref>From runs submitted this year (see Section 3), a new qrels file was built using pooling on 10 topics different from the train file: the last 5 topics from the Guardian and the first 5 from Tech Xplore (Table <ref type="table" coords="3,178.39,344.06,3.81,10.91" target="#tab_0">1</ref>, line 3). For pooling, only top 10 abstracts of each submitted run were considered for manual assessment. While the train file was released to participants to allow them to have supervised approaches, the test file is only used for the track evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Expected results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Ad-hoc passage retrieval</head><p>Participants had to retrieve, for each topic and each query, all passages from DBLP abstracts, related to the query and relevant to be inserted as a citation in the paper associated with the topic. Some passages could require simplification. We encouraged participants to take into account passage complexity as well as its credibility/influentialness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Open passage retrieval (optional)</head><p>Participants were also encouraged to extract supplementary relevant queries from the titles or content articles and to provide results based on these supplementary queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Output format</head><p>Results had to be provided in a TREC style JSON or TSV format with the following fields: run_id Run ID starting with : team_id_task_id_method_used, e.g. UBO_task_1_TFIDF manual Whether the run is manual {0,1}  For each query, the maximum number of distinct DBLP references (doc_id field) was 100 and the total length of passages could not exceed 1000 tokens. The idea of taking into account complexity is to have passages easier to understand for non-experts, while credibility score aims at guiding them on the expertise of authors and the value of publication w.r.t. the article topic. For example, complexity scores can be evaluated using readability score and credibility scores using bibliometrics.</p><p>Here is an output format example: An example of the output is shown in Table <ref type="table" coords="4,307.08,626.42,3.81,10.91" target="#tab_1">2</ref>. For each topic, the maximum number of distinct DBLP references (_id JSON field) was 100 and the total length of passages was not to exceed 1,000 tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Evaluation Metrics</head><p>Passage relevance has been assessed based on:</p><p>• lexical and semantic overlap of extracted passages with topic article content • manual relevance assessment of a pool of passages (relevance scores provided by participants will be used to measure ranking quality) • manual assessment by non-expert users of credibility and complexity</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Participants' approaches</head><p>Five teams submitted 39 runs in total.</p><p>Elsevier (represented as 𝐸𝑙𝑠𝑒𝑣𝑖𝑒𝑟* in Table <ref type="table" coords="5,301.65,245.58,4.25,10.91" target="#tab_2">7</ref>) <ref type="bibr" coords="5,313.15,245.58,18.07,10.91" target="#b9">[10]</ref> made 10 submissions to Task 1. Their submissions focused on evaluating the performance of neural rankers, utilizing both zero-shot approaches and unsupervised fine-tuning techniques on scientific documents.</p><p>The University of Amsterdam (𝑈 𝐴𝑚𝑠 * ) <ref type="bibr" coords="5,277.02,286.23,17.75,10.91" target="#b10">[11]</ref> entered 10 submissions for Task 1. Initially, they contributed three baseline rankers aimed at enhancing the pool of judgments. These baseline rankers included an ElasticSearch run utilizing keyword queries (non-phrase), as well as a cross-encoder reranking approach applied to the top 100 and top 1,000 results obtained from ElasticSearch. They made four additional submissions that focused on evaluating the credibility of the retrieved results. These submissions took into consideration factors such as the recency and number of citations for each paper to assess their credibility. Finally, they submitted three runs specifically aimed at addressing the readability of the retrieved results.</p><p>The University of Maine (AIIR Lab, 𝑚𝑎𝑖𝑛𝑒_*) <ref type="bibr" coords="5,318.98,394.63,18.07,10.91" target="#b11">[12]</ref> submitted 5 runs for Task 1. Their submissions involved experimenting with cross-encoder and bi-encoder models, comparing their performance to lexical models.</p><p>The University of Milano Bicocca (𝑢𝑛𝑖𝑚𝑖𝑏_𝐷𝑜𝑆𝑆𝐼𝐸𝑅_*) <ref type="bibr" coords="5,363.17,435.27,17.88,10.91" target="#b12">[13]</ref> submitted 2 runs for Task 1. Their submissions encompassed domain-specific approaches for scientific documents, including probabilistic lexical ranking, hierarchical document classification, and pseudo-relevance feedback (PRF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Retrieval Effectiveness</head><p>Table <ref type="table" coords="5,115.45,555.51,5.00,10.91">3</ref> shows the results of the CLEF 2023 Simpletext Task 1, based on the 34 test queries. The main measure of the task is NDCG@10, and the table is sorted on this measure for convenience. Let us note that some participants used the possibility of having two different scores in their run. Since ranking made according to the relevance or combination scores may vary in this case, we add in the result table 𝑟𝑒𝑙 and 𝑐𝑜𝑚𝑏 for runs with two different scores.</p><p>A number of observations stand out. First and foremost, we see in general that the top of the Table is dominated by neural rankers; in particular, cross-encoders trained on MSMarco applied in a zero-shot way (or variants thereof), perform well for ranking scientific abstracts on NDCG@10 and other early precision measures. Traditional lexical retrieval models perform reasonably but at some distance from the top-scoring runs, with the neural runs typically re-ranking such a lexical baseline run.</p><p>Second, looking at more recall-oriented measures, such as MAP and bpref, the picture is more mixed. This is indicating some approaches privilege precision over recall, whereas other approaches seem to promote all recall levels.</p><p>Third, some submissions aimed to balance the topical relevance with the readability or credibility of the results. We observe that these runs still achieve competitive retrieval effectiveness, despite removing or down-ranking highly relevant abstracts that have for example a high text complexity or are dated with low numbers of citations.</p><p>The document collection contains two different sets of topics. On the one hand, the Guardian topics (G) are built from articles related to societal issues: privacy, ubiquity, misinformation, etc. and are usually associated with general queries that must be disambiguated in the context of the articles. On the other hand, the Tech Xplore topics (T) are linked to an original scientific paper and deal with more technical facets: neural networks, indoor positioning system, RISC architecture, etc. Further analysis was performed on the behavior of systems according to these two sets and shown in Tables <ref type="table" coords="6,250.10,290.20,5.12,10.91">4</ref> and<ref type="table" coords="6,277.25,290.20,3.77,10.91">5</ref>. A comparison of these results exhibits that more relevant abstracts were found for the T topics, with higher scores overall. However, ranking against NDCG@10 leads to a different ranking of systems. While ElsevierSimpleText_run8 still outperforms other systems on T topics, maine_CrossEncoder1 becomes the 1st system on G topics.</p><p>Going back to the training qrels released to participants, we observe as expected that supervised models learned on these data have the highest scores (Table <ref type="table" coords="6,389.56,371.50,3.65,10.91">6</ref>). Runs submitted by the University of Maine and to a lesser extent by the University of Amsterdam outperform others. Runs by Elsevier also resorted to neural rerankers, but other training data were used. Only G topics were included in the train qrels, which may explain why systems behave differently between G or T topics used in the test qrels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Analysis of Readability</head><p>Table <ref type="table" coords="6,116.20,475.42,5.15,10.91" target="#tab_2">7</ref> shows several statistics over to the top 10 results retrieved for the entire topic set for Task 1:</p><p>• citation analysis (impact factor based on ACM records and average number of references per document), • textual analysis (document length and FKGL scores).</p><p>Let us note that when two different scores were provided for a run, only the combined one was considered in this evaluation.</p><p>We make a number of observations. First, it appears that the most effective ranking models tend to retrieve abstracts that are not only longer, but also exhibit greater length variability. These retrieved abstracts often have higher impact factors and extensive bibliographies. There also seems to be a discernible difference between the lengths of abstracts retrieved by lexical-based systems compared to those retrieved by neural-based systems. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,366.39,83.48,10.91;4,89.29,388.91,416.70,10.91;4,116.16,402.46,101.14,10.91;4,89.29,424.97,343.17,10.91;4,89.29,447.49,270.35,10.91;4,89.29,470.01,416.69,10.91;4,116.56,483.55,133.93,10.91;4,89.29,506.07,167.00,10.91"><head></head><label></label><figDesc>topic_id Topic ID query_id Query ID used to retrieve the document (if one of the queries provided for the topic was used; 0 otherwise) doc_id ID of the retrieved document (to be extracted from the JSON output) rel_score Relevance score of the passage (in the [0-1] scale) comb_score General score that may combine relevance and other aspects: readability, citation measures. . . (in the [0-1] scale) passage Text of the selected passage</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,416.99,99.04"><head>Table 1</head><label>1</label><figDesc>Statistics on qrels.</figDesc><table coords="3,89.29,122.01,416.70,67.51"><row><cell>Qrels</cell><cell>Topics</cell><cell>#Queries</cell><cell cols="3">#Assessed abstracts</cell><cell>#Avg Ass.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>1</cell><cell>2</cell></row><row><cell>2022 test</cell><cell>G1-G20, T2,4,5,10-12,15-16,T18-20</cell><cell>72</cell><cell cols="2">192 187</cell><cell>107</cell><cell>6.8</cell></row><row><cell>2023 train</cell><cell>G1-G15</cell><cell>29</cell><cell cols="2">728 338</cell><cell>237</cell><cell>44.9</cell></row><row><cell>2023 test</cell><cell>G16-G20, T1-T5</cell><cell>34</cell><cell cols="2">2260 357</cell><cell>1218</cell><cell>112.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,412.68,249.20"><head>Table 2</head><label>2</label><figDesc>CLEF 2023 SimpleText Task 1 on content selection: example of output</figDesc><table coords="4,95.27,122.01,406.41,217.67"><row><cell>Run</cell><cell cols="3">M/A Topic Query</cell><cell>Doc</cell><cell cols="2">Rel Comb Passage</cell></row><row><cell>ST1_task1_1</cell><cell>0</cell><cell>G01</cell><cell cols="3">G01.1 1564531496 0.97</cell><cell>0.85</cell><cell>A CDA is a mobile user de-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>vice, similar to a Personal</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Digital Assistant (PDA). It</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>supports the citizen when</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>dealing with public author-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ities and proves his rights -</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>if desired, even without re-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>vealing his identity.</cell></row><row><cell>ST1_task1_1</cell><cell>0</cell><cell>G01</cell><cell cols="3">G01.1 3000234933 0.9</cell><cell>0.9</cell><cell>People are becoming in-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>creasingly comfortable us-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ing Digital Assistants (DAs)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>to interact with services or</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>connected objects</cell></row><row><cell>ST1_task1_1</cell><cell>0</cell><cell>G01</cell><cell cols="3">G01.2 1448624402 0.6</cell><cell>0.3</cell><cell>As extensive experimental</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>research has shown indi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>viduals suffer from diverse</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>biases in decision-making.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,88.99,90.49,416.99,374.01"><head>Table 7</head><label>7</label><figDesc>Text Analysis of SimpleText Task 1 output.</figDesc><table coords="11,89.29,122.01,416.70,342.48"><row><cell>Run</cell><cell>Impact</cell><cell>#Refs</cell><cell cols="2">Length</cell><cell></cell><cell>FKGL</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mean</cell><cell>Median</cell><cell>Mean</cell><cell>Median</cell></row><row><cell>ElsevierSimpleText_run1</cell><cell>1.88</cell><cell>0.95</cell><cell>965.02</cell><cell>921.00</cell><cell>13.80</cell><cell>13.80</cell></row><row><cell>ElsevierSimpleText_run2</cell><cell>2.24</cell><cell>1.36</cell><cell>1017.57</cell><cell>981.00</cell><cell>13.98</cell><cell>13.90</cell></row><row><cell>ElsevierSimpleText_run3</cell><cell>1.80</cell><cell>0.94</cell><cell>951.64</cell><cell>912.00</cell><cell>13.71</cell><cell>13.75</cell></row><row><cell>ElsevierSimpleText_run4</cell><cell>2.10</cell><cell>1.21</cell><cell>1011.10</cell><cell>994.00</cell><cell>13.95</cell><cell>13.90</cell></row><row><cell>ElsevierSimpleText_run5</cell><cell>1.78</cell><cell>0.71</cell><cell>993.14</cell><cell>972.50</cell><cell>13.76</cell><cell>13.80</cell></row><row><cell>ElsevierSimpleText_run6</cell><cell>1.59</cell><cell>0.65</cell><cell>995.65</cell><cell>975.50</cell><cell>13.75</cell><cell>13.90</cell></row><row><cell>ElsevierSimpleText_run7</cell><cell>2.37</cell><cell>0.94</cell><cell>1101.23</cell><cell>1075.50</cell><cell>13.87</cell><cell>13.80</cell></row><row><cell>ElsevierSimpleText_run8</cell><cell>0.60</cell><cell>0.50</cell><cell>1089.90</cell><cell>1045.00</cell><cell>14.09</cell><cell>14.00</cell></row><row><cell>ElsevierSimpleText_run9</cell><cell>0.71</cell><cell>0.54</cell><cell>1016.96</cell><cell>991.00</cell><cell>13.66</cell><cell>13.70</cell></row><row><cell>UAms_CE100</cell><cell>3.20</cell><cell>1.64</cell><cell>1028.78</cell><cell>975.00</cell><cell>14.59</cell><cell>14.50</cell></row><row><cell>UAms_CE1k</cell><cell>2.41</cell><cell>1.24</cell><cell>1071.67</cell><cell>985.50</cell><cell>14.70</cell><cell>14.60</cell></row><row><cell>UAms_CE1k_Combine</cell><cell>0.84</cell><cell>0.49</cell><cell>924.38</cell><cell>839.00</cell><cell>10.84</cell><cell>11.20</cell></row><row><cell>UAms_CE1k_Filter</cell><cell>1.09</cell><cell>0.62</cell><cell>988.00</cell><cell>913.50</cell><cell>12.40</cell><cell>12.70</cell></row><row><cell>UAms_ElF_Cred44</cell><cell>3.32</cell><cell>1.62</cell><cell>973.03</cell><cell>970.50</cell><cell>13.60</cell><cell>14.50</cell></row><row><cell>UAms_ElF_Cred44Read</cell><cell>1.85</cell><cell>1.34</cell><cell>799.29</cell><cell>851.00</cell><cell>13.18</cell><cell>14.20</cell></row><row><cell>UAms_ElF_Cred53</cell><cell>2.89</cell><cell>1.49</cell><cell>938.41</cell><cell>932.00</cell><cell>13.73</cell><cell>14.40</cell></row><row><cell>UAms_ElF_Cred53Read</cell><cell>1.70</cell><cell>1.28</cell><cell>774.76</cell><cell>823.00</cell><cell>13.29</cell><cell>14.30</cell></row><row><cell>UAms_ElF_Read25</cell><cell>1.60</cell><cell>1.25</cell><cell>767.70</cell><cell>819.00</cell><cell>13.09</cell><cell>14.20</cell></row><row><cell>UAms_Elastic</cell><cell>2.84</cell><cell>1.45</cell><cell>922.36</cell><cell>917.00</cell><cell>13.49</cell><cell>14.30</cell></row><row><cell>maine_CrossEncoder1</cell><cell>4.22</cell><cell>2.86</cell><cell>961.17</cell><cell>923.00</cell><cell>14.64</cell><cell>14.60</cell></row><row><cell>maine_CrossEncoderFinetuned1</cell><cell>4.41</cell><cell>3.37</cell><cell>1003.75</cell><cell>988.00</cell><cell>15.01</cell><cell>14.80</cell></row><row><cell>maine_CrossEncoderFinetuned2</cell><cell>3.49</cell><cell>3.04</cell><cell>988.86</cell><cell>951.50</cell><cell>14.95</cell><cell>14.80</cell></row><row><cell>maine_Pl2TFIDF</cell><cell>3.35</cell><cell>2.58</cell><cell>893.29</cell><cell>894.00</cell><cell>14.03</cell><cell>14.00</cell></row><row><cell>maine_tripletloss</cell><cell>4.76</cell><cell>3.29</cell><cell>969.09</cell><cell>973.50</cell><cell>14.69</cell><cell>14.60</cell></row><row><cell>unimib_DoSSIER_2</cell><cell>1.44</cell><cell>1.33</cell><cell>1024.48</cell><cell>994.00</cell><cell>14.77</cell><cell>14.60</cell></row><row><cell>unimib_DoSSIER_4</cell><cell>1.44</cell><cell>1.33</cell><cell>238.63</cell><cell>212.00</cell><cell>15.11</cell><cell>15.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,100.20,527.16,405.79,10.91;1,89.29,540.70,416.69,10.91;1,89.29,554.25,416.69,10.91;1,89.29,567.80,416.69,10.91;1,89.29,581.35,416.69,10.91;1,89.29,594.90,416.69,10.91"><p>Scientific literacy is a vital skill for individuals. It serves as a key component of critical thinking, enabling individuals to make objective decisions and assess the validity and significance of research findings. Scientific literacy helps to differentiate between reliable evidence and unsubstantiated claims and navigate the complex landscape of scientific advancements. Despite increasing digitization and open access to scientific literature, several barriers remain that impede non-experts from accessing unbiased scientific information from these texts. One</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1" coords="2,92.57,659.98,87.95,8.97"><p>https://www.aminer.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="2,92.57,670.94,95.09,8.97"><p>https://docs.openalex.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="3,92.43,660.08,413.56,8.97;3,92.11,671.64,7.17,7.86"><p>Judgments made last year on a 0-5 scale were transformed with the following conversion rules: 0/1 → 0; 2/3 → 1;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4" coords="3,100.81,671.64,34.74,7.86"><p>4/5 → 2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was funded, in whole or in part, by the <rs type="funder">French National Research Agency (ANR)</rs> under the project <rs type="grantNumber">ANR-22-CE23-0019-01</rs>. We would like to thank <rs type="person">Radia Hannachi</rs>, <rs type="person">Silvia Araújo</rs>, <rs type="person">Pierre De Loor</rs>, <rs type="person">Olga Popova</rs>, <rs type="person">Diana Nurbakova</rs>, <rs type="person">Quentin Dubreuil</rs>, <rs type="person">Aurianne Damoy</rs>, <rs type="person">Angelique Robert</rs>, <rs type="person">Julien Gaudin</rs>, and all other colleagues and participants who helped run this track.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_89KUyTR">
					<idno type="grant-number">ANR-22-CE23-0019-01</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Second, in terms of readability levels, the overwhelming majority of systems retrieve abstracts with an FKGL of around 14 -corresponding to university-level texts. This is entirely as expected since the corpus is based on scientific text, known to be written for experts with higher text complexity than for example newspaper articles.</p><p>Third, two systems retrieve abstracts with an FKGL of 11-12 -corresponding to the exit level of compulsory education, and the reading level of the average newspaper reader targeted by the use case of the track. These runs still achieved very reasonable retrieval effectiveness (NDCG@10 0.37-0.45 in Table <ref type="table" coords="8,225.19,564.28,4.18,10.91">3</ref>) while only retrieving abstracts with the desirable readability level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this CLEF lab track, a range of language models has been systematically examine and compare by participants in an attempt to elucidate their strengths and weaknesses when employed for accessing scientific information, especially amid the burgeoning science communication </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>landscape.</head><p>Task lab results involve the construction of a unique test set that pairs layperson queries with ideal scientific documents. The queries have been derived from a large-scale student experiment, providing a realistic representation of the nature of layperson queries. The test set has been used to train various participating systems, and the results have been enhanced with expert manual annotation of an additional pool of results.</p><p>This comprehensive exploration provides valuable insights into the effectiveness of each model and presents a critical comparison of their performances. The findings from this study have the potential to inform future research directions and aid the development of more userfriendly AI tools, leading to more accurate and effective retrieval of scientific literature for laypeople.</p><p>The comprehensive analysis of the CLEF 2023 SimpleText track leads to the overall conclusion that state-of-the-art models have made significant progress. However, it is evident that there is still substantial room for improvement in the field. This indicates that further advancements and refinements are necessary to enhance the performance and capabilities of the models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,112.66,614.79,394.53,10.91;11,112.66,628.34,393.53,10.91;11,112.66,641.89,395.17,10.91;11,112.66,655.44,394.53,10.91;12,112.39,86.97,394.88,10.91;12,112.66,100.52,204.11,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,171.43,628.34,334.75,10.91;11,112.66,641.89,126.72,10.91">Overview of simpletext 2021 -CLEF workshop on text simplification for scientific information access</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Braslavski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85251-1_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-85251-1_27" />
	</analytic>
	<monogr>
		<title level="m" coord="11,262.60,641.89,245.23,10.91;11,112.66,655.44,389.91,10.91">CLEF&apos;21: Experimental IR Meets Multilinguality, Multimodality, and Interaction -12th International Conference of the CLEF Association</title>
		<title level="s" coord="12,191.73,87.98,152.88,9.72">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12880</biblScope>
			<biblScope unit="page" from="432" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,114.06,394.53,10.91;12,112.66,127.61,393.33,10.91;12,112.66,141.16,394.53,10.91;12,112.66,154.71,394.52,10.91;12,112.39,168.26,394.88,10.91;12,112.66,181.81,204.11,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,271.16,127.61,234.83,10.91;12,112.66,141.16,142.54,10.91">Overview of the CLEF 2022 simpletext lab: Automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ovchinnikova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nurbakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hannachi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Mathurin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-13643-6_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-13643-6_28" />
	</analytic>
	<monogr>
		<title level="m" coord="12,282.70,141.16,224.49,10.91;12,112.66,154.71,389.97,10.91">CLEF&apos;22: Experimental IR Meets Multilinguality, Multimodality, and Interaction -13th International Conference of the CLEF Association</title>
		<title level="s" coord="12,191.73,169.28,152.88,9.72">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13390</biblScope>
			<biblScope unit="page" from="470" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,195.36,393.33,10.91;12,112.33,208.91,315.11,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,339.80,195.36,166.19,10.91;12,112.33,208.91,246.16,10.91">Overview of the CLEF 2023 SimpleText Task 2: Difficult Concept Identification and Explanation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,222.46,393.33,10.91;12,112.33,236.01,225.86,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mccombie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<title level="m" coord="12,330.52,222.46,175.46,10.91;12,112.33,236.01,157.37,10.91">Overview of the CLEF 2023 SimpleText Task 3: Scientific text simplification</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,249.56,393.33,10.91;12,112.66,263.11,394.52,10.91;12,112.66,276.66,394.53,10.91;12,112.66,290.20,395.17,10.91;12,112.66,303.75,363.24,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,435.45,249.56,70.54,10.91;12,112.66,263.11,306.79,10.91">Overview of the CLEF 2023 SimpleText Lab: Automatic simplification of scientific texts</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ermakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Huet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,234.07,290.20,273.76,10.91;12,112.66,303.75,128.32,10.91">CLEF&apos;23: Proceedings of the Fourteenth International Conference of the CLEF Association</title>
		<title level="s" coord="12,248.24,303.75,155.05,10.91">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,317.30,393.33,10.91;12,112.66,330.85,255.72,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,330.75,317.30,175.23,10.91;12,112.66,330.85,111.25,10.91">Arnetminer: Extraction and mining of academic social networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,247.36,330.85,32.33,10.91">KDD&apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,344.40,393.33,10.91;12,112.66,357.95,393.33,10.91;12,112.66,371.50,81.21,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,303.41,344.40,202.57,10.91;12,112.66,357.95,140.00,10.91">A unified probabilistic framework for name disambiguation in digital library</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,260.56,357.95,245.43,10.91">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,385.05,395.17,10.91;12,112.66,398.60,393.33,10.91;12,112.66,412.15,250.82,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,417.44,385.05,90.40,10.91;12,112.66,398.60,207.14,10.91">An overview of microsoft academic service (mas) and applications</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B.-J</forename><forename type="middle">P</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,342.55,398.60,163.44,10.91;12,112.66,412.15,133.86,10.91">Proceedings of the 24th international conference on world wide web</title>
		<meeting>the 24th international conference on world wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,425.70,394.53,10.91;12,112.39,439.25,278.17,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Priem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Piwowar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Orr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01833</idno>
		<title level="m" coord="12,243.98,425.70,263.20,10.91;12,112.39,439.25,148.07,10.91">Openalex: A fully-open index of scholarly works, authors, venues, institutions, and concepts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,452.79,393.33,10.91;12,112.66,466.34,308.30,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,359.92,452.79,146.07,10.91;12,112.66,466.34,238.70,10.91">Elsevier at SimpleText: Passage Retrieval by Fine-tuning GPL on Scientific Documents</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Capari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Azarbonyad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,479.89,393.58,10.91;12,112.66,493.44,167.19,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,337.18,479.89,169.06,10.91">University of Amsterdam at the CLEF</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sutmuller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Adib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note>SimpleText Track</note>
</biblStruct>

<biblStruct coords="12,112.66,506.99,393.33,10.91;12,112.66,520.54,181.44,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,372.31,506.99,133.68,10.91;12,112.66,520.54,39.84,10.91">AIIR and LIAAD Labs Systems for CLEF</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Durgin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Campos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,178.24,520.54,46.88,10.91">SimpleText</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,534.09,393.61,10.91;12,112.66,547.64,259.26,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="12,217.33,534.09,288.93,10.91;12,112.66,547.64,190.74,10.91">Domain Context-centered Retrieval for the Content Selection task in the Simplification of Scientific Literature</title>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">E</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,561.19,394.62,10.91;12,112.66,574.74,395.17,10.91;12,111.60,588.29,60.89,10.91" xml:id="b13">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="12,370.93,561.19,136.34,10.91;12,112.66,574.74,211.44,10.91">Working Notes of CLEF 2023: Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="12,333.50,574.74,174.33,10.91;12,111.60,588.29,10.14,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
