<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,382.61,15.42;1,89.29,106.66,127.03,15.42">Overview of FungiCLEF 2023: Fungi Recognition Beyond 1/0 Cost</title>
				<funder ref="#_CTewQ7z">
					<orgName type="full">Technology Agency of the Czech Republic</orgName>
				</funder>
				<funder ref="#_XDHbx3Z">
					<orgName type="full">UWB</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,134.97,58.19,11.96"><forename type="first">LukÃ¡Å¡</forename><surname>Picek</surname></persName>
							<email>picekl@kky.zcu.cz</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Applied Sciences</orgName>
								<orgName type="institution">University of West Bohemia</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.11,134.97,51.78,11.96"><forename type="first">Milan</forename><surname>Å ulc</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Second Foundation</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.53,134.97,82.60,11.96"><forename type="first">Rail</forename><surname>Chamidullin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Applied Sciences</orgName>
								<orgName type="institution">University of West Bohemia</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.13,134.97,47.16,11.96"><forename type="first">JiÅ™Ã­</forename><surname>Matas</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">The Center for Machine Perception Dept. of Cybernetics</orgName>
								<orgName type="department" key="dep2">FEE</orgName>
								<orgName type="institution">Czech Technical University in</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,382.61,15.42;1,89.29,106.66,127.03,15.42">Overview of FungiCLEF 2023: Fungi Recognition Beyond 1/0 Cost</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">3989E9E9B028E9875AF1FA2430A90BA7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>FungiCLEF</term>
					<term>fine grained visual categorization</term>
					<term>metadata</term>
					<term>open-set recognition</term>
					<term>fungi</term>
					<term>species identification</term>
					<term>machine learning</term>
					<term>computer vision</term>
					<term>classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computer vision systems for fungi recognition aid mycologists, researchers, and enthusiasts in the efficient identification of mushroom species. FungiCLEF 2023, the second edition of the fungi recognition challenge at LifeCLEF, builds upon the Danish Fungi 2020 dataset and upon its predecessor by presenting several recognition tasks differing in the cost functions corresponding to different practical scenarios, including poisonous/edible decision making or discovering unseen species. With practical applications in mind, the 2023 challenge only accepted submissions with model size under 1GB. The competition received 16 final submissions from 3 teams. This overview paper provides a detailed description of the challenge data and tasks, a review of the submitted methods, and a discussion of the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Computer vision systems for fungi recognition <ref type="bibr" coords="1,308.58,409.04,11.48,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,323.78,409.04,9.03,10.91" target="#b1">2]</ref> aid mycologists, researchers, and enthusiasts in the efficient identification of mushroom species: A process that could take even hours of searching in the literature is now a question of seconds. For example, with the fungi identification service provided by the Atlas of Danish Fungi <ref type="bibr" coords="1,348.95,449.69,11.28,10.91" target="#b2">[3]</ref>, users only take a picture of their observation, and the system instantly proposes a list of predicted species for the observation, allowing the user to manually verify the prediction by comparing the observation with photos of the species and with the matching description. Species recognition presents a challenging fine-grained recognition problem with a high number of categories (species) with high similarities between categories -some of them even genetically related -and high intra-class variances at the same time -as the observations depend on a number of factors, such as genotype, age, time of year, local conditions, etc. As part of LifeCLEF 2023 <ref type="bibr" coords="1,351.19,544.53,11.27,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,365.19,544.53,7.51,10.91" target="#b4">5]</ref>, and FGVC-CVPR workshops, FungiCLEF 2023 follows on the previous edition <ref type="bibr" coords="1,305.40,558.08,11.37,10.91" target="#b5">[6,</ref><ref type="bibr" coords="1,319.49,558.08,8.96,10.91" target="#b6">7]</ref> with new test data described in Section 3.1, constraints on the models' memory footprint and a set of species recognition scenarios with different loss functions, described later in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>With advances in computer vision and machine learning, fine-grained categorization problems gained significant attention due to the challenges of discriminating subtle differences among visually similar objects. Image-based species recognition is a challenging case of fine-grained classification due to high inter-class similarities, high intra-class variances, large numbers of categories, etc.</p><p>Image-based Fungi Recognition: Computer vision processing for fungi recognition dates back to analysis tools from morphological characteristics by De Vooren et al. <ref type="bibr" coords="2,429.96,197.62,12.78,10.91" target="#b7">[8]</ref> in 1992. More recently, Tahir et al. <ref type="bibr" coords="2,181.10,211.17,11.55,10.91" target="#b8">[9]</ref>, and Zielinski et al. <ref type="bibr" coords="2,284.35,211.17,18.04,10.91" target="#b9">[10]</ref> introduced datasets of microscopy images of fungal infections for medical diagnosis. Fine-grained fungi recognition "in the wild" has been the aim of the FGVCx Fungi classification challenge 2018. More recently, data from the Atlas of Danish Fungi were used to build the Danish Fungi 2020 dataset <ref type="bibr" coords="2,368.15,251.82,16.12,10.91" target="#b10">[11]</ref>, which is further described in Section 3.1 and which was used in the FungiCLEF 2022 and FungiCLEF 2023 competitions. All contributions to FungiCLEF 2022 <ref type="bibr" coords="2,249.65,278.92,17.75,10.91" target="#b11">[12]</ref> were based on modern Convolutional Neural Network (CNN) or transformer-inspired architectures, such as Metaformer <ref type="bibr" coords="2,381.10,292.46,16.24,10.91" target="#b12">[13]</ref>, Swin Transformer <ref type="bibr" coords="2,486.88,292.46,16.24,10.91" target="#b13">[14]</ref>, and BEiT <ref type="bibr" coords="2,133.28,306.01,16.41,10.91" target="#b14">[15]</ref>. The best performing teams used ensembles of both CNNs and Transformers. The winning team <ref type="bibr" coords="2,173.63,319.56,18.01,10.91" target="#b15">[16]</ref> achieved 80.43% accuracy with a combination of ConvNext-large <ref type="bibr" coords="2,487.98,319.56,18.00,10.91" target="#b16">[17]</ref> and MetaFormer. The results were often improved by combining predictions belonging to the same observation and by both training-time and test-time data augmentations. We have seen successful applications of different loss functions targeting the unbalanced class distributionsnamely the Seesaw loss <ref type="bibr" coords="2,192.65,373.76,16.09,10.91" target="#b17">[18]</ref>, Focal loss <ref type="bibr" coords="2,258.81,373.76,16.08,10.91" target="#b18">[19]</ref>, Arcface loss <ref type="bibr" coords="2,335.47,373.76,16.09,10.91" target="#b19">[20]</ref>, Sub-Center loss <ref type="bibr" coords="2,428.06,373.76,17.75,10.91" target="#b20">[21]</ref> and Adaptive Margin <ref type="bibr" coords="2,122.98,387.31,16.09,10.91" target="#b21">[22]</ref>. A number of methods have been experimented to utilize the observation metadata, including hand-crafted encoding of the metadata into feature vectors, as well as encoding of the metadata with a multilingual BERT model <ref type="bibr" coords="2,304.44,414.41,18.07,10.91" target="#b22">[23]</ref> and RoBERTa <ref type="bibr" coords="2,390.90,414.41,16.41,10.91" target="#b23">[24]</ref>. The metadata were then combined with image features extracted from a CNN or Transformer image classifier, or directly used as an input to Metaformer.</p><p>Image-based Plant Recognition: While plants (Plantae) and fungi are different kingdoms, both are mainly immobile and have similarities in general morphology and growth habitat. From the technical point of view, one can thus consider image based recognition of plant and fungi species to be related tasks. Compared to fungi recognition, a higher number of plant recognition datasets are available to the scientific community: Ranging from datasets of specific plant organs like leaves <ref type="bibr" coords="2,247.78,527.85,16.56,10.91" target="#b24">[25,</ref><ref type="bibr" coords="2,267.35,527.85,14.11,10.91" target="#b25">26]</ref> and flowers <ref type="bibr" coords="2,339.29,527.85,16.41,10.91" target="#b26">[27]</ref>, to general plant recognition "in the wild" <ref type="bibr" coords="2,132.07,541.40,16.55,10.91" target="#b27">[28,</ref><ref type="bibr" coords="2,152.54,541.40,12.42,10.91" target="#b28">29]</ref>. Plant recognition from more constrained visual inputs, such as images of tree bark or leaves scanned on a white background, were addressed both with a wide range of hand-crafted features -such as shape <ref type="bibr" coords="2,310.30,568.49,16.56,10.91" target="#b29">[30,</ref><ref type="bibr" coords="2,330.74,568.49,12.42,10.91" target="#b25">26]</ref>, texture <ref type="bibr" coords="2,385.59,568.49,16.42,10.91" target="#b30">[31]</ref>, as well as with deep learning <ref type="bibr" coords="2,128.88,582.04,16.42,10.91" target="#b31">[32]</ref>. Plant recognition "in the wild" without major constraints on the visual inputs is largely dominated by deep learning approaches, as shown in the previous PlantCLEF competitions <ref type="bibr" coords="2,150.14,609.14,16.56,10.91" target="#b27">[28,</ref><ref type="bibr" coords="2,170.20,609.14,12.59,10.91" target="#b32">33,</ref><ref type="bibr" coords="2,186.30,609.14,14.11,10.91" target="#b28">29]</ref> and the best performing methods <ref type="bibr" coords="2,359.90,609.14,16.55,10.91" target="#b33">[34,</ref><ref type="bibr" coords="2,379.96,609.14,12.59,10.91" target="#b34">35,</ref><ref type="bibr" coords="2,396.06,609.14,12.42,10.91" target="#b35">36]</ref>. Moreover, "Experts vs. Machines" experiments performed in <ref type="bibr" coords="2,276.59,622.69,16.56,10.91" target="#b36">[37,</ref><ref type="bibr" coords="2,296.23,622.69,14.11,10.91" target="#b32">33]</ref> showed that the accuracy of the best deep convolutional networks was on the human level<ref type="foot" coords="2,303.56,634.48,3.71,7.97" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Challenge Description</head><p>Automatic recognition of species at scale, such as in popular citizen-science projects <ref type="bibr" coords="3,480.76,145.59,11.49,10.91" target="#b0">[1,</ref><ref type="bibr" coords="3,495.70,145.59,7.65,10.91" target="#b1">2]</ref>, requires efficient prediction on limited resources. In practice, species identification typically depends not solely on the visual observation of the specimen but also on other information available to the observer, e.g., habitat, substrate, location, and time. Thanks to rich metadata, precise annotations, and baselines available to all competitors, the challenge aims at providing a major benchmark for combining visual observations with other observed information. Interestingly, such information might be already included in the observation images (see Figure <ref type="figure" coords="3,496.88,226.89,3.60,10.91" target="#fig_0">1</ref>). Additionally, the 2023 edition of the FungiCLEF competition considers decision processes for different usage scenarios, which go beyond the commonly assumed 0/1 cost function -e.g., cost for misclassification of edible and poisonous mushrooms is an important practical aspect to be evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The FungiCLEF 2023 dataset is based on data collected through the Atlas of Danish Fungi mobile (iOS and Android) and Web applications. All fungi specimen observation had to pass the expert validation process, therefore guaranteeing high-quality labels. Besides high-quality labels, rich observation metadata about habitat, substrate, edibility, time, location, EXIF, etc., is provided. For training the DanishFungi 2020 (DF20) dataset <ref type="bibr" coords="3,376.00,385.01,18.07,10.91" target="#b10">[11]</ref> has been provided. The DF20 contains 295,938 images -newly split into 177,170 observations -belonging to 1,604 species. The validation and test datasets were constructed from all observations submitted to the Atlas of Danish Fungi in 2021, for which expert-verified species labels are available covering observations collected across all substrate and habitat types. Both datasets (Validation and Public Test) cover a similar number of observations, images, and species. The validation set contains 30,131 observations with 60,832 images belonging to 2,713 species: 1,084 known from the training set and 1,629 unknown species. The public test set contains 30,130 observations with 60,225 images belonging to 2,650 species: 1,085 known from the training set and 1,565 unknown species. In both datasets, roughly 30% of the observations captured unknown species. The private test set, used for the official leaderboard after the challenge deadline, consists of 45,021 observations with 91,231 images and corresponding metadata. The dataset statistics are listed in Table <ref type="table" coords="4,314.90,181.81,3.74,10.91" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Recognition Scenarios</head><p>Given the set of visual fungi observations and corresponding metadata, the goal is to create return a ranked list of predicted species for each observation (one or more photographs of the same individual + geographical location). To focus the challenge on models practically applicable e.g. on mobile devices, as opposed too large ensembles, models in the official benchmark have to fit a limit for memory footprint of 1 GB (in the ONNX format). The FungiCLEF 2023 recognition challenge used several metrics representing different decision scenarios, where the goal is to minimize the empirical loss ğ¿ for decisions ğ‘(ğ‘¥) over observations ğ‘¥ and true labels ğ‘¦, given a cost function ğ‘Š (ğ‘¦, ğ‘(ğ‘¥)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğ¿ = âˆ‘ï¸</head><p>ğ‘– ğ‘Š (ğ‘˜ ğ‘– , ğ‘(ğ‘¥ ğ‘– ))</p><p>Different recognition scenarios and their cost function ğ‘Š (ğ‘¦, ğ‘(ğ‘¥)) are described together with their motivation in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard classification with "unknown" category.</head><p>The first metric is the standard classification accuracy, i.e. the average correctness of the predicted class. All species not represented in the training set should correctly be classified as an "unknown" category. The decision function is simple: for each observation is simply represented by an identity matrix, i.e.</p><formula xml:id="formula_1" coords="4,222.77,618.91,283.87,25.30">ğ‘Š 1 (ğ‘¦, ğ‘(ğ‘¥))) = {ï¸‚ 0 if ğ‘(ğ‘¥) = ğ‘¦ 1 otherwise (2)</formula><p>Cost for confusing edible species for poisonous and vice versa. Let us have a function ğ‘‘ that indicates dangerous (poisonous) species as ğ‘‘(ğ‘¦) = 1 if species ğ‘¦ is poisonous, and ğ‘‘(ğ‘¦) = 0 otherwise. Let us denote ğ‘ PSC the cost for poisonous species confusion (if a poisonous observation was misclassified as edible) and ğ‘ ESC the cost for edible species confusion (if an edible observation was misclassified as poisonous).</p><formula xml:id="formula_2" coords="5,179.19,137.03,327.45,39.96">ğ‘Š 2 (ğ‘¦, ğ‘(ğ‘¥))) = â§ â¨ â© 0 if ğ‘‘(ğ‘¦) = ğ‘‘(ğ‘(ğ‘¦)) ğ‘ PSC if ğ‘‘(ğ‘¦) = 1 and ğ‘‘(ğ‘(ğ‘¦)) = 0 ğ‘ ESC otherwise<label>(3)</label></formula><p>For the benchmark, we set ğ‘ ESC = 1 and ğ‘ PSC = 100.</p><p>A user-focused loss composed of both the classification error and the poisonous/edible confusion Assuming the user is interested both in the species classification as well as in recognition of poisonousness, the third cost function simply combines ğ‘Š 1 and ğ‘Š 2 :</p><formula xml:id="formula_3" coords="5,200.44,267.55,306.20,11.36">ğ‘Š 3 (ğ‘¦, ğ‘(ğ‘¥))) = ğ‘Š 1 (ğ‘¦, ğ‘(ğ‘¥)) + ğ‘Š 2 (ğ‘¦, ğ‘(ğ‘¥))<label>(4)</label></formula><p>Cost for missing "unknown" species is higher; misclassifying for "unknown" is cheaper than confusing species. When collecting data for biological research, as common for citizenscience projects like the Atlas of Danish Fungi, missing an observation of a new/unknown species comes with a higher cost ğ›¼ &gt; 1. On the other hand, checking a known species misclassified as "unknown" may come with a lower cost 0 &lt; ğ›½ &lt; 1 than trusting misclassification for a different species. The decision cost for each observation can be represented by the following cost matrix (where last row corresponds to unknown species, and last column to observations classified as unknown):</p><formula xml:id="formula_4" coords="5,253.31,398.45,253.33,44.04">ğ‘Š 4 = â¡ â¢ â£ 0 1 ğ›½ 1 . . . ğ›½ ğ›¼ ğ›¼ 0 â¤ â¥ â¦<label>(5)</label></formula><p>For the benchmark, we set ğ›¼ = 10 and ğ›½ = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Timeline</head><p>The FungiCLEF 2023 competition was announced alongside the release of the dataset on February 14, 2023, through the LifeCLEF, HuggingFace, and FGVC challenge pages, welcoming registrations and participation from anyone interested. The competition spanned approximately 3.5 months, with a deadline set for May 24. Unlike the previous year, the test data was kept secret. Participants were allowed to submit one submission a day using the HuggingFace evaluation platform and the provided public test set. Two weeks before the deadline, the submission limit was increased to five submissions per day. The final evaluation was done over the submitted "code+models. " To simplify this process, a dockerizer sample "code+model submission" was provided one week prior to the deadline, allowing all participants to submit their "models". easily. After the submission phase finished, participants could submit post-competition entries to evaluate their ablation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Working Notes</head><p>Participants were strongly encouraged to include both code and a technical report (Working Notes) containing all the necessary details to reproduce the results of their submissions. The Working Note papers submitted by participants underwent a rigorous review process, with 2-3 reviewers possessing a solid publication history in the fields of Computer Vision and Machine Learning. This ensured a sufficient level of reproducibility and maintained a high standard of quality. The review process followed a single-blind approach, and participants were given the opportunity to provide up to two rebuttals to address any concerns or comments raised during the review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Participants and Methods</head><p>Twelve teams participated in the FungiCLEF 2023 challenge; four provided their models for a private evaluation, and three submitted working notes. This section provides an overview of the methods and systems employed by the participating teams, with further elaboration available in the individual working notes submitted by the participants <ref type="bibr" coords="6,407.04,301.65,16.43,10.91" target="#b37">[38,</ref><ref type="bibr" coords="6,426.20,301.65,12.55,10.91" target="#b38">39,</ref><ref type="bibr" coords="6,441.47,301.65,12.32,10.91" target="#b39">40]</ref>.</p><p>meng18 <ref type="bibr" coords="6,130.71,328.75,16.56,10.91" target="#b37">[38]</ref>: The team achieved the best results in the competition, combined visual information with metadata using MetaFormer <ref type="bibr" coords="6,303.38,342.30,16.41,10.91" target="#b12">[13]</ref>. To tackle class imbalance, the authors utilized the Seesaw loss <ref type="bibr" coords="6,202.57,355.85,16.41,10.91" target="#b17">[18]</ref>. On top of that, this contribution introduced two novelties: an entropy-guided recognition of unknown species in the open-set recognition scenario and an additional poisonous-classification loss to enhance the identification of poisonous species.</p><p>stefanwolf <ref type="bibr" coords="6,145.41,410.05,16.41,10.91" target="#b38">[39]</ref>, scoring second in the competition leaderboard, participated with a model based on Swin Transformer V2 <ref type="bibr" coords="6,228.28,423.60,16.20,10.91" target="#b13">[14]</ref>. A combination of predictions for images belonging to the same observation is done on the feature vector level before the classification head, following the last year's practice of Wolf and Beyerer <ref type="bibr" coords="6,280.13,450.69,16.11,10.91" target="#b40">[41]</ref>. To cope with the long-tailed class distribution, authors use the data resampling scheme by Gupta et al. <ref type="bibr" coords="6,337.30,464.24,16.25,10.91" target="#b41">[42]</ref>.</p><p>word2vector <ref type="bibr" coords="6,151.56,491.34,16.32,10.91" target="#b39">[40]</ref>: The authors, scoring third in the competition leaderboard, based their final submission on the VOLO <ref type="bibr" coords="6,205.06,504.89,18.07,10.91" target="#b42">[43]</ref> backbone architecture without any utilisation of metadata (as methods experimented in <ref type="bibr" coords="6,203.21,518.44,17.80,10.91" target="#b39">[40]</ref> did not bring an improvement in results). The class imbalance is tackled by optimising the Seesaw loss <ref type="bibr" coords="6,253.93,531.99,16.08,10.91" target="#b17">[18]</ref>. Additional improvements were achieved by rich data augmentation using the Albumentations library <ref type="bibr" coords="6,306.39,545.54,16.34,10.91" target="#b43">[44]</ref>, including several mixing augmentation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Challenge Results</head><p>The official challenge results, based on Track 1 to Track 4 Metrics, are displayed in Figure <ref type="figure" coords="6,500.04,617.71,3.81,10.91">2</ref>.</p><p>Apart from that, we show the public leaderboard scores in Figure <ref type="figure" coords="6,396.91,631.26,3.81,10.91" target="#fig_4">3</ref>. The best-performing team on the private test set -meng18 -achieved best scores in all measured scenarios. More precisely this team achieved F ğ‘š 1 score of 57.15%, Poisonous â†’ Edible confusion rate of 5.31%</p><p>and Edible â†’ Poisonous confusion rate of 2.05%. Interestingly, none of the teams that submitted working notes optimized decision-making for each of the five tasks.</p><p>Edible â†â†’ Poisonous Species Confusion: Overall, all participants achieved relatively small Poisonous â†’ Edible species confusion (2-2.5%). However the Edible â†’ Poisonous confusion still remains relatively high.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper presents an overview and results evaluation of the second edition of the FungiCLEF challenge organized in conjunction with the CLEF LifeCLEF lab <ref type="bibr" coords="8,374.00,124.83,11.38,10.91" target="#b4">[5]</ref>, and CVPR-FGVC10 -The Tenth Workshop on Fine-Grained Visual Categorization organized within the CVPR conference. FungiCLEF 2023 followed up on the previous edition <ref type="bibr" coords="8,328.04,151.93,18.02,10.91" target="#b11">[12]</ref> and introduced two novel practical aspects: limitation of the model size (1GB), and different cost functions depending on the considered application. While the best performing team introduced an additional loss towards enhancing identification of poisonous species, none of the teams optimized their models specifically for all considered cost functions. The number of contributions decreased noticeably from the previous edition of FungiCLEF. The limitation of model size, practically checked by submitting the code with trained models, may have discouraged a number of participants. On the other hand, all submitted contributions focused on the practical aspects of the recognition tasks, rather than scaling-up impractically large ensembles of machine learning models. The results suggest Fungi Recognition, as well as recognition with different application-motivated cost functions, remain an open problems with great room for improvements in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,641.90,383.05,9.96;3,97.78,469.90,77.93,160.31"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Selected observation from the FungiCLEF 2023 private test dataset. Â©Peter Stidsen.</figDesc><graphic coords="3,97.78,469.90,77.93,160.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,89.29,393.20,355.18,9.96"><head>Figure 2 :m e n g 1 8 s t e f a n w o lf w o r d 2 v e c t o r S S S A M M M M r u b e n g v 1 9 9 9 h e a d a c h e Is H e a d a c h e m a s ie s a m u e li s e t r a n s f r o m m r z a v</head><label>29</label><figDesc>Figure 2: Official FungiCLEF 2023 competition results -4 teams. Private Leaderboard.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,140.40,420.57,14.35,8.34;7,140.40,427.05,14.35,8.34;7,140.40,433.52,14.35,8.34;7,384.20,583.05,19.23,12.88;7,389.59,583.05,22.55,16.17;7,394.92,583.04,26.60,19.54;7,404.26,583.04,24.54,18.89;7,410.95,583.04,27.25,20.89;7,407.01,583.04,39.95,33.52;7,439.86,583.04,14.91,9.36;7,442.17,583.04,22.16,15.74;7,451.32,583.05,20.58,15.27;7,463.66,583.04,18.05,11.63;7,389.51,573.50,7.01,8.34;7,389.51,549.10,7.01,8.34;7,389.51,524.71,7.01,8.34;7,389.51,500.31,7.01,8.34;7,389.51,475.92,7.01,8.34;7,389.51,451.52,7.01,8.34;7,389.51,427.13,7.01,8.34;7,376.36,501.09,13.10,20.97;7,376.36,490.50,13.10,8.39;7,376.36,476.31,13.10,11.99;7,398.16,421.43,9.53,11.22;7,406.85,428.75,18.22,13.66;7,424.24,436.07,9.53,11.22;7,432.93,445.83,26.91,11.22;7,459.00,460.46,26.91,16.10"><head>r u b e n g v 1 9 9 9 h e a d a c h e Is H e a d a c h e m a s ie s a m u e li s e t r a n s f r o m m r z a v</head><label>9</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,89.29,632.28,410.90,9.96"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: FungiCLEF 2023 competition results -Top10 teams on public test set. Public Leaderboard.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,208.03,398.93,99.42"><head>Table 1</head><label>1</label><figDesc>FungiCLEF 2023 dataset statistics (taxonomic coverage) for each split and subset.</figDesc><table coords="4,104.86,239.60,383.06,67.85"><row><cell>Subset</cell><cell cols="5">Species Known Species Unknown Species Images Observations</cell></row><row><cell>Training</cell><cell>1,604</cell><cell>1,604</cell><cell>-</cell><cell>295,938</cell><cell>177,170</cell></row><row><cell>Validation</cell><cell>2,713</cell><cell>1,084</cell><cell>1,629</cell><cell>60,832</cell><cell>30,131</cell></row><row><cell>Public Test</cell><cell>2,650</cell><cell>1,085</cell><cell>1,565</cell><cell>60,225</cell><cell>30,130</cell></row><row><cell>Private Test</cell><cell>3,299</cell><cell>1,116</cell><cell>2,183</cell><cell>91,231</cell><cell>45,021</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,660.07,413.41,8.97;2,92.57,671.03,123.45,8.97"><p>In the experiment, only image data were provided to the human experts, not the physical specimen the experts are often used to examine in practice.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>RCH, LP, and JM were supported by the <rs type="funder">Technology Agency of the Czech Republic</rs>, project No. <rs type="grantNumber">SS05010008</rs>. RCH was supported by the <rs type="funder">UWB</rs> grant, project No. <rs type="grantNumber">SGS-2022-017</rs>. We acknowledge the funding of the challenge awards provided by the <rs type="institution">Visual Recognition Group at the Dept. of Cybernetics, Faculty of Electrical Engineering, Czech Technical University in Prague</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CTewQ7z">
					<idno type="grant-number">SS05010008</idno>
				</org>
				<org type="funding" xml:id="_XDHbx3Z">
					<idno type="grant-number">SGS-2022-017</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,458.87,393.33,10.91;8,112.66,472.42,393.53,10.91;8,112.30,485.97,124.54,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,375.95,458.87,130.03,10.91;8,112.66,472.42,33.31,10.91">Fungi recognition: A practical use case</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,167.21,472.42,338.98,10.91;8,112.30,485.97,26.65,10.91">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2316" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,499.52,393.33,10.91;8,112.66,513.06,297.83,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,433.00,499.52,72.99,10.91;8,112.66,513.06,191.96,10.91">Automatic fungi recognition: Deep learning meets mycology</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,313.60,513.06,34.15,10.91">Sensors</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">633</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,526.61,395.01,10.91;8,112.48,540.16,368.90,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,217.74,540.16,231.73,10.91">Danish mycological society, fungal records database</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>FrÃ¸slev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>LaessÃ¸e</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>SÃ¸chting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vesterholt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,553.71,394.53,10.91;8,112.66,567.26,394.53,10.91;8,112.66,580.81,393.33,10.91;8,112.66,594.36,395.17,10.91;8,112.66,607.91,394.52,10.91;8,112.33,621.46,329.01,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,112.66,580.81,393.33,10.91;8,112.66,594.36,135.53,10.91">Overview of lifeclef 2023: evaluation of ai models for the identification and prediction of birds, plants, snakes and fungi</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Estopinan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Chamidullin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>HrÃºz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,271.76,594.36,236.08,10.91;8,112.66,607.91,389.92,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 14th International Conference of the CLEF Association, CLEF 2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">September 18-23, 2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,635.01,395.01,10.91;8,112.66,648.56,394.62,10.91;8,112.66,662.11,337.99,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,179.38,648.56,307.15,10.91">Lifeclef 2023 teaser: Species identification and prediction challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>HrÃºz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Moussi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,662.11,207.71,10.91">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,394.53,10.91;9,112.66,100.52,393.33,10.91;9,112.66,114.06,393.33,10.91;9,112.66,127.61,393.59,10.91;9,112.28,141.16,394.90,10.91;9,112.66,154.71,55.16,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,194.50,100.52,311.49,10.91;9,112.66,114.06,258.38,10.91">Overview of lifeclef 2022: an evaluation of machine-learning based species identification and species distribution prediction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,400.42,114.06,105.56,10.91;9,112.66,127.61,393.59,10.91;9,112.28,141.16,101.56,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022</title>
		<meeting><address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="257" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,393.33,10.91;9,112.66,181.81,248.72,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<title level="m" coord="9,346.39,168.26,159.60,10.91;9,112.66,181.81,216.80,10.91">Overview of fungiclef 2022: Fungi recognition as an open set classification problem</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,393.33,10.91;9,112.66,208.91,297.84,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,338.54,195.36,167.44,10.91;9,112.66,208.91,90.71,10.91">Identification of mushroom cultivars using image analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Van De Vooren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Polder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Van Der Heijden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,211.55,208.91,115.01,10.91">Transactions of the ASAE</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="347" to="350" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,222.46,393.32,10.91;9,112.66,236.01,393.33,10.91;9,112.66,249.56,223.54,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,432.66,222.46,73.32,10.91;9,112.66,236.01,363.07,10.91">A fungus spores dataset and a convolutional neural network based approach for fungus detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Vellekoop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,484.09,236.01,21.90,10.91;9,112.66,249.56,139.60,10.91">IEEE transactions on nanobioscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="281" to="290" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.33,10.91;9,112.66,276.66,393.33,10.91;9,112.66,290.20,365.41,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,483.17,263.11,22.81,10.91;9,112.66,276.66,358.06,10.91">Deep learning approach to description and classification of fungi microscopic images</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sroka-Oleksiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rymarczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Piekarczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brzychczy-Wloch</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1906.09449" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,394.53,10.91;9,112.66,317.30,393.33,10.91;9,112.66,330.85,392.48,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,112.66,317.30,281.26,10.91">Danish fungi 2020-not just another image recognition dataset</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>LaessÃ¸e</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>FrÃ¸slev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,420.58,317.30,85.40,10.91;9,112.66,330.85,294.59,10.91">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1525" to="1535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,344.40,393.33,10.91;9,112.66,357.95,296.50,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,346.39,344.40,159.60,10.91;9,112.66,357.95,214.29,10.91">Overview of fungiclef 2022: Fungi recognition as an open set classification problem</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>CEUR-WS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,393.53,10.91;9,112.66,385.05,288.50,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02751</idno>
		<title level="m" coord="9,307.65,371.50,198.53,10.91;9,112.66,385.05,106.31,10.91">Metaformer: A unified meta framework for fine-grained recognition</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,398.60,393.33,10.91;9,112.66,412.15,393.58,10.91;9,112.66,425.70,352.07,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,483.95,398.60,22.04,10.91;9,112.66,412.15,232.11,10.91">Swin transformer v2: Scaling up capacity and resolution</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,371.96,412.15,134.28,10.91;9,112.66,425.70,244.01,10.91">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12009" to="12019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,439.25,393.33,10.91;9,112.66,452.79,107.17,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.08254</idno>
		<title level="m" coord="9,226.97,439.25,203.67,10.91">Beit: Bert pre-training of image transformers</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,466.34,393.53,10.91;9,112.66,479.89,393.59,10.91;9,112.66,493.44,261.72,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,407.33,466.34,98.86,10.91;9,112.66,479.89,265.79,10.91">An empirical study for fine-grained fungi recognition with transformer and convnet</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,401.56,479.89,104.69,10.91;9,112.66,493.44,231.02,10.91">Working Notes of CLEF 2022 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,506.99,394.53,10.91;9,112.66,520.54,173.79,10.91" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.03545</idno>
		<title level="m" coord="9,395.24,506.99,107.37,10.91">A convnet for the 2020s</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,534.09,394.53,10.91;9,112.66,547.64,393.58,10.91;9,112.66,561.19,351.04,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,112.66,547.64,228.32,10.91">Seesaw loss for long-tailed instance segmentation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,370.86,547.64,135.39,10.91;9,112.66,561.19,252.92,10.91">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9695" to="9704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,574.74,394.61,10.91;9,112.66,588.29,395.01,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,327.53,574.74,159.84,10.91">Focal loss for dense object detection</title>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,588.29,299.48,10.91">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,601.84,393.33,10.91;9,112.66,615.39,393.33,10.91;9,112.66,628.93,147.08,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,276.47,601.84,229.52,10.91;9,112.66,615.39,48.67,10.91">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,184.24,615.39,321.74,10.91;9,112.66,628.93,49.16,10.91">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4690" to="4699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,642.48,393.33,10.91;9,112.66,656.03,394.52,10.91;9,112.66,669.58,80.57,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,308.67,642.48,197.32,10.91;9,112.66,656.03,134.00,10.91">Sub-center arcface: Boosting face recognition by large-scale noisy web faces</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,269.49,656.03,189.95,10.91">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="741" to="757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.66,100.52,393.33,10.91;10,112.66,114.06,159.65,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,259.22,86.97,246.77,10.91;10,112.66,100.52,48.18,10.91">Adaptiveface: Adaptive margin and sampling for face recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,183.01,100.52,322.98,10.91;10,112.66,114.06,51.39,10.91">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11947" to="11956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,127.61,393.33,10.91;10,112.66,141.16,363.59,10.91" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="10,353.43,127.61,152.55,10.91;10,112.66,141.16,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,154.71,394.53,10.91;10,112.30,168.26,393.68,10.91;10,112.66,181.81,107.17,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="10,173.53,168.26,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,195.36,393.33,10.91;10,112.66,208.91,143.53,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="10,207.14,195.36,236.60,10.91">Leaf recognition of woody species in central europe</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>NovotnÃ½</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,454.79,195.36,51.20,10.91;10,112.66,208.91,54.52,10.91">Biosystems Engineering</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="444" to="452" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,222.46,395.17,10.91;10,112.66,236.01,393.53,10.91;10,112.30,249.56,213.43,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="10,485.59,222.46,22.24,10.91;10,112.66,236.01,325.89,10.91">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">V</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,461.24,236.01,44.96,10.91;10,112.30,249.56,82.83,10.91">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,394.04,10.91;10,112.66,276.66,394.03,10.91;10,112.66,290.20,154.62,10.91" xml:id="b26">
	<monogr>
		<ptr target="https://sites.google.com/view/fgvc5/competitions/fgvcx/flowers" />
		<title level="m" coord="10,112.66,263.11,188.45,10.91">FGVCx flower classification challenge</title>
		<imprint>
			<date type="published" when="2018">2018. 2023-07-4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,303.75,395.17,10.91;10,112.66,317.30,393.33,10.91;10,112.66,330.85,299.41,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="10,238.38,303.75,269.44,10.91;10,112.66,317.30,175.37,10.91">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,310.69,317.30,195.30,10.91;10,112.66,330.85,147.84,10.91">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">Sep. 2017. 2017</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2017</note>
</biblStruct>

<biblStruct coords="10,112.66,344.40,393.33,10.91;10,112.66,357.95,393.32,10.91;10,112.66,371.50,304.31,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="10,246.85,344.40,259.13,10.91;10,112.66,357.95,157.08,10.91">Overview of lifeclef plant identification task 2019: diving into data deficient tropical countries</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,292.46,357.95,213.52,10.91;10,112.66,371.50,128.70,10.91">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2019</note>
</biblStruct>

<biblStruct coords="10,112.66,385.05,393.33,10.91;10,112.66,398.60,393.33,10.91;10,112.66,412.15,148.13,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="10,338.40,385.05,167.59,10.91;10,112.66,398.60,167.73,10.91">A comparative experiment of several shape methods in recognizing plants</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">E</forename><surname>Nugroho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">I</forename><surname>Santosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,297.10,398.60,208.88,10.91;10,112.66,412.15,108.41,10.91">International Journal of Computer Science &amp; Information Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,425.70,393.68,10.91;10,112.66,439.25,394.51,10.91;10,112.66,455.24,129.02,7.90" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="10,205.68,425.70,148.02,10.91">Texture-based leaf identification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-16220-1_14</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,386.43,425.70,119.91,10.91;10,112.66,439.25,69.44,10.91">Computer Vision -ECCV 2014 Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">8928</biblScope>
			<biblScope unit="page" from="185" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,466.34,393.98,10.91;10,112.41,479.89,23.60,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="10,190.50,466.34,203.08,10.91">Fine-grained recognition of plants from images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,401.97,466.34,63.30,10.91">Plant Methods</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,493.44,394.53,10.91;10,112.66,506.99,394.62,10.91;10,112.66,520.54,393.54,10.91;10,112.66,534.09,255.87,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="10,187.99,506.99,319.29,10.91;10,112.66,520.54,216.02,10.91">Plant identification: Experts vs. machines in the era of deep learning: deep learning techniques challenge flora experts</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>MalÃ©cot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jauzein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-C</forename><surname>Melet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,337.02,520.54,169.18,10.91;10,112.66,534.09,184.81,10.91">Multimedia tools and applications for environmental &amp; biodiversity informatics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,547.64,393.33,10.91;10,112.66,561.19,193.67,10.91" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="10,173.30,547.64,332.68,10.91;10,112.66,561.19,37.20,10.91">Image-based plant species identification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,177.71,561.19,98.72,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,574.74,393.32,10.91;10,112.66,588.29,223.89,10.91" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="10,233.73,574.74,272.25,10.91;10,112.66,588.29,68.09,10.91">Plant recognition by inception networks with test-time class prior estimation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,207.93,588.29,98.72,10.91">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,601.84,393.32,10.91;10,112.66,615.39,297.41,10.91" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="10,230.72,601.84,275.27,10.91;10,112.66,615.39,134.20,10.91">Recognition of the amazonian flora by inceptionnetworks with test-time class prior estimation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,259.41,615.39,100.80,10.91">CLEF (Working Notes)</title>
		<imprint>
			<biblScope unit="page">188</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,628.93,393.33,10.91;10,112.66,642.48,393.32,10.91;10,112.66,656.03,171.70,10.91" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="10,398.54,628.93,107.45,10.91;10,112.66,642.48,273.79,10.91">Deep learning for plant identification: how the web can compete with human experts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Hang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,394.81,642.48,111.17,10.91;10,112.66,656.03,99.01,10.91">Biodiversity Information Science and Standards</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">25637</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,669.58,393.33,10.91;11,112.66,86.97,393.33,10.91;11,112.66,100.52,57.08,10.91" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="10,314.19,669.58,191.80,10.91;11,112.66,86.97,50.14,10.91">Entropy-guided open-set fine-grained fungi recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,187.42,86.97,318.56,10.91;11,112.66,100.52,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,395.17,10.91;11,112.66,127.61,395.17,10.91;11,112.66,141.16,232.29,10.91" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="11,209.42,114.06,298.41,10.91;11,112.66,127.61,238.06,10.91">It is all about the metrics: Optimizing transformer-based fungiclassification for multiple application-oriented metrics</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,373.53,127.61,134.30,10.91;11,112.66,141.16,201.59,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,154.71,393.32,10.91;11,112.66,168.26,393.33,10.91;11,112.66,181.81,57.08,10.91" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="11,356.81,154.71,149.17,10.91;11,112.66,168.26,57.91,10.91">A deep learning based solution to fungiclef</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X.-S</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,193.68,168.26,312.30,10.91;11,112.66,181.81,26.38,10.91">Working Notes of CLEF 2023 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,195.36,393.33,10.91;11,112.66,208.91,181.25,10.91" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="11,203.02,195.36,302.96,10.91;11,112.66,208.91,35.11,10.91">Transformer-based fine-grained fungi classification in an open-set scenario</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,156.09,208.91,105.91,10.91">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,222.46,394.53,10.91;11,112.66,236.01,394.53,10.91;11,112.66,249.56,90.72,10.91" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="11,251.23,222.46,251.23,10.91">Lvis: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,127.24,236.01,375.49,10.91">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5356" to="5364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,263.11,394.53,10.91;11,112.66,276.66,374.67,10.91" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="11,301.13,263.11,201.50,10.91">Volo: Vision outlooker for visual recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,112.66,276.66,280.59,10.91">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="6575" to="6586" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,290.20,394.53,10.91;11,112.28,303.75,368.43,10.91" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="11,112.28,303.75,243.36,10.91">Albumentations: fast and flexible image augmentations</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Buslaev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">I</forename><surname>Iglovikov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Khvedchenya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Parinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Druzhinin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,364.46,303.75,53.51,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
