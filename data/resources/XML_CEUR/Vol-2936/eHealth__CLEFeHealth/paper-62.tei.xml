<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,365.65,15.42">Consumer Health Search at CLEF eHealth 2021</title>
				<funder ref="#_K8Jga4G">
					<orgName type="full">Commonwealth Scientific and Industrial Research Organisation</orgName>
				</funder>
				<funder>
					<orgName type="full">Our Health in Our Hands (OHIOH)</orgName>
				</funder>
				<funder ref="#_G2bD9fy">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">CLEF Initiative</orgName>
				</funder>
				<funder ref="#_hNZwWyp">
					<orgName type="full">Austrian FWF</orgName>
				</funder>
				<funder>
					<orgName type="full">Australian National University</orgName>
					<orgName type="abbreviated">ANU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,113.06,88.23,11.96"><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
							<email>lorraine.goeuriot@univ-grenoble-alpes.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,190.16,113.06,84.76,11.96"><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
							<email>hanna.suominen@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Data61</orgName>
								<orgName type="department" key="dep2">Commonwealth Scientific and Industrial Research Organisation</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Turku</orgName>
								<address>
									<settlement>Turku</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.15,113.06,67.18,11.96"><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
							<email>gabriella.pasi@unimib.it</email>
							<affiliation key="aff4">
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>DISCo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.97,113.06,63.17,11.96"><forename type="first">Elias</forename><surname>Bassani</surname></persName>
							<email>elias.assani@unimib.it</email>
							<affiliation key="aff4">
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>DISCo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Consorzio per il Trasferimento Tecnologico -C2T</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,127.00,84.67,11.96"><forename type="first">Nicola</forename><surname>Brew-Sam</surname></persName>
							<email>nicola.brew-sam@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,186.60,127.00,114.70,11.96"><forename type="first">Gabriela</forename><surname>González-Sáez</surname></persName>
							<email>gabriela-nicole.gonzalez-saez@univ-grenoble-alpes.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.94,127.00,55.68,11.96"><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
							<email>liadh.kelly@mu.ie</email>
							<affiliation key="aff6">
								<orgName type="institution">Maynooth University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,382.26,127.00,84.26,11.96"><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
							<email>philippe.mulhem@univ-grenoble-alpes.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,140.95,100.61,11.96"><forename type="first">Sandaru</forename><surname>Seneviratne</surname></persName>
							<email>sandaru.seneviratne@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.55,140.95,91.96,11.96"><forename type="first">Rishabh</forename><surname>Upadhyay</surname></persName>
							<email>r.upadhyay@campus.unimib.it</email>
							<affiliation key="aff4">
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>DISCo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.15,140.95,69.38,11.96"><forename type="first">Marco</forename><surname>Viviani</surname></persName>
							<email>marco.viviani@unimib.it</email>
							<affiliation key="aff4">
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>DISCo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,407.53,140.95,66.58,11.96"><forename type="first">Chenchen</forename><surname>Xu</surname></persName>
							<email>chenchen.xu@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Data61</orgName>
								<orgName type="department" key="dep2">Commonwealth Scientific and Industrial Research Organisation</orgName>
								<address>
									<settlement>Canberra</settlement>
									<region>ACT</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,365.65,15.42">Consumer Health Search at CLEF eHealth 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B22BAEA04C66BD0041C8D6680B1BDFDF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Relevance</term>
					<term>eHealth</term>
					<term>Evaluation</term>
					<term>Health Records</term>
					<term>Medical Informatics</term>
					<term>Information Storage and Retrieval</term>
					<term>Self-Diagnosis</term>
					<term>Test-set Generation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper details materials, methods, results, and analyses of the Consumer Health Search Task of the CLEF eHealth 2021 Evaluation Lab. This task investigates the effectiveness of information retrieval (IR) approaches in providing access to medical information to laypeople. For this a TREC-style evaluation methodology was applied: a shared collection of documents and queries is distributed, participants' runs received, relevance assessments generated, and participants' submissions evaluated. The task generated a new representative web corpus including web pages acquired from a 2021 CommonCrawl and social media content from Twitter and Reddit, along with a new collection of 55 manually generated layperson medical queries and their respective credibility, understandability, and topicality assessments for returned documents. This year's task focused on three subtask: (i) ad-hoc IR, (ii) weakly supervised IR, and (iii) document credibility prediction. In total, 15 runs were submitted to the three subtasks: eight addressed the ad-hoc IR task, three the weakly supervised IR challenge, and 4 the document credibility prediction challenge. As in previous years, the organizers have made data and tools associated with the task available for future research and development.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In today's information overloaded society, using a web search engine to find information related to health and medicine that is credible, easy to understand, and relevant to a given information need is increasingly difficult, thereby hindering patient and public involvement in healthcare <ref type="bibr" coords="2,138.92,151.93,11.51,10.91" target="#b0">[1]</ref>. These problems are referred to as credibility, understandability, and topicality dimensions of relevance in information retrieval (IR) <ref type="bibr" coords="2,318.33,165.48,11.23,10.91" target="#b1">[2,</ref><ref type="bibr" coords="2,331.81,165.48,7.42,10.91" target="#b2">3,</ref><ref type="bibr" coords="2,341.48,165.48,7.42,10.91" target="#b3">4,</ref><ref type="bibr" coords="2,351.16,165.48,7.42,10.91" target="#b4">5,</ref><ref type="bibr" coords="2,360.83,165.48,7.49,10.91" target="#b5">6]</ref>. The CLEF eHealth lab (https:// clefehealth.imag.fr/) of the Conference and Labs of the Evaluation Forum (CLEF, formerly known as Cross-Language Evaluation Forum, http://www.clef-initiative.eu/) is a research initiative that aims at providing datasets and gathering researchers working on information extraction, management and retrieval tasks in the medical comain. Since its establishment in 2012, CLEF eHealth has included eight IR tasks on CHS with more more than twenty subtasks in total <ref type="bibr" coords="2,89.29,246.77,11.48,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,104.71,246.77,7.52,10.91" target="#b7">8,</ref><ref type="bibr" coords="2,116.17,246.77,7.52,10.91" target="#b8">9,</ref><ref type="bibr" coords="2,127.62,246.77,12.59,10.91" target="#b9">10,</ref><ref type="bibr" coords="2,144.15,246.77,12.59,10.91" target="#b10">11,</ref><ref type="bibr" coords="2,160.68,246.77,12.59,10.91" target="#b11">12,</ref><ref type="bibr" coords="2,177.21,246.77,12.59,10.91" target="#b12">13,</ref><ref type="bibr" coords="2,193.74,246.77,12.59,10.91" target="#b13">14,</ref><ref type="bibr" coords="2,210.27,246.77,12.59,10.91" target="#b14">15,</ref><ref type="bibr" coords="2,226.80,246.77,12.59,10.91" target="#b15">16,</ref><ref type="bibr" coords="2,243.33,246.77,12.42,10.91" target="#b16">17]</ref>. Its usage scenario is to ease and support laypeople, policymakers, and healthcare professionals in understanding, accessing, and authoring eHealth information in a multilingual setting.</p><p>In 2021, CLEF eHealth initiative has organised a CHS task with the following three IR subtasks: 1. Adhoc IR, 2. Weakly Supervised IR, and 3. Document Credibility Prediction.</p><p>The task has challenged researchers, scientists, engineers, analysts, and graduate students to develop better IR systems to support creating web-based search tools that return webpages that are better suited to laypeople's information needs from perspectives of 1. information topicality (i.e., how relevant are the contents to the search topic), 2. information understandability (i.e., how easily can a layperson understand the contents), and 3. information credibility (i.e., should the contents be trusted).</p><p>As a continuation of the previous CLEF eHealth IR tasks that ran in 2013-2018, and 2020 <ref type="bibr" coords="2,495.86,447.75,11.33,10.91" target="#b1">[2,</ref><ref type="bibr" coords="2,89.04,461.29,12.50,10.91" target="#b17">18,</ref><ref type="bibr" coords="2,104.05,461.29,12.50,10.91" target="#b18">19,</ref><ref type="bibr" coords="2,119.05,461.29,12.50,10.91" target="#b19">20,</ref><ref type="bibr" coords="2,134.06,461.29,12.50,10.91" target="#b20">21,</ref><ref type="bibr" coords="2,149.06,461.29,12.50,10.91" target="#b21">22,</ref><ref type="bibr" coords="2,164.07,461.29,12.50,10.91" target="#b22">23,</ref><ref type="bibr" coords="2,179.08,461.29,12.23,10.91" target="#b23">24]</ref>, the 2021 CHS task has embraced the Text REtrieval Conference (TREC) -style evaluation process. Namely, it has designed, developed, and deployed a shared collection of documents and queries, called for the contribution of runs from participants, and conducted the subsequent formation of relevance assessments and evaluation of the participants' submissions.</p><p>The main contributions of the CLEF eHealth 2021 task on CHS are as follows:</p><p>1. generating a novel representative web corpus, 2. collecting layperson medical queries, 3. attracting new submissions from participants, 4. contributing to IR evaluation metrics relevant to the three dimensions of document relevance, and 5. evaluating IR systems (i.e., runs submitted by the task participants or from organizers' baseline systems) on newly conducted assessments.</p><p>The remainder of this paper is structured as follows: First, Section 2 details the task. Then, Section 3 introduces the document collection, topics, baselines, pooling strategy, and evaluation metrics. After this, Section 4 presents the participants and their approaches while Section 5 addresses their results. Finally, Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Description of the Tasks</head><p>In this section, we provide a description of the three subtasks offered in this year's CHS task, namely: Subtask 1 on ad-hoc IR; Subtask 2 on weakly supervised IR; and Subtask 3 on document credibility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Subtask 1: Adhoc Information Retrieval</head><p>Similar to previous years of the CHS task, this was a standard ad-hoc IR task. A document collection was provided to task participants along with realistic layperson medical information need use cases, both described in Section 3. The purpose of the task was to evaluate IR systems' abilities to provide users with credible, understandable, and topical documents. As such, participating teams submitted their runs, which were pooled together with baseline runs and manual relevance assessments conducted, also described in Section 3. These systems' performance was assessed on multiple dimensions of relevance -credibility, understandability, and topicality. Evaluation metrics employed for this task are described in Section 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Subtask 2: Weakly Supervised Information Retrieval</head><p>This task aimed to evaluate the ability of machine learning-based ad-hoc IR models, trained with weak supervision, to retrieve relevant documents in the health domain. In order to train neural models to address the search task, a large collection of real-world health related queries extracted from commercial search engine query logs and synthetic (weak) relevance scores computed with a competitive IR system were considered. The submissions were evaluated against the same test set as Subtask 1 submissions, in order to allow a full comparison of traditional vs neural approaches. Details on the methods and materials associated with this task are described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Subtask 3: Document Credibility Prediction</head><p>The purpose of this task was the automatic assessment of the credibility of information that is disseminated online, through the Web and social media. Using the dataset related to Subtask 1, this task aimed at comparing approaches estimating documents credibility. The ground truth for this classification task is based on the credibility labels assigned to documents during the relevance assessment process. Evaluation of the runs includes classical classification metrics and investigates the ability of the participants systems to perform well on both web documents and social media content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Materials and Methods</head><p>In this section, we will describe the materials and methods used in the CHS task of the CLEF eHealth evaluation lab 2021. After introducing our new document collection and novel topics, we will describe our baseline systems and pooling methodology. Finally, we will address our relevance assessments and evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Document Collection</head><p>The 2021 CLEF eHealth Consumer Health Search document collection consisted of two separate crawls of documents: web documents acquired from the CommonCrawl and social media documents composed by Reddit and Twitter submissions.</p><p>First, we acquired web pages from the CommonCrawl. We extracted an initial list of websites from the 2018 CHS task of CLEF eHealth. This list was built by submitting a set of medical queries to the Microsoft Bing Application Programming Interfaces (through the Azure Cognitive Services) repeatedly over a period of a few weeks, and acquiring the uniform resource Locators (URL) of the retrieved results <ref type="bibr" coords="4,224.03,202.38,16.55,10.91" target="#b21">[22,</ref><ref type="bibr" coords="4,243.42,202.38,12.42,10.91" target="#b12">13]</ref>. We included the domains of the acquired URLs in the 2021 list, except some domains that were excluded for decency reasons. After this, similarly to 2018, we augmented the list by including a number of known reliable and unreliable health websites, domains, and social media contents of ranging reliability levels. Finally, we further extended the list by including websites that were highly relevant for the task queries to finalize our list of 600 domains. In summary, we introduced thirteen new domains in 2021 compared to the 2018 collection, and then the newly crawled domains from the latest CommonCrawl 2021-04 (https://commoncrawl.org/2021/02/january-2021-crawl-archive-now-available/).</p><p>Second, we complemented the collection with social media documents from Reddit and Twitter. As the first step, we selected a list of 150 health topics related to various health conditions. Then, we generated search queries manually from those topics and submitted them to Reddit to retrieve posts and comments. After this, we applied the same process on Twitter to get related tweets from the platform.</p><p>Please note that for the purposes of the 2021 CHS task, we defined a social media document as a text obtained by a single interaction. This implied that • on Reddit, a document is composed by a post, one comment of the post, and associated meta-information and • on Twitter, a document is a single tweet with its associated meta-information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Topics</head><p>The set of topics of CLEF eHealth IR task aimed at being representative of laypersons' medical information needs in various scenarios. This year, the set of topics was collected from two sources as follows:</p><p>• The first part was based on our insights from consulting laypeople with lived experience of multiple sclerosis (MS) or diabetes to motivate, validate, and refine the search scenarios; we, as experts in IR and CHS tasks, captured these layperson-informed insights as the scenarios. • The second part was based on use cases from Reddit health forums; we extracted and manually selected a list of topics from Google trends to best fit each use case.</p><p>As a result, we had a new set of 55 queries in English for authoring realistic search scenarios. To describe the scenarios, we enriched each query manually by labels in English either to characterize the search intent (for manually created queries) or to capture the submission text (for social medial queries) (Table <ref type="table" coords="4,236.92,669.58,3.64,10.91" target="#tab_2">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>suicidal terrified. I don't have any underlying conditions and while I'm not young I'm not old either. I don't smoke and I'm not terribly overweight. I don't have insulin resistance and my reproductive organs looks good other than my ovaries. I'd been taking the combo pill to skip periods for months now. I don't even take the brown pills. When I first heard that you can skip periods and only have 2-3 a year when taking brown pills I started on them. The first time I tried to have a period on the brown pills nothing happened. No period. This was 2 years ago. I freaked out but they said I just respond strongly to the pills. So I went off of the pills completely and had 2-3 normal periods starting about 2 months later. Could the birth control be suppressing my antral follicle count and amh this much? Please help.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Illustration of Some of Our Queries and Narratives Subtasks 1, 2, and 3 used these 55 queries with 5 released for training and 50 reserved for testing; the test topics contained a balanced sample of the manually constructed and automatically extracted search scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Baseline Systems</head><p>With respect to both Subtask 1 and Subtask 2, we provided six baseline systems. These systems applied the Okapi BM25 (BM for Best Matching), Dirichlet Language Model (DirichletLM), and Term Frequency times Inverse Document Frequency (TF×IDF) algorithms with default parameters. Each of them was implemented without and with pseudo relevance feedback (RF) using default parameters (DFR Bo1 model <ref type="bibr" coords="5,278.25,592.14,17.94,10.91" target="#b24">[25]</ref> on three documents, selecting ten terms). This resulted in the 3 × 2 = 6 baseline systems. The systems are implemented using Terrier version 5.4 <ref type="bibr" coords="5,104.56,619.24,17.91,10.91" target="#b25">[26]</ref> as following:</p><formula xml:id="formula_0" coords="5,89.29,635.23,417.82,7.90">terrier batchretrieve -t topics.txt -w [TF_IDF|DirichletLM|BM25] [-q|].</formula><p>Regarding Subtask 3, where it is necessary to evaluate the effectiveness of the approaches with respect to assessing the credibility of information, it was decided to approach the problem as a binary classification (identification of credible versus non-credible information). For this reason, simple baselines were developed based on supervised classifiers that act on a set of features that can be extracted from the documents under consideration. Dealing with documents that are both Web pages and social content, it was necessary to consider, in baseline development, only those features that are directly extractable from the text of the documents. For social content, it would also be possible to consider other metadata related to the social network of the authors of the posts, but for consistency with the evaluation of Web pages, such metadata have not been considered.</p><p>The employed supervised classifiers are based on Support Vector Machines (SVM), Random Forests (RF), and Logistic Regression (LR), i.e., the machine learning techniques that have proven to be more effective for binary credibility assessment in the literature <ref type="bibr" coords="6,401.59,222.46,16.28,10.91" target="#b26">[27]</ref>. Such baselines act on the following linguistic features: the TF×IDF text representation, the word embedding text representation obtained by Word2vec pre-trained on Google News, <ref type="foot" coords="6,376.38,247.80,3.71,7.97" target="#foot_0">1</ref> and, given the health-related scenario considered, the word embedding representation obtained by Word2vec pre-trained on both PubMed and Medical Information Mart for Intensive Care III (MIMIC-III). <ref type="foot" coords="6,446.44,274.90,3.71,7.97" target="#foot_1">2</ref> Python and the scikit-learn library <ref type="bibr" coords="6,213.46,290.20,18.00,10.91" target="#b27">[28]</ref> have been employed for implementing the machine learning algorithms and for producing the TF×IDF text representation. Furthermore, we have considered threshold tuning to get the optimal cut-off for the runs, based on the Youden's index <ref type="bibr" coords="6,467.32,317.30,16.25,10.91" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pooling Methodology</head><p>Similar to the 2016, 2017, 2018, and 2020 pools, we created the pool using the rank-biased precision (RBP)-based Method A (Summing contributions) <ref type="bibr" coords="6,341.53,380.58,17.76,10.91" target="#b29">[30]</ref> in which documents are weighted according to their overall contribution to the effectiveness evaluation as provided by the RBP formula (with 𝑝 = 0.8, following a study published in 2007 on RBP <ref type="bibr" coords="6,390.02,407.68,15.74,10.91" target="#b30">[31]</ref>). This strategy, called RBPA, has been proven more efficient than traditional fixed-depth or stratified pooling to evaluate systems under fixed assessment budget constraints <ref type="bibr" coords="6,366.24,434.78,16.42,10.91" target="#b31">[32]</ref>, as it was the case for this task. All participants' runs were considered on the document's pool, along with six baselines provided by the organizers. In order to guarantee the judgements of the documents of the participants' runs, half of the pool was composed by their documents and half from documents of the baselines' runs which resulted in 250 documents per query in the pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Relevance Assessment</head><p>The credibility, understandability, and topicality assessments were performed by 26 volunteers (19 women and 7 men) in May-June 2021. Of these assessors, 16 were from Australia, 4 from Italy, 3 from France, 2 from Ireland, and 1 from Finland. We recruited, trained, and supervised them by using bespoke written materials from April to June 2021. The recruitment took place via email and on social media, using both our existing contacts and snowballing.</p><p>We implemented these assessments online by expanding and customising the Relevation! tool for relevance assessments <ref type="bibr" coords="6,231.09,619.99,18.06,10.91" target="#b32">[33]</ref> to capture the three dimensions of document relevance, and their scale (see <ref type="bibr" coords="6,178.20,633.54,16.56,10.91" target="#b16">[17,</ref> for illustrations of the online assessment environment).</p><p>We associated every query with 250 documents to be assessed with respect to their credibility, understandability, and topicality. Initially, we allocated each assessor with 2 queries for their assessment and then revised these allocations based on their individual needs and availability. In the end, every assessor completed 1-4 queries.</p><p>Ethical approval (2021/013) was obtained for all aspects of this assessment study involving human participants as assessors from the Human Research Ethics Committee of the Australian National University (ANU). Each study participant provided informed consent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Evaluation Metrics</head><p>We considered evaluation measures that allowed to evaluate both:</p><p>1. the effectiveness of the systems with respect to the ranking produced by taking into account the three criteria considered, and 2. the accuracy of the (binary) classification of documents with respect to credibility (Subtask 3).</p><p>Specifically, with regard to the first aspect, this included the following performance evaluation measures: Mean Average Precision (MAP), preference-based BPref metric, normalized Discounted Cumulative Gain (nDCG), understandability-based variant of Rank Biased Precision (uRBP), and credibility-ranked Rank Biased Precision (cRBP) <ref type="bibr" coords="7,360.64,340.35,11.43,10.91" target="#b5">[6]</ref>.</p><p>With respect to the second aspect, we referred to classical measures to assess the goodness of a classifier, such as Accuracy and the Area under the Receiver Operating Characteristic (ROC) Curve (AUC) <ref type="bibr" coords="7,149.86,380.99,16.21,10.91" target="#b33">[34]</ref>. In particular, since Subtask 3 is also devoted to assess credibility in relation to information needs (topics), also the average of a Topic-based Credibility Precision w.r.t. each topic, namely CP(𝑞), has been considered. A brief explanation of the three measures that need more detail, namely uRBP, cRBP, and CP(𝑞) is provided below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1.">Understandability-Ranked Biased Precision</head><p>The uRBP measure evaluates IR systems by taking into account both topicality and understandability dimensions of relevance. In particular, the function for calculating uRBP was <ref type="bibr" coords="7,464.66,497.98,16.39,10.91" target="#b34">[35]</ref>:</p><formula xml:id="formula_1" coords="7,202.82,521.23,303.16,33.98">uRBP = (1 -𝜌) 𝐾 ∑︁ 𝑘=1 𝜌 𝑘-1 𝑟(𝑑@𝑘)• 𝑢(𝑑@𝑘),<label>(1)</label></formula><p>where 𝑟(𝑑@𝑘) is the relevance of the document 𝑑 at position 𝑘, 𝑢(𝑑@𝑘) is the understandability value of the document 𝑑 at position 𝑘, and the persistent parameter 𝜌 models the user desire to examine every answer, which was set to 0.50, 0.80, and 0.95 to obtain three version of uRBP, according to different user behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2.">Credibility-Ranked Biased Precision</head><p>In CLEF eHealth 2020, we have adapted uRBP to credibility, obtaining the so-called credibilityranked biased precision (cRBP) measure <ref type="bibr" coords="7,270.18,669.58,11.32,10.91" target="#b5">[6]</ref>. In this case the function for calculating cRBP was the same used to calculate uRBP, replacing 𝑢(𝑑@𝑘) by the credibility value of the document 𝑑 at position 𝑘, 𝑐(𝑑@𝑘):</p><formula xml:id="formula_2" coords="8,204.14,124.47,301.84,33.98">cRBP = (1 -𝜌) 𝐾 ∑︁ 𝑘=1 𝜌 𝑘-1 𝑟(𝑑@𝑘)• 𝑐(𝑑@𝑘).<label>(2)</label></formula><p>As in uRBP, the parameter 𝜌 was set to three values, from an impatient user (0.50) to more persistent users (0.80 and 0.95).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.3.">Topic-based Credibility Precision</head><p>The precision in retrieving credible documents can be calculated over the top-𝑘 documents in the ranking, for each topic (query) 𝑞, as follows:</p><formula xml:id="formula_3" coords="8,191.29,269.29,212.70,24.43">CP(𝑞) = #𝑐𝑟𝑒𝑑𝑖𝑏𝑙𝑒_𝑟𝑒𝑡𝑟𝑖𝑒𝑣𝑒𝑑_𝑑𝑜𝑐𝑠_𝑡𝑜𝑝_𝑘(𝑞) #𝑟𝑒𝑡𝑟𝑖𝑒𝑣𝑒𝑑_𝑑𝑜𝑐𝑠_𝑡𝑜𝑝_𝑘(𝑞) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Participants and Approaches</head><p>In 2021, 43 teams registered for the task on the web site and two teams submitted runs to the subtasks. We provided the registered participants with the crawler code and the domain list of the crawl for both the web documents and social media documents. They also had access to indexes built by organizers from the document collection on demand. Participants' submissions were due by 8 May 2021.</p><p>Of the four run submissions, two were to Subtask 1 on Adhoc IR, one was to Subtask 2 on Weakly Supervised IR, and one was to Subtask 3 on Document Credibility Prediction. The teams were from two countries (i.e., China and Italy) in two continents (i.e., Asia and Europe). In Subtask 1, the submissions were by 1. a 4-member team from the School of Computer Science, Zhongyuan University of Technology (ZUT) in Zhengzhou, China <ref type="bibr" coords="8,276.81,480.04,17.91,10.91" target="#b35">[36]</ref> and 2. a 2-member team from the Information Management Systems (IMS) Research Group, University of Padova (UniPd), Padova, Italy <ref type="bibr" coords="8,312.01,508.50,16.25,10.91" target="#b36">[37]</ref>.</p><p>In Subtasks 2 and 3, the submissions were by the leader of this IMS UniPd team <ref type="bibr" coords="8,436.50,528.82,17.75,10.91" target="#b36">[37]</ref> -a regular participant in our previous CHS tasks. The two teams submitted the following types of document ranking approaches as runs to the Adhoc IR subtask (Table <ref type="table" coords="8,221.92,569.47,3.71,10.91" target="#tab_4">4</ref>): Team ZUT used a learning-to-rank approach in all its four submitted runs, but with four different machine learning algorithms to train their models <ref type="bibr" coords="8,487.40,583.02,16.21,10.91" target="#b35">[36]</ref>. In contrast, Team UniPd founded their four submissions on a renown Python framework for IR called PyTerrier as variants of Reciprocal Rank Fusion with the provided Terrier index <ref type="bibr" coords="8,475.18,610.12,16.25,10.91" target="#b36">[37]</ref>.</p><p>The UniPd team submitted closely related approaches to the other two subtasks (Table <ref type="table" coords="8,496.73,623.67,3.65,10.91" target="#tab_4">4</ref>). Namely, they also submitted their aforementioned four approaches to the Weekly Supervised IR subtask and two of them and another two of their variants to the Document Credibility Prediction subtask <ref type="bibr" coords="8,176.96,664.31,16.25,10.91" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtasks Team Run Approach</head><p>Algorithmic Details </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In 2021, the CLEF eHealth CHS task generated a new representative Web corpus including Web pages acquired from a 2021 CommonCrawl, and social media content from Twitter and Reddit. A new collection of 55 manually generated layperson medical queries was also created, along with their respective credibility, understandability, and topicality assessments for returned documents. In total, 15 runs were submitted to the three subtasks on adhoc IR, weakly supervised IR, and document credibility prediction, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Coverage of Relevance Assessments</head><p>A total of 12, 500 assessments were made on 11, 357 documents: 7, 400 Web documents, and 3, 957 social media documents. Figure <ref type="figure" coords="9,258.61,598.94,4.97,10.91" target="#fig_0">1</ref> shows the number of social media and Web documents that were assessed for each query. The bottom part shows which queries were created from discussion with patients (Expert queries), and queries created from discussions on social media (Social media queries). We can see that Web documents took a bigger part of the pool of documents. Nevertheless, the proportion of social media documents was bigger for queries based on social media. A special case is presented in queries 22, 63, and 116, where the pool of documents was composed by Web documents only. This means that the submitted runs retrieved only Web documents. While the distribution of the assessments on topicality and understandability dimensions were similar on social media and Web documents, the credibility assessments presented a big difference (Table <ref type="table" coords="10,164.07,519.50,3.57,10.91" target="#tab_5">5</ref>.1), with only 12 documents (less than 1% of social media assessed documents) were assessed as highly credible in the social media set, in contrast to the 4, 552 (54% of Web assessed documents) highly credible Web documents. Finally, an important part of social media documents were assessed as not credible. Figure <ref type="figure" coords="10,310.63,560.15,5.17,10.91" target="#fig_1">2</ref> shows the relationship between the three dimensions of relevance; its diagonal exemplifies the distribution of each dimension. Each plot exposes the number of documents evaluated as "highly", "somewhat", or "not", with respect to two dimensions of relevance (one in each axis). By example, in social media assessments the Figure <ref type="figure" coords="10,120.98,614.35,5.17,10.91" target="#fig_1">2</ref> shows for the not credible documents that a fraction is not topical relevant, a set of documents is somewhat topical relevant, and a small part of the not credible is anyways highly topically relevant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Subtask 1: Adhoc Information Retrieval</head><p>In this section we present the results for the Adhoc IR subtask where the systems were evaluated in different dimensions of relevance. For topicality, we evaluated the systems using MAP, BPref, and NDCG@10 performances metrics. For readability, we made use of uRBP that considers topicality and understandability of the documents. Finally, in order to include credibility in our evaluation, we measured systems' cRBP performance that considers topicality and credibility of the document.</p><p>Table <ref type="table" coords="11,126.96,449.82,4.17,10.91" target="#tab_5">5</ref>.2 presents the ranking of participant systems and organizers baselines, with respect to three metrics of topical relevance: MAP, BPref, and NDCG@10. The team achieving the highest results was UniPd. Their top run, original_rm3_rrf used Reciprocal Rank Fusion with BM25, QLM, DFR approaches using pseudo relevance feedback with 10 documents and 10 terms (query weight 0.5). It achieved 0.43 MAP and 0.51 BPref. The best system of ZUT team was their run3, which used learning to rank techniques with a model trained using Random Forests. ZUT run3 was the best systems of the team on the three metrics with 0.4 MAP, 0.47 BPref, and 0.66 NDCG@10. For BPref and NDCG@10, the organizers baseline using TF×IDF with query expansion obtained higher results.</p><p>Table <ref type="table" coords="11,127.31,571.76,4.23,10.91" target="#tab_5">5</ref>.2 compares the results of our baseline systems with respect to last year's Adhoc IR task results. In the case of MAP and BPref metrics, all the systems had better performance on 2021 test collection; for NDCG@10, DirichletLM with and without relevance feedback had a better performance on 2020 test collection. Despite this clear improvement from 2020 to 2021, the ranking of systems has changed in all the metrics. Namely, in 2020, the best MAP and BPref performance was achieve by DirichletLM, and TF×IDF with respect to NDCG@10 metric. In contrast, in this year's task, the best baseline MAP, Bpref, and NDCG@10 was achieved by TF×IDF with relevance feedback.</p><p>Rank Team -run MAP Team -run BPref Team -run NDCG@10  The results for all participants for readability and credibility evaluation is shown in Table <ref type="table" coords="12,493.02,587.61,3.66,10.91" target="#tab_5">5</ref>.2. For readability evaluation the best run was the baseline system TF×IDF with relevance feedback. The best participant system was ZUT's run3 that is the same system that presented the best performance in terms of topicality as well. For credibility evaluation, the best run was the baseline system DirichletLM while the best participant system was UniPd's original_rm3_rrfthe best system of the team in topicality evaluation. Runs ranked for readability relevance dimension (rRBP) and credibility (cRBP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Subtask 2: Weakly Supervised Information Retrieval</head><p>The purpose of the task was to evaluate systems based on machine learning, trained on the weakly supervised dataset. UniPD submitted their runs to Subtask 1 for this subtask, which are not trained on the weakly supervised dataset. Their submission provides a kind of baseline for a system that does not use any information. Since no other team submitted runs to this task, we cannot provide any evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Subtask 3: Document Credibility Prediction</head><p>The UniPd team, to assess document credibility, reused the runs computed in Subtask 1 and grouped them in order to produce a single score for each document. Their simple hypothesis was that documents that have a higher score across different search engines are also more credible. Their approach did not consider any additional information about the provenance of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.">Credibility Assessment as a Binary Classification Problem</head><p>The results illustrated in this section were obtained by performing a binary credibility assessment using the CLEF 2020 eHealth dataset for training the baselines and testing on a subset of the CLEF 2021 eHealth data, that is, those that were employed for both runs subtask1_ims_original and subtask1_ims_simplified submitted by the UniPd team. In this case, the topics against which the documents were retrieved are not taken into account. The results of classifying documents according to their credibility using both simple baselines (illustrated in Section 3.3) and considered runs are illustrated in Table <ref type="table" coords="13,284.92,628.88,3.74,10.91" target="#tab_7">7</ref>.</p><p>The results obtained from both baselines and runs were evaluated by means of classical measures in the context of document classification, that is, the AUC and Accuracy (as discussed in Section 3.6). As it can be observed from the table, having considered only linguistic features, the classification results obtained were not particularly significant to the considered problem, neither for the runs nor for the baselines considered. The idea discussed by the members of the UniPd group, that documents having a higher score across different search engines are also more credible, did not appear to be supported by these results, but nevertheless merited future investigation, in particular in relation to the results reported in the next section. Regarding the baselines, it was possible to observe that, when supervised classifiers employ the word embedding text representation obtained by Word2vec pre-trained on biomedical datasets, such as Pubmed and MIMIC-III, we obtained best results as compared to their counterparts employing text representation features based on TF×IDF and Word2vec pre-trained on the general-purpose Google News dataset. However, it must be considered that, in general, the Accuracy values in particular could be influenced by the fact that the dataset considered was strongly unbalanced, being made up of about 20% of documents labeled as credible and 80% labeled as non-credible. Probably, this should also raise the need to deepen an analysis about the way in which human assessors evaluate the documents proposed to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2.">Topic-based Credibility Assessment</head><p>Regarding the problem of assessing the credibility of the documents retrieved with respect to the topics considered, we provide below the results relative to the runs sent by UniPD, namely subtask2_ims_original and subtask2_ims_simplified. In this case, for each topic considered, the precision in retrieving credible documents with respect to the topic was evaluated based on the value of CP(𝑞) calculated as shown in Section 3.6.3.</p><p>In Table <ref type="table" coords="15,139.57,127.61,3.81,10.91" target="#tab_8">8</ref>, we report the average CP(𝑞) values with respect to the set of topics considered. Specifically, the top-100 and top-200 documents retrieved with respect to each topic were taken into account in computing the CP(𝑞) metric. As it can be observed from the table, with respect to the evaluations carried out in the previous case related to binary credibility assessment (i.e., Section 5.4.1), it seems that the methods applied in the two submitted runs that consider credibility associated with documents retrieved with respect to specific topics, actually managed to find credible information in the first top-𝑘 positions, in particular as 𝑘 decreases. In general, the most effective method seems to be the one implemented in the run subtask2_ims_original; however, from specific observations with respect to the results submitted by the participants (which are omitted in this paper), we can state that the second method, the one implemented in subtask2_ims_simplified, proved to be particularly efficient for some topics (even more than the method implemented in subtask2_ims_original) and much less so with respect to others, leading to a lower average CP(𝑞) value. It is therefore worth investigating this aspect more in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper has described methods, results and analysis of the Consumer Health Search (CHS) challenge at the CLEF eHealth 2021 Evaluation Lab. The task considered the problem of lay people searching for medical information related to their health condition on the web. In particular, across web pages and social media content. The task included three subtasks on ad hoc IR, weakly supervised IR, and document credibility prediction. 15 runs were submitted to these tasks.</p><p>The CLEF eHealth CHS challenge, first ran at the inaugural CLEF eHealth lab in 2013, and has offered since then TREC-style IR challenges with medical datasets consisting of large medical web and lay person query collections. As a by-product of this evaluation exercise, the task contributes to the research community a collection with associated assessments and evaluation framework that can be used to evaluate the effectiveness of retrieval methods for health information seeking on the web. Queries, assessments, and participants' runs for the 2021 CHS challenge are publicly available at https://github.com/CLEFeHealth/CHS-2021 and previous years' CHS collections are available at https://github.com/CLEFeHealth/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,89.29,438.79,418.36,8.93;10,89.29,450.79,416.70,8.87;10,89.29,462.75,247.54,8.87;10,89.29,245.95,416.69,173.45"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Proportion of social media and Web documents per each query, orange represents the proportion of Web documents and blue social media. The bottom line shows queries based on experts discussions with patients, and queries based on reddit posts.</figDesc><graphic coords="10,89.29,245.95,416.69,173.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,89.29,298.40,416.69,8.93;11,89.29,310.40,74.77,8.87;11,89.29,84.19,416.70,195.66"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relationship between pairs of relevance dimensions, and distribution of assessments for each type of document.</figDesc><graphic coords="11,89.29,84.19,416.70,195.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,240.56,669.58,14.56,10.91"><head></head><label></label><figDesc>.2). 've been on birth control taking only active pills for months now and I went in to a doctor's office to inquire about egg freezing. She seemed optimistic that my ultrasound would be very reassuring but instead she came away from the ultrasound deeply concerned. I did an AMH test and it came back 0.3 which was consistent with what was seen in the ultrasound. I'm terrified. Like...</figDesc><table coords="5,96.81,89.95,399.17,121.98"><row><cell>Scenario Query</cell><cell></cell><cell>Narrative</cell></row><row><cell cols="2">8 best apps daily activ-</cell><cell>I'm a 15 year old with diabetes. I'm planning to join the school</cell></row><row><cell cols="2">ity exercise diabetes</cell><cell>hiking club. What are the best apps to track my daily activity</cell></row><row><cell></cell><cell></cell><cell>and exercises?</cell></row><row><cell>57 multiple</cell><cell>sclerosis</cell><cell>I read that MS develops with several stages and includes phases</cell></row><row><cell cols="2">stages phases</cell><cell>of relapse. I want to know more about how this disease develops</cell></row><row><cell></cell><cell></cell><cell>over time.</cell></row><row><cell cols="2">126 birth control sup-</cell><cell>So I</cell></row><row><cell>pression</cell><cell>antral</cell><cell></cell></row><row><cell>follicle count</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,88.19,107.38,417.80,309.53"><head>Table 2 Summary</head><label>2</label><figDesc></figDesc><table coords="9,113.56,107.38,382.49,253.45"><row><cell>1</cell><cell>ZUT</cell><cell>i Learning to Rank</cell><cell>LM</cell></row><row><cell>1</cell><cell>ZUT</cell><cell>ii Learning to Rank</cell><cell>MR</cell></row><row><cell>1</cell><cell>ZUT</cell><cell>iii Learning to Rank</cell><cell>RFs</cell></row><row><cell>1</cell><cell>ZUT</cell><cell>iv Learning to Rank</cell><cell>RB</cell></row><row><cell cols="2">1-3 UniPd</cell><cell>a RRF using PyTerrier with the</cell><cell>BM25, QLM, &amp; DFR</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell></cell></row><row><cell cols="2">1 &amp; 2 UniPd</cell><cell>b RRF using PyTerrier with the</cell><cell>BM25, QLM, &amp; DFR using the</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell>RM3 relevance language model for</cell></row><row><cell></cell><cell></cell><cell></cell><cell>pseudo RF</cell></row><row><cell cols="2">1-3 UniPd</cell><cell>c RRF using PyTerrier with the</cell><cell>BM25, QLM, &amp; DFR on manual</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell>variants of the query</cell></row><row><cell cols="2">1 &amp; 2 UniPd</cell><cell>d RRF using PyTerrier with the</cell><cell>BM25, QLM, &amp; DFR on manual</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell>variants using RM3 pseudo RF</cell></row><row><cell cols="2">3 UniPd</cell><cell>e RRF using PyTerrier with the</cell><cell>UniPd's runs a &amp; b above (i.e., the</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell>ones without manual variants of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the query) merged with min-max</cell></row><row><cell></cell><cell></cell><cell></cell><cell>normalization</cell></row><row><cell cols="2">3 UniPd</cell><cell>f RRF using PyTerrier with the</cell><cell>UniPd's runs c &amp; d above (i.e., the</cell></row><row><cell></cell><cell></cell><cell>provided Terrier index</cell><cell>ones with manual variants of the</cell></row><row><cell></cell><cell></cell><cell></cell><cell>query) merged with min-max nor-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>malization</cell></row></table><note coords="9,131.45,384.13,374.53,8.87;9,89.29,396.09,416.69,8.87;9,88.19,408.04,335.01,8.87"><p>of Runs Submitted by Participating Teams. Acronyms: BM -Best Match, DFR -divergence from randomness, LM -LambdaMART, MR -MART, RB -RankBoost, RF -relevance feedback, RFs -random forests, RRF -Reciprocal Rank Fusion, QLM -query likelihood model</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,88.99,86.02,416.99,99.26"><head>Table 3</head><label>3</label><figDesc>Number of topical (a.k.a relevant), understandable, and credible documents in social media and Web documents.</figDesc><table coords="10,132.21,86.02,328.37,57.48"><row><cell></cell><cell></cell><cell>Social Media</cell><cell></cell><cell></cell><cell>Web</cell></row><row><cell cols="3"># of documents Highly Somewhat</cell><cell cols="3">Not Highly Somewhat</cell><cell>Not</cell></row><row><cell>Topical</cell><cell>925</cell><cell cols="2">1, 046 1, 555</cell><cell>2, 175</cell><cell cols="2">2, 540 4, 259</cell></row><row><cell>Understandable</cell><cell>1, 160</cell><cell>1, 766</cell><cell>600</cell><cell>4, 758</cell><cell cols="2">3, 014 1, 202</cell></row><row><cell>Credible</cell><cell>12</cell><cell cols="2">1, 427 1, 967</cell><cell>4, 552</cell><cell>3, 123</cell><cell>753</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,88.98,399.10,374.14,132.01"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="12,88.98,411.11,374.14,120.01"><row><cell>Ad-hoc task ranking of systems</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>MAP</cell><cell></cell><cell>BPref</cell><cell></cell><cell cols="2">NDCG@10</cell></row><row><cell>year</cell><cell>2020</cell><cell>2021</cell><cell>2020</cell><cell>2021</cell><cell>2020</cell><cell>2021</cell></row><row><cell>terrier_BM25</cell><cell cols="4">0.2627 0.3641 0.3964 0.4707</cell><cell cols="2">0.5919 0.6364</cell></row><row><cell>terrier_BM25_qe</cell><cell cols="4">0.2453 0.3903 0.3784 0.4994</cell><cell cols="2">0.5698 0.6352</cell></row><row><cell cols="5">terrier_DirichletLM 0.2706 0.3694 0.416 0.4724</cell><cell cols="2">0.6054 0.5952</cell></row><row><cell>terrier_DirichletLM_qe</cell><cell cols="4">0.1453 0.2423 0.2719 0.3691</cell><cell cols="2">0.5521 0.5362</cell></row><row><cell>terrier_TF×IDF</cell><cell cols="6">0.2613 0.3663 0.3958 0.4744 0.6292 0.6464</cell></row><row><cell>terrier_TF×IDF_qe</cell><cell cols="4">0.25 0.3974 0.3802 0.5106</cell><cell cols="2">0.608 0.6535</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,88.99,540.05,416.12,20.87"><head>Table 5</head><label>5</label><figDesc>MAP, BPref, and NDCG@10 2020 and 2021 Adhoc CHS task on baseline systems. Best system in bold</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="13,88.99,86.42,395.65,194.51"><head>Table 6</head><label>6</label><figDesc></figDesc><table coords="13,108.14,86.42,376.50,176.64"><row><cell>Rank Team -run</cell><cell>rRBP Team -run</cell><cell>cRBP</cell></row><row><cell>1 Baseline terrier_TF×IDF_qe</cell><cell>0.523 Baseline terrier_DirichletLM</cell><cell>0.458</cell></row><row><cell>2 Baseline terrier_TF×IDF</cell><cell>0.509 UniPd original_rm3_rrf</cell><cell>0.452</cell></row><row><cell>3 Baseline terrier_BM25_qe</cell><cell>0.507 Baseline terrier_TF×IDF_qe</cell><cell>0.450</cell></row><row><cell>4 Baseline terrier_BM25</cell><cell>0.501 Baseline terrier_BM25_qe</cell><cell>0.432</cell></row><row><cell>5 ZUT run3_clef2021_task2</cell><cell cols="2">0.494 Baseline terrier_DirichletLM_qe 0.429</cell></row><row><cell>6 UniPd original_rrf</cell><cell>0.491 UniPd original_rrf</cell><cell>0.427</cell></row><row><cell>7 UniPd original_rm3_rrf</cell><cell>0.475 Baseline terrier_TF×IDF</cell><cell>0.418</cell></row><row><cell>8 Baseline terrier_DirichletLM</cell><cell>0.463 ZUT run3_clef2021_task2</cell><cell>0.414</cell></row><row><cell>9 ZUT run4_clef2021_task2</cell><cell>0.450 ZUT run4_clef2021_task2</cell><cell>0.409</cell></row><row><cell cols="2">10 Baseline terrier_DirichletLM_qe 0.408 Baseline terrier_BM25</cell><cell>0.406</cell></row><row><cell>11 ZUT run1_clef2021_task2</cell><cell>0.408 UniPd simplified_rm3_rrf</cell><cell>0.331</cell></row><row><cell>12 UniPd simplified_rm3_rrf</cell><cell>0.369 ZUT run2_clef2021_task2</cell><cell>0.330</cell></row><row><cell>13 UniPd simplified_rrf</cell><cell>0.359 ZUT run1_clef2021_task2</cell><cell>0.319</cell></row><row><cell>14 ZUT run2_clef2021_task2</cell><cell>0.349 UniPd simplified_rrf</cell><cell>0.317</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="14,88.98,86.42,417.25,292.89"><head>Table 7</head><label>7</label><figDesc>AUC and Accuracy values for baselines and runs when credibility assessment is treated as a binary classification problem.</figDesc><table coords="14,183.18,86.42,226.43,248.77"><row><cell>Model</cell><cell>AUC</cell><cell>Accuracy</cell></row><row><cell>Baseline SVM_orig_tf_idf</cell><cell>56.89%</cell><cell>63.38%</cell></row><row><cell>Baseline RF_orig_tf_idf</cell><cell>47.37%</cell><cell>70.94%</cell></row><row><cell>Baseline LR_orig_tf_idf</cell><cell>65.12%</cell><cell>64.98%</cell></row><row><cell>Baseline SVM_orig_w2v_google</cell><cell>59.81%</cell><cell>64.26%</cell></row><row><cell>Baseline RF_orig_w2v_google</cell><cell>51.82%</cell><cell>71.11%</cell></row><row><cell>Baseline LR_orig_w2v_google</cell><cell>67.70%</cell><cell>65.47%</cell></row><row><cell>Baseline SVM_orig_w2v_bio</cell><cell>65.30%</cell><cell>64.33%</cell></row><row><cell>Baseline RF_orig_w2v_bio</cell><cell>56.10%</cell><cell>76.06%</cell></row><row><cell>Baseline LR_orig_w2v_bio</cell><cell>69.50%</cell><cell>65.80%</cell></row><row><cell>Baseline SVM_simp_tf_idf</cell><cell>57.31%</cell><cell>63.56%</cell></row><row><cell>Baseline RF_simp_tf_idf</cell><cell>54.40%</cell><cell>74.34%</cell></row><row><cell>Baseline LR_simp_tf_idf</cell><cell>61.43%</cell><cell>63.19%</cell></row><row><cell cols="2">Baseline SVM_simp_w2v_google 60.24%</cell><cell>65.54%</cell></row><row><cell>Baseline RF_simp_w2v_google</cell><cell>54.43%</cell><cell>75.64%</cell></row><row><cell>Baseline LR_simp_w2v_google</cell><cell>62.35%</cell><cell>64.87%</cell></row><row><cell>Baseline SVM_simp_w2v_bio</cell><cell>63.97%</cell><cell>64.66%</cell></row><row><cell>Baseline RF_simp_w2v_bio</cell><cell>56.26%</cell><cell>78.14%</cell></row><row><cell>Baseline LR_simp_w2v_bio</cell><cell>67.87%</cell><cell>67.45%</cell></row><row><cell>Run subtask1_ims_original</cell><cell>62.33%</cell><cell>48.37%</cell></row><row><cell>Run subtask1_ims_simplified</cell><cell>51.45%</cell><cell>45.11%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="15,88.93,179.38,417.05,101.61"><head>Table 8</head><label>8</label><figDesc>Average CP(𝑞) values when credibility assessment is performed by considering documents retrieved with respect to specific topics.</figDesc><table coords="15,147.35,179.38,298.08,57.48"><row><cell>Model</cell><cell cols="2">No of top-𝑘 documents Average CP(𝑞)</cell></row><row><cell>Run subtask2_ims_original</cell><cell>𝑘 = 100</cell><cell>0.6767</cell></row><row><cell>Run subtask2_ims_simplified</cell><cell>𝑘 = 100</cell><cell>0.5221</cell></row><row><cell>Run subtask2_ims_original</cell><cell>𝑘 = 200</cell><cell>0.5205</cell></row><row><cell>Run subtask2_ims_simplified</cell><cell>𝑘 = 200</cell><cell>0.3433</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,108.93,660.07,223.30,8.97"><p>https://github.com/mmihaltz/word2vec-GoogleNews-vectors</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,108.93,671.03,145.60,8.97"><p>https://github.com/ncbi-nlp/BioSentVec</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>


			<div type="funding">
<div><p>. Suominen); https://www.unimib.it/gabriella-pasi (G. Pasi); https://researchers.anu.edu.au/researchers/brew-sam-n (N. Brew-Sam); https://www.maynoothuniversity.ie/people/liadh-kelly (L. Kelly); https://ikr3.disco.unimib.it/people/marco-viviani/ (<rs type="person">M. Viviani</rs>) 0000-The CHS task of the CLEF eHealth 2021 evaluation lab has been supported in part by the <rs type="funder">CLEF Initiative</rs>. It has also been supported in part by the <rs type="funder">Our Health in Our Hands (OHIOH)</rs> initiative of the <rs type="funder">Australian National University (ANU)</rs>, as well as the <rs type="institution">ANU School of Computing</rs>, <rs type="institution">ANU Research School of Population Health</rs>, and Data61/<rs type="funder">Commonwealth Scientific and Industrial Research Organisation</rs>. OHIOH is a strategic initiative of the ANU which aims to transform health care by developing new personalised health technologies and solutions in collaboration with patients, clinicians, and health care providers. Moreover, the task has been supported in part by the bi-lateral <rs type="projectName">Kodicare</rs> (<rs type="projectName">Knowledge Delta based improvement and continuous evaluation of retrieval engines) project</rs> funded by the <rs type="funder">French ANR</rs> (<rs type="grantNumber">ANR-19-CE23-0029</rs>) and <rs type="funder">Austrian FWF</rs>. Finally, the task has been supported in part by the <rs type="programName">EU Horizon 2020 Research and Innovation Programme</rs> under the <rs type="grantName">Marie Skłodowska-Curie Grant</rs> Agreement No <rs type="grantNumber">860721 -DoSSIER</rs>: "<rs type="projectName">Domain Specific Systems for Information Extraction and Retrieval</rs>". We are also thankful to the people involved in the query creation and relevance assessment exercises. Last but not least, we gratefully acknowledge the participating teams' hard work. We thank them for their submissions and interest in the task.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_K8Jga4G">
					<orgName type="project" subtype="full">Kodicare</orgName>
				</org>
				<org type="funded-project" xml:id="_G2bD9fy">
					<idno type="grant-number">ANR-19-CE23-0029</idno>
					<orgName type="project" subtype="full">Knowledge Delta based improvement and continuous evaluation of retrieval engines) project</orgName>
				</org>
				<org type="funded-project" xml:id="_hNZwWyp">
					<idno type="grant-number">860721 -DoSSIER</idno>
					<orgName type="grant-name">Marie Skłodowska-Curie Grant</orgName>
					<orgName type="project" subtype="full">Domain Specific Systems for Information Extraction and Retrieval</orgName>
					<orgName type="program" subtype="full">EU Horizon 2020 Research and Innovation Programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="16,112.66,386.69,393.33,10.91;16,112.66,400.24,393.33,10.91;16,112.66,413.79,322.24,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="16,375.85,386.69,130.13,10.91;16,112.66,400.24,393.33,10.91;16,112.66,413.79,52.55,10.91">From information seeking to information avoidance: Understanding the health information behavior during a global health crisis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">H</forename><surname>Soroya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Isoaho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,172.79,413.79,184.16,10.91">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">102440</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,427.34,395.17,10.91;16,112.66,440.89,393.33,10.91;16,112.66,454.44,393.33,10.91;16,112.66,467.99,80.64,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="16,186.25,440.89,164.22,10.91;16,378.50,440.89,127.48,10.91;16,112.66,454.44,263.12,10.91">Task 3: Information retrieval to address patients&apos; questions when reading clinical reports</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salantera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,383.98,454.44,122.01,10.91;16,112.66,467.99,25.70,10.91">CLEF 2013 Online Working Notes</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page">8138</biblScope>
		</imprint>
	</monogr>
	<note>ShARe/CLEF eHealth Evaluation Lab</note>
</biblStruct>

<biblStruct coords="16,112.66,481.54,393.32,10.91;16,112.66,495.09,393.58,10.91;16,112.66,508.64,231.03,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="16,269.66,481.54,236.33,10.91;16,112.66,495.09,393.58,10.91;16,112.66,508.64,40.05,10.91">Scholarly influence of the Conference and Labs of the Evaluation Forum eHealth Initiative: Review and bibliometric study of the 2012 to 2017 outcomes</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,161.64,508.64,109.36,10.91">JMIR Research Protocols</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10961</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,522.18,393.32,10.91;16,112.66,535.73,393.98,10.91;16,112.66,549.28,32.64,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="16,262.18,522.18,243.80,10.91;16,112.66,535.73,260.60,10.91">Consumer health search on the web: Study of web page understandability and its integration in ranking algorithms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,381.79,535.73,82.50,10.91">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">10986</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,562.83,393.58,10.91;16,112.66,576.38,395.16,10.91;16,112.66,589.93,393.33,10.91;16,112.66,603.48,164.71,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="16,277.71,562.83,228.53,10.91;16,112.66,576.38,135.38,10.91">The scholarly impact and strategic intent of CLEF eHealth Labs from 2012 to 2017</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,382.53,576.38,125.30,10.91;16,112.66,589.93,288.77,10.91">Information Retrieval Evaluation in a Changing World: Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="333" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,617.03,393.33,10.91;16,112.66,630.58,393.33,10.91;16,112.66,644.13,395.01,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="16,369.19,617.03,136.80,10.91;16,112.66,630.58,294.33,10.91">Overview of the CLEF eHealth 2020 task 2: consumer health search with ad hoc and spoken queries</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,429.00,630.58,76.99,10.91;16,112.66,644.13,365.46,10.91">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,112.66,657.68,393.33,10.91;17,112.66,86.97,393.33,10.91;17,112.66,100.52,152.13,10.91" xml:id="b6">
	<monogr>
		<title level="m" coord="16,198.10,657.68,307.89,10.91;17,112.66,86.97,393.33,10.91;17,112.66,100.52,85.57,10.91">The Proceedings of the CLEFeHealth2012 -the CLEF 2012 Workshop on Cross-Language Evaluation of Methods, Applications, and Resources for eHealth Document Analysis</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Suominen</surname></persName>
		</editor>
		<imprint>
			<publisher>NICTA</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,114.06,394.53,10.91;17,112.66,127.61,394.53,10.91;17,112.66,141.16,393.32,10.91;17,112.28,154.71,393.71,10.91;17,112.66,168.26,134.65,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="17,165.23,141.16,242.26,10.91">Overview of the ShARe/CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salanterä</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">R</forename><surname>South</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,451.83,141.16,54.15,10.91;17,112.28,154.71,314.28,10.91">Information Access Evaluation. Multilinguality, Multimodality, and Visualization</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="212" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,181.81,394.53,10.91;17,112.14,195.36,393.85,10.91;17,112.66,208.91,394.53,10.91;17,112.66,222.46,288.11,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="17,332.32,195.36,173.66,10.91;17,112.66,208.91,67.56,10.91">Overview of the ShARe/CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,224.58,208.91,282.60,10.91;17,112.66,222.46,75.57,10.91">Information Access Evaluation. Multilinguality, Multimodality, and Visualization</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="172" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,236.01,394.53,10.91;17,112.66,249.56,395.01,10.91;17,112.66,263.11,370.13,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,112.66,249.56,208.99,10.91">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hanlen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,366.15,249.56,141.52,10.91;17,112.66,263.11,215.48,10.91">Information Access Evaluation. Multilinguality, Multimodality, and Visualization</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,276.66,393.33,10.91;17,112.66,290.20,393.33,10.91;17,112.66,303.75,394.87,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="17,431.11,276.66,74.88,10.91;17,112.66,290.20,132.33,10.91">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,289.28,290.20,216.71,10.91;17,112.66,303.75,185.42,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="255" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,317.30,394.52,10.91;17,112.66,330.85,393.33,10.91;17,112.66,344.40,394.53,10.91;17,112.66,357.95,80.57,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<title level="m" coord="17,161.71,330.85,187.62,10.91;17,370.63,330.85,135.36,10.91;17,112.66,344.40,264.25,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="291" to="303" />
		</imprint>
	</monogr>
	<note>CLEF 2017 eHealth Evaluation Lab overview</note>
</biblStruct>

<biblStruct coords="17,112.66,371.50,394.53,10.91;17,112.66,385.05,393.33,10.91;17,112.66,398.60,393.53,10.91;17,112.66,412.15,303.65,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="17,323.32,385.05,182.67,10.91;17,112.66,398.60,16.45,10.91">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,180.29,398.60,325.90,10.91;17,112.66,412.15,90.47,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,425.70,394.53,10.91;17,112.66,439.25,394.62,10.91;17,112.66,452.79,394.53,10.91;17,112.66,466.34,393.33,10.91;17,112.66,479.89,320.67,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="17,254.38,439.25,210.75,10.91">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Scells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,245.56,466.34,260.42,10.91;17,112.66,479.89,47.12,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Heinatz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bürki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="322" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,493.44,394.53,10.91;17,112.66,506.99,394.53,10.91;17,112.66,520.54,394.53,10.91;17,112.28,534.09,395.55,10.91;17,112.66,547.64,383.90,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="17,278.13,506.99,203.45,10.91">Overview of the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Miranda-Escalada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,299.23,534.09,208.60,10.91;17,112.66,547.64,110.35,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="255" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,561.19,395.01,10.91;17,112.66,574.74,394.52,10.91;17,112.66,588.29,393.33,10.91;17,112.66,601.84,290.84,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="17,112.66,588.29,147.65,10.91">CLEF eHealth 2021 Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Alemany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Brew-Sam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Filippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seneviratne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,282.29,588.29,223.70,10.91;17,112.66,601.84,117.86,10.91">Advances in Information Retrieval -43st European Conference on IR Research</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,112.66,615.39,394.53,10.91;17,112.66,628.93,394.53,10.91;17,112.66,642.48,393.33,10.91;17,112.66,656.03,393.33,10.91;17,112.66,669.58,286.60,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="17,303.46,642.48,202.52,10.91">Overview of the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Alonso Alemany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bassani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Brew-Sam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Filippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seneviratne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,152.89,656.03,273.50,10.91">CLEF 2021 -11th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="17,434.17,656.03,71.82,10.91;17,112.66,669.58,108.44,10.91">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,86.97,393.33,10.91;18,112.48,100.52,395.34,10.91;18,112.66,114.06,394.53,10.91;18,112.66,127.61,85.46,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="18,159.49,100.52,167.18,10.91;18,355.12,100.52,152.70,10.91;18,112.66,114.06,70.84,10.91">Task 3: User-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,206.27,114.06,296.17,10.91">CLEF 2014 Evaluation Labs and Workshop: Online Working Notes</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>ShARe/CLEF eHealth Evaluation Lab</note>
</biblStruct>

<biblStruct coords="18,112.66,141.16,393.59,10.91;18,112.66,154.71,394.61,10.91;18,112.66,168.26,228.74,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="18,482.55,141.16,23.69,10.91;18,112.66,154.71,102.32,10.91;18,242.55,154.71,244.31,10.91">Task 2: Retrieving Information about Medical Symptoms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanburyn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.66,168.26,147.96,10.91">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>CLEF eHealth Evaluation Lab</note>
</biblStruct>

<biblStruct coords="18,112.66,181.81,394.53,10.91;18,112.28,195.36,393.71,10.91;18,112.66,208.91,393.33,10.91;18,112.66,222.46,104.20,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="18,165.79,195.36,340.19,10.91;18,112.66,208.91,96.26,10.91">The IR Task at the CLEF eHealth Evaluation Lab 2016: User-centred Health Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Budaher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deacon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,233.10,208.91,272.89,10.91;18,112.66,222.46,23.42,10.91">CLEF 2016 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,236.01,393.58,10.91;18,112.66,249.56,393.33,10.91;18,112.66,263.11,395.01,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="18,481.95,236.01,24.30,10.91;18,112.66,249.56,288.40,10.91">CLEF 2017 Task Overview: The IR Task at the eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,425.26,249.56,80.73,10.91;18,112.66,263.11,365.46,10.91">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,276.66,394.61,10.91;18,112.14,290.20,393.85,10.91;18,112.66,303.75,81.94,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="18,243.72,276.66,244.48,10.91">Overview of the CLEF 2018 consumer health search task</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jimmy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.14,290.20,393.85,10.91;18,112.66,303.75,51.81,10.91">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,317.30,393.33,10.91;18,112.66,330.85,393.32,10.91;18,112.66,344.40,230.97,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="18,440.82,317.30,65.17,10.91;18,112.66,330.85,393.32,10.91">An Analysis of Evaluation Campaigns in ad-hoc Medical Information Retrieval: CLEF eHealth 2013 and</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,139.28,344.40,172.43,10.91">Springer Information Retrieval Journal</title>
		<imprint>
			<date type="published" when="2014">2014. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,357.95,394.53,10.91;18,112.66,371.50,393.33,10.91;18,112.66,385.05,393.98,10.91;18,112.66,398.60,194.44,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="18,112.66,371.50,393.33,10.91;18,112.66,385.05,66.95,10.91">Overview of the CLEF eHealth 2020 task 2: Consumer health search with ad hoc and spoken queries</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,207.17,385.05,299.47,10.91;18,112.66,398.60,164.32,10.91">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,412.15,395.17,10.91;18,112.66,425.70,296.06,10.91" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="18,158.09,412.15,349.75,10.91;18,112.66,425.70,36.17,10.91">Probabilistic Models for Information Retrieval Based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Glasgow, the UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Glasgow University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="18,112.66,439.25,393.33,10.91;18,112.66,452.79,331.82,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="18,332.88,439.25,173.11,10.91;18,112.66,452.79,179.63,10.91">Research directions in terrier: a search engine for advanced retrieval on the web</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,301.34,452.79,103.42,10.91">CEPIS Upgrade Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,466.34,393.32,10.91;18,112.66,479.89,393.98,10.91;18,112.66,493.44,27.57,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="18,200.02,466.34,305.96,10.91;18,112.66,479.89,26.96,10.91">Credibility in social media: opinions, news, and health information-a survey</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,148.07,479.89,321.55,10.91">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1209</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,506.99,395.16,10.91;18,112.66,520.54,394.52,10.91;18,112.28,534.09,395.00,10.91;18,112.66,547.64,395.01,10.91;18,112.41,561.19,38.81,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="18,112.28,534.09,375.20,10.91">API design for machine learning software: experiences from the scikit-learn project</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Buitinck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Grobler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.66,547.64,346.61,10.91">ECML PKDD Workshop: Languages for Data Mining and Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="108" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,574.74,310.62,10.91" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="18,175.27,574.74,140.03,10.91">Index for rating diagnostic tests</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Youden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,323.01,574.74,31.55,10.91">Cancer</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="32" to="35" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,588.29,393.33,10.91;18,112.33,601.84,250.70,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="18,197.05,588.29,278.55,10.91">Rank-biased precision for measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,483.05,588.29,22.94,10.91;18,112.33,601.84,166.69,10.91">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,615.39,394.61,10.91;18,112.66,628.93,390.80,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="18,207.04,615.39,280.72,10.91">On the distribution of user persistence for rank-biased precision</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,112.66,628.93,312.27,10.91">Proceedings of the 12th Australasian document computing symposium</title>
		<meeting>the 12th Australasian document computing symposium</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,112.66,642.48,393.33,10.91;18,112.66,656.03,394.53,10.91;18,112.66,669.58,123.33,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="18,381.32,642.48,124.67,10.91;18,112.66,656.03,146.27,10.91">Fixed-cost pooling strategies based on ir evaluation measures</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lipani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,287.78,656.03,215.10,10.91">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="357" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,86.97,393.33,10.91;19,112.66,100.52,393.33,10.91;19,112.66,114.06,361.52,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="19,228.98,86.97,277.00,10.91;19,112.66,100.52,93.41,10.91">Relevation!: an open source system for information retrieval relevance assessment</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,229.52,100.52,276.47,10.91;19,112.66,114.06,235.31,10.91">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1243" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,127.61,394.53,10.91;19,112.66,141.16,394.52,10.91;19,112.34,154.71,394.84,10.91;19,112.66,168.26,212.45,10.91" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="19,225.14,141.16,219.44,10.91">Performance evaluation measures for text mining</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hiissa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Marghescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pahikkala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Karsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,172.79,154.71,277.82,10.91">Handbook of Research on Text and Web Mining Technologies</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</editor>
		<meeting><address><addrLine>Hershey, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="724" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,181.81,393.32,10.91;19,112.66,195.36,181.77,10.91" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="19,163.96,181.81,265.93,10.91">Understandability biased evaluation for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,452.18,181.81,53.80,10.91;19,112.66,195.36,94.24,10.91">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="280" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,208.91,394.62,10.91;19,112.66,222.46,393.53,10.91;19,112.66,236.01,22.69,10.91" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="19,277.71,208.91,207.99,10.91">Learning to rank for Consumer Health Search</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,112.66,222.46,289.42,10.91">CLEF 2021 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2021-09">September 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,112.66,249.56,393.32,10.91;19,112.66,263.11,394.52,10.91;19,112.66,276.66,72.61,10.91" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="19,224.88,249.56,281.11,10.91;19,112.66,263.11,28.18,10.91">IMS-UNIPD @ CLEF eHealth Task 2: Reciprocal Ranking Fusion in CHS</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Di Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Vezzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,164.78,263.11,287.95,10.91">CLEF 2021 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2021-09">September 2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
