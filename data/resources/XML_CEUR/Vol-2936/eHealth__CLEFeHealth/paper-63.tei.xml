<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,283.19,15.42;1,88.69,106.66,314.20,15.42">IMS-UNIPD @ CLEF eHealth Task 1: A Memory Based Reproducible Baseline</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,134.97,83.39,11.96"><forename type="first">Giorgio</forename><forename type="middle">Maria</forename><surname>Di</surname></persName>
							<email>dinunzio@unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,283.19,15.42;1,88.69,106.66,314.20,15.42">IMS-UNIPD @ CLEF eHealth Task 1: A Memory Based Reproducible Baseline</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">47B2EF1B3306E112A81C828EC37D43A2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>classification</term>
					<term>memory based classifier</term>
					<term>R tidyverse</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report the results of our participation to the CLEF eHealth 2021 Task on "Multilingual Information Extraction". This year, this task focuses on Named Entity Recognition from Spanish clinical text in the domain of radiology reports. In particular, the main objective is to classify entities into seven different classes as well as hedge cues.</p><p>Our main contribution can be summarized as follows: 1) continue the study of minimal/reproducible pipeline for text analysis baselines using a tidyverse approach in the R language; 2) evaluate the simplest memory based classifiers without optimization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper, we report the results of our participation to the CLEF eHealth <ref type="bibr" coords="1,428.77,380.87,12.85,10.91" target="#b0">[1]</ref> Task 1 "Multilingual Information Extraction" <ref type="bibr" coords="1,228.96,394.42,11.28,10.91" target="#b1">[2]</ref>. The 2021 task focuses on the Named Entity classification of clinical textual data which consists in 513 ultrasonography reports. The unstructured text and the number of orthographic and grammatical errors make this tasks challenging for automatic approaches.</p><p>The contribution of our experiments to this task can be summarized as follows:</p><p>• The implementation of a reproducible pipeline for text analysis;</p><p>• An evaluation of a simple memory based classifier.</p><p>The remainder of the paper will introduce the methodology and a brief summary of the experimental settings that we used in order to create the run that we submitted for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>In this section, we summarize the pipeline for text pre-processing which has been developed in the last three years <ref type="bibr" coords="1,174.48,584.75,11.23,10.91" target="#b2">[3,</ref><ref type="bibr" coords="1,188.25,584.75,7.42,10.91" target="#b3">4,</ref><ref type="bibr" coords="1,198.21,584.75,8.88,10.91" target="#b4">5]</ref> and has been simplified and the source code will be made available. 1  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pipeline for Data Cleaning</head><p>In order to produce a dataset ready for training a classifier, we followed the same pipeline for data ingestion and preparation for all the experiments. We used the tidytext approach to automatically parse and extract the text. <ref type="foot" coords="2,268.33,132.88,3.71,7.97" target="#foot_0">2</ref>The following code summarizes the initial steps of the analysis of the documents: t r a i n _ a n n &lt;-t r a i n _ a n n %&gt;% s e p a r a t e _ r o w s ( t e x t , s e p = " \ n " ) %&gt;% s e p a r a t e ( c o l = t e x t , s e p = " \ t " , i n t o = c ( " i d " , " t y p e " , " t e x t " ) ) t r a i n _ a n n &lt;-t r a i n _ a n n %&gt;% m u t a t e ( i n t e r v a l = s t r _ s u b ( t y p e , s t a r t = s t r _ l o c a t e ( s t r i n g = t y p e , p a t t e r n = " [ 0 -9 ] + [ 0 -9 ] + ( ; [ 0 -9 ] + [ 0 -9 ] + ) * " ) ) ) %&gt;% m u t a t e ( t y p e = s t r _ s u b ( s t r i n g = t y p e , end = s t r _ l o c a t e ( s t r i n g = t y p e , p a t t e r n = " [ 0</p><formula xml:id="formula_0" coords="2,194.57,303.20,265.81,10.91">-9 ] + [ 0 -9 ] + ( ; [ 0 -9 ] + [ 0 -9 ] + ) * " ) [ , 1 ] -1 ) )</formula><p>With just two lines of code we separate each token of each document and extract the location in the text. As an additional example, with the following line, we tried to reduce the possibility to match smaller sequences by adding spaces around the text (even though we may lose some matches with this extra characters) t a $ t e x t _ l o w e r [ n c h a r ( t a $ t e x t _ l o w e r ) &lt; 3 ] &lt;-p a s t e 0 ( " " , s h o r t _ t e x t , " " )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Classification</head><p>The main idea of a memory based classifier follows the idea presented in <ref type="bibr" coords="2,415.28,438.61,11.56,10.91" target="#b2">[3]</ref>:</p><p>• Choose the morphological level (in our experiments token level); • Given a (multi-word) token in a sentence, search for any previously classified documents that contains that sentence; • Add the classification label to the document.</p><p>We built the rules for the memory based system by looking at all the documents provided in the training and validation set. No optimization was performed at any steps and only one run was submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminary Results</head><p>In this section, we briefly comment the official results sent by the organizers before the workshop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Considerations before the official results</head><p>Our initial goal with this approach was to build a memory based approach that could capture with high precision (only known sequences) and low recall (all the sequences that are not previously seen are not recognized) some entities that were labeled by the experts in the training and validation set.</p><p>Without any optimization or evaluation on the validation set, our initial guess was a recall around 50% (we suppose that at least half of the entities of the test set are not in the training/validation set), and a precision around 70-80% (when a sequence previously labeled is found, we suppose that there is a low chance that it is categorized wrongly).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Considerations after the official results</head><p>Compared to the same approach used in the past years, the results on this task were surprisingly low: on one hand, recall was around the figure we expected for most of the categories; on the other hand, precision was extremely low.</p><p>These results, despite being negative, open interesting questions about what went wrong in the implementation of rules of the classifier. In particular, we have started to analyze the runs for the first time since the runs were submitted, and we found some odd classifications of one or two characters entities. For example, for document 4901 we have Therefore, we believe that in some parts of the source code (see for example the line in Section 2.1 where we try to find a solution for smaller sequences) we introduced errors that could and should be avoided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Source code debugging</head><p>After a careful analysis of the code, we found that we unintentionally removed the trailing white spaces introduced for shorter character sequences. In particular, when we extract the pattern to find in the text, we also "squish" any multiple white spaces including the trailing white spaces. In doing so, single characters like "m", "o", "s", are included as patterns; thus, the number of patterns wrognly assigned to each document increases and the precision for that category decreases.</p><p>For this reason, we modify the code in order to avoid this passage when shorter sequences are involved and run again the classification of the validation sets.</p><p>We provide the source code to replicate these results; 3 in particular, with this simple modification we could recover most of the precision initially lost. For example, for the category "Abbreviation", the initial precision around 7% increases up to 40%, for "Anatomical Entity" from 25-30% up to 50%, for "Negation" from 10% up to 60%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Final remarks and Future Work</head><p>The aim of our participation to the CLEF 2021 eHealth Task 1 was to test the effectiveness of a simple textual pipeline implemented in R with the 'tidyverse' approach for the problem of classification of Spanish clinical textual data. A preliminary failure analysis showed an anomaly in the values of precision, too low compared to the expected effectiveness. After a careful analysis, we found a mistake in the source code and, after we fixed the error, the performances increased significantly. In order to make this study reproducible, we will make the source code available. Additional analyses will be carried out to find patterns that can be easily used as a kind of knowledge base to support more advanced systems. We will provide a finer analysis on the test set when the ground truth will be made available.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,108.93,670.96,168.15,8.97"><p>https://bnosac.github.io/udpipe/en/index.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,107.59,421.01,400.25,10.91;4,107.59,434.55,399.59,10.91;4,107.41,448.10,398.84,10.91;4,107.59,461.65,398.60,10.91;4,107.59,475.20,138.77,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,236.18,448.10,201.94,10.91">Overview of the CLEF eHealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Alemany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bassani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Brew-Sam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Filippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>González-Sáez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seneviratne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,482.07,448.10,24.17,10.91;4,107.59,461.65,264.05,10.91">CLEF 2021 -12th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="4,380.62,461.65,125.57,10.91;4,107.59,475.20,60.71,10.91">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.59,488.75,399.59,10.91;4,107.20,502.30,398.78,10.91;4,107.59,515.85,398.40,10.91;4,107.06,529.40,317.19,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,234.99,502.30,270.99,10.91;4,107.59,515.85,235.21,10.91">Overview of CLEF eHealth task 1 -spradie: A challenge on information extraction from spanish radiology reports</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Cotik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Alemany</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ayach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Carranza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Francesca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dellanzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Urquiza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,368.48,515.85,137.51,10.91;4,107.06,529.40,287.06,10.91">CLEF 2021 Evaluation Labs and Workshop: Online Working Notes, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,107.59,542.95,398.40,10.91;4,107.59,556.50,399.60,10.91;4,107.20,570.05,398.78,10.91;4,107.59,583.60,398.40,10.91;4,107.59,597.15,367.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,174.10,542.95,331.88,10.91;4,107.59,556.50,42.90,10.91">As simple as possible: Using the R tidyverse for multilingual information extraction</title>
		<author>
			<persName coords=""><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_137.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="4,157.50,556.50,171.47,10.91;4,186.14,570.05,319.84,10.91;4,107.59,583.60,26.91,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="4,432.30,584.61,73.68,9.72;4,107.59,597.15,77.32,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
	<note>IMS unipd ad CLEF ehealth 2020 task 1</note>
</biblStruct>

<biblStruct coords="4,107.59,610.69,398.40,10.91;4,107.59,624.24,398.40,10.91;4,107.59,637.79,399.60,10.91;4,105.65,669.45,2.78,5.98;4,108.93,671.01,91.39,8.97;5,107.59,86.97,400.08,10.91;5,107.59,100.52,218.46,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,174.43,610.69,265.27,10.91">Classification of animal experiments: A reproducible study</title>
		<author>
			<persName coords=""><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/paper_104.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="4,447.09,610.69,58.90,10.91;4,107.59,624.24,89.12,10.91;4,466.22,624.24,39.77,10.91;4,107.59,637.79,298.05,10.91">Working Notes of CLEF 2019 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="5,282.11,86.97,154.89,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">3. , 2019. 2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
	<note>IMS unipd at CLEF ehealth task 1</note>
</biblStruct>

<biblStruct coords="5,107.59,114.06,400.08,10.91;5,107.59,127.61,398.40,10.91;5,107.59,141.16,399.68,10.91;5,107.24,154.71,172.79,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,179.09,114.06,323.90,10.91">Classification of ICD10 codes with no resources but reproducible code</title>
		<author>
			<persName coords=""><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2125/paper_180.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="5,107.59,127.61,154.37,10.91;5,288.85,127.61,217.14,10.91;5,107.59,141.16,131.00,10.91">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14, 2018., 2018</date>
		</imprint>
	</monogr>
	<note>IMS unipd at CLEF ehealth task 1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
