<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,375.35,15.42;1,89.29,106.66,347.61,15.42;1,89.29,128.58,343.28,15.43">Accenture at CheckThat! 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.89,71.26,11.96"><forename type="first">Evan</forename><surname>Williams</surname></persName>
							<email>e.m.williams@accenture.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>800 N. Glebe Rd</addrLine>
									<postCode>22209</postCode>
									<settlement>Arlington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,173.20,156.89,73.62,11.96"><forename type="first">Paul</forename><surname>Rodrigues</surname></persName>
							<email>paul.rodrigues@accenture.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>800 N. Glebe Rd</addrLine>
									<postCode>22209</postCode>
									<settlement>Arlington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<addrLine>7005 52nd Avenue</addrLine>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.10,156.89,47.01,11.96"><forename type="first">Sieu</forename><surname>Tran</surname></persName>
							<email>sieu.tran@accenture.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Accenture</orgName>
								<address>
									<addrLine>800 N. Glebe Rd</addrLine>
									<postCode>22209</postCode>
									<settlement>Arlington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,375.35,15.42;1,89.29,106.66,347.61,15.42;1,89.29,128.58,343.28,15.43">Accenture at CheckThat! 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">222CB706376BAE32B571614447D121AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fact checking</term>
					<term>claim retrieval</term>
					<term>check-worthy</term>
					<term>social media</term>
					<term>BERT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper discusses the approach used by the Accenture Team for CLEF2021 CheckThat! Lab, Task 1, to identify whether a claim made in social media would be interesting to a wide audience and should be fact-checked. Twitter training and test data were provided in English, Arabic, Spanish, Turkish, and Bulgarian. Claims were to be classified (check-worthy/not check-worthy) and ranked in priority order for the fact-checker. Our method used deep neural network transformer models with contextually sensitive lexical augmentation applied on the supplied training datasets to create additional training samples. This augmentation approach improved the performance for all languages. Overall, our architecture and data augmentation pipeline produced the best submitted system for Arabic, and performance scales according to the quantity of provided training data for English, Spanish, Turkish, and Bulgarian. This paper investigates the deep neural network architectures for each language as well as the provided data to examine why the approach worked so effectively for Arabic, and discusses additional data augmentation measures that should be useful to this problem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Labeled data for some machine learning tasks can be quite rare and valuable. Data labeling is a time consuming task, and can be expensive if subject matter or language expertise are required. Machine learning engineers know that generally, the larger the training set, the higher accuracy the classifier will have <ref type="bibr" coords="1,191.37,498.93,11.43,10.91" target="#b0">[1]</ref>, so they often request more data.</p><p>Further, engineers have been taught to prefer balanced data sets to train more robust classifiers. Most annotation processes yield unbalanced datasets naturally. Data scientists often have four options: upsampling, downsampling, cost-sensitive learning, or active learning to seek a balanced dataset through additional annotation. Downsampling reduces the data provided to the learner, which removes valuable labeled data from the dataset. Active learning incurs additional labeling cost. Upsampling is an attractive alternative. Upsampling in NLP application areas could involve exact text duplication or text augmentation.</p><p>The CLEF CheckThat! Labs provide shared training data for all the groups. This data provided in 2020 and 2021 was naturally unbalanced, predominantly consisting of documents that are not check-worthy.</p><p>Last year we published a paper at CLEF CheckThat! which used back translation to balance the classes in our Arabic training data. <ref type="bibr" coords="2,268.43,168.26,13.00,10.91" target="#b1">[2]</ref> The noise introduced by the machine translation system provided for an improvement in classifier performance. This method resulted in the best performing Arabic model in the Lab. For this year's Lab, we again endeavored to generate additional labeled data from the provided labeled data.</p><p>This year we used a different technique, contextually sensitive lexical augmentation, and we applied the approach to all the languages. Our technique uses BERT and RoBERTa models to replace text from the provided sample to construct alternative samples for the positive class tweets. We used this as additional training input to our transformer neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">CheckThat! Lab</head><p>CLEF CheckThat! is a series of annual challenges to identify the best algorithms for automated fact-checking. The 2021 Lab focused on social media and news articles. <ref type="bibr" coords="2,397.38,326.38,12.68,10.91" target="#b2">[3]</ref> Accenture focused on Task 1 of this Lab, which required identification if a claim on Twitter was worth fact-checking, and ranking the claim for how check-worthy the claim was. <ref type="bibr" coords="2,370.25,353.48,13.00,10.91" target="#b3">[4]</ref> This challenge focused on Arabic, Bulgarian, English, Spanish, and Turkish.</p><p>Accenture's paper in the 2020 Lab reached 1st place in the English track, and 1st, 2nd, 3rd, and 4th in the Arabic track. <ref type="bibr" coords="2,219.01,394.13,11.58,10.91" target="#b1">[2]</ref>. This year, only one submission per team per language was accepted for final reporting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Data Augmentation</head><p>Data augmentation is considered an important component in Deep Learning workflows <ref type="bibr" coords="2,492.22,457.40,11.58,10.91" target="#b4">[5]</ref>. These techniques are commonly applied in speech recognition (e.g. insertion of babble), and computer vision (e.g. image rotation) systems, but are not as commonly applied in natural language processing workflows due to differences in resources and techniques based on language and task. <ref type="bibr" coords="2,132.29,511.60,12.84,10.91" target="#b5">[6]</ref> Augmentation in an NLP context can take many forms. Words can be replaced with synonyms, antonyms, hypernyms, homonyms, or semantic neighbors. Words can be deleted, or inserted either randomly or where the lexical insertion best fits a language model. Words can be misspelled intentionally, either phonetically or at the character level, with a deletion, insertion, replacement or a swap of character sequence. There are numerous methods for NLP data augmentation, but none are commonplace.</p><p>[6] explored the use of text augmentation at the lexical level on five classification tasks, including a subjective/objective discrimination task. For each sentence in a training set, the researchers randomly selected between four operations-random lexical insertion, random lexical substitution, random lexical deletion, and synonym replacement. They showed that by applying these random augmentations, they were able to boost accuracy on all five classification tasks. Further, in an ablation study, the researchers showed that each of the four operations contributed to accuracy improvements. They noted that their augmentation strategy was particularly beneficial to smaller datasets. The authors performed their experiments on LSTM-RNN and CNN architectures. We are not aware of any papers describing NLP augmentation as input to transformer architectures for document classification tasks.</p><p>This study uses one of the methods mentioned in the previous paragraph, lexical substitution, but instead of applying these randomly, we use a contextual embedding model to choose the most probable operations. We demonstrate this technique with two samples below. Each invocation of the algorithm could produce a novel alternative sample.</p><p>Original check-worthy tweet:</p><p>The country is panic stricken over the #coronavirus, yet this flu season there have been 9.7 million flu illnesses, 87,000 hospitalizations and 4800 deaths from flu, including 32 pediatric deaths. It's time to stop the panic and put things into perspective.</p><p>Random Substitution 1:</p><p>The country is panic tweeting over the #coronavirus, yet this flu season there have been 9.7 million flu illnesses, 87,000 illnesses, 46 deaths from flu, including 32 pediatric deaths. It's time you stop the panic and put things into perspective.</p><p>Random Substitution 2:</p><p>The country remains panic stricken over the #coronavirus, yet this flu pand there are been 9.7 million flu illnesses, 800,000 hospitalizations and 4800 deaths from flu, including 32 pediatric deaths. It's time to stop the panic and put things into policy.</p><p>Original check-worthy tweet:</p><p>People aren't surprised when I tell them there are 13,000 Covid-19 cases outside China, or when I tell them this number doubles every 3 days. But when I tell them that if growth continues at this rate, we'll have 1.7 million cases in 3 weeks, they're astonished.</p><p>Random Substitution 1:</p><p>People aren't surprised when I tell them there are 100,000 Covid-19 cases outside Minnesota, or when we tell them this number grows every 3 days. So when I tell them that if growth continues at this speed, we'll have 1.7 million cases in 3 weeks, they're astonished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Substitution 2</head><p>People aren't surprised when I tell her there are 13,000 X-19 cases outside China, than when I tell them this number doubled every 3 days. But when I tell them that if growth continues at my forecast, we'll have 1.7 million cases in 3 weeks, they're astonished.</p><p>More information on this procedure, including the models used, can be found in Section 4.1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Exploratory Analysis</head><p>Table <ref type="table" coords="4,115.20,368.39,4.97,10.91" target="#tab_0">1</ref> shows the number of samples and unique word counts for each of the datasets provided. We see that Arabic had the largest number of samples in training (3,095) while English had the least (688). Similarly, Arabic had the highest count of unique words (29,619), and English had the lowest (4,499). Assuming consistent data collection methodology and annotation standards across languages, we would hypothesize that larger datasets would yield higher-accuracy models.</p><p>A qualitative analysis found that the topics included were consequential and that many tweets were worthy of fact-checking. Understanding the topics discussed in the data helps to evaluate the lexical coverage of our pre-trained models and helps to consider specialized pre-trained neural network models that could be relevant.</p><p>Arabic. The provided training set contains a large number of tweets referencing consequential political and human conflicts around the "Houthis movement". Notable portions of the training data also focus on diplomatic disagreements around the Algerian-Qatar relations. Political issues such as feminism are also discussed. Finally, a smaller set of tweets reference COVID-19-related political events. The testing set contain mainly the latter two topics while validation set largely contained the former two. Keywords that define these datasets include, but not limited to, "Houthis", "Yemen", "Qatar", "Algerian", "feminist", and "Veros Koruna".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bulgarian.</head><p>The training, testing, and validation sets all focus on COVID-19. However, the tweets covers a rather varied set of topics, including political events, pandemic progression, and scientific and informational statements about the virus. The most consistent keywords are amalgamations of the term "COVID-19", including "Koronavirus", "Korona", "Coronavius", and "Covid".</p><p>Spanish. The conversations in the training, testing and validation sets are about political issues including: government corruption, unemployment, economic instability, the importance of education, political elections, and other related topics. Spanish President, Pedro Sanchez, was named in a large number of tweets. Many tweets in the training set also mention climate issues, which are rare in the validation and testing sets. Keywords that define these sets are "President", "Sanchez", "government" and "economy".</p><p>Turkish. The training, testing, and validation set topics are varied but mostly related to Turkey domestic news, Turkish international affairs, and facts about Turkey as a country or the Turkish people. The training contains a higher number of tweets covering Turkey's national/external debt, claims of mistreatment of children, the Syrian population, unemployment, and the Turkish economy. Some keywords include "Turkey", "Turkish", "unemployment", "President", "Erdogan", "presidential election" and "Istanbul".</p><p>English. Tweets from all modeling sets are about COVID-19. The training set contains many statements and information about COVID-19, global news about COVID-19, and COVID-19-related political decisions and events. The testing and validation set are more politically oriented with most tweets mentioning a political event. The most frequent keywords include "corona", "coronavirus" and other amalgamations of the term "COVID-19".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Label Balance</head><p>All of the datasets provided by the CheckThat! organizers had label bias which skewed each dataset towards tweets that were not considered check-worthy. The Turkish dataset had the highest percentage of check-worthy tweets (38%), followed by English (35%), Arabic (22%), Bulgarian (13%), and Spanish (8%).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">WordPiece Analysis</head><p>Transformer models utilize WordPiece tokenization schemes that are dependant on the model being evaluated. At the time of pre-training, the WordPiece algorithm determines which pieces of words will be retained, and which will be discarded. An UNK token is utilized as a placeholder in the lexicon, and used to represent WordPiece tokens received in novel input that did not get utilized at model creation. We expect language samples which have a high amount of tokens processed as UNK would perform poorly. We present our analysis in Table <ref type="table" coords="6,252.72,445.94,3.81,10.91" target="#tab_1">2</ref>. Most notably, Arabic training set contains over 120K WordPieces, the largest number across all five languages, second by just over 110K for Spanish. In addition, Arabic training set produced a much lower rate of unknown tokens (0.291%) compared to Spanish (2.313%). Unexpectedly, the RoBERTa tokenizers we used did not return UNK tokens on any dataset provided by the CLEF CheckThat! organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Transformer Architectures and Pre-trained Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pre-trained Models</head><p>In this work, we utilize BERT and RoBERTa models. The Bidirectional Encoder Representation Transformer (BERT) is a transformer-based architecture that was introduced in 2018 <ref type="bibr" coords="6,481.32,593.28,11.48,10.91" target="#b6">[7,</ref><ref type="bibr" coords="6,496.18,593.28,7.65,10.91" target="#b7">8]</ref>. BERT has had a substantial impact on the field of NLP, and achieved state of the art results on 11 NLP benchmarks at the time of its release. RoBERTa, introduced by <ref type="bibr" coords="6,389.06,620.38,11.34,10.91" target="#b8">[9]</ref>, modified various parts of BERTs training process. These modifications include more training data, more pre-training steps with bigger batches over more data, removing BERT's Next Sentence Prediction, training on longer sequences, and dynamically changing the masking pattern applied to the training data <ref type="bibr" coords="7,110.96,86.97,11.43,10.91" target="#b1">[2]</ref>.</p><p>For the Arabic Dataset, we used asafaya/arabic-bert-large <ref type="bibr" coords="7,367.74,100.52,16.41,10.91" target="#b9">[10]</ref>, which was trained on an Arabic version of OSCAR, an Arabic Wikipedia dump, and other Arabic resources. It contains a vocabulary of length of 32,000.</p><p>For Turkish and Spanish, we used dbmdz/bert-base-turkish-cased <ref type="bibr" coords="7,401.09,141.16,18.06,10.91" target="#b10">[11]</ref> and geotrend/bertbase-es-cased <ref type="bibr" coords="7,150.82,154.71,17.76,10.91" target="#b11">[12]</ref> respectively. The Turkish BERT model contains a vocabulary of length 32,000 and the Turkish model contains a vocabulary of length 26,359.</p><p>For English and for Bulgarian, we used roberta-large <ref type="bibr" coords="7,355.18,181.81,18.07,10.91" target="#b12">[13]</ref> and iarfmoose/roberta-basebulgarian <ref type="bibr" coords="7,136.07,195.36,18.07,10.91" target="#b13">[14]</ref> respectively. The English RoBERTa model contains 50,265 WordPieces, and the Bulgarian RoBERTa model contains 52,000 WordPieces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Augmentation</head><p>The organizers provided a training and a development set for each language. We created 80/20 stratified splits on each training set to create internal training and validation sets for experimentation. We used the development set provided by organizers as a hold-out test set. For each of the internal training datasets, we extracted positive labels and performed contextual word embedding augmentation on each of the positive labels, one epoch at a time, repeating until the number of positive labels at each epoch exceeded the number of negative labels.</p><p>For each language, augmentation and training were done with BERT or RoBERTa models. BERT-based contextual embedding models were used for Arabic <ref type="bibr" coords="7,371.05,383.35,16.09,10.91" target="#b9">[10]</ref>, Spanish <ref type="bibr" coords="7,430.64,383.35,16.08,10.91" target="#b11">[12]</ref>, and Turkish <ref type="bibr" coords="7,89.29,396.90,16.09,10.91" target="#b10">[11]</ref>, and RoBERTa-based contextual embedding models were used for English <ref type="bibr" coords="7,425.79,396.90,17.76,10.91" target="#b12">[13]</ref> and Bulgarian <ref type="bibr" coords="7,89.29,410.45,16.31,10.91" target="#b13">[14]</ref>. We used <ref type="bibr" coords="7,153.47,410.45,17.97,10.91" target="#b14">[15]</ref> <ref type="foot" coords="7,171.44,408.69,3.71,7.97" target="#foot_0">1</ref> to apply Contextual Word Embedding Augmentation. This augmentation type uses the surrounding words of a tweet to apply the most probable insertion or substitution of a lexical item. We chose to only apply substitution.</p><p>With Contextual Word Embedding Augmentation, the user must determine the probability a token should be augmented. On the Bulgarian and Turkish datasets, we tried using no augmentation (p = null) and augmentation at p = {0.1, 0.2, 0.3, 0.4, 0.5}. Additionally, we explored back-translation using AWS translation. We appended back-translated check-worthy tweets to the training set, using English as a pivot language. In the table below, we show the precision, recall, and f1 score for check-worthy class on the Bulgarian dataset. The Turkish experiments yielded similar results. For both languages, we found that augmentations at p = 0.1 resulted in a significant increase in recall and f1 for check-worthy tweets, as we show in the table below. Augmentations at higher probability thresh-holds also yielded better recall and f1 than our null model, but not better than at p = 0.1. We found that augmentation at p=0.1 provided better precision, recall and f1 than using back-translation (translation). Due to time and cost limitations, we did not repeat back-translation experiments for other competition languages or using other pivot languages.</p><p>Based on this exploration (and due to the computational cost of this technique) we adopted p = 0.1 for all languages. For each language, BERT-or RoBERTa-augmented check-worthy examples were appended to the training data and given a check-worthy label. In all languages, we found this improved f1 score for the check-worthy class when applied to our hold-out dev set. However, it's possible that this technique limited some models' performance on the evaluation test set. The table below displays the number of check-worthy augmented samples that were generated for each language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classification</head><p>For both BERT and RoBERTa, we added an additional mean-pooling layer and dropout layer on top of the model prior to the final classification layer. Adding these additional layers has been shown to help prevent over-fitting while fine-tuning <ref type="bibr" coords="8,328.68,435.72,11.54,10.91" target="#b1">[2]</ref>. We used an Adam optimizer with a learning rate of 1.5e-5 and an epsilon of 1e-8. We use a binary cross-entropy loss function, 2 epochs, and a batch size of 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ranking</head><p>To generate rankings, the model's outputs were fed through a SoftMax function. The difference between the positive and negative class likelihoods were then used to rank tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>The official metric of the Lab was mAP for all languages. Table 5 lists our results. Arabic performed the best with 0.658. This was followed by Bulgarian (0.497), Spanish (0.491), Turkish (0.402), and English (0.101).</p><p>The results from Arabic and English can be compared to Accenture's results in CheckThat! 2020. Compared to last year, our team's Arabic score increased and our team's English score decreased. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>In Section 4.1, we showed that contextual embedding augmentation on top of the current training data improved the f1 score of our systems. In the Lab ranking, however, we found that the Accenture received the top results for Arabic, and performed less well for other languages. Table <ref type="table" coords="9,115.71,413.67,5.06,10.91">6</ref> shows our mean average precision versus the number of training samples provided by the CheckThat! organizers. We believe the transformer methods we employed to be highly sensitive to the quantity of training data and distribution of topics across the split dataset. While we were able to generate additional training data, and improve the results, we believe even more augmentation should be employed where natural labeled text cannot be acquired.</p><p>Back translation, which we employed last year, worked well for this problem. We employed it only on Arabic, but expect the technique would work well for the other languages in the Lab as well. We used Contextual Word Embedding Augmentation, this year, but limited our transformations to swaps. Lexical insertion may show to be useful as well. Synonyms and hypernym replacement would likely show advantage.</p><p>Because of the computational cost of augmenting the data with contextual embedding augmentation, we chose p = 0.1 for all languages. The optimal value is likely to be language and task dependant. We would recommend a parameter search of this value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper presents results from the Accenture Team for CLEF2021 CheckThat! Lab, Task 1, to analyze English, Arabic, Spanish, Turkish, and Bulgarian social media to identify claims that require fact-checking. We presented a methodology that provided NLP augmentation of the training data to create additional synthetic training samples. We found this method improved our results. This approach received the highest mean average precision in the Lab this year for Arabic.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,652.79,398.27,8.93;5,137.99,481.82,316.80,158.40"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Label distribution across Arabic, Bulgarian, English, Spanish, and Turkish Training Sets</figDesc><graphic coords="5,137.99,481.82,316.80,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,90.49,338.24,226.88"><head>Table 1</head><label>1</label><figDesc>Dataset descriptionsLanguage Modeling set # of samples Unique word count</figDesc><table coords="4,168.04,139.53,232.32,177.83"><row><cell></cell><cell>Train</cell><cell>3,095</cell><cell>26,919</cell></row><row><cell>Arabic</cell><cell>Test</cell><cell>344</cell><cell>5,413</cell></row><row><cell></cell><cell>Validation</cell><cell>661</cell><cell>8,242</cell></row><row><cell></cell><cell>Train</cell><cell>2,400</cell><cell>10,182</cell></row><row><cell cols="2">Bulgarian Test</cell><cell>600</cell><cell>4,009</cell></row><row><cell></cell><cell>Validation</cell><cell>350</cell><cell>2,074</cell></row><row><cell></cell><cell>Train</cell><cell>698</cell><cell>4,499</cell></row><row><cell>English</cell><cell>Test</cell><cell>124</cell><cell>1,424</cell></row><row><cell></cell><cell>Validation</cell><cell>140</cell><cell>1,607</cell></row><row><cell></cell><cell>Train</cell><cell>2,245</cell><cell>12,765</cell></row><row><cell>Spanish</cell><cell>Test</cell><cell>1,247</cell><cell>2,931</cell></row><row><cell></cell><cell>Validation</cell><cell>250</cell><cell>8,744</cell></row><row><cell></cell><cell>Train</cell><cell>1,709</cell><cell>8,366</cell></row><row><cell>Turkish</cell><cell>Test</cell><cell>1,90</cell><cell>1,745</cell></row><row><cell></cell><cell>Validation</cell><cell>388</cell><cell>2,599</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,90.49,429.75,226.88"><head>Table 2</head><label>2</label><figDesc>Unknown token distribution in data for each language.</figDesc><table coords="6,95.27,122.10,423.47,195.27"><row><cell cols="2">Language Tokenizer</cell><cell cols="4">Modeling Set WordPieces Unknown Token Unknown Percent (%)</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>122,991</cell><cell>358</cell><cell>0.291</cell></row><row><cell>Arabic</cell><cell>BERT</cell><cell>Testing</cell><cell>14,184</cell><cell>35</cell><cell>0.247</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>26,752</cell><cell>66</cell><cell>0.247</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>48,437</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Bulgarian RoBERTa-based</cell><cell>Testing</cell><cell>12,172</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>5,799</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>22,610</cell><cell>0</cell><cell>0</cell></row><row><cell>English</cell><cell>RoBERTa-based</cell><cell>Testing</cell><cell>3,704</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>4,856</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>111,976</cell><cell>2,590</cell><cell>2.313</cell></row><row><cell>Spanish</cell><cell>BERT</cell><cell>Testing</cell><cell>12,246</cell><cell>251</cell><cell>2.050</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>61,361</cell><cell>1,492</cell><cell>2.432</cell></row><row><cell></cell><cell></cell><cell>Training</cell><cell>45,937</cell><cell>104</cell><cell>0.226</cell></row><row><cell>Turkish</cell><cell>BERT</cell><cell>Testing</cell><cell>5,073</cell><cell>11</cell><cell>0.217</cell></row><row><cell></cell><cell></cell><cell>Validation</cell><cell>10,160</cell><cell>13</cell><cell>0.128</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,88.98,90.49,417.00,173.95"><head>Table 3</head><label>3</label><figDesc>Augmentation substitution improvements on Bulgarian training set using varied token augmentation probabilities</figDesc><table coords="8,88.99,134.06,367.37,130.38"><row><cell></cell><cell cols="7">p=null p=0.1 p=0.2 p=0.3 p=0.4 p=0.5 translation</cell></row><row><cell cols="2">cw_precision 0.65</cell><cell>0.51</cell><cell>0.41</cell><cell>0.36</cell><cell>0.36</cell><cell>0.42</cell><cell>0.47</cell></row><row><cell>cw_recall</cell><cell>0.17</cell><cell>0.6</cell><cell>0.66</cell><cell>0.45</cell><cell>0.31</cell><cell>0.31</cell><cell>0.47</cell></row><row><cell>cw_f1</cell><cell>0.28</cell><cell>0.55</cell><cell>0.51</cell><cell>0.4</cell><cell>0.33</cell><cell>0.36</cell><cell>0.47</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Number of augmented check-worthy samples generated for each language</cell><cell></cell></row><row><cell>Language</cell><cell></cell><cell cols="6">Bulgarian Arabic English Spanish Turkish</cell></row><row><cell cols="3">Augmentations 2,471</cell><cell>2,748</cell><cell>492</cell><cell></cell><cell>1,800</cell><cell>656</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,88.98,90.49,385.71,231.51"><head>Table 5</head><label>5</label><figDesc>Accenture results from CheckThat! 2021 Task 1</figDesc><table coords="9,88.98,119.88,385.71,202.11"><row><cell>Entry</cell><cell cols="2">mAP MRR</cell><cell>RP</cell><cell>P@1</cell><cell cols="3">P@3 P@5 P@10 P@20 P@30</cell></row><row><cell>Arabic</cell><cell>0.658</cell><cell cols="2">1.000 0.599</cell><cell cols="2">1.000 1.000 1.000</cell><cell cols="2">1.000 0.9500</cell><cell>0.840</cell></row><row><cell cols="2">Bulgarian 0.497</cell><cell cols="2">1.000 0.474</cell><cell cols="2">1.000 1.000 0.800</cell><cell>0.700</cell><cell>0.600</cell><cell>0.440</cell></row><row><cell>English</cell><cell>0.101</cell><cell cols="2">0.143 0.158</cell><cell cols="2">0.000 0.000 0.000</cell><cell>0.200</cell><cell>0.200</cell><cell>0.100</cell></row><row><cell>Spanish</cell><cell cols="5">0.491 1.0000 0.508 1.0000 0.667 0.800</cell><cell>0.900</cell><cell>0.700</cell><cell>0.620</cell></row><row><cell>Turkish</cell><cell>0.402</cell><cell cols="2">0.250 0.415</cell><cell cols="2">0.000 0.000 0.400</cell><cell>0.400</cell><cell>0.650</cell><cell>0.660</cell></row><row><cell>Table 6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">Accenture mAP results from CheckThat! 2021 Task 1, with training sample count</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">mAP # Samples</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>English</cell><cell cols="2">0.101 698</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Turkish</cell><cell cols="2">0.402 3095</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Spanish</cell><cell cols="2">0.491 2245</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Bulgarian 0.497 2400</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Arabic</cell><cell cols="2">0.658 3095</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,108.93,671.02,145.36,8.97"><p>https://github.com/makcedward/nlpaug</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,186.24,395.17,10.91;10,112.66,199.79,393.33,10.91;10,112.66,213.34,270.25,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,315.50,186.24,192.33,10.91;10,112.66,199.79,128.19,10.91">Inductive learning algorithms and representations for text categorization</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,263.54,199.79,242.45,10.91;10,112.66,213.34,181.49,10.91">Proceedings of the seventh international conference on Information and knowledge management</title>
		<meeting>the seventh international conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="148" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,226.89,395.17,10.91;10,112.66,240.44,394.53,10.91;10,112.66,253.99,393.33,10.91;10,112.66,267.54,393.33,10.91;10,112.66,281.08,395.01,10.91;10,112.66,294.63,17.97,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,289.48,226.89,218.34,10.91;10,112.66,240.44,259.19,10.91">Accenture at checkthat! 2020: If you say so: Posthoc fact-checking of claims using transformer-based models</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_226.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,235.82,253.99,270.17,10.91;10,112.66,267.54,78.90,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="10,480.56,268.55,25.43,9.72;10,112.66,281.08,123.00,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,308.18,394.53,10.91;10,112.66,321.73,395.01,10.91;10,112.66,335.28,393.64,10.91;10,112.66,348.83,394.61,10.91;10,112.66,362.38,393.32,10.91;10,112.28,375.93,394.91,10.91;10,112.66,389.48,153.66,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,332.72,335.28,173.58,10.91;10,112.66,348.83,374.20,10.91">Overview of the CLEF-2021 CheckThat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,112.66,362.38,393.32,10.91;10,112.28,375.93,390.55,10.91">Proceedings of the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021</title>
		<meeting>the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021<address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,403.03,393.32,10.91;10,112.66,416.58,394.53,10.91;10,112.66,430.13,393.33,10.91;10,112.66,443.67,393.33,10.91;10,112.66,457.22,310.90,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,112.66,430.13,393.33,10.91;10,112.66,443.67,123.26,10.91">Overview of the CLEF-2021 CheckThat! lab task 1 on check-worthiness estimation in tweets and political debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Yavuz Selim Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,259.42,443.67,246.57,10.91;10,112.66,457.22,150.24,10.91">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF &apos;2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,470.77,395.01,10.91;10,112.66,486.76,97.35,7.90" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11755</idno>
		<title level="m" coord="10,229.76,470.77,243.40,10.91">A survey of deep learning for scientific discovery</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,497.87,393.33,10.91;10,112.66,511.42,393.33,10.91;10,112.66,524.97,393.33,10.91;10,112.66,538.52,393.33,10.91;10,112.66,552.07,395.01,10.91;10,112.66,565.62,138.14,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,183.05,497.87,322.94,10.91;10,112.66,511.42,103.04,10.91">EDA: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1670</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1670.doi:10.18653/v1/D19-1670" />
	</analytic>
	<monogr>
		<title level="m" coord="10,239.58,511.42,266.41,10.91;10,112.66,524.97,393.33,10.91;10,112.66,538.52,361.86,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6382" to="6388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,579.17,393.33,10.91;10,112.66,592.72,363.59,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,323.15,579.17,182.83,10.91;10,112.66,592.72,181.08,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,606.27,393.33,10.91;10,112.66,619.81,321.60,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Turc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08962</idno>
		<title level="m" coord="10,321.65,606.27,184.33,10.91;10,112.66,619.81,191.23,10.91">Well-read students learn better: On the importance of pre-training compact models</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,633.36,395.17,10.91;10,112.66,646.91,393.33,10.91;10,112.33,660.46,296.49,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="10,140.00,646.91,263.30,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1907.11692" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,86.97,393.53,10.91;11,112.66,100.52,393.33,10.91;11,112.66,114.06,393.33,10.91;11,112.33,127.61,395.33,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,275.44,86.97,230.75,10.91;11,112.66,100.52,194.80,10.91">KUISAIL at SemEval-2020 task 12: BERT-CNN for offensive speech identification in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Safaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abdullatif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yuret</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.semeval-1.271" />
	</analytic>
	<monogr>
		<title level="m" coord="11,329.09,100.52,176.90,10.91;11,112.66,114.06,343.73,10.91">Proceedings of the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics</title>
		<meeting>the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics<address><addrLine>Barcelona (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2054" to="2059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,141.16,395.00,10.91;11,112.66,154.71,190.14,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="11,168.70,141.16,144.11,10.91">Berturk -bert models for turkish</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3770924</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3770924.doi:10.5281/zenodo.3770924" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,168.26,394.53,10.91;11,112.66,181.81,131.69,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,251.10,168.26,252.12,10.91">Load what you need: Smaller versions of mutlilingual bert</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abdaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sigel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,127.29,181.81,85.54,10.91">SustaiNLP / EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,195.36,395.17,10.91;11,112.66,208.91,393.33,10.91;11,112.33,222.46,296.49,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,140.00,208.91,263.30,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="1907.11692" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,236.01,394.53,10.91;11,112.66,249.56,345.74,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="11,204.64,236.01,297.98,10.91">Token classification with subword tokenizers for bulgarian</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montgomerie</surname></persName>
		</author>
		<ptr target="https://amontgomerie.github.io/2020/09/02/token-classification-bg.html" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,263.11,324.17,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://github.com/makcedward/nlpaug" />
		<title level="m" coord="11,143.13,263.11,81.36,10.91">NLP augmentation</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
