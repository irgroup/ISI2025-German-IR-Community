<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,322.17,15.42;1,88.78,106.66,379.17,15.42">NITK_NLP at CheckThat! 2021: Ensemble Transformer Model for Fake News Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,217.15,11.96"><forename type="first">Hariharan</forename><forename type="middle">Ramakrishnaiyer</forename><surname>Lekshmiammal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<settlement>Surathkal</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.08,134.97,124.81,11.96"><forename type="first">Anand</forename><surname>Kumar Madasamy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">National Institute of Technology Karnataka</orgName>
								<address>
									<settlement>Surathkal</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,322.17,15.42;1,88.78,106.66,379.17,15.42">NITK_NLP at CheckThat! 2021: Ensemble Transformer Model for Fake News Classification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A30DAEF411C35D35EDC9A2B4B4DFB439</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fake news</term>
					<term>RoBERTa</term>
					<term>COVID-19</term>
					<term>Ensemble</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media has become an inevitable part of our life as we are primarily dependent on them to get most of the news around us. However, the amount of false information propagated through it is much higher than the genuine ones, thus becoming a peril to society. In this paper, we have proposed a model for Fake News Classification as a part of CLEF2021 Checkthat! Lab 1 shared task, which had Multi-class Fake News Detection and Topical Domain Classification of News Articles. We have used an ensemble model consisting of pre-trained transformer-based models that helped us achieve 4 ùë°‚Ñé and 1 ùë†ùë° positions on the leaderboard of the two tasks. We achieved an F1-score of 0.4483 against a top score of 0.8376 in one task and a score of 0.8813 in another.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays, social media is the primary platform for people to get the latest news and updates happening around them, either political or entertainment or even health-related. People are more dependent on reliable information during this pandemic situation, which is propagated through social media. But here, the situation is quite different as many information are fake, which spreads faster than authentic ones <ref type="bibr" coords="1,268.58,432.51,11.27,10.91" target="#b0">[1]</ref>. Also, it can be seen that there has been an increase in concern for fake news on social media <ref type="bibr" coords="1,274.65,446.06,11.37,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,288.74,446.06,8.97,10.91" target="#b2">3]</ref> due to various situations in the modern world. Hence tackling fake news is more important as well as challenging in this social media age. This process isn't easy because even humans can't distinguish between fake and authentic news accurately. Thus it becomes crucial to develop an automated system for fake news identification.</p><p>CLEF-2021 CheckThat! <ref type="bibr" coords="1,206.48,500.25,11.36,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,220.58,500.25,8.96,10.91" target="#b4">5]</ref> Lab had organized a shared task named Fake News Classification 1 . The shared task had two subtasks called Multi-Class Fake News Detection and Topical Domain Classification of News Articles. The first subtask was to classify the articles into fake, partially fake, other, true, and the second subtask was to classify into domains health, election, crime, climate, election, education. They had provided datasets for both the tasks, from 2010 to 2021, covering several topics like election, COVID-19, etc.</p><p>In this paper, we have used transformers, which is effective for text classification because of their self-attention mechanism and a better understanding of word features. We have used the transformer-based model <ref type="bibr" coords="2,248.21,86.97,11.49,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,262.68,86.97,9.03,10.91" target="#b6">7]</ref> and finetuned them for the training data to get the predictions. This paper is presented as follows, section 2 about the related works, section 3 explains the dataset, section 4 explains the Methodology and System Description, section 5 about the Experiments and Results, which follows Conclusions and Future scope.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Fake information analysis and detection have gained attention because of the ease of availability of the data from social media. This is because even social media needs to curb the spreading of misinformation through their platform. We have many traditional machine learning methods to classify fake and real information. However, the performance of such systems is not that accurate because of the inability to understand the data. Deep Learning is now becoming an integral part of these fake information detection systems because of the computation capability. We have analyzed some recent works which have used deep learning models and some of the newer datasets used for fake news classification, which are explained below.</p><p>Umer et al. <ref type="bibr" coords="2,151.87,294.63,11.73,10.91" target="#b7">[8]</ref> has used a CNN-LSTM deep learning architecture to detect relative stance of fake news towards it headline. They have employed PCA and Chi-Square to reduce the dimensionality of features to predict the relative stance of a news article towards its title. Their results show a 20% improvement in the F1-Score, and PCA excels Chi-Square and state-of-the-art methods. Das et al. <ref type="bibr" coords="2,175.82,348.83,12.71,10.91" target="#b8">[9]</ref> proposed an Ensemble model for COVID-19 fake news detection for the Constraint COVID19 shared task <ref type="bibr" coords="2,241.99,362.38,16.41,10.91" target="#b9">[10]</ref>. They have used a combination of pre-trained models with a heuristic algorithm based on the username handle and link-domain in tweets. Shahi et al. <ref type="bibr" coords="2,115.64,389.48,18.07,10.91" target="#b10">[11]</ref> have done an experimental study of COVID-19 misinformation on Twitter. They have analyzed the propagation, authors, and content of misinformation to gain early insights and categorized tweets into false, partially false, true, and other. They have also found that fake claims disseminate faster than partially false claims. Shahi et al. <ref type="bibr" coords="2,409.87,430.13,18.07,10.91" target="#b11">[12]</ref> have proposed a benchmark classification dataset for fake news, which had multilingual cross-domain factchecked news articles for COVID-19, collected from 92 fact-checking websites. Shahi <ref type="bibr" coords="2,487.91,457.22,18.07,10.91" target="#b12">[13]</ref> proposed an annotation framework of multi-modal social media data. They have presented a semi-automated framework for collecting multi-modal annotated data from social media combining machines and humans in the data compilation process. They have also implemented this framework for gathering COVID-19 misinformation. Mehta et al. <ref type="bibr" coords="2,410.51,511.42,18.06,10.91" target="#b13">[14]</ref> have proposed a transformer model for fake news classification of a specific domain dataset, including human justification and metadata for added performance. They have used multiple BERT models with shared weights between them to handle various inputs. Liao et al. <ref type="bibr" coords="2,383.14,552.07,17.85,10.91" target="#b14">[15]</ref> proposed an integrated multi-task model for fake news detection. They have considered news topics and authors as any of them can have a higher percentage of fake news. They investigate the influence of topic labels and contextual information at the same time to improve the performance on short fake news. Manouchehri et al. <ref type="bibr" coords="2,234.01,606.27,18.07,10.91" target="#b15">[16]</ref> proposed a theoretical approach to block the influence of misinformation in social networks efficiently. The main idea was to limit the spread of misinformation as much as possible. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset Description</head><p>There were two tasks given on the competition website<ref type="foot" coords="3,352.29,347.00,3.71,7.97" target="#foot_0">2</ref> under Fake News Detection by CLEF2021-CheckThat! Lab<ref type="foot" coords="3,209.76,360.54,3.71,7.97" target="#foot_1">3</ref> , namely Multi-class Fake News Detection of News Articles (Task 3a) and Topical Domain Classification of News Articles (Task 3b). The training dataset for Task3a is shown in table 1, which had 900 articles with respective labels and the testing data had 364 articles without labels. The training dataset for Task3b is shown in table 1, which had 318 articles with respective labels and the testing data had 137 articles. The label distributions of both the datasets are shown in figure <ref type="figure" coords="3,268.77,430.05,3.74,10.91" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>We had a classification task under both Task3a and Task3b where we had to classify the articles into labels and domains as in figure <ref type="figure" coords="3,242.53,605.48,3.66,10.91" target="#fig_0">1</ref>. The proposed model had Text Preprocessing, Tokenization, Model Architecture, and Ensemble Modeling <ref type="bibr" coords="3,287.30,619.03,11.28,10.91" target="#b8">[9]</ref>. The overall design is as shown in figure <ref type="figure" coords="3,482.02,619.03,3.66,10.91" target="#fig_1">2</ref>, the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Text Preprocessing</head><p>The data provided by the organizers were mainly retrieved from various news websites and articles which need to be preprocessed; for this, we used the clean-text<ref type="foot" coords="4,407.76,357.35,3.71,7.97" target="#foot_2">4</ref> library from python, which helped in removing contents like URLs, ASCII conversions, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Tokenization</head><p>We were dealing with articles that had sentences. To process the sentence data, we need to convert them to some tokens and pass them on to the model. We have used the tokenization <ref type="foot" coords="4,501.78,434.17,3.71,7.97" target="#foot_3">5</ref>approach corresponding to the pre-trained model being used, which expects the tokens to be in an explicit structure depending upon the model. Each model will tokenize based on its structure during training on the data. We have used Longformer <ref type="bibr" coords="4,338.48,476.57,16.35,10.91" target="#b16">[17]</ref>, and RoBERTa <ref type="bibr" coords="4,426.01,476.57,18.01,10.91" target="#b17">[18]</ref> models and a combination of them which are modified versions of BERT <ref type="bibr" coords="4,353.39,490.12,16.25,10.91" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model Architecture</head><p>We have used pre-trained models <ref type="foot" coords="4,235.90,538.09,3.71,7.97" target="#foot_4">6</ref> as the base model for this classification task. The model has been individually trained for data using the pre-trained weights, which gives the probabilities for the different labels. As transfer learning is being used, the model has its own vocabulary and pre-trained embeddings, which is fine-tuned to get the predictions using the training data.</p><p>The same tokenizer and model are used to get the predictions for test data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ensemble Modeling</head><p>In this method, we have used an ensemble approach to predict the labels for the testing data. We have applied RoBERTa and Longformer as the base models for our classification. Longformer was chosen as it can handle up to a maximum length of 4096, whereas RoBERTa was chosen because it outperformed BERT in most of the downstream tasks and benchmarks. We have used the model prediction vectors from these models and combined them to get the final result for our classification model. The final prediction is the sum of the individual predictions by the models and taking the maximum probability among the class labels. This helps in predicting the labels with more probability towards a particular category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">Data Analysis and Modeling</head><p>The longformer model was mainly chosen because as per the token distribution in the figure <ref type="figure" coords="5,499.80,528.30,3.69,10.91" target="#fig_2">3</ref>, we can see that most of the articles have tokens which are less than 3000, but we have some 20 odd number of articles having tokens of size 4096 (which is the maximum model can handle) even after truncation. Even though we lose some information, for training the longformer model, 3000 was chosen as the maximum token length for both the task as they had a similar distribution of tokens. When we tried to use the full token size, there wasn't much difference in the predictions.</p><p>The training strategy for the RoBERTa model was different as it can handle only tokens up to 512 length. To train the data with this model, we split the single article into small chunks keeping the same label for the split parts. We had split one article into 450 tokens (around 50 is left because the model splits words into subwords) each so that the model can perform well. For example, if an article had 2000 tokens, we split it into four articles having 450 tokens and one having 200 tokens with the same labels as the original one. The one drawback of this method is that while we are testing the data, articles are truncated to 450 tokens which can affect the results.</p><p>Ensemble model output is obtained using the predicted probabilities for each of the models. Instead of taking the final prediction from the models, we took the probabilities for each of the labels (Task 3a) and domains (Task 3b). These probabilities were summed and rounded up to get the final predictions. Result analysis for both the tasks will be explained in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Results</head><p>We have fine-tuned the pre-trained models for the training data using AdamW <ref type="bibr" coords="6,431.16,253.99,17.75,10.91" target="#b19">[20]</ref> and learning rate 2e-5 (as recommended in the original model). We had used cross-entropy loss as the loss function. The experiments were performed on a nvidia-dgx machine with CentOS, Tesla V100 32GB GPU. The learning rate was kept the same for all the tasks, and the number of epochs varied from 10-15 with callbacks on validation loss. The same parameters were used for both the tasks as they had similar data; only classification labels were different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results of Individual Models</head><p>In this section, we will discuss the individual model results for both tasks. We have used a training and validation split of 0.20 for the training data, and the results of validation data are shown in the table2. The longformer model with maximum token length 3000 gave an F1-score (weighted average was taken as it will consider the proportion for each label in the dataset) of 0.60 for task 3a. Even though longformer had more tokens, it couldn't get better than that of RoBERTa. Hence we came up with an ensemble model as our proposed model whose results are explained in the following section.</p><p>While coming to task 3b, we have tried a different method because longformer could not perform well for the token length of size 3000. Here we have used the RoBERTa model (with maximum token length of 450) directly on the entire article without splitting for the long sequences whose results are shown in the table 2. Then we split the data into chunks of 450 as explained in the last section, whose results are shown as RoBERTa_SplitText in the table 2. These two models were used as an ensemble model for the task 3b classification because the model which was trained on chunks of text could have a better understanding. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results of Ensemble Models</head><p>The final model results for test data are as shown in table <ref type="table" coords="7,348.07,107.54,3.76,10.91" target="#tab_2">3</ref>. As discussed in the methodology section, we have used an ensemble of the fine-tuned Longformer and RoBERTa as the final prediction for the test data. We can see from the results that for task 3b ensemble model outperformed, but the Longformer performed well for task 3a. The final results of our proposed model for task 3b achieved 1 ùë†ùë° position in the leaderboard of the competition (position on the leaderboard is given in brackets corresponding to the task). Eventhough the ensemble model could perform well for task 3b, we believe some mislabelled articles were causing the ensemble model to underperform in task 3a. Also, we have given F1-weighted score in the previous section because of the unbalanced class labels. Here, we have provided the F1-macro score because it was used as the final score for the leaderboard by the organizers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Scope</head><p>In this modern social media age, we have to be vigilant in the rapid spreading of fake information, which can have immense ramifications on our day-to-day lives. In this paper, we have focussed on building a model to classify the news articles from social media comprising politics, entertainment, COVID-19, etc., as fake or not. We have fine-tuned transformer-based models Longformer and RoBERTa to predict the news articles. Moreover, our results got improved when we implemented the ensemble combination of these models. In the future, this method can be extended to learn more features with different models used in combination, and also, we would evaluate our model on generic Fake News datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,286.83,126.52,8.93;3,89.29,84.19,416.69,178.13"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dataset Distribution</figDesc><graphic coords="3,89.29,84.19,416.69,178.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,89.29,244.67,131.81,8.93;4,89.29,84.19,416.70,135.96"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall Model Design</figDesc><graphic coords="4,89.29,84.19,416.70,135.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.29,325.96,150.59,8.93;5,188.99,84.19,214.80,229.20"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Token Length Distribution</figDesc><graphic coords="5,188.99,84.19,214.80,229.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,459.05,261.04,71.40"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="3,89.29,471.06,260.74,59.39"><row><cell>Dataset Details</cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell cols="2">Data Training Testing</cell></row><row><cell>3a</cell><cell>900</cell><cell>364</cell></row><row><cell>3b</cell><cell>318</cell><cell>137</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,576.61,364.08,83.35"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="6,89.29,588.61,363.78,71.35"><row><cell cols="2">Individual Model Results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell>Model</cell><cell cols="4">Accuracy Precision Recall F1-Weighted</cell></row><row><cell>3a</cell><cell>Longformer RoBERTa</cell><cell>0.62 0.64</cell><cell>0.58 0.62</cell><cell>0.62 0.64</cell><cell>0.60 0.62</cell></row><row><cell>3b</cell><cell>RoBERTa RoBERTa_SplitText</cell><cell>0.91 0.93</cell><cell>0.90 0.93</cell><cell>0.91 0.93</cell><cell>0.91 0.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,258.49,384.48,83.36"><head>Table 3</head><label>3</label><figDesc></figDesc><table coords="7,89.29,270.49,384.18,71.36"><row><cell cols="2">Final Model Results on Test Data</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell>Model</cell><cell cols="4">Accuracy Precision Recall F1-Macro</cell></row><row><cell>3a</cell><cell>Longformer Longformer+RoBERTa_SplitText</cell><cell>0.52 0.42</cell><cell>0.50 0.33</cell><cell>0.47 0.34</cell><cell>0.45(4) 0.31</cell></row><row><cell>3b</cell><cell>RoBERTa RoBERTa+RoBERTa_SplitText</cell><cell>0.83 0.91</cell><cell>0.82 0.91</cell><cell>0.76 0.87</cell><cell>0.77 0.88(1)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,108.93,660.04,192.37,8.97"><p>https://competitions.codalab.org/competitions/31238</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,108.93,671.00,276.40,8.97"><p>https://gitlab.com/checkthat_lab/clef2021-checkthat-lab/-/tree/master/task3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="4,108.93,649.05,127.66,8.97"><p>https://pypi.org/project/clean-text/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,108.93,660.01,196.53,8.97"><p>https://huggingface.co/docs/tokenizers/python/latest/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="4,108.93,670.97,107.31,8.97"><p>http://huggingface.co/models</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,556.79,393.98,10.91;7,112.41,570.34,394.76,10.91;7,112.66,586.33,91.42,7.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,239.95,556.79,178.02,10.91">The spread of true and false news online</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.1126/science.aap9559</idno>
		<ptr target="https://science.sciencemag.org/content/359/6380/1146.doi:10.1126/science.aap9559" />
	</analytic>
	<monogr>
		<title level="j" coord="7,426.23,556.79,33.12,10.91">Science</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="1146" to="1151" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,597.44,393.33,10.91;7,112.66,610.98,292.79,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,376.35,597.44,129.64,10.91;7,112.66,610.98,162.91,10.91">Fake news detection on social media using geometric deep learning</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mannion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06673</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,624.53,393.61,10.91;7,112.66,638.08,393.33,10.91;7,112.66,651.63,394.03,10.91;7,112.41,665.18,284.03,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,427.02,624.53,79.25,10.91;7,112.66,638.08,393.33,10.91;7,112.66,651.63,9.07,10.91">Political Ideology Predicts Perceptions of the Threat of COVID-19 (and Susceptibility to Fake News About It)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Calvillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J B</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">J</forename><surname>Smelter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rutchick</surname></persName>
		</author>
		<idno type="DOI">10.1177/1948550620940539</idno>
		<ptr target="https://doi.org/10.1177/1948550620940539.doi:10.1177/1948550620940539" />
	</analytic>
	<monogr>
		<title level="j" coord="7,128.40,651.63,193.95,10.91">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1119" to="1128" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,394.53,10.91;8,112.66,100.52,393.33,10.91;8,112.66,114.06,393.33,10.91;8,112.66,127.61,394.53,10.91;8,112.66,141.16,393.33,10.91;8,112.66,154.71,394.53,10.91;8,112.39,168.26,394.89,10.91;8,112.31,181.81,374.62,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,488.80,100.52,17.19,10.91;8,112.66,114.06,393.33,10.91;8,112.66,127.61,99.49,10.91">The CLEF-2021 checkthat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-72240-1_75</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-72240-1_75.doi:10.1007/978-3-030-72240-1\_75" />
	</analytic>
	<monogr>
		<title level="m" coord="8,202.85,141.16,303.14,10.91;8,112.66,154.71,105.71,10.91;8,414.33,154.71,89.84,10.91">Advances in Information Retrieval -43rd European Conference on IR Research, ECIR 2021</title>
		<title level="s" coord="8,185.14,169.28,144.92,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-04-01">March 28 -April 1, 2021. 2021</date>
			<biblScope unit="volume">12657</biblScope>
			<biblScope unit="page" from="639" to="649" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct coords="8,112.66,195.36,394.53,10.91;8,112.66,208.91,395.01,10.91;8,112.66,222.46,393.64,10.91;8,112.66,236.01,394.61,10.91;8,112.66,249.56,393.32,10.91;8,112.28,263.11,394.91,10.91;8,112.66,276.66,153.66,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,332.72,222.46,173.58,10.91;8,112.66,236.01,374.20,10.91">Overview of the CLEF-2021 CheckThat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barr√≥n-Cede√±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>M√≠guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Stru√ü</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,249.56,393.32,10.91;8,112.28,263.11,390.55,10.91">Proceedings of the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021</title>
		<meeting>the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021<address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,290.20,394.53,10.91;8,112.66,303.75,394.53,10.91;8,112.66,317.30,393.33,10.91;8,112.66,330.85,253.34,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="8,309.90,317.30,196.09,10.91;8,112.66,330.85,123.30,10.91">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,344.40,394.52,10.91;8,112.66,357.95,283.01,10.91" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,176.30,357.95,111.98,10.91">Attention Is All You Need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Brain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">≈Å</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="8,112.66,371.50,393.33,10.91;8,112.66,385.05,395.01,10.91;8,112.66,398.60,179.18,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,388.06,371.50,117.93,10.91;8,112.66,385.05,210.79,10.91">Fake news stance detection using deep learning architecture (CNN-LSTM)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Umer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>On</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3019735</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,336.83,385.05,56.43,10.91">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="156695" to="156706" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,412.15,393.33,10.91;8,112.66,425.70,394.62,10.91;8,112.31,439.25,218.89,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,240.32,412.15,265.67,10.91;8,112.66,425.70,72.77,10.91">A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dutta</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="2101.03545" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,452.79,394.52,10.91;8,112.33,466.34,395.33,10.91;8,112.66,479.89,154.86,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Patwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">Y</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Guptha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03327</idno>
		<ptr target="www.boomlive" />
		<title level="m" coord="8,186.10,466.34,235.97,10.91">Fighting an infodemic: COVID-19 fake news dataset</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,493.44,393.33,10.91;8,112.66,506.99,283.01,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,292.17,493.44,213.82,10.91;8,112.66,506.99,42.26,10.91">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Majchrzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,162.86,506.99,154.86,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,520.54,393.33,10.91;8,112.66,534.09,393.33,10.91;8,112.66,547.64,387.87,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,220.22,520.54,285.77,10.91;8,112.66,534.09,49.79,10.91">FakeCovid -a multilingual cross-domain fact check news dataset for covid-19</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nandini</surname></persName>
		</author>
		<ptr target="http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="8,183.76,534.09,322.22,10.91;8,112.66,547.64,73.20,10.91">Workshop Proceedings of the 14th International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,561.19,393.59,10.91;8,112.66,574.74,146.44,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00502</idno>
		<title level="m" coord="8,168.48,561.19,305.06,10.91">Amused: An annotation framework of multi-modal social media data</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,588.29,393.32,10.91;8,112.66,601.84,395.01,10.91;8,112.66,615.39,174.74,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="8,354.07,588.29,151.91,10.91;8,112.66,601.84,119.12,10.91">A transformer-based architecture for fake news classification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">‚Ä¢</forename><forename type="middle">M</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13278-021-00738-y</idno>
		<ptr target="https://doi.org/10.1007/s13278-021-00738-y.doi:10.1007/s13278-021-00738-y" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,628.93,393.61,10.91;8,112.66,642.48,393.33,10.91;8,112.41,656.03,246.17,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,392.04,628.93,114.23,10.91;8,112.66,642.48,137.78,10.91">An Integrated Multi-Task Model for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2021.3054993</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,258.96,642.48,247.03,10.91">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">4347</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,669.58,393.33,10.91;9,112.66,86.97,393.33,10.91;9,112.66,100.52,374.92,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,327.63,669.58,178.36,10.91;9,112.66,86.97,302.73,10.91">A Theoretically Guaranteed Approach to Efficiently Block the Influence of Misinformation in Social Networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Manouchehri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Helfroush</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Danyali</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCSS.2021.3059430</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,424.41,86.97,81.58,10.91;9,112.66,100.52,149.04,10.91">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,395.01,10.91;9,112.66,127.61,296.08,10.91" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="9,266.23,114.06,210.76,10.91">Longformer: The Long-Document Transformer</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<ptr target="https://github.com/allenai/longformer.arXiv:2004.05150" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,394.53,10.91;9,112.30,154.71,394.97,10.91;9,112.66,168.26,256.43,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<ptr target="https://github.com/pytorch/fairseq.arXiv:1907.11692" />
		<title level="m" coord="9,172.90,154.71,276.19,10.91">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,181.81,395.17,10.91;9,112.66,195.36,344.59,10.91" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,289.64,181.81,218.19,10.91;9,112.66,195.36,165.11,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><forename type="middle">C</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kristina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:arXiv:1810.04805v2</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,395.01,10.91;9,112.66,224.90,97.35,7.90" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m" coord="9,262.02,208.91,203.76,10.91">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
