<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,364.02,15.42;1,88.78,106.66,414.43,15.42;1,89.29,128.58,106.29,15.43">CIVIC-UPM at CheckThat! 2021: Integration of Transformers in Misinformation Detection and Topic Classification</title>
				<funder>
					<orgName type="full">Convenio Plurianual</orgName>
				</funder>
				<funder ref="#_gaQCY9D">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
				<funder ref="#_eYv2rvg">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder>
					<orgName type="full">Programa de Excelencia para el Profesorado Universitario</orgName>
				</funder>
				<funder ref="#_jRCwPxj">
					<orgName type="full">BBVA FOUNDATION GRANTS FOR SCIENTIFIC RESEARCH</orgName>
				</funder>
				<funder>
					<orgName type="full">Universidad Politécnica de Madrid</orgName>
				</funder>
				<funder ref="#_8cCurTf #_vgnbWe9">
					<orgName type="full">Comunidad Autónoma de Madrid</orgName>
				</funder>
				<funder ref="#_xuasrQb #_hDxaXv6">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,156.89,110.87,11.96"><forename type="first">Álvaro</forename><surname>Huertas-García</surname></persName>
							<email>alvaro.huertas.garcia@alumnos.upm.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer System Engineering</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Calle de Alan Turing</addrLine>
									<postCode>28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">Universidad Rey Juan Carlos</orgName>
								<address>
									<addrLine>Calle Tulipán</addrLine>
									<postCode>28933</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.67,156.89,95.32,11.96"><forename type="first">Javier</forename><surname>Huertas-Tato</surname></persName>
							<email>javier.huertas.tato@upm.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer System Engineering</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Calle de Alan Turing</addrLine>
									<postCode>28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.64,156.89,84.86,11.96"><forename type="first">Alejandro</forename><surname>Martín</surname></persName>
							<email>alejandro.martin@upm.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer System Engineering</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Calle de Alan Turing</addrLine>
									<postCode>28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,170.84,77.73,11.96"><forename type="first">David</forename><surname>Camacho</surname></persName>
							<email>david.camacho@upm.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer System Engineering</orgName>
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
								<address>
									<addrLine>Calle de Alan Turing</addrLine>
									<postCode>28031</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,364.02,15.42;1,88.78,106.66,414.43,15.42;1,89.29,128.58,106.29,15.43">CIVIC-UPM at CheckThat! 2021: Integration of Transformers in Misinformation Detection and Topic Classification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">65B36B146E29A546F05D62FC29B21025</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Misinformation</term>
					<term>Social Media</term>
					<term>Topic Modeling</term>
					<term>Fact-checking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Online Social Networks (OSNs) growth enables and amplifies the quick spread of harmful, manipulative and false information that influence public opinion while sow conflict on social or political issues. Therefore, the development of tools to detect malicious actors and to identify low-credibility information and misinformation sources is a new crucial challenge in the ever-evolving field of Artificial Intelligence. The scope of this paper is to present a Natural Language Processing (NLP) approach that uses Doc2Vec and different state-of-the-art transformer-based models for the CLEF2021 Checkthat! lab Task 3. Through this approach, the results show that it is possible to achieve 41.43% macro-average F1-score in the misinformation detection (Task A) and 67.65% macro-average F1-score in the topic classification (Task B).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Misleading information spreads on the Internet at an incredible speed and Online Social Networks (OSNs) amplify the quick spread of harmful, manipulative and false information. This phenomenon undermines the integrity of online conversations, influences public opinion, and originates conflicts on social, political, or health issues <ref type="bibr" coords="1,346.74,490.96,11.59,10.91" target="#b0">[1]</ref>. In particular, since COVID-19 emerged in Wuhan, China, in December 2019, the public has been bombarded with vast quantities of information, much of which is not checked, leading the World Health Organization (WHO) to coin this situation as the term infodemic <ref type="bibr" coords="1,317.57,531.61,11.38,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,331.67,531.61,7.59,10.91" target="#b1">2]</ref>. Therefore, the development of tools devoted to detecting malicious actors (e.g. bots and trolls) and identifying low-credibility information and misinformation sources is a new crucial challenge. Throughout this paper, we will use the term misinformation instead of fake news following the recommendations of the Poynter Institute <ref type="foot" coords="2,166.54,85.21,3.71,7.97" target="#foot_0">1</ref> and the Council of Europe as they consider it inadequate to describe the complexity of the information disorder ecosystem <ref type="bibr" coords="2,314.29,100.52,11.43,10.91" target="#b2">[3]</ref>.</p><p>The scope of this paper is to describe a Natural Language Processing (NLP) approach that makes use of Machine Learning (ML) and Deep Learning (DL) techniques for the CLEF2021 Checkthat! lab Task 3 <ref type="bibr" coords="2,186.85,141.16,11.23,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,200.76,141.16,7.49,10.91" target="#b4">5]</ref>. In this competition, we carry out a comparative study between the classical Doc2Vec algorithm <ref type="bibr" coords="2,218.54,154.71,12.96,10.91" target="#b5">[6]</ref> as document feature extractor combined with ML classifiers, and fine-tuned state-of-the-art models based on Transformers such as T5 <ref type="bibr" coords="2,427.23,168.26,11.58,10.91" target="#b6">[7]</ref>, RoBERTa <ref type="bibr" coords="2,491.74,168.26,11.58,10.91" target="#b7">[8]</ref>, Electra <ref type="bibr" coords="2,123.09,181.81,12.84,10.91" target="#b8">[9]</ref> and Longformers <ref type="bibr" coords="2,217.90,181.81,11.43,10.91" target="#b5">[6]</ref>.</p><p>This paper is organized into the following sections: Section 2 provides a general view of some related works on misinformation detection and the description of the Checkthat! lab task <ref type="bibr" coords="2,110.34,222.46,11.45,10.91" target="#b3">[4]</ref>. Section 3 introduces our proposed approach. Section 4 describes the results from the experiments conducted. Finally, the conclusions are covered in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task Description and Related Work</head><p>In recent years, there has been growing interest in detecting misinformation <ref type="bibr" coords="2,428.63,294.63,16.35,10.91" target="#b9">[10,</ref><ref type="bibr" coords="2,447.72,294.63,12.52,10.91" target="#b10">11,</ref><ref type="bibr" coords="2,462.97,294.63,12.27,10.91" target="#b11">12]</ref>. Since 2017, Checkthat! organizers have proposed different tasks of misinformation detection such as automatic identification and verification of claims, check-worthiness, or evidence retrieval <ref type="bibr" coords="2,490.81,321.73,16.38,10.91" target="#b12">[13,</ref><ref type="bibr" coords="2,89.04,335.28,12.23,10.91" target="#b13">14]</ref>. In addition, other authors <ref type="bibr" coords="2,222.90,335.28,17.75,10.91" target="#b11">[12]</ref> have committed to combating the misinformation generated during the COVID-19 pandemic by collecting data since the pandemic's outbreak to explore the impact of fact-checkers on misinformation.</p><p>The current task addressed in this paper of misinformation detection Checkthat! lab at CLEF 2021 <ref type="bibr" coords="2,111.83,389.48,11.23,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,125.72,389.48,12.50,10.91" target="#b14">15,</ref><ref type="bibr" coords="2,140.87,389.48,13.95,10.91" target="#b15">16]</ref> is divided into two subtasks: Task A and Task B. Task A is designed to classify a set of news into four classes (false, partially false, true, other) <ref type="bibr" coords="2,364.95,403.03,16.28,10.91" target="#b16">[17]</ref>. On the other hand, Task B consists of classifying a subset of news from Task A into six topical categories: health, economy, crime, climate, elections, and education <ref type="bibr" coords="2,268.22,430.13,16.31,10.91" target="#b17">[18]</ref>. Both subtasks share that the text data is divided into the title and the body of news, and that they are a multi-class classification problem with imbalanced data (see Table <ref type="table" coords="2,212.19,457.22,3.60,10.91" target="#tab_0">1</ref>). Therefore, the official evaluation metric is the macro-averaged F1-score. The steps used by the organizers for the data collection were defined in the research presenting the AMUSED framework <ref type="bibr" coords="2,259.51,484.32,16.42,10.91" target="#b18">[19]</ref>. It is important to point out that during the data exploration some inconsistencies were found. For example, in Task A, some news titles and bodies seemed to be unrelated. Moreover, in Task B, the title and the body fields appeared to be swapped as the length of the title was longer than the length of the body.</p><p>Regarding previous related work in the literature, the appearance of the attention-based method in 2017 <ref type="bibr" coords="2,161.20,552.07,18.00,10.91" target="#b19">[20]</ref> paved the way for the development of transformer architectures such as Bidirectional Encoder Representations from transformers (BERT) <ref type="bibr" coords="2,390.81,565.62,16.42,10.91" target="#b20">[21]</ref>. Jwa et al. <ref type="bibr" coords="2,462.35,565.62,18.07,10.91" target="#b21">[22]</ref> were among the first to develop a model based on BERT for detecting misinformation. The authors conclude that fine-tuning the model in the specific task leads to better results than traditional approaches, such as using a simple classifier model based on TF-IDF and cosine similarity to classify news <ref type="bibr" coords="2,152.67,619.81,16.41,10.91" target="#b22">[23]</ref>. Nevertheless, in the literature, there are also examples of using classical techniques such as Doc2Vec <ref type="bibr" coords="2,218.44,633.36,12.94,10.91" target="#b5">[6]</ref> to deal with long text documents in tasks related to the fight against misinformation <ref type="bibr" coords="2,195.80,646.91,16.25,10.91" target="#b23">[24]</ref>. Unlike Doc2Vec, one of the main transformer-based models' limitations on Natural Language Processing (NLP) tasks is the text length. The average text length in Task A is 4,167 and 286 words in body and title, with a maximum of 32,767 and 9,960 words, respectively. In Task B, in body and title, the average is 4,980 and 566 words, and the maximum is 32,767 and 16,524 words, respectively. Long sequences of text are disproportionately expensive for transformers because attention is quadratic to the sequence length <ref type="bibr" coords="3,336.76,350.85,16.41,10.91" target="#b20">[21]</ref>. For this reason, recently, a new method has been proposed, namely Longformer. The authors of Longformer <ref type="bibr" coords="3,439.08,364.40,18.07,10.91" target="#b24">[25]</ref> developed a model with an attention mechanism that scales linearly with sequence length by replacing the full self-attention mechanism with the combination of local windowed attention and global attention to have in to account larger interactions without increasing the computation, making it easy to process documents of thousands of tokens. Furthermore, a recent research <ref type="bibr" coords="3,449.48,418.60,17.75,10.91" target="#b25">[26]</ref> includes Longformers in a framework for jointly predicting rumor stance and veracity on the dataset released at SemEval 2019 RumorEval <ref type="bibr" coords="3,255.85,445.70,16.25,10.91" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed approaches methodology</head><p>This section describes the proposed approaches for Tasks A and B of Checkthat! lab CLEF2021. As described in the previous section, the training data for both subtasks contains two text data fields, title and body news. To obtain the best results and avoid overfitting, we reserved 20% of the training data split in a stratified way as a development set. Table <ref type="table" coords="3,428.14,544.97,5.08,10.91" target="#tab_1">2</ref> summarizes the hyperparameters tuned for both tasks using their respective development set. It is essential to highlight that for each subtask using only titles, only body texts, or title and body texts as data input is explored.</p><p>Two remarkable hyperparameters for transformer-based model approaches are the sliding window and oversampling. As previously mentioned, transformers models typically have a restriction on the maximum length allowed for a sequence. A plausible strategy to overcome this limitation is to use the sliding window approach introduced by Zhang et al. <ref type="bibr" coords="3,440.57,639.81,16.09,10.91" target="#b27">[28]</ref>. Here, any sequence exceeding the maximum length is split into several windows (sub-sequences), and each one is assigned the label from the original sequence. We explored the use of this technique, and to minimize any information loss that hard cutoffs between two windows may cause, we applied 20% of overlapping between the sub-sequences. Finally, we explored to over-sample the unbalanced data so that all classes had the same frequency as the most abundant class using the RandomOversampler from imblearn<ref type="foot" coords="4,249.44,125.86,3.71,7.97" target="#foot_1">2</ref> package. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Task A</head><p>To carry out the Task A, two approaches are tested. The first one is based on the use of the classical Doc2Vec algorithm <ref type="bibr" coords="4,212.86,502.75,12.69,10.91" target="#b5">[6]</ref> as document feature extractor combined with Machine Learning (ML) classifiers. The second approach takes advantage of different state-of-the-art transformerbased models <ref type="bibr" coords="4,153.28,529.84,16.55,10.91" target="#b19">[20,</ref><ref type="bibr" coords="4,172.86,529.84,14.11,10.91" target="#b20">21]</ref> to extract dense embeddings with a linear layer on top to classify the documents into four categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Doc2Vec approach</head><p>Doc2Vec represents documents into dense vectors named document or paragraph embeddings. This algorithm extends the idea of Word2Vec <ref type="bibr" coords="4,292.30,606.27,16.42,10.91" target="#b28">[29,</ref><ref type="bibr" coords="4,311.47,606.27,12.32,10.91" target="#b29">30]</ref>, adding a new paragraph representation that is trained along word embeddings to develop document-level embeddings so that documents of differing lengths can be represented by fixed-length vectors <ref type="bibr" coords="4,356.46,633.37,11.28,10.91" target="#b5">[6]</ref>. These dense document vectors can be obtained by concatenating the paragraph vector with the word vectors to predict a target word, or predicting sample words from the paragraph using the paragraph vector. These two implementations of Doc2Vec are named PD-DM and PD-DBOW, respectively. The Doc2Vec models are obtained from Gensim library <ref type="bibr" coords="5,274.81,114.06,16.22,10.91" target="#b30">[31]</ref>. We explore the use of PD-DM, PD-DBOW, and the combination of both models as feature extractors for this classification task. The classifiers tested were Naive Bayes (NB), Random Forest (RF), Logistic Regression with L1 and L2 regularization (LR1 and LR2, respectively), Elastic Net, and Support Vector Classifier (SVC).</p><p>The data processing for this approach consists of different steps. The ftfy package <ref type="bibr" coords="5,487.91,181.81,18.07,10.91" target="#b31">[32]</ref> is used to repair Unicode and emoji errors, and the ekphrasis package <ref type="bibr" coords="5,408.97,195.36,18.07,10.91" target="#b32">[33]</ref> for lower-casing, normalizing percentages, time, dates, emails, phones and numbers. Abbreviations are expanded using contractions package<ref type="foot" coords="5,208.18,220.70,3.71,7.97" target="#foot_2">3</ref> and word tokenization, stop-word removal, punctuation removal, and word lemmatization is carried out using the NLTK toolkit <ref type="bibr" coords="5,367.79,236.01,16.25,10.91" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Transformers approach</head><p>In this approach, we use different transformer-based models to classify the Task A news. The models tested were T5 small and T5 base <ref type="bibr" coords="5,304.11,298.89,11.58,10.91" target="#b6">[7]</ref>, Longformer base <ref type="bibr" coords="5,404.34,298.89,11.58,10.91" target="#b5">[6]</ref>, RoBERTa base <ref type="bibr" coords="5,492.98,298.89,13.00,10.91" target="#b7">[8]</ref> and DistilRoBERTa base <ref type="bibr" coords="5,201.40,312.43,11.49,10.91" target="#b7">[8,</ref><ref type="bibr" coords="5,215.64,312.43,12.42,10.91" target="#b34">35]</ref>. The data processing procedure for this approach consists of repairing Unicode and emoji errors with ftfy package <ref type="bibr" coords="5,326.80,325.98,17.81,10.91" target="#b31">[32]</ref> and normalizing emails, phones and URLs with ekphrasis package <ref type="bibr" coords="5,221.31,339.53,16.25,10.91" target="#b32">[33]</ref>.</p><p>Finally, the model with the best performance on the development set is selected to boost its performance by incorporating more data from related tasks: Kaggle's KDD2020 <ref type="foot" coords="5,440.32,364.88,3.71,7.97" target="#foot_3">4</ref> and Clickbait news detection<ref type="foot" coords="5,158.08,378.43,3.71,7.97" target="#foot_4">5</ref> competitions. KDD2020 competition consists of distinguishing fake claims from authentic ones. On the other hand, Clickbait detection is focused on classifying articles into news, clickbait, and other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Task B</head><p>The proposed approach for Task B is based on transformer-based models. The models tested were: Electra base <ref type="bibr" coords="5,174.20,470.55,11.58,10.91" target="#b8">[9]</ref>, T5 base <ref type="bibr" coords="5,229.73,470.55,11.58,10.91" target="#b6">[7]</ref>, RoBERTa base <ref type="bibr" coords="5,316.05,470.55,12.99,10.91" target="#b7">[8]</ref> and DistilRoBERTa base <ref type="bibr" coords="5,444.07,470.55,11.48,10.91" target="#b7">[8,</ref><ref type="bibr" coords="5,458.34,470.55,12.42,10.91" target="#b34">35]</ref>. As for the transformer-based model approach for Task A, the data processing procedure consists of repairing Unicode and emoji errors with ftfy package <ref type="bibr" coords="5,326.80,497.65,17.81,10.91" target="#b31">[32]</ref> and normalizing emails, phones and URLs with ekphrasis package <ref type="bibr" coords="5,221.31,511.20,16.25,10.91" target="#b32">[33]</ref>.</p><p>In addition, multi-task training was explored in the case of the T5 base model. The model was trained on Task B and Kaggle's Ag News task <ref type="foot" coords="5,293.88,536.55,3.71,7.97" target="#foot_5">6</ref> . Ag News is a topic classification competition with 120k news grouped into 4 categories: World, Sports, Business, and Sci-Tech. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Task A</head><p>Table <ref type="table" coords="6,115.38,456.58,4.99,10.91" target="#tab_2">3</ref> reports the performance of Doc2Vec models evaluated in the development set. The best macro F1-score (29.23%) is achieved using the title field as input data and combining features from PV-DM and PV-DBOW models with Logistic Regression classifier with L2 regularization. Remarkably, this same approach worsens when the input data includes the body text field: 24.96% F1-score only with body text and 25.93% F1-score with title and body texts.</p><p>Regarding the transformer-based model approach, Table <ref type="table" coords="6,360.24,524.32,5.17,10.91" target="#tab_3">4</ref> details the performance of the models, the training data, the type of data input, and if oversampling and sliding window techniques are used during training.</p><p>As expected, our experiments show that state-of-the-art transformer-based models outperform the classical Doc2Vec algorithms. The best performance, 50.96% macro-averaged F1-score, is achieved with DistilRoBERTa base, a distilled version of RoBERTa base, using the body field from Checkthat! data as data input with oversampling and sliding window for dealing with long texts. The hyperparameters selected for this model were polynomial decay scheduler with warmup, one step for gradient accumulation, 0.04731 as weight decay, and learning rate equals to 9.468e-5. Significantly, the performance of the model obtained using the same hyperparameters without oversampling and without sliding window was 39.61% macro-averaged  All the models get the best performance applying oversampling. Unlike Task A, the sliding window technique does not seem crucial for the topic classification. The reason could be due in part to the different complexity of the tasks. The classification of news articles according to the veracity of their information requires a high level of text comprehension. On the other hand, the topic analysis may not require such a high level of comprehension, and using the sliding window technique could be not as important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Task B</head><p>Turning now to the T5 base model multi-task training, we can note from Table <ref type="table" coords="7,452.32,448.44,5.06,10.91" target="#tab_4">5</ref> that multitask training on Ag News and Checkthat! lab Task B reduces the performance from 82.49% to 33.87% of the T5 base model on Task B compared with the T5 base model exclusively fine-tuned for Task B.</p><p>Finally, the best macro-average F1-score (91.22%) is obtained by RoBERTa base model trained using the title and body text fields from Checkthat! lab Task B data with oversampling and without sliding window. The hyperparameters used for training this model were constant schedule with warmup, one step for gradient accumulation, one as weight decay, and the learning rate equals 5.583e-5. This model was submitted to the competition, and the official test result is shown in Table <ref type="table" coords="7,197.93,570.38,3.74,10.91" target="#tab_5">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we have proposed a NLP approach for misinformation detection Task A and topic classification Task B from the CLEF2021 Checkthat! lab Task 3 <ref type="bibr" coords="7,406.77,642.48,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="7,421.46,642.48,12.42,10.91" target="#b14">15]</ref>. Our work has led us to conclude that transformer-based models fine-tuned explicitly for the tasks have achieved the best performance. In Task A, the results indicate that the transformer-based models </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,279.68,165.91"><head>Table 1</head><label>1</label><figDesc>Checkthat! lab-CLEF2021 Task 3 breakdown according to its classes.</figDesc><table coords="3,228.83,122.05,135.12,134.34"><row><cell></cell><cell>Class</cell><cell>Count</cell></row><row><cell></cell><cell>false</cell><cell>465</cell></row><row><cell>Task A</cell><cell>partially false true</cell><cell>217 142</cell></row><row><cell></cell><cell>other</cell><cell>76</cell></row><row><cell></cell><cell>health</cell><cell>127</cell></row><row><cell></cell><cell>climate</cell><cell>49</cell></row><row><cell>Task B</cell><cell>economy crime</cell><cell>43 39</cell></row><row><cell></cell><cell>elections</cell><cell>32</cell></row><row><cell></cell><cell>education</cell><cell>28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,156.62,418.53,278.65"><head>Table 2</head><label>2</label><figDesc>Hyperparameters optimized during the development of the proposed approaches. C is the inverse of regularization strength, logspace is the logarithmic sequence (start base, end base, number of elements).</figDesc><table coords="4,93.77,198.75,405.88,236.52"><row><cell>Optimization</cell><cell>Method</cell><cell>Hyperparameters</cell><cell>Values</cell></row><row><cell></cell><cell></cell><cell>learning rate</cell><cell>min = 1e-6 , max = 1e-3</cell></row><row><cell></cell><cell></cell><cell>epochs</cell><cell>min = 1, max = 20</cell></row><row><cell></cell><cell></cell><cell>weight decay</cell><cell>min = 0 , max = 1</cell></row><row><cell></cell><cell></cell><cell cols="2">gradient accumulation steps min = 1 , max = 4</cell></row><row><cell cols="2">Transformer-based model Grid and Bayesian Search</cell><cell></cell><cell>constant_schedule_with_warmup</cell></row><row><cell></cell><cell></cell><cell>scheduler</cell><cell>cosine_schedule_with_warmup</cell></row><row><cell></cell><cell></cell><cell></cell><cell>polynomial_decay_schedule_with_warmup</cell></row><row><cell></cell><cell></cell><cell>sliding window</cell><cell>True, False</cell></row><row><cell></cell><cell></cell><cell>over-sampling</cell><cell>True, False</cell></row><row><cell></cell><cell></cell><cell>dimensions</cell><cell>[50, 75, 100]</cell></row><row><cell>Doc2Vec</cell><cell>Grid Search</cell><cell>window size</cell><cell>[15, 20, 30]</cell></row><row><cell></cell><cell></cell><cell>min count</cell><cell>[2, 5]</cell></row><row><cell></cell><cell></cell><cell>n_estimators</cell><cell>[5, 10, 15, 30]</cell></row><row><cell></cell><cell></cell><cell>max_depth</cell><cell>[3, 5, 10, 15, 20]</cell></row><row><cell>RF</cell><cell>Grid search with CV = 5</cell><cell>min_samples_split min_samples_leaf</cell><cell>[2, 5, 10] [1, 2, 4]</cell></row><row><cell></cell><cell></cell><cell>max_features</cell><cell>[2, 3, "auto"]</cell></row><row><cell></cell><cell></cell><cell>min_samples_split</cell><cell>[8, 10, 12]</cell></row><row><cell>LR1</cell><cell>Grid search with CV = 5</cell><cell>C</cell><cell>logspace(-3, 2, 8)</cell></row><row><cell>LR2</cell><cell>Grid search with CV = 5</cell><cell>C</cell><cell>logspace(-3, 2, 8)</cell></row><row><cell>Elastic Net</cell><cell>Grid search with CV = 5</cell><cell>C L1_ratio</cell><cell>logspace(-3, 2, 8) [0 , 0.33333333, 0.66666667, 1 ]</cell></row><row><cell></cell><cell></cell><cell>C</cell><cell>numpy logspace(-3, 2, 10)</cell></row><row><cell>SVC</cell><cell>Grid search with CV = 5</cell><cell>Kernel</cell><cell>polynomial, RBF, linear</cell></row><row><cell></cell><cell></cell><cell>Gamma</cell><cell>logspace(-3, 3, 10)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,416.99,141.60"><head>Table 3</head><label>3</label><figDesc>Performance of Doc2Vec models in Checkthat! lab CLEF2021 development set. Performance is reported as macro-averaged F1-score×100.</figDesc><table coords="6,173.39,134.06,248.49,98.03"><row><cell>Model</cell><cell>Data input</cell><cell cols="2">Classifier F1-score</cell></row><row><cell>PV-DM</cell><cell>Title</cell><cell>RF</cell><cell>25.81</cell></row><row><cell>PV-DBOW</cell><cell>Title</cell><cell>LR2</cell><cell>23.67</cell></row><row><cell>PV-DM</cell><cell>Body</cell><cell>LR2</cell><cell>22.74</cell></row><row><cell>PV-DBOW</cell><cell>Body</cell><cell>NB</cell><cell>27.72</cell></row><row><cell>PV-DM &amp; PV-DBOW</cell><cell>Title</cell><cell>LR2</cell><cell>29.23</cell></row><row><cell>PV-DM &amp; PV-DBOW</cell><cell>Body</cell><cell>NB</cell><cell>24.96</cell></row><row><cell cols="2">PV-DM &amp; PV-DBOW Title &amp; Body</cell><cell>LR2</cell><cell>25.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.99,254.35,418.66,130.66"><head>Table 4</head><label>4</label><figDesc>Performance of Transformer-based models in Checkthat! lab CLEF2021 Task A development set. Performance is reported as macro-averaged F1-score×100.</figDesc><table coords="6,94.64,297.31,403.79,87.70"><row><cell>Model</cell><cell>Train data</cell><cell>Data input</cell><cell cols="3">Oversampling Sliding window F1-score</cell></row><row><cell>T5 small</cell><cell>Checkthat!</cell><cell>Title</cell><cell>True</cell><cell>False</cell><cell>34.52</cell></row><row><cell>T5 base</cell><cell>Checkthat!</cell><cell>Title &amp; Body</cell><cell>False</cell><cell>True</cell><cell>37.11</cell></row><row><cell>Longformer base</cell><cell>Checkthat!</cell><cell>Body</cell><cell>False</cell><cell>True</cell><cell>45.59</cell></row><row><cell>RoBERTa base</cell><cell>Checkthat!</cell><cell>Body</cell><cell>True</cell><cell>True</cell><cell>48.62</cell></row><row><cell>DistilRoBERTa base</cell><cell>Checkthat!</cell><cell>Body</cell><cell>True</cell><cell>True</cell><cell>50.96</cell></row><row><cell>DistilRoBERTa base</cell><cell>Checkthat! &amp; KD2020</cell><cell>Body</cell><cell>True</cell><cell>True</cell><cell>42.17</cell></row><row><cell>DistilRoBERTa base</cell><cell>Checkthat! &amp; Clickbait</cell><cell>Title</cell><cell>True</cell><cell>True</cell><cell>35.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.99,90.49,418.66,210.82"><head>Table 5</head><label>5</label><figDesc>Performance of transformer-based models in Checkthat! lab CLEF2021 Task B development set. Performance is reported as macro-averaged F1-score×100. Remarkably, the introduction of new related data from KDD2020 and Clickbait news detection competitions did not improve the performance on Checkthat! lab Task A. Moroever, the Clickbait task has a more noticeable impact on performance, suggesting that less related tasks have more impact on performance.The official test results for the best model on the development set, DistilRoBERTa base, are shown in</figDesc><table coords="7,89.29,133.24,409.44,100.32"><row><cell>Model</cell><cell>Train Data</cell><cell>Data Input</cell><cell cols="3">Oversampling Sliding Window F1-score</cell></row><row><cell>Electra base</cell><cell>Checkthat!</cell><cell>Body</cell><cell>True</cell><cell>True</cell><cell>87.08</cell></row><row><cell>T5 base</cell><cell>Checkthat!</cell><cell>Title and Body</cell><cell>True</cell><cell>False</cell><cell>82.49</cell></row><row><cell cols="2">T5 base multitasking Checkthat! and Ag News</cell><cell>Title</cell><cell>True</cell><cell>False</cell><cell>33.87</cell></row><row><cell>DistilRoBERTa base</cell><cell>Checkthat!</cell><cell>Body</cell><cell>True</cell><cell>False</cell><cell>88.82</cell></row><row><cell>RoBERTa base</cell><cell>Checkthat!</cell><cell>Title and Body</cell><cell>True</cell><cell>False</cell><cell>91.22</cell></row><row><cell>F1-score.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,133.22,290.40,34.30,10.91"><head>Table 6 .</head><label>6</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,88.96,340.05,417.02,24.46"><head>Table 5</head><label>5</label><figDesc>compares the performance of the different transformer-based models evaluated on Checkthat! Task B development set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,88.89,90.49,418.29,186.97"><head>Table 6</head><label>6</label><figDesc>Official results of the subtasks from CLEF2021 Checkthat! lab Task 3. Performance is reported as macro-averaged F1-score×100. Doc2Vec model. Oversampling proves to be a valuable technique to deal with unbalanced data in both tasks. However, the sliding window technique to overcome the maximum length transformers' limitation shows different effects in Task A and Task B. Finally, we achieved a macro-average F1-score of 41.43% in Task A and 67.65% in Task B. In future work, we will most likely test new architectures, such as Hierarchical Attention Networks, and add more related data to boost the transformer-based model performance.</figDesc><table coords="8,89.29,134.06,315.65,75.66"><row><cell>Model</cell><cell cols="3">Task Training Data F1-score</cell></row><row><cell>DistilRoBERTa base</cell><cell>A</cell><cell>Checkthat!</cell><cell>41.43</cell></row><row><cell>RoBERTa base</cell><cell>B</cell><cell>Checkthat!</cell><cell>67.65</cell></row><row><cell>outperform the classical</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.03,93.86,8.97"><p>https://www.poynter.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,108.93,671.03,208.91,8.97"><p>https://github.com/scikit-learn-contrib/imbalanced-learn</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,108.93,638.02,153.23,8.97"><p>https://github.com/kootenpv/contractions</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,108.93,648.98,200.90,8.97"><p>https://www.kaggle.com/c/fakenewskdd2020/overview</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,108.93,659.94,190.17,8.97"><p>https://www.kaggle.com/c/clickbait-news-detection</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,108.93,670.90,259.35,8.97"><p>https://www.kaggle.com/amananandrai/ag-news-classification-dataset</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the following grants and funding agencies: <rs type="funder">Spanish Ministry of Science and Innovation</rs> under <rs type="grantNumber">TIN2017-85727-C4-3-P</rs> (<rs type="projectName">DeepBio</rs>) grant, by <rs type="funder">Comunidad Autónoma de Madrid</rs> under <rs type="grantNumber">S2018/TCS-4566</rs> grant (<rs type="projectName">CYNAMON</rs>), and by <rs type="funder">BBVA FOUNDATION GRANTS FOR SCIENTIFIC RESEARCH</rs> <rs type="grantNumber">TEAMS SARS-CoV-2</rs> and <rs type="grantNumber">COVID-19</rs> under the grant: "<rs type="projectName">CIVIC</rs>: Intelligent characterisation of the <rs type="projectName">veracity of the information related to COVID-19</rs>". Relevant parts of this research is a result of the project <rs type="projectName">IBERIFIER -Iberian Digital Media Research and Fact-Checking Hub</rs>, funded by the <rs type="funder">European Commission</rs> under the call <rs type="grantNumber">CEF-TC-2020-2</rs> (<rs type="projectName">European Digital Media Observatory</rs>), grant number <rs type="grantNumber">2020-EU-IA-0252</rs>. Finally, the work has been supported by the <rs type="funder">Comunidad Autónoma de Madrid</rs> under <rs type="funder">Convenio Plurianual</rs> with the <rs type="funder">Universidad Politécnica de Madrid</rs> in the actuation line of "<rs type="funder">Programa de Excelencia para el Profesorado Universitario</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_gaQCY9D">
					<idno type="grant-number">TIN2017-85727-C4-3-P</idno>
					<orgName type="project" subtype="full">DeepBio</orgName>
				</org>
				<org type="funded-project" xml:id="_8cCurTf">
					<idno type="grant-number">S2018/TCS-4566</idno>
					<orgName type="project" subtype="full">CYNAMON</orgName>
				</org>
				<org type="funding" xml:id="_jRCwPxj">
					<idno type="grant-number">TEAMS SARS-CoV-2</idno>
				</org>
				<org type="funded-project" xml:id="_xuasrQb">
					<idno type="grant-number">COVID-19</idno>
					<orgName type="project" subtype="full">CIVIC</orgName>
				</org>
				<org type="funded-project" xml:id="_hDxaXv6">
					<orgName type="project" subtype="full">veracity of the information related to COVID-19</orgName>
				</org>
				<org type="funded-project" xml:id="_eYv2rvg">
					<idno type="grant-number">CEF-TC-2020-2</idno>
					<orgName type="project" subtype="full">IBERIFIER -Iberian Digital Media Research and Fact-Checking Hub</orgName>
				</org>
				<org type="funded-project" xml:id="_vgnbWe9">
					<idno type="grant-number">2020-EU-IA-0252</idno>
					<orgName type="project" subtype="full">European Digital Media Observatory</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,519.29,394.53,10.91;8,112.66,532.84,380.55,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,211.17,519.29,291.77,10.91">The Covid-19 &apos;infodemic&apos;: a new front for information professionals</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">B</forename><surname>Naeem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bhatti</surname></persName>
		</author>
		<idno type="DOI">10.1111/hir.12311</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,112.66,532.84,174.05,10.91">Health Information &amp; Libraries Journal</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="233" to="239" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,546.39,394.53,10.91;8,112.66,559.94,393.33,10.91;8,112.33,573.49,234.75,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,231.42,559.94,173.03,10.91">The COVID-19 social media infodemic</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cinelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Quattrociocchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Galeazzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Valensise</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brugnoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Zollo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Scala</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-73510-5</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,413.40,559.94,79.45,10.91">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">16598</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,587.04,395.17,10.91;8,112.66,600.59,393.60,10.91;8,112.66,614.14,397.48,10.91;8,112.36,630.13,26.14,7.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,398.93,587.04,108.90,10.91;8,112.66,600.59,393.60,10.91;8,112.66,614.14,68.17,10.91">Disinformation y misinformation, posverdad y fake news: precisiones conceptuales, diferencias, similitudes y yuxtaposiciones</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Estrada-Cuzcano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Alfaro-Mendives</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Saavedra-Vásquez</surname></persName>
		</author>
		<idno type="DOI">10.34096/ics.i42.7427</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,188.84,614.14,137.54,10.91">Información, cultura y sociedad</title>
		<imprint>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,641.24,394.53,10.91;8,112.66,654.78,393.33,10.91;8,112.66,668.33,393.33,10.91;9,112.66,86.97,393.33,10.91;9,112.66,100.52,394.03,10.91;9,112.41,114.06,136.90,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,488.80,654.78,17.19,10.91;8,112.66,668.33,393.33,10.91;9,112.66,86.97,94.69,10.91">The CLEF-2021 CheckThat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-72240-1_75</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-72240-1_75" />
	</analytic>
	<monogr>
		<title level="m" coord="9,231.02,86.97,274.97,10.91;9,112.66,100.52,80.27,10.91">Proceedings of the 43rd European Conference on Information Retrieval, ECIR &apos;21</title>
		<meeting>the 43rd European Conference on Information Retrieval, ECIR &apos;21<address><addrLine>Lucca, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="639" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,127.61,393.33,10.91;9,112.66,141.16,393.33,10.91;9,112.66,154.71,293.98,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,274.26,127.61,231.73,10.91;9,112.66,141.16,103.38,10.91">Overview of the CLEF-2021 CheckThat! lab task 3 on fake news detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,240.60,141.16,265.39,10.91;9,112.66,154.71,133.32,10.91">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF &apos;2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,168.26,395.01,10.91;9,112.66,184.25,91.42,7.90" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4053</idno>
		<title level="m" coord="9,214.74,168.26,259.87,10.91">Distributed representations of sentences and documents</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,394.53,10.91;9,112.66,208.91,395.01,10.91;9,112.66,224.90,97.35,7.90" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<title level="m" coord="9,112.66,208.91,363.43,10.91">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,236.01,395.17,10.91;9,112.66,249.56,395.01,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="9,137.85,249.56,241.29,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.33,10.91;9,112.66,276.66,295.16,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m" coord="9,334.34,263.11,171.65,10.91;9,112.66,276.66,165.13,10.91">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,393.32,10.91;9,112.66,303.75,393.33,10.91;9,112.66,317.30,60.01,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,302.78,290.20,203.20,10.91;9,112.66,303.75,312.53,10.91">exbake: Automatic fake news detection model based on bidirectional encoder representations from transformers (bert)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,432.87,303.75,73.11,10.91">Applied sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">4062</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,393.33,10.91;9,112.26,344.40,394.38,10.91;9,112.41,357.95,59.11,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,293.07,330.85,212.92,10.91;9,112.26,344.40,186.74,10.91">Fakebert: Fake news detection in social media with a bert-based deep learning approach</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Kaliyar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Narang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,308.48,344.40,154.71,10.91">Multimedia tools and applications</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="11765" to="11788" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,371.50,395.16,10.91;9,112.66,385.05,393.33,10.91;9,112.66,398.60,390.70,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,337.18,371.50,170.65,10.91;9,112.66,385.05,206.69,10.91">Co-spread of misinformation and factchecking content during the covid-19 pandemic</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Burel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mensio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
		<ptr target="http://oro.open.ac.uk/71786/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,342.69,385.05,163.30,10.91;9,112.66,398.60,204.28,10.91">Proceedings of the 12th International Social Informatics Conference (SocInfo), LNCS</title>
		<meeting>the 12th International Social Informatics Conference (SocInfo), LNCS</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,412.15,394.53,10.91;9,112.66,425.70,393.33,10.91;9,112.39,439.25,393.59,10.91;9,112.66,452.79,393.32,10.91;9,112.66,466.34,164.71,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,180.49,425.70,325.50,10.91;9,112.39,439.25,94.95,10.91">Overview of the clef-2019 checkthat! lab: Automatic identification and verification of claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,235.68,439.25,270.30,10.91;9,112.66,452.79,48.06,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<title level="s" coord="9,247.30,453.81,149.32,9.72">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11696</biblScope>
			<biblScope unit="page" from="301" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,479.89,394.53,10.91;9,112.66,493.44,393.64,10.91;9,112.66,506.99,393.32,10.91;9,112.66,520.54,393.53,10.91;9,112.66,534.09,304.81,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,404.24,493.44,102.05,10.91;9,112.66,506.99,311.48,10.91">Overview of checkthat! 2020: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,447.35,506.99,58.64,10.91;9,112.66,520.54,258.47,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<title level="s" coord="9,379.55,520.54,126.64,10.91;9,112.66,534.09,31.10,10.91">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="215" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,547.64,394.53,10.91;9,112.66,561.19,394.53,10.91;9,112.66,574.74,393.33,10.91;9,112.66,588.29,393.33,10.91;9,112.66,601.84,393.33,10.91;9,112.66,615.39,393.32,10.91;9,112.33,628.93,62.17,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,254.58,574.74,251.41,10.91;9,112.66,588.29,307.18,10.91">Overview of the CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,442.14,588.29,63.85,10.91;9,112.66,601.84,393.33,10.91;9,112.66,615.39,296.76,10.91">Proceedings of the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021</title>
		<meeting>the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021<address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,642.48,393.33,10.91;9,112.66,656.03,393.33,10.91;9,112.66,669.58,387.87,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,220.22,642.48,285.77,10.91;9,112.66,656.03,49.79,10.91">FakeCovid -a multilingual cross-domain fact check news dataset for covid-19</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nandini</surname></persName>
		</author>
		<ptr target="http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="9,183.76,656.03,322.22,10.91;9,112.66,669.58,73.20,10.91">Workshop Proceedings of the 14th International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.66,100.52,283.01,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,292.17,86.97,213.82,10.91;10,112.66,100.52,42.26,10.91">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Majchrzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,162.86,100.52,154.86,10.91">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,114.06,393.61,10.91;10,112.66,127.61,225.88,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<title level="m" coord="10,167.30,114.06,338.97,10.91;10,112.66,127.61,121.38,10.91">A multilingual domain identification using fact-checked articles: A case study on covid-19 misinformation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,141.16,393.59,10.91;10,112.66,154.71,146.44,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00502</idno>
		<title level="m" coord="10,168.48,141.16,305.06,10.91">Amused: An annotation framework of multi-modal social media data</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,168.26,395.17,10.91;10,112.66,181.81,273.50,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m" coord="10,148.16,181.81,107.76,10.91">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,195.36,393.33,10.91;10,112.66,208.91,363.59,10.91" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="10,353.43,195.36,152.55,10.91;10,112.66,208.91,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,112.66,222.46,393.32,10.91;10,112.66,236.01,393.33,10.91;10,112.66,249.56,165.49,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,302.78,222.46,203.20,10.91;10,112.66,236.01,311.74,10.91">exbake: Automatic fake news detection model based on bidirectional encoder representations from transformers (bert)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.3390/app9194062</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,432.03,236.01,73.96,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,263.11,393.33,10.91;10,112.66,276.66,346.17,10.91" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">P</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03264</idno>
		<title level="m" coord="10,347.48,263.11,158.51,10.91;10,112.66,276.66,216.53,10.91">A simple but tough-to-beat baseline for the fake news challenge stance detection task</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,290.20,395.17,10.91;10,112.66,303.75,395.17,10.91;10,112.66,317.30,395.01,10.91;10,112.66,330.85,214.79,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="10,317.95,290.20,189.89,10.91;10,112.66,303.75,64.34,10.91">Detection of counterfeit news using machine learning</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Anjali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Reshma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">Geetha</forename><surname>Lekshmy</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICICICT46008.2019.8993330</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,206.64,303.75,301.19,10.91;10,112.66,317.30,237.39,10.91">2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1382" to="1386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,344.40,395.01,10.91;10,112.66,360.39,97.35,7.90" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m" coord="10,270.90,344.40,205.60,10.91">Longformer: The long-document transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,371.50,393.61,10.91;10,112.33,385.05,29.19,10.91" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
		<title level="m" coord="10,187.30,371.50,318.96,10.91">Fine-tune longformer for jointly predicting rumor stance and veracity</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,398.60,393.33,10.91;10,112.66,412.15,395.00,10.91" xml:id="b26">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06683</idno>
		<title level="m" coord="10,452.58,398.60,53.41,10.91;10,112.66,412.15,264.85,10.91">Rumoureval 2019: Determining rumour veracity and support for rumours</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,425.70,393.33,10.91;10,112.66,439.25,343.71,10.91" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08167</idno>
		<title level="m" coord="10,317.53,425.70,188.45,10.91;10,112.66,439.25,213.33,10.91">Multi-passage bert: A globally normalized bert model for open-domain question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,452.79,393.33,10.91;10,112.66,466.34,295.17,10.91" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.4546</idno>
		<title level="m" coord="10,346.41,452.79,159.58,10.91;10,112.66,466.34,171.09,10.91">Distributed representations of words and phrases and their compositionality</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,479.89,393.32,10.91;10,112.39,493.44,176.99,10.91" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="10,297.98,479.89,208.00,10.91;10,112.39,493.44,52.97,10.91">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,506.99,394.61,10.91;10,112.66,520.54,394.53,10.91;10,112.30,534.09,140.09,10.91" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="10,209.74,506.99,276.93,10.91">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,112.66,520.54,358.88,10.91">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,547.64,328.45,10.91" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="10,153.59,547.64,14.07,10.91">ftfy</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.2591652</idno>
		<idno>5.5</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,173.90,547.64,31.08,10.91">Zenodo</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,561.19,393.33,10.91;10,112.26,574.74,393.73,10.91;10,112.66,588.29,393.53,10.91;10,112.66,601.84,294.21,10.91" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="10,293.99,561.19,212.00,10.91;10,112.26,574.74,304.14,10.91">Datastories at semeval-2017 task 4: Deep lstm with attention for message-level and topic-based sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Baziotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pelekis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Doulkeridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,439.44,574.74,66.55,10.91;10,112.66,588.29,319.32,10.91">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="747" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,615.39,393.33,10.91;10,112.14,628.93,393.85,10.91;10,112.66,642.48,393.33,10.91;10,112.66,656.03,397.48,10.91;10,112.66,672.02,121.09,7.90" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="10,196.89,615.39,157.73,10.91">Nltk: The natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<idno type="DOI">10.3115/1118108.1118117</idno>
		<ptr target="https://doi.org/10.3115/1118108.1118117.doi:10.3115/1118108.1118117" />
	</analytic>
	<monogr>
		<title level="m" coord="10,382.14,615.39,123.85,10.91;10,112.14,628.93,393.85,10.91;10,112.66,642.48,141.53,10.91;10,303.17,642.48,61.04,10.91">Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</title>
		<meeting>the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
	<note>ETMTNLP &apos;02</note>
</biblStruct>

<biblStruct coords="11,112.66,86.97,394.53,10.91;11,112.66,100.52,394.53,10.91;11,112.66,114.06,393.33,10.91;11,112.66,127.61,253.34,10.91" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="11,309.90,114.06,196.09,10.91;11,112.66,127.61,123.30,10.91">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
