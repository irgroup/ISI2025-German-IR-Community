<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,397.21,15.42;1,89.29,106.66,107.34,15.42">GPLSI team at CheckThat! 2021: Fine-tuning BETO and RoBERTa</title>
				<funder ref="#_bt62bcT">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_mVDDHKr">
					<orgName type="full">Generalitat Valenciana</orgName>
				</funder>
				<funder ref="#_nBSG2EF #_Weymec8">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,121.03,11.96"><forename type="first">Robiert</forename><surname>Sepúlveda-Torres</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Apdo. de Correos 99</addrLine>
									<postCode>E-03080</postCode>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.44,134.97,70.14,11.96"><forename type="first">Estela</forename><surname>Saquete</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Apdo. de Correos 99</addrLine>
									<postCode>E-03080</postCode>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,397.21,15.42;1,89.29,106.66,107.34,15.42">GPLSI team at CheckThat! 2021: Fine-tuning BETO and RoBERTa</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">42B2C683205136EE09AB5ACDC735ABA6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Check-worthiness</term>
					<term>Transfer learning models</term>
					<term>Fake news detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>CheckThat! Lab is a challenging lab aimed at tackling the disinformation problem. The GPLSI team from the University of Alicante (Spain) has participated in two tasks of the CheckThat! Lab namely, Task 1 (Check-Worthiness Estimation) and Task 3 (Fake News Detection). We attained second and fifth place in the Spanish-version and English-version of Subtask 1A. Our systems use models based on transfer learning such as RoBERTa and BETO. The best results were achieved by fine-tuning these models. However, our results for Subtask 3A are low compared to the team that achieved the best result. We included some external features in the models for Subtask 1A and 3A, but we could not improve the results. In future work, we will experiment by incorporating other external features into the models with the aim of improving the results of the tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fake news has existed for a long time, but with the exponential rise in the consumption of news through digital media, disinformation has become one of the main problems in modern society <ref type="bibr" coords="1,89.29,417.64,11.28,10.91" target="#b0">[1]</ref>. More recently, the huge volume of news in digital media makes it impossible to evaluate its veracity manually in a reasonable time frame <ref type="bibr" coords="1,292.94,431.19,11.43,10.91" target="#b1">[2]</ref>. The scientific community is currently using artificial intelligence to address the problem by, for example, developing large-scale datasets with the aim of creating automated fact-checking systems <ref type="bibr" coords="1,349.84,458.29,11.43,10.91" target="#b2">[3]</ref>.</p><p>In this context, CheckThat! Lab emerges as part of the Cross-Language Evaluation Forum (CLEF). CheckThat! Lab's goal is to foster the development of technologies that allow the automatic verification of claims <ref type="bibr" coords="1,240.33,498.93,11.59,10.91" target="#b3">[4]</ref>. This article provides a comprehensive report on the participation of the GPLSI team in Subtask 1A (Check-worthiness of tweets) and 3A (Multi-class fake news detection of news articles) of CheckThat! Lab. <ref type="bibr" coords="1,343.39,526.03,12.80,10.91" target="#b3">[4]</ref> provides a detailed description of CheckThat! Lab. The subtasks are summarized below:</p><p>1. Subtask 1A consists of predicting whether a given tweet is worth fact-checking. Subtask 1A is offered in Arabic, Bulgarian, English, Turkish, and Spanish. The GPLSI team participates in the English and Spanish version of the subtask. Subtask 1A uses Mean Average Precision (MAP) as the official evaluation measure and we will report reciprocal rank, and P@k for k ∈ {1, 3, 5, 10, 20, 30} as well <ref type="bibr" coords="2,340.00,100.52,11.43,10.91" target="#b4">[5]</ref>. 2. Subtask 3A consists of detecting fake news as a four-class classification problem. Given the title and body text of a news article, it determines whether the main claim made in the article is true, partially true, false, or other <ref type="bibr" coords="2,323.94,142.52,11.40,10.91" target="#b5">[6]</ref>. Subtask 3A is offered only in English and uses the macro F1 measure. The categories are as follows:</p><p>• False -The main claim made in an article is untrue.</p><p>• Partially False -The main claim of an article is a mixture of true and false information.</p><p>The article contains partially true and partially false information, but cannot be considered 100% true. • True -This rating indicates that the primary elements of the main claim are demonstrably true. • Other-An article that cannot be categorised as true, false, or partially false due to lack of evidence about its claims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Automatic detection of misinformation and fake news is a complex task in which Artificial Intelligence (AI) and Natural Language Processing (NLP) play a key role. Due to the complexity of the task, different subtasks are being dealt with <ref type="bibr" coords="2,318.03,361.72,11.58,10.91" target="#b6">[7]</ref>, both in traditional media <ref type="bibr" coords="2,451.98,361.72,12.99,10.91" target="#b7">[8]</ref> or social media <ref type="bibr" coords="2,120.58,375.27,11.58,10.91" target="#b8">[9]</ref>. Within these subtasks, automatic fact checking is one of the most challenging problems, and related competitions are very important as new datasets are designed to create models. In 2018, the two main competitions were: i) CheckThat! Lab, the CLEF-2018 Fact checking Lab<ref type="foot" coords="2,147.01,414.16,3.71,7.97" target="#foot_0">1</ref> for the automatic identification and verification of claims in political debates <ref type="bibr" coords="2,485.67,415.92,17.60,10.91" target="#b9">[10]</ref>.</p><p>The dataset delivered by this competition was obtained from FactCheck.org and it annotates statements with true/half-true/false values <ref type="bibr" coords="2,284.12,443.02,16.51,10.91" target="#b10">[11]</ref>; and, ii) the Fact Extraction and VERification (FEVER) <ref type="foot" coords="2,128.86,454.81,3.71,7.97" target="#foot_1">2</ref> , which is a workshop on fact extraction and verification providing a dataset of 220K claims verified against Wikipedia <ref type="bibr" coords="2,239.28,470.12,36.76,10.91">[12] [13]</ref>. The statements in the corpus were annotated with supports/ refutes/ notEnoughInfo. CheckThat! Lab 2021 is the fourth edition of the lab and Task 3 on Fake News Detection is new for this edition. Task 1 on Check-Worthiness has been present in previous editions, but it is new in the Spanish, Turkish, and Bulgarian versions. The previous year (2020) the winning team in the English-version of this task was the Accenture team <ref type="bibr" coords="2,373.82,537.86,16.14,10.91" target="#b13">[14]</ref>. This team fine-tuned the RoBERTa model and reached a MAP score of 0.8064. The second team ranked was Alex, and this team concatenated the RoBERTa model with tweet metadata <ref type="bibr" coords="2,381.17,564.96,16.27,10.91" target="#b14">[15]</ref>, obtaining a MAP score of 0.8034.</p><p>There have been efforts similar to CheckThat! Lab's approach to tackling the problem of disinformation, such as <ref type="bibr" coords="2,195.65,605.61,16.43,10.91" target="#b15">[16,</ref><ref type="bibr" coords="2,214.81,605.61,12.32,10.91" target="#b16">17]</ref>, that have developed approaches for automated fact-checking.</p><p>In recent years, the use of Transfer Learning models has become popular to tackle the main tasks within Natural Language Processing (NLP). Some of the most successful models in this context are BERT and RoBERTa for the English language and BETO for the Spanish language <ref type="bibr" coords="3,89.29,100.52,16.55,10.91" target="#b17">[18,</ref><ref type="bibr" coords="3,108.56,100.52,12.59,10.91" target="#b18">19,</ref><ref type="bibr" coords="3,123.87,100.52,12.41,10.91" target="#b19">20]</ref>. For example, RoBERTa has been used to predict the stance relationship between the headline and body text of an article <ref type="bibr" coords="3,266.49,114.06,16.25,10.91" target="#b20">[21]</ref>.</p><p>Considering the literature, our participation in the CheckThat! Lab makes use of these Learning Transfer models to address subtasks 1A and 3A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Neural Models</head><p>The models used in this research are based on the BERT model. BERT is a multi-layer bidirectional Transformer encoder that is designed to pre-train from text without labels. This pre-training model has the advantage of fine-tuning capability via a single additional layer of output, a feature that facilitates the creation of state-of-the-art models in various NLP tasks <ref type="bibr" coords="3,487.56,240.44,16.08,10.91" target="#b17">[18]</ref>. For Subtask 1A and Subtask 3A in English, the RoBERTa model will be used and for Subtask 1A in Spanish, the BETO model will be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">English-version Subtask: RoBERTa model</head><p>RoBERTa (Robustly optimized BERT approach) is a pre-training model based on BERT <ref type="bibr" coords="3,487.15,317.26,16.41,10.91" target="#b18">[19]</ref>. RoBERTa includes the following modifications: eliminating the prediction of the next sentence; performing the training on a greater volume of data; enlarging the batch size; and, lengthening the input sequence. This implementation attains state-of-the-art results in General Language Understanding Evaluation (GLUE) and Reading Comprehension Dataset From Examinations (RACE). In this research, we use RoBERTa large model architecture with 24 self-attention layers, a hidden size of 1024 and 355M parameters <ref type="bibr" coords="3,283.24,398.56,16.25,10.91" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Spanish-version Subtask: BETO model</head><p>BETO also uses BERT's architecture but includes a series of optimizations similar to those performed in the RoBERTa model. The BETO model was pre-trained with Wikipedia texts and all OPUS Project sources <ref type="bibr" coords="3,204.17,475.38,18.06,10.91" target="#b21">[22]</ref> in the Spanish language. This model achieved better results in most of the tasks present in the GLUE benchmark than the multilingual models based on BERT. This model has 12 self-attention layers with a hidden size of 768 and a total of 110M parameters <ref type="bibr" coords="3,89.29,516.03,16.25,10.91" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Architecture modifications</head><p>Some researchers include additional features to blend them with the output of the last layer of the transfer learning models <ref type="bibr" coords="3,213.48,579.31,16.31,10.91" target="#b22">[23,</ref><ref type="bibr" coords="3,231.94,579.31,12.23,10.91" target="#b23">24]</ref>. This strategy could improve the prediction of models based on transfer learning. In the tasks where the GPLSI team participates, we have experimented by varying our model so as to bring it closer to the domain of each task. Figure <ref type="figure" coords="3,452.14,606.40,5.17,10.91" target="#fig_0">1</ref> shows the internal architecture of our classifier when we included external features.</p><p>In Subtask 1A, for both English and Spanish-language versions, we extract features related to the presence and quantity of numbers and dates in the tweets. The Stanza Python library is used to extract these features. Stanza library analyzes part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition parser <ref type="bibr" coords="4,388.17,303.30,16.25,10.91" target="#b24">[25]</ref>.</p><p>Another change that has been tested for both Subtask 1A is the inclusion of features from Linguistic Inquiry and Word Count (LIWC). LIWC is a resource for detecting meaning in a wide variety of experimental settings, including showing the focus of attention, emotionality, social relationships, thinking styles, and individual differences <ref type="bibr" coords="4,341.85,357.49,16.45,10.91" target="#b25">[26,</ref><ref type="bibr" coords="4,361.02,357.49,12.34,10.91" target="#b26">27]</ref>. The LIWC dictionaries have been translated into several languages, including Spanish, German, Italian and Portuguese. We used Spanish translated LIWC for the Spanish-version Subtask and the LIWC original version for the English-version Substask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>The objective of the experiments is to find the model and the hyperparameters that are the best possible fit for the tasks outlined.This section presents the experiments carried out based on the models described previously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Subtask 1A experiments</head><p>This subtask aims to determine whether a tweet should be checked or not; hence the input to each model is a tweet and, in the case of some experiments, the input also adds external features. The input tweet to the models is pre-processed and Emoji are extracted to decrease the out-of-vocabulary words in the models being used. The proposed six experiments for this subtask use techniques that are well recognized by the scientific community, and will be described next:</p><p>1. Our baseline system with RoBERTa or BETO model: This experiment makes a fine-tuning of the corresponding model over the corpus of the task in evaluation. In line with <ref type="bibr" coords="4,476.60,638.20,12.70,10.91" target="#b0">[1]</ref> the BETO baseline system and RoBERTa baseline system have the same hyperparameters, as follows: maximum sequence length of 125; batch size of 4; training rate of 1.5e-5; and training epochs of 3. 2. This experiment performs a Bayes search to optimize the hyperparameters. We used the Weights &amp; Biases library to automate hyperparameter tuning and explore the space of possible models. This library enables the visualization and comparison of the results of each model <ref type="bibr" coords="5,169.89,156.07,16.25,10.91" target="#b27">[28]</ref>. The search configuration is shown in table <ref type="table" coords="5,385.91,156.07,3.74,10.91" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Subtask 3A experiments</head><p>The first two experiments of the previous subtask are used in the same way for this subtask. Subtask 3A is conducted in English and therefore only the RoBERTa model can be used. In addition, as this task classifies news according to its veracity, the RoBERTa model processes both the title and the body text of the article, representing them as a sequence of concatenated words. A third experiment is added that tries to improve the results of the two previous experiments. This experiment splits the four-class classification into two binary classifications and one three-class classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Result and Discussion</head><p>The experiments were implemented using the Simple Transformer <ref type="foot" coords="5,394.03,580.69,3.71,7.97" target="#foot_2">3</ref> and PyTorch<ref type="foot" coords="5,461.08,580.69,3.71,7.97" target="#foot_3">4</ref> libraries.</p><p>The experiments are trained with the training set and their performance is evaluated with the development set provided by the organizers of CheckThat! Lab. In our experiments, the output of BETO and RoBERTa models passes through a series of layers to finish classifying the tweet or the news. The layers used, in order, are two Dropouts, and Linear. After the first Dropout layer, we used the Tanh activation function. The tweet classification is a binary classification so the output layer has a single neuron and binary cross-entropy is used as the loss function. However, the news is classified into four classes, so the output layer has 4 neurons and cross-entropy is used as the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Subtask 1A</head><p>The Spanish-version of Subtask 1A has a dataset of 2,495 tweets for training, 1,247 for development, and 1248 for testing. The English-version of Subtask 1A has a dataset of 822 tweets for training, 140 for development and 350 for testing. The BETO baseline system obtains good results in the macro F1 metric; however, the evaluation metric of this subtask is MAP and in this case, the results are quite close to the baseline provided by the organizers. Similarly to the behavior of the BETO baseline system, the RoBERTa baseline system achieves good results on the macro F1 metric. However, the MAP metric is 4 points lower than 0.8064, which was reached by the best competitor of CheckThat! Lab 2020.</p><p>Experiment 2 is the experiment with the best results in both languages. With the help of the Weights &amp; Biases library, a configuration has been found, although it cannot be guaranteed that it is the best one given that the search was not exhaustive. In the Spanish-version, the hyperparameter configurations are a maximum sequence length of 125, batch size of 8, training rate of 1e-5, dropout rate of 0.2, and, training performed for 2 epochs. For the English-version, the hyperparameter configurations are as follows: maximum sequence length of 125; batch size of 4; training rate of 1.5e-5; dropout rate of 0.2; training performed for 3 epochs. Table <ref type="table" coords="6,470.69,367.03,5.00,10.91" target="#tab_1">2</ref> shows the results. Experiment 3 indicates that the features obtained do not help to identify whether a tweet should be checked or not. Experiment 4 worsened the results for both languages. Experiments 5 and 6 also did not improve the results achieved by simply fine-tuning the basic model. In both cases, the two metrics descended in relation to experiment 2.</p><p>The GPLSI team reached second place in the Spanish-version of Subtask 1A to predict the test set. The difference in the MAP metric is less than one point with respect to the team that came first in this subtask. Table <ref type="table" coords="6,232.72,646.16,5.07,10.91">3</ref> shows the results.</p><p>In the English-version of Subtask 1A, the GPLSI team reached fifth place. In this case,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3</head><p>CheckThat! Spanish-version of Subtask 1A results</p><p>Team MAP MRR RP P@1 P@3 P@5 P@10 P@20 P@30 GPLSI 0.529 0.500 0.533 0.000 0.667 0.600 0.800 0.750 0.620 the difference between the first-place team and GPLSI was greater than that observed in the Spanish-version of the same subtask. Table <ref type="table" coords="7,283.63,181.84,5.07,10.91">4</ref> shows the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>CheckThat! English-version Subtask 1A result Team MAP MRR RP P@1 P@3 P@5 P@10 P@20 P@30 GPLSI 0.132 0.167 0.158 0.000 0.000 0.000 0.200 0.150 0.140</p><p>To sum up, the numerous experiments that were conducted failed to improve the results achieved by experiment 2, indicating the power of models based on transfer learning for this task. Evidently, we have not been able to find appropriate external features to tackle this subtask. The systems developed in experiment 2 are used to predict the test set for both languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Subtask 3A</head><p>The training dataset available for this subtask contains 900 news items <ref type="bibr" coords="7,397.69,370.67,16.09,10.91" target="#b28">[29]</ref>. In order to evaluate the models that were being fine-tuned, the training dataset was divided into a training set and a development set. The split proportion is of 0. Our baseline system uses the hyperparameters described in experiment 1 of the previous section by only changing the maximun sequence length to 512. Task 3A is considered more complicated than 1A because it is necessary to find patterns that classify the news into 4 classes. The macro F1 result of the baselines fine-tuning RoBERTa is quite low which corroborates the complexity of this subtask.</p><p>Experiment 2 carried out a deep hyperparameter tuning and, as the results show, the improvement is negligible. In another task, a hyperparameter tuning like this should have improved the baseline significantly. The last experiment is depicted in figure <ref type="figure" coords="7,276.73,656.03,3.66,10.91" target="#fig_2">2</ref>. The strategy involved placing the majority class in the first classifier and the minority classes in the subsequent classifiers. In the first classifier, we predict False and Remaining classes (Partially False, True, and Other). In the second classifier, we predict False, Partially False and Remaining classes (True and Other). Finally, the third classifier is True and Other. Each classifier specializes in predicting a group of classes and the remaining classes are passed to subsequent classifiers. The GPLSI team ranked 16th in this subtask. In this subtask, we failed to find a competitive model that could obtain state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We participated in two tasks of the three CheckThat! tasks. The results achieved in the Spanishversion of subtask 1A are considered good. They confirm that, depending on the task, fine-tuning pre-trained models may be a good option. In the Spanish-version, we ranked second with a MAP score of 0.529 and in the English-version we ranked fifth with a MAP score of 0.132.</p><p>On the other hand, the results obtained in Subtask 3A leave considerable room for improvement and to date, no enhancement was found in the models used. However, the classifier cascade technique improved the classification. In this research, we classify the most majority classes in the first classifiers. We include some external features to the models used but the results obtained do not improve the fine-tuning experiment of each model.</p><p>In future work, we will experiment with other reference neural models and look for specific features that can improve the results for the most complicated tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,252.15,244.12,8.93;4,223.47,84.19,145.85,155.39"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture modifications with external features</figDesc><graphic coords="4,223.47,84.19,145.85,155.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,286.32,397.77,219.66,10.91;7,89.29,411.32,416.69,10.91;7,89.29,424.87,174.04,10.91"><head></head><label></label><figDesc>7 and 0.3 for a new training set and a development set. The training and development sets maintain similar percentages of examples from each class. The test set has 365 news stories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,89.29,313.23,208.40,8.93;8,108.88,150.07,375.04,150.59"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Explanation of the classification pipeline</figDesc><graphic coords="8,108.88,150.07,375.04,150.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,102.63,185.07,403.36,218.63"><head>Table 1</head><label>1</label><figDesc>RoBERTa or BETO best model with number and date indicators: Concatenated the output of the last layer of RoBERTa or BETO with the number and date indicators. 4. RoBERTa or BETO best model with LIWC features: Concatenated the output of the last layer of RoBERTa or BETO with the LIWC features. 5. RoBERTa or BETO best model with oversampling: The training set is extended with examples of the least representative classes to balance the dataset. 6. RoBERTa or BETO best model with undersampling: Examples of the most representative classes are eliminated to balance the dataset.</figDesc><table coords="5,102.93,197.08,308.57,107.72"><row><cell>Hyperparameter tuning</cell><cell></cell></row><row><cell>Parameters</cell><cell>Values</cell></row><row><cell cols="2">Number train epochs 2, 3, or 4</cell></row><row><cell>Dropout</cell><cell>0.1, 0.2, 0.3, 0.4, or 0.5</cell></row><row><cell>Batch size</cell><cell>2, 4, or 8</cell></row><row><cell>Learning rate</cell><cell>1e-5, 1.5e-5, 2e-5, 2.5e-5, or 3e-5</cell></row><row><cell>3.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,407.14,416.99,136.52"><head>Table 2</head><label>2</label><figDesc>CheckThat! Spanish-version and English-version of Subtask 1A experiments with BETO and RoBERTa models in the development dataset</figDesc><table coords="6,348.32,450.71,116.63,8.87"><row><cell>Spanish</cell><cell>English</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,88.99,561.40,363.53,76.75"><head>Table 5</head><label>5</label><figDesc>CheckThat! Subtask 3 English experiments with RoBERTa model in development dataset</figDesc><table coords="7,193.80,593.02,207.68,45.13"><row><cell cols="2">No Experiment</cell><cell>Macro F1</cell></row><row><cell>1</cell><cell>Our baseline system</cell><cell>0.516</cell></row><row><cell>2</cell><cell>Hyperparameter tuning</cell><cell>0.520</cell></row><row><cell>3</cell><cell>Best model with three classifiers</cell><cell>0.548</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,660.07,135.95,8.97"><p>http://alt.qcri.org/clef2018-factcheck/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,108.93,671.03,52.37,8.97"><p>http://fever.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,108.93,660.08,207.63,8.97"><p>https://simpletransformers.ai/ (accessed on 20 May 2021)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,108.93,671.04,170.70,8.97"><p>https://pytorch.org/ (accessed on 20 May 2021)</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research work has been partially funded by <rs type="funder">Generalitat Valenciana</rs> through project "<rs type="projectName">SIIA: Tecnologias del lenguaje humano para una sociedad inclusiva, igualitaria, y accesible</rs>" (<rs type="grantNumber">PROME-TEU/2018/089</rs>), by the <rs type="funder">Spanish Government</rs> through project "<rs type="projectName">Modelang: Modeling the behavior of digital entities by Human Language Technologies"</rs> (<rs type="grantNumber">RTI2018-094653-B-C22</rs>), and project "<rs type="projectName">IN-TEGER -Intelligent Text Generation</rs>" (<rs type="grantNumber">RTI2018-094649-B-I00</rs>). Also, this paper is also based upon work from <rs type="programName">COST Action</rs> <rs type="grantNumber">CA18231</rs> "<rs type="projectName">Multi3Generation: Multi-task, Multilingual, Multi-modal Language Generation</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_mVDDHKr">
					<idno type="grant-number">PROME-TEU/2018/089</idno>
					<orgName type="project" subtype="full">SIIA: Tecnologias del lenguaje humano para una sociedad inclusiva, igualitaria, y accesible</orgName>
				</org>
				<org type="funded-project" xml:id="_bt62bcT">
					<idno type="grant-number">RTI2018-094653-B-C22</idno>
					<orgName type="project" subtype="full">Modelang: Modeling the behavior of digital entities by Human Language Technologies&quot;</orgName>
				</org>
				<org type="funded-project" xml:id="_nBSG2EF">
					<idno type="grant-number">RTI2018-094649-B-I00</idno>
					<orgName type="project" subtype="full">IN-TEGER -Intelligent Text Generation</orgName>
					<orgName type="program" subtype="full">COST Action</orgName>
				</org>
				<org type="funded-project" xml:id="_Weymec8">
					<idno type="grant-number">CA18231</idno>
					<orgName type="project" subtype="full">Multi3Generation: Multi-task, Multilingual, Multi-modal Language Generation</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,112.66,299.06,394.61,10.91;9,112.28,312.61,356.24,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,336.95,299.06,170.31,10.91;9,112.28,312.61,204.38,10.91">Here Are the Rules: Ignore All Rules&quot;: Automatic Contradiction Detection in Spanish</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sepúlveda-Torres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bonet-Jover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Saquete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,325.26,312.61,75.45,10.91">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3060</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,326.16,393.33,10.91;9,112.66,339.71,383.92,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,281.64,326.16,224.35,10.91;9,112.66,339.71,183.91,10.91">Fighting Fake News and Post-Truth Politics with Behavioral Science: The Pro-Truth Pledge</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsipursky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Votta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Roose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,305.08,339.71,117.71,10.91">Behavior and Social Issues</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="47" to="70" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,353.26,393.53,10.91;9,112.66,366.81,356.27,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,364.23,353.26,141.96,10.91;9,112.66,366.81,135.31,10.91">FEVER: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,380.36,394.53,10.91;9,112.66,393.91,393.33,10.91;9,112.66,407.46,393.33,10.91;9,112.66,421.01,394.53,10.91;9,112.66,434.55,393.33,10.91;9,112.66,448.10,393.33,10.91;9,112.41,461.65,316.64,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,488.80,393.91,17.19,10.91;9,112.66,407.46,393.33,10.91;9,112.66,421.01,99.49,10.91">The CLEF-2021 checkthat! lab on detecting check-worthy claims, previously fact-checked claims, and fake news</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">D S</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,199.90,434.55,306.09,10.91;9,112.66,448.10,87.66,10.91;9,382.45,448.10,85.29,10.91">Advances in Information Retrieval -43rd European Conference on IR Research, ECIR 2021</title>
		<title level="s" coord="9,152.11,462.67,146.73,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-04-01">March 28 -April 1, 2021. 2021</date>
			<biblScope unit="volume">12657</biblScope>
			<biblScope unit="page" from="639" to="649" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct coords="9,112.66,475.20,393.32,10.91;9,112.66,488.75,394.53,10.91;9,112.66,502.30,393.33,10.91;9,112.66,515.85,393.33,10.91;9,112.66,529.40,310.90,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,112.66,502.30,393.33,10.91;9,112.66,515.85,123.26,10.91">Overview of the CLEF-2021 CheckThat! lab task 1 on check-worthiness estimation in tweets and political debates</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Yavuz Selim Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,259.42,515.85,246.57,10.91;9,112.66,529.40,150.24,10.91">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum, CLEF &apos;2021</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,542.95,393.33,10.91;9,112.66,556.50,393.33,10.91;9,112.66,570.05,297.11,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,274.42,542.95,231.56,10.91;9,112.66,556.50,104.98,10.91">Overview of the CLEF-2021 CheckThat! Lab Task 3 on Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,250.40,556.50,255.58,10.91;9,112.66,570.05,136.45,10.91">Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Bucharest, Romania (online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>CLEF &apos;2021</note>
</biblStruct>

<biblStruct coords="9,112.66,583.60,393.33,10.91;9,112.66,597.15,393.32,10.91;9,112.28,610.69,139.49,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,418.26,583.60,87.73,10.91;9,112.66,597.15,292.34,10.91">Fighting post-truth using natural language processing: A review and open challenges</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Saquete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tomás</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Moreda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez-Barco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,413.43,597.15,92.55,10.91;9,112.28,610.69,56.47,10.91">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page">112943</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,624.24,394.53,10.91;9,112.66,637.79,393.33,10.91;9,112.66,651.34,263.66,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,112.66,637.79,393.33,10.91;9,112.66,651.34,39.31,10.91">Exploiting discourse structure of traditional digital media to enhance automatic fake news detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bonet-Jover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Piad-Morffis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Saquete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez-Barco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ángel</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>García-Cumbreras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,160.27,651.34,150.97,10.91">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="page">114340</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,86.97,393.33,10.91;10,112.66,100.52,222.48,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,303.25,86.97,169.19,10.91">Fake News Detection on Social Media</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,482.10,86.97,23.89,10.91;10,112.66,100.52,148.69,10.91">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,114.06,394.53,10.91;10,112.66,127.61,393.33,10.91;10,112.66,141.16,254.38,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,178.73,127.61,327.25,10.91;10,112.66,141.16,70.01,10.91">CLEF-2018 lab on automatic identification and verification of claims in political debates</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,205.69,141.16,130.87,10.91">Proceedings of the CLEF-2018</title>
		<meeting>the CLEF-2018</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,154.71,394.53,10.91;10,112.66,168.26,393.33,10.91;10,112.66,181.81,394.62,10.91;10,112.66,195.36,393.33,10.91;10,112.66,208.91,393.33,10.91;10,112.66,222.46,228.00,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,319.55,168.26,186.44,10.91;10,112.66,181.81,370.91,10.91">Overview of the clef-2018 checkthat! lab on automatic identification and verification of political claims, task 2: Factuality</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,340.31,195.36,165.67,10.91;10,112.66,208.91,307.49,10.91">CLEF 2018 Working Notes. Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="10,428.74,208.91,77.25,10.91;10,112.66,222.46,51.81,10.91">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS.org</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,236.01,393.33,10.91;10,112.66,249.56,395.17,10.91;10,112.66,263.11,395.01,10.91;10,112.66,276.66,200.38,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,422.84,236.01,83.15,10.91;10,112.66,249.56,151.12,10.91">The fact extraction and verification (fever) shared task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Cocarascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W18-5501" />
	</analytic>
	<monogr>
		<title level="m" coord="10,286.25,249.56,221.58,10.91;10,112.66,263.11,327.74,10.91">Proceedings of the First Workshop on Fact Extraction and VERification (FEVER), Association for Computational Linguistics</title>
		<meeting>the First Workshop on Fact Extraction and VERification (FEVER), Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,290.20,393.33,10.91;10,112.66,303.75,393.33,10.91;10,112.66,317.30,394.53,10.91;10,112.30,330.85,395.36,10.91;10,112.66,344.40,338.49,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,355.90,290.20,150.09,10.91;10,112.66,303.75,113.62,10.91">Fever: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1074</idno>
		<ptr target="http://aclweb.org/anthology/N18-1074.doi:10.18653/v1/N18-1074" />
	</analytic>
	<monogr>
		<title level="m" coord="10,248.33,303.75,257.66,10.91;10,112.66,317.30,389.93,10.91">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="10,112.66,357.95,393.33,10.91;10,112.66,371.50,251.89,10.91" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,167.40,357.95,108.96,10.91;10,349.82,357.95,156.17,10.91;10,112.66,371.50,141.00,10.91">so: Post-hoc fact-checking of claims using transformer-based models</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Accenture at CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,385.05,394.62,10.91;10,112.66,398.60,379.07,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,341.52,385.05,139.83,10.91;10,112.66,398.60,268.10,10.91">Identifying Check-Worthy Tweets With Transformer Models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Team Alex at CLEF CheckThat!</note>
</biblStruct>

<biblStruct coords="10,112.66,412.15,395.16,10.91;10,112.66,425.70,180.57,10.91" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="10,363.35,412.15,144.48,10.91;10,112.66,425.70,149.96,10.91">Description of the system developed by team athene in the FNC-1</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Hanselowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pvs</forename><surname>Avinesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Caspelherr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,439.25,393.54,10.91;10,112.66,452.79,393.32,10.91;10,112.30,466.34,182.02,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,394.87,439.25,111.33,10.91;10,112.66,452.79,105.20,10.91">Team gplsi. approach for automated fact checking</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alonso-Reina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sepúlveda-Torres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Saquete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,240.85,452.79,265.13,10.91;10,112.30,466.34,93.73,10.91">Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)</title>
		<meeting>the Second Workshop on Fact Extraction and VERification (FEVER)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="110" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,479.89,393.33,10.91;10,112.33,493.44,322.61,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="10,321.08,479.89,184.91,10.91;10,112.33,493.44,190.61,10.91">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,506.99,394.53,10.91;10,112.30,520.54,395.36,10.91;10,112.66,536.53,97.35,7.90" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="10,180.97,520.54,292.34,10.91">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,547.64,393.33,10.91;10,112.66,561.19,157.12,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,304.02,547.64,201.97,10.91;10,112.66,561.19,102.18,10.91">Spanish pre-trained bert model and evaluation data, PML4DC at ICLR</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Canete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chaperon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pérez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,574.74,393.33,10.91;10,112.66,588.29,393.33,10.91;10,112.66,601.84,315.17,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,395.81,574.74,110.18,10.91;10,112.66,588.29,166.54,10.91">Exploring summarization to enhance headline stance detection</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sepúlveda-Torres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Saquete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lloret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,304.24,588.29,201.75,10.91;10,112.66,601.84,184.28,10.91">International Conference on Applications of Natural Language to Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="243" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,615.39,393.33,10.91;10,112.66,628.93,393.33,10.91;10,112.66,642.48,353.44,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,178.56,615.39,186.60,10.91">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,389.74,615.39,116.25,10.91;10,112.66,628.93,393.33,10.91;10,112.66,642.48,177.61,10.91">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12), European Language Resources Association (ELRA)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12), European Language Resources Association (ELRA)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,656.03,393.53,10.91;10,112.66,669.58,220.38,10.91" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="10,385.71,656.03,120.49,10.91;10,112.66,669.58,109.48,10.91">Semantics-aware BERT for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="11,112.66,86.97,393.33,10.91;11,112.66,100.52,111.81,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">M</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Madabushi</surname></persName>
		</author>
		<title level="m" coord="11,243.09,86.97,262.90,10.91;11,112.66,100.52,79.89,10.91">UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,393.33,10.91;11,112.66,127.61,393.33,10.91;11,112.66,141.16,356.53,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="11,347.66,114.06,158.33,10.91;11,112.66,127.61,196.43,10.91">Stanza: A Python natural language processing toolkit for many human languages</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,331.17,127.61,174.82,10.91;11,112.66,141.16,326.19,10.91">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,154.71,393.32,10.91;11,112.66,168.26,214.69,10.91" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="11,349.13,154.71,156.85,10.91;11,112.66,168.26,103.23,10.91">The development and psychometric properties of LIWC</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="11,112.66,181.81,393.33,10.91;11,112.66,195.36,393.33,10.91;11,112.33,208.91,58.19,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="11,275.24,181.81,230.75,10.91;11,112.66,195.36,169.83,10.91">The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">R</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,293.76,195.36,198.61,10.91">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,222.46,395.01,10.91;11,112.66,236.01,188.31,10.91" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Biewald</surname></persName>
		</author>
		<ptr target="https://www.wandb.com/,softwareavailablefromwandb.com" />
		<title level="m" coord="11,163.90,222.46,197.33,10.91">Experiment tracking with weights and biases</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,249.56,394.52,10.91;11,112.66,263.11,378.11,10.91" xml:id="b28">
	<monogr>
		<title level="m" type="main" coord="11,263.93,249.56,238.32,10.91">Task 3: Fake news detection at CLEF-2021 CheckThat!</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4714517</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4714517.doi:10.5281/zenodo.4714517" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
