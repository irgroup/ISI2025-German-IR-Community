<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.03,75.53,336.09,17.00">UAICS at CheckThat! 2021: Fake news detection</title>
				<funder ref="#_cDCmykA #_t8AtV8g #_GYjPMTm">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.03,108.58,103.01,10.80"><forename type="first">Ciprian</forename><forename type="middle">G</forename><surname>Cusmuliuc</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.58,108.58,96.37,10.80"><forename type="first">Matei</forename><forename type="middle">A</forename><surname>Amarandei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.63,108.58,52.64,10.80"><forename type="first">Ioana</forename><surname>Pelin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.90,108.58,80.30,10.80"><forename type="first">Vlad</forename><forename type="middle">I</forename><surname>Cociorva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,452.70,108.58,64.31,10.80"><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,76.75,133.11,63.25,9.10"><forename type="first">Alexandru</forename><surname>Ioan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza&quot; University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.03,75.53,336.09,17.00">UAICS at CheckThat! 2021: Fake news detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3D5BE497DA818C009A6D6B55F6CE0540</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fake news detection</term>
					<term>LSTM</term>
					<term>Bi-LSTM</term>
					<term>BERT</term>
					<term>RoBERTa</term>
					<term>Random Forest</term>
					<term>Gradient Boosting</term>
					<term>Naïve Bayes</term>
					<term>KNN</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media growth in recent years has facilitated an enhancement in human communication. Platforms such as Facebook and Twitter are now ever-present in our lives, influencing how we speak, think and act. The growth of fake news greatly impacts this phenomenon as it lowers one's trust in the content presented. One such example is related to the 2016 U.S. presidential election campaign where fake news was a deciding factor in tipping the balance of power. It is hence of critical importance to develop tools that detect and combat such destructive content. CLEF 2021 CheckThat! Task 3 tries to address the problem of fake news, posing a challenge to develop systems that could detect if the main claim made in an article is true, partially true, false, or other. Our team participated in this task with 5 models, ranking 6th place with an F1macro of 0.44 and a model based on Gradient Boosting; in this paper we will present our methods, runs and results but also discuss future work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent advances in computing, that date at the beginning of the millennium, have drastically changed human interaction, people no longer tend to meet in real life to maintain contact with friends; furthermore, the COVID-19 pandemic has accelerated this movement by forcing everybody to dialogue via digital means for months at a time. The main facilitators of this movement are social media platforms, that have seen massive usage spikes in the past decade, radically changing how we speak, read news, watch videos and so on, this freedom however comes at a cost. Allowing everybody almost unlimited reachability and free hand to post however they please is a big advantage, but it is also very dangerous; the classical example is related to the 2016 U.S. presidential election campaign where a mixture of social profiling and fake news have led to surprising electoral results (this result contrasts with the 2020 U.S. elections where social media platforms have banned many ads 2 ). Considering the previous argument, it is obvious that we need automated methods that analyze the posts and flag them for fake or misleading content.</p><p>CLEF CheckThat! 2021 Task 3a <ref type="bibr" coords="1,237.65,561.41,12.87,9.90" target="#b0">[1]</ref> [2] [17] <ref type="bibr" coords="1,292.88,561.41,18.16,9.90" target="#b17">[18]</ref> has exactly the goal expressed in the previous section; the task definition been that: "given the text of a news article, determine whether the main claim made in the article is true, partially true, false, or other (e.g., claims in dispute) and also detect the topical domain of the article". In the competition we submitted 5 different models and overall ranked 6th.</p><p>This paper describes the participation of team UAICS, from the Faculty of Computer Science, "Alexandru Ioan Cuza" University of Iasi, in Task 3a at CLEF 2021. The remaining of this paper was organized as follows: Section 2 details the models we developed and the submitted runs and then Section 3 details the results we obtained and finally Section 4 concludes this paper and presents future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods and runs</head><p>In this section we will detail the submitted models; 5 models have been developed in the search of finding the best one, we relied on state-of-the-art methods such as LSTM, Bi-LSTM, BERT, RoBERTa but also experimented with a few novel methods based on more traditional techniques such as Gradient Boosting, Naïve Bayes, KNN and Random Forest. In future sections we will take a look at state-of-theart techniques, analyze the dataset as well as discuss our models and preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State of the art</head><p>Research interest in fake news classification has grown exponentially in just a few years. Identification efforts have been very diverse but they all can be summarized in 3 big categories as <ref type="bibr" coords="2,510.61,278.82,12.66,9.90" target="#b2">[3]</ref> outlines: creator and user analysis, social context analysis and news content analysis.</p><p>Creator and user analysis focuses on extensive analysis of user accounts in order to identify malicious behaviors. Malicious user accounts behave differently from authentic users; thus, identification is possible. Different user categorization can be achieved using different techniques: user profiling analysis <ref type="bibr" coords="2,153.33,342.09,12.11,9.90" target="#b3">[4]</ref> <ref type="bibr" coords="2,165.44,342.09,12.11,9.90" target="#b4">[5]</ref>, temporal and posting behavior analysis <ref type="bibr" coords="2,365.65,342.09,11.63,9.90" target="#b5">[6]</ref>, credibility-related analysis <ref type="bibr" coords="2,507.48,342.09,11.62,9.90" target="#b6">[7]</ref>, and sentiment-related analysis <ref type="bibr" coords="2,210.85,354.59,11.62,9.90" target="#b7">[8]</ref>. Considering user information was not available in the CheckThat! dataset, these techniques would not have been possible to apply.</p><p>Social context analysis tries to study how the news disseminates in the social environment, meaning how quick and wide the data is share/distributed and how users interact with each other, having 2 big research areas: user network analysis (users with high interaction with the news creator can be used to predict the truthfulness of the news) <ref type="bibr" coords="2,236.11,417.86,12.66,9.90" target="#b8">[9]</ref> and distribution pattern analysis (analysis of the information spread in the network) <ref type="bibr" coords="2,175.58,430.61,16.60,9.90" target="#b9">[10]</ref>. Just like creator and user analysis, social analysis is not feasible on this task, not to mention that this technique is not used often. Many approaches choose to analyze the news itself.</p><p>News content analysis in contrast to creator and user analysis does not focus on who posts rather on what they post. In <ref type="bibr" coords="2,151.55,481.14,18.16,9.90" target="#b10">[11]</ref> they used a multitude of neural networks in combination with GloVE embedding to predict the label of a news article; the best result was with a Bi-LSTM, accuracy of 0.91, but notable results were obtained with CNN (0.90) and vanilla RNN (0.78). <ref type="bibr" coords="2,358.52,506.39,18.16,9.90" target="#b11">[12]</ref> takes a different approach based on machine learning, implying Naïve Bayes, Gradient Boosting and Random Forest in order to identify a series of 10000 tweets collected in August 2012, concluding that Random Forest is the best algorithm with an accuracy of 96%. Finally <ref type="bibr" coords="2,225.38,544.39,18.40,9.90" target="#b12">[13]</ref> uses the most novel techniques at this time, BERT <ref type="bibr" coords="2,478.73,544.39,17.42,9.90" target="#b13">[14]</ref>; they start off by tokenizing the input string, then padding after which feeding it to a pre-trained large cased BERT model to perform the classification which yields an accuracy of 0.69 on a test dataset.</p><p>Knowing thus what the best models are but also what their limitations were we proceeded with training them in order to see a result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Training and test dataset analysis</head><p>The training and test dataset have been provided by the organizers and examples can be seen in Table <ref type="table" coords="2,101.75,665.44,5.50,9.90" target="#tab_0">1</ref> and 2. The training dataset consisted of 945 labeled articles and the test dataset had 365 unlabeled articles. This small number of articles proved to be a disadvantage to neural network models as we did not use any other additional datasets. In Figure <ref type="figure" coords="3,151.28,285.57,5.50,9.90" target="#fig_0">1</ref> a dataset analysis is done; taking the Task 3a batches we plot them in order to gain some insight in the collection. In the left size of the figure a word cloud view of most frequent words in the dataset has been build, with the biggest topics being related to politics and COVID-19. The right part of the figure also confirms the latter assumption as there we can see the most frequent words, such as "trump", "covid19" and so on (the plots have been done with tokenized data).</p><p>A problem that was identified early on and will greatly impact the results is relat-ed to label imbalance. Figure <ref type="figure" coords="3,167.83,361.59,5.50,9.90" target="#fig_1">2</ref> shows in different representations how many articles are available with a certain label, unfortunately since False is the most common one, automatically the algorithms will be biased in that direction (0-False, 1-Other, 2-Partially False, 3-True).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.3.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models 2.3.1. 3Layer Model</head><p>The first model, and the one which proven to be the most performant, has been named "3Layer Model" because of its use of 3 different preprocessing methods and 3 different Machine Learning algorithms used.</p><p>In the data preparation phase, there have been a series of alterations over the dataset. The public_id field has been removed, the two training batches have been combined as well as the title field and text, punctuation signs have been removed as well as stop-words, dashed and underscores and lastly the text has been lowercased and lemmatized.</p><p>The feature extraction phase consisted of three approaches:</p><p>• Clean text is a bigram (a contiguous sequence of n items, where n is 2), the training column will be called clean_text; • POS Tagging on text column using spaCY <ref type="foot" coords="4,271.88,255.64,3.25,5.85" target="#foot_0">3</ref> to obtain the POS form), the training column will be called POS_text; • Semantic Analysis is done using Stanford's Empath Tool<ref type="foot" coords="4,330.15,279.89,3.25,5.85" target="#foot_1">4</ref>  <ref type="bibr" coords="4,336.65,281.00,16.58,9.00" target="#b14">[15]</ref> to categorize the words in the articles by their lexicon and approximate which articles that are fake predominantly use a certain lexicon (this column was named semantics_text). An example can be seen in appendix A.</p><p>Besides the three aforementioned techniques we created a fourth one by weighting them as follows: clean_text: 0.5, POST_tagging: 0.15 and semantic_text: 0.35 (these values have been determined experimentally).</p><p>On the columns mentioned earlier, clean_text, POS_text and semantics_text, in order to feed the data to the M.L. algorithms we applied TF-IDF.</p><p>As for the models used, they consisted of Naïve Bayes, KNN, Random Forest and Gradient Boosting. In the results section we will discuss the hyperparameter tuning in relationship to the result; in the end the most performant variant consisted of Gradient Boosting combined with the weighted representation of clean text, POS tagging and semantic analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">BERT</head><p>Another model developed is based on BERT which yielded great results in many state of the art systems <ref type="bibr" coords="4,109.56,481.14,16.77,9.90" target="#b12">[13]</ref>.</p><p>Data preparations for this method consisted of shuffling the training articles, concatenation of the batches, merging the title and text columns and eliminating public_id (it was redundant to training). Other operations have consisted of punctuation signs removal, lemmatization, mandatory text padding and a special BERT tokenizing process.</p><p>As for the model, we used bert-large-uncased (24-layer, 1024 hidden dimensions, 16 attention heads, 336M parameters) from HuggingFace<ref type="foot" coords="4,286.13,555.89,3.50,6.30" target="#foot_2">5</ref> and begun the fine-tuning process. A problem immediately apparent was the size of the dataset as BERT requires many training entities. We used AdamW Optimizer (fine-tuned the learning rate as well as possible, 6e-6 yielding the best results), 3 epochs and a batch size of 3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">RoBERTa</head><p>Since RoBERTa <ref type="bibr" coords="5,162.54,284.82,18.16,9.90" target="#b15">[16]</ref> proves to be better than BERT in some scenarios, we were eager to use it and compare the results. The pre-trained RoBERTa has been taken from HuggingFace as well, we used the model 'roberta-base' <ref type="foot" coords="5,166.58,308.82,3.50,6.30" target="#foot_3">6</ref> .</p><p>The data processing is similar to BERT. The dataset has been split as follows: 70% of data is for training, 20% testing and 10% validation. Hyperparameters used are: text sequence is 256, batches are of 32 elements. Code samples are available in appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4.">LSTM</head><p>The fourth implemented model is LSTM. Training and testing have been done on an 80-20 split. The data processing involves combining the title and text columns and then applying SnowballStemmer<ref type="foot" coords="5,153.33,429.84,3.50,6.30" target="#foot_4">7</ref> from NTLK <ref type="foot" coords="5,216.60,429.84,3.50,6.30" target="#foot_5">8</ref> to stem the text. The text has also been tokenized using Keras's Tokenizer.</p><p>Feature extraction uses Word2Vec as it preserves semantic meaning of words in documents, using the embedding matrix resulted we fed it to the model.</p><p>The model is built with Tensorflow and it's a combination of the following layers:</p><p>• Embedding layer;</p><p>• Dropout layer with a dropout rate of 0.3;</p><p>• LSTM layer with 100 units with a recurrent dropout (fraction of the units to drop for the linear transformation of the recurrent state) of 0.2 and a dropout of 0.2 (fraction of the units to drop for the linear transformation of the inputs); • Dense layer with 4 units (because we predict 4 labels) and using SoftMax activation function.</p><p>The loss function used was sparse categorical cross entropy with Adam optimizer. The total params of the model were 2,648,304. The optimum number of epochs found were 8 and the batch size 16. We used callback functions such as ReduceLROnPlateau <ref type="foot" coords="5,230.10,606.48,3.25,5.85" target="#foot_6">9</ref> to reduce the learning rate if the accuracy does not improve and early stopping to halt training if the model does not improve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5.">Bi-LSTM</head><p>The fifth and final implemented model is an improvement effort on the previous LSTM network. The dataset split was: 90% training and 10% validation.</p><p>The title and text columns were merged in a single column, just like all the models. The newly formed total column was then processed by removing every stop word and lemmatizing it using NLTK. Finally, the sentences were converted to lowercase and had their whitespaces removed.</p><p>The text was tokenized using the Keras Tokenizer. The word index generated length was 27401. For extracting the features, we used GloVe embedding (Global Vectors for Word Representation) with 100 dimensions. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations show case interesting linear substructures of the word vector space.</p><p>For building the model we used Tensorflow. The model was build using the Bidirectional LSTM architecture. We experimented with a lot of combinations of layers but the one that gave the best results during the validation stage was the following (in order):</p><p>• Embedding layer with the input dimension equaling the word index length (27401), output dimension equaling the number of embedding dimensions (100) and the input length equaling the maximum sentence length from the training test. • Bidirectional LSTM layer with 64 units and return sequences set to true.</p><p>• Bidirectional LSTM layer with 32 units.</p><p>• Dropout layer with dropout rate equaling 0.25 to better handle the overfitting due to the small dataset.</p><p>• Dense layer with 4 units (because it predicts 4 labels) and softmax.</p><p>The loss function we used was sparse categorical cross entropy with Adam optimizer. The total params of the model was 2,866,156. We experimented with many variations of values for the number of epochs and batch sizes, but the best performing was setting the number of epochs to 5 and the batch size to 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">3Layer Model</head><p>In this section we will discuss the results of the 3Layer model as well as parameter tuning on the models. Throughout Table <ref type="table" coords="6,147.83,425.54,5.00,9.00" target="#tab_1">3</ref> to 6 there have been experiments with each of the 3 feature extraction methods (clean text, POS tagging and semantic tags) as well as a weighted approach of the three; what worked best in the end is the weighed approach combined with Gradient Boosting, this combination earned us 6 th place with a F1-macro of 0.44. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">RoBERTa</head><p>RoBERTa accuracy is very different, depending on the label; the F1-macro is 0.37. In Table <ref type="table" coords="8,517.47,300.34,5.50,9.90" target="#tab_5">9</ref> we can see a confusion matrix of the model, unfortunately the imbalance of label has left the system unable to predict 'other' label, it is only good at 'false' and 'partially false'. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">LSTM</head><p>The accuracy and loss measured for this model are 0.563157 and 1.405469. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Bi-LSTM</head><p>The results were not the best, mainly to the fact that, the dataset was small, the F1-macro for this model has been measured at 0.33. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Results conclusions</head><p>To conclude the results section, we had 5 models, the best approach seems to be the 3Layer weighted method that officially has an F1-macro of 0.44. We were unable to calculate the other scores with the gold label and the organizers did not provide a ranking. Mostly the results seem to revolve around a score of 0.5 which is in part related to the small dimension of the dataset and the fact that many of our models relied on neural network which require large training sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.03,592.43,450.81,11.00;3,72.03,605.93,136.06,11.00;3,151.02,616.95,292.95,138.83"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left -word cloud view of most frequent words in the dataset; Right -Bar Plot of most frequent words in the dataset.</figDesc><graphic coords="3,151.02,616.95,292.95,138.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.03,758.98,397.91,11.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Label distribution in the dataset (0 -False, 1 -Other, 2 -Partially False, 3 -True).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,86.53,607.66,436.26,9.90;4,72.03,620.42,441.84,9.90"><head>Figure 2</head><label>2</label><figDesc>presents the Training and Validation loss over the epochs; training set contained 70% of the data, 20% for testing and 10% for validation. Apendix B shows a snippet of the BERT classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,72.03,225.83,204.24,11.00;5,181.60,72.00,245.83,144.75"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Training and Validation loss of BERT.</figDesc><graphic coords="5,181.60,72.00,245.83,144.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.03,86.78,419.35,183.30"><head>Table 1 Training</head><label>1</label><figDesc></figDesc><table coords="3,72.03,100.28,419.35,169.80"><row><cell>dataset example</cell><cell></cell><cell></cell><cell></cell></row><row><cell>public_id</cell><cell>text</cell><cell></cell><cell></cell><cell>title</cell><cell>our rating</cell></row><row><cell>c7ea6a6e</cell><cell cols="2">New evidence ties</cell><cell cols="2">Flooding of Coast,</cell><cell>False</cell></row><row><cell></cell><cell cols="2">COVID-19 creation to</cell><cell cols="2">Caused by Global</cell></row><row><cell></cell><cell cols="2">research funded by</cell><cell cols="2">Warming, Has Already</cell></row><row><cell></cell><cell cols="2">Fauci?</cell><cell cols="2">Begun.</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training dataset example</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">public_id</cell><cell></cell><cell>text</cell><cell>title</cell></row><row><cell cols="2">58bea1db</cell><cell cols="2">Second patient cured</cell><cell>Lisa Page Squeals: DNC</cell></row><row><cell></cell><cell></cell><cell cols="2">of HIV, say doctors.</cell><cell>Server Was Not</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hacked By Russia.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,72.03,485.40,431.59,174.44"><head>Table 3 TF</head><label>3</label><figDesc></figDesc><table coords="6,78.53,498.90,425.09,160.94"><row><cell cols="2">-IDF Vectorization on Cleaned Text</cell><cell></cell><cell></cell></row><row><cell>Classifier</cell><cell>Parameters</cell><cell>Accuracy</cell><cell>Macro Average</cell></row><row><cell>Multinomial Naive-</cell><cell>alpha = 0.0</cell><cell>0.57</cell><cell>0.48</cell></row><row><cell>Bayes</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">K-Nearest Neighbors p=2, n_neighbors = 29,</cell><cell>0.61</cell><cell>0.41</cell></row><row><cell></cell><cell>leaf_size = 45</cell><cell></cell><cell></cell></row><row><cell>Random Forest</cell><cell>n_estimators = 1000,</cell><cell>0.47</cell><cell>0.25</cell></row><row><cell></cell><cell>max_features = 'sqrt',</cell><cell></cell><cell></cell></row><row><cell></cell><cell>max_depth = 50,</cell><cell></cell><cell></cell></row><row><cell></cell><cell>min_samples_split = 2,</cell><cell></cell><cell></cell></row><row><cell></cell><cell>min_samples_leaf = 2</cell><cell></cell><cell></cell></row><row><cell>Gradient Boosting</cell><cell>n_estimators = 200</cell><cell>0.57</cell><cell>0.43</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,72.03,104.77,450.91,22.65"><head>Table 6</head><label>6</label><figDesc>highlight the performance of BERT; it is clear from this table that the best setup is with 3 epochs, yielding an F1 of 0.5 on the training dataset split.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,72.03,142.30,423.66,103.92"><head>Table 7</head><label>7</label><figDesc>Validation accuracy of BERT on the training dataset split.</figDesc><table coords="8,108.80,171.79,386.89,74.43"><row><cell>Epoch</cell><cell>Training</cell><cell>Validation</cell><cell>Validation</cell><cell>Validation</cell><cell>Training</cell><cell>Validation</cell></row><row><cell></cell><cell>loss</cell><cell>loss</cell><cell>accuracy</cell><cell>F1</cell><cell>Time</cell><cell>Time</cell></row><row><cell>1</cell><cell>1.31</cell><cell>1.26</cell><cell>0.50</cell><cell>0.50</cell><cell>0:00:44</cell><cell>0:00:02</cell></row><row><cell>2</cell><cell>1.29</cell><cell>1.25</cell><cell>0.48</cell><cell>0.48</cell><cell>0:00:47</cell><cell>0:00:03</cell></row><row><cell>3</cell><cell>1.25</cell><cell>1.24</cell><cell>0.50</cell><cell>0.50</cell><cell>0:00:50</cell><cell>0:00:03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,72.03,350.35,381.43,192.44"><head>Table 8</head><label>8</label><figDesc>Classification report for RoBERTa on training data</figDesc><table coords="8,135.55,380.11,317.91,162.68"><row><cell>RoBERTa</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>Support</cell></row><row><cell>False</cell><cell>0.65</cell><cell>0.85</cell><cell>0.74</cell><cell>97</cell></row><row><cell>True</cell><cell>0.35</cell><cell>0.20</cell><cell>0.26</cell><cell>30</cell></row><row><cell>Partially</cell><cell>0.50</cell><cell>0.49</cell><cell>0.49</cell><cell>47</cell></row><row><cell>false</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Other</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>15</cell></row><row><cell>Accuracy</cell><cell></cell><cell></cell><cell>0.59</cell><cell>189</cell></row><row><cell>Macro avg</cell><cell>0.38</cell><cell>0.38</cell><cell>0.37</cell><cell>189</cell></row><row><cell>Weighted</cell><cell>0.51</cell><cell>0.59</cell><cell>0.54</cell><cell>189</cell></row><row><cell>avg</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,72.03,559.92,376.29,135.17"><head>Table 9</head><label>9</label><figDesc>Confusion matrix for RoBERTa on training data.</figDesc><table coords="8,140.55,589.41,307.77,105.68"><row><cell>Other</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>10</cell></row><row><cell>Partially</cell><cell>0</cell><cell>23</cell><cell>4</cell><cell>20</cell></row><row><cell>False</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>True</cell><cell>0</cell><cell>10</cell><cell>6</cell><cell>14</cell></row><row><cell>False</cell><cell>0</cell><cell>10</cell><cell>5</cell><cell>82</cell></row><row><cell></cell><cell>Partially</cell><cell>False</cell><cell>True</cell><cell>Other</cell></row><row><cell></cell><cell>False</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,72.03,74.28,376.29,135.91"><head>Table 10</head><label>10</label><figDesc>Confusion matrix for LSTM on training data.</figDesc><table coords="9,140.55,103.77,307.77,106.42"><row><cell>Partially</cell><cell>23</cell><cell>25</cell><cell>5</cell><cell>0</cell></row><row><cell>false</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>False</cell><cell>10</cell><cell>78</cell><cell>4</cell><cell>0</cell></row><row><cell>True</cell><cell>9</cell><cell>12</cell><cell>6</cell><cell>0</cell></row><row><cell>Other</cell><cell>3</cell><cell>14</cell><cell>1</cell><cell>0</cell></row><row><cell></cell><cell>Partially</cell><cell>False</cell><cell>True</cell><cell>Other</cell></row><row><cell></cell><cell>False</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,72.03,297.10,381.43,173.16"><head>Table 11</head><label>11</label><figDesc>Classification report for Bi-LSTM on training data.</figDesc><table coords="9,135.55,326.59,317.91,143.67"><row><cell>Bi-LSTM</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>Support</cell></row><row><cell>False</cell><cell>0.58</cell><cell>0.73</cell><cell>0.64</cell><cell>92</cell></row><row><cell>True</cell><cell>0.43</cell><cell>0.11</cell><cell>0.18</cell><cell>27</cell></row><row><cell>Partially</cell><cell>0.46</cell><cell>0.58</cell><cell>0.52</cell><cell>53</cell></row><row><cell>false</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Other</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>18</cell></row><row><cell>Macro avg</cell><cell>0.37</cell><cell>0.36</cell><cell>0.33</cell><cell>190</cell></row><row><cell>Weighted</cell><cell>0.47</cell><cell>0.53</cell><cell>0.48</cell><cell>190</cell></row><row><cell>avg</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,72.03,487.40,376.29,135.16"><head>Table 12</head><label>12</label><figDesc>Confusion matrix for Bi-LSTM on training data.</figDesc><table coords="9,140.55,516.89,307.77,105.67"><row><cell>False</cell><cell>67</cell><cell>1</cell><cell>24</cell><cell>0</cell></row><row><cell>True</cell><cell>14</cell><cell>3</cell><cell>10</cell><cell>0</cell></row><row><cell>Partially</cell><cell>21</cell><cell>1</cell><cell>31</cell><cell>0</cell></row><row><cell>false</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Other</cell><cell>14</cell><cell>2</cell><cell>2</cell><cell>0</cell></row><row><cell></cell><cell>False</cell><cell>True</cell><cell>Partially</cell><cell>Other</cell></row><row><cell></cell><cell></cell><cell></cell><cell>False</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="4,108.05,744.51,50.66,7.20"><p>https://spacy.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="4,108.05,753.76,129.75,7.20"><p>https://github.com/Ejhfast/empath-client</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="4,108.05,763.01,182.99,7.20"><p>https://huggingface.co/transformers/model_doc/bert.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="5,108.05,735.52,113.08,7.20"><p>https://huggingface.co/roberta-base</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="5,108.05,744.51,179.50,7.20"><p>https://www.nltk.org/_modules/nltk/stem/snowball.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="5,108.05,753.76,68.90,7.20"><p>https://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="5,108.05,763.01,164.50,7.20"><p>https://keras.io/api/callbacks/reduce_lr_on_plateau/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4.">Conclusions</head><p>To conclude, in this paper we presented our run at the CLEF 2021 Task 3a; our best method had a F1-macro of 0.44 ranking us 6th. We proposed multiple mod-els based on different methods, for future work we plan on increasing the dataset as well as create a system based on inference so that the article content will be verified using different ontologies.</p></div>
<div><head n="5.">Acknowledgements</head><p>Special thanks go to: <rs type="person">Smau Adrian-Constantin</rs>, <rs type="person">Mosor Andre</rs>, <rs type="person">Radu Rares-Aurelian</rs>, <rs type="person">Gramescu George-Rares</rs>, <rs type="person">Filipescu Iustina-Andreea</rs> without whom this work would not have been possible. This work was supported by project <rs type="projectName">REVERT</rs> (<rs type="projectName">taRgeted thErapy for adVanced colorEctal canceR paTients</rs>), Grant Agreement number: <rs type="grantNumber">848098</rs>, <rs type="grantNumber">H2020-SC1-BHC-2018-2020/H2020-SC1-2019-Two-Stage-RTD</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_cDCmykA">
					<orgName type="project" subtype="full">REVERT</orgName>
				</org>
				<org type="funded-project" xml:id="_t8AtV8g">
					<idno type="grant-number">848098</idno>
					<orgName type="project" subtype="full">taRgeted thErapy for adVanced colorEctal canceR paTients</orgName>
				</org>
				<org type="funding" xml:id="_GYjPMTm">
					<idno type="grant-number">H2020-SC1-BHC-2018-2020/H2020-SC1-2019-Two-Stage-RTD</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,108.05,297.09,415.39,9.90;10,86.28,309.84,436.87,9.90;10,86.28,322.59,437.19,9.90;10,86.28,335.09,437.10,9.90;10,86.28,347.84,437.13,9.90;10,86.28,360.34,437.15,9.90;10,86.28,373.09,118.73,9.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,473.44,297.09,50.00,9.90;10,86.28,309.84,252.19,9.90;10,154.73,335.09,368.65,9.90;10,86.28,347.84,173.65,9.90">The CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News</title>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">San</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fatima</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikolay</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kishore</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julia</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maria</forename><surname>Struss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,283.93,347.84,239.48,9.90;10,86.28,360.34,172.95,9.90">Advances in Information Retrieval -43rd European Conference on IR Research, ECIR 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-03-28">2021. March 28 -April 1, 2021</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="639" to="649" />
		</imprint>
	</monogr>
	<note>on-Cedeño and Rubén M&apos;iguez and Shaden Shaar and Firoj Alam and</note>
</biblStruct>

<biblStruct coords="10,108.05,385.86,415.42,9.90;10,86.28,398.36,331.65,9.90" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,357.85,385.86,165.62,9.90;10,86.28,398.36,111.78,9.90">An exploratory study of covid-19 misinformation on twitter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dirkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Majchrzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.75,398.36,153.06,9.90">Online Social Networks and Media</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">100104</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,411.00,415.27,10.01;10,86.28,423.50,437.11,10.00;10,86.28,436.36,214.51,9.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,251.14,411.00,272.18,10.01;10,86.28,423.50,63.23,10.00">An overview of online fake news: Characterization, detection, and discussion</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.03.004</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2019.03.004" />
	</analytic>
	<monogr>
		<title level="j" coord="10,173.01,423.50,171.72,10.00">Information Processing &amp; Management</title>
		<idno type="ISSN">0306- 4573</idno>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102025</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,449.11,415.10,9.90;10,86.28,461.64,17.11,9.90;10,119.25,461.64,15.91,9.90;10,150.98,461.64,9.16,9.90;10,175.96,461.64,25.80,9.90;10,217.44,461.64,21.03,9.90;10,254.18,461.64,43.50,9.90;10,313.43,461.64,25.01,9.90;10,354.39,461.64,13.75,9.90;10,383.88,461.64,5.50,9.90;10,405.12,461.64,21.99,9.90;10,442.85,461.64,28.49,9.90;10,487.08,461.64,36.12,9.90;10,86.28,474.39,164.71,9.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,86.28,461.64,17.11,9.90;10,119.25,461.64,15.91,9.90;10,150.98,461.64,9.16,9.90;10,175.96,461.64,25.80,9.90;10,217.44,461.64,16.83,9.90">The rise of social bots</title>
		<author>
			<persName coords=""><forename type="first">Emilio</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Onur</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clayton</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alessandro</forename><surname>Flammini</surname></persName>
		</author>
		<idno type="DOI">10.1145/2818717</idno>
		<ptr target="https://doi.org/10.1145/2818717" />
	</analytic>
	<monogr>
		<title level="j" coord="10,254.18,461.64,43.50,9.90;10,313.43,461.64,25.01,9.90">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="96" to="104" />
			<date type="published" when="2016-07">2016. July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,486.89,414.40,9.90;10,86.28,499.64,436.74,9.90;10,86.28,512.39,436.88,9.90;10,86.28,524.89,137.25,9.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,383.66,486.89,138.80,9.90;10,86.28,499.64,230.45,9.90">#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346922</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,342.60,499.64,180.41,9.90;10,86.28,512.39,95.77,9.90">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1773" to="1782" />
			<date type="published" when="2014-12-31">31 Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,537.64,415.33,9.90;10,86.28,550.16,322.97,9.90" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,394.59,537.64,128.79,9.90;10,86.28,550.16,137.03,9.90">Entropy-based classification of&apos;retweeting&apos;activity on twitter</title>
		<author>
			<persName coords=""><forename type="first">Rumi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tawan</forename><surname>Surachawala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1106.0346</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,108.05,562.91,415.05,9.90;10,86.28,575.67,436.83,9.90;10,86.28,588.16,436.70,9.90;10,86.28,600.91,393.03,9.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,179.48,575.67,226.89,9.90">Measurement and analysis of online social networks</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Massimiliano</forename><surname>Marcon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bobby</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/1298306.1298311</idno>
		<ptr target="https://doi.org/10.1145/1298306.1298311" />
	</analytic>
	<monogr>
		<title level="m" coord="10,425.14,575.67,97.97,9.90;10,86.28,588.16,304.09,9.90">Proceedings of the 7th ACM SIGCOMM conference on Internet measurement (IMC &apos;07)</title>
		<meeting>the 7th ACM SIGCOMM conference on Internet measurement (IMC &apos;07)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,613.42,415.11,9.90;10,86.28,626.16,436.96,9.90;10,86.28,638.94,436.97,9.90;10,86.28,651.44,155.46,9.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,340.28,613.42,182.88,9.90;10,86.28,626.16,178.59,9.90">Using sentiment to detect bots on Twitter: Are humans more opinionated than bots?</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASONAM.2014.6921650</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,300.32,626.16,222.92,9.90;10,86.28,638.94,301.77,9.90">IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="620" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,664.19,415.14,9.90;10,86.28,676.69,436.74,9.90;10,86.28,689.44,51.99,9.90;10,156.00,689.44,12.90,9.90;10,186.49,689.44,49.26,9.90;10,253.49,689.44,50.72,9.90;10,321.70,689.44,20.68,9.90;10,360.16,689.44,25.48,9.90;10,403.13,689.44,18.72,9.90;10,439.60,689.44,24.73,9.90;10,482.07,689.44,41.38,9.90;10,86.28,702.19,205.96,9.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,404.65,664.19,118.54,9.90;10,86.28,676.69,27.55,9.90">Information credibility on twitter</title>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<idno type="DOI">10.1145/1963405.1963500</idno>
		<ptr target="https://doi.org/10.1145/1963405.1963500" />
	</analytic>
	<monogr>
		<title level="m" coord="10,136.74,676.69,382.38,9.90">Proceedings of the 20th international conference on World wide web (WWW &apos;11)</title>
		<meeting>the 20th international conference on World wide web (WWW &apos;11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.05,714.69,415.16,9.90;10,86.28,727.46,436.90,9.90;10,86.28,739.96,15.99,9.90;10,118.01,739.96,52.73,9.90;10,186.49,739.96,24.75,9.90;10,226.98,739.96,56.51,9.90;10,299.19,739.96,14.24,9.90;10,329.18,739.96,13.75,9.90;10,358.67,739.96,41.25,9.90;10,415.66,739.96,13.75,9.90;10,445.15,739.96,39.80,9.90;10,500.69,739.96,22.53,9.90;10,86.28,752.71,133.68,9.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,358.40,714.69,164.81,9.90;10,86.28,727.46,166.90,9.90">Diamonds in the rough: Social media visual analytics for journalistic inquiry</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kivran-Swaine</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2010.5652922</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,271.00,727.46,252.17,9.90;10,86.28,739.96,15.99,9.90;10,118.01,739.96,52.73,9.90">VAST 10 -IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,74.77,415.13,9.90;11,86.28,87.27,436.84,9.90;11,86.28,100.02,421.13,9.90" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,474.18,74.77,48.99,9.90;11,86.28,87.27,296.51,9.90">Fake News Detection using Bi-directional LSTM-Recurrent Neural Network</title>
		<author>
			<persName coords=""><forename type="first">Pritika</forename><surname>Bahad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preeti</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raj</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pritika</forename><surname>Bahad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preeti</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raj</forename><surname>Kamal</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2020.01.072</idno>
		<ptr target="https://doi.org/10.1016/j.procs.2020.01.072" />
	</analytic>
	<monogr>
		<title level="j" coord="11,393.21,87.27,125.29,9.90">Procedia Computer Science</title>
		<idno type="ISSN">1877-0509</idno>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,112.41,414.84,10.01;11,86.28,125.18,436.60,10.00;11,86.28,138.04,437.04,9.90;11,86.28,150.54,162.33,9.90" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,310.89,112.41,211.99,10.00;11,86.28,125.18,252.42,10.00">Identifying Fake News on Twitter using Naive Bayes, SVM and Random Forest Distributed Algorithms</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Cusmuliuc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Coca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,364.31,125.18,158.57,10.00;11,86.28,138.04,437.04,9.90">Proceedings of The 13th Edition of the International Conference on Linguistic Resources and Tools for Processing Romanian Language</title>
		<meeting>The 13th Edition of the International Conference on Linguistic Resources and Tools for Processing Romanian Language<address><addrLine>ConsILR-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="177" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,163.29,414.85,9.90;11,86.28,175.79,436.70,9.90;11,86.28,188.54,98.19,9.90" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,382.21,163.29,140.69,9.90;11,86.28,175.79,393.84,9.90">exBAKE: automatic fake news detection model based on bidirectional encoder representations from transformers (bert)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,487.49,175.79,35.49,9.90;11,86.28,188.54,36.88,9.90">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">4062</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,201.29,415.05,9.90;11,86.28,213.82,252.89,9.90" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="11,214.67,201.29,308.43,9.90;11,86.28,213.82,60.42,9.90">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,108.05,226.57,414.78,9.90;11,86.28,239.07,436.72,9.90;11,86.28,251.82,24.75,9.90" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,348.60,226.57,174.23,9.90;11,86.28,239.07,66.42,9.90">Empath: Understanding topic signals in large-scale text</title>
		<author>
			<persName coords=""><forename type="first">Ethan</forename><surname>Fast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Binbin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,163.33,239.07,354.98,9.90">Proceedings of the 2016 CHI conference on human factors in computing systems</title>
		<meeting>the 2016 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,264.57,414.67,9.90;11,86.28,277.06,115.46,9.90" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="11,197.70,264.57,249.24,9.90">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,108.05,289.81,415.30,9.90;11,86.28,302.34,436.77,9.90;11,86.28,315.09,31.99,9.90" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,288.78,289.81,234.57,9.90;11,86.28,302.34,107.37,9.90">Overview of the CLEF-2021 CheckThat! Lab Task 3 on Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">Julia</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,205.69,302.34,317.35,9.90;11,86.28,315.09,26.66,9.90">Working Notes of CLEF 2021--Conference and Labs of the Evaluation Forum</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,108.05,327.84,415.01,9.90;11,86.28,340.34,437.18,9.90;11,86.28,353.09,437.16,9.90;11,86.28,365.59,437.19,9.90;11,86.28,378.36,436.61,9.90;11,86.28,390.75,364.16,10.00" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,181.43,353.09,342.01,9.90;11,86.28,365.59,251.50,9.90">Overview of the CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Míguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Shahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Struß</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,360.28,365.59,163.19,9.90;11,86.28,378.36,436.61,9.90;11,86.28,390.75,204.96,10.00">Proceedings of the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021</title>
		<meeting>the 12th International Conference of the CLEF Association: Information Access Evaluation Meets Multiliguality, Multimodality, and Visualization, CLEF &apos;2021<address><addrLine>Bucharest, Romania(online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,280.38,416.36,48.69,9.90;11,72.03,437.29,236.17,9.00;11,72.03,449.29,401.14,9.00;11,72.03,461.29,402.02,9.00;11,72.03,473.32,421.26,9.00;11,72.03,485.32,418.07,9.00;11,72.03,497.32,431.31,9.00;11,72.03,509.32,431.82,9.00;11,72.03,521.32,421.84,9.00;11,72.03,533.32,439.56,9.00;11,72.03,545.32,442.91,9.00;11,72.03,557.34,432.33,9.00;11,72.03,569.35,446.88,9.00;11,72.03,581.34,429.56,9.00;11,72.03,593.34,446.16,9.00;11,72.03,605.35,442.36,9.00;11,72.03,617.34,430.17,9.00;11,72.03,629.34,442.54,9.00;11,72.03,641.37,416.36,9.00;11,72.03,653.37,425.66,9.00;11,72.03,665.37,438.05,9.00;11,72.03,677.37,439.87,9.00;11,72.03,689.37,433.09,9.00;11,72.03,701.37,420.64,9.00;11,72.03,713.37,433.64,9.00;11,72.03,725.39,450.68,9.00;11,72.03,737.40,447.85,9.00;12,72.03,74.95,447.48,9.00;12,72.03,86.95,57.27,9.00" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,143.05,437.29,86.56,9.00">he hit the other person</title>
	</analytic>
	<monogr>
		<title level="m" coord="11,280.38,416.36,48.69,9.90;11,72.03,437.29,62.67,9.00">Apendix A lexicon.analyze</title>
		<imprint/>
	</monogr>
	<note>office&apos;: 0.0, &apos;violence&apos;: 0.2, &apos;dance&apos;: 0.0, &apos;money&apos;: 0.0, &apos;wedding&apos;: 0.0, &apos;valuable&apos;: 0.0, &apos;domestic_work&apos;: 0.0, &apos;sleep&apos;: 0.0, &apos;medical_emergency&apos;: 0.0, &apos;cold&apos;: 0.0, &apos;hate&apos;: 0.0, &apos;cheerfulness&apos;: 0.0, &apos;aggression&apos;: 0.0, &apos;occupation&apos;: 0.0, &apos;envy&apos;: 0.0, &apos;anticipation&apos;: 0.0, &apos;family&apos;: 0.0, &apos;crime&apos;: 0.0, &apos;attractive&apos;: 0.0, &apos;masculine&apos;: 0.0, &apos;prison&apos;: 0.0, &apos;health&apos;: 0.0, &apos;pride&apos;: 0.0, &apos;dispute&apos;: 0.0, &apos;nervousness&apos;: 0.0, &apos;government&apos;: 0.0, &apos;weakness&apos;: 0.0, &apos;horror&apos;: 0.0, &apos;swearing_terms&apos;: 0.0, &apos;leisure&apos;: 0.0, &apos;suffering&apos;: 0.0, &apos;royalty&apos;: 0.0, &apos;wealthy&apos;: 0.0, &apos;white_collar_job&apos;: 0.0, &apos;tourism&apos;: 0.0, &apos;furniture&apos;: 0.0, &apos;school&apos;: 0.0, &apos;magic&apos;: 0.0, &apos;beach&apos;: 0.0, &apos;journalism&apos;: 0.0, &apos;morning&apos;: 0.0, &apos;banking&apos;: 0.0, &apos;social_media&apos;: 0.0, &apos;exercise&apos;: 0.0, &apos;night&apos;: 0.0, &apos;kill&apos;: 0.0, &apos;art&apos;: 0.0, &apos;play&apos;: 0.0, &apos;computer&apos;: 0.0, &apos;college&apos;: 0.0, &apos;traveling&apos;: 0.0, &apos;stealing&apos;: 0.0, &apos;real_estate&apos;: 0.0, &apos;home&apos;: 0.0, &apos;divine&apos;: 0.0, &apos;sexual&apos;: 0.0, &apos;fear&apos;: 0.0, &apos;monster&apos;: 0.0, &apos;irritability&apos;: 0.0</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
