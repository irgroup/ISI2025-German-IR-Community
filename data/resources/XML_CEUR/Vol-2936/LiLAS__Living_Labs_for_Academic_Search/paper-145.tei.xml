<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,391.05,15.42;1,89.29,106.66,336.15,15.42">PyTerrier-based Research Data Recommendations for Scientific Articles in the Social Sciences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,124.13,11.96"><forename type="first">Narges</forename><surname>Tavakolpoursaleh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.07,134.97,78.16,11.96"><forename type="first">Johann</forename><surname>Schaible</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,391.05,15.42;1,89.29,106.66,336.15,15.42">PyTerrier-based Research Data Recommendations for Scientific Articles in the Social Sciences</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">290D6695D31441C3818993A4A4C9B36C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>recommender systems</term>
					<term>information retrieval</term>
					<term>online evaluation</term>
					<term>research data</term>
					<term>living lab</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Research data is of high importance in scientific research, especially when making progress in experimental investigations. However, finding appropriate research data is difficult. One possible way to alleviate the situation is to recommend research data to scholarly search system users based on the research articles they are searching. With LiLAS, the lab organizers provide the opportunity i) to present such recommendations to users of the live system GESIS Search and ii) to evaluate the experimental recommender system in this live system with its actual users. As part of our participation in LiLAS, we computed a simple method for recommending research data and evaluated our approach in two rounds each lasting approximately one month. For our approach, we applied the classical TF-IDF method to rank the research data by their relevance to existing publications. We measure our method's usefulness using user feedback, i.e., simple clicks on the recommendations. In both rounds, our experimental system obtained almost the same outcomes as the baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Evaluating recommender systems and its underlying approaches is a crucial step in assessing the overall quality of recommendations. Typically, such approaches are evaluated offline using test collections. Using such collections including relevance assessment, we can specify how well a recommendation fits the users' information need. The CLEF-lab LiLAS makes use of the STELLA framework <ref type="bibr" coords="1,178.42,466.66,11.23,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,192.06,466.66,7.43,10.91" target="#b1">2,</ref><ref type="bibr" coords="1,201.90,466.66,7.49,10.91" target="#b2">3]</ref>, which allows the organizers to provide an environment to evaluate recommendations online. This means that recommendations are presented to real users in a live system and the recommendation quality is assessed by how well the users perceive the recommendations. Thus, no test collection or manual relevance assessment by domain experts is needed. Instead, solely the actions by the actual users of the search system "indicate" whether a recommendation fits the information need or not. This pseudo-relevance is estimated by implicit user feedback, such as clicking on well-fitting recommendations.</p><p>Recommending research data based on a currently viewed publication aims at alleviating the situation of finding appropriate research data for a specific use. However, to do so, a scholarly search system must contain information on both scientific publications and research data in a given domain. Luckily, the live search system for the broad domain of social sciences GESIS Search <ref type="bibr" coords="1,120.46,615.70,12.84,10.91" target="#b3">[4]</ref> is integrated in the STELLA framework provided in the LiLAS lab.</p><p>In this paper, we present our recommendation approach for GESIS Search that suggests research data based on a currently viewed scientific publication. We considered the basic content representing metadata of publication and research data as the features. After extracting the features, we compute term frequency and document frequency (TF-IDF) for each term in each dataset for text matching and making recommendations. The implemented approach is provided as a Docker image in the format required by LiLAS for reproducibility. This way, our recommendation approach is able to compute recommendations on-the-fly instead of using pre-computed result lists for only a small portion of scientific publications. The results illustrate that our approach is not outperforming the provided baseline in a statistical significant manner. However, it shows its general usefulness, especially being a simple approach that can be improved further in many ways, e.g., using multi-lingual features to detect more precise similarities.</p><p>In the following, we briefly present the scientific search system GESIS Search as well as the data and task provided by LiLAS (cf. Section 2). We depict and describe our approach in detail in Section 3. The results of the evaluation and the discussion of the results are described in Section 4 and Section 5, respectively, before we conclude the paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System, Data and Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">System and the Data</head><p>GESIS Search<ref type="foot" coords="2,153.61,368.04,3.71,7.97" target="#foot_0">1</ref>  <ref type="bibr" coords="2,160.88,369.80,13.00,10.91" target="#b3">[4]</ref> offers an integrated search system for information on the broad topic of social sciences and facilitates finding research data and publication in one portal.</p><p>To train a recommendation approach, GESIS provides a corpus of social science publications and research data for the LiLAS participants. The research data set consists of about 78ùëò records in the first round and 99ùëò records in the second round. The number of publications provided increased from 93ùëò records in the first round to 110k in the second round. The records are composed of metadata of the documents in different languages. This metadata consists of a title, an abstract, and topics for both research data and publications and some specific metadata like authors and DOI for publication and temporal and geographical coverages for research data. Examples of such research data and publications can be seen in Figure <ref type="figure" coords="2,404.54,491.74,3.74,10.91" target="#fig_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">LiLAS Task</head><p>The recommendation task is defined as ranking the most relevant research data to the top for a given source publication. In submission type B, the participants should provide a REST-API for sending requests and getting the ranking. The system should be prepared as a Docker container service which LiLAS integrates into the evaluation environment in GESIS Search. LiLAS also provides sample templates that implement minimal REST-based web services and can be developed by the participant. Finally, the participants register their public accessible GitHub repository at the central dashboard service of the LiLAS for the Living lab evaluation. To perform the task, the participants are provided with a list of seed publications (i.e., the  publication IDs), a list of research data IDs, the metadata for both obtained from GESIS Search, as well as a list of research data candidates for 1ùëò seed publications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>Kr√§mer et al. <ref type="bibr" coords="3,149.27,355.36,12.84,10.91" target="#b4">[5]</ref> classified the relevancy of research data to the research question in the social science domain into three main aspects: relevance of the content, relevance criteria related to data characteristics or factors, and documentation needed to assess relevance. In their study, the participants assess the topical relevance of research data based on how well the research data content fits the research questions. Besides the topical relevance, participants assess the relevance based on other metadata as the type of publication of the primary research connected to a research data, temporal and spatial extent of the data, and characteristics of the sample.</p><p>The context-based recommendation of contextual data is rarely covered due to the lack of standard evaluation data and the cold start problem <ref type="bibr" coords="3,323.87,463.75,11.51,10.91" target="#b5">[6]</ref>. Given the opportunity to participate in a living lab evaluation infrastructure, we aim to assess our experimental content-based recommendation methods for recommending research data based on publications with actual users of the GESIS portal.</p><p>The records (research data and publications) are rarely described with the whole metadata set. But most of the publications have at least a title with an average of 11.5 words. More than 40% of publications have no abstract. On average, the number of words in the abstract amounts to 86.7 terms. We selected a few descriptive metadata from the publications and research data as the entities' features. These metadata of research data and publication include information that can characterize the entities and semantically connect the two types of entities. These include the title, abstract, and the topics for research data and publications, which resemble the set of features used by our approach. The title as a noteworthy minimal description of data expresses the very brief data content and is scanned when looking for data <ref type="bibr" coords="3,382.92,626.34,11.51,10.91" target="#b4">[5]</ref>. Unlike the abstract and topics, titles are always available for both data types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental System: gesis_rec_pyterrier</head><p>We collected three fundamental descriptive metadata elements to identify the resources of both types: title, abstract, and topics. The publication's titles are, in most cases, highly representative and informative and represent the content of the paper. However, the titles of research data are not always informative; for example, "German general Social Survey -ALLBUS 2012". Nevertheless, the abstract information of both resources is limited but appropriate to identify them. Also, the topics or keywords hold compact essential descriptive information about the content of the resources. Figure <ref type="figure" coords="4,235.82,188.83,5.17,10.91" target="#fig_3">3</ref> and 1 depicts the distribution of topics, titles, and abstract lengths (number of words) in both types of documents.</p><p>As the first experimental system, we decided to utilize Pyterrier, a Python wrapper on top of Terrier for performing information retrieval experiments <ref type="bibr" coords="4,344.59,229.48,12.82,10.91" target="#b6">[7]</ref> and compare it with the baseline. We chose this system to establish a comparison between the baseline and this simplistic out-ofthe-box approach. Pyterrier provides easy to conduct IR experiments with different weighting models, such as TF-IDF and BM25. Terrier also supports non-English language texts since it represents terms as UTF. It has additional plugins for Bert, EPIC, ColBert, and other methods. However, we did not apply them for the first two experimental rounds. We considered the simple term weighting model of TF-IDF, which scores a document regardless of term position in the text, in order to compare it directly to the baseline using BM25. We collected the title, abstract and the topics of the publications for issuing the queries, and the research data for the indexing.</p><p>The research data recommendations are based on the terms in the title, topic, and abstract of the research data as well as of the publications. When providing a publication identifier (seed item of the recommendation), it will be translated into the corresponding publication title, abstract, and topics, which, in turn, are used to query the index of research data with a basic TF-IDF-based algorithm without extra features. This means, during the indexing as well as retrieval process, the text from the title, abstract, and topics of research data and publications is analyzed using the standard tokenizer, stemmer, as well as stop-word-removal provided by Pyterrier. The Terrier weighting model employs Robertson's TF (the term frequency of the term in the document) and standard Sparck Jones' IDF <ref type="bibr" coords="4,308.42,473.36,11.36,10.91" target="#b6">[7]</ref>. The experimental system implements an API for indexing and searching, and it is provided as a Docker image with the LiLAS required format for reproducibility<ref type="foot" coords="4,203.90,498.71,3.71,7.97" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Experimental Setup</head><p>The STELLA infrastructure used for the LiLAS lab contributes the participants' experimental recommender systems in two forms: A) the pre-computed runs and B) the Docker container (Dockerfiles and their source code) <ref type="bibr" coords="4,242.25,577.29,11.28,10.91" target="#b7">[8]</ref>. The participants can decide whether they submit type A) or type B). We chose to submit type B), i.e., a Docker container comprising our recommendation approach.</p><p>Our experimental ranking is merged with the baseline through the STELLA interleaving mechanism to generate the final result list and to present it to the users (see Figure <ref type="figure" coords="4,470.63,631.48,3.65,10.91" target="#fig_2">2</ref>). User feedback in the form of clicks is collected and sent to the central STELLA server. There the  evaluation metrics are calculated with some statistics and are displayed as well as reported to the participants (Figure <ref type="figure" coords="6,198.98,296.73,3.57,10.91" target="#fig_4">4</ref>).  In the first round in March 2021, the first 100 most frequently viewed publications in the GESIS search were clicked between 4 to 29 times per session. In some sessions, items have been viewed several times. The recommended research data of all systems got about 0.013 CTR with 91 clicks (which includes 82 unique research data) in 6, 765 impressions. The CTR for gesis_rec_pyterrier and baseline are respectively 0.0055 and 0.0069. (Figure <ref type="figure" coords="7,425.71,388.34,3.57,10.91" target="#fig_5">5</ref>).</p><p>In the first round, the two systems performed almost the same (Figure <ref type="figure" coords="7,412.76,401.89,3.55,10.91" target="#fig_7">6</ref>). It is observed that the baseline is showing an not substantially better performance than the experimental system with the outcome of 0.5168.</p><p>In the second round from 15 April to 25 May, we proceeded with our single experimental system gesis_rec_pyterrier. The experimental setting remained unchanged, and only new records of publication and research data are included in the corpus. In the second round GESIS received 131 user clicks on recommended items of all three systems. The CTR is 0.016, with the whole impressions of 7, 753. Our pyterrier system received 25 clicks and got a CTR of 0.0068. In this round, the CTRs for the baseline and new experimental system are 0.007 and 0.011.</p><p>Our pyterrier system and the baseline, as for the first round, perform almost the same (see Figure <ref type="figure" coords="7,120.36,537.39,3.57,10.91" target="#fig_7">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>Although the pair of experimental ranking systems are interleaved starting randomly from one system ranking, as shown in Figure <ref type="figure" coords="7,250.83,609.56,3.76,10.91">8</ref>, the number of clicks on the top-1 ranked item (highest rank) is greatly different from the items in the other places. 52.8% of clicked items have the ranking position one. It shows that the first item in the ranking list has been clicked the most, regardless of the ranker system. Recommendations on the second (13.5%) and third positions (15.7%) have been clicked almost the same. Different studies ( <ref type="bibr" coords="7,368.25,663.76,11.35,10.91" target="#b8">[9,</ref><ref type="bibr" coords="7,382.32,663.76,12.95,10.91" target="#b9">10]</ref>) have also specified that   the baseline constantly and an experimental system interleaved by LiLAS. Due to the low traffic of active users viewing the publication (the number of impressions per day) and the limited number of recommended items, the number of user clicks is deficient. Therefore, the collected clicks might not be entirely satisfactory for two months of evaluation for several test systems (Figure <ref type="figure" coords="9,123.28,351.85,3.57,10.91" target="#fig_9">9</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We succeeded in the first-hand experiment on online evaluation of cross-domain recommendations between publication and research data. As the experimental system, we have implemented a naive content-based recommendation using the metadata available in most documents, i.e., title, abstract, and topics, primarily to compare this out-of-the-box approach to the baseline. We submitted a dockerized system capable of reproducing the ranking with new data. Our recommender system is implemented using the pyterrier library, and we applied the weighting model based on TF-IDF, which resembles a direct comparison to the baseline's BM25 ranking. This simplistic approach was not able outperform the baseline. However, we used only the out-of-the-box Pyterrier system without any further configuration or inclusion of other features, such as the multi-lingual support. Future work comprises to extend this simplistic approach step by step. For example, we will focus on utilizing the Bert plugin to integrate our embedding-based recommendation approach <ref type="bibr" coords="10,297.12,154.71,18.07,10.91" target="#b10">[11]</ref> into Pyterrier. We will also focus on user needs and decision factors for considering the research data and apply information extraction, translation and semantic representations, and contextual text representation methods for the research data recommendation.</p><p>On a general note, the low number of clicks during the first two evaluation rounds (Figure <ref type="figure" coords="10,498.45,208.91,4.09,10.91" target="#fig_9">9</ref>) indicate that more "traffic" is needed to better evaluate recommendation approaches in a live setting, as a recommended item is clicked only after the users have searched for a publication, clicked on a publication of interest, and then only clicked on the recommended research data. However, we still believe that LiLAS provides an excellent opportunity for researchers to evaluate their approaches with real users in a live system. It supports both researchers and the portal to develop and evaluate their experimental system to recommend cross-domain data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,245.58,243.96,8.93;3,100.55,86.16,195.85,128.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Density of number of words in abstract and titles</figDesc><graphic coords="3,100.55,86.16,195.85,128.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,89.29,623.73,417.78,8.93;5,89.29,635.73,219.58,8.87;5,89.29,111.37,430.38,505.77"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Screenshot of GESIS Search: an example of experimental recommendation ranking, gesis_rec_pyterrier, interleaved with Baseline ranking</figDesc><graphic coords="5,89.29,111.37,430.38,505.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,89.29,245.58,252.76,8.93;6,100.55,84.19,195.84,130.90"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Density of number of words in topics of documents</figDesc><graphic coords="6,100.55,84.19,195.84,130.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,89.29,640.31,416.69,8.93;6,114.72,319.45,365.82,308.30"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Screenshot of LiLAS dashboard contains the evaluation metrics for the experimental system</figDesc><graphic coords="6,114.72,319.45,365.82,308.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,89.29,302.21,401.47,8.93;7,100.55,121.09,195.85,150.63"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The cumulative number of user clicks on the recommended items during the first round</figDesc><graphic coords="7,100.55,121.09,195.85,150.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="8,89.29,267.25,348.01,8.93;8,100.55,87.08,195.84,149.67"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Outcomes for Baseline and Pyterrier during the first and the second round</figDesc><graphic coords="8,100.55,87.08,195.84,149.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,89.29,600.27,247.64,8.93;8,100.55,426.23,195.84,143.54"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Click-Through Rate in the first and second rounds</figDesc><graphic coords="8,100.55,426.23,195.84,143.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="9,89.29,525.95,400.19,8.93;9,137.15,381.62,159.24,131.76"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Daily number of clicks on the all recommended item during the first and second Round</figDesc><graphic coords="9,137.15,381.62,159.24,131.76" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.01,80.78,8.97"><p>http://search.gesis.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,108.93,671.02,191.94,8.97"><p>https://github.com/stella-project/gesis_rec_pyterrier</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,348.83,393.32,10.91;10,112.66,362.38,394.53,10.91;10,112.66,375.93,65.36,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,437.87,348.83,68.11,10.91;10,112.66,362.38,288.90,10.91">Stella: Towards a framework for the reproducibility of online search experiments</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>M√ºller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,429.57,362.38,72.88,10.91">OSIRRC@ SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,389.48,393.33,10.91;10,112.66,403.03,335.99,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,457.07,389.48,48.92,10.91;10,112.66,403.03,181.31,10.91">Evaluation infrastructures for academic shared tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,302.05,403.03,95.83,10.91">Datenbank-Spektrum</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,416.58,393.73,10.91;10,112.66,430.13,394.53,10.91;10,112.66,443.67,393.33,10.91;10,112.66,457.22,393.33,10.91;10,112.66,470.77,393.32,10.91;10,112.66,484.32,142.00,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,461.99,416.58,44.40,10.91;10,112.66,430.13,200.94,10.91">Overview of lilas 2021 -living labs for academic search</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,447.41,443.67,58.58,10.91;10,112.66,457.22,393.33,10.91;10,112.66,470.77,254.11,10.91">Proceedings of the Twelfth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="10,474.41,471.79,31.57,9.72;10,112.66,485.34,112.43,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Candan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Twelfth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">12880</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="10,112.66,497.87,393.32,10.91;10,112.66,511.42,393.33,10.91;10,112.66,524.97,218.63,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,359.43,497.87,146.55,10.91;10,112.66,511.42,203.42,10.91">A digital library for research data and related information in the social sciences</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hienert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zapilko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mutschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,362.90,511.42,143.09,10.91;10,112.66,524.97,103.92,10.91">ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,538.52,393.33,10.91;10,112.66,552.07,309.37,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,372.91,538.52,133.07,10.91;10,112.66,552.07,62.60,10.91">Data-seeking behaviour in the social sciences</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kr√§mer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Papenmeier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Carevic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mathiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,183.50,552.07,182.68,10.91">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,565.62,393.33,10.91;10,112.66,579.17,249.04,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,333.46,565.62,172.53,10.91;10,112.66,579.17,49.09,10.91">Contextual recommendation based on text mining</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,185.19,579.17,88.87,10.91">Coling 2010: Posters</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="692" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,592.72,393.32,10.91;10,112.66,606.27,205.58,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,244.82,592.72,261.16,10.91;10,112.66,606.27,37.16,10.91">Declarative experimentation ininformation retrieval using pyterrier</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,172.51,606.27,115.78,10.91">Proceedings of ICTIR 2020</title>
		<meeting>ICTIR 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,619.81,394.53,10.91;10,112.66,633.36,393.33,10.91;10,112.66,646.91,175.93,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,270.07,619.81,232.77,10.91">Overview of lilas 2020-living labs for academic search</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J G</forename><surname>Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,130.06,633.36,375.92,10.91;10,112.66,646.91,44.89,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="364" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,660.46,395.17,10.91;11,112.66,86.97,393.60,10.91;11,112.66,100.52,394.61,10.91;11,112.66,114.06,337.56,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,203.42,660.46,260.91,10.91">Position-normalized click prediction in search advertising</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">W</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2339530.2339654</idno>
		<ptr target="https://doi.org/10.1145/2339530.2339654.doi:10.1145/2339530.2339654" />
	</analytic>
	<monogr>
		<title level="m" coord="10,488.38,660.46,19.45,10.91;11,112.66,86.97,393.60,10.91;11,112.66,100.52,72.26,10.91">Pro-ceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,127.61,393.33,10.91;11,112.66,141.16,215.44,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yankov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Berkhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.07662</idno>
		<title level="m" coord="11,238.60,127.61,267.38,10.91;11,112.66,141.16,33.01,10.91">Evaluation of explore-exploit policies in multi-result ranking systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,112.66,154.71,393.33,10.91;11,112.66,168.26,257.25,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tavakolpoursaleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schaible</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dietze</surname></persName>
		</author>
		<title level="m" coord="11,309.09,154.71,196.90,10.91;11,112.66,168.26,175.46,10.91">Using word embeddings for recommending datasets based on scientific publications</title>
		<imprint>
			<publisher>LWDA</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
