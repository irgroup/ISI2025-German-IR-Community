<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,346.72,15.42">Pixelwise annotation of coral reef substrates</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.10,113.06,70.09,11.96"><forename type="first">Jessica</forename><surname>Wright</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,171.84,113.06,93.10,11.96"><forename type="first">Ioana-Lia</forename><surname>Palosanu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.58,113.06,51.18,11.96"><forename type="first">Louis</forename><surname>Clift</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.40,113.06,57.64,11.96"><forename type="first">Alba</forename><surname>Garc√≠a</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.03,113.06,77.86,11.96"><forename type="first">Seco</forename><surname>De Herrera</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.10,127.00,82.55,11.96"><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,346.72,15.42">Pixelwise annotation of coral reef substrates</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A3B927518B7C2782960156EBDDEBB1A6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image segmentation</term>
					<term>automatic annotation</term>
					<term>coral reef annotation</term>
					<term>semantic segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Coral reef substrate composition is regularly surveyed for ecosystem health monitoring. The current method of visual assessment is slow and limited in scale. ImageCLEFcoral aims to identify reef areas of interest and annotate them appropriately. We present an adaptation of a submission to the 2019 Im-ageCLEFcoral task that uses a semantic segmentation model, DeepLabV3, with a ResNet-101 backbone. We implemented pre-training image colour enhancement and supplemented the available training data with that of NOAA NCEI for specific runs. Our runs had no overall improvement from the 2019 code, though did predict submassive corals and table corals with greater accuracy (+3.022% and +0.353%).</p><p>Though none of our model runs had the highest precision or accuracy, we did best predict submassive corals (3.022%), boulder corals (12.787%), table corals (0.353%), foliose corals (0.097%), gorgonian soft corals (0.002%) and algae (0.027%) across 3 of our 4 runs. Image colour enhancement benefited the prediction accuracy of boulder corals (+1.209-5.026%), encrusting corals (+1.7-2.578%) and algae (+0.027%), most likely by making them more distinct from their surroundings. Adding NOAA data enhanced the precision of encrusting coral, soft coral and gorgonian predictions despite only providing additional annotations for encrusting and foliose corals. Our results suggest that a more balanced approach to data augmentation combined with image-specific colour improvements may provide a more desirable outcome, particularly when paired with a model that is fine-tuned to the data set used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Coral reefs are vital marine systems that are known to provide many ecosystem functions and services <ref type="bibr" coords="1,128.36,472.83,13.00,10.91" target="#b0">[1]</ref> while supporting one third of marine species <ref type="bibr" coords="1,351.20,472.83,11.58,10.91" target="#b1">[2]</ref>. Their decline has been widely reported and tracked <ref type="bibr" coords="1,181.72,486.38,11.28,10.91" target="#b2">[3]</ref>. Current monitoring of coral reefs benthic communities relies on in-situ data collection, sometimes followed by ex-situ video analysis, requiring time and expertise to analyse correctly <ref type="bibr" coords="1,170.12,513.48,11.58,10.91" target="#b3">[4]</ref>. Automatic annotation from video stills or photographs would greatly increase the speed and scale of feasible monitoring, and could free up reef experts to focus on other areas to gain a wider view of shifting coral reef dynamics.</p><p>Deep learning algorithms provide an answer to automatic annotation <ref type="bibr" coords="1,417.15,554.13,11.57,10.91" target="#b4">[5]</ref>. The underlying architecture of most are Convolutional Neural Networks, often used for image and pattern recognition <ref type="bibr" coords="1,118.90,581.23,11.49,10.91" target="#b5">[6]</ref>. Image segmentation models have been the most successful in the ImageCLEFcoral pixel-wise parsing task <ref type="bibr" coords="1,194.67,594.77,11.36,10.91" target="#b6">[7,</ref><ref type="bibr" coords="1,208.76,594.77,7.57,10.91" target="#b7">8]</ref>, where each pixel is predicted as a particular class. This is the third iteration of an annual ImageCLEF task <ref type="bibr" coords="1,341.30,608.32,11.23,10.91" target="#b8">[9,</ref><ref type="bibr" coords="1,355.01,608.32,12.50,10.91" target="#b9">10,</ref><ref type="bibr" coords="1,369.98,608.32,13.95,10.91" target="#b10">11]</ref> which has subtasks looking Considering the value of each subtask in terms of practical use in monitoring reef systems accurately, we focused on subtask 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data</head><p>The initial data provided were split into a training and test images of coral reef systems. The training set was annotated (Fig. <ref type="figure" coords="2,233.33,395.53,4.17,10.91" target="#fig_0">1</ref>) with the morphological substrate classes set in the task <ref type="bibr" coords="2,493.13,395.53,12.85,10.91" target="#b8">[9]</ref> and the test set was not annotated. The training set was then provided to build and train a network, with the test set given later to get submission runs. More details about the dataset can be found at Chamberlain et al. <ref type="bibr" coords="2,227.28,436.18,16.25,10.91" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The training set</head><p>879 images with a combined set of 21,748 annotations were provided as the training data. The annotations were not evenly split across classes, likely as some are more prevalent than others in reef systems (Fig. <ref type="figure" coords="2,181.39,513.00,3.57,10.91" target="#fig_1">2</ref>). Each substrate morphology can be indistinct from others due to the variation in that class' species. This is particularly true of classes that are not broken down into morphological groups, i.e. "soft coral", and less of an issue with classes that are split, i.e. each "hard coral" group.</p><p>The use of NOAA NCEI 1 and/or CoralNet 2 data was recommended for the task. We chose to utilise the NOAA data set for some experiments. 3032 NOAA images were downloaded of a possible 15,019, due to time limitations on our machines. The NOAA data set contains a greater number of classification labels than the ImageCLEFcoral classes. These classifications are also of a single pixel (10 pixels per image) so did not provide enough information for our image analysis and recognition algorithms. We developed a NOAA Translation processor to capture the classification types within the data set and translate them via an expert defined translation matrix into the ImageCLEFcoral classes which we made available through the ImageCLEFcoral website for other participants. The processor then created an adjustable Region Of Interest (ROI) around the same pixel to provide an image patch, typically a 10x10 pixel area, that enabled our machine learning routines to adapt to the NOAA data sets.</p><p>5 substrate classes were then selected to refine the number of images to a more manageable amount: Fire Coral -Millepora, Hard Coral -Foliose, Hard Coral -Table , Hard Coral -Sub-Massive, and Hard Coral -Encrusting. These classes had a lower number of annotations than others and were chosen to increase accuracy. Despite low incidence, Soft Coral -Gorgonian, Hard Coral -Mushroom, and Sponge -Barrel were not chosen from the NOAA data set as they have more distinct morphologies than the selected classes so were more likely to be predicted despite relatively few occurrences. Algae -Macro or Leaves were also not selected from the NOAA data set despite low incidence. Algae classification of the ImageCLEF set only accounted for large leaf macroalgae, whereas the NOAA data set also included other types such as turf and CCA, so conflicting annotations could have hampered the model predictions.</p><p>502 viable NOAA images were found, within which 2 of the 5 selected classes were found: Hard Coral -Encrusting and Hard Coral -Foliose. This almost doubled the processing time per epoch and pushed the entire model training time from 10 hours to 17.5 hours (10 epochs total), and increased the total number of substrate annotations from 21,748 to 22,403 (Fig. <ref type="figure" coords="3,460.40,661.70,3.57,10.91" target="#fig_1">2</ref>). Each image had (b,e) balanced RGB levels, then (c,f) when through a generalised channel mixing process to balance the colors while maintaining image contrast. The leveling and mixing were selected to optimise substrate color and contrast with less focus on the background and water colouring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Image enhancement</head><p>Underwater imagery is often lower quality than that taken on land. Light attenuation distorts colour detection and water turbidity can reduce image quality, and with all underwater imagery there is a greater chance for blurred or unfocused photographs. Taking steps to investigate, process and augment the provided data is expected to improve the data quality and subsequent network results <ref type="bibr" coords="4,161.66,466.13,16.43,10.91" target="#b11">[12,</ref><ref type="bibr" coords="4,180.82,466.13,7.57,10.91" target="#b6">7]</ref>.</p><p>Images were visually assessed and split into those with accurate colouring and contrast, those with a heavy green tint and those with a heavy blue tint. Accurate images were not altered in any way. Green and blue images were passed through an RGB histogram leveller followed by an RGB channel mixer, generalised to green or blue images for speed (Fig. <ref type="figure" coords="4,416.65,520.33,3.52,10.91" target="#fig_2">3</ref>). This would allow all the images to be processed easily but would not allow for image-specific editing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Data augmentation</head><p>Before training the model, each image was cropped into 12 squares which were each then cropped at a random point to a 480px square. Random horizontal flips were also utilized due to the limited amount of data. These pre-processing techniques are used to present the model with different iterations of the same images, increasing the size of the data set available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">The test set</head><p>The provided test set included 485 unannotated images from 4 different regions:</p><p>Region 1: The training set location. Region 2: A geographically and biologically similar region. Region 3: A geographically distinct but biologically similar region. Region 4: A region that is both geographically and biologically distinct.</p><p>The test images were also cropped into 12 squares to match the training images used on the model. Each test image was then resized to a 520px square, which allowed us to predict all test images despite system limitations.</p><p>The predicted pixel array of each test image had to be resized to its original dimensions before submission to match the ground truth annotation mask. This was carried out using spline interpolation through the zoom function in SciPy <ref type="foot" coords="5,338.38,251.28,3.71,7.97" target="#foot_0">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The model</head><p>We used the DeepLabV3 model based on a previous submission <ref type="bibr" coords="5,364.44,311.66,11.27,10.91" target="#b7">[8]</ref>. It makes use of a ResNet-101 backbone and the application of both atrous convolution and Atrous Spatial Pyramid Pooling (ASPP). ResNet-101 is used for feature extraction before atrous convolution and ASPP are applied. Atrous convolution increases the field of view in the last layer of ResNet-101 by inserting 0-values between filter values used in the network layer <ref type="bibr" coords="5,380.36,365.85,16.15,10.91" target="#b12">[13]</ref>. The atrous rate utilised corresponds to the amount of 0-values inserted -the higher the rate, the bigger the field of view becomes. ASPP is then applied to assign a label to each pixel using 4 atrous convolution rates. This enables the model to utilise different aspects of the objects it is identifying, ensuring that when pixels are labelled the network has seen multiple perspectives of field of view.</p><p>The model was evaluated using different crop and batch sizes during training. Batch size 4 was used in each run as it had the best performance within our system limitations. A crop size of 480px was selected as, when combined with batch size 4, it provided the greatest overall accuracy (per mAP0.0 and mAP0.5) of all tested crop size combinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Submission</head><p>Each team in the competition were allowed to submit up to 10 runs per task using the collaboration platform AICrowd<ref type="foot" coords="5,203.40,544.67,3.71,7.97" target="#foot_1">4</ref> . We chose to submit 4 files to the pixelwise-parsing subtask only, representing 4 individual runs: MTRU1: the "baseline" run, using the 2019 submission <ref type="bibr" coords="5,360.92,578.70,12.97,10.91" target="#b7">[8]</ref> that was rewritten and finetuned by experimenting on crop √ó batch size combinations. Batch size 4 with crop size 480 were found to give the best results and were used in this run.</p><p>MTRU2: the edited ImageCLEF run, using the same settings as MTRU1. Poorly coloured training images were enhanced to represent more accurate coloring of the coral reefs. MTRU3: the NOAA run, using additional data from NOAA in three different substrates. The images were not enhanced or edited in any way, and the same settings from MTRU1 were used. MUTR4: the fully edited run, using same settings as MTRU1, with both the additional NOAA data and image colour enhancements where needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Self-intersecting polygons</head><p>All 4 runs predicted some images containing self-intersecting polygons. These polygons invalidate a run and are not permitted in the submission file so must be removed. The evaluation script was used to identify any images with self-intersecting polygons and the substrate type of the polygon. This process involved removing each polygon of the relevant substrate type one by one, re-running the evaluation script each time to check if the error was resolved. Initial images were checked polygon by polygon in this manner to minimise any impact on model accuracy but the time constraints of the challenge required faster processing of the latter runs. Images in these runs were checked in polygon "batches", where several at a time would be deleted before running the evaluation script. While this did increase the speed of evaluation before submission, it is likely that a significant proportion of the deleted polygons were not self-intersecting and as such the mean average precision (mAP) of the runs would be both lower and less accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Blank predictions</head><p>3 of the 4 runs (MTRU2, MTRU3 and MTRU4) predicted images with no substrate classes. While clearly an error as all images were of coral reef substratum, these predictions were a part of our model outcome and therefore our submitted runs. The evaluation script used upon submission blocks these images and deem runs with them a failure so each had to be altered. As all images from the test set must be used, the blank images could not be removed. Our solution to this was to include a small square annotation in the center of the blank images and label it as Fire Coral -Millepora. This class was used as it had the lowest number of annotations and had no additional images added from NOAA images so was likely to be the least accurate class, limiting the effect on overall accuracy as much as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and discussion</head><p>Results provided by ImageCLEFcoral after submission used 2 metrics. mAP0.5 showed the localised mean average precision using IoU ‚â• 0.5. Accuracy per substrate calculated the segmenation accuracy as the number of correctly labelled pixels of class over the number of pixels labeled with class in ground truth.</p><p>Overall results of the pixel-wise parsing subtask (Table <ref type="table" coords="6,358.78,655.12,4.25,10.91" target="#tab_0">1</ref>) show that our runs were less accurate and precise than the other participant team. When considering the accuracy per class, however, there were some substrate categories that were better predicted by our model.</p><p>Across the MTRU runs, we saw the highest accuracy of submassive coral, table coral and foliose coral predictions when images run unedited and without additional NOAA data. The greatest prediction accuracy of boulder corals and algae across the subtask occurred when images were colour corrected, and of gorgonian soft corals occurred when unedited ImageCLEF data and NOAA data were used. MTRU3 was the only instance of gorgonian predictions with positive accuracy (0.002%) across all submissions. Similarly, MTRU1 was the only instance of positive accuracy in foliose coral prediction (0.097%). None of our runs predicted mushroom corals, sponges, barrel sponges or fire coral accurately.</p><p>Of our runs, the greatest precision was seen in MTRU1 (mAP0.5 = 0.021), though it did not have the highest accuracy (2.767%). MTRU4 was most accurate (2.951%) despite having the lowest overall precision (mAP0.5 = 0.011). Overall precision and average accuracy were also lower than the 2019 run of this model <ref type="bibr" coords="7,491.98,538.45,11.41,10.91" target="#b7">[8]</ref>, however we did show improvement in the prediction of submassive corals (MTRU1 = 0.030221, 2019 = 0) and table corals (MTRU1 = 0.0.003534, 2019 = 0), neither of which were predicted with any accuracy in 2019.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Image colour enhancement</head><p>The colour adjustments made to the images increased the prediction accuracy of boulder corals, encrusting corals and algae (Table <ref type="table" coords="7,272.54,642.37,3.52,10.91" target="#tab_0">1</ref>). For boulder corals, colour enhancement may have distinguished them from other reef substrates and enabled greater recognition of the coral over rocks and other substratum that they can easily resemble. Encrusting corals would benefit for the same reasons. Algae would likely show improvement with colour enhancement due to the removal of green image tints, which would allow the natural green of the algae to become more defined and clear. Brown and red algae would also benefit from the red channel correction to make them more distinct from surrounding substrate.</p><p>Submassive corals were less accurately predicted with image enhancement, as well as table corals, foliose corals, soft corals and gorgonians. Any loss in predictive power is likely due to the general nature of the colour correction performed. While some images would improve with the balancing and mixing at the levels set, others may have had colour blow outs or excessive input from one or more RGB channels. This could have a blur-like effect, wherein neighbouring substrate categories look indistinct from each other due to a lack of colour definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Augmenting annotations with NOAA data</head><p>The NOAA data used was from a different location than the ImageCLEF data which could greatly impact mAP0.5 and prediction accuracy as substrates from different geographic regions can show vastly different morphologies. Of the 2 categories with increased annotations from the NOAA data set, encrusting corals saw a greater accuracy while foliose corals had less prediction accuracy. Encrusting corals are very similar globally despite varying conditions, so increasing the number of annotations would likely improve the models predictive power by adding distinctive pixels to train on. This is not the case with foliose corals, which are more likely to show differing morphologies as they are not flat to the substrate. Foliose corals also have extensive structures that often appear layered and often appear to have many shadows that could hamper the training capabilities of the model. Any shadows would look like black, probably with a flat texture, regions of the image. These would provide no benefit to the model and may cause it to relate any dark spots to foliose corals or to fail to recognise them at all.</p><p>Adding NOAA data had a detrimental effect on the accuracy of most other substrate categories. Where a prediction accuracy &gt; 0 without NOAA data (MTRU1 and MTRU2), adding NOAA annotations reduced the prediction accuracy of submassive, boulder, and table corals as well as algae. This could occur if the additional NOAA annotations skewed the models perception of each category and altered the predictions made as a result. Accuracy also decreased for branching corals between MTRU1 and MTRU3 (unedited images), but increased between the colour enhanced runs (MTRU2 and MTRU4) by 5.026%. Predictions were also more accurate for soft coral (+0.228%) and gorgonians (+0.002%) when NOAA data was added but no colour enhancement was performed. These substrate categories can form more distinct morphologies across all locations that may have become more distinct with an increasingly balanced data set at the expense of the other classes. Although the soft coral category encompasses several distinct organisms with different morphologies, the abundance of annotations likely compensated by providing many examples of each structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Image colour enhancements can increase the accuracy of coral reef substrate predictions when those substrates are otherwise difficult to distinguish from the surrounding environment. It can also be detrimental when the editing performed is generalised instead of image specific.</p><p>Similarly, augmenting the training data set with NOAA annotations can improve the predictions of substrates that are either morphologically general across different geographical regions or those that form distinct structures despite changing geography. Large increases in the number of annotations should be reflected in a subsequent increase of accuracy in the represented classes. When this does not occur, the abundance of data can impair the predictive power of the model by blurring the line between substrate categories through incorrect annotation or by skewing the predictions made as a result of an imbalanced data set.</p><p>A combination of an augmented data set with distinct image enhancement pathways for either different geographic locations or substrate categories may provide a more accurate and precise prediction array. Combining these steps with improved hyperparameters would enhance model performance and provide a coral reef substrate prediction tool that would be applicable to reefs across the globe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Limitations of the model</head><p>The use of a dedicated GPU greatly increases the computational power of machine learning models. Training time can then be diminished and hyperarameters can be improved. The machine we used to run our model was affected by a lack of GPU memory, which can only be rectified by changing the graphics card to a more powerful one. The memory limitation heavily impacted batch sizes testing, limiting tests to batch size 4 at most. DeepLabV3 works best with a batch size of 16 (demonstrated on the PASCAL VOC data set <ref type="bibr" coords="9,369.15,353.48,15.73,10.91" target="#b12">[13]</ref>). Using a computer with a better GPU would allow for a greater batch size to be used which would improve the model parameters and strengthen the power of the predictions.</p><p>In the future we plan to include a greater volume of NOAA data when training the model. This would both increase the number annotations per class across the training data. More specific pixel expansion would have also enabled us to be more precise in training and may have provided more pixels per class than otherwise achieved. A potential method could have different expansion shapes set by class (i.e. boulder coral expands as a circle) and a pixel selection/rejection threshold based on annotated pixel value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Improving the approach</head><p>Images and predictions would likely benefit from a more tailored colour correction approach. This could be performed with the commonly used Rayleigh distribution <ref type="bibr" coords="9,413.89,525.15,16.49,10.91" target="#b11">[12,</ref><ref type="bibr" coords="9,433.11,525.15,12.57,10.91" target="#b13">14,</ref><ref type="bibr" coords="9,448.41,525.15,14.07,10.91" target="#b14">15]</ref> or with a different approach such as red channel weighted compensations <ref type="bibr" coords="9,382.51,538.70,18.06,10.91" target="#b15">[16]</ref> that leverage the other colour input channels to colour balance an image with accuracy.</p><p>Leveraging the results from this approach, developing a staggered pipeline may improve prediction accuracy in the future. A bounding box approach to gain a generalised location of each substrate could be used to then send images through different processing steps, such as colour correction, blur reduction, contrast changes, etc, based on the class found. This could then feed into a pixel-wise prediction model to find precise location of substrate classes within an image.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,258.66,397.36,8.93;2,89.29,103.12,197.94,148.11"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of reef images (a) without and (b) with morphological substrate annotations.</figDesc><graphic coords="2,89.29,103.12,197.94,148.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,368.04,416.70,9.15;3,89.29,380.00,386.99,9.14"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Substrate annotations in the ImageCLEF training set of 879 images (n = 21, 748; green), and in the training set when combined with an additional 502 NOAA images (n = 22, 403; orange).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,89.29,317.90,416.70,8.93;4,89.29,329.91,416.70,8.87;4,89.29,341.86,416.70,8.87;4,89.29,353.82,418.23,8.87;4,89.29,216.76,124.95,93.71"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Transformation of (a) a green and (d) blue image through 2 stages to an image used in training. Each image had (b,e) balanced RGB levels, then (c,f) when through a generalised channel mixing process to balance the colors while maintaining image contrast. The leveling and mixing were selected to optimise substrate color and contrast with less focus on the background and water colouring.</figDesc><graphic coords="4,89.29,216.76,124.95,93.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,88.99,265.02,418.66,254.68"><head>Table 1</head><label>1</label><figDesc>Overall precision (mAP0.5), average accuracy (%) and substrate class accuracy (%) of pixel-wise parsing subtask submissions to ImageCLEFcoral 2021 (4 MTRU runs, 1 run from team Pilsen Eyes that performed best overall). The best scores for each category are shown in orange.</figDesc><table coords="7,103.34,320.54,388.59,199.15"><row><cell>Category</cell><cell>MTRU1</cell><cell>MTRU2</cell><cell>MTRU3</cell><cell>MTRU4</cell><cell>Pilsen Eyes</cell></row><row><cell>mAP0.5</cell><cell>0.021</cell><cell>0.018</cell><cell>0.017</cell><cell>0.011</cell><cell>0.075</cell></row><row><cell>Average accuracy</cell><cell>2.767</cell><cell>2.531</cell><cell>1.942</cell><cell>2.951</cell><cell>6.147</cell></row><row><cell>Hard Coral -Branching</cell><cell>1.090</cell><cell>2.299</cell><cell>0.536</cell><cell>5.562</cell><cell>11.095</cell></row><row><cell>Hard Coral -Submassive</cell><cell>3.022</cell><cell>0.279</cell><cell>1.036</cell><cell>0.039</cell><cell>2.704</cell></row><row><cell>Hard Coral -Boulder</cell><cell>9.607</cell><cell>12.787</cell><cell>7.601</cell><cell>8.827</cell><cell>5.385</cell></row><row><cell>Hard Coral -Encrusting</cell><cell>0.017</cell><cell>2.595</cell><cell>0.729</cell><cell>2.429</cell><cell>2.615</cell></row><row><cell>Hard Coral -Table</cell><cell>0.353</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.008</cell></row><row><cell>Hard Coral -Foliose</cell><cell>0.097</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Hard Coral -Mushroom</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Soft Coral</cell><cell>0</cell><cell>0</cell><cell>0.228</cell><cell>0</cell><cell>50.433</cell></row><row><cell>Gorgonian</cell><cell>0</cell><cell>0</cell><cell>0.002</cell><cell>0</cell><cell>0</cell></row><row><cell>Sponge</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.625</cell></row><row><cell>Barrel Sponge</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.329</cell></row><row><cell>Fire Coral -Millepora</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Algae</cell><cell>0</cell><cell>0.027</cell><cell>0</cell><cell>0</cell><cell>1.0ùëí -4</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="5,108.93,660.04,287.27,8.97"><p>https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.zoom.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,108.93,671.00,97.91,8.97"><p>https://www.aicrowd.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank the team that developed the 2019 base code that we used [8], particularly <rs type="person">Antonio Campello</rs> for his support and advice throughout this process. We would also like to thank <rs type="institution">NOAA</rs> and the MTRU team of participants at the 2020 NOAA hackathon https://www. gpuhackathons.org/event/noaa-gpu-hackathon, when we began working on this project.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,210.55,393.33,10.91;10,112.66,224.10,132.09,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,212.90,210.55,234.43,10.91">Ecological goods and services of coral reef systems</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Moberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Folke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,459.51,210.55,46.48,10.91;10,112.66,224.10,48.15,10.91">Ecological Economics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="215" to="233" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,237.65,393.33,10.91;10,112.66,251.20,196.49,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,285.19,237.65,182.73,10.91">The origins of tropical marine biodiversity</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bowen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Toonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,475.78,237.65,30.21,10.91;10,112.66,251.20,112.56,10.91">Trends in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,264.75,393.33,10.91;10,112.66,278.30,393.60,10.91;10,112.66,291.85,344.03,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,451.50,264.75,54.49,10.91;10,112.66,278.30,393.60,10.91;10,112.66,291.85,172.16,10.91">Coupling of palaeontological and neontological reef coral data improves forecasts of biodiversity responses under global climatic change</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mannion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Farnsworth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Valdes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kelland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">A</forename><surname>Allison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,293.61,291.85,123.36,10.91">Royal Society Open Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,305.40,393.33,10.91;10,112.66,318.95,246.63,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wilkinson</surname></persName>
		</author>
		<title level="m" coord="10,206.78,305.40,219.78,10.91">Methods for Ecological Monitoring of Coral Reefs</title>
		<meeting><address><addrLine>Townsville, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Australian Institute of Marine Science</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>1 ed</note>
</biblStruct>

<biblStruct coords="10,112.66,332.50,394.53,10.91;10,112.28,346.05,393.71,10.91;10,112.66,359.59,70.45,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,112.28,346.05,253.39,10.91">Automatic annotation of coral reefs using deep learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Boussaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hovey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kendrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,390.37,346.05,115.61,10.91;10,112.66,359.59,40.03,10.91">OCEANS 2016 MTS/IEEE Monterey</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,373.14,395.01,10.91;10,112.66,389.13,97.35,7.90" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,220.55,373.14,251.01,10.91">An Introduction to Convolutional Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nash</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08458</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,400.24,393.33,10.91;10,112.66,413.79,393.33,10.91;10,112.66,427.34,191.99,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,227.39,400.24,278.60,10.91;10,112.66,413.79,160.71,10.91">Coral reef annotation, localisation and pixel-wise classification using Mask R-CNN and Bag of Tricks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>≈ò√≠ha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zita</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,295.40,413.79,109.66,10.91">CLEF2020 Working Notes</title>
		<title level="s" coord="10,480.56,414.81,25.43,9.72;10,112.66,427.34,122.99,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,440.89,393.32,10.91;10,112.66,454.44,393.33,10.91;10,112.66,467.99,321.33,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,387.54,440.89,118.44,10.91;10,112.66,454.44,279.70,10.91">Deep segmentation: Using deep convolutional networks for coral reef pixel-wise parsing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Steffens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ravenscroft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hagras</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,417.78,454.44,88.21,10.91;10,112.66,467.99,23.42,10.91">CLEF2019 Working Notes</title>
		<title level="s" coord="10,213.84,467.99,151.15,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,481.54,394.52,10.91;10,112.66,495.09,393.33,10.91;10,112.66,508.64,220.14,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,112.66,495.09,177.53,10.91">Overview of ImageCLEFcoral 2019 task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Clift</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garc√≠a Seco De Herrera</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,314.23,495.09,114.81,10.91">CLEF2019 Working Notes</title>
		<title level="s" coord="10,112.66,508.64,151.15,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,522.18,394.52,10.91;10,112.66,535.73,394.62,10.91;10,112.66,549.28,394.53,10.91;10,112.66,562.83,22.69,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,112.66,535.73,374.41,10.91">Overview of the ImageCLEFcoral 2020 task: Automated coral reef image annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Clift</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garc√≠a Seco De Herrera</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,112.66,549.28,115.49,10.91">CLEF2020 Working Notes</title>
		<title level="s" coord="10,309.43,549.28,153.31,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,576.38,395.17,10.91;10,112.66,589.93,393.33,10.91;10,112.66,603.48,394.52,10.91;10,112.66,617.03,116.58,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,145.70,589.93,360.29,10.91;10,112.66,603.48,53.89,10.91">Overview of the ImageCLEFcoral 2021task: Coral reef image annotation of a 3d environment</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garc√≠a Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Moustahfid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,189.88,603.48,110.50,10.91">CLEF2021 Working Notes</title>
		<title level="s" coord="10,307.73,603.48,172.68,10.91">CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,630.58,395.17,10.91;10,112.66,644.13,394.53,10.91;11,112.66,86.97,394.52,10.91;11,112.66,100.52,22.69,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,375.95,630.58,131.87,10.91;10,112.66,644.13,390.27,10.91">The effects of colour enhancement and IoU optimisation on object detection and segmentation of coral reef structures</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>R√ºckert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Br√ºngel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Brumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Friedrich</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,127.06,86.97,110.25,10.91">CLEF2020 Working Notes</title>
		<title level="s" coord="11,313.77,86.97,150.66,10.91">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,114.06,393.53,10.91;11,112.66,127.61,262.56,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,342.80,114.06,163.38,10.91;11,112.66,127.61,132.16,10.91">Rethinking Atrous Convolution for Semantic Image Segmentation</title>
		<author>
			<persName coords=""><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,141.16,393.33,10.91;11,112.66,154.71,336.07,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,236.25,141.16,269.74,10.91;11,112.66,154.71,212.86,10.91">Underwater image quality enhancement through composition of dual-intensity images and rayleigh-stretching</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Abdul</forename><surname>Ghani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Mat</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,333.83,154.71,57.23,10.91">SpringerPlus</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">757</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,168.26,393.33,10.91;11,112.66,181.81,369.22,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,239.56,168.26,266.42,10.91;11,112.66,181.81,168.48,10.91">Underwater image quality enhancement through integrated color model with rayleigh distribution</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Abdul</forename><surname>Ghani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Mat</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,289.27,181.81,108.68,10.91">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,195.36,393.32,10.91;11,112.66,208.91,393.33,10.91;11,112.41,222.46,70.16,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,301.65,195.36,204.33,10.91;11,112.66,208.91,269.82,10.91">Underwater image enhancement based on red channel weighted compensation and gamma correction model</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,391.25,208.91,114.73,10.91">Opto-Electronic Advances</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">180024</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
