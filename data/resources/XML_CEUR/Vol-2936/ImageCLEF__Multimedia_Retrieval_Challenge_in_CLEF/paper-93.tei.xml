<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.03,75.53,450.65,17.00;1,72.03,96.28,293.43,17.00">ImageCLEF 2021: Deep categorizing tuberculosis cases using normalization and pseudo-color CT image</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.03,129.35,84.80,10.80"><forename type="first">Tetsuya</forename><surname>Asakawa</surname></persName>
							<email>asakawa@kde.cs.tut.ac.jp</email>
							<affiliation key="aff3">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.83,129.35,67.06,10.80"><forename type="first">Riku</forename><surname>Tsuneda</surname></persName>
							<email>tsuneda@kde.cs.tut.ac.jp</email>
						</author>
						<author>
							<persName coords="1,243.85,129.35,77.51,10.80"><forename type="first">Kazuki</forename><surname>Shimizu</surname></persName>
							<email>shimizu@heart-center.or.jp</email>
						</author>
						<author>
							<persName coords="1,331.65,129.35,90.07,10.80"><forename type="first">Takuyuki</forename><surname>Komoda</surname></persName>
							<email>komoda@heart-center.or.jp</email>
							<affiliation key="aff2">
								<orgName type="institution">Toyohashi Heart center</orgName>
								<address>
									<addrLine>21-1 Gobutori Tenpaku</addrLine>
									<settlement>Oyama, Toyohashi</settlement>
									<region>Aichi</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,449.45,129.35,64.99,10.80"><forename type="first">Masaki</forename><surname>Aono</surname></persName>
							<email>aono@tut.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyohashi University of Technology</orgName>
								<address>
									<addrLine>1-1</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Hibarigaoka Tenpaku</orgName>
								<address>
									<settlement>Toyohashi</settlement>
									<region>Aichi</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.03,75.53,450.65,17.00;1,72.03,96.28,293.43,17.00">ImageCLEF 2021: Deep categorizing tuberculosis cases using normalization and pseudo-color CT image</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0A5D839AD452EEB03712110BDD95E235</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tuberculosis</term>
					<term>Deep Learning</term>
					<term>Normalization</term>
					<term>Pseudo-color</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ImageCLEF 2021 Tuberculosis task is an example of a challenging research problem in the field of computed tomography (CT) image analysis. The purpose of this study is to make accurate estimates for five labels (infiltrative, focal, tuberculoma, miliary, and fibrocavernous) based on lung images. We describe the tuberculosis task and approach for chest CT image analysis and then perform a single-label CT image analysis using the task dataset. We propose an image processing and fine-tuning deep neural network model that uses inputs from convolutional neural network features. This paper presents several approaches for applying normalization and pseudo-color to the extracted 2D images, for applying mask data to the extracted 2D image data, and for extracting a set of 2D projection images based on the 3D chest CT data. Our submissions for the task test dataset achieved an unweighted Cohen's kappa of 0.117 and an accuracy of 0.382.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the spread of various diseases (e.g., tuberculosis (TB), COVID-19, and influenza), medical research has been performed to develop and implement the necessary treatments for viruses. However, there is no method currently available to identify such diseases early. An early diagnosis method is needed to provide the necessary treatment, develop specific medicines, and prevent the deaths of patients.</p><p>Accordingly, a significant amount of effort has been invested in medical image analysis research in recent years. In fact, a task dedicated to TB has been adopted as part of the ImageCLEF evaluation campaign for the five last years <ref type="bibr" coords="1,244.91,519.78,12.46,10.00" target="#b0">[1]</ref>[2][3][4] <ref type="bibr" coords="1,294.74,519.78,12.46,10.00" target="#b4">[5]</ref>. In ImageCLEF 2021 the main task <ref type="bibr" coords="1,507.47,519.78,11.43,10.00" target="#b5">[6]</ref>, "ImageCLEFmed Tuberculosis," is treated as a computed tomography (CT) report. The goal of this subtask is to automatically categorize each TB case into one of the following five types: infiltrative, focal, tuberculoma, miliary, or fibrocavernous. Accordingly, the goal of this study is to automatically categorize the TB type from 3D CT images of TB patients.</p><p>In this paper, we employ a new fine-tuning neural network model that uses features extracted by pretrained convolutional neural network (CNN) models as input. The existing CNN model had weak classifications; therefore, we propose a new fully connected two layers. The new contributions of this paper are the proposition of novel feature building techniques, the incorporation of features from the proposed CNN model, and the use of several forms of pre-processing to predict TB from the images. In Section 2, we describe the conducted task and the ImageCLEF2021 dataset. In Section 3, we introduce the image pre-processing, experimental settings, and features used in this study. In Section 4, we describe the experiments we performed. In Section 5, we provide our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ImageCLEF 2021 Dataset</head><p>The TB task of the ImageCLEF 2021 Challenge included partial 3D patient chest CT images <ref type="bibr" coords="2,507.23,145.04,11.43,9.90" target="#b6">[7]</ref>. The dataset contained the chest CT scan imaging data, including 917 images for the training (development) dataset and 421 images for the test dataset. Some of the scans include additional metainformation, which may vary depending on data availability for different cases. Each CT image corresponds to only one TB type. In this edition, each CT scan corresponds to one patient. Using the CT image data, our goal is to automatically extract and categorize each TB case into one of the following five types: (1) Infiltrative, (2) Focal, (3) Tuberculoma, (4) Miliary, <ref type="bibr" coords="2,368.03,221.07,12.90,9.90" target="#b4">(5)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>We propose a single-label analysis system to predict the TB type from CT scan images. The first step is input data pre-processing. After introducing our pre-processing of the input data, we describe our deep neural network model, which enables single-label outputs given the CT scan images. In addition, optionally in the first step, we can use a CT scan movie instead of CT scan images. We detail our proposed system in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Input data pre-processing</head><p>The 3D CT scans in the training and test datasets are provided in compressed Nifti format. We decompressed the files and extracted the slices along the z-axis of the 3D image, as shown in fig. <ref type="figure" coords="2,496.85,565.80,4.13,10.00" target="#fig_0">1</ref>. For each Nifti image, we obtained a number of slices, according to the dimensions, ranging from 110 to 250 images for the z-dimension. After extracting the slices along the z-axis, we filtered the slices of each patient using mask1 and mask2 data <ref type="bibr" coords="2,236.67,603.91,11.99,9.90" target="#b7">[8]</ref> <ref type="bibr" coords="2,248.67,603.91,11.99,9.90" target="#b8">[9]</ref>. The mask1 data provide more accurate masks but tend to miss large abnormal regions of the lungs in the most severe TB cases. The mask2 data provide more rough bounds but behave more stably in terms of including lesion areas. We extracted the filtered CT scan images. We noticed that all slices contain relevant information, including bone, space, fat, and skin, in addition to the lungs that could help classify the samples. This is why we added a step to the filter and selected a number of slices per patient. We call this data the Applying mask CT data.</p><p>In addition, as shown in fig. <ref type="figure" coords="2,214.22,679.58,4.13,10.00" target="#fig_1">2</ref>, we implemented pseudo-color on the normalization mask CT data. We call this data the normalization mask CT data.</p><p>In addition, as shown in fig. <ref type="figure" coords="2,214.18,704.83,4.13,10.00" target="#fig_2">3</ref>, we perform pseudo color for normalization mask CT data. We call this data pseudo color CT data.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Proposed deep neural network model</head><p>To solve this single-label problem, we propose fine-tuning neural network models that allow inputs coming from end-to-end CNN features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Training and Validation sets</head><p>The training dataset consists of 107,955 and 105,494 images extracted from the applying mask1 and mask2 CT datasets, respectively, for the z-axis.</p><p>We divided the training dataset at random into training and validation datasets with a ratio of 8:2. The CNN features were extracted using pre-trained CNN-based neural networks, including EfficientNet B05. To deal with the above features, we propose a deep neural network architecture.</p><p>Our system incorporates CNN features, which can be extracted using deep CNNs pre-trained on ImageNet <ref type="bibr" coords="4,117.75,679.19,18.21,9.90" target="#b9">[10]</ref> such as EffcientNet B05 <ref type="bibr" coords="4,239.95,679.19,19.50,9.90" target="#b10">[11]</ref>. Because of the lack of datasets in visual sentiment analysis, we adopted transfer learning for the feature extraction to prevent overfitting. We decreased the dimensions of the fully connected layers used in the CNN models. In addition, we extracted the vector to 2048 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Training and Validation sets and Test data</head><p>We employed the unweighted Cohen's kappa and accuracy to fine-tune the above CNN model. As illustrated in fig. <ref type="figure" coords="5,176.24,118.43,4.13,10.00" target="#fig_3">4</ref>, the CNN features are combined and represented by an integrated feature as a linearly weighted average, where the weights are w3 for the CNN features. The features are passed through "Fusion" processing to generate the integrated features, followed by a "softmax" activation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Single-label probability</head><p>We propose the method illustrated in Algorithm 1. The input is a collection of features extracted from each image with K types of diseases, while the output is a K-dimensional hot vector.</p><p>In Algorithm 1, we assume that the extracted CNN features are represented by their probabilities. For each TB case, we sum the features, followed by the median of the result, which is denoted as Ti k in Algorithm 1. In short, the vector Si represents the output of each hot vector. We repeat this computation until all the test (unknown) images are processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments 4.1. Unweighted Cohen's Kappa and Accuracy of training and validation sets</head><p>The training dataset consists in Applying mask1 and mask2 CT data, and the normalization mask1 and mask2 CT data. The training dataset consists of 105 494,107 955 images extracted for the mask1 and mask2 CT data respectively.</p><p>Here, we have divided the filtering data into training and validation datasets with a ratio of 8:2. We determined the following hyper-parameters: the batch size is 256, the optimization function is stochastic gradient descent with a learning rate of 0.001 and a momentum of 0.9, and the number of epochs is 200. For the implementation, we employed Tensorflow <ref type="bibr" coords="5,291.39,457.75,19.46,10.00" target="#b11">[12]</ref> as our deep learning framework.</p><p>For the evaluation of the single-label classification, we employed the un-weighted Cohen's kappa and the accuracy. Table <ref type="table" coords="5,178.46,483.03,5.50,10.00" target="#tab_1">2</ref> shows the results. finally, we employed EfficientNet B05 for the training and validation datasets and the test data. The results are given in Section (4.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results for the training and validation datasets and the test data using our proposed model</head><p>The test dataset consisted of 59 835 and 60 758 images extracted from the applying mask1 and mask2 CT data, respectively, as show in Table <ref type="table" coords="6,279.95,364.34,4.13,9.90" target="#tab_2">3</ref>.</p><p>It is likely that our proposed models will give better results after more advanced data pre-processing including the use of several types of CT images and data augmentation. Here as described above, we employed fine-tuning CNN models in EfficientNet B05 based on several pre-processing methods.</p><p>Table <ref type="table" coords="6,114.50,415.00,5.50,10.00" target="#tab_3">4</ref> shows the results. Here, we compare the results in terms of the unweighted Cohen's kappa and the accuracy. For mask1 and normalization on fine-tuning EfficientNet B05, our proposed CNN model has good values of un-weighted Cohen's kappa and accuracy.</p><p>In addition, results of the other participants' submissions with their un-weighted Cohen's kappa and accuracy are shown in Table <ref type="table" coords="6,199.22,465.53,4.13,10.00" target="#tab_4">5</ref>. Here, we compare the results in terms of the unweighted Cohen's kappa and the accuracy.</p><p>For our team, KDE-lab, our proposed CNN model has the best unweighted Cohen's kappa and accuracy.</p><p>The results achieved by our submissions are well ranked compared to those at the top of the list given in Table <ref type="table" coords="6,139.72,528.89,4.13,9.90" target="#tab_4">5</ref>. Note that several runs in the table belong to the same teams and likely do not differ significantly. In terms of the unweighted Cohen's kappa, our model ranks 8th. In terms of the accuracy, our model ranks 7th. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this study, we proposed image pre-processing and a CNN model for predicting five labels (infiltrative, focal, tuberculoma, miliary, and fibrocavernous) from chest CT images. We performed a lung CT image analysis in which we proposed a deep neural network model that enabled the inputs to be derived from the CNN features. To predict the five labels, we introduced a threshold-based singlelabel prediction algorithm.</p><p>Specifically, after training our deep neural network using the pre-processed images, we were able to predict the categories of the five types of TB cases from unknown CT scan images. The experimental results demonstrate that our proposed models out-perform some models in terms of the unweighted Cohen's kappa and the accuracy. For the unweighted Cohen's kappa, our model achieved a good value. As a consequence, we believe that using normalization to pre-process an image is effective.</p><p>In the future, given an arbitrary X-ray, CT, echo, or magnetic resonance imaging image might be included the optimal weights for the neural networks. Moreover, we hope our proposed model will encourage further research into the early detection of diseases (such as TB, COVID-19, and influenza) or unknown diseases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgment</head><p>A part of this research was carried out with the support of the Grant for Toy-ohashi Heart Center Smart Hospital Joint Research Course and the Grant for Education and Research in Toyohashi University of Technology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.03,328.35,276.90,11.00;3,86.20,339.43,451.00,253.70"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pre-processing of the input data applying mask data.</figDesc><graphic coords="3,86.20,339.43,451.00,253.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,72.03,595.67,278.48,11.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pre-processing of the input data using normalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,72.03,328.35,274.65,11.00;4,86.20,72.00,451.00,253.70"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Pre-processing of the input data using pseudo color.</figDesc><graphic coords="4,86.20,72.00,451.00,253.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,72.03,544.15,243.13,11.00;4,86.20,409.82,430.46,132.00"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Our proposed method for feature extraction.</figDesc><graphic coords="4,86.20,409.82,430.46,132.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,72.03,221.07,451.04,160.03"><head></head><label></label><figDesc>fibrocavernous Table 1 lists the labels for the chest CT scan in the training dataset.</figDesc><table coords="2,72.03,258.58,379.63,122.52"><row><cell>Table 1</cell><cell></cell></row><row><cell cols="2">Presence of labels for the chest CT scan in the training dataset.</cell></row><row><cell>Label</cell><cell>In Training set (number of patients)</cell></row><row><cell>Infiltrative</cell><cell>420</cell></row><row><cell>Focal</cell><cell>226</cell></row><row><cell>Tuberculoma</cell><cell>101</cell></row><row><cell>Miliary</cell><cell>100</cell></row><row><cell>fibrocavernous</cell><cell>70</cell></row><row><cell>Total</cell><cell>917</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,72.03,520.65,451.07,151.55"><head>Table 2</head><label>2</label><figDesc>Unweighted Cohen's Kappa and Accuracy of training and validation sets for fine-tuning EfficientNet B05.</figDesc><table coords="5,89.05,563.17,424.36,109.03"><row><cell>Mask</cell><cell>Pre-processing</cell><cell>Unweighted Cohen's</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>Kappa</cell><cell></cell></row><row><cell></cell><cell>applying mask</cell><cell>0.213</cell><cell>0.443</cell></row><row><cell>mask1</cell><cell>applying mask and normalization</cell><cell>0.199</cell><cell>0.443</cell></row><row><cell></cell><cell>applying mask, normalization, pseudo color</cell><cell>0.215</cell><cell>0.475</cell></row><row><cell></cell><cell>applying mask</cell><cell>0.215</cell><cell>0.495</cell></row><row><cell>mask2</cell><cell>applying mask and normalization</cell><cell>0.244</cell><cell>0.489</cell></row><row><cell></cell><cell>applying mask, normalization, pseudo color</cell><cell>0.183</cell><cell>0.448</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.03,74.28,421.70,196.80"><head>Table 3</head><label>3</label><figDesc>Numbers of images with the five labels for the chest CT scans in the training dataset.</figDesc><table coords="6,114.55,103.28,379.17,167.80"><row><cell>Mask</cell><cell>Pre-processing</cell><cell>In Training set (number of</cell></row><row><cell></cell><cell></cell><cell>images)</cell></row><row><cell></cell><cell>Infiltrative</cell><cell>49058</cell></row><row><cell></cell><cell>Focal</cell><cell>25722</cell></row><row><cell>mask1</cell><cell>Tuberculoma</cell><cell>11293</cell></row><row><cell></cell><cell>Miliary</cell><cell>11692</cell></row><row><cell></cell><cell>fibrocavernous</cell><cell>7729</cell></row><row><cell></cell><cell>Infiltrative</cell><cell>50035</cell></row><row><cell></cell><cell>Focal</cell><cell>26203</cell></row><row><cell>mask2</cell><cell>Tuberculoma</cell><cell>11552</cell></row><row><cell></cell><cell>Miliary</cell><cell>12030</cell></row><row><cell></cell><cell>fibrocavernous</cell><cell>8135</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,72.03,579.18,437.63,138.02"><head>Table 4</head><label>4</label><figDesc>Results of experiments for single-label classification.</figDesc><table coords="6,92.55,608.18,417.11,109.02"><row><cell>Mask</cell><cell>Pre-processing</cell><cell>Unweighted Cohen's</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>Kappa</cell><cell></cell></row><row><cell></cell><cell>applying mask</cell><cell>0.016</cell><cell>0. 382</cell></row><row><cell>mask1</cell><cell>applying mask and normalization</cell><cell>0.117</cell><cell>0.382</cell></row><row><cell></cell><cell>applying mask, normalization, pseudo color</cell><cell>0.069</cell><cell>0.371</cell></row><row><cell></cell><cell>applying mask</cell><cell>0.015</cell><cell>0.372</cell></row><row><cell>mask2</cell><cell>applying mask and normalization</cell><cell>0.085</cell><cell>0.375</cell></row><row><cell></cell><cell>applying mask, normalization, pseudo color</cell><cell>0.081</cell><cell>0.373</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,72.03,74.28,407.60,206.05"><head>Table 5</head><label>5</label><figDesc>The best participants' runs submitted for the CTR subtask.</figDesc><table coords="7,92.30,103.28,387.33,177.05"><row><cell>Group name</cell><cell>Rank</cell><cell>Unweighted Cohen's</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>Kappa</cell><cell></cell></row><row><cell>SenticLab.UAIC</cell><cell>1</cell><cell>0.221</cell><cell>0.446</cell></row><row><cell>hasibzunair</cell><cell>2</cell><cell>0.200</cell><cell>0.423</cell></row><row><cell>SDVA-UCSD</cell><cell>3</cell><cell>0.190</cell><cell>0.371</cell></row><row><cell>Emad-Aghajanzadeh</cell><cell>4</cell><cell>0.181</cell><cell>0.333</cell></row><row><cell>MIDL-NCAI-CUI</cell><cell>5</cell><cell>0.140</cell><cell>0.333</cell></row><row><cell>uaic2021</cell><cell>6</cell><cell>0.129</cell><cell>0.401</cell></row><row><cell>IALab PUC</cell><cell>7</cell><cell>0.120</cell><cell>0.401</cell></row><row><cell>KDE-Lab</cell><cell>8</cell><cell>0.117</cell><cell>0.381</cell></row><row><cell>JBTTM</cell><cell>9</cell><cell>0.038</cell><cell>0.221</cell></row><row><cell>Zhao_Shi_</cell><cell>10</cell><cell>0.015</cell><cell>0.380</cell></row><row><cell>YNUZHOU</cell><cell>11</cell><cell>-0.08</cell><cell>0.385</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,144.05,649.19,379.42,9.90;7,107.30,661.94,416.03,9.90;7,107.30,674.44,415.45,9.90;7,107.30,687.19,306.06,9.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,189.49,661.94,333.84,9.90;7,107.30,674.44,90.23,9.90">Overview of ImageCLEFtuberculosis 2017 -predicting tubercu-losis type and drug resistances</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cid</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Kalinovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="7,218.20,674.44,262.87,9.90">CLEF2017 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,144.05,699.83,379.02,10.01;7,107.30,712.33,415.74,10.00;7,107.30,725.21,416.14,9.90;7,107.30,737.71,415.31,9.90;7,107.30,750.46,415.88,9.90;8,107.30,74.77,415.78,9.90;8,107.30,87.27,416.14,9.90;8,107.30,100.02,234.10,9.90" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,107.30,750.46,295.46,9.90">Overview of ImageCLEF 2018: Challenges, datasets and evaluation</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Garc´ıa Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vas-Sili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Farri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Lun-Gren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,421.19,750.46,101.99,9.90;8,107.30,74.77,415.78,9.90;8,107.30,87.27,224.33,9.90">Experimental IR Meets Multilinguality, Multimodality, and Interac-tion, Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018)</title>
		<title level="s" coord="8,107.30,100.02,186.02,9.90">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">September 10-14 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,112.52,379.08,9.90;8,107.30,125.29,415.86,9.90;8,107.30,138.04,416.07,9.90;8,107.30,150.54,416.03,9.90;8,107.30,163.18,415.70,10.01;8,107.30,175.68,415.29,10.00;8,107.30,188.54,415.51,9.90;8,107.30,201.29,415.66,9.90;8,107.30,213.82,415.33,9.90;8,107.30,226.57,415.69,9.90;8,107.30,239.07,416.03,9.90;8,107.30,251.82,138.67,9.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,341.63,188.54,181.18,9.90;8,107.30,201.29,415.66,9.90;8,107.30,213.82,149.04,9.90">ImageCLEF 2019: Multimedia Retrieval in Medicine, Lifel-ogging, Security and Nature: Multimedia Retrieval in Medicine, Lifelogging, Secu-rity and Nature</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>P´eteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dzmitri</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sa-Did</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Gur-Rin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Narciso</forename><surname>Garc´ıa Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ergina</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Roberto Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Cuevas Rodr´ıguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantinos</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,276.48,213.82,246.15,9.90;8,107.30,226.57,64.76,9.90;8,250.50,226.57,272.49,9.90;8,107.30,239.07,113.27,9.90">Proceedings of the 10th International Conference of the CLEF Association (CLEF 2019)</title>
		<title level="s" coord="8,429.12,239.07,94.20,9.90;8,107.30,251.82,90.55,9.90">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF 2019)<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-12">September 9-12 2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,144.05,264.46,379.40,10.00;8,107.30,277.06,416.20,9.90;8,107.30,289.81,415.48,9.90;8,107.30,302.34,175.52,9.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,150.01,277.06,373.48,9.90;8,107.30,289.81,64.39,9.90">Medical image understanding: Overview of the ImageCLEFmed 2020 concept prediction task</title>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Garc´ıa Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hen-Ning</forename><surname>M¨uller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,191.24,289.81,227.39,9.90">CLEF2020 Working Notes, Workshop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,315.09,379.08,9.90;8,107.30,327.84,416.13,9.90;8,107.30,340.34,415.68,9.90;8,107.30,352.98,416.14,10.01;8,107.30,365.59,163.51,9.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,235.00,327.84,288.43,9.90;8,107.30,340.34,73.24,9.90">Overview of ImageCLEFtuberculosis 2021 -automatic CT-based report generation</title>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="8,198.02,340.34,324.97,9.90;8,107.30,352.98,202.69,10.00">Overview of ImageCLEF tuberculosis 2021 -CT-based Tuberculosis Type Classification, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">September 21-24 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,378.36,378.95,9.90;8,107.30,390.86,415.50,9.90;8,107.30,403.50,415.63,10.00;8,107.30,416.25,415.83,10.01;8,107.30,428.86,415.74,9.90;8,107.30,441.61,415.94,9.90;8,107.30,454.11,415.46,9.90;8,107.30,466.89,415.68,9.90;8,107.30,479.64,415.80,9.90;8,107.30,492.14,415.73,9.90;8,107.30,504.89,339.88,9.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,298.53,454.11,224.22,9.90;8,107.30,466.89,295.67,9.90">Overview of the ImageCLEF 2020: Multimedia Retrieval in Medical, Lifelogging, Nature, and Internet Applications</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>P´eteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Van-Tu</forename><surname>Garc´ıa Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tu-Khiem</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liting</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P˚al</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dim-Itri</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raul</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mi-Hai</forename><surname>Daniel S¸tefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Constantin</forename><surname>Gabriel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,420.99,466.89,101.99,9.90;8,107.30,479.64,212.24,9.90;8,412.45,479.64,110.65,9.90;8,107.30,492.14,305.54,9.90">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="8,213.33,504.89,185.77,9.90">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,144.05,517.39,379.08,9.90;8,107.55,530.14,415.89,9.90;8,107.55,542.89,415.58,9.90;8,107.55,555.41,306.06,9.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,233.76,530.14,289.68,9.90;8,107.55,542.89,73.26,9.90">Overview of ImageCLEFtuberculosis 2020 -auto-matic CT-based report generation</title>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="8,198.77,542.89,258.68,9.90">CLEF2020 Working Notes, CEUR Work-shop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,568.16,379.03,9.90;8,107.55,580.55,415.06,10.00;8,107.55,593.31,415.86,10.01;8,107.55,606.16,415.46,9.90;8,107.55,618.66,381.34,9.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,190.00,580.55,314.40,10.00">Efficient and fully automatic segmentation of the lungs in ct volumes</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oscar</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alfonso Jim´enez</forename><surname>Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,226.81,606.16,296.20,9.90;8,107.55,618.66,210.21,9.90">Proceedings of the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">Orcun</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Oscar</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alfonso Jim´enez</forename><surname>Del Toro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Antonio</forename><surname>Foncubierta-Rodr´ıguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>M¨uller</surname></persName>
		</editor>
		<meeting>the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI, CEUR Workshop Proceedings</meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,631.42,379.25,9.90;8,107.55,643.83,415.68,10.01;8,107.55,656.69,415.66,9.90;8,107.55,669.44,415.80,9.90;8,107.55,681.94,170.53,9.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,310.73,631.42,212.57,9.90;8,107.55,643.94,173.27,9.90">Imageclef 2017: Supervoxels and co-occurrence for tuberculosis CT image classification</title>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,240.97,656.69,282.25,9.90;8,107.55,669.44,77.39,9.90">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="8,445.36,669.44,77.99,9.90;8,107.55,681.94,82.76,9.90">CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">Linda</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September11-14, 2017. 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,694.69,378.88,9.90;8,107.55,707.19,415.86,9.90;8,107.55,719.97,415.76,9.90;8,107.55,732.71,216.08,9.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,162.03,719.97,243.36,9.90">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName coords=""><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Alexan-Der</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,415.13,719.97,108.18,9.90;8,107.55,732.71,107.19,9.90">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,144.05,745.10,379.33,10.00;8,107.55,757.96,208.71,9.90" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,296.16,745.10,227.22,10.00;8,107.55,757.96,105.18,9.90">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,220.29,757.96,27.23,9.90">ICML</title>
		<imprint>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.80,74.66,225.92,10.00" xml:id="b11">
	<monogr>
		<ptr target="https://github.com/tensorflow" />
		<title level="m" coord="9,184.55,74.66,48.14,10.00">Tensorflow</title>
		<imprint/>
		<respStmt>
			<orgName>Google</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
