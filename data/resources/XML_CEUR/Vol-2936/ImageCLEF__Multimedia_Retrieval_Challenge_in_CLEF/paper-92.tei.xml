<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,370.84,15.42">Simple Neural Network based TB Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,113.06,74.22,11.96"><forename type="first">Anirudh</forename><surname>Anand</surname></persName>
							<email>anirudh19015@cse.ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.06,113.06,61.10,11.96"><forename type="first">Raja</forename><surname>Karthik</surname></persName>
							<email>karthikraja19048@cse.ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.15,113.06,96.98,11.96"><forename type="first">Bhuvana</forename><surname>Anandan</surname></persName>
							<email>bhuvanaj@ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.12,113.06,52.23,11.96;1,145.59,127.00,36.95,11.96"><forename type="first">Thanga</forename><surname>Jayaraman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.53,127.00,69.72,11.96"><forename type="first">Thanga</forename><surname>Nadar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.24,127.00,22.27,11.96"><surname>Thai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
									<region>Tamil Nadu</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,370.84,15.42">Simple Neural Network based TB Classification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">28AB70036312289137D8DBD0BB502A9E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computed Tomography</term>
					<term>Tuberculosis classification</term>
					<term>Neural Network</term>
					<term>Tensorflow</term>
					<term>Image Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Analysis of images is a vitally important task in medical applications. It helps the prompt detection and categorization of diseases, among others. This paper depicts a intuitive and simple approach to classify the Tuberculosis found in the 3D CT-images of patients' chests as a part of the ImageCLEF2021 challenge. A simple shallow neural network is employed with three layers. The model is trained using augmented images of the dataset. The proposed model is tested for it's accuracy and kappa coefficient to obtain the degree to which the model correctly classifies the chest images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Tuberculosis (TB) is an airborne disease caused by Mycobacterium tuberculosis (MTB) that usually affects the lungs leading to severe coughing, fever, and chest pains. Although current research in the past four years has provided valuable insight into TB transmission, diagnosis and treatment, much remains to be discovered to effectively decrease the incidence of and eventually eradicate TB <ref type="bibr" coords="1,198.07,403.89,11.49,10.91" target="#b0">[1]</ref>. According to a report in 2013, around 3 million cases of TB went undiagnosed, mainly because of under trained staff, inaccurate tests and lack of equipment <ref type="bibr" coords="1,492.52,417.44,11.36,10.91" target="#b1">[2]</ref>.</p><p>Computed Tomography (CT) uses X-rays to create images of objects. It has a plethora of applications and is of importance in the medical field <ref type="bibr" coords="1,330.42,444.54,11.52,10.91" target="#b2">[3]</ref>. Analysis of CT-images can provide useful insight in the diagnosis of TB. Motivation of the above, JBTTM team participated in the ImageCLEF2021 <ref type="bibr" coords="1,162.43,471.64,12.71,10.91" target="#b3">[4]</ref> Tuberculosis challenge <ref type="bibr" coords="1,280.52,471.64,12.70,10.91" target="#b4">[5]</ref> to categorize images of patients' chests into one of 5 significant types.</p><p>Prior to the development of the model, simple shallow neural networks and convolutional neural networks were studied <ref type="bibr" coords="1,229.11,512.28,11.58,10.91" target="#b5">[6]</ref>. Basics of Python's NumPy and associated libraries were also studied. Image compression techniques were researched. The model was then developed culminating knowledge gained from the same.</p><p>The approach used for analysis of 3D CT-images involved using simple neural networks to map test images to one of five classes. The model is trained using augmented images of the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task and Dataset</head><p>As mentioned above, the broad objective of ImageCLEF2021 is to classify 3D CT-images of patients' lungs into one of 5 TB categories, namely: (1) Infiltrative, (2) Focal, (3) Tuberculoma, (4) Miliary and (5) Fibro-cavernous. A dataset containing chest CT scans of 1338 TB patients is used. 917 images for the Training (development) data set and 421 for the Test set. Additionally, metadata is provided for some images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multi-dimensional neuroimaging data</head><p>For all patients a single 3D CT image with an image size per slice of 512×512 pixels and number of slices being around 100 is provided. All the CT images are stored in NIFTI file format with .nii.gz file extension (g-zipped .nii files). This file format stores raw voxel intensities in Hounsfield units (HU) as well the corresponding image metadata such as image dimensions, voxel size in physical units, slice thickness, etc. Python's Nibabel package <ref type="bibr" coords="2,362.31,303.71,12.84,10.91" target="#b7">[8]</ref> is used to read the .nii files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodologies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data preprocessing</head><p>Nibabel library was used to load the zipped Nifti fileformat of CT-scan images and return them as NumPy arrays. The values of the NumPy array is normalized based on threshold values of hounsfield units. The given NumPy array contains raw voxel intensities in Hounsfield units (HU). The Hu for Air is -1000 and Hu for tissues is 500.And those intensities higher than 500 makes up the bones in the image.Here we are taking into those account only those between -1000 to 500 and used to normalize the voxel(Volume pixel) values of the NumPy array to the range [0 to 1]. This is scaled down to 128*128*64 image size from 512*512*113. The resulting scaled down 3D-array is then rotated to randomize the orientation. Since the entire data set can't be read into memory in one go,it is read in batches of 20 and is then sent for training. A linear interpolation <ref type="bibr" coords="2,148.94,505.25,12.69,10.91" target="#b8">[9]</ref> operator from SciPy was used to scale down the image sizes.Since the CT-scan image was already given in higher resolution , it is assumed that the features and edges would be retained after a simple Linear interpolation.It also results in faster processing.Normalizing data is said to speed up the learning process and leads to faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Image Augmentation</head><p>To increase the count of training set and to enhance variability into the training set, the obtained dataset is mapped to functions that rotate the images by degrees of 5 to create augmented data that is used for training. The training batch size is set as 20 (the maximum possible size without getting an out of memory error). Validation set contains equal number of all category dataset, to produce an unbiased accuracy. However, one additional instance each, was added to class 3 and class 4 to tune the model well during the training and hence the validation set size is 27. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model Architecture</head><p>A simple shallow neural network model has been designed to classify the Tuberculosis found in the 3D CT-images. The proposed model has three layers in it as shown in Fig. <ref type="figure" coords="3,435.81,313.49,5.05,10.91" target="#fig_0">1</ref> The first layer accepts the preprocessed images and are flattened before passing them to two fully connected layers.</p><p>The 128*128*64 3D image is flattened to (128*128*64) single dimensional vector and is passed through a dense layer of 600 (picked at random after working with lower dimensions) neurons and the output of this layer is given to the last layer which returns a one hot encoded vector.</p><p>The first fully connected layer uses 'relu' as activation function, since that activation function handles the problem of vanishing gradient. The last classification layer has 5 nodes corresponding to the classes of Tuberculosis and employs sigmoid activation function, that produces outcome similar to the probabilistic values pertaining to the classes.</p><p>The loss function used is Binary cross entropy which is optimized using the Stochastic Gradient Descent optimizer. The model performance during training is evaluated using the accuracy metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Convolutional Neural Network (CNN) Model</head><p>The proposed model for Tuberculosis classification is arrived after exploring another model using the Convolutional layers called as Convolutional Neural Network (CNN). The CNN model has been designed with 4 convolutional layers, each followed by max pooling layer to reduce the spatial dimension of the images. The convolutional layers extract the features from the input images and are fed to 2 fully connected layers. Batch normalization is done to avoid model over fitting. The model configuration and parameter details are shown in Fig. <ref type="figure" coords="3,436.23,593.55,3.74,10.91" target="#fig_1">2</ref>.</p><p>CNN model used the same pre-processing techniques followed by Neural Network model. This CNN model did not show any promising results while training when compared to the Neural Network model explained in section 3.3. The average validation accuracy measured was only 0.15. We suspect that lack of data can attributed to this poor accuracy. Hence we had to alter our model to a much simpler neural network that can work with smaller amount of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Hardware used</head><p>Google Colab notebook was used to train the model. A general purpose RAM size of 8GB was alloted with a 2.3GHz Intel Xenon CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Code</head><p>Implementation is done using Python and the URL to the code is shared below. https://colab. research.google.com/drive/1wbTPPOn2AF72OMnCkchTcQl2Cd87KeFR?usp=sharing <ref type="bibr" coords="4,468.72,209.07,16.25,10.91" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Result</head><p>The two models are trained for 20 epochs, accuracy metric is used to study the performance of the model during training. The Metric for both the models are given in Table <ref type="table" coords="4,432.20,272.35,3.71,10.91" target="#tab_1">1</ref>  The proposed model has obtained a testing accuracy of 0.221 and a kappa value of 0.038 as reported in Table <ref type="table" coords="4,182.11,446.37,3.81,10.91" target="#tab_2">2</ref>. These metrics were used for ranking and placed us in the ninth place ImageClef 2021 TB classification <ref type="bibr" coords="4,236.36,459.92,12.84,10.91" target="#b4">[5]</ref> challenge. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The crux of the JBTTM's submission is based on simple and shallow neural networks (with an input layer, single hidden layer and an output layer). Other model were such as the 3D CNN model were also experimented. They weren't selected due to their low accuracy. The team's submission placed it ninth out of a total of eleven participant teams. A rigorous assessment of the submission showed that the model can be improved by adding more meaningful layers and/or adding more neurons per layer in such a way that the model doesn't become intractable. When compared to previous year's results, the submission of JBTTM and other teams shows a steady improvement in the accuracy. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,241.77,202.43,8.93;3,89.29,84.19,416.69,133.06"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Proposed Neural Network Architecture</figDesc><graphic coords="3,89.29,84.19,416.69,133.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,655.19,159.35,8.93;6,89.29,91.87,465.00,538.80"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: CNN Architecture Summary</figDesc><graphic coords="6,89.29,91.87,465.00,538.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,89.29,272.35,418.37,65.11"><head></head><label></label><figDesc>. Complex deep learning networks namely ResNet, GoogleNet have achieved around 0.4033 in 2017 imageclef. So keeping them into account, we have tried out to build a simpler Neural Network model for classifying and have achieved validation accuracy of 0.20. The Neural network model was alone out of the two experiments, submitted to the ImageCLEFmedical task for evaluation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,355.55,337.97,60.87"><head>Table 1</head><label>1</label><figDesc>Training metrics</figDesc><table coords="4,168.31,383.24,258.65,33.17"><row><cell>Model</cell><cell>Training Accuracy</cell><cell>Validation Accuracy</cell></row><row><cell>Neural Network</cell><cell>0.647</cell><cell>0.20</cell></row><row><cell>CNN</cell><cell>0.566</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.99,488.93,307.75,108.69"><head>Table 2</head><label>2</label><figDesc>Evaluated results of ImageCLEF medical</figDesc><table coords="4,198.53,516.57,198.22,81.05"><row><cell>Rank</cell><cell>Participant</cell><cell>Kappa</cell><cell>Accuracy</cell></row><row><cell>06</cell><cell>uaic2021</cell><cell>0.129</cell><cell>0.333</cell></row><row><cell>07</cell><cell>IALab_PUC</cell><cell>0.120</cell><cell>0.401</cell></row><row><cell>08</cell><cell>KDE-lab</cell><cell>0.117</cell><cell>0.382</cell></row><row><cell>09</cell><cell>JBTTM</cell><cell>0.038</cell><cell>0.221</cell></row><row><cell>10</cell><cell>Zhao_Shi_</cell><cell>0.015</cell><cell>0.380</cell></row><row><cell>11</cell><cell>YNUZHOU</cell><cell>-0.008</cell><cell>0.385</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,112.66,264.75,269.27,10.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,155.74,264.75,194.27,10.91">Tuberculosis: A disease without boundaries</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fogel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,278.30,394.03,10.91;5,112.66,291.85,351.45,10.91" xml:id="b1">
	<monogr>
		<ptr target="http://www.stoptb.org/assets/documents/resources/factsheets/StopTBinfographicMissing3Million.pdf" />
		<title level="m" coord="5,112.66,278.30,235.06,10.91">Stop tb partnership -fact sheet: The missing 3 million</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,305.40,393.61,10.91;5,112.66,318.95,173.58,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Assili</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1808.09172" />
		<title level="m" coord="5,154.39,305.40,351.88,10.91">A review of tomographic reconstruction techniques for computed tomography</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,332.50,395.01,10.91;5,112.66,346.05,394.53,10.91;5,112.48,359.59,395.18,10.91;5,112.66,373.14,394.53,10.91;5,112.28,386.69,393.70,10.91;5,112.66,400.24,393.33,10.91;5,112.66,413.79,393.33,10.91;5,112.66,427.34,393.53,10.91;5,112.66,440.89,197.61,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,264.32,386.69,241.66,10.91;5,112.66,400.24,261.75,10.91">Overview of the ImageCLEF 2021: Multimedia retrieval in medical, nature, internet and social media applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sarrouti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jacutprakart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tauteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Moustahfid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deshayes-Chossart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,401.27,400.24,104.72,10.91;5,112.66,413.79,393.33,10.91;5,112.66,427.34,201.15,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 12th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="5,348.61,427.34,157.57,10.91;5,112.66,440.89,31.10,10.91">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,454.44,395.17,10.91;5,112.66,467.99,394.53,10.91;5,112.66,481.54,394.53,10.91;5,112.66,495.09,22.69,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,393.45,454.44,114.38,10.91;5,112.66,467.99,257.62,10.91">Overview of ImageCLEFtuberculosis 2021 -CT-based tuberculosis type classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="5,392.48,467.99,110.11,10.91">CLEF2021 Working Notes</title>
		<title level="s" coord="5,112.66,481.54,181.84,10.91">CEUR Workshop Proceedings, CEUR-WS.</title>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,508.64,394.53,10.91;5,112.28,522.18,393.96,10.91;5,112.33,535.73,29.19,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.01427</idno>
		<title level="m" coord="5,112.28,522.18,246.72,10.91">A simple neural network module for relational reasoning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="5,112.66,549.28,347.74,10.91" xml:id="b6">
	<monogr>
		<ptr target="https://numpy.org/doc/stable/user/whatisnumpy.html" />
		<title level="m" coord="5,112.66,549.28,67.57,10.91">What is numpy</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,562.83,395.00,10.91" xml:id="b7">
	<monogr>
		<ptr target="https://nipy.org/nibabel/" />
		<title level="m" coord="5,112.66,562.83,253.79,10.91">Nibabel access a cacophony of neuro-imaging file formats</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,576.38,394.53,10.91;5,112.66,589.93,248.75,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,249.35,576.38,253.44,10.91">A survey on evaluation methods for image interpolation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Amanatiadis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Andreadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,112.66,589.93,170.79,10.91">Measurement Science and Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">104015</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,112.66,603.48,393.86,10.91;5,112.66,617.03,121.69,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zunair</surname></persName>
		</author>
		<ptr target="https://keras.io/examples/vision/3D_image_classification" />
		<title level="m" coord="5,166.47,603.48,169.31,10.91">3d image classification from ct scans</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
