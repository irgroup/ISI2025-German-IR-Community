<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,99.20,84.74,396.37,15.42;1,118.55,106.66,358.18,15.42;1,137.11,129.00,324.97,11.96">Team Skeletor at Touché 2021: Argument Retrieval and Visualization for Controversial Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,48.99,11.96"><forename type="first">Kevin</forename><surname>Ros</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>Illinois</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,156.21,154.90,65.95,11.96"><forename type="first">Carl</forename><surname>Edwards</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>Illinois</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.09,154.90,36.61,11.96"><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>Illinois</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.69,154.90,86.35,11.96"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>Illinois</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,99.20,84.74,396.37,15.42;1,118.55,106.66,358.18,15.42;1,137.11,129.00,324.97,11.96">Team Skeletor at Touché 2021: Argument Retrieval and Visualization for Controversial Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">FC31A0BBAD6C3CD164980476D3334140</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>information retrieval</term>
					<term>argument</term>
					<term>manifold approximation</term>
					<term>visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Arguments are a critical part of education and political discourse in society, especially since more and more information is available online. In order to access this information, argument retrieval is a necessary task. In this work, we leverage the existing techniques of BM25 and BERT-based passage embedding similarity and introduce a new information retrieval technique based on manifold approximation. Evaluation results on the Touché @ CLEF 2021 topics and relevance scores show that the manifold-based approximation helps discover higher-quality arguments. Furthermore, we use these retrieval methods to visualize argument progression for users watching debates. The visualization results show promising directions for future exploration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Arguments are an important part of education and political discourse in society. As the amount of information and social media use grows on the internet, especially surrounding controversial topics, it is critical to improve access to relevant debates, thereby improving public understanding of divisive topics <ref type="bibr" coords="1,165.44,453.11,11.23,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,179.31,453.11,7.49,10.91" target="#b1">2]</ref>. Furthermore, traditional search engines are often limited in their ability to effectively display and update relevant information during a live debate, especially when the debate topics are constantly changing.</p><p>This paper attempts to address these concerns by investigating both argument retrieval and visualization. More specifically, we participate in Touché @ CLEF 2021 <ref type="bibr" coords="1,395.05,507.30,11.23,10.91" target="#b2">[3,</ref><ref type="bibr" coords="1,408.33,507.30,7.49,10.91" target="#b3">4]</ref>, which presents two distinct argument retrieval tasks: retrieving arguments for controversial questions and retrieving arguments for comparative questions. We focus on the first task, with the goal of supporting users by retrieving and visualizing relevant arguments and sentences for controversial questions. This argument retrieval task goes beyond traditional information retrieval because the retrieval methods need to capture both relevance and argument strength.</p><p>As the basic retrieval models have performed well on this task <ref type="bibr" coords="1,373.00,588.60,11.27,10.91" target="#b4">[5]</ref>, in addition to the standard baseline BM25 and BERT embedding-based retrieval we explore a new approach in which we CLEF <ref type="bibr" coords="1,105.06,627.81,15.77,7.99">'21:</ref> Conference and Labs of the Evaluation Forum, September 21-24, 2021, Bucharest, Romania kjros2@illinois.edu (K. Ros); cne2@illinois.edu (C. Edwards); hengji@illinois.edu (H. Ji); czhai@illinois.edu (C. Zhai) leverage the properties of manifold approximation, which is commonly used for dimensionality reduction <ref type="bibr" coords="2,158.27,100.52,11.54,10.91" target="#b5">[6]</ref>, as a pseudo-relevance-feedback reranking approach. The manifold-based reranking approach assumes the highest-ranked initially retrieved arguments are relevant to the controversial question, and computes a directed-edge existence probability from each argument to all other arguments in the corpus.</p><p>Our hypothesis is that strong, complete, and relevant arguments will have many other arguments "pointing" to it. That is, these arguments should have many high-probability incoming directed edges. Thus, we rerank the arguments based on the aggregation of their incoming edge probabilities. Furthermore, we build on these retrieval approaches to visualize the topics and trajectory of real-time debates as they progress per word with respect to a reference corpus.</p><p>Experiments using the args.me corpus <ref type="bibr" coords="2,273.65,222.46,12.87,10.91" target="#b6">[7]</ref> and the Touché @ CLEF 2021 <ref type="bibr" coords="2,423.38,222.46,12.86,10.91" target="#b4">[5]</ref> topics and relevance scores show that our manifold-based ranking formula improves upon BM25 in argument quality. Additionally, our exploration of visualization techniques using the args.me corpus and a spoken debate shows promise in the direction of debate summarization and augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Our retrieval methods are inspired by passage-level evidence, as we treat each argument as a collection of sentences <ref type="bibr" coords="2,202.87,335.28,11.58,10.91" target="#b7">[8]</ref>. We follow the general methods described by SBERT's retrieval and re-ranking. <ref type="foot" coords="2,159.86,347.08,3.71,7.97" target="#foot_0">1</ref> Zhao et al. <ref type="bibr" coords="2,219.60,348.83,12.84,10.91" target="#b8">[9]</ref> use manifold-based text representations of sentences in the biomedical domain to capture the geometric relationships between sentences. Other work also incorporates manifold learning into text representations <ref type="bibr" coords="2,338.41,375.93,16.33,10.91" target="#b9">[10,</ref><ref type="bibr" coords="2,357.47,375.93,12.51,10.91" target="#b10">11,</ref><ref type="bibr" coords="2,372.71,375.93,12.25,10.91" target="#b11">12]</ref>. To our knowledge, we are the first to incorporate sentence-level manifold representations into information retrieval.</p><p>Regarding conversation augmentation, Lyons et al. investigate leveraging dual-purpose speech, which they define as speech socially appropriate to humans and meaningful to computers <ref type="bibr" coords="2,104.74,430.13,16.09,10.91" target="#b12">[13]</ref>. Their software plays the role of an assistant (recording dates, scheduling events) rather than introducing additional knowledge to the conversations, which is what we aim to do. <ref type="bibr" coords="2,483.51,443.67,22.48,10.91;2,89.29,457.22,21.58,10.91">Boyd et al.</ref> propose to augment conversations with prosody information to help users with autism detect atypical prosody <ref type="bibr" coords="2,193.47,470.77,16.09,10.91" target="#b13">[14]</ref>. We attempt to introduce similar metadata to the debates (however, in the form of conversational topics) as well as introduce additional arguments directly related to the topics being discussed. Popescu-Belis et al. introduce a speech-based just-in-time retrieval system which uses semantic search <ref type="bibr" coords="2,254.46,511.42,16.42,10.91" target="#b14">[15]</ref>. That is, they record and transcribe conversations, and provide relevant documents to the participants of the conversation in real-time. Their search methods are based on keywords previously spoken during the conversation using ASR (automatic speech recognition) <ref type="bibr" coords="2,225.34,552.07,16.09,10.91" target="#b15">[16]</ref>. A word is considered a keyword if it is in the ASR transcript and is not a stopword, or if it is in a pre-constructed list. Thus, the search queries are limited to what has already been spoken, and high-level dependencies between previously discussed ideas cannot be leveraged. We believe our visualization approaches better address both of these issues.</p><p>There has also been much work in the general field of visualizing information retrieval <ref type="bibr" coords="2,486.95,619.81,16.19,10.91" target="#b16">[17]</ref>, but none of these approaches combine BERT and manifold-based dimensionality reduction to allow for more fine-grained understanding of arguments over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Argument Retrieval</head><p>In the following subsections, we describe our argument retrieval methods and results. Each approach retrieves arguments from the args.me corpus (version 2020-04-01), which consists of 387,740 arguments scraped from various online debate portals <ref type="bibr" coords="3,366.15,138.38,11.38,10.91" target="#b6">[7]</ref>. For each argument entry in the corpus, we only consider the text in the "premise" field. Our methods are primarily evaluated using the topics and relevance scores from Touché @ CLEF 2021, and we also include the scores of our methods on last year's iteration of the competition for completeness. The relevance scores from last year consist of -2 (non-argument) or a range from 1 (low relevance, weak argument) to 5 (high relevance, strong argument. This year's relevance scores use the same range, however, they consist of two separate dimensions: argument relevance and argument quality. There are 50 distinct topics each consisting of a short "title" field and a longer "description" and "narrative" fields. For our queries, we only use the "title" field. Some examples of "title" fields include "Do we need sex education in schools?" and "Should stem cell research be expanded?".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">BM25</head><p>For our baseline approach, we use BM25. BM25 is a bag-of-words ranking formula that relies on keyword matching between a query and a collection of arguments, along with various weighting heuristics. To process, index, and search arguments, we use Pyserini, which is a Python-based information retrieval toolkit built over Anserini and Lucene <ref type="bibr" coords="3,423.02,370.57,16.28,10.91" target="#b17">[18]</ref>. All argument premises are processed and indexed using the default Pyserini settings. This includes stopword removal and stemming. All queries are also processed similarly. We use Pyserini's provided BM25 implementation to search the corpus, only adjusting the 𝑘 1 and 𝑏 parameters. We tune the parameters on last year's topics and relevance scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Semantic Search</head><p>Given that BM25 only matches exact terms, we explore the effectiveness of encoder-based 𝑘 nearest neighbor search to help bridge potential vocabulary gaps. To do this, we first split the premises of each argument by sentence into smaller passages of approximately 200 words each. Then, we encode each passage using the msmarco-distilbert-base-v3 encoder model provided by Sentence Transformers <ref type="bibr" coords="3,195.23,527.59,16.28,10.91" target="#b18">[19]</ref>. At a high level, msmarco-distilbert-base-v3 is a BERT-based <ref type="bibr" coords="3,488.04,527.59,17.95,10.91" target="#b19">[20]</ref> Siamese sentence encoder fine-tuned for question-answering on the MS MARCO data set <ref type="bibr" coords="3,487.40,541.14,16.21,10.91" target="#b20">[21]</ref>. The passage embeddings are stored and indexed using the hnwslib Python library <ref type="bibr" coords="3,455.51,554.69,16.24,10.91" target="#b21">[22]</ref>, which provides an approximate nearest-neighbor lookup index using hierarchical navigable small world graphs. Each topic title is also encoded using msmarco-distilbert-base-v3, and given the encoded topic, we search for the approximate top 𝑘 nearest neighbor passages. The top arguments are ordered based on the maximum cosine similarity between the topic and any of its passages. All parameters are again tuned using the previous iteration of the task.</p><p>We also investigate combining the scores returned via semantic search with those returned using BM25. To calculate this, we use the following formula:</p><formula xml:id="formula_0" coords="3,225.47,670.31,143.85,10.69">𝑠𝑐𝑜𝑟𝑒 𝐵𝑀 25 + 𝛼 × 𝑠𝑐𝑜𝑟𝑒 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Manifold Approximation</head><p>Our third argument retrieval approach attempts to leverage the techniques utilized in UMAP (Uniform Manifold Approximation and Projection) <ref type="bibr" coords="4,321.91,121.08,11.58,10.91" target="#b5">[6]</ref>. UMAP is a dimensionality reduction technique that first approximates a uniform manifold for each data point and patches together their local fuzzy simplicial set representations, where a simplicial set is a higher-dimensional generalization of a directed graph. Then, this topoligical representation is used to assess and optimize lower-dimensional representations. A full theoretical description of UMAP is beyond the scope of this paper, so we focus solely on the computational aspects of UMAP's manifold approximation which are relevant to our retrieval approach.</p><p>To approximate a uniform manifold for each data point 𝑥 𝑖 , UMAP first finds the 𝑘 nearest neighbors to 𝑥 𝑖 . Then, it defines 𝜌 𝑖 and 𝜎 𝑖 , where</p><formula xml:id="formula_1" coords="4,190.01,253.99,315.97,12.19">𝜌 𝑖 = 𝑚𝑖𝑛{𝑑(𝑥 𝑖 , 𝑥 𝑖 𝑗 )|1 ≤ 𝑗 ≤ 𝑘, 𝑑(𝑥 𝑖 , 𝑥 𝑖 𝑗 ) &gt; 0},<label>(1)</label></formula><formula xml:id="formula_2" coords="4,193.86,279.32,312.13,33.71">𝑘 ∑︁ 𝑗=1 exp( -𝑚𝑎𝑥(0, 𝑑(𝑥 𝑖 , 𝑥 𝑖 𝑗 ) -𝜌 𝑖 ) 𝜎 𝑖 ) = log 2 (𝑘),<label>(2)</label></formula><p>and 𝑑(𝑥 𝑖 , 𝑥 𝑖 𝑗 ) is the distance between 𝑥 𝑖 and 𝑥 𝑖 𝑗 . Intuitively, 𝜌 𝑖 is the distance to 𝑥 𝑖 's closest neighbor (in our case, the most similar passage) and 𝜎 𝑖 smooths and normalizes the distances to the nearest neighbors. Next, UMAP calculates the following weights between data points:</p><formula xml:id="formula_3" coords="4,193.33,372.16,312.66,26.38">𝑤((𝑥 𝑖 , 𝑥 𝑗 )) = exp( -𝑚𝑎𝑥(0, 𝑑(𝑥 𝑖 , 𝑥 𝑖 𝑗 ) -𝜌 𝑖 ) 𝜎 𝑖 ).<label>(3)</label></formula><p>Calculating this for every data point 𝑥 𝑖 results in a 𝑘-granularity weighted adjacency matrix between all points in the data. The authors of UMAP note that 𝑤((𝑥 𝑖 , 𝑥 𝑗 )), or entry 𝑖, 𝑗 of the weighted adjacency matrix, can be interpreted as the probability that a directed edge from 𝑥 𝑖 to 𝑥 𝑗 exists.</p><p>For the purposes of argument retrieval, our hypothesis is that strong, complete, and relevant arguments will have many other arguments "pointing" to it. That is, these arguments should have many high-probability incoming directed edges. Thus, for a given topic title, we first search using the aforementioned interpolated BM25 and semantic retrieval methods. We encode all of the passages for the top 𝑛 arguments. Next, for each encoded passage, we find the 𝑘 nearest neighbors and calculate (1), <ref type="bibr" coords="4,213.16,525.87,10.39,10.91" target="#b1">(2)</ref>, and (3) as described above. Finally, we score each argument by the sum of all directed edges pointing to the argument.</p><p>Note that the sum of these calculated passage weights possess different properties than just the sum of the passage similarities. Most notably, Equation 2 constrains the scaled sum of distances to log 2 (𝑘), where k is the number of nearest neighbors. Our understanding is that this calculation gives importance to points that have fewer highly-similar (closer) neighbors. For example, if we have two points (x) and (y), and the (point,distance) pairs of their three nearest neighbors are (𝑥) : [(𝑎, 0.1), (𝑏, 0.2), (𝑐, 0.9)] (𝑦) : [(𝑑, 0.1), (𝑒, 0.2), (𝑓, 0.3)] Intuitively, this may help reduce importance of passages that are similar to many other passages, as that passage will contribute lower weights to other passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Results</head><p>We submitted five runs to Touché 2021, and the performance measures for these five runs are listed in Table <ref type="table" coords="5,173.90,371.50,3.81,10.91" target="#tab_0">1</ref>. The 2021 runs are judged in two dimensions: argument relevance and argument quality, which correspond to the second and third columns of the table, respectively. We also include the performance of our retrieval models on the topics and relevance scores from Touché 2020 as a reference, see column three. All measures are calculated using normalized discounted cumulative gain at five (nDCG@5). The first run, "bm25", corresponds to the approach outlined in Section 3.1.1. We tune the parameters using grid search and arrived at 𝑘 1 = 3.2 and 𝑏 = 0.2 using the 2020 topics and relevance scores. The next row, "semantic", corresponds to Section 3.1.2. We set the number of nearest neighbors 𝑘 = 1000 for each topic. Next, "bm25-0.7semantic" denotes the interpolation of the two aforementioned approaches, with an 𝛼 value of 0.7. The final two rows correspond to the approach described in Section 3.1.3. For "manifold", we assume the top 3 arguments from "bm25-0.7semantic" are relevant and search for 𝑘 = 50 nearest neighbors for each argument passage. The retrieved passages are completely reranked by aggregating the weights over each argument. For "manifold-c10", we perform the exact same search, but only rerank the top 10 arguments of the "bm25-0.7semantic" run.</p><p>For this year's evaluations, our best-performing run with respect to relevance is "bm25-0.7semantic". However, all of our other runs which utilize BM25 (i.e., excluding "semantic") perform similarly. With respect to quality, our best-performing run is "manifold". Here, it is promising that "manifold" outperformed "manifold-c10", as this implies that the manifold technique is able to increase argument quality by retrieving arguments outside of the top 10 initially-ranked arguments.</p><p>It is unclear whether or not our initial hypothesis is supported by the scores listed in Table <ref type="table" coords="5,500.33,656.03,3.67,10.91" target="#tab_0">1</ref>. The evaluation metrics from this year seem to support our hypothesis in the context of our "manifold" run, but last year's results show a decrease in performance. This may be because last year's relevance scores combine many different measures into a single dimension. Furthermore, it is difficult to separate out the effects of BM25 on our manifold-based approaches, since it appears that these approaches perform similarly. This, along with the high scores of our "bm25" run, stresses the importance of well-tuned robust models. Overall, these results are a step in the right direction for our hypothesis, but more analysis is needed to draw firm conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Visualization</head><p>While a ranked list of document snippets is often sufficient for ordinary web search, such a list is not necessarily optimal for showing results of argument retrieval to the users because it is common to discuss many topics during a debate and the user may want to see the topical structure. These topics may be discussed at length, briefly mentioned, or revisited as the debate unfolds. Traditional search engines, which require explicit user querying, often display relevant documents and arguments in a ranked list, which makes it difficult to effectively capture and visualize these topic changes. For example, it may be too time consuming for a participant in a debate to constantly search for and read all of the relevant documents. Or, someone may want a high-level summary of the debate at various points. Thus, we explore various visualization techniques to help mitigate these concerns. This is accomplished by minimizing the necessity of constant user input as well as visualizing these structural topic changes. Visualization of search results has been studied before <ref type="bibr" coords="6,259.73,362.38,16.39,10.91" target="#b16">[17,</ref><ref type="bibr" coords="6,278.85,362.38,12.53,10.91" target="#b22">23,</ref><ref type="bibr" coords="6,294.11,362.38,12.53,10.91" target="#b23">24,</ref><ref type="bibr" coords="6,309.38,362.38,12.42,10.91" target="#b24">25]</ref>; however, existing visualization methods will not work well for our use case, so we explore new approaches.</p><p>For our visualization exploration, we utilize the args.me corpus to help summarize and augment debates in real time. We demonstrate our visualization methods on the publiclyavailable debate between Bill Nye and Ken Ham on Evolution vs. Creationism. <ref type="foot" coords="6,437.26,414.82,3.71,7.97" target="#foot_1">2</ref> We chose this debate primarily because YouTube provides an accurate transcript of the debate with timestamps, and because of the debate's diverse topic coverage.</p><p>The YouTube transcript timestamps occur approximately every 3 seconds and contain approximately 1 -8 words per timestamp. We maintain these groupings for our analysis. The text for the transcript referenced in the analysis is in Table <ref type="table" coords="6,355.02,484.32,3.77,10.91" target="#tab_2">4</ref>. The full text of each referenced argument ID is available on GitHub. <ref type="foot" coords="6,250.12,496.12,3.71,7.97" target="#foot_2">3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Visualization Approach with BM25</head><p>For any given timestamp 𝑡 𝑖 , we define a look-back window of size 𝑛 and collect all the terms that occurred between 𝑡 𝑖-𝑛 and 𝑡 𝑖 . Then, we search the args.me corpus using our BM25 retrieval approach outlined in Section 3.1.1, with the query being the collected transcript terms. We record the ranks of the top 𝑘 arguments returned. We choose BM25 because it is well-known to be robust and efficient. Repeating this over a given interval of timestamps results in a smoothed argument-level summary for the interval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Arguments from Figure <ref type="figure" coords="7,187.34,360.51,4.63,8.87" target="#fig_0">1</ref> Argument ID Representative Topic(s)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4fde9bb-Aef3913d8 description of a bicycle incident S9a8b0a09-A22358c86</head><p>understanding scriptures, the gospel, God S690aacea-A986a10d7 creator of universe, infinite power, God S23dda237-A69f9884f having unlimited power, omnipotence of God S5059e885-Abe1aa26d the justness of God</p><p>As an example, consider the debate time interval 110:53-114:04. Each timestamp and corresponding text is listed in Table <ref type="table" coords="7,226.80,494.50,3.70,10.91" target="#tab_2">4</ref>. We define a look-back window of size 𝑛 = 5 and retrieve the top 𝑘 = 20 arguments for each timestamp. Then, we collect the number of times an argument is ranked in the top 20 arguments across all timestamps, and consider only the five most frequent arguments. Figure <ref type="figure" coords="7,203.88,535.15,5.17,10.91" target="#fig_0">1</ref> displays the ranks of these five argument at each timestamp, and Table <ref type="table" coords="7,115.79,548.70,5.07,10.91">2</ref> lists a high-level description of each argument. The parameters are manually tuned to demonstrate the benefits and drawbacks of this visualization approach.</p><p>Of the five arguments returned, S4fde9bb-Aef3913d8 seems to be topically irrelevant to the transcript text. Interestingly, this argument appears to also be a transcript, and thus it contains many filler words (such as "uh") also present in the debate transcript. It appears to be playing the role of a background language model. The other four arguments seem to be relevant as they discuss topics and themes present in the transcript at different timestamps. From 111:29 to 111:50, argument S9a8b0a09-A22358c86 is one of the highest-ranked, and it discusses "God", "His kingdom", "scripture", and "His actions". From 112:22 to 112:47, we find that arguments S690aacea-A986a10d7 and S23dda237-A69f9884f are ranked the highest. Both arguments discuss the powers of the creator of the universe. From 112:53 to 113:10, we observe that argument S5059e885-Abe1aa26d is the highest-ranked, which argues in favor of the justness of God.</p><p>One use case for this visualization technique is to help participants of the debate better analyze and justify their stance. For example, the participants can draw on the additional knowledge provided by the retrieved arguments to strengthen their own arguments in real-time. On the other hand, it is also possible that rebuttals to participants' arguments will be retrieved, which could help increase the overall robustness of the debate by exposing counterpoints.</p><p>In order to reduce noise and irrelevant arguments, we also explore the possibility of allowing users to specify the search terms or arguments. More specifically, using pre-defined sets of terms, we search the args.me corpus with BM25 to find the most relevant arguments to the provided terms. Then, we display the frequencies of the returned arguments using the methods outlined above, except we consider ranks through 100 rather than 20.</p><p>Consider the same debate time interval and the keyword groups "bible god creationism" and "heavens astronomy stars". Figure <ref type="figure" coords="8,270.62,413.02,5.17,10.91" target="#fig_1">2</ref> displays the frequencies of the five most relevant arguments to each keyword group. The first five argument IDs in the legend correspond to the first keyword group, and the second five argument IDs in the legend correspond to the second keyword group. Additionally, high-level descriptions of the arguments that appear in Figure <ref type="figure" coords="8,121.18,467.22,5.17,10.91" target="#fig_1">2</ref> are listed in Table <ref type="table" coords="8,213.47,467.22,3.81,10.91" target="#tab_1">3</ref>. The first two arguments are from "bible god creationism" and the last three arguments correspond to "heavens astronomy stars". From Figure <ref type="figure" coords="8,445.51,480.76,3.74,10.91" target="#fig_1">2</ref>, we see that arguments relevant to both keyword groups are highly ranked between 112:10 and 112:36, indicating that the keywords in the retrieved arguments strongly match the keywords from the debate transcript in the time interval.</p><p>An important benefit of this visualization technique is that it allows the user to specify specific topics before, during, or after a debate in order to easily track various topic occurrences for further analysis. For example, a user looking to get a high-level summary of a debate can examine the ranking frequencies of known arguments in order to pinpoint the most relevant points in the debate.</p><p>As this visualization approach provides a high-level overview of a debate by referencing relevant arguments using keywords, it abstracts away from the actual content of the debate and relevant sentences within arguments. To help address this issue, we explore a more fine-grained visualization approach in the following subsection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Visualization Approach with UMAP</head><p>The advent of new Transformer-based language models such as BERT <ref type="bibr" coords="9,398.29,381.67,17.78,10.91" target="#b19">[20]</ref> have lead to impressive improvement on a variety of NLP tasks. We seek to use BERT's semantic representation space to better visualize the dynamics of arguments. To do so, we take advantage of UMAP <ref type="bibr" coords="9,492.57,408.77,11.32,10.91" target="#b5">[6]</ref>. The goal of UMAP is to visualize high-dimensional embeddings in a low-dimensional space while preserving topological and structural properties. Using the same BERT-based encoder discussed in Section 3.1.2, we combine the encodings of the sentences of relevant arguments and the "caterpillar embeddings" of our debate transcript to visualize how the debate evolves over time. This approach allows us to analyze fine-grained topic changes as they unfold in the debate, as well as their relevance to a reference corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Caterpillar Embeddings</head><p>Caterpillar embeddings are used to track the course of the debate over time. They consist of a sequence of encoder representations taken from across the debate. A naïve approach is to slide a window of size 𝑛 over the sequence of words 𝑤 in the transcript with stride 𝑠. However, this has the downside of both adding and removing information (words) at each step. Instead, we split each step into two: a growth step and a contraction step. Given a window from word 𝑤 𝑖 to 𝑤 𝑖+𝑛 of the transcript for some 𝑖, the next window will grow to be from 𝑤 𝑖 to 𝑤 𝑖+𝑛+𝑠 . The subsequent window will be a contraction: it will range from 𝑤 𝑖+𝑠 to 𝑤 𝑖+𝑛+𝑠 Hence, this "caterpillar embedding" technique moves along the transcript of the debate like a caterpillar inching along. At step 𝑡, the start and end of the window, 𝑆 and 𝐸 respectively, are calculated as follows:</p><formula xml:id="formula_4" coords="10,235.43,101.25,123.92,15.19">𝑆 = 𝑤 𝑠⌊ 𝑡 2 ⌋ , 𝐸 = 𝑤 𝑠⌊ 𝑡+1 2 ⌋+𝑛</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Argument Retrieval-Based Semantic Visualizations</head><p>In order to better define the topology of the semantic space, we extract the top 𝑘 most frequent arguments over the transcript interval 110:53 to 127:01 as described in Section 4.1 from the args.me corpus, split them into sentences, and encode the sentences using the previouslymentioned BERT-based sentence encoder. We combine these argument embeddings with the caterpillar embeddings of the debate transcript and project them into two dimensions using UMAP. This creates a path of the debate as it visits different arguments in the semantic space. We can then use the nearby neighbors of the caterpillar embeddings as relevant arguments to show the user at a given timestamp. The full animation can be found on GitHub. <ref type="foot" coords="10,448.01,244.52,3.71,7.97" target="#foot_3">4</ref>Regardless of which 𝑘 value we use, we find that this UMAP projection does not preserve the original space well regarding nearest neighbors. We believe this is because of the large differences between the semantic structures of the conversational YouTube debate and the written structures of the corpus debates. To mitigate this, we use a nearest neighbor search in the original space, and we plot the debate embedding using its 𝑚 nearest neighbors. Through empirical exploration, we find that 𝑚 = 100 and 𝑘 = 100 yields the clearest results. Additionally, we consider the same window as explored in Section 4.1, namely 110:53 to 114:04. Note that the transcript of the debate in this window is available in Table <ref type="table" coords="10,362.54,354.67,3.81,10.91" target="#tab_2">4</ref>. The resulting path at various timestamps is shown in Figure <ref type="figure" coords="10,228.08,368.22,3.74,10.91" target="#fig_2">3</ref>.</p><p>The argument quickly moves to the lower left quadrant, which we find to signify the creation of the universe and heavens, particularly in relation to God. The path briefly moves to the right, when the debate focuses more on the omnipotence and omniscience of God. Finally, the debate moves upward, when the discussion changes to physics, life science, and astronomy. The full video can also be found on GitHub. <ref type="foot" coords="10,245.99,434.21,3.71,7.97" target="#foot_4">5</ref>In Figure <ref type="figure" coords="10,143.64,449.51,3.78,10.91" target="#fig_2">3</ref>, we clearly see groupings of arguments' topics and how they change over time. Interestingly, we can also examine the topic path through the corpus that the YouTube debate took. This could be used to track debate topic progression in a visual manner, and augment live debates with both relevant information at the current point as well as relevant information for future, forecasted points. More work is needed, however, to investigate the effects of parameter selection and the effectiveness in various domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work, we apply several techniques to the Touché Argument Retrieval task, such as BM25, semantic search, and manifold-based reranking. Among them, we find that the manifold-based reranking was sometimes more effective in returning high-quality arguments when compared to BM25. In the future, we hope to compute the manifold weights for every argument in the data set as a preprocessing step, and investigate efficient ways to combine these weights with retrieval methods that perform well along the relevance dimension, in order to return the strongest and the most relevant arguments.</p><p>To better display search results to users in argument retrieval, we also introduce various visualization techniques based on BM25 keyword matching and UMAP dimensionality reduction, which shows promise in the direction of debate augmentation. Although the benefits of this augmentation are difficult to quantify, we believe it will help improve debate understanding and retention, as well as open up avenues for future work. We also hope to improve the visualization by further testing different parameters, retrieval techniques, and background corpora. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,89.29,315.35,407.85,8.93;7,89.29,84.19,416.69,218.60"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Rankings of the five most frequent arguments over the transcript window 110:53 -114:04.</figDesc><graphic coords="7,89.29,84.19,416.69,218.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,89.29,311.54,416.70,8.93;9,89.29,323.55,246.51,8.87;9,89.29,84.19,416.70,219.56"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Rankings of the five most relevant arguments to "bible god creationism" and to "heavens astronomy stars" over the transcript window 110:53 -114:04.</figDesc><graphic coords="9,89.29,84.19,416.70,219.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,89.29,457.51,404.00,8.93;11,297.64,267.14,208.35,165.01"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualization of the evolution-creationism debate through the retrieved argument space.</figDesc><graphic coords="11,297.64,267.14,208.35,165.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.96,90.49,417.02,195.69"><head>Table 1</head><label>1</label><figDesc>Performance on Touché 2021 and 2020 Topics and Relevance Scores</figDesc><table coords="5,88.96,122.10,417.02,164.08"><row><cell>Run Name</cell><cell cols="3">Relevance nDCG@5 Quality nDCG@5 2020 nDCG@5</cell></row><row><cell>bm25</cell><cell>0.661</cell><cell>0.822</cell><cell>0.6214</cell></row><row><cell>semantic</cell><cell>0.570</cell><cell>0.671</cell><cell>0.3475</cell></row><row><cell>bm25-0.7semantic</cell><cell>0.667</cell><cell>0.815</cell><cell>0.6347</cell></row><row><cell>manifold</cell><cell>0.666</cell><cell>0.827</cell><cell>0.5417</cell></row><row><cell>manifold-c10</cell><cell>0.666</cell><cell>0.818</cell><cell>0.5906</cell></row><row><cell cols="4">then the weight between (x) and (b) will be higher than (y) and (e), even though they have</cell></row><row><cell cols="4">the same relative distances. Here are the resulting weights from the manifold calculation</cell></row><row><cell cols="2">(𝜎 𝑥 = 0.179741, 𝜎 𝑦 = 0.113319):</cell><cell></cell><cell></cell></row><row><cell cols="2">(𝑥) : [(𝑎, 1), (𝑏, 0.5733), (𝑐, 0.0117)]</cell><cell cols="2">(𝑦) : [(𝑑, 1), (𝑒, 0.4138), (𝑓, 0.1712)]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,88.98,90.49,343.30,106.13"><head>Table 3</head><label>3</label><figDesc>Arguments from Figure2</figDesc><table coords="8,163.00,122.10,269.28,74.52"><row><cell>Argument ID</cell><cell>Representative Topic(s)</cell></row><row><cell cols="2">S379f0b2-Ab47bd29b showing the validity of theistic evolution</cell></row><row><cell>S56a34f98-A3adb8db7</cell><cell>biblical creationism, unfalsifiable</cell></row><row><cell>Scf918055-Af439fe9a</cell><cell>heaven, hell, stars, God</cell></row><row><cell cols="2">S70cdd68a-A5b15aee9 physics, star formation, modern science</cell></row><row><cell>S9ad5951e-A78e904a7</cell><cell>astronomy in the context of the Quran</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,88.99,90.49,409.82,549.31"><head>Table 4</head><label>4</label><figDesc>Transcript of creationism debate from 110:53 to 114:04</figDesc><table coords="12,96.47,121.22,402.34,518.57"><row><cell>Timestamp</cell><cell>Text</cell><cell>Timestamp</cell><cell>Text</cell></row><row><cell>110:53</cell><cell>creationism account for the celestial</cell><cell>112:23</cell><cell>um and just to show us he's an</cell></row><row><cell>110:55</cell><cell>bodies</cell><cell>112:25</cell><cell>all-powerful god he's an infinite god so</cell></row><row><cell>110:56</cell><cell>planets stars moons moving further and</cell><cell>112:27</cell><cell>i made the stars and he made them to</cell></row><row><cell>110:59</cell><cell>further apart</cell><cell>112:29</cell><cell>show us how great he is and he is he's</cell></row><row><cell>111:00</cell><cell>and what function does that serve in the</cell><cell>112:31</cell><cell>an</cell></row><row><cell>111:02</cell><cell>grand design</cell><cell>112:32</cell><cell>infinite creator god and the more that</cell></row><row><cell>111:04</cell><cell>well when it comes to uh looking at the</cell><cell>112:34</cell><cell>you understand what that means that god</cell></row><row><cell>111:06</cell><cell>universe of course we believe that in</cell><cell>112:36</cell><cell>is all-powerful infinite you stand back</cell></row><row><cell>111:08</cell><cell>the beginning god created the heavens</cell><cell>112:39</cell><cell>in all</cell></row><row><cell>111:09</cell><cell>and the earth</cell><cell>112:39</cell><cell>you realize how small we are you realize</cell></row><row><cell>111:10</cell><cell>and i believe our uh creationist</cell><cell>112:42</cell><cell>wow that god would consider this planet</cell></row><row><cell>111:12</cell><cell>astronomers would say yeah you can</cell><cell>112:44</cell><cell>is is so significant that he created</cell></row><row><cell>111:13</cell><cell>observe</cell><cell>112:47</cell><cell>human beings here</cell></row><row><cell>111:14</cell><cell>the universe expanding uh why god is</cell><cell>112:48</cell><cell>knowing they would sin and yet stepped</cell></row><row><cell>111:16</cell><cell>doing that in fact in the bible it even</cell><cell>112:50</cell><cell>into history to die for us be raised</cell></row><row><cell>111:17</cell><cell>says he stretches out</cell><cell>112:52</cell><cell>from the dead</cell></row><row><cell>111:19</cell><cell>the heavens and seems to indicate that</cell><cell>112:53</cell><cell>to offer us a free gift to salvation wow</cell></row><row><cell>111:22</cell><cell>there is</cell><cell>112:56</cell><cell>what a god and that's what i would say</cell></row><row><cell>111:22</cell><cell>an expansion of the universe and so</cell><cell>112:58</cell><cell>when i see</cell></row><row><cell>111:26</cell><cell>we would say yeah that you can observe</cell><cell>112:59</cell><cell>the universe as it is mr nye one minute</cell></row><row><cell>111:27</cell><cell>that that fits with</cell><cell>113:02</cell><cell>any response</cell></row><row><cell>111:29</cell><cell>what we call observational science</cell><cell>113:03</cell><cell>there's a question that troubles us all</cell></row><row><cell>111:30</cell><cell>exactly why god did it that way</cell><cell>113:05</cell><cell>from the time we are</cell></row><row><cell>111:32</cell><cell>uh i can't answer that question of</cell><cell>113:08</cell><cell>absolutely youngest and first able to</cell></row><row><cell>111:34</cell><cell>course uh because you know the bible</cell><cell>113:10</cell><cell>think</cell></row><row><cell>111:36</cell><cell>says that uh</cell><cell>113:11</cell><cell>and that is where did we come from where</cell></row><row><cell>111:37</cell><cell>god made uh the heavens for for his</cell><cell>113:13</cell><cell>did i come from</cell></row><row><cell>111:39</cell><cell>glory and that's why he made</cell><cell>113:15</cell><cell>and this question is so compelling that</cell></row><row><cell>111:41</cell><cell>uh the stars that we see out there and</cell><cell>113:18</cell><cell>we've</cell></row><row><cell>111:44</cell><cell>it's uh it's to tell us how great he is</cell><cell>113:19</cell><cell>invented the science of astronomy we've</cell></row><row><cell>111:46</cell><cell>and how big he is and in fact i think</cell><cell>113:22</cell><cell>invented life science we've invented</cell></row><row><cell>111:48</cell><cell>that's the the thing about the universe</cell><cell>113:24</cell><cell>physics we've discovered these natural</cell></row><row><cell>111:49</cell><cell>the universe is</cell><cell>113:26</cell><cell>laws</cell></row><row><cell>111:50</cell><cell>so large so big out there one of our</cell><cell>113:27</cell><cell>so that we can learn more about our</cell></row><row><cell>111:53</cell><cell>planetarium programs</cell><cell>113:29</cell><cell>origin and where we came from</cell></row><row><cell>111:54</cell><cell>looks at this we go in and show you uh</cell><cell>113:31</cell><cell>to you when it says he invented the</cell></row><row><cell>111:57</cell><cell>how large the universe is</cell><cell>113:34</cell><cell>stars also</cell></row><row><cell>111:59</cell><cell>and i think it shows us how great god</cell><cell>113:36</cell><cell>that's satisfying you're done oh good</cell></row><row><cell>112:02</cell><cell>is uh how big he is that he's an</cell><cell>113:39</cell><cell>okay to me when i look at the night sky</cell></row><row><cell>112:04</cell><cell>all-powerful god he's an infinite god</cell><cell>113:41</cell><cell>i want to know what's out there</cell></row><row><cell>112:07</cell><cell>uh an infinite all-knowing god who</cell><cell>113:43</cell><cell>i'm driven i want to know if what's out</cell></row><row><cell>112:09</cell><cell>created the universe</cell><cell>113:46</cell><cell>there is any part of me</cell></row><row><cell>112:10</cell><cell>to show us his power i mean can you</cell><cell>113:48</cell><cell>and indeed it is the oh by the way</cell></row><row><cell>112:13</cell><cell>imagine that and the thing that's</cell><cell>113:51</cell><cell>i find compelling you are satisfied and</cell></row><row><cell>112:14</cell><cell>remarkable</cell><cell>113:55</cell><cell>the big thing i want from you</cell></row><row><cell>112:15</cell><cell>in the bible for instance says on the</cell><cell>113:56</cell><cell>mr ham is can you come up with something</cell></row><row><cell>112:17</cell><cell>fourth day of creation</cell><cell>113:59</cell><cell>that you can predict</cell></row><row><cell>112:18</cell><cell>and and oh he made the stars also it's</cell><cell>114:00</cell><cell>do you have a creation model that</cell></row><row><cell>112:21</cell><cell>almost like oh by the way i made the</cell><cell>114:02</cell><cell>predicts something that will happen in</cell></row><row><cell>112:22</cell><cell>stars</cell><cell>114:04</cell><cell>nature</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.03,281.21,8.97"><p>https://www.sbert.net/examples/applications/retrieve_rerank/README.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,108.93,660.03,183.82,8.97"><p>https://www.youtube.com/watch?v=z6kgvhG3AkI</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,108.93,670.99,290.67,8.97"><p>https://github.com/kevinros/toucheRetrievalVisualization/tree/main/arguments</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="10,108.93,660.06,349.85,8.97"><p>https://github.com/kevinros/toucheRetrievalVisualization/blob/main/animations/full_anim.mp4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="10,108.93,671.02,386.50,8.97"><p>https://github.com/kevinros/toucheRetrievalVisualization/blob/main/animations/100top_mean_anim.mp4</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,112.66,111.28,305.71,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,159.46,111.28,81.89,10.91">Social media usage</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Perrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,249.88,111.28,89.62,10.91">Pew research center</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="52" to="68" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,124.83,394.53,10.91;13,112.66,138.38,393.33,10.91;13,112.66,151.93,95.49,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,112.66,138.38,339.45,10.91">Echo chambers: Emotional contagion and group polarization on facebook</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Vicario</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vivaldo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bessi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zollo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Scala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Caldarelli</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Quattrociocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,464.28,138.38,41.71,10.91;13,112.66,151.93,31.84,10.91">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,165.48,394.53,10.91;13,112.66,179.03,313.98,10.91;13,445.87,179.03,60.12,10.91;13,112.33,192.57,394.85,10.91;13,112.66,206.12,393.33,10.91;13,112.66,219.67,393.33,10.91;13,112.66,233.22,395.00,10.91;13,112.66,246.77,393.74,10.91;13,112.66,260.32,394.88,10.91;13,112.66,273.87,193.04,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,445.87,179.03,60.12,10.91;13,112.33,192.57,147.40,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-72240-1_67</idno>
		<idno>doi:10.1007/978-3-030-72240-1\_67</idno>
		<ptr target="https://urldefense.com/v3/__https://link.springer.com/chapter/10.1007/978-3-030-72240-1_67__;!!DZ3fjg!qiIStvQ7N0tMq0XWzNrBDwdUszdG_1Cm5f0npcVKkP9lL7BwqrITiN5eveoZNiWt_Q" />
	</analytic>
	<monogr>
		<title level="m" coord="13,269.09,206.12,236.90,10.91;13,112.66,219.67,183.82,10.91">Advances in Information Retrieval. 43rd European Conference on IR Research (ECIR 2021)</title>
		<title level="s" coord="13,386.66,220.69,119.33,9.72;13,112.66,234.24,29.07,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="574" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,287.42,394.53,10.91;13,112.66,300.97,313.98,10.91;13,445.87,300.97,60.12,10.91;13,112.33,314.52,394.86,10.91;13,112.14,328.07,395.05,10.91;13,112.66,341.62,22.69,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,445.87,300.97,60.12,10.91;13,112.33,314.52,141.80,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,112.14,328.07,390.30,10.91">Working Notes Papers of the CLEF 2021 Evaluation Labs, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,355.17,395.17,10.91;13,112.66,368.71,395.17,10.91;13,112.66,382.26,393.33,10.91;13,112.66,395.81,394.41,10.91;13,112.66,409.36,393.65,10.91;13,112.66,422.91,384.65,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,369.03,368.71,138.80,10.91;13,112.66,382.26,77.10,10.91">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<ptr target="!DZ3fjg!qiIStvQ7N0tMq0XWzNrBDwdUszdG_1Cm5f0" />
	</analytic>
	<monogr>
		<title level="m" coord="13,466.22,382.26,39.77,10.91;13,112.66,395.81,218.31,10.91;13,112.66,422.91,373.34,10.91">Working Notes Papers of the CLEF 2020 Evaluation Labs</title>
		<title level="s" coord="13,413.71,396.83,93.36,9.72;13,112.66,410.38,34.26,9.72">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
	<note>npcVKkP9lL7BwqrITiN5ever8RPesww</note>
</biblStruct>

<biblStruct coords="13,112.66,436.46,393.33,10.91;13,112.66,450.01,287.74,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03426</idno>
		<title level="m" coord="13,257.35,436.46,248.63,10.91;13,112.66,450.01,105.51,10.91">Umap: Uniform manifold approximation and projection for dimension reduction</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,463.56,393.53,10.91;13,112.28,477.11,393.71,10.91;13,112.66,490.66,393.73,10.91;13,112.34,504.21,286.03,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,415.08,463.56,91.11,10.91;13,112.28,477.11,167.13,10.91">Data Acquisition for Argument Search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30179-8_4</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,112.66,490.66,241.68,10.91">German Conference on Artificial Intelligence (KI 2019)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Benzmüller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,517.76,395.01,10.91;13,112.66,531.30,38.81,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,166.39,517.76,195.22,10.91">Passage-level evidence in document retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,383.91,517.76,35.96,10.91">SIGIR&apos;94</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="302" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,544.85,393.33,10.91;13,112.26,558.40,395.41,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,396.43,544.85,109.56,10.91;13,112.26,558.40,188.86,10.91">Sentence representation with manifold learning for biomedical texts</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,308.91,558.40,117.04,10.91">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page">106869</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,571.95,393.32,10.91;13,112.66,585.50,393.98,10.91;13,112.66,599.05,38.81,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,331.30,571.95,174.68,10.91;13,112.66,585.50,69.57,10.91">Word embeddings as metric recovery in semantic spaces</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Alvarez-Melis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,190.61,585.50,278.49,10.91">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="273" to="286" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,612.60,393.33,10.91;13,112.66,626.15,190.34,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,196.40,612.60,251.24,10.91">Word re-embedding via manifold dimensionality retention</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Curry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,455.07,612.60,50.92,10.91;13,112.66,626.15,160.15,10.91">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,639.70,393.33,10.91;13,112.66,653.25,395.01,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,271.74,639.70,234.25,10.91;13,112.66,653.25,40.93,10.91">Latent topic text representation learning on statistical manifolds</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,161.06,653.25,256.09,10.91">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="5643" to="5654" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,666.80,393.33,10.91;14,112.66,86.97,393.33,10.91;14,112.66,100.52,332.23,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,449.23,666.80,56.76,10.91;14,112.66,86.97,188.45,10.91">Augmenting conversations using dual-purpose speech</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Skeels</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Starner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Snoeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ashbrook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,332.31,86.97,173.67,10.91;14,112.66,100.52,244.02,10.91">Proceedings of the 17th annual ACM symposium on User Interface Software and Technology</title>
		<meeting>the 17th annual ACM symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="237" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,114.06,394.52,10.91;14,112.66,127.61,393.33,10.91;14,112.66,141.16,394.83,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,112.66,127.61,306.12,10.91">Saywat: Augmenting face-to-face conversations for adults with autism</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">E</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tomimbang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conejo-Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tentori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">R</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,441.55,127.61,64.43,10.91;14,112.66,141.16,296.99,10.91">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4872" to="4883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,154.71,393.33,10.91;14,112.66,168.26,307.89,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="14,376.94,154.71,129.04,10.91;14,112.66,168.26,170.06,10.91">A speech-based just-in-time retrieval system using semantic search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu-Belis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nanchen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Garner</surname></persName>
		</author>
		<idno>Idiap</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="14,112.66,181.81,394.53,10.91;14,112.66,195.36,312.75,10.91" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="14,157.48,195.36,129.77,10.91">Real-time ASR from meetings</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dines</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">El</forename><surname>Hannani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Karafiat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Korchagin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lincoln</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno>Idiap</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="14,112.66,208.91,302.03,10.91" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="14,161.65,208.91,95.75,10.91">Search user interfaces</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,222.46,393.33,10.91;14,112.66,236.01,394.53,10.91;14,112.66,249.56,173.79,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.10073</idno>
		<title level="m" coord="14,392.48,222.46,113.51,10.91;14,112.66,236.01,389.98,10.91">Pyserini: An easy-to-use python toolkit to support replicable ir research with sparse and dense representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,112.66,263.11,394.53,10.91;14,112.66,276.66,173.79,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m" coord="14,219.74,263.11,282.85,10.91">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,112.66,290.20,393.33,10.91;14,112.66,303.75,363.59,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="14,353.43,290.20,152.55,10.91;14,112.66,303.75,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,112.66,317.30,393.71,10.91;14,112.66,330.85,368.97,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,449.54,317.30,56.83,10.91;14,112.66,330.85,258.71,10.91">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,394.17,330.85,57.15,10.91">CoCo@ NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,344.40,393.33,10.91;14,112.66,357.95,393.33,10.91;14,112.66,371.50,195.39,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,248.28,344.40,257.71,10.91;14,112.66,357.95,215.17,10.91">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">A</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Yashunin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,336.51,357.95,169.48,10.91;14,112.66,371.50,111.46,10.91">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="824" to="836" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,385.05,393.33,10.91;14,112.66,398.60,393.32,10.91;14,112.66,412.15,196.48,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,468.04,385.05,37.95,10.91;14,112.66,398.60,230.28,10.91">Bridging text visualization and mining: A task-driven survey</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>El-Assady</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,351.46,398.60,154.52,10.91;14,112.66,412.15,102.40,10.91">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2482" to="2504" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,425.70,394.53,10.91;14,112.30,439.25,394.89,10.91;14,112.66,452.79,394.53,10.91;14,112.66,466.34,55.16,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,209.74,439.25,292.68,10.91">Senseplace2: Geotwitter analytics support for situational awareness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Maceachren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pezanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Savelyev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Blanford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,150.56,452.79,299.30,10.91">IEEE conference on visual analytics science and technology (VAST)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,479.89,393.33,10.91;14,112.66,493.44,393.33,10.91;14,112.66,506.99,199.16,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,290.07,479.89,215.91,10.91;14,112.66,493.44,128.25,10.91">Topic-relevance map: Visualization for improving search result comprehension</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peltonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Belorustceva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ruotsalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,266.73,493.44,239.26,10.91;14,112.66,506.99,111.69,10.91">Proceedings of the 22nd international conference on intelligent user interfaces</title>
		<meeting>the 22nd international conference on intelligent user interfaces</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="611" to="622" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
