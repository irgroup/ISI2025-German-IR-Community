<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,109.72,84.74,375.83,15.42;1,110.16,106.66,374.95,15.42;1,137.11,129.00,324.97,11.96">Exploring Argument Retrieval for Controversial Questions Using Retrieve and Re-rank Pipelines Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,81.67,11.96"><forename type="first">Raunak</forename><surname>Agarwal</surname></persName>
							<email>ragarwal@uni-potsdam.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">University of Potsdam</orgName>
								<address>
									<postCode>14476</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,183.60,154.90,76.55,11.96"><forename type="first">Andrei</forename><surname>Koniaev</surname></persName>
							<email>koniaev@uni-potsdam.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">University of Potsdam</orgName>
								<address>
									<postCode>14476</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.15,154.90,73.30,11.96"><forename type="first">Robin</forename><surname>Schaefer</surname></persName>
							<email>robin.schaefer@uni-potsdam.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">University of Potsdam</orgName>
								<address>
									<postCode>14476</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,109.72,84.74,375.83,15.42;1,110.16,106.66,374.95,15.42;1,137.11,129.00,324.97,11.96">Exploring Argument Retrieval for Controversial Questions Using Retrieve and Re-rank Pipelines Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">6F9695AC47700F343CAE0F890FEF91F7</idno>
					<idno type="arXiv">arXiv:2010.08240.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Argument Retrieval</term>
					<term>Sentence Embeddings</term>
					<term>Semantic Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This notebook documents Team Macbeth's contribution to the CLEF 2021 shared task Touché: Argument Retrieval for Controversial Questions. Our approach consists of different configurations of a two-step retrieve and re-rank pipeline. We experimented with sparse and dense approaches for argument retrieval and trained query-document cross-encoders for argument re-ranking. Our findings suggest that a sparse retriever combined with a custom re-ranker performed the best out of all our approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this notebook, we present our approaches for Touché 2021 Task 1: Argument Retrieval for Controversial Questions <ref type="bibr" coords="1,195.93,380.18,11.58,10.91" target="#b0">[1]</ref>. The task entails retrieval of arguments on a focused document collection crawled from debate portals <ref type="bibr" coords="1,260.79,393.73,11.33,10.91" target="#b1">[2]</ref>. The aim here is to assist users with finding "strong" arguments that support or oppose their position on a given controversial topic.</p><p>We discuss some of the recent work on information retrieval (IR) methods (Section 2), after which we present a high-level overview of our experiments (Section 3), as well as results (Section 4). For better reproducibility of our experiments, we also make available the source code 1 and the trained models 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>While standard information retrieval systems have focused largely on sparse bag-of-wordsbased approaches such as BM25, recent trends in IR indicate the performant nature of a two-step retrieval and re-ranking pipeline, where a sizeable number of candidate documents are first retrieved using the aforementioned sparse representations, and then re-ranked using (trainable) neural models <ref type="bibr" coords="1,154.97,574.30,11.43,10.91" target="#b2">[3]</ref>.</p><p>Attempts are also being made to get rid of sparse representations altogether through the use of dense retrieval systems <ref type="bibr" coords="2,205.51,100.52,11.31,10.91" target="#b3">[4]</ref>. A standard dense retrieval architecture comprises a transformerbased encoder, which is fine-tuned on a given training corpus with queries and relevant documents. The encoded documents are usually added into an inverted index based on approximate nearest neighbours. There is also work which shows that combining sparse and dense representations can further enhance the performance of these IR systems <ref type="bibr" coords="2,379.25,154.71,11.43,10.91" target="#b4">[5]</ref>.</p><p>Our submissions for the Touché shared task center around the above methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental Setup</head><p>All our experiments were computed on a setup comprising of an Intel Xeon E5-2650 CPU (24 cores, 256 GB RAM) and 2 NVIDIA GTX 1080Ti GPU's (24 GB VRAM). We also used Weights and Biases<ref type="foot" coords="2,135.03,272.85,3.71,7.97" target="#foot_0">3</ref> to track our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pre-training</head><p>We pre-trained the entire args.me corpus on a Masked Language Modeling (MLM) task introduced first by BERT <ref type="bibr" coords="2,178.58,337.53,12.68,10.91" target="#b5">[6]</ref> and later modified by Liu et al. in RoBERTa <ref type="bibr" coords="2,384.50,337.53,11.27,10.91" target="#b6">[7]</ref>. RoBERTa demonstrated an improvement on BERT's performance with a small adaptation to the pre-training task, hence we chose to follow their approach.</p><p>Our motivation for pre-training was to make sure that our model first learns from the domaininvariant representations present in RoBERTa-base, and then enhances these representations through (continued) pre-training on our custom domain. This kind of domain-adaptive pretraining has been known to offer gains in task performance <ref type="bibr" coords="2,356.67,418.82,11.43,10.91" target="#b7">[8]</ref>.</p><p>We used the hyper-parameters presented in the RoBERTa-base model and trained it for 10 epochs <ref type="foot" coords="2,120.27,444.17,3.71,7.97" target="#foot_1">4</ref> , generating a domain-specific RoBERTa-base model with perplexity ≈ 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Re-annotation</head><p>The organisers of Touché 2021 provide the participants with 2298 relevance judgements to allow training/evaluation of their systems. These relevance judgments are the result of crowd-sourcing efforts of Mechanical Turk<ref type="foot" coords="2,207.31,520.64,3.71,7.97" target="#foot_2">5</ref> workers -a practice which has been criticised for its questionable data quality <ref type="bibr" coords="2,144.18,535.95,11.33,10.91" target="#b8">[9]</ref>, leaving aside major ethical considerations concerning labour exploitation <ref type="bibr" coords="2,487.48,535.95,16.15,10.91" target="#b9">[10]</ref>.</p><p>Our initial plan was to use these annotations to train a sentence-pair classifier. After a closer look, however, we found that these annotations were riddled with errors and therefore, not suitable as a training set.</p><p>Instead of eliminating their use altogether, we decided to re-annotate all of the 2298 relevance judgements. <ref type="foot" coords="2,144.01,601.94,3.71,7.97" target="#foot_3">6</ref> We went through two rounds of annotation for each query-document pair, and achieved the following metric for inter-annotator agreement: Krippendorff's alpha = 0.39 Due to time constraints, the runs we submitted were trained only on the first round of annotations. The relatively low inter-annotator score suggests our runs would've turned out slightly different had we trained our models on an average of the two annotation rounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Sentence Embeddings</head><p>When it was first introduced, BERT set new state-of-the-art results on various NLP tasks, including question answering, sentence classification, and sentence-pair regression. A big disadvantage of the BERT's network structure, however, was its inability to generate sentence embeddings based on single-input sequences.</p><p>To overcome the above issue, we used UKP Lab's Sentence-BERT (or SBERT) <ref type="bibr" coords="3,440.73,425.58,17.82,10.91" target="#b11">[12]</ref> which is a modification of the standard BERT architecture. SBERT adds a mean pooling operation on top of the contextualized word vectors generated by BERT/RoBERTa. This enables the generation of semantically meaningful sentence/document embeddings which can be used for downstream tasks. We made use of the regression objective function described in their paper. A pair-wise regressor was trained using cosine-similarity between the two embeddings 𝑢 and 𝑣 (where 𝑢 is the query embedding and 𝑣 is the document embedding). The objective function was optimized using mean-squared-error loss.</p><p>The terminology used in SBERT is further refined by Humeau et al. <ref type="bibr" coords="3,397.38,533.97,17.76,10.91" target="#b12">[13]</ref> where the following approaches for pair-wise sentence scoring are defined: Bi-Encoders and Cross-Encoders. (See Figure <ref type="figure" coords="3,120.36,561.07,3.57,10.91" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Bi-Encoder</head><p>The architecture introduced in SBERT is what is now known as a bi-encoder. Using a bi-encoder, each sentence can be encoded into an independent sentence embedding. The creation of these vector representations enables efficient document retrieval through the use of standard similarity measures (such as Euclidean distance/cosine-similarity) in the embedding space.</p><p>After the pre-training step (3.2), we trained a bi-encoder using the query-document annotations described in 3.3. This bi-encoder was used to generate document embeddings for the entire corpus, giving us an embedding space of size 𝑚 * 𝑛, where 𝑚 is the embedding size and 𝑛 is the total number of documents. This embedding space was then indexed by a dense retriever as described in 3.5.2.</p><p>Note: Each document in the corpus consists of premises and a conclusion. To generate document embeddings, we ignore the conclusion and use only the premises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Cross-Encoder</head><p>A cross-encoder is analogous to the standard BERT design where full-attention is applied across tokens over an input sentence pair. While a bi-encoder takes two inputs and returns two representations (or embeddings), cross-encoders take two inputs and return a single decision directly. They outperform bi-encoders on pair-wise sentence scoring tasks at the cost of speed.</p><p>Since cross-encoders are slow and do not produce independent embeddings, they cannot be used for retrieval tasks. We used them in the second step of our pipeline to re-rank documents where a cross-encoder was trained (after MLM pretraining 3.2) on the annotations as described in 3.3. As a baseline, we also made use of a cross-encoder pretrained on the MSMARCO dataset.</p><p>[14]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Retrieval Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.">Sparse: BM25 (Elasticsearch)</head><p>BM25 is a traditional bag-of-words-based retrieval function which scores the relevancy of documents for a given query using the frequencies of common terms between the query and document. As a variation of the TF-IDF function, it is sensitive to the token frequencies as well as their inverse document frequencies.</p><p>Due to its simplicity, computational efficiency, and performance, BM25 serves as a critical component of large-scale search applications and serves as the de facto industrial standard in IR tasks. To index our id-document pairs, we used the implementation available in Elasticsearch <ref type="foot" coords="4,501.96,475.82,3.71,7.97" target="#foot_4">7</ref>with the default settings enabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2.">Dense: Approximate Nearest Neighbours (hnswlib)</head><p>Despite its robustness, BM25 has several shortcomings. It suffers from the lexical gap problem <ref type="bibr" coords="4,89.29,554.00,16.32,10.91" target="#b14">[15]</ref>, a common occurrence in systems built on sparse representations; empirical results have also shown that it overly penalizes very long documents <ref type="bibr" coords="4,342.97,567.55,16.25,10.91" target="#b15">[16]</ref>.</p><p>To overcome the above problems, we deployed BM25's sparse retriever alongside a dense retriever. Experimental results demonstrate that the contextual text representations from BERT are more effective than BM25 on retrieval tasks <ref type="bibr" coords="4,302.63,608.20,11.43,10.91" target="#b3">[4]</ref>.</p><p>Constructing a dense retriever was a two step process: first, we encoded the entire corpus into a dense vector space using the bi-encoder described in 3.4.1. Second, the representations created by the bi-encoder were indexed using a library that implements approximate nearest neighbours search (hnswlib). <ref type="foot" coords="5,217.96,304.67,3.71,7.97" target="#foot_5">8</ref>Approximate nearest neighbour search is an important step in efficiently generating similar document vectors for a given query vector. The alternative is to attempt cosine-similarity of the query vector with every single document vector i.e. brute force. We chose hnswlib since systems based on hierarchical navigable small world graphs (HNSW) <ref type="bibr" coords="5,393.11,360.62,17.75,10.91" target="#b16">[17]</ref> represent the current state-of-the-art in approximate nearest neighbour search.<ref type="foot" coords="5,344.62,372.41,3.71,7.97" target="#foot_6">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Data Augmentation</head><p>For our data augmentation approach, we utilized the methodology described in the Augmented SBERT paper <ref type="bibr" coords="5,152.99,437.44,18.07,10.91" target="#b17">[18]</ref> where a pre-trained cross-encoder was used to weakly label a sample of unlabeled query-document pairs. The query-document pairs were sampled using BM25, fed into a cross-encoder trained on MSMARCO to generate silver labels, which were then appended to the gold training set to train an augmented bi-encoder. (Figure <ref type="figure" coords="5,381.72,478.09,4.16,10.91" target="#fig_1">2</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Retrieve and Re-rank</head><p>The two-step pipeline of retrieve and re-rank has been known to work well on IR tasks. Given a search query, the first step is to retrieve a large list of candidate documents which are potentially relevant for the query. For the retrieval stage, we experimented with a sparse retriever (3.5.1), a dense retriever (3.5.2), and a combination of both (by simply appending the outputs of the two retrievers).</p><p>In the second step, we used a re-ranker based on a cross-encoder (3.4.2) that scores the relevancy of all the retrieved candidates (Figure <ref type="figure" coords="5,312.32,609.11,3.65,10.91" target="#fig_2">3</ref>). We experimented with a custom crossencoder trained on our annotations and a pre-trained cross-encoder trained on the MSMARCO dataset. For each query, 100 candidate documents were retrieved and sent to the cross-encoder  for the purposes of re-ranking. After re-ranking, only the top 50 documents were included in the final submission file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>We performed evaluation using the relevance judgements 10 and quality judgements 11 provided by the organisers of the shared task. The metric used was nDCG@5. The results are in Table <ref type="table" coords="6,500.26,465.05,3.70,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we outlined Team Macbeth's contribution to the CLEF lab Touché. Our central approach consisted of using tried-and-tested methods for information retrieval and re-ranking. We pre-trained the args.me corpus on a masked language modeling task, re-annotated the relevance arguments from Touché 2020, and attempted neural methods for both retrieval and re-ranking. The combination of a sparse retriever and a custom neural re-ranker stands out as the best method in terms of both argument relevance as well as argument quality.</p><p>10 https://webis.de/events/touche-21/touche-task1-51-100-relevance.qrels 11 https://webis.de/events/touche-21/touche-task1-51-100-quality.qrels</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,256.95,349.30,8.93;3,152.69,84.19,287.40,160.20"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pair-wise scoring architectures (Figure taken from the SBERT website [11])</figDesc><graphic coords="3,152.69,84.19,287.40,160.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,243.64,416.87,8.93;5,89.29,255.64,19.45,8.87;5,145.64,84.19,301.50,152.70"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pipeline for weakly-supervised learning (Figure taken from the Augmented SBERT paper [18])</figDesc><graphic coords="5,145.64,84.19,301.50,152.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,89.29,201.78,416.70,8.93;6,89.29,213.78,340.64,8.87;6,118.39,84.19,356.00,111.00"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the retrieve and re-rank pipeline: candidate documents are retrieved using a sparse/dense retriever and then re-ranked using a pretrained/custom cross-encoder</figDesc><graphic coords="6,118.39,84.19,356.00,111.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,246.88,389.31,105.74"><head>Table 1</head><label>1</label><figDesc>Summary of evaluation (Measure used: nDCG@5)</figDesc><table coords="6,116.97,278.50,361.33,74.12"><row><cell>Run</cell><cell>Retriever</cell><cell>Augmenter</cell><cell>Reranker</cell><cell cols="2">Relevance Quality</cell></row><row><cell>1</cell><cell>Sparse</cell><cell>No</cell><cell>Pretrained Cross Encoder</cell><cell>0.456</cell><cell>0.525</cell></row><row><cell>2</cell><cell>Sparse</cell><cell>No</cell><cell>Custom Cross Encoder</cell><cell>0.608</cell><cell>0.803</cell></row><row><cell>3</cell><cell>Sparse + Dense</cell><cell>No</cell><cell>Custom Cross Encoder</cell><cell>0.607</cell><cell>0.783</cell></row><row><cell>4</cell><cell>Dense</cell><cell>No</cell><cell>Custom Cross Encoder</cell><cell>0.507</cell><cell>0.75</cell></row><row><cell>5</cell><cell>Sparse + Dense</cell><cell>Yes</cell><cell>Custom Cross Encoder</cell><cell>0.554</cell><cell>0.752</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,108.93,638.16,62.38,8.97"><p>https://wandb.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,108.93,649.12,143.85,8.97"><p>https://wandb.ai/ragabet/'roberta-base'</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="2,108.93,660.08,91.27,8.97"><p>https://www.mturk.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="2,108.93,671.04,188.05,8.97"><p>The annotations are available on our git repository.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,108.93,671.01,371.88,8.97"><p>https://lucene.apache.org/core/7_0_1/core/org/apache/lucene/search/similarities/BM25Similarity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="5,108.93,660.08,127.08,8.97"><p>https://github.com/nmslib/hnswlib</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="5,108.93,671.03,105.36,8.97"><p>http://ann-benchmarks.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,111.28,394.52,10.91;7,112.66,124.83,393.33,10.91;7,112.66,138.38,66.41,10.91" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,338.25,124.83,167.73,10.91;7,112.66,138.38,35.82,10.91">Overview of touché 2021: Argument retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,151.93,393.54,10.91;7,112.66,165.48,226.50,10.91" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,416.97,151.93,89.23,10.91;7,112.66,165.48,165.33,10.91">Data acquisition for argument search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>KI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,179.03,349.90,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m" coord="7,206.07,179.03,126.93,10.91">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,192.57,393.33,10.91;7,112.66,206.12,325.37,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,478.42,192.57,27.57,10.91;7,112.66,206.12,239.86,10.91">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Oğuz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,375.96,206.12,30.55,10.91">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,219.67,395.17,10.91;7,112.66,233.22,225.52,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00181</idno>
		<title level="m" coord="7,324.06,219.67,183.78,10.91;7,112.66,233.22,96.05,10.91">Sparse, dense, and attentional representations for text retrieval</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,246.77,393.33,10.91;7,112.66,260.32,311.37,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="7,326.58,246.77,179.40,10.91;7,112.66,260.32,181.08,10.91">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,273.87,395.17,10.91;7,112.66,287.42,395.01,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="7,137.85,287.42,241.29,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,300.97,395.01,10.91;7,112.66,314.52,395.01,10.91;7,112.66,330.51,97.35,7.90" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10964</idno>
		<title level="m" coord="7,146.78,314.52,328.55,10.91">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,341.62,394.61,10.91;7,112.66,355.17,394.91,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,276.77,341.62,230.50,10.91;7,112.66,355.17,100.69,10.91">Common concerns with mturk as a participant pool: Evidence and solutions</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paolacci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Chandler</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/uq45c</idno>
		<ptr target="psyarxiv.com/uq45c.doi:10.31234/osf.io/uq45c" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,368.71,395.17,10.91;7,112.66,382.26,395.01,10.91;7,112.66,395.81,119.84,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,346.60,368.71,161.23,10.91;7,112.66,382.26,206.65,10.91">Ethical norms and issues in crowdsourcing practices: A habermasian analysis</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Schlagwein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cecez-Kecmanovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hanckel</surname></persName>
		</author>
		<idno type="DOI">10.1111/isj.12227</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,337.26,382.26,135.41,10.91">Information Systems Journal</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,409.36,394.53,10.91;7,112.66,422.91,139.20,10.91" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="7,224.86,409.36,170.00,10.91">Sentence-transformers documentation</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://www.sbert.net/,2019" />
		<imprint>
			<date type="published" when="2021-05-28">05/28/2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,436.46,394.53,10.91;7,112.66,450.01,122.77,10.91" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m" coord="7,219.42,436.46,283.17,10.91">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,463.56,393.33,10.91;7,112.66,477.11,368.73,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,351.26,463.56,154.72,10.91;7,112.66,477.11,295.50,10.91">Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-A</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,490.66,394.53,10.91;7,112.66,504.21,393.71,10.91;7,112.66,517.76,388.45,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<title level="m" coord="7,448.57,504.21,57.79,10.91;7,112.66,517.76,258.71,10.91">Ms marco: A human generated machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,531.30,394.62,10.91;7,112.66,544.85,267.76,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,381.36,531.30,125.92,10.91;7,112.66,544.85,175.27,10.91">Bridging the lexical chasm: statistical approaches to answer-finding</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,311.16,544.85,39.98,10.91">SIGIR &apos;00</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,558.40,395.17,10.91;7,112.66,571.95,393.32,10.91;7,112.33,585.50,29.19,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,177.68,558.40,191.34,10.91">When documents are very long, bm25 fails!</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,376.33,558.40,131.50,10.91;7,112.66,571.95,393.32,10.91">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,599.05,393.33,10.91;7,112.66,612.60,341.42,10.91" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">A</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Yashunin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09320</idno>
		<title level="m" coord="7,247.51,599.05,258.47,10.91;7,112.66,612.60,211.25,10.91">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,626.15,395.17,10.91;7,112.66,639.70,395.01,10.91" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="7,356.24,626.15,151.60,10.91;7,112.66,639.70,362.53,10.91">Augmented sbert: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
