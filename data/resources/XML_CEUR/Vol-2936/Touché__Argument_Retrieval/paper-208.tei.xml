<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,399.88,15.42;1,89.29,110.65,324.97,5.42">Development of an IR System for Argument Search Notebook for the Touch√© Lab on Argument Retrieval at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,136.56,64.34,5.42"><forename type="first">Marco</forename><surname>Alecci</surname></persName>
							<email>marco.alecci@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.28,136.56,78.16,5.42"><forename type="first">Tommaso</forename><surname>Baldo</surname></persName>
							<email>tommaso.baldo@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.09,136.56,74.56,5.42"><forename type="first">Luca</forename><surname>Martinelli</surname></persName>
							<email>luca.martinelli.1@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.65,136.56,57.58,5.42"><forename type="first">Elia</forename><surname>Ziroldo</surname></persName>
							<email>elia.ziroldo@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,399.88,15.42;1,89.29,110.65,324.97,5.42">Development of an IR System for Argument Search Notebook for the Touch√© Lab on Argument Retrieval at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">6F8D7EDDAEE1B756312E38C4527D4638</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Search Engine</term>
					<term>Argument Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Search engines are the easiest way to find the information that we need in our daily life, and they have became more and more powerful in the last years. Anyway, they are still far from perfection, and some problems afflict also the more advanced search engines. In this paper we discuss our approach to the problem of argument retrieval documenting our participation to the CLEF 2021 Touch√© Task 1. In particular, we present our IR system for the args.me corpus, a collection of documents extracted from web debate portals. After a pre-processing phase of the documents, we tried to use different methods like query expansion and re-ranking based on sentiment analysis. In the final part we report the results of our experiments and discuss about them and about other possible strategies that can be applied in the future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the last decade, our everyday life has became more and more strictly connected to the web and the use of search engines is one of the most common tasks in our daily routine. Indeed they are the easiest and most reliable way to get information about anything we need, but unfortunately they are still far from perfection. One of the problems that afflict search engines concerns the retrieval of arguments, that according to previous existing works, could be defined as a single conclusion supported by one or more premises <ref type="bibr" coords="1,349.36,459.56,11.43,4.94" target="#b0">[1]</ref>.</p><p>To give our contribution to the resolution of this problem, we decided to participate to the Touch√© 2021 Lab <ref type="bibr" coords="1,185.54,501.86,13.00,4.94" target="#b1">[2]</ref> on argument retrieval 1 proposed by CLEF 2 because we believe that argument retrieval is a crucial feature , especially in these days, when the web sources such as social media community and blogs are growing faster and faster. Among two different Tasks proposed from Touch√® Lab we decided to take part to Task 1 that regards argument retrieval from debates on controversial topics. The dataset is the one used by the argument search engine args.me <ref type="bibr" coords="2,126.67,90.23,12.84,4.94" target="#b2">[3]</ref> and we chose to use the downloadable corpus <ref type="foot" coords="2,345.85,87.59,3.71,3.61" target="#foot_0">3</ref> .</p><p>The paper is organized as follows: in Sec. 2 we describe some related works concerning argument retrieval. Then, in Sec. 3 we examine our approach to solve the task. After the pre-processing of the documents we tried to implement three different strategies : different weights for the fields of a document, query expansion with synonyms from WordNet <ref type="foot" coords="2,481.70,157.00,3.71,3.61" target="#foot_1">4</ref> and re-ranking with sentiment analysis. To select the parameters and the weights used by our methods, we relied on the scores obtained from our system using the topics from Touch√© 2020 Lab. Going further, in Sec. <ref type="bibr" coords="2,212.87,200.28,5.17,4.94" target="#b3">4</ref> we describe the experimental setup we used during our works, meanwhile Sec. 5 is for result analysis. Finally, Sec. 6 is about our final considerations and discussions for possible future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Different previous studies has been carried out to try to resolve the problem of argument search, but our starting point was the overview of the last years edition of the Touch√© Lab <ref type="bibr" coords="2,492.44,299.56,11.42,4.94" target="#b3">[4]</ref>. The common approach followed by the participating teams was constituted by three main parts: (1) a retrieval strategy; <ref type="bibr" coords="2,193.24,326.65,11.66,4.94" target="#b1">(2)</ref> an augmentation component like query expansion (3) a re-ranking component which modifies the score of the initially retrieved documents.</p><p>The most two used model were BM25 and LMDirichlet, while other few teams used DPH or TFIDF. The argument search engine args.me <ref type="bibr" coords="2,286.32,382.51,11.28,4.94" target="#b4">[5]</ref>, from which the corpus was extracted, is based on the retrieval model BM25. Anyway, previous studies compared different retrieval models and demonstrated how LMDirichlet and DPH are better suited for argument retrieval <ref type="bibr" coords="2,479.96,409.61,11.43,4.94" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pre-processing</head><p>A fundamental step for argument retrieval is the pre-processing of the documents. One possible approach is the one followed by Staudte et al. <ref type="bibr" coords="2,349.02,472.89,12.99,4.94" target="#b6">[7]</ref> that regards primarily the preprocessing of the words instead of the whole documents. They started with basic things such as removing punctuation, URL and square brackets, but then they also introduced more specific rules such replacing a repetition (&gt;2) of the same letter with a single one. Indeed, in blogs and social media users frequently write in colloquial language repeating the same letter more than once. They also deleted arguments smaller than 26 words since users make short arguments to express agreement or disagreement with a previous argument rather than to express their own reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Query expansion</head><p>A query represents the information need by a user, but usually they are a bit too short to find the most relevant documents. For example, due to a vocabulary mismatch the Information Retrieval (IR) system can discard a document that in reality was relevant. To avoid this problem query are often expanded with more terms to reduce the gap between the query and concepts that users wanted to express. The approach was followed by Akiki et al. <ref type="bibr" coords="3,407.86,117.33,12.70,4.94" target="#b7">[8]</ref> make use of GPT-2 model <ref type="bibr" coords="3,120.12,130.88,12.99,4.94" target="#b8">[9]</ref> to add argumentative text to the original query. Then a new set of queries is built from the generated sentences. Another possible solution is the use of lexical properties to add new terms to the original query. Bundesmann et al. <ref type="bibr" coords="3,328.42,157.97,18.07,4.94" target="#b9">[10]</ref> implement this strategy by adding synonyms taken from WordNet database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Re-ranking</head><p>After the retrieval of the most relevant documents, an IR system can re-rank the candidates to consider additional criteria that can involve different features of the documents. In the paper provided by Shahshahani et al. <ref type="bibr" coords="3,257.39,248.35,16.26,4.94" target="#b10">[11]</ref>, they described how their final ranking is produced using the learning-to-rank library RankLib<ref type="foot" coords="3,276.37,259.26,3.71,3.61" target="#foot_2">5</ref> to incorporate argument quality and Named Entity Recognition. Their assumption is that recognized entities mean that the premises are more persuasive and effective. Another approach presented by Dumani et al. <ref type="bibr" coords="3,398.70,289.00,17.76,4.94" target="#b11">[12]</ref> is to group premises that support the same conclusion. After this is possible to calculate a score that indicate how much a premise is convincing in comparison to other premises of the same claim. The solution provided by Bundesmann et al. <ref type="bibr" coords="3,269.52,329.64,17.91,4.94" target="#b9">[10]</ref> uses a machine learning approach to process the initial documents and assign them a score indicating their argumentative quality. According to Wachsmuth et al. <ref type="bibr" coords="3,183.58,356.74,18.07,4.94" target="#b12">[13]</ref> they annotated a score for each one of these three aspects: Logical quality, Rhetorical quality and Dialectical quality. Another possible strategy to follow is the use of sentiment analysis to determine the sentiment of a document, and so how much its author is emotionally involved. Indeed to deal with argument retrieval, it is crucial to be able to understand the emotions and the writer's frame of mind. Since several studies <ref type="bibr" coords="3,446.58,410.94,12.99,4.94" target="#b2">[3]</ref> underline that an emotional argument is more powerful than a neutral or impassive one, Staude et al. <ref type="bibr" coords="3,89.29,438.04,13.00,4.94" target="#b6">[7]</ref> decided to encourage the emotional documents combining their DPH score with the one calculated with sentiment analysis. By contrast, another team from the previous edition of Touch√©, decided to assign an higher score to the neutral arguments, assuming that a neutral sentiment coincides with higher relevance of a document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>As a starting point, we pre-processed all the documents contained in the args.me corpus, removing stop words and applying different filters. To create the index and to perform the search we relied on Apache Lucene <ref type="foot" coords="3,241.92,561.78,3.71,3.61" target="#foot_3">6</ref> . Since BM25 and LMDirichlet were the most used models in the previous edition of Touch√© Lab, and since also args.me search engine relies on BM25 we decided to use the Lucene's implementation of these two models. Then we tried three different methods to improve the performance of our IR system:</p><p>‚Ä¢ Assigning different weights to different fields of the documents. ‚Ä¢ Query expansion using synonyms extracted from WordNet.</p><p>‚Ä¢ Re-ranking using the score obtained by performing sentiment analysis on the documents. First, we followed each one of these strategies separately to find the best parameters/weights to use with them. After, we tried to combine all the three techniques at the same time to see the effects with respect to the base implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pre Processing</head><p>Our approach in creating Lucene Documents<ref type="foot" coords="4,298.58,185.92,3.71,3.61" target="#foot_4">7</ref> was to store different information in independent fields, in order to assign distinct weights to each field. Additionally to the field that store the identification number of the document and the field that store the stance of the document, we decided to create three other fields for the premises, the conclusion and the body. The body field, in particular, contains both premises and conclusion, and extra information about the document. These information are, in order, acquisition time, source URL, topic, author, author role and author organization, source domain and discussion title. We decided to not keep the source text because we noticed that it contains too much useless terms, such as copyright information, navigation menus, site map etc. . . . We decided to adopt the ClassicTokenizer<ref type="foot" coords="4,303.65,322.91,3.71,3.61" target="#foot_5">8</ref> provided by Apache Lucene. This is a simple grammar-based tokenizer constructed with the lexical analyzer generator JFlex. It's designed to be a good tokenizer for most European-language documents: it splits words at punctuation characters, removing them. However, a dot that's not followed by a whitespace is considered part of a token. As a result it splits words at hyphens, unless there's a number in the token, in which case the whole token is interpreted as a product number and is not split. It recognizes email addresses and internet hostnames as one token.</p><p>Beyond this we implemented the LowerCaseFilter<ref type="foot" coords="4,341.59,432.81,3.71,3.61" target="#foot_6">9</ref> , in order to normalize all tokens to lower case. This also allows terms of the query to match with terms in the documents written, for example, in upper case. The next filter we used is the LengthFilter<ref type="foot" coords="4,391.62,459.91,7.41,3.61" target="#foot_7">10</ref> . This filter keeps tokens with a length between 3 and 20 characters, removing the others. A significant improvement on the score has been noted, due to the exclusion of many words not informative, such as I, be, me, a, etc. The last filter we applied is a custom filter that excludes equal consecutive letters if they're more than three. This filter is useful to remove typos or words emphasized e.g. helllo or yesssss becames relatively hello and yess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">StopLists</head><p>Stopword filtering is a common step in preprocessing text because it removes lots of not informative words. We realized that stoplists have a considerable impact on the nDCG@5 score. So we tried different lists, as reported in Tab. 1 and Tab. 2. The nDCG@5 was computed using only Lucene's LMDirichlet implementation with no pre processing and without following any of the techniques previously described, in order to take into account only the stoplists. The max score were obtanied with the stoplist EBSCOhost 11 : it is a list of 24 words used in EBSCOhost medical databases MEDLINE and CINAHL. In general we saw that lists with more words generally decrease the score. In fact using an empty stoplist the score was overall on the average. After that we tried to create a stoplist with the 150 most frequent terms in the index (150 custom). We found that it has an average score, too. Then we have integrated EBSCOhost with the ten, twenty and thirty most frequent terms not yet present in the stoplist. The score with the first two attempts was just a little lower than stock EBSCOhost, and it decreases significantly adding more words (e.g. EBSCOhost+30), confirming that in this situation a small stoplist is the best solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stock stoplists</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Stemmers</head><p>Stemming is the reduction of a word into its base form, called stem. In particular we tried in four different ways, synthesized in Tab. 3. The nDCG@5 was computed using only Lucene's LMDirichlet implementation with no pre processing and without following any of the techniques previously described, in order to take into account only the stemmers. First of all we didn't use any form of stemming. After that we tried to implement three different stemmers included in Lucene package. We started with the EnglishMinimalStemFilter 12 , that simply stems plural English words to their singular form. Then, in the second way we used the KStemFilter 13 . This filter implements the Krovetz stemmer, an hybrid algorithmic-dictionary that produces words. For the last, we tried the most used filter in IR, the Porter stemmer, implemented in Lucene as PorterStemFilter 14 , that eliminates the longest suffix possibile, working in steps and trying to delete each suffix every time, until it reaches the base form for generate stems. As already seen in Sec. 3.1.1, adding complexity to the system, the score obtained decreases, this probably due to limitations of stemmers used <ref type="bibr" coords="6,401.32,273.39,16.25,4.94" target="#b13">[14]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stem</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Different fields' weights</head><p>Since documents have more than one field to search in, at query time it is possible to assign different weights to each field. In this way, a term found in a field with an higher weight, will also have an higher impact on the final score of the document. As already explained in Sec. 3.1, we decided to have three different fields containing respectively the body, the premises and the conclusion. We noticed that premises are the most informative field, instead the conclusions are often composed by one single term, and very rarely this is relevant. According to these considerations, the best score would be obtained assigning an higher weight to the premises, and a lower one to the body and the conclusions.</p><p>To choose the best values, we wrote a Python program that automatically calculates, using trec_eval, the nDCG@5 among all possibilities of weights (to each field) from 0 to 1, with a step of 0.25. The best five combinations of weights are in the Tab. 4, using BM25 as similarity, and in the Tab. 5, using LMDirichlet similarity. In both cases we pre-processed the documents using the best options obtained in Sec. 3.1.1 and Sec. 3.1.2: no stemmers and EBSCO stoplist. In 12 https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/en/EnglishMinimalStemFilter.html 13 https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/en/KStemFilter.html 14 https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/en/PorterStemFilter.html the Tab. 9 in Sec. 7 are listed all the tried combinations for both similarities. These results are in agreement with the previous considerations and they confirm our theories. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Body Premises</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Query Expansion</head><p>Query expansion is a technique used to match more relevant documents, by expanding or reformulating the basic search query. To improve the retrieval performances of our model we tried to integrate query expansion in our IR system by adding to a query all the synonyms of the terms that are left after the pre-processing phase. In particular, we decided to use WordNet: a lexical database of semantic relations between words. In fact the SynonymMap<ref type="foot" coords="7,440.80,468.08,7.41,3.61" target="#foot_8">15</ref> object of the WordNet package allows to load the file downloaded from WordNet <ref type="foot" coords="7,382.93,481.63,7.41,3.61" target="#foot_9">16</ref> into an hash map that can be used for fast high-frequency lookups of synonyms. We decided to assign a different weight to the synonyms added at query time to give them more or less importance in the search. We tried different values and the results are reported in Tab. 6. We pre-processed the documents using the best options obtained in Sec. 3.1.1 and Sec. 3.1.2: no stemmers and EBSCO stoplist. As can be noticed, using BM25 similarity with a weight of 0.4 to the synonyms there is an increase of the evaluated score. On the contrary, using LMDirichlet similarity adding synonyms brings no improvement. This probably is caused by an increment of noise that causes matches with non relevant documents, decreasing the final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>nDCG@5 Synonyms Weight BM25 LMDirichlet</head><p>No </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Re-ranking</head><p>In the last step, we re-ranked the top 30 documents retrieved from the previous phase performing a sentiment analysis on the arguments. To perform the analysis we used the VADER tool <ref type="bibr" coords="8,109.73,361.71,18.07,4.94" target="#b14">[15]</ref> and in particular the Java port provided by Animesh Pandey on Github 17 . This tool allows to compute a value between -1 and 1 for each argument. Values greater than 0 represent a positive sentiment from the author, while values lower than 0 indicate negativity. The values that are closer to 0 express neutral sentiment.</p><p>We decided to try two different approaches to do the re-ranking:</p><p>1. Promote emotional documents combining the score from the previous phase with the sentiment analysis score, using Eq. 1</p><formula xml:id="formula_0" coords="8,225.95,496.28,280.04,24.43">1 3 * ùëÜùëêùëúùëüùëí + 2 3 * |ùëÜùëíùëõùë°ùëñùëöùëíùëõùë°| * ùëÜùëêùëúùëüùëí<label>(1)</label></formula><p>2. Promote neutral documents instead of emotional ones, using Eq. 2</p><formula xml:id="formula_1" coords="8,225.95,564.12,280.04,24.43">1 3 * ùëÜùëêùëúùëüùëí - 2 3 * |ùëÜùëíùëõùë°ùëñùëöùëíùëõùë°| * ùëÜùëêùëúùëüùëí<label>(2)</label></formula><p>We decided to give more importance to the sentiment score, using an higher value in Eq. 1 and Eq. 2, since using lower values we could not observe any improvements. We tried to re-rank both with sentiment score computed on premises and on conclusions to see which strategy could be the right one. The results are provided in Tab. 7. We pre-processed the documents using the best options obtained in Sec. 3.1.1 and Sec. 3.1.2: no stemmers and EBSCO stoplist.</p><p>As we can see, with the sentiment scores computed on the conclusion the scores decrease drastically with both approaches and with both models. This is probably due to the fact that conclusions are often composed by few words (sometimes only one) and so the sentiment score doesn't perfectly express the true sentiment of the author. Using the sentiment scores computed on the premises, the scores drops almost to zero when we give more importance to neutral documents, while we can see a little improvement of the score (BM25) and almost the same value (LMDirichlet) when we promote emotional documents. Hence we can affirm that an higher absolute value of the sentiment score leads to better argumentation and so to a general high relevance of the retrieved documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>nDCG@5 Sentiment on premises</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup</head><p>Touch√® Task 1 offers us the possibilities to access the args.me corpus via the API of args.me search engine or downloading the file containing all the documents. We decided to download the entire corpus and in the particular the version updated to 2020-04-01. For the Touch√® Task 1 we also used TIRA platform <ref type="bibr" coords="9,248.28,442.95,17.96,4.94" target="#b15">[16]</ref> to submit and evaluate our model. Indeed, a working implementation of your approach is available in TIRA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Description</head><p>The updated version of the args.me corpus contains 387,740 arguments crawled from four debate portals (debatewise.org, idebate.org, debatepedia.org, and debate.org), and 48 arguments from Canadian parliament discussions. The arguments were extracted using heuristics that are designed for each debate portal. Each argument is identified by an ID an it is constituted by a conclusion and one or more premises. For each document there are also present some information about the context like the source URL, the title of the discussion and many others.</p><p>For what concern the topics, Touch√© Lab provided us 50 controversial topics (the query potentially issued by a user), Each topic has both pro and con relevant arguments present in the document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation measures</head><p>We used the Normalized Discounted Cumulated Gain (nDCG) <ref type="bibr" coords="10,373.55,110.80,18.07,4.94" target="#b16">[17]</ref> score with an evaluation depth of 5 since this is the same evaluation measure used by Touch√© Lab to evaluate our runs. In particular, we used the implementation provided by the trec_eval library <ref type="foot" coords="10,426.55,135.26,7.41,3.61" target="#foot_10">18</ref> , to measure the performance of our IR system. The nDCG is the result of Eq. 3. Parameter ùëè indicates the patience of the user in scanning the result lists, and usually it is a value of 2 for an impatient user, or 10 for a patient user. To compute the Discounted Cumulated Gain (DCG) score, trec_eval uses as parameter ùëè the value of 2. Since the result is not bounded in [0,1], it is necessary normalize the score dividing nDCG by the Ideal Discounted Cumulated Gain (iDCG), provided by Touch√© Lab, as can be seen in Eq. 4. The iDCG can be obtained sorting all relevant documents in the corpus by their relative relevance, and producing the maximum possible DCG through position 5.</p><formula xml:id="formula_2" coords="10,214.99,266.54,290.99,33.58">ùê∑ùê∂ùê∫@5 = 5 ‚àëÔ∏Å ùëõ=1 ùëüùëíùëôùëíùë£ùëéùëõùëêùëí ùëõ max (1, log ùëè (ùëñ + 1))<label>(3)</label></formula><p>ùëõùê∑ùê∂ùê∫@5 = ùê∑ùê∂ùê∫@5 ùëñùê∑ùê∂ùê∫@5 (4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results</head><p>As previously mentioned, we first tried all the different techniques separately to choose the best parameters/weights for each method, then we merged all together using the three strategies at the same time. In all cases we pre-processed the documents using the best options obtained in Sec. Looking at Tab. 8 we can notice that with the BM25 similarity all the three methods worked well increasing the score of the base case, but the score achieved with the combination of all the three techniques is not the best one. For what concerns the LMDirichlet model we can see that the final score is lower than the base one, while the best is the one that doesn't use query expansion and sentiment analysis. Hence, these two techniques have not worked well with the LMDirichlet model and so they leads to lower performance when merging all the techniques. The score achieved with the query expansion is very low and it's almost half of the base one. One possible explanation to this phenomenon is the fact that there are too many synonyms for each word and this introduces noise that degrades the performance of the search. In fact according to previous studies <ref type="bibr" coords="11,220.27,186.73,17.79,4.94" target="#b17">[18]</ref> there is no way using only WordNet to select an appropriate subset of synonyms.</p><p>The sentiment analysis leads to a very small improvement for BM25 but for LMDirichlet the score is almost the same. Looking manually at the documents retrieved after the first phase, we discovered that almost all the documents in the top positions have an high sentiment value. According to this, the re-ranking probably doesn't work very well because the documents with an higher sentiment value are already marked as the most relevant ones. Hence it isn't possible to improve the nDCG@5 score because the top ranked documents are also the ones with the higher sentiment score.</p><p>Finally, we can affirm that the LMDirichlet model is better than BM25 for argument retrieval confirming the results obtained by the teams of the previous edition of Touch√© Argument Retrieval Lab <ref type="bibr" coords="11,150.70,366.19,11.43,4.94" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>We implemented our IR system to retrieve the most relevant arguments to the given queries provided in the Touch√© shared task. We used both BM25 and LMDirichlet models, but we demonstrate that LMDirichlet is much better for what concern argument retrieval. We also show how much important is to give the right weight to the different parts of a document, since a lot of information can be useless during the search. Anyway there are some aspects that can be improved to reach better performances. For example, instead of expanding the queries simply adding all the synonyms of a specific word, it would be better to associate a score to each synonym to indicate how much the two word are similar, and then use it to weight the different synonyms while performing the query. Another improvement can be done by using a better formula to re-rank the documents or maybe using a different score instead of the one retrieved with sentiment analysis. For example, with a machine learning approach it would be possible to train a model to assign a quality score to each argument and then use this value to re-rank the top retrieved documents.</p><p>To conclude, we presented our approach to the problem of argument retrieval and we think that in the future always better solutions will be presented, especially with the help of machine learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">APPENDIX A :</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,159.34,234.08,276.26,375.53"><head>Table 1 :</head><label>1</label><figDesc>nDCG@5 scores obtained with different stock stoplists.</figDesc><table coords="5,177.60,234.08,240.09,375.53"><row><cell></cell><cell cols="2">Number of words nDCG@5</cell></row><row><cell>tent1</cell><cell>400</cell><cell>0.5599</cell></row><row><cell>Air3z4</cell><cell>1298</cell><cell>0.5757</cell></row><row><cell>zettair</cell><cell>469</cell><cell>0.5790</cell></row><row><cell>smart</cell><cell>571</cell><cell>0.5895</cell></row><row><cell>terrier</cell><cell>733</cell><cell>0.5919</cell></row><row><cell>cook1988</cell><cell>221</cell><cell>0.6043</cell></row><row><cell>taporwave</cell><cell>485</cell><cell>0.6068</cell></row><row><cell>postgre</cell><cell>127</cell><cell>0.6078</cell></row><row><cell>nltk</cell><cell>153</cell><cell>0.6078</cell></row><row><cell>lexisnexis</cell><cell>100</cell><cell>0.6131</cell></row><row><cell>NO STOPLIST</cell><cell>0</cell><cell>0.6189</cell></row><row><cell>corenlp</cell><cell>28</cell><cell>0.6211</cell></row><row><cell>okapi</cell><cell>108</cell><cell>0.6224</cell></row><row><cell>ranksnl</cell><cell>32</cell><cell>0.6249</cell></row><row><cell>lucene_elastic</cell><cell>33</cell><cell>0.6256</cell></row><row><cell>ovid</cell><cell>39</cell><cell>0.6259</cell></row><row><cell>lingpipe</cell><cell>76</cell><cell>0.6260</cell></row><row><cell>EBSCOhost</cell><cell>24</cell><cell>0.6265</cell></row><row><cell cols="3">Custom stoplists Number of words nDCG@5</cell></row><row><cell>150_custom</cell><cell>150</cell><cell>0.6066</cell></row><row><cell>ebsco+10</cell><cell>34</cell><cell>0.6258</cell></row><row><cell>ebsco+20</cell><cell>44</cell><cell>0.6258</cell></row><row><cell>ebsco+30</cell><cell>54</cell><cell>0.6123</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,89.29,627.76,391.28,50.02"><head>Table 2 :</head><label>2</label><figDesc>nDCG@5 scores obtained with custom stoplists.</figDesc><table coords="5,89.29,660.30,391.28,17.48"><row><cell>11 https://connect.ebsco.com/s/article/What-are-the-stop-words-used-in-EBSCOhost-medical-databases-</cell></row><row><cell>MEDLINE-and-CINAHL</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,167.32,295.48,260.30,89.11"><head>Table 3 :</head><label>3</label><figDesc>nDCG@5 scores obtained using different stemmers.</figDesc><table coords="6,218.79,295.48,157.71,63.06"><row><cell>Filter</cell><cell>nDCG@5</cell></row><row><cell>No Stem</cell><cell>0.6265</cell></row><row><cell>English Minimal Stem</cell><cell>0.6184</cell></row><row><cell>Krovetz Stem</cell><cell>0.5747</cell></row><row><cell>Porter Stem</cell><cell>0.5401</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,136.30,125.87,322.34,208.51"><head>Table 4 :</head><label>4</label><figDesc>nDCG@5 scores obtained with different fieds' weights and BM25.</figDesc><table coords="7,190.15,125.87,214.98,208.51"><row><cell></cell><cell></cell><cell cols="2">Conclusions nDCG@5</cell></row><row><cell>0.0</cell><cell>1.0</cell><cell>0.25</cell><cell>0.4150</cell></row><row><cell>0.25</cell><cell>1.0</cell><cell>0.25</cell><cell>0.4143</cell></row><row><cell>0.5</cell><cell>1.0</cell><cell>0.25</cell><cell>0.4032</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.4029</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.4023</cell></row><row><cell cols="4">Body Premises Conclusions nDCG@5</cell></row><row><cell>0.25</cell><cell>1</cell><cell>0</cell><cell>0.7379</cell></row><row><cell>0</cell><cell>1</cell><cell>0</cell><cell>0.7345</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0</cell><cell>0.7331</cell></row><row><cell>0.5</cell><cell>1</cell><cell>0</cell><cell>0.7239</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0</cell><cell>0.7123</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,116.44,352.53,362.06,7.90"><head>Table 5 :</head><label>5</label><figDesc>nDCG@5 scores obtained with different fields' weights and LMDirichlet.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,101.24,114.72,392.48,172.79"><head>Table 6 :</head><label>6</label><figDesc>nDCG@5 scores obtained with different weight to synonyms in query expansion.</figDesc><table coords="8,225.42,114.72,160.22,146.74"><row><cell>synoynms</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>0.1</cell><cell>0.4113</cell><cell>0.6986</cell></row><row><cell>0.2</cell><cell>0.4159</cell><cell>0.6483</cell></row><row><cell>0.3</cell><cell>0.3973</cell><cell>0.5913</cell></row><row><cell>0.4</cell><cell>0.3898</cell><cell>0.5267</cell></row><row><cell>0.5</cell><cell>0.3764</cell><cell>0.4731</cell></row><row><cell>0.6</cell><cell>0.3596</cell><cell>0.4273</cell></row><row><cell>0.7</cell><cell>0.3304</cell><cell>0.3847</cell></row><row><cell>0.8</cell><cell>0.2931</cell><cell>0.3406</cell></row><row><cell>0.9</cell><cell>0.2584</cell><cell>0.2892</cell></row><row><cell>1.0</cell><cell>0.2253</cell><cell>0.2564</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,88.96,234.66,418.86,100.52"><head>Table 7 :</head><label>7</label><figDesc>nDCG@5 scores obtained with BM25 and LMDirichlet similarities and different configurations of sentiment analysis.</figDesc><table coords="9,123.99,234.66,347.30,65.59"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Sentiment on conclusions</cell></row><row><cell></cell><cell>BM25</cell><cell>LMDirichlet</cell><cell>BM25</cell><cell>LMDirichlet</cell></row><row><cell>No sentiment</cell><cell>0.3938</cell><cell>0.7345</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>Neutral is better</cell><cell>0.0811</cell><cell>0.0569</cell><cell>0.0811</cell><cell>0.0569</cell></row><row><cell cols="2">Emotional is better 0.4362</cell><cell>0.6952</cell><cell>0.1423</cell><cell>0.1414</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,89.29,438.41,416.69,142.67"><head>Best different fields weights 0.4698 0.8026 Best query expansion with synonyms</head><label></label><figDesc>3.1.1 and Sec. 3.1.2: no stemmers and EBSCO stoplist. In Tab. 8 we reported the best score achieved for each method and in the last line we show the score obtained by using all the techniques.</figDesc><table coords="10,144.24,487.60,306.79,93.48"><row><cell></cell><cell cols="2">nCDG@5</cell></row><row><cell></cell><cell cols="2">BM25 LMDirchlet</cell></row><row><cell>Base</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell></cell><cell>0.4159</cell><cell>0.6986</cell></row><row><cell cols="2">Best re-ranking with sentiment analysis 0.4362</cell><cell>0.6952</cell></row><row><cell>Merging all three strategies</cell><cell>0.4521</cell><cell>0.6661</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,126.63,596.70,341.69,7.90"><head>Table 8 :</head><label>8</label><figDesc>nDCG@5 final scores obtained with the different presented strategies.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="14,106.78,85.67,392.78,590.14"><head>Table with all combinations of field's weights with BM25 and LMDirichlet</head><label></label><figDesc></figDesc><table coords="14,113.61,138.53,368.06,537.28"><row><cell cols="5">Body Premises Conclusions nDCG@5 BM25 nDCG@5 LMDirichlet</cell></row><row><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.0024</cell><cell>0.0024</cell></row><row><cell>0</cell><cell>0</cell><cell>0.25</cell><cell>0.153</cell><cell>0.1618</cell></row><row><cell>0</cell><cell>0</cell><cell>0.5</cell><cell>0.153</cell><cell>0.1618</cell></row><row><cell>0</cell><cell>0</cell><cell>0.75</cell><cell>0.153</cell><cell>0.1618</cell></row><row><cell>0</cell><cell>0</cell><cell>1</cell><cell>0.153</cell><cell>0.1618</cell></row><row><cell>0</cell><cell>0.25</cell><cell>0</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>0</cell><cell>0.25</cell><cell>0.25</cell><cell>0.3191</cell><cell>0.6147</cell></row><row><cell>0</cell><cell>0.25</cell><cell>0.5</cell><cell>0.2954</cell><cell>0.5228</cell></row><row><cell>0</cell><cell>0.25</cell><cell>0.75</cell><cell>0.2835</cell><cell>0.4491</cell></row><row><cell>0</cell><cell>0.25</cell><cell>1</cell><cell>0.2631</cell><cell>0.414</cell></row><row><cell>0</cell><cell>0.5</cell><cell>0</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>0</cell><cell>0.5</cell><cell>0.25</cell><cell>0.3827</cell><cell>0.6606</cell></row><row><cell>0</cell><cell>0.5</cell><cell>0.5</cell><cell>0.3191</cell><cell>0.6147</cell></row><row><cell>0</cell><cell>0.5</cell><cell>0.75</cell><cell>0.3035</cell><cell>0.5709</cell></row><row><cell>0</cell><cell>0.5</cell><cell>1</cell><cell>0.2954</cell><cell>0.5228</cell></row><row><cell>0</cell><cell>0.75</cell><cell>0</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>0</cell><cell>0.75</cell><cell>0.25</cell><cell>0.3996</cell><cell>0.6829</cell></row><row><cell>0</cell><cell>0.75</cell><cell>0.5</cell><cell>0.3516</cell><cell>0.6524</cell></row><row><cell>0</cell><cell>0.75</cell><cell>0.75</cell><cell>0.3191</cell><cell>0.6147</cell></row><row><cell>0</cell><cell>0.75</cell><cell>1</cell><cell>0.3061</cell><cell>0.5947</cell></row><row><cell>0</cell><cell>1</cell><cell>0</cell><cell>0.3938</cell><cell>0.7345</cell></row><row><cell>0</cell><cell>1</cell><cell>0.25</cell><cell>0.415</cell><cell>0.6849</cell></row><row><cell>0</cell><cell>1</cell><cell>0.5</cell><cell>0.3827</cell><cell>0.6606</cell></row><row><cell>0</cell><cell>1</cell><cell>0.75</cell><cell>0.3438</cell><cell>0.6455</cell></row><row><cell>0</cell><cell>1</cell><cell>1</cell><cell>0.3191</cell><cell>0.6147</cell></row><row><cell>0.25</cell><cell>0</cell><cell>0</cell><cell>0.3309</cell><cell>0.6513</cell></row><row><cell>0.25</cell><cell>0</cell><cell>0.25</cell><cell>0.2562</cell><cell>0.5294</cell></row><row><cell>0.25</cell><cell>0</cell><cell>0.5</cell><cell>0.2397</cell><cell>0.4395</cell></row><row><cell>0.25</cell><cell>0</cell><cell>0.75</cell><cell>0.2326</cell><cell>0.4001</cell></row><row><cell>0.25</cell><cell>0</cell><cell>1</cell><cell>0.233</cell><cell>0.3596</cell></row><row><cell>0.25</cell><cell>0.25</cell><cell>0</cell><cell>0.3875</cell><cell>0.7095</cell></row><row><cell>0.25</cell><cell>0.25</cell><cell>0.25</cell><cell>0.351</cell><cell>0.6345</cell></row><row><cell>0.25</cell><cell>0.25</cell><cell>0.5</cell><cell>0.3036</cell><cell>0.585</cell></row><row><cell>0.25</cell><cell>0.25</cell><cell>0.75</cell><cell>0.2902</cell><cell>0.5395</cell></row><row><cell>0.25</cell><cell>0.25</cell><cell>1</cell><cell>0.2757</cell><cell>0.4881</cell></row><row><cell>0.25</cell><cell>0.5</cell><cell>0</cell><cell>0.3817</cell><cell>0.7239</cell></row><row><cell>0.25</cell><cell>0.5</cell><cell>0.25</cell><cell>0.3773</cell><cell>0.6605</cell></row><row><cell>0.25</cell><cell>0.5</cell><cell>0.5</cell><cell>0.3362</cell><cell>0.6278</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="15,113.61,86.43,368.06,579.12"><head>Table continued from previous page Body Premises Conclusions nDCG@5 BM25 nDCG@5 LMDirichlet</head><label></label><figDesc></figDesc><table coords="15,117.51,116.65,324.58,548.90"><row><cell>0.25</cell><cell>0.5</cell><cell>0.75</cell><cell>0.3094</cell><cell>0.5938</cell></row><row><cell>0.25</cell><cell>0.5</cell><cell>1</cell><cell>0.2992</cell><cell>0.5648</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0</cell><cell>0.3955</cell><cell>0.7331</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.4023</cell><cell>0.685</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0.5</cell><cell>0.3672</cell><cell>0.6445</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>0.75</cell><cell>0.3363</cell><cell>0.6269</cell></row><row><cell>0.25</cell><cell>0.75</cell><cell>1</cell><cell>0.313</cell><cell>0.6002</cell></row><row><cell>0.25</cell><cell>1</cell><cell>0</cell><cell>0.3959</cell><cell>0.7379</cell></row><row><cell>0.25</cell><cell>1</cell><cell>0.25</cell><cell>0.4143</cell><cell>0.6903</cell></row><row><cell>0.25</cell><cell>1</cell><cell>0.5</cell><cell>0.3741</cell><cell>0.6603</cell></row><row><cell>0.25</cell><cell>1</cell><cell>0.75</cell><cell>0.3524</cell><cell>0.6411</cell></row><row><cell>0.25</cell><cell>1</cell><cell>1</cell><cell>0.3308</cell><cell>0.6271</cell></row><row><cell>0.5</cell><cell>0</cell><cell>0</cell><cell>0.3309</cell><cell>0.6513</cell></row><row><cell>0.5</cell><cell>0</cell><cell>0.25</cell><cell>0.2793</cell><cell>0.5823</cell></row><row><cell>0.5</cell><cell>0</cell><cell>0.5</cell><cell>0.2562</cell><cell>0.5294</cell></row><row><cell>0.5</cell><cell>0</cell><cell>0.75</cell><cell>0.2444</cell><cell>0.4877</cell></row><row><cell>0.5</cell><cell>0</cell><cell>1</cell><cell>0.2397</cell><cell>0.4395</cell></row><row><cell>0.5</cell><cell>0.25</cell><cell>0</cell><cell>0.3878</cell><cell>0.6962</cell></row><row><cell>0.5</cell><cell>0.25</cell><cell>0.25</cell><cell>0.3548</cell><cell>0.6423</cell></row><row><cell>0.5</cell><cell>0.25</cell><cell>0.5</cell><cell>0.3228</cell><cell>0.6058</cell></row><row><cell>0.5</cell><cell>0.25</cell><cell>0.75</cell><cell>0.2969</cell><cell>0.5631</cell></row><row><cell>0.5</cell><cell>0.25</cell><cell>1</cell><cell>0.2853</cell><cell>0.5292</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>0</cell><cell>0.3875</cell><cell>0.7095</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>0.25</cell><cell>0.3841</cell><cell>0.6624</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.351</cell><cell>0.6345</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>0.75</cell><cell>0.3266</cell><cell>0.6094</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>1</cell><cell>0.3036</cell><cell>0.585</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0</cell><cell>0.3827</cell><cell>0.7123</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0.25</cell><cell>0.4029</cell><cell>0.6698</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0.5</cell><cell>0.3654</cell><cell>0.6462</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>0.75</cell><cell>0.34</cell><cell>0.6314</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>1</cell><cell>0.3239</cell><cell>0.608</cell></row><row><cell>0.5</cell><cell>1</cell><cell>0</cell><cell>0.3817</cell><cell>0.7239</cell></row><row><cell>0.5</cell><cell>1</cell><cell>0.25</cell><cell>0.4032</cell><cell>0.6896</cell></row><row><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>0.3773</cell><cell>0.6605</cell></row><row><cell>0.5</cell><cell>1</cell><cell>0.75</cell><cell>0.3658</cell><cell>0.6384</cell></row><row><cell>0.5</cell><cell>1</cell><cell>1</cell><cell>0.3362</cell><cell>0.6278</cell></row><row><cell>0.75</cell><cell>0</cell><cell>0</cell><cell>0.3309</cell><cell>0.6513</cell></row><row><cell>0.75</cell><cell>0</cell><cell>0.25</cell><cell>0.2881</cell><cell>0.6014</cell></row><row><cell>0.75</cell><cell>0</cell><cell>0.5</cell><cell>0.2776</cell><cell>0.5608</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,108.93,662.74,125.55,4.06"><p>https://zenodo.org/record/3734893</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,108.93,673.70,112.74,4.06"><p>https://wordnet.princeton.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,108.93,662.76,167.48,4.06"><p>https://sourceforge.net/p/lemur/wiki/RankLib</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,108.93,673.71,94.91,4.06"><p>https://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,108.93,640.84,323.19,4.06"><p>https://lucene.apache.org/core/8_8_1/core/org/apache/lucene/document/Document.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="4,108.93,651.80,427.84,4.06"><p>https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/standard/ClassicTokenizer.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="4,108.93,662.76,409.85,4.06"><p>https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/core/LowerCaseFilter.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7" coords="4,108.93,673.72,430.72,4.06"><p>https://lucene.apache.org/core/8_8_1/analyzers-common/org/apache/lucene/analysis/miscellaneous/LengthFilter.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_8" coords="7,108.93,662.66,388.54,4.06"><p>https://lucene.apache.org/core/8_8_1/api/contrib-wordnet/org/apache/lucene/wordnet/SynonymMap.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_9" coords="7,108.93,673.62,148.82,4.06"><p>https://wordnet.princeton.edu/download</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_10" coords="10,108.93,673.72,110.54,4.06"><p>https://trec.nist.gov/trec_eval/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,112.66,114.54,351.21,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,159.62,114.54,145.86,4.94">Walton&apos;s argumentation schemes</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,314.39,114.54,117.56,4.94">OSSA Conference Archive</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,128.09,394.52,4.94;12,112.66,141.64,393.33,4.94;12,112.66,155.19,393.33,4.94;12,112.66,168.74,81.94,4.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,336.55,141.64,169.43,4.94;12,112.66,155.19,38.01,4.94">Overview of Touch√© 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fr√∂be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,173.41,155.19,332.58,4.94;12,112.66,168.74,51.81,4.94">Working Notes Papers of the CLEF 2021 Evaluation Labs, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,182.29,394.53,4.94;12,112.66,195.84,393.33,4.94;12,112.66,209.39,393.33,4.94;12,112.66,222.94,241.88,4.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,112.66,195.84,314.54,4.94">Computational argumentation quality assessment in natural language</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Thijm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,450.78,195.84,55.20,4.94;12,112.66,209.39,393.33,4.94;12,112.66,222.94,46.74,4.94">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,236.48,394.52,4.94;12,112.66,250.03,394.52,4.94;12,112.66,263.58,393.33,4.94;12,112.66,277.13,175.93,4.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,304.79,250.03,198.47,4.94">Overview of touch√© 2020: Argument retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fr√∂be</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,130.06,263.58,375.92,4.94;12,112.66,277.13,44.89,4.94">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="384" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,290.68,394.53,4.94;12,112.30,304.23,394.97,4.94;12,112.66,317.78,395.17,4.94;12,112.66,331.33,394.04,4.94;12,112.14,344.88,188.26,4.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,267.50,304.23,217.89,4.94">Building an argument search engine for the web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5106</idno>
		<ptr target="https://www.aclweb.org/anthology/W17-5106.doi:10.18653/v1/W17-5106" />
	</analytic>
	<monogr>
		<title level="m" coord="12,112.66,317.78,395.17,4.94;12,112.66,331.33,31.52,4.94">Proceedings of the 4th Workshop on Argument Mining, Association for Computational Linguistics</title>
		<meeting>the 4th Workshop on Argument Mining, Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,358.43,394.53,4.94;12,112.66,371.98,395.17,4.94;12,112.66,385.53,394.53,4.94;12,112.66,399.07,395.01,4.94;12,112.66,412.62,362.24,4.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,159.87,371.98,208.97,4.94">Argument search: Assessing argument relevance</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Euchner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heilenk√∂tter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weidmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331327</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331327.doi:10.1145/3331184.3331327" />
	</analytic>
	<monogr>
		<title level="m" coord="12,390.14,371.98,117.69,4.94;12,112.66,385.53,394.53,4.94;12,112.66,399.07,36.22,4.94">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR&apos;19</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR&apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1117" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,426.17,393.33,4.94;12,112.66,439.72,161.84,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,215.72,426.17,290.27,4.94;12,112.66,439.72,46.36,4.94">Sentarg: A hybrid doc2vec/dph model with sentiment analysis refinement</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Staudte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,167.59,439.72,59.39,4.94">Methodology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,453.27,393.33,4.94;12,112.66,466.82,117.16,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,213.79,453.27,214.88,4.94">Exploring argument retrieval with transformers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,437.29,453.27,68.70,4.94;12,112.66,466.82,85.24,4.94">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,480.37,394.53,4.94;12,112.66,493.92,22.69,4.94" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="12,234.77,480.37,268.17,4.94">Improving language understanding by generative pre-training</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,507.47,393.33,4.94;12,112.66,521.02,65.26,4.94" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,291.85,507.47,214.13,4.94;12,112.66,521.02,33.34,4.94">Creating an argument search engine for online debates</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bundesmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Christ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,534.57,326.81,4.94" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,244.60,534.57,139.93,4.94">University of amsterdam at clef</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Shahshahani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,548.12,393.33,4.94;12,112.66,561.67,395.01,4.94;12,112.66,575.21,17.97,4.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,221.10,548.12,284.89,4.94;12,112.66,561.67,82.23,4.94">Ranking arguments by combining claim similarity and argument quality dimensions</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dumani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_174.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="12,203.71,561.67,45.74,4.94">Argument</title>
		<imprint>
			<date type="published" when="2020">2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,588.76,394.53,4.94;12,112.66,602.31,393.33,4.94;12,112.66,615.86,393.33,4.94;12,112.66,629.41,394.52,4.94;12,112.66,642.96,340.10,4.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,112.66,602.31,314.54,4.94">Computational argumentation quality assessment in natural language</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Thijm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/E17-1017" />
	</analytic>
	<monogr>
		<title level="m" coord="12,450.78,602.31,55.20,4.94;12,112.66,615.86,393.33,4.94;12,112.66,629.41,46.69,4.94">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="12,213.62,629.41,52.92,4.94">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,656.51,393.98,4.94;12,112.41,670.06,48.96,4.94" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,156.90,656.51,197.04,4.94">A comparative study of stemming algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jivani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,362.41,656.51,107.38,4.94">Int. J. Comp. Tech. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1930" to="1938" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,90.23,393.33,4.94;13,112.66,103.78,393.33,4.94;13,112.66,117.33,130.40,4.94" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,206.21,90.23,299.77,4.94;13,112.66,103.78,75.84,4.94">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,214.56,103.78,291.42,4.94;13,112.66,117.33,54.06,4.94">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,130.88,394.53,4.94;13,112.66,144.43,393.33,4.94;13,112.66,157.97,394.51,4.94;13,112.66,170.70,123.08,7.90" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,327.46,130.88,175.13,4.94">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,240.99,144.43,264.99,4.94;13,112.66,157.97,123.97,4.94">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,185.07,393.33,4.94;13,112.33,198.62,282.50,4.94" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,235.39,185.07,235.64,4.94">Cumulated Gain-Based Evaluation of IR Techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>J√§rvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kek√§l√§inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,482.10,185.07,23.89,4.94;13,112.33,198.62,198.57,4.94">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,212.17,393.33,4.94;13,112.66,225.72,251.75,4.94" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,275.28,212.17,230.71,4.94;13,112.66,225.72,102.08,4.94">Query expansion using wordnet with a logical model of information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barreiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,226.34,225.72,43.99,4.94">IADIS AC</title>
		<imprint>
			<biblScope unit="volume">2005</biblScope>
			<biblScope unit="page" from="487" to="494" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
