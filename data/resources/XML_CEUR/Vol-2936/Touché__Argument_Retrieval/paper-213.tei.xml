<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.06,84.74,393.15,15.42;1,206.10,106.66,183.07,15.42;1,137.11,129.00,324.97,11.96">Exploring BERT Synonyms and Quality Prediction for Argument Retrieval Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.93,154.90,80.23,11.96"><forename type="first">Tommaso</forename><surname>Green</surname></persName>
							<email>tommaso.green@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<addrLine>Via Gradenigo 6</addrLine>
									<postCode>b, 35131</postCode>
									<settlement>Padova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,181.81,154.90,67.89,11.96"><forename type="first">Luca</forename><surname>Moroldo</surname></persName>
							<email>luca.moroldo@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<addrLine>Via Gradenigo 6</addrLine>
									<postCode>b, 35131</postCode>
									<settlement>Padova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.70,154.90,76.70,11.96"><forename type="first">Alberto</forename><surname>Valente</surname></persName>
							<email>alberto.valente.3@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<addrLine>Via Gradenigo 6</addrLine>
									<postCode>b, 35131</postCode>
									<settlement>Padova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.06,84.74,393.15,15.42;1,206.10,106.66,183.07,15.42;1,137.11,129.00,324.97,11.96">Exploring BERT Synonyms and Quality Prediction for Argument Retrieval Notebook for the Touché Lab on Argument Retrieval at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">1E7C33EED4E42EBBE56AC3EDC533B2F1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Argument Retrieval</term>
					<term>Automatic Query Expansion</term>
					<term>Argument Quality</term>
					<term>Transformer</term>
					<term>BERT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper attests the participation of the Yeagerists team from University of Padua in the Touché @ CLEF 2021 challenge <ref type="bibr" coords="1,210.04,232.06,9.33,8.97" target="#b0">[1,</ref><ref type="bibr" coords="1,221.93,232.06,6.22,8.97" target="#b1">2]</ref>, specifically in the Argument Retrieval for Controversial Questions shared task. The project has been submitted as part of the Search Engines course (a.y. 2020-21) held by professor N.Ferro for the Master's Degree in Computer Engineering. We show our retrieval pipeline architecture and discuss our approach, which employs a DirichletLM retrieval model coupled with transformer-based models for both query expansion and argument quality re-ranking. For the first, after having explored several possibilities, we decided to deploy a BERT-based synonym substitution technique. For argument quality re-ranking, we built an approach based on previous work and explored how different models from the BERT family performed in predicting a quality score for a given argument. As a summary of our main findings, we tested different configurations of our system and achieved a retrieval performance of 0.8279 nDCG@5 on Touché 2020 topics, slightly improving over the task baseline, while on 2021 topics we managed to align with the provided baseline at 0.6246 nDCG@5.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Search engines are nowadays one of the most important means to retrieve information, however, they are not specialised for tasks related to the retrieval of nuanced and complex information. As the influence of search engines in opinion formation increases, it is of paramount importance for them to be able to address citizens' enquiries on both general matters ("Should the death penalty be allowed?") or personal decisions ("Should I invest in real estate?") with relevant and high-quality results. This type of task, called argument retrieval, requires the system to respond to user queries with arguments, which could be defined as a set of premises with evidence that leads to a conclusion. Often arguments have a stance, i.e. the author's position (in favour or against) on the debated subject. Clearly, this scenario requires finding a proper trade-off between how relevant an argument is with respect to the user query and its intrinsic quality.</p><p>This paper summarizes our submission to the Touché @ CLEF 2021 shared task on Argument Retrieval for Controversial Questions <ref type="bibr" coords="1,252.21,602.42,11.23,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,265.44,602.42,8.88,10.91" target="#b1">2]</ref> which was centred on the usage of transformer-based models for query expansion and argument quality re-ranking.</p><p>As a brief introduction, our approach consists of two phases: in the first, we use a simple Lucene-based searcher with our query expansion subroutine on top of it. In the second phase, the relevance scores of retrieved documents are combined with the document quality scores provided by our argument quality module. We show that by combining these components we can achieve competitive performance and, as far as Touché 2020 topics are concerned, even surpass the baseline score by properly selecting similarity functions, ranking strategies and other model-specific parameters.</p><p>The paper is organized as follows: Section 2 introduces related works; Section 3 describes our approach; Section 4 provides details of our experimental setup; Section 5 discusses our main findings; finally, Section 6 draws some conclusions and outlooks for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Argument Search Engines</head><p>As described in Wachsmuth et al. <ref type="bibr" coords="2,246.45,302.05,12.84,10.91" target="#b2">[3]</ref> an argument comprises a statement, i.e. the author's position on the topic, and premises, which are usually supported by evidence. Several sub-tasks constitute this area of research: argument mining, i.e. the extraction of an argument from raw text, argument retrieval, with the related techniques to increase the recall of the system such as Query Expansion (QE), and argument re-ranking, so as to consider other parameters in addition to the relevance score, for example, argument quality. Some recent approaches in developing self-contained argument search engines include the args.me search engine introduced in Ajjour et al. <ref type="bibr" coords="2,313.26,396.90,11.47,10.91" target="#b3">[4]</ref>. A similar approach was used by IBM's Project Debater <ref type="bibr" coords="2,156.97,410.45,11.28,10.91" target="#b4">[5]</ref>, where a topic-classifier was used to mine arguments from recognized sources (e.g. Wikipedia) at index-time. Differently from the above mentioned, ArgumenText <ref type="bibr" coords="2,458.31,423.99,12.68,10.91" target="#b5">[6]</ref> is more similar to web search engines as it indexes entire documents and delays argument mining to query-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Query Expansion</head><p>Query Expansion (QE) is a technique that consists in expanding a user query to increase its effectiveness in the search process, mainly by reducing its ambiguity and inserting new related keywords. As reported in Azad and Deepak <ref type="bibr" coords="2,285.26,527.92,11.42,10.91" target="#b6">[7]</ref>, one of the best candidates for implementing a successful query expansion routine is to make use of the recently developed transformer-based models <ref type="bibr" coords="2,123.96,555.02,11.48,10.91" target="#b7">[8]</ref>, which proved impressive performance and ability to grasp semantic nuances. For this reason, our query expansion approach aligned to that of Victor <ref type="bibr" coords="2,390.82,568.57,11.42,10.91" target="#b8">[9]</ref>, who experimented on how contextual embeddings produced by a Masked Language Model (MLM) such as BERT <ref type="bibr" coords="2,486.97,582.12,16.17,10.91" target="#b9">[10]</ref>, can be applied in generating query expansion terms. Furthermore, we took inspiration from the idea <ref type="bibr" coords="2,127.08,609.21,17.86,10.91" target="#b10">[11]</ref> of using an end-to-end BERT-based terms substitution approach, which proposes and validates substitute term candidates based on their influence on the global contextualized representation of the query. A big difference from <ref type="bibr" coords="2,308.83,636.31,17.76,10.91" target="#b10">[11]</ref> is that we do not apply dropout to target word embedding to partially mask it, but we completely mask the word and let BERT generate a large enough batch of candidates from which to choose the best ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Argument Quality</head><p>Wachsmuth et al. <ref type="bibr" coords="3,174.09,283.93,17.91,10.91" target="#b11">[12]</ref> provide a categorization of the key components that contribute to the overall quality of an argument: logical quality considers how sound an argument is, i.e. how the conclusion follows from the premises, rethorical quality measures how persuasive an argument is for the audience and dialectical quality represents the effectiveness of the argument in making the audience create their own stance. The authors stress that dialectical quality builds on rhetorical, and rhetorical builds on logical. The application of transformer-based pre-trained language models to argument quality prediction was explored in Gretz et al. <ref type="bibr" coords="3,432.71,365.22,16.26,10.91" target="#b12">[13]</ref>, where they provide an extensive dataset on argument quality called IBM-Rank-30k. They compared the performance of a Bi-LSTM with GloVe embeddings and Support Vector Regressor </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Our solution is composed of 3 parts: a Lucene-based indexer and searcher, a query expansion module and a quality measurement module. The procedure consists of reading the topics (i.e. queries) from a file, performing query expansion for each topic, running the searcher to retrieve a set of arguments, measuring the quality of a portion (of size 𝑛 𝑟𝑒𝑟𝑎𝑛𝑘 ) of the retrieved arguments, and (re)ranking the arguments using the quality score. Figure <ref type="figure" coords="3,425.66,572.89,5.17,10.91" target="#fig_0">1</ref> summarizes our pipeline.</p><p>When query expansion is enabled, the set of expanded queries obtained from a topic may retrieve duplicated arguments. Duplicated arguments are removed right after the retrieval step, and only the top 𝑛 𝑟𝑒𝑟𝑎𝑛𝑘 arguments are given as input to the argument quality module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Indexing and searching</head><p>We indexed the Args.me corpus <ref type="bibr" coords="4,240.73,107.54,18.07,10.91" target="#b13">[14]</ref> by tokenizing and storing the body and title of each argument. Besides tokenization, only a lowercase filter was applied. For the retrieval part, we used the Dirichlet similarity by matching the query terms with both the title and the body of the arguments, we used a title boost parameter to weight the score assigned to a match of a query term with a title term, while the score assigned to a match with a body term is left untouched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Query Expansion</head><p>The Query Expansion subroutine generates a new set of queries for each query of a list, which in our case is the list of Touché topics. It works as follows:</p><p>1. The query is tokenized and Part of Speech (PoS) tagged; the query tokens which are recognized as nouns, adjectives or past participles are masked and then replaced with BERT's [MASK] special token. 2. Use BERT to generate the best 10 tokens that, according to its bidirectional attention mechanism, fit in place of each [MASK] token. 3. Compute the BERT embeddings of these 10 tokens and compare them, using cosine similarity, to the embedding of the original token: more about this in section 4.4. 4. Perform a two-phase screening, where at first we keep only the best tokens among the 10 that have a similarity score above 85%. If none of the generated tokens is good enough, we lower the similarity score threshold to 75% and use BERT again to generate batches of 20 new candidates each, until at least one good substitute is found or 100 candidates in total are generated. 5. Using the lists of new tokens for each position of [MASK], we compute their cartesian product to compose the list of all the possible new queries and take from it a set of max_n_query queries at random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Argument Quality</head><p>Building on Gretz et al. <ref type="bibr" coords="4,192.61,490.17,16.21,10.91" target="#b12">[13]</ref>, we decided to explore the possibility of using pre-trained language models for predicting the overall quality of an Argument. We make a distinction in the training process of models made of a transformer-based encoder and a traditional feedforward neural network:</p><p>• Adaptation: while keeping the weights of the encoder frozen, only the dense layer on top is trained on the new task; • Fine-tuning: the whole model is fine-tuned on the new task.</p><p>Both approaches have advantages and disadvantages, and in the end, we decided to go with the first approach as it reduces model complexity (lowering the possibility of overfitting) and requires fewer computational resources. In addition to this, as reported in <ref type="bibr" coords="4,408.41,631.40,17.75,10.91" target="#b14">[15]</ref> fine-tuning seems to be more appropriate when pre-training task and transfer tasks are closely related. This was not the case as BERT <ref type="bibr" coords="4,181.59,658.50,17.76,10.91" target="#b9">[10]</ref> for example is pre-trained on MLM and Next Sentence Prediction (NSP) (both can be framed as classification tasks) and the target task required to produce a real-valued score (regression task), so we decided to proceed with adaption.</p><p>The model works as follows: given an argument (truncated at 512 tokens), an encoded representation is computed using the [CLS] embedding of one of the models mentioned below. Finally, this representation is passed to a feedforward neural network with 2 hidden layers which computes the Mean Square Error (MSE) loss w.r.t. the original target value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Ranking Functions</head><p>We decided to apply the argument quality re-ranking only to 𝐷 𝑞 𝑛_𝑟𝑒𝑟𝑎𝑛𝑘 i.e. the top 𝑛_𝑟𝑒𝑟𝑎𝑛𝑘 arguments according to the relevance score for each query 𝑞. For the final list of results, we had to combine relevance and quality scores. We tried three different ranking functions, using a parameter 𝛼 ∈ [0, 1] that represented the importance of the quality score for a document 𝑑 with relevance score 𝑟(𝑑) and a quality score 𝑞(𝑑):</p><p>• Normalization function: w.r.t. a query 𝑞, we re-ranked the list by normalizing relevance and quality scores:</p><formula xml:id="formula_0" coords="5,116.56,318.14,406.85,40.18">𝑅(𝑞, 𝑑) = (1-𝛼) 𝑟 𝑛𝑜𝑟𝑚 +𝛼 𝑞 𝑛𝑜𝑟𝑚 = (1-𝛼) 𝑟(𝑑) max 𝑑 ′ ∈𝐷 𝑞 𝑛_𝑟𝑒𝑟𝑎𝑛𝑘 𝑟(𝑑 ′ ) +𝛼 𝑞(𝑑) max 𝑑 ′ ∈𝐷 𝑞 𝑛_𝑟𝑒𝑟𝑎𝑛𝑘 𝑞(𝑑 ′ ) (1)</formula><p>• Sigmoid Function: in order to compress relevance and quality scores, we decided to use the sigmoid function, 𝜎(𝑥) :=<ref type="foot" coords="5,264.75,374.31,4.23,6.99" target="#foot_0">1</ref> 1+𝑒 -𝑥 , with a scale parameter 𝛽. The function used was:</p><formula xml:id="formula_1" coords="5,215.46,400.38,290.52,10.91">𝑅(𝑞, 𝑑) = (1 -𝛼) 𝜎(𝛽 𝑟(𝑑)) + 𝛼 𝜎(𝛽 𝑞(𝑑))<label>(2)</label></formula><p>The parameter 𝛽 was used to counter the typical "squishing" of the sigmoid, which maps large positive or negative values into close output values (closer to 1 or 0 respectively), while values near the origin can assume a wider spectrum of values. As 𝛽 tends to 0, the steepness of the sigmoid decreases and allows for a wider neighbourhood of values centred in the origin to get more diverse values. • Hybrid Function: in this case, we applied the sigmoid to the quality scores while normalizing relevance scores:</p><formula xml:id="formula_2" coords="5,116.74,530.98,389.24,40.18">𝑅(𝑞, 𝑑) = (1 -𝛼) 𝑟 𝑛𝑜𝑟𝑚 + 𝛼 𝜎(𝛽 𝑞(𝑑)) = (1 -𝛼) 𝑟(𝑑) max 𝑑 ′ ∈𝐷 𝑞 𝑛_𝑟𝑒𝑟𝑎𝑛𝑘 𝑟(𝑑 ′ ) + 𝛼 𝜎(𝛽 𝑞(𝑑))<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup</head><p>To reproduce our results, please refer to our GitHub repository 1 . Our submission was done through the provided TIRA <ref type="bibr" coords="5,214.48,632.43,17.98,10.91" target="#b15">[16]</ref> virtual machine to allow for our approach to be deployed on different data of the same format in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Args.me corpus</head><p>The Args.me corpus <ref type="bibr" coords="6,180.26,107.54,17.79,10.91" target="#b13">[14]</ref> consists of 5 collections of arguments obtained from different sources. Each collection is a list of arguments containing a variety of fields: the body, which is the text written by the user to support a claim; a stance, that can be "PRO" or "CON" w.r.t. the parent discussion; a title, which summarizes the discussion that the argument belongs to. The title can be written by the author of the argument or inherited from the discussion and is sometimes empty. We decided to discard duplicated arguments having the same ID as well as arguments having an empty body.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Indexing</head><p>We developed a Lucene-based program to index the Args.me corpus. Each indexed document contains the ID, body, title, and stance of an argument parsed from the Args.me corpus. The original content of the body and the title is stored in the index. The Analyzer, which is responsible for the tokenization of the body and title of an argument, is composed of a Lucene StandardTokenizer and a LowerCaseFilter as we found that using any other kind of analyzer downgraded the nDCG@5 score, especially any stemming filter. Stopwords were not removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Searching</head><p>Given the text of a query, e.g. any Touché topic, we parsed it using Lucene's MultiFieldQuery-Parser. This parser allowed us to search for any match in both the body and the title (when present) of an argument, assigning different boosts depending on the field where the match occurred. By default, the boost assigned to a match with the title is set to zero as we disabled this feature because it did not improve our solution. The retrieval model that we used is the Lucene LMDirichletSimilarity, with 𝜇 = 2000, and for each topic we always retrieved 100 documents. As a consequence, when query expansion is enabled, a set of 𝑘 expanded queries produces up to 𝑘 × 100 arguments, some of which may be duplicated. We remove duplicated arguments from the results obtained from the same topic, we select the top 𝑛 𝑟𝑒𝑟𝑎𝑛𝑘 arguments using the DirichletLM score, and pass them to the argument quality module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Query Expansion</head><p>As an implementation choice, we decided to consider as embeddings of the tokens generated by BERT the 3072-dimensional vectors obtained concatenating the token representations (of size 768) from the last 4 layers of the bert-base-uncased deep neural network. This choice was based on a tradeoff between the fact that they should be framed to retain as much information as possible in terms of context classification while remaining small enough. Moreover, this is the best performing configuration for using BERT contextual features according to the authors themselves <ref type="bibr" coords="6,140.22,609.00,16.08,10.91" target="#b9">[10]</ref>. To perform PoS tagging on each query to expand we used the model averagedperceptron-tagger<ref type="foot" coords="6,166.27,620.79,3.71,7.97" target="#foot_1">2</ref> from the NLTK<ref type="foot" coords="6,245.21,620.79,3.71,7.97" target="#foot_2">3</ref> (Natural Language Toolkit) Python library. We set the number max_n_query of new queries generated from each query to 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Argument Quality</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1.">The Argument Quality Dataset</head><p>To build our argument quality predictor, we decided to use the Argument Quality Dataset of Gienapp et al. <ref type="bibr" coords="7,156.54,141.65,16.29,10.91" target="#b16">[17]</ref>, as it contains 1271 arguments extracted from the args.me corpus, each having detailed quality scores as well as topical relevance. Quality scores were obtained by almost 42k pairwise judgements. We made our model predict only the overall quality, which can be obtained from the rhetorical, logical and dialectical quality as described in <ref type="bibr" coords="7,451.08,182.30,16.20,10.91" target="#b16">[17]</ref>, using a train-validation-test split of 80%-10%-10%. Both hyperparameter selection and training were performed in a deterministic way by setting a specific seed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2.">Model Selection</head><p>Differently from Gretz et al. <ref type="bibr" coords="7,215.10,258.73,16.24,10.91" target="#b12">[13]</ref>, we decided to explore 4 different models of the BERT family: BERT <ref type="bibr" coords="7,116.11,272.28,16.09,10.91" target="#b9">[10]</ref>, DistilBERT <ref type="bibr" coords="7,188.79,272.28,16.09,10.91" target="#b17">[18]</ref>, RoBERTa <ref type="bibr" coords="7,253.83,272.28,17.76,10.91" target="#b18">[19]</ref> and ALBERT <ref type="bibr" coords="7,331.42,272.28,16.09,10.91" target="#b19">[20]</ref>. BERT is by far the most famous one using the transformer encoder to create bi-directional contextualized word representations, and several variants have been published due to its performance in state-of-the-art NLP. Specifically, we used the HuggingFace <ref type="bibr" coords="7,212.82,312.93,18.07,10.91" target="#b20">[21]</ref> implementations of the aforementioned models: bert-baseuncased, distilbert-base-uncased, albert-base-v2 and roberta-base. For the hyperparameter selection, an exhaustive grid search was performed over the following set of parameters: learning rate (𝑙𝑟), Adam weight decay (𝑤) <ref type="bibr" coords="7,365.49,353.57,16.41,10.91" target="#b21">[22]</ref>, batch size (𝑏) and dropout probability (𝑝). If the latter is set to 0, a simple feedforward neural network with 2 hidden layers and ReLU activations was used, otherwise AlphaDropout <ref type="bibr" coords="7,375.65,380.67,17.90,10.91" target="#b22">[23]</ref> was applied to the [CLS] embedding and to the hidden activations of the feedforward neural network. In that case, ReLUs were substituted with SeLUs <ref type="bibr" coords="7,218.64,407.77,16.25,10.91" target="#b22">[23]</ref>.</p><p>For all configurations, we tracked the 𝑅 2 score on both the training set and validation set and picked the best combination for each of the 4 models according to 𝑅 2 on the validation set. The 4 selected models were then trained for 30 epochs, using early stopping and saving the best model according to validation 𝑅 2 . Finally, the model performance was assessed on the remaining test set. Selected models and results are available in Table <ref type="table" coords="7,396.00,475.52,3.73,10.91" target="#tab_0">1</ref>. Every experiment was logged using the online WandB logger <ref type="bibr" coords="7,262.79,489.06,16.25,10.91" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Argument Quality Prediction Results</head><p>The four final models had very similar results in terms of validation 𝑅 2 score. This also holds true for the results on the test set, in particular with BERT and DistilBERT being close and slightly better than the other two as you can see in Table <ref type="table" coords="7,347.42,595.76,3.77,10.91" target="#tab_0">1</ref>. Compared to results on the same dataset obtained by <ref type="bibr" coords="7,178.00,609.31,16.18,10.91" target="#b24">[25]</ref>, we were able to produce a more powerful regressor since they report that the MSE loss of their best (ensemble) model on the same dataset is 1.322 for combined quality, while our best result in terms of loss is 0.718. This is to be expected, as they used a simple SVR using pre-processed textual features while in our case we could count on the full word-level attention typical of transformer models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Overall Pipeline Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Touché 2020 Topics</head><p>To provide an overview of our retrieval pipeline performance, we run it on topics from Touché 2020 with different combinations of parameters by using WandB Sweeps <ref type="bibr" coords="8,426.05,488.27,16.41,10.91" target="#b23">[24]</ref>. Of these we selected the 10 most interesting runs: we made this choice not only by considering their nDCG@5 score, but also their diversity in terms of hyperparameters. To compute nDCG@5 we used trec_eval<ref type="foot" coords="8,166.81,527.17,3.71,7.97" target="#foot_3">4</ref> (version 9.0.7), and thus the scores may present very slight differences with respect to those in the official Touché leaderboard as the evaluators used a different tool, meaning that the reported swordsman baseline (DirichletLM) scores are not precisely comparable to the others.</p><p>Table <ref type="table" coords="8,127.13,583.12,5.09,10.91" target="#tab_1">2</ref> shows the results in decreasing order of nDCG@5 (2020) score: we can see that the swordsman baseline is not very far from our lucene baseline, obtained by using just DirichletLM with the title boost set to zero, and the best score of our solution, which presents an improvement of 0.16%. We expected this difficulty in improving the baseline with deep learning methods as this was also proven in Touché 2020 <ref type="bibr" coords="8,270.81,637.32,18.07,10.91" target="#b25">[26]</ref> and may be due to the challenge of developing efficient modules for argument quality prediction and query expansion.</p><p>As it is clear from the last two rows of Table <ref type="table" coords="9,304.92,330.21,3.81,10.91" target="#tab_1">2</ref>, we did not get any improvement by using query expansion, both combining it with argument quality reranking (as in good-sweep-85) or applying it directly on our DirchetLM baseline (see lucene-query-exp). This was an expected outcome since some queries were well expanded, so they managed to produce a set of synonyms that allowed the searcher to retrieve a wider range of arguments that fall in the same topic, while many others were subject to changes in their original meaning, leading to a score that is lower than what they would have achieved without these incoherent queries. This phenomenon is linked both to the size of the original query, as a masked short query is more likely to lack the context BERT needs to work properly, and to how easily replaceable its terms are, so even setting a higher number of generated queries (max_n_query) would not have improved the expansion quality in any noticeable way.</p><p>A few combinations of parameters allowed the quality re-ranker to slightly improve the baseline score. This happens when the re-ranker permutates the top-5 arguments, i.e. changing only the order of the results that influence nDCG@5 without adding any new argument.</p><p>As mentioned in 4.3, the boost assigned to matches occurring on the title of an argument did not lead to better results: one reason may be that this boost pushes up in the ranked list arguments that inherit the title from the parent discussion without containing a relevant body. For this reason, we did not log any test with titleboost different than 0 to concentrate on other parameters.</p><p>Figure <ref type="figure" coords="9,130.42,587.64,4.97,10.91" target="#fig_2">2</ref> summarizes the performance of the 10 selected runs on each Touché 2020 topic. This allows us to see that, while at least ten topics lead consistently to optimal performance among all the runs, a few others perform especially bad. Let's discuss some examples of the latter case:</p><p>• Topic 8 ("Should abortion be legal?") gets an nDCG@5 score of 0 on both runs which include query expansion (good-sweep-85 and lucene-query-exp). This is clearly linked to how this topic is expanded, as we have noticed that BERT consistently recognizes some specific pairs of words as very similar. In this topic the terms "abortion" and "divorce", although being far from having the same meaning, are being replaced in new queries interchangeably. This is almost certainly due to bias in BERT's pre-training dataset, where these two words used to appear together very often. • Also topic 10 ("Should any vaccines be required for children?") manages to get an nDCG@5 of 0 on the same runs. Having a look at how query expansion worked on this topic, we think it may be due to the term required being replaced interchangeably with mandatory and recommended, whose meanings are similar but their lexical nuances really make the difference in this specific context. • On the other hand, we observe that topics such as 12 ("Should birth control pills be available over the counter?"), 20 ("Is drinking milk healthy for humans?") and 44 ("Should election day be a national holiday?") perform uniformly bad among all of the selected runs.</p><p>We suggest it could be the result of a misunderstanding of the expression over the counter, which is possibly not very common, but also of the odd specificity of these questions. For example, in topic 20 the presence or absence of the term milk changes the meaning of the topic completely, making it difficult to retrieve actually relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Touché 2021 Topics</head><p>We ran our pipeline on the Touché 2021 topics made available by the new edition of the challenge.</p><p>We measured the nDCG@5 scores of the same parameters combinations we used for the 2020 challenge, observing the same trend: the scores align with the swordsman baseline but we could not improve on it due to a 0.14% difference. Table <ref type="table" coords="10,315.07,382.89,5.06,10.91" target="#tab_1">2</ref> shows the nDCG@5 scores with the 2021 topics. Nevertheless, we were able to improve our lucene baseline by 2% thanks to the quality re-ranking module. The 2021 topics appear to be tougher when compared to the previous year's edition, as shown by the plot of Figure <ref type="figure" coords="10,182.47,437.09,3.81,10.91" target="#fig_3">3</ref>: we achieved a score of zero on 4 topics, which are "Should suicide be a criminal offense?", "Should the press be subsidized?", "Should we imprison fewer people?", and "Is psychology a science?". Even the employment of query expansion was not able to retrieve any relevant argument with respect to these queries. Finally, the number of topics on which we achieved a full score has decreased.</p><p>The following list presents how a few queries were expanded:</p><p>• Topic 51 ("Do we need sex education in schools?") has the word "sex" replaced by "sexual", "education" replaced by "school", "classes", "instruction", "teachers" and "lessons", and "schools" replaced by "classrooms" and "education". Even if the words replacements seem to make sense, we achieved an nDCG@5 score of 0 for this topic using query expansion. • Topic 53 ("Should blood donations be financially compensated?") is expanded to "Should blood donations be financially supported?", which appears to be a good expansion, and "Should blood sacrifices be financially compensated?", which is clearly (negatively) affected by the BERT training bias. • Topic 87 ("Are gas prices too high?") is expanded to "Are gas prices too bad?", "Are oil prices too low", etc. leading to a higher nDCG@5 score when compared to some runs that do not make use of query expansion. Topic 87 along with topic 92 are the only two topics where query expansion was able to have a positive impact on the scores w.r.t. some of the runs not using it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Statistical Significance Analysis</head><p>In order to determine if the differences between the 10 selected runs we reported in Table <ref type="table" coords="11,500.81,388.00,5.17,10.91" target="#tab_1">2</ref> are statistically significant, we performed two-way ANalysis Of VAriance (ANOVA) test on the Touché 2021 per-topic results. We employed the Matlab script anova_test, which is available in our repository on GitHub<ref type="foot" coords="11,218.50,426.89,3.71,7.97" target="#foot_4">5</ref> under the statistical_analysis section. As we can see in Figure <ref type="figure" coords="11,89.04,442.19,3.81,10.91" target="#fig_4">4</ref>, we can distinguish between two families of runs, which are those with and without query expansion (in red and blue respectively). We can also see that our lucene baseline cannot be considered significantly different from the other runs not applying query expansion, despite having a noticeably lower nDCG@5 score. We also provide the ANOVA table (see Table <ref type="table" coords="11,303.00,496.39,3.60,10.91" target="#tab_2">3</ref>), which confirms the previous observations: using the standard significance level 𝛼 = 0.05, the 𝑝-value associated with the runs is extremely low, meaning that the null hypothesis is rejected and so there is definitely a difference between runs of the two families. The relatively low value of Mean Squares (MS) associated with Error source means that most of the variance (represented by the horizontal whiskers in Figure <ref type="figure" coords="11,479.90,550.59,4.08,10.91" target="#fig_4">4</ref>) can be explained as the effect of changes in the parameters combinations of each run which in turn produce different behaviours when dealing with different topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>As noted in <ref type="bibr" coords="11,140.24,636.16,16.09,10.91" target="#b25">[26]</ref>, the usage of state-of-the-art architectures for argument retrieval in the previous edition of the challenge only slightly improved the results obtained by the DirichletLM baseline  and our results seem to point in that direction, achieving a slight improvement over the baseline with an nDCG@5 score of 0.8279. Regarding the 2021 edition of the challenge, the new topics appear tougher, leading to a lower average nDCG@5 score. Nevertheless, the improvement of our approach is more significant when compared to our lucene baseline.</p><p>We believe that the difficulty of meaningfully improving the baseline score is related to the complexity of the task, but nevertheless, we deem that deep-learning-based approaches could provide interesting insights and improvements over traditional baselines.</p><p>First of all, it would be interesting to use transformer-based models also for the retrieval part: in particular, similarly to what was done last year in <ref type="bibr" coords="12,330.35,535.10,16.42,10.91" target="#b26">[27]</ref>, it could be interesting to design a vector space IR model based on BERT, which could produce document embeddings fine-tuned for this task. For example, BERT models tailored to produce embeddings of long spans of text such as SBERT <ref type="bibr" coords="12,159.35,575.75,18.07,10.91" target="#b27">[28]</ref> could be deployed on this task. This integration would be orthogonal to our work and substitute the DirichletLM retrieval model.</p><p>As far as query expansion is concerned, while developing the approach described in section 3.2, we had the opportunity to try Back-translation, which consists of using a multilingual translation model to translate a sentence into a foreign language and back again into the original one. We tested it using the TextBlob library <ref type="foot" coords="12,332.74,641.74,3.71,7.97" target="#foot_5">6</ref> , which for translation task relies on Google Translate API, so we could not use it for the final submission. Since it proved to be a really promising way of exploiting pre-trained transformer-based models to generate differently phrased sentences, while preserving most of the original meaning, we are eager to further investigate this technique.</p><p>Regarding argument quality prediction, it could be interesting to study the performance of our model in a fine-tuning approach instead of the adaptation one we used. In addition to this, it could be interesting to make the re-ranker predict the three types of quality (logical, dialectical and rhetorical) to see whether it would be possible for it to capture these three aspects independently. The re-ranking of results could then be performed based only on one of these qualities or on the overall quality score. Clearly, this adds a substantial layer of difficulty for the language model but could yield interesting details on how it internally represents these sophisticated features of language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,225.75,320.42,8.93;3,89.29,84.19,416.70,129.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Summary of our pipeline: inputs in purple, neural modules in green.</figDesc><graphic coords="3,89.29,84.19,416.70,129.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,450.15,392.32,55.83,10.91;3,89.29,405.87,416.69,10.91;3,88.89,419.42,417.10,10.91;3,89.29,432.97,417.02,10.91;3,89.29,446.52,416.69,10.91;3,89.29,460.07,364.51,10.91"><head></head><label></label><figDesc>(SVR) with 3 different variants of BERT: BERT-Vanilla, where the [CLS] tokens of the last 4 encoder layers were concatenated and fed to a feed-forward neural network with ReLU and sigmoid activation to produce a score in [0, 1], BERT-FineTune where they fine-tuned the entire model (BERT encoder and linear layer on top), and finally BERT-FineTuneTOPIC, identical to BERT-FineTune but with the input enriched with the topic as in [CLS]&lt;topic&gt;[SEP]&lt;query&gt;[SEP].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,89.29,279.06,413.73,8.93;9,89.29,84.19,416.69,182.30"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Bar plot of nDCG@5 scores for the 10 selected runs grouped by topic (Touché 2020 topics).</figDesc><graphic coords="9,89.29,84.19,416.69,182.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,89.29,279.80,413.73,8.93;11,89.29,84.19,416.69,183.05"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Bar plot of nDCG@5 scores for the 10 selected runs grouped by topic (Touché 2021 topics).</figDesc><graphic coords="11,89.29,84.19,416.69,183.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="12,89.29,282.83,413.82,8.93;12,107.51,84.19,380.25,186.08"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results of two-way ANOVA significance test of the 10 selected runs on Touché 2021 topics.</figDesc><graphic coords="12,107.51,84.19,380.25,186.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,88.99,90.49,344.43,86.37"><head>Table 1</head><label>1</label><figDesc>Results on the test set for argument quality prediction.</figDesc><table coords="8,159.36,116.73,274.07,60.12"><row><cell>Model</cell><cell>𝑙𝑟</cell><cell>𝑤</cell><cell>𝑏</cell><cell cols="2">𝑝 Test 𝑅 2 Test MSE Loss</cell></row><row><cell>BERT</cell><cell>0.005</cell><cell cols="3">0.0005 16 0 0.7439</cell><cell>0.7280</cell></row><row><cell cols="2">DistilBERT 0.005</cell><cell cols="3">0.0001 16 0 0.7412</cell><cell>0.7440</cell></row><row><cell>RoBERTa</cell><cell>0.005</cell><cell cols="3">0.0001 16 0 0.735</cell><cell>0.7187</cell></row><row><cell>ALBERT</cell><cell cols="4">0.0001 0.0005 32 0 0.703</cell><cell>0.7494</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,81.27,196.76,426.38,209.48"><head>Table 2</head><label>2</label><figDesc>List of 10 selected runs, sorted in decreasing order of nDCG@5 (2020). Runs sent to Touché are highlighted (our baseline is in light blue, while Swordsman baseline is in yellow). The title boost was disabled.</figDesc><table coords="8,81.27,249.26,425.07,156.98"><row><cell>Run name</cell><cell cols="2">QE 𝛼</cell><cell>𝛽</cell><cell cols="2">𝑛 𝑟𝑒𝑟𝑎𝑛𝑘 Quality</cell><cell>𝑅(𝑞, 𝑑)</cell><cell cols="2">nDCG@5 nDCG@5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>model</cell><cell></cell><cell>(2020)</cell><cell>(2021)</cell></row><row><cell>lunar-sweep-201</cell><cell>no</cell><cell cols="2">0.75 -</cell><cell>5</cell><cell>BERT</cell><cell cols="2">normalize 0.8279</cell><cell>0.6241</cell></row><row><cell>chocolate-sweep-50</cell><cell>no</cell><cell>0.1</cell><cell>2</cell><cell>5</cell><cell>BERT</cell><cell>sigmoid</cell><cell>0.8273</cell><cell>0.6241</cell></row><row><cell>volcanic-sweep-138</cell><cell>no</cell><cell>0.5</cell><cell cols="2">0.8 5</cell><cell>BERT</cell><cell>sigmoid</cell><cell>0.8271</cell><cell>0.6246</cell></row><row><cell>swordsman baseline</cell><cell>no</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.8266</cell><cell>0.6260</cell></row><row><cell>lunar-sweep-58</cell><cell>no</cell><cell>0.1</cell><cell cols="2">0.2 5</cell><cell>RoBERTa</cell><cell>hybrid</cell><cell>0.8230</cell><cell>0.6104</cell></row><row><cell cols="2">vague-sweep-rev-204 no</cell><cell cols="3">0.75 1.1 5</cell><cell>ALBERT</cell><cell>sigmoid</cell><cell>0.8229</cell><cell>0.6211</cell></row><row><cell>lucene baseline</cell><cell>no</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">normalize 0.8224</cell><cell>0.6095</cell></row><row><cell>sage-sweep-rev-160</cell><cell>no</cell><cell>0.5</cell><cell cols="2">1.5 5</cell><cell>RoBERTa</cell><cell>sigmoid</cell><cell>0.8093</cell><cell>0.6211</cell></row><row><cell cols="2">distinctive-sweep-110 no</cell><cell>0.1</cell><cell cols="2">0.8 15</cell><cell>ALBERT</cell><cell>hybrid</cell><cell>0.7992</cell><cell>0.6177</cell></row><row><cell>good-sweep-85</cell><cell cols="2">yes 0.1</cell><cell cols="2">0.3 15</cell><cell cols="2">DistilBERT hybrid</cell><cell>0.6857</cell><cell>0.5357</cell></row><row><cell>lucene-query-exp</cell><cell cols="2">yes 0</cell><cell>-</cell><cell>5</cell><cell>-</cell><cell cols="2">normalize 0.6801</cell><cell>0.5384</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,88.99,315.98,369.05,86.37"><head>Table 3</head><label>3</label><figDesc>Two-way ANOVA table with significance level 𝛼 set to 0.05</figDesc><table coords="12,134.75,343.80,323.29,58.55"><row><cell>Source</cell><cell>SS</cell><cell cols="2">DoF MS</cell><cell>𝐹 𝑠𝑡𝑎𝑡</cell><cell>𝑝-value (Prob &gt; 𝐹 𝑠𝑡𝑎𝑡 )</cell></row><row><cell cols="2">Columns (Runs) 0.5516</cell><cell>9</cell><cell cols="2">0.0613 8.6504</cell><cell>5.4886e-12</cell></row><row><cell>Rows (Topics)</cell><cell cols="2">47.2754 49</cell><cell cols="3">0.9648 136.1783 3.7870e-235</cell></row><row><cell>Error</cell><cell>3.1244</cell><cell>441</cell><cell cols="2">0.0071 0.0</cell><cell>0.0</cell></row><row><cell>Total</cell><cell cols="2">50.9514 499</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,108.93,671.03,227.46,8.97"><p>http://github.com/tommaso-green/yeagerists-clef-touche-2021</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,108.93,660.08,228.00,8.97"><p>https://www.kaggle.com/nltkdata/averaged-perceptron-tagger</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,108.93,671.03,80.21,8.97"><p>https://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="8,108.93,671.01,110.54,8.97"><p>https://trec.nist.gov/trec_eval/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="11,108.93,671.04,230.96,8.97"><p>https://github.com/tommaso-green/yeagerists-clef-touche-2021</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="12,108.93,671.03,141.58,8.97"><p>https://textblob.readthedocs.io/en/dev/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,112.66,294.63,394.53,10.91;13,112.66,308.18,313.98,10.91;13,445.87,308.18,60.12,10.91;13,112.33,321.73,394.85,10.91;13,112.66,335.28,395.17,10.91;13,112.66,348.83,394.52,10.91;13,112.66,362.38,394.03,10.91;13,112.66,375.93,369.76,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,445.87,308.18,60.12,10.91;13,112.33,321.73,147.40,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-72240-1_67</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-72240-1_67.doi:10.1007/978-3-030-72240-1\_67" />
	</analytic>
	<monogr>
		<title level="m" coord="13,257.58,335.28,250.25,10.91;13,112.66,348.83,158.40,10.91">Advances in Information Retrieval. 43rd European Conference on IR Research (ECIR 2021)</title>
		<title level="s" coord="13,355.63,349.84,147.39,9.72">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="574" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,389.48,394.53,10.91;13,112.66,403.03,313.98,10.91;13,445.87,403.03,60.12,10.91;13,112.33,416.58,394.86,10.91;13,112.14,430.13,395.05,10.91;13,112.66,443.67,22.69,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,445.87,403.03,60.12,10.91;13,112.33,416.58,141.80,10.91">Overview of Touché 2021: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,112.14,430.13,390.30,10.91">Working Notes Papers of the CLEF 2021 Evaluation Labs, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,457.22,394.53,10.91;13,112.30,470.77,394.97,10.91;13,112.66,484.32,395.17,10.91;13,112.66,497.87,394.04,10.91;13,112.14,511.42,188.26,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,267.50,470.77,217.89,10.91">Building an argument search engine for the web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5106</idno>
		<ptr target="https://www.aclweb.org/anthology/W17-5106.doi:10.18653/v1/W17-5106" />
	</analytic>
	<monogr>
		<title level="m" coord="13,112.66,484.32,395.17,10.91;13,112.66,497.87,31.52,10.91">Proceedings of the 4th Workshop on Argument Mining, Association for Computational Linguistics</title>
		<meeting>the 4th Workshop on Argument Mining, Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,524.97,394.53,10.91;13,112.66,538.52,394.53,10.91;13,112.14,552.07,393.85,10.91;13,112.33,565.62,394.85,10.91;13,112.66,579.17,245.39,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,150.30,538.52,279.85,10.91">Visualization of the topic space of argument search results in args</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Riehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Castiglia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Adejoh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fröhlich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D18-2011" />
	</analytic>
	<monogr>
		<title level="m" coord="13,198.45,552.07,307.54,10.91;13,112.33,565.62,174.35,10.91">Conference on Empirical Methods in Natural Language Processing (EMNLP 2018) -System Demonstrations</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Blanco</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,592.72,393.32,10.91;13,112.66,606.27,393.33,10.91;13,112.66,619.81,393.73,10.91;13,112.66,633.36,383.93,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,347.73,592.72,158.25,10.91;13,112.66,606.27,160.89,10.91">Towards an argumentative content search engine using weak supervision</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/C18-1176" />
	</analytic>
	<monogr>
		<title level="m" coord="13,294.62,606.27,211.37,10.91;13,112.66,619.81,323.62,10.91">Proceedings of the 27th International Conference on Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics, Association for Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2066" to="2081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,646.91,394.53,10.91;13,112.28,660.46,393.71,10.91;14,112.66,86.97,393.33,10.91;14,112.66,100.52,394.53,10.91;14,112.66,114.06,397.48,10.91;14,112.36,130.06,103.79,7.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,112.28,660.46,288.95,10.91">ArgumenText: Searching for arguments in heterogeneous sources</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stahlhut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tauchmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-5005</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-5005.doi:10.18653/v1/N18-5005" />
	</analytic>
	<monogr>
		<title level="m" coord="13,424.06,660.46,81.93,10.91;14,112.66,86.97,393.33,10.91;14,112.66,100.52,325.24,10.91">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, Association for Computational Linguistics<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,141.16,393.71,10.91;14,112.66,154.71,394.04,10.91;14,112.26,168.26,394.92,10.91;14,112.36,184.25,150.76,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,235.92,141.16,270.45,10.91;14,112.66,154.71,27.79,10.91">Query expansion techniques for information retrieval: A survey</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">K</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deepak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.05.009</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2019.05.009" />
	</analytic>
	<monogr>
		<title level="j" coord="14,156.31,154.71,184.41,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1698" to="1735" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,195.36,394.53,10.91;14,112.66,208.91,394.53,10.91;14,112.66,222.46,393.33,10.91;14,112.66,236.01,253.34,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="14,309.90,222.46,196.09,10.91;14,112.66,236.01,123.30,10.91">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,249.56,393.33,10.91;14,111.16,263.11,135.28,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,156.88,249.56,349.11,10.91;14,111.16,263.11,105.62,10.91">Neuralqa: A usable library for question answering (contextual query expansion + bert) on large datasets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Victor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,276.66,393.33,10.91;14,112.66,290.20,311.37,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="14,326.58,276.66,179.40,10.91;14,112.66,290.20,181.08,10.91">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,303.75,393.32,10.91;14,112.66,317.30,393.33,10.91;14,112.66,330.85,395.01,10.91;14,112.66,344.40,284.04,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,290.77,303.75,138.64,10.91">BERT-based lexical substitution</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1328</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1328.doi:10.18653/v1/P19-1328" />
	</analytic>
	<monogr>
		<title level="m" coord="14,452.18,303.75,53.80,10.91;14,112.66,317.30,393.33,10.91;14,112.66,330.85,135.11,10.91">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3368" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,357.95,394.53,10.91;14,112.66,371.50,393.33,10.91;14,112.66,385.05,393.33,10.91;14,112.66,398.60,394.52,10.91;14,112.66,412.15,340.10,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,112.66,371.50,314.54,10.91">Computational argumentation quality assessment in natural language</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Thijm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/E17-1017" />
	</analytic>
	<monogr>
		<title level="m" coord="14,450.78,371.50,55.20,10.91;14,112.66,385.05,393.33,10.91;14,112.66,398.60,46.69,10.91">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="14,213.62,398.60,52.92,10.91">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,425.70,393.71,10.91;14,112.66,439.25,395.17,10.91;14,112.66,452.79,387.52,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,498.63,425.70,7.73,10.91;14,112.66,439.25,329.89,10.91">A large-scale dataset for argument quality ranking: Construction and analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cohen-Karlik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,469.07,439.25,38.76,10.91;14,112.66,452.79,238.90,10.91">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7805" to="7813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,466.34,393.53,10.91;14,112.28,479.89,393.71,10.91;14,112.66,493.44,393.73,10.91;14,112.34,506.99,286.03,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,415.08,466.34,91.11,10.91;14,112.28,479.89,167.13,10.91">Data Acquisition for Argument Search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30179-8_4</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,112.66,493.44,241.68,10.91">German Conference on Artificial Intelligence (KI 2019)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Benzmüller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,520.54,395.17,10.91;14,112.66,534.09,393.33,10.91;14,112.66,547.64,185.71,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,270.03,520.54,237.80,10.91;14,112.66,534.09,99.09,10.91">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,234.29,534.09,271.70,10.91;14,112.66,547.64,112.63,10.91">Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</title>
		<meeting>the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,561.19,394.53,10.91;14,112.66,574.74,393.33,10.91;14,112.66,588.29,394.51,10.91;14,112.66,604.28,123.08,7.90" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,327.46,561.19,175.13,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,240.99,574.74,264.99,10.91;14,112.66,588.29,123.97,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,615.39,395.17,10.91;14,112.28,628.93,397.86,10.91;14,112.66,644.93,43.94,7.90" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3780049</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3780049.doi:10.5281/zenodo.3780049" />
		<title level="m" coord="14,305.96,615.39,201.87,10.91;14,112.28,628.93,59.38,10.91">Webis Argument Quality Corpus 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Webis-ArgQuality-20</note>
</biblStruct>

<biblStruct coords="14,112.66,656.03,394.53,10.91;14,112.66,669.58,295.45,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m" coord="14,303.00,656.03,204.19,10.91;14,112.66,669.58,113.82,10.91">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,112.66,86.97,394.53,10.91;15,112.30,100.52,393.68,10.91;15,112.66,114.06,107.17,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="15,173.99,100.52,256.51,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,112.66,127.61,393.53,10.91;15,112.66,141.16,393.33,10.91;15,112.66,154.71,209.68,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="15,408.01,127.61,98.18,10.91;15,112.66,141.16,227.98,10.91">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,363.40,141.16,142.59,10.91;15,112.66,154.71,179.66,10.91">ICLR 2020 : Eighth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,168.26,394.53,10.91;15,112.66,181.81,394.53,10.91;15,112.66,195.36,395.17,10.91;15,112.66,208.91,393.33,10.91;15,112.66,222.46,394.53,10.91;15,112.66,236.01,385.60,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,315.63,195.36,192.20,10.91;15,112.66,208.91,72.82,10.91">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m" coord="15,207.25,208.91,298.74,10.91;15,112.66,222.46,390.37,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,249.56,394.62,10.91;15,112.66,263.11,293.54,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="15,254.35,249.56,172.96,10.91">A Method for Stochastic Optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,454.40,249.56,52.88,10.91;15,112.66,263.11,242.71,10.91">ICLR 2015 : International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,276.66,394.53,10.91;15,112.66,290.20,384.84,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,354.84,276.66,147.43,10.91">Self-normalizing neural networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,127.29,290.20,231.06,10.91">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="971" to="980" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,303.75,395.01,10.91;15,112.66,317.30,188.31,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Biewald</surname></persName>
		</author>
		<ptr target="https://www.wandb.com/,softwareavailablefromwandb.com" />
		<title level="m" coord="15,163.90,303.75,197.33,10.91">Experiment tracking with weights and biases</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,330.85,393.33,10.91;15,112.66,344.40,393.59,10.91;15,112.66,357.95,393.53,10.91;15,112.66,371.50,394.61,10.91;15,112.31,385.05,172.79,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="15,291.85,330.85,214.13,10.91;15,112.66,344.40,31.02,10.91">Creating an argument search engine for online debates</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bundesmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Christ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richter</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_182.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="15,401.11,344.40,105.13,10.91;15,112.66,357.95,237.01,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="15,238.07,371.50,151.26,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,398.60,394.52,10.91;15,112.66,412.15,393.33,10.91;15,112.66,425.70,393.33,10.91;15,112.66,439.25,394.61,10.91;15,112.66,452.79,129.98,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="15,336.55,412.15,169.43,10.91;15,112.66,425.70,37.63,10.91">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/" />
	</analytic>
	<monogr>
		<title level="m" coord="15,406.99,425.70,98.99,10.91;15,112.66,439.25,143.83,10.91">Working Notes Papers of the CLEF 2020 Evaluation Labs</title>
		<title level="s" coord="15,332.13,440.26,121.85,9.72">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,466.34,394.53,10.91;15,112.66,479.89,393.33,10.91;15,112.66,493.44,393.33,10.91;15,112.66,506.99,394.04,10.91;15,112.66,520.54,66.21,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="15,212.03,466.34,210.87,10.91">Exploring argument retrieval with transformers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_241.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="15,291.12,479.89,214.87,10.91;15,112.66,493.44,128.24,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="15,124.75,506.99,152.64,10.91">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020. 2696. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,534.09,394.53,10.91;15,112.66,547.64,395.17,10.91;15,112.66,561.19,395.17,10.91;15,112.66,574.74,132.19,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="15,219.74,534.09,282.85,10.91">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,126.77,547.64,381.06,10.91;15,112.66,561.19,395.17,10.91;15,112.66,574.74,33.90,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3980" to="3990" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
