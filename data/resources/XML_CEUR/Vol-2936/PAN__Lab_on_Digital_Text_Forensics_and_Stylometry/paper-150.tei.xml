<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.32,370.84,16.17;1,89.29,108.89,160.62,10.37">Profiling Hate Spreaders using word N-grams Notebook for PAN at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.06,134.79,65.85,10.37"><forename type="first">Jorge</forename><surname>Alcañiz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,168.36,134.79,58.10,10.37"><forename type="first">José</forename><surname>Andrés</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Politècnica de València</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.32,370.84,16.17;1,89.29,108.89,160.62,10.37">Profiling Hate Spreaders using word N-grams Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B989F7D9F05768D793D80FB4FEE259A3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the rise of social media over the last decade, the amount of content that is published every day on the internet has become huge. Unfortunately, as the amount of published content grows, the amount of hate speech that can be found on social media also grows. This fact motivates the creation of systems that could automatically detect this undesired behaviors in order to report them to the competent authorities. With this purpose, we have developed a system that detect users which could be considered as hate spreaders employing a TF-IDF vectorizer in combination with an SVM, achieving an accuracy of 81% over the Spanish dataset and 69% over the English dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Hate speech is commonly defined as a propaganda of ideas based on the superiority of a group of people because of their race, color or ethnic origin. This problem is not novel, as it has been present in our society during centuries, but due to the rise of social media it has reached unprecedented levels. Given the huge amount of content generated by the users and the impossibility to manually check all the content, the automatic detection of hate speech has become a relevant task.</p><p>With this purpose, the aim of this competition is to automatically detect hate speech, but employing an author profiling perspective instead of a tweet perspective. Therefore, we are interested in detecting which users could be considered as hate spreaders.</p><p>This paper presents our participation in the Author Profiling task at PAN <ref type="bibr" coords="1,415.26,467.01,12.62,9.46" target="#b0">[1]</ref> for detecting hate spreaders <ref type="bibr" coords="1,133.01,480.56,11.55,9.46" target="#b1">[2]</ref>. Our method follows the ideas presented in <ref type="bibr" coords="1,338.34,480.56,11.55,9.46" target="#b2">[3]</ref>, which were focused on employing n-grams of chars and words as features and an SVM as classifier. Moreover, we have tried different classifiers and we have compared the obtained accuracies between them. The rest of this paper is structured as follows: Section 2 describes the dataset used for this shared task, Section 3 presents the preprocessing that we have applied for each language, Section 4 presents our approach to the problem, the results obtained per each model and a discussion of them and finally Section 5 summarizes the paper and proposes possible future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Corpus</head><p>The dataset of this competition was composed by 200 authors for each language, where each author was composed by 200 tweets. From the 200 authors, 100 were hate spreaders and the other 100 were not. Moreover, we would like to remark that all the urls, links, hashtags and user mentions on the corpus were masked by a unique token for each type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preprocessing</head><p>The objective of this step is to reduce the vocabulary size by merging different token occurrences that are referring to the same concept. For the preprocessing of the dataset we have followed these steps.</p><p>In first place, as we are interested in detecting hate speech at author level, we have concatenated all the tweets of each author into one single string. Then, we have converted the text to lowercase and we have replaced all the emojis and emoticons by the token "emoji" employing a regular expression. After that, we have applied a different linguistic preprocessing for each language: in the English dataset, we have replaced some contractions by their expanded form, (for example, the token: "you'd" has been replaced by "you would", the token "it's" has been replaced by "it is", etc), meanwhile in the Spanish dataset we have replaced some words by their homologous colloquial tokens (for instance, the token "por" has been replaced by "x" and the token "que" has been replaced by "k"). Then, we have removed all the punctuation signs such as points, commas, exclamation signs, etc. Moreover, we have reduced different forms of expressing laugh such as "hahahah", "ahahha","jajajaja", "lol","lmao" to the token "haha". Finally, we have removed the stopwords and performed stemming on both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our Approach</head><p>In this task we have considered the feature extraction process and the machine learning model estimation as a combined optimization process. Therefore, we have performed an extensive grid search to choose the best combination of hyper-parameters for the tfidf vectorizer and the different machine learning models employed. To assess the performance of our classifier, we have performed a 10-fold cross validation over the training dataset.</p><p>For feature extraction, we have employed a TF-IDF <ref type="bibr" coords="2,324.77,530.88,12.60,9.46" target="#b3">[4]</ref> vectorizer, which allows us to quantify the importance of every sequence of terms present in the corpus, multiplying the term frequency in the text by the inverse document frequency of the term in the corpus. The hyper-parameters of the Vectorizer are the following: "analyzer", which denotes the level at which the feature extraction is performed (either word level or character level), "ngram_range", which denotes the order of the employed language model and "min_df", which removes those n-grams whose document frequencies are lower than a given threshold.</p><p>Before starting to discuss the selected classifiers, we would like to remark that we have decided to avoid employing deep learning for this task. This is due to the fact that we only have 200 samples for each author, and given that deep learning is usually data-hungry, it could easily turn into overfit. Therefore, among all the possible machine learning models, we have chosen the following: logistic regression (LR) <ref type="bibr" coords="3,246.32,192.01,11.71,9.46" target="#b4">[5]</ref>, Naive Bayes (NB) <ref type="bibr" coords="3,342.41,192.01,14.39,9.46" target="#b5">[6]</ref>, Support Vector Machine (SVM) <ref type="bibr" coords="3,89.29,205.56,11.74,9.46" target="#b6">[7]</ref>, Random Forest (RF) <ref type="bibr" coords="3,202.40,205.56,11.74,9.46" target="#b7">[8]</ref>, multiple linear models trained with Stochastic Gradient Descent (SGD) <ref type="bibr" coords="3,120.74,219.11,12.72,9.46" target="#b8">[9]</ref> and K-nearest neighbor (KNN) <ref type="bibr" coords="3,274.93,219.11,16.97,9.46" target="#b9">[10]</ref>:</p><p>• Logistic regression: Basic algorithm for binary classification, equivalent to "Linear regression" but taking a logit function. The hyper-parameters taken for this model are, "penalty" of L2, with a "solver" liblinear and the regularization coefficient "C".</p><p>• Naive Bayes: A well-known technique which has been employed for tackling many information retrieval problems. For this model, the hyper-parameters used are the smoothing parameter "alpha" and "fit_prior", which denotes if the model wants to learn the prior of every class in the model.</p><p>• Support Vector Machine: A linear classification model that employs as decision boundary the maximal margin hyperplane. This fact is relevant to our task, given that due to the moderate size of the dataset and the large number of extracted features, many possible decision boundaries exist. Moreover, this model also allows solving non-linear problems by applying the appropriate kernel function. The tuned hyper-parameters are the regularization coefficient "C" and the employed kernel.</p><p>• Random Forest: An ensemble model of multiple decision trees. The tuned hyperparameters are "criterion", to measure the quality of every split, and "min_samples_leaf", which denotes the number of samples required to be a leaf node.</p><p>• Stochastic Gradient Descent classifier: An optimization technique that allows us to fit linear classifiers employing gradient descent. The hyper-parameters selected for this model are the following: "'loss" criteria, where each one of the losses represent a linear classifier (for example, having as loss "log" will result in a logistic regression model with SGD training). In this task we have used an L2 "penalty" and an "'alpha" to regularize terms.</p><p>• K-Nearest Neighbor: A well known non-parametric classifier where the class for each test sample is computed from a simple majority vote of the K nearest neighbors of each point. The tuned hyper-parameters for this model are the "weights", which could be uniform (each point is weighted equally) or proportional to the distance from their neighbors. Among all the possible distance metrics, we have tried the following: Euclidean distance, Manhattan distance and Minkowski distance. Finally, we have also tuned the number of neighbors "n_neighbors" to consider during the voting and the "leaf_size" of each branch.</p><p>Finally, we would like to remark that we have used scikit-learn <ref type="bibr" coords="4,370.58,192.39,18.03,9.46" target="#b10">[11]</ref> as toolkit for the employed machine learning models. If we take a look at Tab. 2, it can be seen that linear models such as SVM, logistic regression and SGD classifier have performed particularly well at this task. This is due to the fact that the number of features is much larger than the number of samples, making it feasible to separate the two classes linearly. From these models, the best performing one has been the SVM, achieving an 80.90% of accuracy for the Spanish dataset and a 70.50% of accuracy for the English dataset.</p><p>Again, this is motivated by the fact that the SVM chooses the separating hyperplane with the maximal margin from among all the possible separating hyperplanes. Other techniques such as Random Forest, Naïve Bayes classifier and K-NN also performed well, but they did not achieve the results obtained by the linear models. As final model, we have chosen an SVM for both datasets, given that it is the classifier which has achieved the highest estimated accuracy in both languages. Finally, we have trained an SVM for each language, employing the full train dataset and the hyper-parameters described in Tab. 2. The results obtained in the competition with these models are the following: It can be seen that our estimation of the performance of the system has worked reasonably well, matching the test accuracy very similar levels to the ones predicted during training. Test accuracy results have been provided by the TIRA evaluation platform <ref type="bibr" coords="5,395.24,582.66,16.72,9.46" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>To sum up, we have described the methods employed for this task. We have detailed how our whole system works, from the preprocessing step to the estimation of the best hyper-parameters for the feature extractor and the machine learning models. We have also seen that our estimation of the accuracy employing a 10 fold CV is consistent with the test results. As future works, we would like to test an ensemble model of different classifiers to see if it can beat the performance achieved by our SVM.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,335.07,284.12,9.35;5,181.05,150.11,230.40,172.80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Accuracies obtained by each model during 10-fold CV.</figDesc><graphic coords="5,181.05,150.11,230.40,172.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.98,90.03,295.10,73.50"><head>Table 1</head><label>1</label><figDesc>Hyper-parameters tested during grid search for Tfidf Vectorizer.</figDesc><table coords="3,208.43,118.05,175.65,45.48"><row><cell>Vectorization</cell><cell>Hyper-parameters</cell></row><row><cell>Analyzer</cell><cell>{'word','char','char_wb'}</cell></row><row><cell>Ngrams</cell><cell>{(1,1), (1,2), (2,2)}</cell></row><row><cell>min_df</cell><cell>{1,2,3,4,5,6,7,8,9,10,11}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.98,232.37,457.37,326.55"><head>Table 2</head><label>2</label><figDesc>Best hyper-parameters and accuracy obtained performing a 10-fold cross validation.</figDesc><table coords="4,95.27,260.39,451.08,298.53"><row><cell cols="2">Model Language</cell><cell>Model Hyper-params</cell><cell cols="2">Tf-idfVect Hyper-params Acc. (%)</cell></row><row><cell>LR</cell><cell>EN</cell><cell>C: 100</cell><cell>word, unigram and bigrams,</cell><cell>68.50</cell></row><row><cell></cell><cell>ES</cell><cell>C: 100</cell><cell>min_df: 11</cell><cell>80.50</cell></row><row><cell>NB</cell><cell>EN</cell><cell>alpha: 0.25, prior: False</cell><cell>word, unigram and bigrams,</cell><cell>65.55</cell></row><row><cell></cell><cell>ES</cell><cell>alpha: 0.25, prior: True</cell><cell>min_df: 8</cell><cell>79.00</cell></row><row><cell>RF</cell><cell>EN</cell><cell>criterion:"gini", depth: 4, min_samples: 10</cell><cell>word, unigram and bigrams,</cell><cell>67.00</cell></row><row><cell></cell><cell>ES</cell><cell>criterion:"gini", depth: 4, min_samples: 8</cell><cell>min_df: 8</cell><cell>80.50</cell></row><row><cell>KNN</cell><cell>EN</cell><cell>weights:"distance", metric: "euclidean", neighbors: 5, leaf_size=20</cell><cell>word, min_df: 8 unigram and bigrams,</cell><cell>65.00</cell></row><row><cell></cell><cell>ES</cell><cell>weights:"distance", metric: "euclidean", neighbors: 10, leaf_size=20</cell><cell>word, min_df: 9 bigrams,</cell><cell>77.00</cell></row><row><cell>SGD</cell><cell>EN</cell><cell>alpha:0.01, loss:"perceptron"</cell><cell>word, unigram and bigrams,</cell><cell>70.00</cell></row><row><cell></cell><cell>ES</cell><cell>alpha:0.001, loss:"hinge"</cell><cell>min_df: 9</cell><cell>80.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell>word</cell><cell></cell></row><row><cell>SVM</cell><cell>EN</cell><cell>C: 0.1, kernel: "linear"</cell><cell>unigrams,</cell><cell>70.50</cell></row><row><cell></cell><cell></cell><cell></cell><cell>min_df: 4</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>word</cell><cell></cell></row><row><cell></cell><cell>ES</cell><cell>C: 1, kernel: "linear"</cell><cell>unigrams,</cell><cell>80.90</cell></row><row><cell></cell><cell></cell><cell></cell><cell>min_df: 10</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.98,450.36,284.42,82.10"><head>Table 3</head><label>3</label><figDesc>Train and test obtained accuracies employing an SVM.</figDesc><table coords="5,219.11,481.91,154.29,50.56"><row><cell>Language</cell><cell>Estimated acc. (Train 10 -CV)</cell><cell>Test Acc.</cell></row><row><cell>ES</cell><cell>80.90%</cell><cell>81%</cell></row><row><cell>EN</cell><cell>70.50%</cell><cell>69%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.92,175.10,394.43,9.46;6,112.92,188.65,394.43,9.46;6,112.92,202.20,393.06,9.46;6,112.92,215.75,393.06,9.46;6,112.92,229.30,242.59,9.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,229.32,202.20,276.66,9.46;6,112.92,215.75,242.16,9.46">Overview of PAN 2021: Authorship Verification,Profiling Hate Speech Spreaders on Twitter,and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,377.83,215.75,128.15,9.46;6,112.92,229.30,168.03,9.46">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,242.85,393.07,9.46;6,112.92,256.39,393.34,9.46;6,112.92,269.94,130.54,9.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,408.63,242.85,97.36,9.46;6,112.92,256.39,150.05,9.46">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,309.68,256.39,144.89,9.46">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="6,462.54,256.39,43.71,9.46;6,112.92,269.94,57.34,9.46">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,283.49,364.23,9.46" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,160.78,283.49,237.90,9.46">Using n-grams to detect fake news spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,297.04,394.43,9.46;6,112.71,310.59,146.04,9.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,169.96,297.04,333.46,9.46">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,112.71,310.59,111.50,9.46">Journal of documentation</title>
		<imprint>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,324.14,393.07,9.46;6,112.92,337.69,393.06,9.46;6,112.92,351.24,188.45,9.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,203.56,324.14,302.43,9.46;6,112.92,337.69,153.67,9.46">On the rate of growth of the population of the united states since 1790 and its mathematical representation</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,274.83,337.69,231.16,9.46;6,112.92,351.24,126.64,9.46">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">275</biblScope>
			<date type="published" when="1920">1920</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,364.79,394.42,9.46;6,112.71,378.34,208.76,9.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,232.56,364.79,270.88,9.46">On relevance, probabilistic indexing and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Kuhns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,112.71,378.34,125.13,9.46">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="216" to="244" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,391.89,376.43,9.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,209.07,391.89,105.88,9.46">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,323.62,391.89,76.65,9.46">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,405.44,281.15,9.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,169.27,405.44,67.53,9.46">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,244.70,405.44,76.65,9.46">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,418.99,393.06,9.46;6,112.92,432.53,88.06,9.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,166.74,418.99,208.88,9.46">Online learning and stochastic approximations</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,387.84,418.99,118.14,9.46;6,112.92,432.53,39.88,9.46">On-line learning in neural networks</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,446.08,393.06,9.46;6,112.92,459.63,393.06,9.46;6,112.56,473.18,395.33,9.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,377.85,446.08,128.13,9.46;6,112.92,459.63,393.06,9.46">An important contribution to nonparametric discriminant analysis and density estimation: Commentary on fix and hodges</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,147.44,473.18,286.62,9.46">International Statistical Review/Revue Internationale de Statistique</title>
		<imprint>
			<biblScope unit="page" from="233" to="238" />
			<date type="published" when="1951">1951. 1951. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,486.73,394.43,9.46;6,112.92,500.28,393.06,9.46;6,112.71,513.83,264.79,9.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,308.95,500.28,175.17,9.46">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,492.73,500.28,13.25,9.46;6,112.71,513.83,164.79,9.46">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.92,527.38,394.43,9.46;6,112.92,540.93,393.07,9.46;6,112.92,554.48,394.37,9.46;6,112.92,569.05,135.63,7.68" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,329.13,527.38,173.72,9.46">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,244.71,540.93,261.27,9.46;6,112.92,554.48,120.48,9.46">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
