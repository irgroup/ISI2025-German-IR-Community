<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.03,75.53,450.53,17.00;1,72.03,96.28,264.83,17.00;1,72.03,116.27,148.65,9.90">Dual Neural Network Classification Based on BERT Feature Extraction for Authorship Verification Notebook for PAN at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.03,141.85,72.06,10.80"><forename type="first">Xiaogang</forename><surname>Miao</surname></persName>
							<email>xiaogangmiao163@gmail.com</email>
						</author>
						<author>
							<persName coords="1,152.74,141.85,57.46,10.80"><forename type="first">Haoliang</forename><surname>Qi</surname></persName>
							<email>qihaoliang@fosu.edu.cn</email>
						</author>
						<author>
							<persName coords="1,223.69,141.85,59.64,10.80"><forename type="first">Zhijie</forename><surname>Zhang</surname></persName>
							<email>zhangzhijie5454@gmail.com</email>
						</author>
						<author>
							<persName coords="1,292.15,141.85,60.92,10.80"><forename type="first">Guiyuan</forename><surname>Cao</surname></persName>
							<email>caoguiyuan2020@163.com</email>
						</author>
						<author>
							<persName coords="1,361.63,141.85,49.61,10.80"><forename type="first">Ruilan</forename><surname>Lin</surname></persName>
							<email>lrllinruilan@163.com</email>
						</author>
						<author>
							<persName coords="1,419.43,141.85,57.72,10.80"><forename type="first">Wenbin</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Foshan University</orgName>
								<address>
									<settlement>Foshan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.03,75.53,450.53,17.00;1,72.03,96.28,264.83,17.00;1,72.03,116.27,148.65,9.90">Dual Neural Network Classification Based on BERT Feature Extraction for Authorship Verification Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">74D9DF9F07C3D44DBC4708884FE118F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dual Neural Network</term>
					<term>BERT</term>
					<term>Long Text Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship verification is the task of deciding whether two texts have been written by the same author. We regard authorship verification as a classification task. A dual neural network is proposed to classify the features of text extraction. Especially, BERT is exploited as the encoder to extract the text features. After training and forecasting on the given pan20authorship-verification-training-small data set, the weighted average of the specified evaluation indexes (including: AUC, F1, c@1, f0.5u, Brier) can reach about 0.85.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Authorship verification is an active research field in computational linguistics. By comparing the writing style of text, the author determines whether the same author has written two texts <ref type="bibr" coords="1,471.53,384.86,11.75,9.90" target="#b0">[1,</ref><ref type="bibr" coords="1,483.28,384.86,7.83,9.90" target="#b1">2]</ref>. It has been widely used in the academic field. It can be used as a detection direction of academic paper fraud and plagiarism, not only detecting word repetition rate. In 2021, the training data are the same as last year, open-set Authorship Verification. It is difficult to see if there are new authors and themes, so the task difficulty has been increased <ref type="bibr" coords="1,223.40,435.36,11.43,9.90" target="#b2">[3]</ref>. Essentially, given two paragraphs, it is a text pair classification problem to determine whether the same author writes it and whether the label is "true" or "false". This paper uses a double-input neural network model, which can extract and learn each text information step by step and then train and predict the results in the upper neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head><p>The dataset used by the Authorship verification is given by the evaluation web pan@clef. The train (calibration) and test datasets consists of pairs of (snippets from) two different fanfics, that were obtained drawn from fanfiction.net. Each pair was assigned a unique identifier and we distinguish between same-author pairs and different-authors pairs <ref type="bibr" coords="1,312.38,569.16,11.44,9.90" target="#b2">[3]</ref>.</p><p>There are two datasets verified by the author. The difference lies in the number of text pairs included. For larger datasets and smaller datasets <ref type="bibr" coords="1,245.96,594.41,11.43,9.90" target="#b3">[4]</ref>, we use smaller datasets, which contain 52,601 pairs of text. They are all written in a JSON file, including 'id', 'fandoms', 'pair' in pair.json file, then 'id', 'same' and 'authors' in truth.json file. In fact, we mainly use the text pairs in the 'pair' item to extract the required information <ref type="bibr" coords="1,126.76,632.41,11.43,9.90" target="#b2">[3]</ref>.</p><p>In the data set, most of the text characters are between 30,000 and 20,670, a few are between 30,000 and 300,000, and most of the words are between 55,433 and 42,372. There are only NYAN, HUAE and other words in the text pairs of some of the data, because the data is from fanfection.net, we can't determine whether it is some wrong data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We adopt a dual-input neural network model to learn text information and a feature extraction processing text based on the BERT model <ref type="bibr" coords="2,259.99,157.79,11.43,9.90" target="#b4">[5]</ref>. The specific implementation method is as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dual Neural Network Classifier</head><p>We used a dual-input model for the authorship verification task for classification training. The specific model is shown below. Figure <ref type="figure" coords="2,247.97,228.07,21.78,9.90" target="#fig_1">1-(a)</ref> is the preprocessing process of the original text, and the long text is aligned with the clause. Figure <ref type="figure" coords="2,263.67,240.82,17.69,9.90" target="#fig_1">1-(b</ref>) is to put the well-divided sentence set into the BERT model to extract the corresponding feature vector of the text. Figure <ref type="figure" coords="2,379.37,253.32,17.17,9.90" target="#fig_1">1-(c</ref>) indicates that the extracted feature vectors are sent to the dual-input neural network for final prediction classification.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Text Processing</head><p>First of all, according to statistics, each text segment is based on multiple sentences, so we use punctuation marks as sentence separators to divide, mainly full stop, exclamation mark, and question mark. In this way, the long text segment can be divided into several small sentences, which can be processed by BERT. However, there are also some problems. For example, the sentences which are composed of multiple repeated words such as 'NYAN' mentioned in the data set do not have the above sentence segmentation conditions. Some text segments are more than 20,000 characters in length, but sentence separators are not used in the whole paragraph, which may be related to the author's writing habits. Therefore, if there is no sentence after the first sentence segmentation, we need to segment the sentence directly according to the length of the character. In theory, some information will be lost. Fortunately, the sentences that need to be segmented occupy a small part of the whole dataset, which is less than 0.1%, so it has little impact on the final result.</p><p>Through the above text segmentation operation, we will divide the long text into several short sentences. Here we use BERT as a feature extractor. As a pre-training model, BERT has multiple versions. We use BERT-Large, Cased (Whole Word Masking): 24-layer, 1,024-hidden, 16-heads, 340M parameters <ref type="bibr" coords="2,157.22,697.69,11.43,9.90" target="#b4">[5]</ref>. Because the parameters have been trained in advance, in the normal text classification task, we use BERT as a feature extractor and then a downstream task (usually neural network) as a model and then fine-tune the overall performance. But in this task, we can't input all the text at one time, so we only consider using BERT as a feature extractor. The specific method is to extract the CLS vector of each short sentence as the feature of the short sentence through 12 level Transformer. CLS obtains the sentence-level information representation through the self-attention mechanism, which can capture the context information representation in the current environment. Then the CLS vectors of several short sentences are superimposed to represent the sentence feature vectors of long text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">References</head><p>Based on the above general introduction, we will introduce the working model and results in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Second level heading</head><p>Because of the length of the text in the task data set and the information contained in the text is very scattered, it is difficult to use sliding window truncation. However, since the computation resources and time consumed by BERT increase with the square level of token length, it can't handle too long tokens. At present, it only supports 512 tokens at most. If the token is too long, it is easy to overflow memory. Therefore, we need to design a clever method to solve this problem when using BERT to process long text. Therefore, we need to first make some clauses in the text. First of all, we divide the data set into two parts: the positive and negative samples of the data set are 50%, the first half is true, and the later version is false. Then we take 52,000 as the training set and the rest as the verification. The first method is to splice the feature vectors of two texts because each feature vector is 768 dimensions, and the spliced vector is a feature representation of 1,536 dimensions. Then we send this feature into a simple neural network for binary classification, but after training, we find that its accuracy in the training set is not very high. The overall verification set is only 0.82. Then the second method is that we build a double input neural network, which is the fusion of the information from the training of the two text features in their respective neural networks <ref type="bibr" coords="3,267.34,405.36,11.43,9.90" target="#b5">[6]</ref>. After a two-classification prediction, the final overall on the test set can reach 0.87. We speculate that the reason for this may be that the neural network can not effectively recognize the whole order of sentences in the first step after using splicing, or we have not trained it sufficiently. In fact, the number of neurons and activation function, and other parameters are selected and experimented with according to our experience. The implementation method is not necessarily the optimal result under this idea but only a reference scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Second level heading</head><p>In addition to the above data allocation, we also allocate 80% of the training data and 20% of the validation data to compare the training before starting the formal training to find the appropriate number of training epochs. Table <ref type="table" coords="3,185.07,551.66,5.50,9.90" target="#tab_0">1</ref> shows the experimental results. Because the final score on the test set was not given at the time of final submission, we can only show the score on the training set now, which may not be very accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">References</head><p>In the authorship verification task, we use the dual-input neural network model to accept the text features extracted from the BERT model for classification learning. In the model, the feature information of the two texts can be learned respectively and then sent to the upper neural network for classification. To some extent, it avoids the decrease of learning efficiency caused by the fact that the splicing cannot learn the two-sentence sequences. Good results are achieved on the training dataset given by the evaluation task. Note that we did not fine-tune the native model when we used BERT as a feature extractor. Because we first segment the text and then extract features, if you want to fine-tune should be considered into the segmented sentence for operation. However, the information obtained by this model may be partial, incomplete information based on the whole text, and we are not sure whether this will help on open sets. It is hoped that someone can solve the problem of feature extraction accuracy in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,72.03,436.12,39.47,11.00;2,114.05,444.37,72.23,1.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: model summary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,72.03,563.67,433.53,68.50"><head>Table 1 The</head><label>1</label><figDesc></figDesc><table coords="3,84.53,577.18,421.03,54.99"><row><cell cols="4">score of training data and validation data after processing</cell><cell></cell><cell></cell></row><row><cell>data set</cell><cell>AUC</cell><cell>C@1</cell><cell>F0.5U</cell><cell>F1-SCORE</cell><cell>OVERALL</cell></row><row><cell>training</cell><cell>0.866</cell><cell>0.938</cell><cell>0.858</cell><cell>0.865</cell><cell>0.881</cell></row><row><cell>verification</cell><cell>0.855</cell><cell>0.914</cell><cell>0.839</cell><cell>0.857</cell><cell>0.867</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,108.05,208.32,415.11,9.90;4,86.28,221.07,335.11,9.90" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,307.51,208.32,215.64,9.90;4,86.28,221.07,317.65,9.90">Overview of PAN 2021: Authorship Verification, Profiling Hate Speech Spreaders on Twitter, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.05,233.57,414.63,9.90;4,86.28,246.32,436.66,9.90;4,86.28,259.06,84.47,9.90" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,352.83,233.57,169.85,9.90;4,86.28,246.32,436.66,9.90;4,86.28,259.06,37.98,9.90">Overview of PAN 2021: Authorship Verification, Profiling Hate Speech Spreaders on Twitter, and Style Change Detection: Extended Abstract</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gldlp Sarrac√©n</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.05,271.57,177.74,9.90" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Organization</surname></persName>
		</author>
		<ptr target="https:/pan.webis.de/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.05,284.31,414.63,9.90;4,86.28,296.84,290.39,9.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,265.86,284.31,256.83,9.90;4,86.28,296.84,40.69,9.90">Research and application on improved BP neural network algorithm</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,131.49,296.84,183.96,9.90">C]// Industrial Electronics &amp; Applications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.05,309.59,415.28,9.90;4,86.28,322.09,168.23,9.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,275.98,309.59,247.35,9.90;4,86.28,322.09,122.20,9.90">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,213.11,322.09,4.63,9.90">J</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,108.05,334.84,414.86,9.90;4,86.28,347.59,436.69,9.90;4,86.28,360.09,24.75,9.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,327.60,334.84,195.32,9.90;4,86.28,347.59,52.06,9.90">Deep Bayes Factor Scoring for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boenninghoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Nickel R M</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,163.46,347.59,354.17,9.90">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
