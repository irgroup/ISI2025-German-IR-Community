<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,409.61,15.42;1,89.29,106.66,68.59,15.42;1,88.93,129.00,164.42,11.96">Profiling Hate Speech Spreaders on Twitter: SVM vs. Bi-LSTM (Notebook for PAN at CLEF 2021)</title>
				<funder>
					<orgName type="full">National Research Center for Applied Cybersecurity ATHENE</orgName>
				</funder>
				<funder>
					<orgName type="full">German Federal Ministry of Education and Research</orgName>
				</funder>
				<funder>
					<orgName type="full">Lernlabor Cybersicherheit&quot; (LLCS)</orgName>
				</funder>
				<funder>
					<orgName type="full">Hessen State Ministry for Higher Education, Research and the Arts</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,52.30,11.96"><forename type="first">Inna</forename><surname>Vogel</surname></persName>
							<email>inna.vogel@sit.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,154.24,154.90,93.37,11.96"><forename type="first">Meghana</forename><surname>Meghana</surname></persName>
							<email>meghana.meghana@sit.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,409.61,15.42;1,89.29,106.66,68.59,15.42;1,88.93,129.00,164.42,11.96">Profiling Hate Speech Spreaders on Twitter: SVM vs. Bi-LSTM (Notebook for PAN at CLEF 2021)</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A885D148E35F84ADCDBA1BF40E9B3F53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Profiling</term>
					<term>Hate Speech Spreaders</term>
					<term>SVM</term>
					<term>Bi-LSTM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hate speech is a crime that has been growing in recent years, especially in online communication. It can harm the individual or a group of people by targeting their conscious or unconscious intrinsic characteristics. Additionally, the psychological burden of manual moderation has necessitated the need for automated hate speech detection methods. In this notebook, we describe our profiling system to the PAN at CLEF 2021 lab "Profiling Hate Speech Spreaders on Twitter". The aim of the task is to determine whether it is possible to identify hate speech spreaders on Twitter automatically. Our final submitted system uses character ùëõ-grams as features in combination with an SVM and achieves an overall average accuracy of 69.5% for the English and Spanish datasets. Additionally, we experimented with a Bi-LSTM model and trained it with Sentence-BERT, achieving slightly worse performance results. The experiments show that it is difficult to detect solidly hate speech spreaders on Twitter as hate speech is not only the use of profanity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Cambridge Dictionary defines hate speech as abusive or threatening speech or writing that expresses hate or prejudice towards a person or a particular group 1 , especially based on ethnicity, religion, sex, or sexual orientation. Thus said, any characteristics of an individual can become the target of hate be it gender, nationality, or even educational background. The Internet and the possibility of communicating anonymously made it additionally an effective vehicle for spreading hateful and offensive content at an unprecedented rate <ref type="bibr" coords="1,405.80,499.93,11.58,10.91" target="#b0">[1]</ref>. Moreover, studies have highlighted a connection between the spread of hate speech and hate-related crimes <ref type="bibr" coords="1,492.37,513.48,11.47,10.91" target="#b1">[2]</ref>. That means, the spread of hate speech has the potential to damage our society, and cause severe harm to people or entire groups.</p><p>Currently, social media companies such as Twitter and Facebook use human annotators to manually detect hateful comments and posts 2 . Additionally, users are encouraged to report offensive and potentially harmful content. Given the high volume of messages posted on social media websites, these methods are time-consuming, expensive, and depend on human judgment. The evident harm and volume of the uncontrolled spread of hate speech <ref type="bibr" coords="2,457.49,86.97,12.75,10.91" target="#b2">[3]</ref> and the psychological burden of manual moderation <ref type="foot" coords="2,284.25,98.76,3.71,7.97" target="#foot_0">3</ref> have necessitated the development of automated hate speech detection methods.</p><p>This problem of detecting hate speech is addressed in this year's author profiling shared task of PAN at CLEF 2021 lab<ref type="foot" coords="2,219.67,139.41,3.71,7.97" target="#foot_1">4</ref>  <ref type="bibr" coords="2,226.61,141.16,11.37,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,240.71,141.16,7.58,10.91" target="#b4">5]</ref>. Author profiling is the analysis of people's writing in an attempt to identify demographic aspects such as age, gender, language variety, or psychographic aspects such as an author's personality type <ref type="bibr" coords="2,289.88,168.26,11.42,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,304.02,168.26,7.61,10.91" target="#b6">7]</ref>. Given a Twitter feed, the final goal of this year's challenge is to identify possible hate speech spreaders on Twitter as a first step towards preventing hate speech from being propagated among online users.</p><p>We propose two different learning experiments. Our final submitted system uses TF-IDF weighted character ùëõ-grams as features in combination with an SVM. As recurrent neural networks (RNN) can preserve sequence information over time, and thereby integrate contextual information better in classification tasks, we additionally experimented with a bidirectional LSTM (Bi-LSTM) and trained it with Sentence-BERT (SBERT), a modification of the BERT network. SBERT uses siamese and triplet network structures to derive semantically meaningful sentence embeddings <ref type="bibr" coords="2,190.71,290.20,11.58,10.91" target="#b7">[8]</ref>. Both models were trained on the PAN 2021 corpus provided by the organizers <ref type="bibr" coords="2,158.67,303.75,11.58,10.91" target="#b8">[9]</ref>. The corpus covers two languages: English (EN) and Spanish (ES). The performance of the systems is ranked by accuracy. Both models have achieved almost the same classification results. The SVM model performed slightly better than the Bi-LSTM model achieving an overall accuracy of 64% and 75% on the English and Spanish corpus, respectively (average 69.5%). The Bi-LSTM model achieved an overall average accuracy of 69%. The results show that it is not an easy task to differentiate solidly Twitter users who spread hate speech from those who for the most part follow the platform's policies and guidelines.</p><p>In the following sections, we describe our approach for the author profiling task at PAN 2021. After a brief review of related work in Section 2, Section 3 details the Twitter data provided by the PAN 2021 organizers. Additionally, we show some key statistics observed in the tweets. Section 4 details the preprocessing steps and features used to train our models. The methodology and classification results are discussed in Section 5. The last Section 6 concludes our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Mutanga et al. <ref type="bibr" coords="2,157.79,511.42,18.07,10.91" target="#b9">[10]</ref> investigated in their study different transformer-based methods for hate speech detection in Twitter texts. They used a publicly available multi-class hate speech corpus containing 24,783 tweets. The dataset is highly imbalanced with 77.4% of the tweets labeled as "neutral", 16.8% as "Offensive", and 5.8% as "Hate". DistilBERT, a distilled version of BERT, outperformed all other trained methods such as XLNet, RoBERTa or attention-based LSTM achieving an ùêπ 1-score of 75%.</p><p>Kov√°cs et al. <ref type="bibr" coords="2,157.94,592.72,12.69,10.91" target="#b2">[3]</ref> used a combination of Convolutional and Long Short-Term Memory (LSTM) neural networks to detect hate speech in social media. The model was applied to the HASOC2019 corpus and attained a macro ùêπ 1-score of 63%. The authors also conducted experiments with RoBERTa and FastText as feature extractors. As the training data was limited, different methods for expanding resources, such as leveraging unlabeled data or similarly labeled corpora, were explored. Their results show that classification results could be significantly increased by leveraging additional data.</p><p>A major challenge for the automatic detection of hate speech on social media is the separation between hate speech and instances of offensive language. Davidson et al. <ref type="bibr" coords="3,423.91,154.71,18.07,10.91" target="#b10">[11]</ref> first collected tweets using hate speech keywords. Crowdsourcing was used to label the tweets into the following three categories: "hate speech", "offensive language", and "neither". A multi-class classifier was then trained to distinguish between the three categories. The best performing model achieved an overall ùêπ 1-score of 90%. However, the confusion matrix revealed that almost 40% of the hate speech tweets were misclassified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset and Corpus Analysis</head><p>To train our system, we used the PAN 2021 author profiling corpus <ref type="foot" coords="3,375.44,279.33,3.71,7.97" target="#foot_2">5</ref> proposed by Rangel et al. <ref type="bibr" coords="3,492.63,281.08,11.28,10.91" target="#b8">[9]</ref>. The corpus consists of 200 English (EN) and Spanish (ES) Twitter authors each. The tweets are stored in an XML file containing 200 tweets per author. Every tweet is stored in a &lt;document&gt; XML tag. The dataset is balanced, which means the data refers to an equal distribution of class instances. Half of the documents per language folder are authors that have been identified sharing hate speech. The other half are texts from users who may share offensive tweets but could not be identified as hate speech spreaders. Table <ref type="table" coords="3,345.62,362.38,5.17,10.91" target="#tab_0">1</ref> shows excerpts from the corpus <ref type="foot" coords="3,501.01,360.62,3.71,7.97" target="#foot_3">6</ref> . Every author received an alphanumeric author-ID which is stored in a separate text file together with the corresponding class affiliation. For training and testing, we split the data in the ratio of 70/30. The gold standard can only be accessed through the TIRA <ref type="bibr" coords="3,395.65,403.03,18.06,10.91" target="#b11">[12]</ref> evaluation platform provided by the PAN organizers. The results are hidden from the participants and can only be unblinded by the organisers.</p><p>It is important to note that the classes are not predefined by the organizers. We assume that class 0 refers to hate speech spreaders. Nevertheless, since the organisers do not explicitly define classes 0 and 1, we have kept the class names as originally proposed. As can be seen in Table <ref type="table" coords="3,115.08,484.32,3.66,10.91" target="#tab_0">1</ref>, the Twitter-specific tokens such as hashtags, URLs, and user mentions were replaced by the providers with the following placeholders: #HASHTAG#, #URL# and #USER#. The examples provided in Table <ref type="table" coords="3,173.31,511.42,5.17,10.91" target="#tab_0">1</ref> were chosen carefully to show that insults and profanities are used by hate speech spreaders as well as by other users. Additionally, Twitter-specific text significantly contributes to the difficulty of automatic hate speech detection, as the posts contain plenty of poorly written text and paralinguistic signals such as emoticons, @-mentions, and hashtags. Prior to feature engineering (described in Section 4), we analysed the distribution of different tokens. Table <ref type="table" coords="3,151.28,579.17,5.07,10.91" target="#tab_1">2</ref> shows some key insights for both languages.</p><p>We observed the distribution of specific tokens to see whether we could use these for the features engineering process. Unfortunately, we could not spot any significant differences between the classes. Therefore, to train our model, we did not use features mentioned in Table <ref type="table" coords="3,500.35,619.81,3.66,10.91" target="#tab_1">2</ref>. "Kappa They gon be beating my fodder ninjas asses weak ass punks and i wont even be laughing on the outside :-)" "RT #USER#: If a nigga taking care of me i'm fasho taking care of him. it's really that simple. " "Shut your fucking mouth i have no ill will towards Kaep but he's not even close lmao #URL#" "RT #USER#: Celebrities are so useless and corny B*tch what the fuck does this even mean?" "#USER# All the people shit talkin this are trippin, i'd pipe tf out if an old lady if she was payin for all my shit" "#USER# #USER# Mordes la mano de quien de da. De comer eres un cancer para nuestro pais #URL#" "#USER# Pos pa tu tierra sucnormal hijadeputa" "Los varones opinando sobre el feminismo #HASHTAG#. Nos sorprende? No nos sorprende" "#USER# Ostia tio que palo meti√≥ el jodido" "Que pinches perras ganas de estar cogiendo con Ale" "RT #USER#: Qu√© horror. Condenado a 15 a√±os de prisi√≥n por dejar embarazada a su hija tras un a√±o de violaciones #URL#" </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Preprocessing and Feature Extraction</head><p>The preprocessing pipeline to clean and structure the data was performed for both languages (EN and ES) and models as follows:</p><p>‚Ä¢ The text from the original XML document was extracted and all 200 tweets per author were concatenated to one text. ‚Ä¢ The white-space between the tokens has been reduced to a single space.</p><p>‚Ä¢ The placeholders #USER#, #URL#, #HASHTAG#, and RT were removed.</p><p>‚Ä¢ HTML characters were converted to Unicode characters (e.g.: "&gt;", "&lt;", "&amp;" to "&amp;amp", "&amp;gt", "&amp;lt"). ‚Ä¢ Emojis were converted to text format by using Python's emoji library.</p><p>‚Ä¢ The text was lowercased.</p><p>‚Ä¢ Irrelevant signs, e.g. "+, *,/" were deleted.</p><p>‚Ä¢ Alphanumeric tokens were separated (e.g. "Berlin2018" to "Berlin 2018").</p><p>‚Ä¢ Sequences of repeated characters with a length greater than three were normalized to a maximum of two letters (e.g. "LOOOOOOOOL" to "LOOL"). ‚Ä¢ Words with less than three characters were ignored (except for the Bi-LSTM model for the English language). ‚Ä¢ Stopwords were deleted (except for the Bi-LSTM model for the English language). ‚Ä¢ As the last step, we lemmatized the English tweets for the TF-IDF character ùëõ-gram SVM model using WordNetLemmatizer.</p><p>Besides the different preprocessing steps, we also experimented with different vectorization techniques and hyperparameter tuning by employing scikit-learn's grid search function. The hyperparameters were tuned separately for English and Spanish. We experimented with emotional signals and lists of hate words as handcrafted features as well as with automatically learned features. The best results were achieved by using Scikit-learn's term frequency-inverse document frequency (TF-IDF) vectorizer and Sentence-BERT (SBERT), a BERT model modification that uses siamese and triplet network structures to generate semantically meaningful sentence embeddings <ref type="bibr" coords="5,188.05,380.75,11.50,10.91" target="#b7">[8]</ref>. For the English language, we used the sentence transformer model stsb-distilbert-base 7 and for Spanish distiluse-base-multilingual-cased-v1, a multilingual knowledge distilled version of multilingual Universal Sentence Encoder <ref type="bibr" coords="5,465.87,407.84,16.08,10.91" target="#b12">[13]</ref>. The models were trained with a maximum of 200 sentences per author, based on the 200 tweets per author and file.</p><p>For the SVM model, we employed TF-IDF weighted character ùëõ-grams. In English, the best results were achieved using a maximum of 1,250 features (min_df=5) and character ùëõ-grams with range <ref type="bibr" coords="5,140.68,475.59,19.34,10.91">[3;7]</ref>. For Spanish, we used top 2,350 features (min_df=5) and character ùëõ-grams with range [2;7].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Methodology</head><p>We defined this year's PAN author profiling task "Hate Speech Spreaders on Twitter" as a binary classification problem. For each language (EN and ES) we trained two different models. We tested different features and vectorization techniques with a Support Vector Machine (SVM). Additionally, we experimented with bidirectional LSTM (Bi-LSTM) models as recurrent neural networks (RNN) have shown that they can preserve sequence information over time and thereby integrate contextual information in classification tasks.</p><p>For the final SVM model, we trained a linear kernel and set the penalty parameter C=10 for the English data. For the Spanish corpus, we trained the SVM with the radial basis function kernel (RBF) and C=5. The performance was ranked by accuracy. Table <ref type="table" coords="6,420.36,368.46,5.17,10.91" target="#tab_3">4</ref> shows the scores for our final system performed on the official PAN 2021 test set on the TIRA platform <ref type="bibr" coords="6,487.15,382.01,16.41,10.91" target="#b11">[12]</ref>. Accuracy scores are calculated individually for each language by discriminating between two classes. Each model was trained on 70% of the training data provided by the organizers. On the remaining 30% split hyperparameters were tuned. The highest accuracy on the test set using SVM with TF-IDF weighted character ùëõ-grams was 64% for the English dataset and 75% for the Spanish dataset. The accuracy dropped to 59% for the English dataset using Bi-LSTM in combination with SBERT, while it increased by 4% achieving 79% accuracy on the Spanish dataset. Therefore, we submitted the SVM model as our final hate speech detection system as it achieved an overall average accuracy of 69.5% performing slightly better than the Bi-LSTM model which achieved an average accuracy of 69% for both languages. The final accuracy scores of both systems are listed in Table <ref type="table" coords="6,242.04,517.50,3.69,10.91" target="#tab_3">4</ref>. To make our Bi-LSTM model reproducible, we have listed all hyperparameters used to train the Bi-LSTM model in Table <ref type="table" coords="6,368.52,531.05,3.74,10.91" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and Conclusion</head><p>In this paper, we described our participation in the PAN 2021 author profiling task. The goal was to develop a system that can detect Twitter users who spread hate speech on a regular basis. First, we observed the distribution of specific tokens in the tweets like the usage of emojis or user mentions to see whether we could use these for the feature engineering process. Unfortunately, we could not spot any significant differences between the two classes. Furthermore, we experimented with emotional signals and dictionaries listing hate words as handcrafted features in addition to automatically learned features. In relation to this, we could not detect any difference in emotions between the two classes and have shown that insults and profanities are not a discriminative features of hate speech spreaders and other users. Our final submitted system uses an SVM with TF-IDF weighted character ùëõ-grams. This model performed best for the English language. To detect hate speech spreaders in Spanish tweets, a bidirectional LSTM (Bi-LSTM) trained with Sentence-BERT achieved better classification results. The SVM model achieved an average accuracy of 69.5% for both languages which is slightly better than the Bi-LSTM model (69%).</p><p>The experiments show that it is challenging to detect hate speech spreaders on Twitter. It is challenging in different ways. First, we have shown that insults and profanities are not only used by hate speech spreaders, but also by users who do not offend other individuals or groups. Additionally, Twitter posts contain plenty of poorly written text (spelling mistakes, abbreviations, etc.) and paralinguistic signals such as emoticons, @-mentions, and hashtags. In the future, we want to make the classification results interpretable to analyse how hate words and the context in which they are expressed contribute to the classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,88.99,90.49,411.76,81.83"><head>Table 1</head><label>1</label><figDesc>English (EN)  and Spanish (ES) excerpts from the PAN 2021 "Hate Speech Spreaders on Twitter" data.</figDesc><table coords="4,121.58,122.10,318.79,50.21"><row><cell>Class 0 Tweets (EN &amp; ES)</cell><cell>Class 1 Tweets (EN &amp; ES)</cell></row><row><cell>"#USER# #USER# Trump, that mother-</cell><cell></cell></row><row><cell>fucker is guilty of cowardice while being</cell><cell></cell></row><row><cell>Commander-in-Chief #HASHTAG#. "</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,371.94,375.00,158.50"><head>Table 2</head><label>2</label><figDesc>Feature distribution of the PAN 2021 "Hate Speech Spreaders" dataset</figDesc><table coords="4,103.65,400.03,360.35,130.41"><row><cell></cell><cell></cell><cell>English</cell><cell></cell><cell>Spanish</cell></row><row><cell>Features</cell><cell>Class 0</cell><cell>Class 1</cell><cell>Class 0</cell><cell>Class 1</cell></row><row><cell>Unique Tokens</cell><cell>20,280</cell><cell>19,298</cell><cell>28,806</cell><cell>28,761</cell></row><row><cell>Emojis Total</cell><cell>8,465</cell><cell>7,201</cell><cell>7,942</cell><cell>7,949</cell></row><row><cell>Emojis Unique</cell><cell>531</cell><cell>540</cell><cell>546</cell><cell>449</cell></row><row><cell>Uppercased Tokens Total</cell><cell>44,316</cell><cell>42,135</cell><cell>34,172</cell><cell>41,950</cell></row><row><cell>Uppercased Phrases Total</cell><cell>1,026</cell><cell>1,243</cell><cell>1,792</cell><cell>1,871</cell></row><row><cell>#URL# Token</cell><cell>8,556</cell><cell>6,759</cell><cell>5,865</cell><cell>6,897</cell></row><row><cell>#HASHTAG# Token</cell><cell>3,644</cell><cell>3,290</cell><cell>1,864</cell><cell>1,658</cell></row><row><cell>#USER# Token</cell><cell>17,250</cell><cell>17,585</cell><cell>16,014</cell><cell>22,088</cell></row><row><cell>Retweets (RT)</cell><cell>7,731</cell><cell>6,159</cell><cell>6,824</cell><cell>7,084</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,90.49,374.44,148.14"><head>Table 3</head><label>3</label><figDesc>Hyperparameters for the Bi-LSTM model</figDesc><table coords="6,131.85,118.58,331.58,120.05"><row><cell>Bi-LSTM</cell><cell>English</cell><cell>Spanish</cell></row><row><cell>Bi-LSTM layer memory units</cell><cell>32</cell><cell>7</cell></row><row><cell>Dropout</cell><cell>0.2</cell><cell>0</cell></row><row><cell>First dense layer memory units</cell><cell>32</cell><cell>7</cell></row><row><cell>Activation function</cell><cell>ReLU</cell><cell>ReLU</cell></row><row><cell>Second dense layer memory units</cell><cell>24</cell><cell>5</cell></row><row><cell>Activation function</cell><cell>ReLU</cell><cell>ReLU</cell></row><row><cell>Activation function in output layer</cell><cell>Sigmoid</cell><cell>Sigmoid</cell></row><row><cell>Loss Function</cell><cell cols="2">Binary crossentropy Binary crossentropy</cell></row><row><cell>Optimizer</cell><cell>Adam</cell><cell>Adam</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.98,258.53,407.72,85.58"><head>Table 4</head><label>4</label><figDesc>Accuracy (Acc.) scores of the final systems on the official PAN 2021 test dataset on Tira</figDesc><table coords="6,103.69,286.62,78.24,8.87"><row><cell>Model</cell><cell>Features</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,108.93,649.10,412.78,8.97"><p>https://www.theguardian.com/technology/2019/sep/17/revealed-catastrophic-effects-working-facebook-moderator</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,108.93,660.06,397.64,8.97;2,89.29,671.02,78.58,8.97"><p>PAN at CLEF 2021 "Profiling Hate Speech Spreaders on Twitter": https://pan.webis.de/clef21/pan21-web/ author-profiling.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,108.93,649.10,187.03,8.97"><p>https://zenodo.org/record/4603578#.YKZKqKgzZaQ</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,108.93,660.06,397.05,8.97;3,89.29,671.02,43.75,8.97"><p>The selected tweets are used for demonstration and research purposes only and do not reflect the opinion of the authors.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="5,108.93,671.02,240.36,8.97"><p>https://huggingface.co/sentence-transformers/stsb-distilbert-base</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">German Federal Ministry of Education and Research</rs> and the <rs type="funder">Hessen State Ministry for Higher Education, Research and the Arts</rs> within their joint support of the <rs type="funder">National Research Center for Applied Cybersecurity ATHENE</rs> and under grant agreement "<rs type="funder">Lernlabor Cybersicherheit" (LLCS)</rs> for cyber security research and training.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,434.55,371.14,10.91;7,112.66,448.10,393.68,10.91;7,112.66,461.65,255.83,10.91;7,112.66,475.20,149.51,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,246.15,434.55,233.09,10.91">Automatic hate speech detection: A literature review</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohiyaddeen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Siddiqui</surname></persName>
		</author>
		<idno type="DOI">10.31033/ijemr.11.2.17</idno>
		<ptr target="https://www.ijemr.net/ojs/index.php/ojs/article/view/766.doi:10.31033/ijemr.11.2.17" />
	</analytic>
	<monogr>
		<title level="j" coord="7,112.66,448.10,285.07,10.91">International Journal of Engineering and Management Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="116" to="121" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,488.75,393.03,10.91;7,112.66,502.30,364.78,10.91;7,112.66,515.85,392.42,10.91;7,112.41,529.40,38.81,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,215.87,488.75,289.82,10.91;7,112.66,502.30,105.42,10.91">Using knn and svm based one-class classifier for detecting online radicalization on twitter</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sureka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,427.03,502.30,50.41,10.91;7,112.66,515.85,159.79,10.91">Distributed Computing and Internet Technology</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Natarajan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Barua</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Patra</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="431" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,542.95,384.95,10.91;7,112.66,556.50,298.17,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,249.24,542.95,226.62,10.91">Challenges of hate speech detection in social media</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kov√°cs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Saini</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42979-021-00457-3</idno>
	</analytic>
	<monogr>
		<title level="j" coord="7,484.69,542.95,12.92,10.91;7,112.66,556.50,80.98,10.91">SN Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,570.05,357.09,10.91;7,112.66,583.60,364.85,10.91;7,112.66,597.15,381.99,10.91;7,112.66,610.69,393.33,10.91;7,112.66,624.24,234.27,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,221.83,597.15,272.83,10.91;7,112.66,610.69,239.38,10.91">Overview of pan 2021: Authorship verification, profiling hate speech spreaders on twitter, and style change detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,374.58,610.69,131.41,10.91;7,112.66,624.24,161.78,10.91">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,637.79,393.33,10.91;7,112.66,651.34,393.59,10.91;7,112.66,664.89,292.62,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,356.27,637.79,149.72,10.91;7,112.66,651.34,102.61,10.91">Profiling hate speech spreaders on twitter task at pan 2021</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,482.10,651.34,24.15,10.91;7,112.66,664.89,112.59,10.91">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="7,233.24,664.89,103.05,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J M M F P</forename><surname>Guglielmo Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,86.97,391.36,10.91;8,112.66,100.52,168.81,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,229.84,86.97,130.46,10.91">Author profiling tracks at fire</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">Rangel</forename><surname>Pardo</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42979-020-0073-1</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,367.68,86.97,96.62,10.91">SN Computer Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,384.36,10.91;8,112.41,127.61,248.28,10.91;8,112.66,143.61,281.33,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,231.13,114.06,86.35,10.91">Profile of a terrorist</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1080/10576107708435394</idno>
		<ptr target="https://doi.org/10.1080/10576107708435394" />
	</analytic>
	<monogr>
		<title level="j" coord="8,325.31,114.06,134.39,10.91">Studies in conflict &amp; terrorism</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="34" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,154.71,348.39,10.91;8,112.66,168.26,393.32,10.91;8,112.66,181.81,382.19,10.91;8,112.66,195.36,380.38,10.91;8,112.66,208.91,353.78,10.91;8,112.66,222.46,138.14,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,224.97,154.71,236.08,10.91;8,112.66,168.26,66.67,10.91">Sentence-BERT: Sentence embeddings using Siamese BERT-networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1410.doi:10.18653/v1/D19-1410" />
	</analytic>
	<monogr>
		<title level="m" coord="8,202.78,168.26,303.20,10.91;8,112.66,181.81,382.19,10.91;8,112.66,195.36,319.86,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,236.01,393.33,10.91;8,112.66,249.56,260.74,10.91;8,112.66,263.11,149.51,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,355.96,236.01,150.03,10.91;8,112.66,249.56,28.12,10.91">Profiling hate speech spreaders on twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4603578</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4603578.doi:10.5281/zenodo.4603578" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,276.66,351.09,10.91;8,112.66,290.20,355.46,10.91;8,112.28,303.75,289.10,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,293.50,276.66,170.25,10.91;8,112.66,290.20,91.37,10.91">Hate speech detection in twitter using transformer methods</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mutanga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naicker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">O</forename><surname>Olugbara</surname></persName>
		</author>
		<idno type="DOI">10.14569/IJACSA.2020.0110972</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,213.02,290.20,255.10,10.91;8,112.28,303.75,56.47,10.91">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,317.30,390.81,10.91;8,112.66,330.85,393.32,10.91;8,112.14,344.40,177.10,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,318.85,317.30,184.61,10.91;8,112.66,330.85,131.24,10.91">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,267.09,330.85,238.90,10.91;8,112.14,344.40,95.68,10.91">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,357.95,391.92,10.91;8,112.66,371.50,378.61,10.91;8,112.66,385.05,326.25,10.91;8,112.66,398.60,187.11,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,323.53,357.95,161.38,10.91">Tira integrated research architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,226.32,371.50,264.95,10.91;8,112.66,385.05,123.40,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,412.15,381.28,10.91;8,112.66,425.70,249.72,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno>ArXiv abs/1910.01108</idno>
		<title level="m" coord="8,295.83,412.15,198.11,10.91;8,112.66,425.70,113.82,10.91">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
