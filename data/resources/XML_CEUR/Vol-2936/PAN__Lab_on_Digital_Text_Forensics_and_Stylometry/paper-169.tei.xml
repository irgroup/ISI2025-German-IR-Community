<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,72.02,75.44,401.16,17.04;1,72.02,96.20,220.46,17.04;1,72.02,116.20,148.90,9.94">Profiling Hate Speech Spreaders on Twitter using stylistic features and word embeddings Notebook for PAN at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,72.02,141.82,113.54,10.80"><forename type="first">Lucía</forename><surname>Gómez-Zaragozá</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Instituto de Investigación e Innovación en Bioingeniería</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
								<address>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.89,141.82,95.96,10.80"><forename type="first">Sara</forename><forename type="middle">Hinojosa</forename><surname>Pinto</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Multiscan Technologies S.L</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
								<address>
									<settlement>Valencia</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,72.02,75.44,401.16,17.04;1,72.02,96.20,220.46,17.04;1,72.02,116.20,148.90,9.94">Profiling Hate Speech Spreaders on Twitter using stylistic features and word embeddings Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2908CA172708DE4AF34A148B29B82698</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hate speech</term>
					<term>author profiling</term>
					<term>natural language processing</term>
					<term>NLP</term>
					<term>embeddings</term>
					<term>LSTM</term>
					<term>Twitter</term>
					<term>machine learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the different solutions proposed for the Profiling Hate Speech Spreaders on Twitter task at PAN 2021, which consists of classifying each author as hater or no hater from a set of tweets, for Spanish and English languages. The given approaches are different for each language. For Spanish, an ensemble of LSTM and a Logistic Regression model trained with stylistic features is used. For English, an ensemble of SVC and Random Forest model, also with stylistic features, is proposed. Our solutions achieved an accuracy of 83% in Spanish and 58% in English, resulting in an overall accuracy of 70.5% in the task ranking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="594.96" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automatic hate speech detection on social media has become a topic of growing interest in the artificial intelligence community and particularly, in the area of Natural Language Processing <ref type="bibr" coords="1,507.69,420.45,11.60,9.94" target="#b0">[1]</ref>. Although different definitions can be found in the literature, hate speech is commonly described as language that attacks or disparages a person or a group based on specific characteristics that include, among others, physical appearance, nationality, religion or sexual orientation <ref type="bibr" coords="1,431.70,458.37,11.69,9.94" target="#b1">[2]</ref>. Given the huge amount of user-generated content and the rapid dissemination of information these days, being able to identify not isolated hate speech comments but hate speech spreaders is a key first step in trying to prevent hate speech from spreading in online communications.</p><p>This paper describes the proposed models for the PAN 2021 Profiling Hate Speech Spreaders on Twitter <ref type="bibr" coords="1,107.06,521.61,11.70,9.94" target="#b2">[3]</ref>, which is one of the three proposed tasks at CLEF 2021 <ref type="bibr" coords="1,367.03,521.61,12.92,9.94" target="#b3">[4]</ref> deployed on TIRA platform <ref type="bibr" coords="1,507.60,521.61,11.70,9.94" target="#b4">[5]</ref>. The dataset provided in the shared task consisted of a balanced set of users that have shared some hate speech tweets, labeled as haters and non-haters otherwise. It was provided in two languages, namely Spanish and English. For each of them, the dataset it included 200 different users and 200 tweets per user. As recommended by the shared task, we presented a different solution for each language. For the Spanish dataset, an ensemble of LSTM and a logistic regression model trained with stylistic features is proposed, which achieved 83% of accuracy in the provided test set. For the English dataset, an ensemble of Support Vector Classification and Random Forest both based on stylistic features is presented, which achieved 58% of accuracy in the provided test set.</p><p>In Section 2 we present some related work on profiling hate speech spreaders. In Section 3 we describe the two approaches proposed, including the description of the features used and the implemented machine learning models. In Section 4 we present the experimental results achieved for both languages independently. Finally, in Section 5, we present the conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Generic text mining features are commonly used for hate speech detection <ref type="bibr" coords="2,410.66,145.12,11.68,9.94" target="#b1">[2]</ref>. These include several types of characteristics, such as those obtained from dictionaries, bag-of-words (BOW), N-grams, TF-IDF, Part-of-speech (POS) or word embeddings. There are also specific features for hate speech detection, but in some cases, they require additional user information (like gender, age or geographic localization), or they focus on specific stereotypes. Regarding the algorithms used for hate speech detection, which is typically considered as a binary classification (hate vs not-hate), the most common are Support Vector Machines, followed by Random Forest, Decision Trees and Logistic Regression <ref type="bibr" coords="2,507.64,220.96,11.61,9.94" target="#b1">[2]</ref>. More recent approaches use deep learning techniques, such as attention-based neural networks <ref type="bibr" coords="2,497.78,233.56,12.89,9.94" target="#b5">[6]</ref> or an ensemble of neural networks <ref type="bibr" coords="2,214.63,246.31,11.86,9.94" target="#b6">[7]</ref>, obtaining good performance results.</p><p>In addition, the aim of this shared task is not only to detect hateful content, but profile hate speech spreaders. In this sense, common features used in the field of author profiling are stylistic features (such as frequency of punctuation marks, capital letters, word frequency), content features (such as BOW, TF-IDF or N-grams), POS tags, readability features or emotional features (emotion words and emoticons) <ref type="bibr" coords="2,125.38,309.55,11.95,9.94" target="#b7">[8,</ref><ref type="bibr" coords="2,137.33,309.55,7.97,9.94" target="#b8">9]</ref>. Other message features such as retweets, hashtags, URLs and mentions are also considered in this area and, recently, the word and character embeddings are also applied. Regarding the algorithms used for author profiling, the traditional machine learning models are widely used, but in the last few years, deep learning approaches such as Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN) have gained attention <ref type="bibr" coords="2,346.02,360.07,17.00,9.94" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>The proposed models aim to discriminate hate speech spreaders from those who have never shared hate speech content on Twitter. They were built as an ensemble of classifiers, using two different approaches. On the one hand, stylistic features were extracted for each tweet and statistics per author were obtained from them in order to apply classic machine learning algorithms. On the other hand, a neural network with word embeddings was trained with the groups of tweets. Since no development set was provided in the shared task, it was decided to randomly split the training set into two partitions: 90% of the users for the development set and 10% for the test set, each containing 180 and 20 users respectively. These data partitions were used to evaluate the models using the official metric for this task, the accuracy, and to compare their performance on the same unseen data. The best models were then applied to the test data provided in the shared task, whose results were used to rank the performance of our system. The following sub-sections describe the two different approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Word embeddings and LSTM</head><p>In this approach, an aggregation of everyone's set of tweets was first performed in order to obtain one text per subject. A preprocessing step was also applied in order to remove accents, capital letters, double spaces and stop-words. Then, the development set was divided into two partitions: 60% of the users for the training set and 40% of the users for the validation set, with 108 and 72 users respectively.</p><p>First, a tokenizer with a selected number of maximum words was adjusted to the training set, so that only the top words remained in the vocabulary, and the less used words were eliminated. The next step was to convert texts into sequences, meaning that each word of the tweet was translated into the index of that word in the vocabulary. The last step was to pad the sequences, so that they all had the same length regardless of the number of words they originally had. Specifically, a maximum sequence length of 1000 words was set, with the sequences being the collection of tweets from one subject, so that none of them would be trimmed. The training of the word embeddings with the configured dimension is performed simultaneously with the rest of the neural network parameters.</p><p>Once the above steps have been completed, the training of the neural network can be performed, setting the maximum number of words to be considered in the tokenizer and the word embedding dimensions. The neural network architecture is based on an LSTM, as shown in Figure <ref type="figure" coords="3,465.37,100.00,4.14,9.94" target="#fig_0">1</ref>, and it was trained using the categorial cross-entropy as the loss function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Stylistic features and classical machine learning algorithms</head><p>To obtain the model that discriminates between a hater and a no hater, a set of stylistic features was calculated for each tweet independently. These characteristics have been divided into three groups: pattern-related, word-related and emoji-related features. The first group include, among others, the number of occurrences of certain patterns in the texts (such as hashtags, URLs or retweets) and the number of certain characters (such as symbols or letters). Word-related features include counts of particular words, such as nouns, verbs or adjectives. Both feature sets were calculated using regular expressions with the RegEx Python module <ref type="bibr" coords="3,275.45,630.00,18.34,9.94" target="#b10">[11]</ref> and the English model "en_core_web_sm" for de English dataset and "es_core_news_sm" for the Spanish dataset from spaCy Python library <ref type="bibr" coords="3,487.90,642.61,18.69,10.04" target="#b11">[12]</ref> for lemmatization and identification of word categories. Regarding the emojis, they were analyzed and grouped following different categories from the advertools Python library <ref type="bibr" coords="3,404.86,668.04,16.90,9.94" target="#b12">[13]</ref>. The rate between the unique emojis and the total emojis in the tweet was also included. The total set of 37 characteristics, referred to here as handcrafted features, is shown in Table <ref type="table" coords="3,330.15,693.24,4.14,9.94">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Stylistic features extracted per tweet, divided into three groups: pattern, word and emoji related features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pattern-related features</head><p>• Retweets</p><formula xml:id="formula_0" coords="4,76.10,129.77,364.25,279.24">• Mentioned users • URLs • Hashtags • Laugh expressions • Symbols • Arousal symbols [¿?¡!] • Capital letters • Total letters Word-related features • Stopwords • Adjectives • Nouns • Proper nouns • Verbs • Repeated words • Total words • Letters/words Emojis-related features • Ratio unique / total emojis • Face-affection • Face-concerned • Face-costume • Face-glasses • Face-hand • Face-negative • Face-neutral-skeptical • Face-sleepy • Face-smiling • Face-tongue • Face-unwell • Body-parts • Emotion • Gender • Hand-fingers-closed • Hand-fingers-partial • Hand-single-finger • Hands • Person-gesture</formula><p>Once the stylistic features were calculated for each tweet, four statistics (mean, standard deviation, minimum and maximum) were computed for all the tweets of the same user. As result, a vector of 148 stylistic features was obtained for each author. Features were then standardized by subtracting the mean and dividing by the standard deviation for the development set, and these values were then applied to the test.</p><p>As there were only 200 different users in the dataset, a feature reduction method was applied to reduce the number of characteristics. First, the Pearson's correlation matrix was calculated, and highcorrelated features (p &gt; 0.95) were eliminated. Then, a filter method was implemented to avoid overfitting. It consisted of calculating the area under the ROC Curve for each characteristic and removing those with values close to 0.5, which mean that they were not relevant for the classification task. With this method 50% of the features were eliminated, remaining the features with more information. Finally, sequential backward selection was applied to determine the optimal combination of N features for classification in the range 10 to a threshold (T) of the maximum allowed characteristics, which could be 15, 20 or 30 items, respectively. This selection method iteratively computes a criterion function for a given machine learning classification algorithm using a crossvalidation strategy. In each iteration, one feature is removed at a time to create n-1 subsets of features. For each of them, a machine learning model is trained, and the criterion function for cross-validation is recalculated. Based on these results, the feature associated with the best performing model is removed, since removing it yielded the best result and therefore, is the one that helps the least in the classification. This process, called feature ablation, is repeated until 10 features are left. In this work, we used accuracy as the criterion function and the stratified K fold cross-validation with five folds as cross-validation strategy.</p><p>Regarding the machine learning classification algorithms, the following were chosen, Support Vector Classification (SVC), K-Nearest Neighbors (KNN), Logistic Regression (LR), Random Forest (RF) and Decision Tree (DT). Each of these algorithms was applied sequentially in both sequential backward selection with default hyperparameters and hyperparameter tuning. In the latter step, the same cross-validation strategy was used as in the feature selection method, for the different hyperparameter combinations shown in Table <ref type="table" coords="5,210.07,74.68,4.14,9.94">2</ref>. Finally, the test set was transformed by keeping only the selected features and applying the standardization with the training set statistics. The machine learning model was then applied with the chosen hyperparameters and the predictions were obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Hyperparameter sets for the implemented machine learning models, with the default values used in cross-validation indicated with "default" in brackets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>The following sections summarize the results obtained with the different datasets, in Spanish and English, and detail the final models chosen for each of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Spanish dataset</head><p>As mentioned above, two approaches were evaluated for the dataset. Firstly, the word embedding described in Section 3.1 was trained using different combinations of parameters to obtain the best configuration. Table <ref type="table" coords="5,165.46,526.05,5.52,9.94" target="#tab_1">3</ref> shows the accuracy results obtained in the test set by modifying the maximum number of dictionary words to be tokenized between 1000, 2000, 3000 and 4000, keeping the embedding dimensions constant. Based on the results of Table <ref type="table" coords="5,230.93,696.60,4.14,9.94" target="#tab_1">3</ref>, the maximum number of words was set at 3000. Then, the embedding dimensions were modified between 5, 10 and 15. The results are shown on Table <ref type="table" coords="5,482.89,709.20,4.14,9.94">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Neural network results varying the word embedding dimensions for the Spanish dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max number words</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Embedding dimension</head><p>Test-accuracy 3000 5 0.55 3000 10 0.80 3000 15 0.70</p><p>The experimentation conducted showed that the best performing network configuration consisted of a maximum of 3000 words considered in the tokenizer and a 10-dimensional embedding, achieving 80% accuracy.</p><p>Despite the good results, the methodology described in Section 3.2 was used to obtain a new hater versus non-hater classifier based on stylistic features. The results are shown in Table <ref type="table" coords="6,466.04,220.96,4.08,9.94" target="#tab_2">5</ref>, where the machine learning model and the number of features used by each model (N-features) are indicated. It also includes the following evaluation metrics: the cross-validation accuracy (CV-acc), the test accuracy (Test-acc), the true positive rate and the true negative rate in the test set (Test-TPR and Test-TNR, respectively). Only the models with the feature selection and hyperparameters that provided the best results have been included, rather than all combinations tested. The highest accuracy was 80%, as in word embedding. This score was achieved with the logistic regression, both in the development test and in the test set, using the features listed in Table <ref type="table" coords="6,478.02,461.61,4.14,9.94">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6</head><p>Selected features in the LR model for the Spanish dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pattern-related features</head><p>• Mean mentioned users As a last step, since both approaches achieved high accuracies, an ensemble of the two best models was built. The logistic regression and the word embedding scores were combined using the sum rule with an alpha weight associated with the score of each approach. It is shown in the equation <ref type="bibr" coords="6,478.06,743.18,11.70,9.94" target="#b0">(1)</ref>, where 𝑠𝑐 𝑐 is the combined score, 𝑠𝑐 𝑙𝑟 is the score from the logistic regression, 𝑠𝑐 𝑤𝑒 is the score from the word embedding and alpha is the weight in the range [0,1].</p><formula xml:id="formula_1" coords="7,205.25,112.03,307.22,12.65">𝑠𝑐 𝑐 = 𝛼 • 𝑠𝑐 𝑤𝑒 + (1 -𝛼) • 𝑠𝑐 𝑙𝑟<label>(1)</label></formula><p>To find the best alpha estimate, values between 0 and 1 were tested in increments of 0.05 for the development set. The alpha value that achieved the highest accuracy was 0.85, which reached 86% accuracy on the development set.</p><p>The ensemble of the regression model and word embedding was finally applied to the test set provided in the task, achieving 83% accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">English dataset</head><p>As with the Spanish tweets, word embeddings were first tested to solve the classification task for the English dataset. The neural network was adapted to the dataset by modifying the maximum number words to be considered in the tokenizer between 1000, 2000, 3000 and 4000, keeping the embedding dimensions constant. The results are shown in Table <ref type="table" coords="7,305.22,287.83,4.09,9.94">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 7</head><p>Neural network results varying the maximum number of vocabulary words for the English dataset. Although the results in Table <ref type="table" coords="7,221.21,436.05,5.52,9.94">7</ref> were not as expected, additional experiments were carried out by varying the embedding dimensions for the best of the configuration found. The results are shown in Table <ref type="table" coords="7,99.86,463.29,4.14,9.94">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max number words</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 8</head><p>Neural network results varying the word embedding dimensions for the English dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max number words</head><p>Embedding dimension Test-accuracy 4000 5 0.45 4000 10 0.55 4000 15 0.50</p><p>The variation of the embedding dimensions also did not provide better results. Therefore, it was decided not to continue in this direction and to focus on the second approach based on classical machine learning classifiers.</p><p>Following the pipeline described in Section 3.2, the results showed in Table <ref type="table" coords="7,427.73,652.44,5.52,9.94" target="#tab_5">9</ref> were achieved. The table shows the machine learning model and the number of features used by each model (N-features). It also includes the following evaluation metrics: the cross-validation accuracy (CV-acc), the test accuracy (Test-acc), the true positive rate and the true negative rate in the test set (Test-TPR and Test-TNR, respectively). According to the results, the best models were the SVC and the RF, which obtained 70% and 65% test accuracy, respectively. The characteristics used in each model are listed in Table <ref type="table" coords="8,454.36,221.92,11.04,9.94" target="#tab_6">10</ref> for the SVC and Table <ref type="table" coords="8,118.56,235.60,11.04,9.94" target="#tab_7">11</ref> for the RF. Since the classical machine learning models based on stylistic features obtained better results, it was decided to create an ensemble of the two best models obtained. The final prediction was obtained by combining the SVC and RF scores using the sum rule with an alpha weight associated with the score of each model, as previously performed in the Spanish ensemble. The combination is shown in the equation <ref type="bibr" coords="8,112.82,696.84,11.79,9.94" target="#b1">(2)</ref>, where 𝑠𝑐 𝑐 is the combined score, 𝑠𝑐 𝑠𝑣𝑐 is the score from the SVC, 𝑠𝑐 𝑟𝑓 is the score from the RF and alpha is the weight in the range [0,1].</p><formula xml:id="formula_2" coords="8,203.57,735.41,308.94,12.65">𝑠𝑐 𝑐 = 𝛼 • 𝑠𝑐 𝑟𝑓 + (1 -𝛼) • 𝑠𝑐 𝑠𝑣𝑐<label>(2)</label></formula><p>To find the best alpha estimate, values between 0 and 1 were tested in increments of 0.05 for the development set. The alpha value that achieved the highest accuracy was 0.65, which reached 56% accuracy on the development set.</p><p>The ensemble of the SVC and RF was finally applied to the test set provided in the task, achieving 58% accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future work</head><p>This paper presented the proposed ensemble models for the PAN 2021 Profiling Hate Speech Spreaders on Twitter shared task at CLEF 2021. The problem was addressed in two languages, namely Spanish and English, and two approaches were presented for each of them, whose evaluations in the task ranking are summarized in Table <ref type="table" coords="9,185.13,220.96,9.12,9.94">12</ref>. For the Spanish dataset, an ensemble was created from a neural network with word embeddings and a logistic regression. The first one was created with all the tweets grouped by subject, whereas the second was based on statistic obtained from stylistic features computed for each user's tweet. This approach achieved 83% accuracy on the provided test set. Regarding English dataset, an ensemble of a support vector classifier and a random forest, both based on statistics of stylistic features, achieved 58% accuracy on the provided test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 12</head><p>Accuracy in test data provided in the shared task for the English and Spanish models, and the mean of both used for the task ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>Accuracy (%) English ensemble 58.0 Spanish ensemble 83.0 Average 70.5</p><p>Overall, the results showed that stylistic characteristics are important features to consider when identifying hate speech spreaders, as they helped to improve the results of the word embeddings in Spanish, and they obtained better results than word embedding for the English dataset. However, the task of detecting hate speech spreaders turned out to be very difficult for the English dataset. The best accuracy result was only 70% in our test partition, which accounted for 58% in the test provided in the shared task. Word embeddings were investigated for this language, but they were not included because they showed not accurate results, contrary to Spanish. The difference in accuracy between English and Spanish may indicate that users have different hate-spreading behaviors in different cultures. Future work will include adding more features, such as TF-IDF based n-grams for both words and characters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,72.02,483.69,345.08,9.94;3,262.60,135.24,84.00,345.75"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Neural network architecture based on word embeddings and LSTM.</figDesc><graphic coords="3,262.60,135.24,84.00,345.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,72.02,576.72,435.22,102.22"><head>Table 3</head><label>3</label><figDesc>Neural network results varying the maximum number of vocabulary words for the Spanish dataset.</figDesc><table coords="5,104.18,616.92,374.46,62.02"><row><cell>Max number words</cell><cell>Embedding dimension</cell><cell>Test-accuracy</cell></row><row><cell>1000</cell><cell>10</cell><cell>0.65</cell></row><row><cell>2000</cell><cell>10</cell><cell>0.70</cell></row><row><cell>3000</cell><cell>10</cell><cell>0.80</cell></row><row><cell>4000</cell><cell>10</cell><cell>0.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,72.02,316.39,439.32,114.96"><head>Table 5</head><label>5</label><figDesc>Results of the classical machine learning models for the Spanish dataset.</figDesc><table coords="6,91.70,356.59,419.64,74.76"><row><cell>Model</cell><cell>N-features</cell><cell>CV-accuracy</cell><cell>Test-acc</cell><cell>Test-TPR</cell><cell>Test-TNR</cell></row><row><cell>SVC</cell><cell>15</cell><cell>0.80 ± 0.09</cell><cell>0.70</cell><cell>0.90</cell><cell>0.50</cell></row><row><cell>KNN</cell><cell>12</cell><cell>0.80 ± 0.05</cell><cell>0.70</cell><cell>0.80</cell><cell>0.60</cell></row><row><cell>LR</cell><cell>18</cell><cell>0.80 ± 0.07</cell><cell>0.80</cell><cell>0.90</cell><cell>0.70</cell></row><row><cell>RF</cell><cell>14</cell><cell>0.79 ± 0.06</cell><cell>0.75</cell><cell>0.90</cell><cell>0.60</cell></row><row><cell>DT</cell><cell>15</cell><cell>0.71 ± 0.05</cell><cell>0.70</cell><cell>0.70</cell><cell>0.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,72.02,74.68,439.32,114.94"><head>Table 9</head><label>9</label><figDesc>Results of the classical machine learning models for the English dataset.</figDesc><table coords="8,91.70,114.88,419.64,74.74"><row><cell>Model</cell><cell>N-features</cell><cell>CV-accuracy</cell><cell>Test-acc</cell><cell>Test-TPR</cell><cell>Test-TNR</cell></row><row><cell>SVC</cell><cell>13</cell><cell>0.72 ± 0.06</cell><cell>0.70</cell><cell>0.50</cell><cell>0.90</cell></row><row><cell>KNN</cell><cell>19</cell><cell>0.69 ± 0.08</cell><cell>0.55</cell><cell>0.80</cell><cell>0.30</cell></row><row><cell>LR</cell><cell>26</cell><cell>0.71 ± 0.05</cell><cell>0.55</cell><cell>0.30</cell><cell>0.80</cell></row><row><cell>RF</cell><cell>12</cell><cell>0.68 ± 0.08</cell><cell>0.65</cell><cell>0.60</cell><cell>0.70</cell></row><row><cell>DT</cell><cell>29</cell><cell>0.67 ± 0.04</cell><cell>0.65</cell><cell>0.60</cell><cell>0.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,72.02,262.75,372.78,174.12"><head>Table 10</head><label>10</label><figDesc>Selected features in the SVC model for the English dataset.</figDesc><table coords="8,76.10,304.03,368.70,132.84"><row><cell>Pattern-related features</cell><cell></cell></row><row><cell>• Mean retweet</cell><cell></cell></row><row><cell>Word-related features</cell><cell></cell></row><row><cell>• Std repeated words</cell><cell>• Max total words</cell></row><row><cell>• Std total words</cell><cell>• Std letters / words ratio</cell></row><row><cell>Emojis-related features</cell><cell></cell></row><row><cell>• Std unique emojis</cell><cell>• Max emoji face-hand</cell></row><row><cell>• Mean emoji face-affection</cell><cell>• Mean emoji face-sleepy</cell></row><row><cell>• Max emoji face-affection</cell><cell>• Std emoji face-unwell</cell></row><row><cell>• Mean emoji face-hand</cell><cell>• Std emoji-hands</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,72.02,455.49,364.21,173.05"><head>Table 11</head><label>11</label><figDesc>Selected features in the RF model for the English dataset.</figDesc><table coords="8,76.10,495.69,360.13,132.85"><row><cell>Pattern-related features</cell><cell></cell></row><row><cell>• Mean retweets</cell><cell>• Mean URLs</cell></row><row><cell>• Std mentioned users</cell><cell></cell></row><row><cell>Word-related features</cell><cell></cell></row><row><cell>• Std stopwords</cell><cell>• Max proper nouns</cell></row><row><cell>• Max nouns</cell><cell>• Max verbs</cell></row><row><cell>Emojis-related features</cell><cell></cell></row><row><cell>• Mean emoji face-costume</cell><cell>• Std emoji face-unwell</cell></row><row><cell>• Mean emoji face-neutral-skeptical</cell><cell>• Std emoji-hands</cell></row><row><cell>• Std emoji face-sleepy</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,108.02,597.36,415.14,9.94;9,86.18,609.96,412.28,9.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,356.49,597.36,166.67,9.94;9,86.18,609.96,184.74,9.94">Resources and benchmark corpora for hate speech detection: a systematic review</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,278.37,609.96,160.23,9.94">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.02,622.68,415.15,9.94;9,86.18,635.28,147.75,9.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,203.81,622.68,235.79,9.94">A survey on automatic detection of hate speech in text</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,446.14,622.68,77.03,9.94;9,86.18,635.28,74.35,9.94">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.02,648.00,415.09,9.94;9,86.18,660.60,436.97,9.94;9,86.18,673.32,97.31,9.94" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,423.22,648.00,99.89,9.94;9,86.18,660.60,155.25,9.94">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,288.01,660.60,147.26,9.94">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="9,444.06,660.60,79.10,9.94;9,86.18,673.32,23.24,9.94">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,108.02,685.92,414.92,9.94;9,86.18,698.52,436.99,9.94;9,86.18,711.24,436.97,9.94;9,86.18,723.84,436.93,9.94;9,86.18,736.58,132.67,9.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,143.27,711.24,379.88,9.94;9,86.18,723.84,163.02,9.94">Overview of PAN 2021: Authorship Verification, Profiling Hate Speech Spreaders on Twitter, and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,272.80,723.84,250.31,9.94;9,86.18,736.58,57.03,9.94">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,74.68,415.14,9.94;10,86.18,87.28,436.96,9.94;10,86.18,100.00,437.02,9.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,320.22,74.68,171.03,9.94">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,194.71,87.28,328.44,9.94;10,86.18,100.00,68.31,9.94">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,112.60,415.00,9.94;10,86.18,125.32,436.78,9.94;10,86.18,137.92,289.12,9.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,414.41,112.60,108.61,9.94;10,86.18,125.32,369.50,9.94">Not all swear words are used equal: Attention over word n-grams for abusive language identification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Jarquín-Vásquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,484.58,125.32,38.39,9.94;10,86.18,137.92,153.05,9.94">Mexican Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="282" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,150.52,415.17,9.94;10,86.18,163.24,436.85,9.94;10,86.18,175.84,140.85,9.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,289.93,150.52,233.27,9.94;10,86.18,163.24,43.83,9.94">Improving hate speech detection with deep learning ensembles</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,153.48,163.24,369.55,9.94;10,86.18,175.84,108.75,9.94">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,188.56,414.73,9.94;10,86.18,201.16,436.94,9.94;10,86.18,213.76,178.82,9.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,375.76,188.56,146.99,9.94;10,86.18,201.16,77.31,9.94">Overview of the author profiling task at pan 2013</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Inches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,190.60,201.16,332.52,9.94;10,86.18,213.76,45.92,9.94">CLEF Conference on Multilingual and Multimodal Information Access Evaluation</title>
		<imprint>
			<publisher>CELCT</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="352" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,226.48,414.74,9.94;10,86.18,239.11,436.97,9.94;10,86.18,251.83,252.76,9.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,101.90,239.11,229.25,9.94">Overview of the 2nd author profiling task at pan 2014</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trenkmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,352.04,239.11,131.19,9.94">CEUR Workshop Proceedings</title>
		<title level="s" coord="10,113.78,251.83,132.45,9.94">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1180</biblScope>
			<biblScope unit="page" from="898" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,264.43,414.94,9.94;10,86.18,277.15,436.92,9.94;10,86.18,289.75,52.31,9.94" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,292.80,264.43,230.16,9.94;10,86.18,277.15,236.14,9.94">Overview of the 5th author profiling task at pan2017: Gender and language variety identification in twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,329.96,277.15,160.00,9.94">Working notes papers of the CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1613" to="0073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,302.35,414.83,9.94;10,86.18,315.07,45.94,9.94" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="10,187.99,302.35,184.67,9.94">The python library reference, release 3.8</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Van Rossum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Python Software Foundation</publisher>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,327.67,414.83,9.94;10,86.18,340.39,376.51,9.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,225.30,327.67,297.55,9.94;10,86.18,340.39,240.57,9.94">spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,334.03,340.39,44.34,9.94">To appear</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="411" to="420" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,108.02,352.99,414.99,9.94;10,86.18,365.59,302.37,9.94" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Elias</forename><surname>Dabbas</surname></persName>
		</author>
		<ptr target="https://advertools.readthedocs.io/en/master/readme.html" />
		<title level="m" coord="10,176.03,352.99,342.26,9.94">advertools: productivity and analysis tools to scale your online marketing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
