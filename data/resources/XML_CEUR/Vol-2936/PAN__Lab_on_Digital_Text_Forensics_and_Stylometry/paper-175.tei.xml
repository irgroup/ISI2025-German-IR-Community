<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,338.25,15.42">Profiling Hate Speech Spreaders on Twitter</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,113.06,64.20,11.96"><forename type="first">Rakshita</forename><surname>Jain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">National Institute Of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,166.13,113.06,71.65,11.96"><forename type="first">Devanshi</forename><surname>Goel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">National Institute Of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.43,113.06,70.22,11.96"><forename type="first">Prashant</forename><surname>Sahu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">National Institute Of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,333.30,113.06,78.07,11.96"><forename type="first">Abhinav</forename><surname>Kumar</surname></persName>
							<email>abhinavkumar@soa.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Siksha &apos;O&apos; Anusandhan Deemed to be University</orgName>
								<address>
									<settlement>Bhubaneswar</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.10,127.00,95.92,11.96"><forename type="first">Jyoti</forename><forename type="middle">Prakash</forename><surname>Singh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">National Institute Of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,338.25,15.42">Profiling Hate Speech Spreaders on Twitter</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">74E06EDD5492060730292B66E1B31ECD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hate Speech</term>
					<term>Online social media</term>
					<term>Natural Language Processing</term>
					<term>Machine Learning</term>
					<term>deep-learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As today is the era of social media with nearly around 192 million daily active users on Twitter alone. With the increase in the number of people online, individuals inclined towards racism, misogyny, etc have led to the spread of hate speech online. It's high time that proper steps must be taken to curb this issue with one major step being to identify people who are spreading hate speech on Twitter. We have tried to perform the above task using natural language processing techniques for two different languages English and Spanish on the two datasets provided by PAN @CLEF 2021. Four machine learning classifiers (i) multinomial naive Bayes, (ii) K-Nearest Neighbors (KNN) classifier, (iii) logistic regression and (iv) linear SVM, along with three deep learning models (i) Long Short Term Memory (LSTM), Bidirectional Long Short term Memory (bi-LSTM) and Bidirectional Encoder Representations for Transformers (BERT) model were implemented for the identification of hate speech spreader. The experiments with all the mentioned models on the training dataset provided by PAN (by splitting it into training and testing datasets) revealed that the multinomial naive Bayes is the best model with an accuracy of 74% for the English dataset and 82% for the Spanish dataset. The multinomial naive Bayes model yielded an accuracy of 66% for the English dataset and 80% for the Spanish dataset with the unknown private dataset used by the organizers for the final evaluation of the models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Due to the excessive use of social media platforms by people belonging to different cultures and backgrounds, toxic online content has become a major issue in today's time. The emergence of social media platforms has given rise to an unparalleled level of hate speech in public conversations. The number of tweets containing hate speech and targeting one or another user is on the increase every day. Unfortunately, any user engaged on these platforms will have a risk of being targeted or harassed via abusing language, expressing hate towards race, colour, religion, descent, gender, nation, etc.</p><p>Hate Speech is no less than a felony that has been continuously and abruptly growing in recent years, and the rapidly growing availability of online platforms. The rise of social media has led users to publish and share any content, tell their views, show their liking or hatred towards people, community, race, non-living objects, etc. in an ever-growing fast way. The increased willingness of people to demonstrate their opinions publicly has contributed to the multiplication of hate speech also. The ease of getting access to these platforms and publishing content with minimal efforts have led to an increase in hate speech about every small thing that people criticize or do not like, influencing other people's minds and causing several negative consequences in society. On the internet and social network platforms, people are more likely to take on inappropriate or violent behaviour due to the anonymity provided by these environments. Since this type of prejudice can cause extreme harm to society, government, and social network platforms such as Twitter and Facebook can be benefited from hate speech detection and prevention tools.</p><p>Understanding whether a tweet is hate speech or not and hence finding out whether the user is a hate speech spreader or not, is a very tough task for the users, especially those who are not experts. Additionally, hate speech can also be present in the form of sarcasm <ref type="bibr" coords="2,442.29,263.11,12.99,10.91" target="#b0">[1]</ref> or indirect taunt, making it confusing for users to understand the intent behind the tweet.</p><p>Our work is based on an assumption that a user can be classified as a hate speech spreader if while analyzing a certain number of tweets of that user, we find that the majority of the tweets can be classified as hate speech content. For that, we have grouped all the tweets of the same id. Our ultimate target is profiling those users who spread hate speech based on the number of tweets containing any hateful content that they spread, for two languages -English and Spanish. This allows the social media platforms to identify hate speech spreaders on Twitter as an initial step towards preventing hate speech from spreading among social media users and preventing it from influencing the lives and work of target people. We focus on classifying users as hate speech spreaders or not hate speech spreaders (binary classification). Examples of each of these categories -taken from the user's tweet dataset (PAN21-Profiling-Hate-Speech-Spreaders-in-Twitter) <ref type="bibr" coords="2,123.93,425.70,13.31,10.91" target="#b1">[2]</ref> can be seen in Table <ref type="table" coords="2,232.51,425.70,3.74,10.91" target="#tab_0">1</ref>. The present work is investigating whether a user is a hate speech spreader or not using various conventional machine learning classifiers and deep learning models. In the case of conventional machine learning models, we used tf-idf and count vector features by varying the word n-gram range. In the case of deep learning models, word embedding, one-hot encoding vector, and BERT embedding vectors are used as input to the models. The performance of each of the models was finally compared to get the best performing model for the hate speech spreaders.</p><p>The rest of the sections are organized as follows: section 2 lists some of the state-of-the-art works for hate speech detection. Section 3 discusses the proposed methodology in detail, section 4 list the finding of the proposed model and finally section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Several works <ref type="bibr" coords="3,152.30,159.14,11.23,10.91" target="#b2">[3,</ref><ref type="bibr" coords="3,165.80,159.14,7.42,10.91" target="#b3">4,</ref><ref type="bibr" coords="3,175.49,159.14,7.43,10.91" target="#b4">5,</ref><ref type="bibr" coords="3,185.18,159.14,7.43,10.91" target="#b5">6,</ref><ref type="bibr" coords="3,194.87,159.14,7.43,10.91" target="#b6">7,</ref><ref type="bibr" coords="3,204.57,159.14,7.42,10.91" target="#b7">8,</ref><ref type="bibr" coords="3,214.26,159.14,7.43,10.91" target="#b8">9,</ref><ref type="bibr" coords="3,223.95,159.14,12.50,10.91" target="#b9">10,</ref><ref type="bibr" coords="3,238.71,159.14,12.50,10.91" target="#b10">11,</ref><ref type="bibr" coords="3,253.47,159.14,12.50,10.91" target="#b11">12,</ref><ref type="bibr" coords="3,268.23,159.14,12.50,10.91" target="#b12">13,</ref><ref type="bibr" coords="3,283.00,159.14,12.50,10.91" target="#b13">14,</ref><ref type="bibr" coords="3,297.76,159.14,8.88,10.91" target="#b2">3]</ref> have been proposed for hate speech detection in the last few years. Here, we are listing some of the state-of-the-art models for the identification of hate content from social media. SemEval-2019 task <ref type="bibr" coords="3,373.88,186.24,18.07,10.91" target="#b14">[15]</ref> was about the Detection of Hate speech against Immigrants and Women. In this task, the participant has been given tweets of two languages English and Spanish. The task included two subtasks. The first one was about identifying the hate speech and the later one was about identifying further features such as aggressiveness and the target group or individual. For the first task, the best result was with a macro F1-score of 0.65 for the English dataset, whereas it is 0.73 for the Spanish dataset. This was obtained by the SVM with RBF kernel using embeddings from Google's Universal Sentence Encoder as features. For the second task, the best result was with a macro F1-Score of 0.70 whereas for the English dataset it is 0.57. The main motive in <ref type="bibr" coords="3,404.66,294.63,13.00,10.91" target="#b3">[4]</ref> was to identify the user who is spreading the fake news, not to identify the message that it is fake news or not. From the evaluation of the approaches of the participants, it has been found that SVM with the combination of character n-grams and word n-grams is the best-suited approach for Spanish and logistic regression ensemble of five submodels: n-grams with Random Forest, n-grams with SVM, n-grams with Logistic Regression, n-grams with XGBoost and XGBoost with features based on textual descriptive statistics, is the best-suited approach for English. The best accuracy obtained for English was 75% and for Spanish was 82%. The authors <ref type="bibr" coords="3,409.47,389.48,13.00,10.91" target="#b4">[5]</ref> have investigated multiple approaches for the problem of hate speech, aggressive behaviour, and target group recognition. They have presented many models including Logistic regression, Convolutional Neural Network (CNN), Bidirectional Transformers (BERT) using word n-grams, character n-grams, word embedding, and psycholinguistic features (LIWC). Among these models, purely Data-Driven BERT model and to some extent hybrid psycho linguistically informed CNN outperformed all other models for all tasks in both languages English and Spanish. For English, the best F1-score of 0.60 for hate speech has been found by CNN using features word embedding and LIWC. For Spanish, the best F1-score of 0.72 for hate speech has been found by BERT using features cased word.</p><p>At EVALITA-2018 <ref type="bibr" coords="3,184.11,538.52,11.56,10.91" target="#b5">[6]</ref>, several models were reported to detect hate speech in Italian Social Media. Linear SVM with word embedding as features had performed best for the given problem. For Twitter and Facebook, the best macro F1-score was 0.79 and 0.77. The paper <ref type="bibr" coords="3,492.99,565.62,13.00,10.91" target="#b6">[7]</ref> introduced a combined Convolution Neural Network (CNN) and Gated Recurrent Networks (GRU) to outperform many previously proposed methods. The problem addressed in <ref type="bibr" coords="3,482.29,592.72,12.99,10.91" target="#b7">[8]</ref> is about identifying hate speech and aggressive tweets on three publicly available datasets. The author used the TF-IDF vectors with different n-gram range as features. The author used the three model-Logistic Regression, Naive Bayes Classifier, and SVM. Among these models, Logistic Regression fed with TF-IDF vector with n-gram range (1,3) has given the best accuracy of 0.956%. The authors <ref type="bibr" coords="3,217.73,660.46,12.99,10.91" target="#b8">[9]</ref> have implemented deep learning models in sixteen different datasets of nine different languages. They found that for small dataset Logistic Regression fed with LASER (Language-Agnostic SEntence Representation) embedding has performed best and for the larger dataset BERT based model has given better results. In this paper, the author has used features of LASER embedding and MUSE embedding and achieved an accuracy of 0.83%. Saha al. et. <ref type="bibr" coords="4,155.68,154.71,18.07,10.91" target="#b9">[10]</ref> used (i) TF-IDF vectors, (ii) sentence embedding, and (iii) Bag Of Words Embedding with various machine learning models to report that Logistic Regression performed best. Two subtasks were performed in their work (i) to classify whether a text is hate speech or not and, (ii) to classify the texts in categories as a stereotype, sexual harassment, dominance, derailing, and discredit. The Logistic Regression model performed best for this task with an accuracy of 0.704. The authors <ref type="bibr" coords="4,231.19,222.46,18.07,10.91" target="#b10">[11]</ref> claim that the performance of various machine learning algorithms to detect hate speech is hampered by inefficient sequence transduction and the vanilla Recurrent Neural Networks (RNN). RNNs with attention also suffer from various problems such as lack of parallelization and long term dependency. Therefore, the authors proposed a transform-based model and used a public dataset containing 24,783 labelled tweets. The proposed DistillBERT transformer method was compared against other transformer baselines and recurrent neural networks for Hate Speech Detection in Twitter and results showed that DistillBERT transformers outperformed other models with an accuracy of 75%. The problem addressed in <ref type="bibr" coords="4,151.13,330.85,18.07,10.91" target="#b15">[16]</ref> is about recognizing hateful content in social media. Recurrent Neural Networks were ensembled and various user-related features were incorporated showing the users' tendency towards hate speech such as racism or sexism. Word frequency vectors along with these features and data were fed as input to the classifiers. The dataset used by them was a corpus of 16,000 tweets that is available publicly. The results were compared to existing state-of-art solutions. The model can successfully differentiate racism and sexism messages from the ones which do not fall in these categories. Finally, the highest F1-score of 0.9320 was achieved using the ensemble approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>This section discusses the proposed methodology in detail. The different classification and deep learning models used for profiling hate speech spreaders that learn the continuous representation of tweets and then pick features from them extracted using count vectorizer and tf-idf vectorizer. The performance of different models was compared for different n-gram ranges. In deep learning models like LSTM, we have used one-hot encoding for feature extraction. The detailed architecture and flow of different phases in which the computation is carried out are shown in Figure <ref type="figure" coords="4,120.36,565.62,3.74,10.91" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data pre-processing</head><p>We have used the PAN21-Profiling-Hate-Speech-Spreaders-on-Twitter data provided by <ref type="bibr" coords="4,487.94,615.34,18.05,10.91" target="#b16">[17]</ref> maintained at <ref type="bibr" coords="4,152.71,628.89,17.82,10.91" target="#b17">[18]</ref> to validate our proposed model. The data contains user ids and their tweets. The data contains tweets of 200 users each for English and Spanish language. 200 tweets are provided for each user containing a combination of hate speech tweets and non-hate speech tweets. Therefore, a total of 40,000 tweets are used for the experimentation. Label information for each user is provided in a separate file classifying users into two classes -hate speech spreader or not hate speech spreader. Being originally a part of PAN at CLEF 2021, the data contains only the training dataset. To test and compare the performance of various classification and deep learning models, we have split this dataset into training and testing datasets in a ratio of 67:33. Finally, our training dataset contains 26,800 tweets (i.e 134 users) and the testing set contains 1,3200 tweets (i.e. 66 users) for each language.</p><p>We preprocessed the tweets to remove hashtag symbols keeping the content of the hashtag as it can be used to identify important details like the target people, emotions, intent behind the tweet. We then removed mentions and converted emoticons and emojis to text. Tweets were converted to lowercase. Punctuations and stop words were removed. Then to remove affixes from words, stemming was performed. Then finally tokenization of tweets was done. The word clouds for the English and the Spanish dataset which depicts the term with the highest frequency in the tweet can be seen in Figure <ref type="figure" coords="6,289.48,263.11,5.07,10.91" target="#fig_1">2</ref> and 3, respectively.</p><p>After preprocessing was completed, we merged all the tweets of a particular user into one tweet separated by spaces. Then we merged the labels with the tweets data based on user id. Finally, we obtained the data containing user id, combined tweets per user, and a label indicating whether the user is a hate speech spreader or not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Deep learning models used for classification</head><p>LSTM: With the success of Long-short-Term-memory (LSTM) networks in various natural language processing tasks <ref type="bibr" coords="6,208.13,669.58,11.37,10.91" target="#b0">[1,</ref><ref type="bibr" coords="6,222.22,669.58,12.33,10.91" target="#b18">19]</ref>, we motivated to use this network for our task. The gates of By doing that it learns to use relevant information for doing predictions. In LSTM gates consist of a sigmoid activation function so for data to forget they multiply it by 0 and for data to keep they multiply it by 1. In LSTM the presence of forget gate, along with the additive property of the cell state gradients enables the network to update the parameter effectively so they emphasize only retaining the important information and discarding the rest. The architecture of the model used: Embedding Layer: Here we pass the vocabulary size as our first parameter, input feature size as the second parameter and the sentence length as the third parameter which in our case is 2500. This layer will give an output which we will pass through an LSTM layer, LSTM Layer: We have used 1 LSTM layer having 100 neurons, and Dense Layer: Since it is a classification problem, we will get an output from this dense layer. The hyper-parameters of the implemented LSTM model can be seen in Table <ref type="table" coords="7,319.43,544.04,3.74,10.91" target="#tab_4">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bi-LSTM:</head><p>The bidirectional long-short-term-memory (Bi-LSTM) network is an extension of traditional LSTM that can improve model performance on sequence classification problems. The architecture of the model used: (i) Embedding Layer: Here we pass the vocabulary size as our first parameter, input feature size as the second parameter, and the sentence length as the third parameter which in our case is 2500. This layer will give an output which we will pass through a Bi-LSTM layer, (ii) Bidirectional-LSTM Layer: We have used one LSTM layer having 100 neurons, (iii) Dense Layer: Since it is a classification problem, we will get an output from this dense layer. The hyper-parameters of the implemented LSTM model can be seen in Table <ref type="table" coords="7,500.35,667.64,3.66,10.91" target="#tab_5">6</ref>. The paper <ref type="bibr" coords="8,246.26,397.64,17.97,10.91" target="#b19">[20]</ref> showed that a bidirectionally trained model performs better than a single direction trained model. BERT can be easily fine-tuned for the classification problem, question answer problem, and named entity problem. We followed the following steps while training the BERT model: (i) First of all, we imported the BERT Tokenizer and Sequence Classifier, (ii) Convert each row of the data into an InputExample Object, (iii) We did tokenization of the InputExample objects and created the required input format from the tokens so that we can feed the data to the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation Metrics</head><p>For evaluating the proposed models we used precision, recall, F1 Score, support, and accuracy. We have used classification reports and confusion matrix, these metrics are widely used for evaluating supervised machine learning models for classification when the dataset is multilabelled.</p><p>Precision It is the ratio of accurately predicted users as hate speech spreaders to the total number of predicted users. It is computed as given in the equation below. The range of precision Recall It is the ratio of accurately predicted users as hate speech spreaders to the total number of real hate speech spreading users. It is computed as is given in the below equation. The range of recall varies between 0 and 1, where 1 is the best and 0 is the worst value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall = Number of accurately predicted users</head><p>Total number of users</p><p>F1-Score The harmonic of Precision and Recall is called F1-Score. It can be represented by the following equation. The range of F1-score varies between 0 and 1, where 1 is the best and 0 is the worst value.</p><formula xml:id="formula_1" coords="9,220.01,597.14,285.98,25.77">F1-Score = 2 √ó Precision √ó Recall Precision + Recall<label>(3)</label></formula><p>The performance of the proposed model is measured in terms of Precision (P), Recall (R), ùêπ 1 -score (ùêπ 1 ), and Accuracy (Acc.). The performance of different classifiers such as Naive Bayes (NB), K-Nearest Neighbour (KNN), Logistic Regression (LR), Support Vector Machine (SVM) with different count and TF-IDF n-gram features for English and Spanish datasets are listed in Tables <ref type="table" coords="10,120.31,469.47,5.12,10.91" target="#tab_1">2</ref> and<ref type="table" coords="10,147.47,469.47,3.77,10.91" target="#tab_2">3</ref>, respectively. The results of the deep learning models such as LSTM, Bi-LSTM, and BERT for English and Spanish datasets are listed in Table <ref type="table" coords="10,362.96,483.02,3.70,10.91" target="#tab_3">4</ref>. For the English dataset, out of all the different classification methods, naive Bayes performed best with an accuracy of 74% for n-gram range (1,1) and count vectorizer while 65% for n-gram range <ref type="bibr" coords="10,402.64,510.12,10.94,10.91" target="#b0">(1,</ref><ref type="bibr" coords="10,413.57,510.12,7.29,10.91" target="#b2">3)</ref>. For other criteria like for TF-IDF vectorizer with n-gram (1,1), it gave 70% accuracy and with n-gram (1,3) it gave 65% accuracy. Similarly, for the Spanish dataset, out of all the different classification methods, naive Bayes performed best with an accuracy of 79% for n-gram range (1,1) and count vectorizer while 81% for n-gram range <ref type="bibr" coords="10,212.98,564.32,10.51,10.91" target="#b0">(1,</ref><ref type="bibr" coords="10,223.49,564.32,7.01,10.91" target="#b2">3)</ref>. For other criteria like for TF-IDF vectorizer with n-gram (1,1), it gave 80% accuracy and with n-gram (1,3) it gave 82% accuracy. The performance of classifiers for English and Spanish Datasets are plotted in Figures <ref type="figure" coords="10,481.90,591.41,5.04,10.91" target="#fig_3">4</ref> and<ref type="figure" coords="10,89.29,604.96,3.68,10.91" target="#fig_4">5</ref>, respectively. In the figure, ùê∂ represents classifier with count vector feature and ùëá represents classifier with TF-IDF feature. From Figures <ref type="figure" coords="10,280.88,618.51,4.97,10.91" target="#fig_3">4</ref> and<ref type="figure" coords="10,306.52,618.51,3.66,10.91" target="#fig_4">5</ref>, it can be seen that the Naive Bayes classifier with count vector features performed best for English Dataset and achieved an accuracy of 0.74 and Naive Bayes classifier with TF-IDF feature performed best for Spanish Dataset and achieved an accuracy of 0.82. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The major finding of the current work is that multinomial naive Bayes with n-gram features is a better model for identifying hate speech spreaders. With the English dataset, a multinomial naive Bayes with one-gram tf-idf feature yielded the best accuracy value of 70% and 66% with known as well as unknown test dataset, respectively. While with the Spanish dataset, the tf-idf features vector of 1-3 gram reported the best result with an accuracy of 82% and 80% for known and unknown test datasets, respectively. The deep learning models such as LSTM, Bi-LSTM and BERT models were not found to be performing well while predicting hate speech spreaders. One of the reasons may be inefficient features presented as input to the deep learning models were not capturing the semantics of the text. The other limitation of the current work is that only the textual contents of the tweets are used for the experiments. The other components of a tweet such as images, videos and URLs may augment the current input to yield better accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The prediction of whether a user is spreading hate speech or not from his combined tweets is a challenging task as tweets have various noise in terms of grammatical mistakes, spelling mistakes, and non-standard abbreviations. Along with that when the different tweets of a single user have merged together the sentiments of a particular tweet might counter the effect of others. We trained classification models using tf-idf and count vector as feature values. We have shown a comparative study of machine learning algorithms with respective feature sets. We have compared their accuracies for different n-gram ranges i.e (1,1) and <ref type="bibr" coords="12,431.05,643.87,11.59,10.91" target="#b0">(1,</ref><ref type="bibr" coords="12,442.64,643.87,7.73,10.91" target="#b2">3)</ref> and also for tf-idf and count vectorizer. We have shown the accuracy estimated in each case in the result</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,89.29,714.24,330.96,8.93;5,126.31,87.58,340.16,614.10"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall flow diagram of the proposed model for hate speech spreaders</figDesc><graphic coords="5,126.31,87.58,340.16,614.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,592.33,187.36,8.93;6,176.15,338.57,240.48,241.20"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Word Cloud for the English dataset</figDesc><graphic coords="6,176.15,338.57,240.48,241.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,89.29,357.39,189.57,8.93;7,171.11,84.19,250.56,260.64"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Word Cloud for the Spanish dataset</figDesc><graphic coords="7,171.11,84.19,250.56,260.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,89.29,346.49,352.54,8.93;8,144.96,118.48,337.87,167.86"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Classifiers comparison for the hate spreaders prediction for English Dataset</figDesc><graphic coords="8,144.96,118.48,337.87,167.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,89.29,374.32,354.75,8.93;9,138.51,113.23,363.93,195.51"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Classifiers comparison for the hate spreaders prediction for Spanish Dataset</figDesc><graphic coords="9,138.51,113.23,363.93,195.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,454.33,417.00,83.88"><head>Table 1</head><label>1</label><figDesc>The table below lists some examples of hate and non-hate speech.</figDesc><table coords="2,89.29,485.11,20.92,7.57"><row><cell>Tweet</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,88.99,90.49,416.99,352.33"><head>Table 2</head><label>2</label><figDesc>Results of different machine learning classifiers with count and TF-IDF features (English Dataset)</figDesc><table coords="10,89.29,122.02,416.69,320.79"><row><cell>Models</cell><cell>N-Gram</cell><cell>Class</cell><cell cols="2">Count Vector</cell><cell></cell><cell></cell><cell>TF-IDF Vector</cell></row><row><cell></cell><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>ùêπ 1</cell><cell cols="2">Acc. P</cell><cell>R</cell><cell>ùêπ 1</cell><cell>Acc.</cell></row><row><cell cols="2">Naive Bayes 1-Gram</cell><cell cols="6">Non-hate spreader 0.79 0.72 0.75 0.74 0.72 0.72 0.72 0.70</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.70 0.77 0.73</cell><cell></cell><cell>0.67 0.67 0.67</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.75 0.74 0.74</cell><cell></cell><cell>0.70 0.70 0.70</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.76 0.53 0.62 0.65 0.72 0.58 0.65 0.65</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.59 0.80 0.68</cell><cell></cell><cell>0.59 0.73 0.66</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.68 0.65 0.65</cell><cell></cell><cell>0.68 0.65 0.65</cell></row><row><cell>KNN</cell><cell>1-Gram</cell><cell cols="6">Non-hate spreader 0.55 0.72 0.63 0.53 0.73 0.61 0.67 0.66</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.47 0.30 0.37</cell><cell></cell><cell>0.61 0.73 0.67</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.52 0.53 0.51</cell><cell></cell><cell>0.68 0.67 0.67</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.62 0.58 0.60 0.58 0.67 0.67 0.67 0.64</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.53 0.57 0.55</cell><cell></cell><cell>0.60 0.60 0.60</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.58 0.58 0.58</cell><cell></cell><cell>0.64 0.64 0.64</cell></row><row><cell>Logistic Regression</cell><cell>1-Gram</cell><cell cols="6">Non-hate spreader 0.67 0.61 0.64 0.62 0.75 0.50 0.6</cell><cell>0.64</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.58 0.63 0.6</cell><cell></cell><cell>0.57 0.80 0.67</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.63 0.62 0.62</cell><cell></cell><cell>0.67 0.64 0.63</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.76 0.61 0.68 0.68 0.88 0.39 0.54 0.64</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.62 0.77 0.69</cell><cell></cell><cell>0.56 0.93 0.70</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.70 0.68 0.68</cell><cell></cell><cell>0.73 0.64 0.61</cell></row><row><cell>SVM</cell><cell>1-Gram</cell><cell cols="2">Non-hate spreader -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.75 0.50 0.60 0.64</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>0.57 0.80 0.67</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>0.67 0.64 0.63</cell></row><row><cell></cell><cell cols="3">(1-3)-Gram Non-hate spreader -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.88 0.39 0.54 0.64</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>0.56 0.93 0.70</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>0.73 0.64 0.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,88.99,90.49,416.99,352.33"><head>Table 3</head><label>3</label><figDesc>Results of different machine learning classifiers with count and TF-IDF features (Spanish Dataset)</figDesc><table coords="11,89.29,122.02,416.69,320.79"><row><cell>Models</cell><cell>N-Gram</cell><cell>Class</cell><cell cols="2">Count Vector</cell><cell></cell><cell cols="2">TF-IDF Vector</cell></row><row><cell></cell><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>ùêπ 1</cell><cell>Acc. P</cell><cell>R</cell><cell>ùêπ 1</cell><cell>Acc.</cell></row><row><cell cols="2">Naive Bayes 1-Gram</cell><cell cols="6">Non-hate spreader 0.78 0.78 0.78 0.79 0.79 0.81 0.80 0.80</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.79 0.79 0.79</cell><cell cols="2">0.82 0.79 0.81</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.77 0.79 0.79</cell><cell cols="2">0.80 0.80 0.80</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.86 0.75 0.80 0.81 0.86 0.75 0.80 0.82</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.79 0.88 0.83</cell><cell cols="2">0.79 0.88 0.83</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.82 0.82 0.82</cell><cell cols="2">0.82 0.82 0.82</cell></row><row><cell>KNN</cell><cell>1-Gram</cell><cell cols="6">Non-hate spreader 0.74 0.81 0.78 0.70 0.75 0.56 0.64 0.66</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.81 0.74 0.77</cell><cell cols="2">0.67 0.82 0.74</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.78 0.77 0.70</cell><cell cols="2">0.71 0.70 0.69</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.71 0.78 0.75 0.74 0.80 0.25 0.38 0.60</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.77 0.71 0.74</cell><cell cols="2">0.57 0.94 0.71</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.75 0.74 0.74</cell><cell cols="2">0.68 0.61 0.55</cell></row><row><cell>Logistic Regression</cell><cell>1-Gram</cell><cell cols="6">Non-hate spreader 0.77 0.84 0.81 0.80 0.79 0.72 0.75 0.77</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.84 0.76 0.80</cell><cell cols="2">0.76 0.82 0.79</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.81 0.80 0.80</cell><cell cols="2">0.77 0.77 0.77</cell></row><row><cell></cell><cell cols="7">(1-3)-Gram Non-hate spreader 0.76 0.81 0.79 0.79 0.84 0.66 0.74 0.77</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.81 0.76 0.79</cell><cell cols="2">0.73 0.88 0.80</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.79 0.79 0.79</cell><cell cols="2">0.78 0.77 0.77</cell></row><row><cell>SVM</cell><cell>1-Gram</cell><cell cols="6">Non-hate spreader 1.00 0.06 0.12 0.54 0.79 0.72 0.75 0.77</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.53 1.00 0.60</cell><cell cols="2">0.76 0.82 0.79</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.76 0.55 0.41</cell><cell cols="2">0.77 0.77 0.70</cell></row><row><cell></cell><cell cols="6">(1-3)-Gram Non-hate spreader 1.00 0.06 0.12 0.54 0.84</cell><cell>0.74 0.77</cell></row><row><cell></cell><cell></cell><cell>Hate spreader</cell><cell cols="3">0.53 1.00 0.69</cell><cell cols="2">0.73 0.88 0.80</cell></row><row><cell></cell><cell></cell><cell>Weighted Avg.</cell><cell cols="3">0.76 0.55 0.41</cell><cell cols="2">0.78 0.77 0.77</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,88.99,465.02,325.49,93.78"><head>Table 4</head><label>4</label><figDesc>Results for the different deep learning models for English and Spanish Datasets</figDesc><table coords="11,201.77,496.64,191.73,62.16"><row><cell>Model</cell><cell cols="2">English Dataset Spanish Dataset</cell></row><row><cell></cell><cell>Acc.</cell><cell>Acc.</cell></row><row><cell>LSTM</cell><cell>0.44</cell><cell>0.47</cell></row><row><cell cols="2">Bi-LSTM 0.54</cell><cell>0.49</cell></row><row><cell>BERT</cell><cell>0.53</cell><cell>0.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,88.99,90.49,313.26,165.51"><head>Table 5</head><label>5</label><figDesc>Description of Hyper parameters for implemented LSTM network</figDesc><table coords="12,193.03,122.10,209.22,133.90"><row><cell>Hyper-parameters</cell><cell>Value</cell></row><row><cell>Activation</cell><cell>ReLU</cell></row><row><cell>Loss function</cell><cell>Binary Cross Entropy</cell></row><row><cell>Optimiser</cell><cell>Adam</cell></row><row><cell>Vocabulary Size</cell><cell>5000</cell></row><row><cell cols="2">Embedding Vector Feature 40</cell></row><row><cell>Sentence Length</cell><cell>2500</cell></row><row><cell>Epochs</cell><cell>15</cell></row><row><cell>Batch Size</cell><cell>64</cell></row><row><cell>Validation Split</cell><cell>0.26</cell></row><row><cell>Metrics</cell><cell>Accuracy</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,88.99,278.26,320.92,117.69"><head>Table 6</head><label>6</label><figDesc>Description of Hyper parameters for Bi-LSTM model</figDesc><table coords="12,185.36,309.87,224.56,86.07"><row><cell cols="2">Hyper-parameters Value</cell></row><row><cell>Activation</cell><cell>ReLU</cell></row><row><cell>Loss function</cell><cell>Sparse Categorical Cross Entropy</cell></row><row><cell>Optimiser</cell><cell>Adam</cell></row><row><cell>Epochs</cell><cell>15</cell></row><row><cell>Batch Size</cell><cell>64</cell></row><row><cell>Metrics</cell><cell>Accuracy</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>section. We achieved our best result with an F1-score of 0.74 for the English dataset when we used Multinomial Naive Bayes with n-gram range (1,1) and count vectorizer and of 0.82 for the Spanish dataset again for Multinomial Naive Bayes with n-gram range (1,3) and for both tf-idf and count vectorizer.</p><p>The final accuracy, as calculated by PAN on the test dataset is 66% for the English dataset and 80% for the Spanish dataset making an average of 73%. These results were obtained using Naive Bayes Classifier with an n-gram range of (1,1) for the English dataset and (1,3) for the Spanish dataset.</p><p>This system can be utilized by different social media platforms to identify hate speech spreaders and remove such hate speech spreaders from their platform.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="13,112.66,267.54,393.33,10.91;13,112.66,281.08,391.76,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,324.09,267.54,181.90,10.91;13,112.66,281.08,192.01,10.91">Hybrid attention-based long short-term memory network for sarcasm identification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,312.71,281.08,108.68,10.91">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">107348</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,294.63,393.33,10.91;13,112.66,308.18,393.60,10.91;13,112.66,321.73,125.73,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,406.65,294.63,99.33,10.91;13,112.66,308.18,154.06,10.91">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,311.51,308.18,142.17,10.91">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="13,461.81,308.18,44.45,10.91;13,112.66,321.73,56.73,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,335.28,393.61,10.91;13,112.66,348.83,314.13,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<title level="m" coord="13,322.17,335.28,184.10,10.91;13,112.66,348.83,239.44,10.91">Overview of the 8th author profiling task at PAN 2020: Profiling fake news spreaders on Twitter</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,362.38,393.32,10.91;13,112.66,375.93,306.70,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,159.74,362.38,346.24,10.91;13,112.66,375.93,36.69,10.91">Using n-grams to detect fake news spreaders on Twitter: Notebook for pan at clef 2020</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,172.44,375.93,178.59,10.91">Cross-Language Evaluation Forum CLEF</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,389.48,393.33,10.91;13,112.66,403.03,393.33,10.91;13,112.66,416.58,42.06,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,432.79,389.48,73.20,10.91;13,112.66,403.03,278.78,10.91">Data driven and psycholinguistics motivated approaches to hate speech detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Caetano Da Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Castro</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Silva Ramos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Paraboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,399.02,403.03,106.97,10.91">Computaci√≥n y Sistemas</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,430.13,393.71,10.91;13,112.66,443.67,393.33,10.91;13,112.66,457.22,379.10,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,385.33,430.13,121.03,10.91;13,112.66,443.67,136.12,10.91">Overview of the EVALITA 2018 hate speech detection task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Maurizio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,271.21,443.67,234.78,10.91;13,112.66,457.22,219.23,10.91">EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2263</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,470.77,395.17,10.91;13,112.66,484.32,394.53,10.91;13,112.66,497.87,55.16,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,263.81,470.77,244.02,10.91;13,112.66,484.32,141.95,10.91">Detecting hate speech on Twitter using a convolution-GRU based deep neural network</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,278.19,484.32,155.94,10.91">European semantic web conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="745" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,511.42,393.33,10.91;13,112.66,524.97,393.60,10.91;13,112.66,538.52,146.44,10.91" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaydhani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Doma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kendre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bhagwat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08651</idno>
		<title level="m" coord="13,337.99,511.42,168.00,10.91;13,112.66,524.97,360.14,10.91">Detecting hate speech and offensive language on twitter using machine learning: An n-gram and tfidf based approach</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,552.07,393.33,10.91;13,112.66,565.62,254.56,10.91" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="13,317.42,552.07,188.57,10.91;13,112.66,565.62,72.48,10.91">Deep learning models for multilingual hate speech detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Aluru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06465</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,579.17,393.33,10.91;13,112.26,592.72,213.09,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.06700</idno>
		<title level="m" coord="13,313.30,579.17,192.69,10.91;13,112.26,592.72,29.47,10.91">Hateminers: Detecting hate speech against women</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,112.66,606.27,393.53,10.91;13,112.66,619.81,393.98,10.91;13,112.66,633.36,12.55,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,280.64,606.27,225.54,10.91;13,112.66,619.81,34.82,10.91">Hate speech detection in twitter using transformer methods</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mutanga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naicker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Olugbara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,156.35,619.81,308.62,10.91">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,112.66,646.91,394.61,10.91;14,112.28,86.97,393.70,10.91;14,112.66,100.52,223.73,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,261.07,646.91,246.20,10.91;14,112.28,86.97,393.70,10.91;14,112.66,100.52,14.56,10.91">NITP-AI-NLP@ HASOC-Dravidian-CodeMix-FIRE2020: A machine learning approach to identify offensive languages from dravidian code-mixed text</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saumya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,153.06,100.52,95.56,10.91">FIRE (Working Notes)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="384" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,114.06,393.54,10.91;14,112.66,127.61,393.33,10.91;14,112.66,141.16,114.65,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,259.92,114.06,246.28,10.91;14,112.66,127.61,301.49,10.91">NITP-AI-NLP@ HASOC-FIRE2020: Fine tuned BERT for the hate speech and offensive content identification from social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saumya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,441.33,127.61,64.66,10.91;14,112.66,141.16,26.87,10.91">FIRE (Working Notes)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="266" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,154.71,393.33,10.91;14,112.66,168.26,393.33,10.91;14,112.33,181.81,247.24,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,269.89,154.71,236.10,10.91;14,112.66,168.26,103.47,10.91">Offensive language identification in Dravidian code mixed social media text</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saumya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,238.55,168.26,267.44,10.91;14,112.33,181.81,169.10,10.91">Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</title>
		<meeting>the First Workshop on Speech and Language Technologies for Dravidian Languages</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,195.36,394.52,10.91;14,112.66,208.91,393.32,10.91;14,112.26,222.46,393.73,10.91;14,112.66,236.01,209.09,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,140.10,208.91,365.88,10.91;14,112.26,222.46,77.83,10.91">Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Debora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,213.01,222.46,233.98,10.91">13th International Workshop on Semantic Evaluation</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,249.56,393.33,10.91;14,112.66,263.11,334.73,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,302.71,249.56,203.28,10.91;14,112.66,263.11,141.90,10.91">Effective hate-speech detection in Twitter data using recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Pitsilis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ramampiaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Langseth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,263.39,263.11,89.92,10.91">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="4730" to="4742" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,276.66,394.53,10.91;14,112.66,290.20,395.17,10.91;14,112.66,303.75,393.33,10.91;14,112.66,317.30,393.33,10.91;14,112.66,330.85,222.66,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,194.78,303.75,311.21,10.91;14,112.66,317.30,221.30,10.91">Overview of PAN 2021: Authorship Verification,Profiling Hate Speech Spreaders on Twitter,and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,357.51,317.30,148.47,10.91;14,112.66,330.85,150.17,10.91">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,344.40,394.53,10.91;14,112.66,357.95,393.33,10.91;14,112.66,371.50,394.51,10.91;14,112.66,387.49,123.08,7.90" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,327.46,344.40,175.13,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,240.99,357.95,264.99,10.91;14,112.66,371.50,123.97,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,398.60,393.53,10.91;14,112.39,412.15,326.76,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,326.97,398.60,179.22,10.91;14,112.39,412.15,126.91,10.91">Attention-based lstm network for rumor veracity estimation of tweets</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">P</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">K</forename><surname>Dwivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,247.71,412.15,135.59,10.91">Information Systems Frontiers</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.66,425.70,393.33,10.91;14,112.66,439.25,363.59,10.91" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="14,323.15,425.70,182.83,10.91;14,112.66,439.25,181.08,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
