<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.32,372.51,16.17;1,89.29,106.24,81.22,16.17;1,89.29,130.81,160.62,10.37">Effective Detection of Hate Speech Spreaders on Twitter Notebook for PAN at CLEF 2021</title>
				<funder ref="#_aaFFYYF">
					<orgName type="full">-Digitalization and Technology Research Center of the Bundeswehr</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.06,156.71,62.11,10.37"><forename type="first">Julian</forename><surname>HÃ¶llig</surname></persName>
							<email>julian.hoellig@unibw.de</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute CODE</orgName>
								<orgName type="institution">Bundeswehr University Munich</orgName>
								<address>
									<settlement>Neubiberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.62,156.71,67.20,10.37"><forename type="first">Yeong</forename><forename type="middle">Su</forename><surname>Lee</surname></persName>
							<email>yeongsu.lee@unibw.de</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute CODE</orgName>
								<orgName type="institution">Bundeswehr University Munich</orgName>
								<address>
									<settlement>Neubiberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.27,156.71,70.06,10.37"><forename type="first">Nina</forename><surname>Seemann</surname></persName>
							<email>nina.seemann@unibw.de</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute CODE</orgName>
								<orgName type="institution">Bundeswehr University Munich</orgName>
								<address>
									<settlement>Neubiberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.04,156.71,90.63,10.37"><forename type="first">Michaela</forename><surname>Geierhos</surname></persName>
							<email>michaela.geierhos@unibw.de</email>
							<affiliation key="aff0">
								<orgName type="department">Research Institute CODE</orgName>
								<orgName type="institution">Bundeswehr University Munich</orgName>
								<address>
									<settlement>Neubiberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.32,372.51,16.17;1,89.29,106.24,81.22,16.17;1,89.29,130.81,160.62,10.37">Effective Detection of Hate Speech Spreaders on Twitter Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">137D5BF6BC4D6459E31ACF1388300B48</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>author profiling</term>
					<term>hate speech</term>
					<term>noun chunks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we summarize our participation in the task of "Profiling Hate Speech Spreaders on Twitter" at the PAN@CLEF Conference 2021. Our models obtained an average accuracy of 76% (79% for Spanish and 73% for English). For English, we used a Linear Support Vector Machine with tf-idf features on noun chunk level, while for Spanish we used a Ridge Classifier with simple counts on noun chunk level. Both classifiers were fed with additional features obtained from a Convolutional Neural Network.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, there has been growing awareness that hate speech became an increasing issue in social media, which offers anonymity and virality to authors of hateful posts. On average, Twitter had 199 million daily active users in the first quarter of 2021, compared to 166 million active users counted the year before, which is an increase of almost 20 percent <ref type="bibr" coords="1,400.10,410.83,11.44,9.46" target="#b0">[1]</ref>. These developments caused political forces and social media providers to act. For example, the EU initiated measures such as the European Council's "No Hate Speech Movement", which aims at mobilizing online consumers to take action against hate <ref type="bibr" coords="1,259.95,451.47,11.72,9.46" target="#b1">[2]</ref>. The EU, with the involvement of YouTube, Twitter, Facebook, and Microsoft, has also drafted a "Code of conduct on countering illegal hate speech online" <ref type="bibr" coords="1,125.87,478.57,11.74,9.46" target="#b2">[3]</ref>, in which these companies commit to check hate speech notifications within 24 hours <ref type="bibr" coords="1,117.05,492.12,11.74,9.46" target="#b3">[4]</ref>. However, the most effective and efficient way to combat hate speech is through its automatic detection, where machine learning applications can play a crucial role.</p><p>In the PAN shared task <ref type="bibr" coords="1,204.24,519.22,11.67,9.46" target="#b4">[5]</ref>, international researchers focus on modeling such applications to identify hate speech spreaders on Twitter. Compared to other hate speech detection tasks <ref type="bibr" coords="1,480.91,532.77,11.85,9.46" target="#b5">[6,</ref><ref type="bibr" coords="1,495.50,532.77,7.90,9.46" target="#b6">7]</ref>, the data for this task consist of tweet collections belonging to the same author, each representing a sample in the dataset. One profound challenge in detecting hate speech is its unclear definition. Table <ref type="table" coords="1,116.23,573.42,5.56,9.46" target="#tab_0">1</ref> compares the attitudes of political, social media, and scientific representatives on four important questions about the definition of hate speech <ref type="bibr" coords="1,344.15,586.97,11.74,9.46" target="#b7">[8]</ref>. The contents of the table were retrieved from official sources of the institutions and from scientific papers <ref type="bibr" coords="1,431.89,600.52,11.73,9.46" target="#b7">[8]</ref>. While there is agreement that hate speech is directed to specific targets, the attitudes differ regarding the influence of humor, whether or not hate speech is intended to incite hate, and whether or not hate speech is intended to attack and disparage. This leads to critically different definitions of hate speech and how to combat it. For example, according to Table <ref type="table" coords="2,369.20,300.43,4.17,9.46" target="#tab_0">1</ref>, YouTube would not define a verbal attack on a person as hate speech, while inciting violence against the same person would be considered as hate speech. Facebook would take the opposite position, according to Table <ref type="table" coords="2,499.64,327.53,4.13,9.46" target="#tab_0">1</ref>. Due to the broad definition of hate speech, it is difficult to find large harmonized data collections, since annotators often have low agreement when building new collections [9, 10, as cited in <ref type="bibr" coords="2,489.02,354.63,11.33,9.46" target="#b7">[8]</ref>]. Consequently, it is challenging to establish a common standard for modeling hate speech so far. The paper is organized as follows. In Section 2, we present relevant related work. In Section 3, we explain our methods in detail and present the evaluation of the final models in Section 4. Finally, we conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In recent years, the detection of hate speech has been of great interest for many researches. As a result, there is a vast literature on this topic. In the following, we will only focus on some other shared tasks and their results.</p><p>Mandl et al. <ref type="bibr" coords="2,160.93,509.43,18.32,9.46" target="#b10">[11]</ref> describe the identification of hate speech and offensive content in Indo-European languages<ref type="foot" coords="2,175.59,520.93,3.99,6.91" target="#foot_0">1</ref> at FIRE 2019. There were three subtasks: subtask A was the coarse-grained binary classification into non Hate-Offensive and Hate &amp; Offensive (HOF). If a post was classified as HOF, then it was handled by subtask B, which further classified it into either hate speech, offensive, or profane. Subtask C addressed the targeting and non-targeting of individuals, groups, or others when a post was classified as HOF. For example, the team with the best performance on the English data achieved a macro F1 score of 78.82% and a weighted F1 score of 83.95% for subtask A, a macro F1 of 54.46% and a weighted F1 of 72.77% for subtask B, and a macro F1 of 51.11% and a weighted F1 of 75.63% for subtask C.</p><p>HatEval <ref type="bibr" coords="2,139.45,631.37,18.32,9.46" target="#b11">[12]</ref> consists of detecting hateful content in Twitter posts for English and Spanish. There were two subtasks: subtask A focused on detecting hate speech against immigrants and women, i.e., a binary classification into hateful or not. In subtask B, a fine-grained classification had to be performed. Hateful tweets had to be further classified in terms of (i) aggressive attitude, i.e., is a tweet aggressive or non-aggressive, and (ii) target classification, i.e., is a specific target harassed or a generic group. Both tasks in subtask B are binary. For subtask A, the best systems obtained a macro-averaged F1 score of 0.651 for English and a macro-averaged F1 score of 0.73 for Spanish. For subtask B, the best systems achieved an Exact Match Ratio (EMR) of 0.570 for English and 0.705 for Spanish.</p><p>Bosco et al. <ref type="bibr" coords="3,158.69,182.89,12.87,9.46" target="#b5">[6]</ref> describe the hate speech shared task at the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian (Evalita) in 2018. Both tasks, Evalita and PAN, focused on detecting hate speech on social media (Facebook and Twitter). However, Evalita targeted hate speech detection at the post level, i.e., tweets. The PAN task focused on identifying an author as hate speech spreader based on a collection of his/her tweets, which introduced additional fuzziness to the challenging task of defining and detecting hate speech. Nine out of ten Evalita participants used external resources to improve their systems, such as pre-trained embeddings, dictionaries, and datasets related to the task. The winning team achieved an F1 score of almost 80% by using additional data from a subjectivity and polarity lexicon and the SENTIPOLC dataset on sentiment analysis along with linear SVM and BiLSTM models. In our work, we also successfully experimented with additional external data. However, the data was not directly used to identify hate speech spreaders, but was used to score the tweets themselves to create a 'hate weight' for each author.</p><p>StruÃ et al. <ref type="bibr" coords="3,150.88,359.03,18.13,9.46" target="#b12">[13]</ref> summarize the 2019 GermEval shared task on identifying offensive language in Twitter data, where 'offensive' is defined as insulting, abusive, or profane language. The shared task was divided in three subtasks: (1) a binary classification into offensive and non-offensive tweets, (2) a multi-classification into insulting, abusive, profane, and non-offensive tweets, and (3) a binary classification of offensive tweets into implicitly and explicitly offensive. The dataset consisted of 7,000 tweets in total (4,000 train set, 3,000 test set). For subtask (2), the offensive tweets were divided into the three indicated groups. For subtask (3), 2,900 offensive tweets were split into 400 implicitly and 2,500 explicitly offensive tweets. The best performing system on all subtasks was a BERT model, which achieved 77%, 54%, and 73% in macro average F1 score (on subtasks (1), (2), and (3)). It was pre-trained on six million German tweets and fine-tuned on the GermEval data. The average performances of all participants obtained on the subtasks were 72%, 47%, and 67%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>We experimented with different approaches and methods, using both deep learning, i.e. neural networks, and machine learning, i.e. more traditional algorithms. In the following sections, we provide an overview of the PAN dataset and its challenges before describing in detail the steps taken to obtain our final results for the task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>For both English and Spanish, the organizers provided us with a dataset containing 200 tweets for 200 authors each, indicating whether or not the author is considered as hate speech spreader. This classifies 100 authors as hate speech spreaders and 100 as legitimate users. In total, the dataset contains 40,000 tweets for each language. An overview of the dataset can be found in Table <ref type="table" coords="4,115.39,278.49,4.05,9.46" target="#tab_1">2</ref>. What makes this author profiling task so challenging is the fact that the tweets collected for an author are neither all hate speech nor all harmless. Hence, not all of the 200 tweets per hate speech spreader are hateful per se. Information on the annotation scheme or threshold (i.e., the minimum number of hateful tweets per author) for classifying an author as hate speech spreader was not provided at the time of the competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Additional Features</head><p>Inspired by the challenging mix of hate speech and harmless tweets per author, we developed additional features to weigh the amount of hateful content produced by each author. Therefore, we relied on external data, which we describe in Section 3.2.1. In recent years, many NLP applications -including text classification tasks -have been significantly improved by the use of deep learning algorithms. Hence, we decided to train a Convolutional Neural Network (CNN, <ref type="bibr" coords="4,89.29,451.25,17.62,9.46" target="#b13">[14]</ref>) with external data and applied the resulting model on the PAN data at the tweet level to generate additional features. In the following subsections, we describe this process in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">External data</head><p>To create the additional features described in Section 3.2, we searched for external data containing hate speech or hate speech related concepts such as offensive language. Since the PAN dataset consists of tweets, we looked for external data also retrieved from Twitter. Our search resulted in several good sources for English. We chose the data from (i) CONAN <ref type="bibr" coords="4,412.89,555.86,16.86,9.46" target="#b14">[15]</ref>, (ii) Davidson et al. <ref type="bibr" coords="4,103.24,569.41,16.89,9.46" target="#b15">[16]</ref>, (iii) HASOC track <ref type="bibr" coords="4,213.67,569.41,16.88,9.46" target="#b10">[11]</ref>, and (iv) SemEval-2019 Task 5 HatEval <ref type="bibr" coords="4,417.13,569.41,16.88,9.46" target="#b11">[12]</ref>. Unfortunately, there was not much data available for Spanish, so we only used the Spanish part of the HatEval dataset <ref type="bibr" coords="4,122.94,596.51,16.88,9.46" target="#b11">[12]</ref>. An overview of the sizes and the percentage of offensive tweets in the datasets is given in Table <ref type="table" coords="4,153.73,610.06,4.09,9.46" target="#tab_2">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Training of the CNN</head><p>We used the Tensorflow/Keras API<ref type="foot" coords="5,237.45,248.17,3.99,6.91" target="#foot_1">2</ref> for the implementation of the CNN. Since the input for neural networks does not require much preprocessing, we simply lowercased the external dataset and removed unwanted characters, symbols, and emojis. We implemented a character-level model with 49 features for English and 57 features for Spanish. The number of features is determined by the number of different characters present after preprocessing. After examining the character length of all tweets, we set the maximum sequence length to 300 per tweet. Keras provides a tokenizer that converts the input into a list of integers (similar to the bag-of-words approach) and a method to convert these integers into a fixed-length vector. This means that tweets containing more than 300 characters were reduced in size and shorter tweets were padded with zeros to maximum length. We trained the CNN with the following setting:</p><p>â¢ filter size: <ref type="bibr" coords="5,163.28,394.67,12.46,9.46" target="#b4">[5,</ref><ref type="bibr" coords="5,175.74,394.67,8.31,9.46" target="#b5">6,</ref><ref type="bibr" coords="5,184.05,394.67,8.31,9.46" target="#b6">7]</ref> â¢ number of filters: 100 â¢ activation: ReLU â¢ output: sigmoid We used the Adam optimizer <ref type="bibr" coords="5,224.67,461.90,18.32,9.46" target="#b16">[17]</ref> and trained the CNN for 80 epochs. After the last epoch, the model had an accuracy of 91.01% on the English external data and 92.12% on the Spanish external data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Applying the model to the PAN data</head><p>For each author, we let the model obtained by the CNN predict the class for each of his/her tweets.</p><p>We recorded the values of the predictions as 'HateCounts' and 'LoveCounts'. After classifying all tweets, we used the majority vote on these counts to predict whether an author was a hate speech spreader or not. In numbers, whenever 'HateCount' was &gt; 100, the author was classified as hate speech spreader and vice versa. Unfortunately, this resulted in an accuracy of about 0.5 for both languages. So we decided to iteratively lower the threshold of 'HateCount' from 100 to 0 to get better accuracy. For English, a threshold of 48 gave the best accuracy of 67.58%, while we obtained the best accuracy of 71.5% with a threshold of 33 for Spanish. Since these performances were not convincing, we decided to move to more traditional machine learning algorithms (see Section 3.3). Unlike deep learning models, traditional machine learning models have no sequence length limit, so we could use them to process all tweets per author at once. However, since the 'HateCounts'/'LoveCounts' showed at least some influence on the classification of hate speech spreaders, we kept them as additional features for the subsequent experiments with the traditional models. Furthermore, we obtained the class probability calculated by the CNN for each tweet and also stored the mean probabilities for each author ('ProbMean').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experiments</head><p>In the following sections, we describe our experiments using traditional methods that led us to our final models. All experiments were implemented in Python using the scikit-learn library<ref type="foot" coords="6,490.65,218.11,3.99,6.91" target="#foot_2">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Experimental setup A</head><p>In our first setup, we tested five algorithms for different features. As preprocessing, we combined all tweets of an author into one document. To mark the beginning of a new tweet, we added a special start-of-tweet token. Furthermore, the data was lowercased. As features, we used simple counts of bag-of-words and tf-idf at the word and character level. To reduce the feature space, we limited the maximum number of features to 5,000. Additional features were not considered for these experiments. We split the data into 70% for training and 30% for testing, using three different random states for splitting. The experimental results are presented in Table <ref type="table" coords="6,474.90,351.87,4.17,9.46" target="#tab_3">4</ref>. The values shown are the mean accuracy for the different data splits. The results were not sufficient, but gave us a reasonable basis on which to improve further. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Experimental setup B</head><p>For our second setup, we used the same setup as for experimental setup A, but fed the 'LoveCounts' and the 'ProbMeans' into the models as additional features to improve our performance. Since the PAN dataset contains only 200 instances in total, we also applied oversampling to the training data using the BorderlineSMOTE library from imbalanced-learn <ref type="foot" coords="7,376.45,86.00,3.99,6.91" target="#foot_3">4</ref> . In doing so, we performed oversampling for both classes rather than just one class (as usually done by SMOTE). Preliminary results showed that an oversampling of 500 gave the best results. Again, we ran experiments with the same five algorithms, but this time with five different random states for splitting into training and test sets. For English, the results obtained are shown in Table <ref type="table" coords="7,378.79,142.24,4.12,9.46" target="#tab_4">5</ref>. The results show that both the additional features and oversampling increased the model performances. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Experimental setup C</head><p>For our third setup and final experiments, we optimized our data preprocessing to achieve further improvements. The following experiments were performed for both English and Spanish, but for brevity we present only the English results. To this end, we first removed stop words by using the stop word list provided by the spaCy library <ref type="foot" coords="7,282.35,452.98,3.99,6.91" target="#foot_4">5</ref> . Second, we used an emoji sentiment recognizer <ref type="foot" coords="7,501.50,452.98,3.99,6.91" target="#foot_5">6</ref>based on the research by Novak et al. <ref type="bibr" coords="7,255.45,468.58,16.73,9.46" target="#b17">[18]</ref>. We replaced positive emojis with 'EMOJI-positive', negative emojis with 'EMOJI-negative', and the remaining ones with 'EMOJI' <ref type="foot" coords="7,445.22,480.08,3.99,6.91" target="#foot_6">7</ref> . Finally, we extracted all noun chunks from the tweets by again using the spaCy library <ref type="foot" coords="7,412.15,493.63,3.99,6.91" target="#foot_7">8</ref> . These noun chunks were then used as input for our experiments. Each word of a noun chunk was lemmatized.</p><p>As shown in Table <ref type="table" coords="7,183.41,522.77,4.07,9.46" target="#tab_5">6</ref>, we added more algorithms in addition to those from the previous setups. We used count and tf-idf vectors based on noun chunks as features, both in combination with the 'LoveCount' and 'ProbMean' features, as these were the most promising from our previous results. We did not limit the number of features for this setup. The mean accuracy for the English test set can be found in Table <ref type="table" coords="7,219.00,576.97,4.09,9.46" target="#tab_5">6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.">Beyond n-gram features</head><p>As shown in Table <ref type="table" coords="8,171.55,359.43,4.03,9.46" target="#tab_5">6</ref>, most models with tf-idf on noun chunks outperform their counterparts with bag-of-words count. Moreover, the models of the Ridge Classifier and the Linear SVM show remarkable improvements. Hence, we compared the feature importance for tf-idf vectors from n-gram and noun chunks models. Table <ref type="table" coords="8,272.06,400.07,5.56,9.46" target="#tab_6">7</ref> shows the five most positive and negative features with their weights <ref type="foot" coords="8,166.73,411.58,3.99,6.91" target="#foot_8">9</ref> . While all n-gram models indicate the importance of the words president and trump, they are not listed in the five most important features of the noun chunks model 10 . On the other hand, it should be also noted that the word white alone receives a high weighting in the 1-gram and 1-&amp; 2-gram models; the word sequence white people makes more sense in the 2-&amp; 3-gram and noun chunks models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5.">spaCy noun chunks and feature extraction</head><p>Table <ref type="table" coords="9,115.42,108.96,5.41,9.46" target="#tab_6">7</ref> shows some awkward noun chunks like illegal and y'. Therefore, we examined the posts containing these words in more detail. The word illegal occurs in 185 different posts. However, among these, the word illegals occurs in 54 different posts in 21 training documents. The noun chunk illegal refers to this use of the word. Of these, only 4 documents were classified as non-hate speech spreader. The other 21 documents were classified as hate speech spreader. From this fact, it can be concluded that the word illegal could be weighted highly for the task. In the following, some examples from the training documents are given:</p><p>â¢ The illegals took most of the blacks jobs! â¢ This is why I don't want more illegals in the USA until we take care of ALL our Vets! â¢ Why are you protecting illegals?</p><p>For example, the spaCy noun chunk module tagged The illegals as noun chunks from the first sentence. But as described in 3.3.4, the first word The is a stop word and was removed (see 3.3.3), and the word illegals has been lemmatized to illegal <ref type="foot" coords="9,316.18,280.87,7.97,6.91" target="#foot_9">11</ref> .</p><p>The word y' occurs only in the combination of y'all in 266 different posts, and the spaCy noun chunk module separates the word y' as noun chunk from the word all. For example, spaCy assigns noun chunks to three units (I, y', college) from the following sentence taken from a training post: I can see why some of y'all ain't go to college.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation on the PAN Test Sets</head><p>For the final evaluation on the test set provided by the PAN2021 shared task organizers, we applied the following algorithms and settings:</p><p>â¢ English: Linear SVM with tf-idf vectors on noun chunks â¢ Spanish: Ridge Classifier with count vectors on noun chunks On the English test set, we achieved an accuracy of 73%, on the Spanish test set an accuracy of 79%. The overall average accuracy for both languages was 76%. According to the PAN2021 Overview <ref type="bibr" coords="9,134.89,484.91,16.78,9.46" target="#b18">[19]</ref>, this corresponds to rank 8. Due to technical issues, we could not use TIRA <ref type="bibr" coords="9,482.00,484.91,20.71,9.46" target="#b19">[20]</ref>. We sent our results to the organizers by email.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>By retrieving noun chunks from the data, we employed a specific linguistic feature that proved its suitability for the classification task. As shown, it outperforms most methods based on n-gram features. In contrast to n-gram features, noun chunks form linguistically meaningful units and are therefore more comprehensible. Furthermore, we have developed the additional features 'LoveCount' and 'ProbMean', which add a kind of a 'hate weight' to each author.</p><p>In future work, we want to explore how linguistic units such as phrasal expressions, and specifically predicate-argument structures, can be obtained and embedded, and to what extent they can contribute to the classification and other tasks related to textual content.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.96,90.03,404.13,141.76"><head>Table 1</head><label>1</label><figDesc>Attitudes of political, social media, and scientific representatives on hate speech.<ref type="bibr" coords="2,446.53,102.08,11.08,9.22" target="#b7">[8]</ref> </figDesc><table coords="2,102.18,121.36,390.91,110.43"><row><cell>Source</cell><cell>Hate speech is</cell><cell cols="3">Hate speech is Hate speech Humor has</cell></row><row><cell></cell><cell>to incite</cell><cell>to attack or</cell><cell>has specific</cell><cell>a specific</cell></row><row><cell></cell><cell>violence or hate</cell><cell>disparage</cell><cell>targets</cell><cell>status</cell></row><row><cell>EU code of conduct</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>No</cell></row><row><cell>ILGA</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>No</cell></row><row><cell>Scientific paper</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell></row><row><cell>Facebook</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>YouTube</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>No</cell></row><row><cell>Twitter</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.98,90.03,347.26,85.35"><head>Table 2</head><label>2</label><figDesc>Overview of the dataset size.</figDesc><table coords="4,159.03,119.46,277.22,55.92"><row><cell>Language</cell><cell>Authors</cell><cell>Tweets</cell></row><row><cell></cell><cell cols="2"># Hate Spreaders # Legitimate Users</cell></row><row><cell>en</cell><cell>100</cell><cell>100 40,000</cell></row><row><cell>es</cell><cell>100</cell><cell>100 40,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,88.98,90.03,302.85,111.27"><head>Table 3</head><label>3</label><figDesc>Overview of the external data used for training the CNN.</figDesc><table coords="5,203.45,121.48,188.38,79.83"><row><cell cols="2">Lang dataset</cell><cell cols="2">Size % Offensive</cell></row><row><cell></cell><cell>CONAN</cell><cell>1,288</cell><cell>1.00</cell></row><row><cell>en</cell><cell cols="2">Davidson 24,802 HASOC 7,005</cell><cell>0.06 0.36</cell></row><row><cell></cell><cell>hatEval</cell><cell>13,000</cell><cell>0.40</cell></row><row><cell>es</cell><cell>hatEval</cell><cell>6,600</cell><cell>0.40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,88.98,406.22,384.75,140.44"><head>Table 4</head><label>4</label><figDesc>Mean accuracy of three runs with different random states on the English dataset.</figDesc><table coords="6,121.55,437.67,352.18,109.00"><row><cell></cell><cell></cell><cell></cell><cell>tf-idf</cell><cell></cell></row><row><cell cols="2">Algorithm Count</cell><cell>word</cell><cell></cell><cell>character</cell></row><row><cell></cell><cell></cell><cell cols="3">1-gram 2-and 3-gram 2-and 3-gram</cell></row><row><cell>Multinomial Naive Bayes</cell><cell>59.67</cell><cell>53.00</cell><cell>56.33</cell><cell>58.33</cell></row><row><cell>Logistic Regression</cell><cell>68.67</cell><cell>56.00</cell><cell>52.67</cell><cell>53.67</cell></row><row><cell>Support Vector Machine</cell><cell>51.67</cell><cell>59.00</cell><cell>53.30</cell><cell>54.30</cell></row><row><cell>Random Forest</cell><cell>57.00</cell><cell>61.67</cell><cell>57.00</cell><cell>60.00</cell></row><row><cell>Extreme Gradient Boosting</cell><cell>63.00</cell><cell>63.67</cell><cell>53.00</cell><cell>59.33</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,88.98,183.05,417.01,174.21"><head>Table 5</head><label>5</label><figDesc>Mean accuracy of five runs with different random states and SMOTE=500. LC is the count of non-hate tweets and PM is the mean of the probabilities obtained from the CNN on the English dataset.</figDesc><table coords="7,112.58,236.31,370.12,120.95"><row><cell></cell><cell></cell><cell></cell><cell>tf-idf</cell><cell></cell></row><row><cell>Algorithm</cell><cell>Count</cell><cell>word</cell><cell></cell><cell>character</cell></row><row><cell></cell><cell></cell><cell cols="3">1-gram 2-and 3-gram 2-and 3-gram</cell></row><row><cell></cell><cell cols="2">LC + PM LC + PM</cell><cell>LC + PM</cell><cell>LC + PM</cell></row><row><cell>Multinomial Naive Bayes</cell><cell>65.0</cell><cell>66.2</cell><cell>51.8</cell><cell>52.6</cell></row><row><cell>Logistic Regression</cell><cell>62.0</cell><cell>65.6</cell><cell>63.0</cell><cell>63.4</cell></row><row><cell>Support Vector Machine</cell><cell>61.8</cell><cell>68.2</cell><cell>64.4</cell><cell>62.8</cell></row><row><cell>Random Forest</cell><cell>63.0</cell><cell>57.4</cell><cell>63.0</cell><cell>60.8</cell></row><row><cell>Extreme Gradient Boosting</cell><cell>62.8</cell><cell>59.8</cell><cell>58.8</cell><cell>61.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,88.98,90.03,381.94,220.49"><head>Table 6</head><label>6</label><figDesc>Mean accuracy of five runs with different random states on the English dataset.</figDesc><table coords="8,124.36,117.95,346.56,192.57"><row><cell cols="3">Algorithm Count + LC + PM tf-idf + LC + PM</cell></row><row><cell>Multinomial Naive Bayes</cell><cell>60.00</cell><cell>60.33</cell></row><row><cell>Logistic Regression</cell><cell>62.33</cell><cell>68.66</cell></row><row><cell>Linear Support Vector Machine</cell><cell>60.67</cell><cell>71.00</cell></row><row><cell>Random Forest</cell><cell>61.33</cell><cell>54.67</cell></row><row><cell>Extreme Gradient Boosting</cell><cell>57.67</cell><cell>58.00</cell></row><row><cell>Decision Tree Classifier</cell><cell>53.67</cell><cell>56.67</cell></row><row><cell>Bernoulli Naive Bayes</cell><cell>57.33</cell><cell>57.33</cell></row><row><cell>Complement Naive Bayes</cell><cell>60.00</cell><cell>62.33</cell></row><row><cell>Stochastic Gradient Descent Classifier</cell><cell>63.33</cell><cell>66.33</cell></row><row><cell>Passive Agressive Classifier</cell><cell>62.00</cell><cell>68.00</cell></row><row><cell>Ridge Classifier</cell><cell>62.00</cell><cell>71.33</cell></row><row><cell>Perceptron</cell><cell>61.00</cell><cell>66.33</cell></row><row><cell>KNeighbors Classifier</cell><cell>59.33</cell><cell>59.33</cell></row><row><cell>Nearest Centroid</cell><cell>59.00</cell><cell>65.00</cell></row><row><cell>Support Vector Machine</cell><cell>58.67</cell><cell>67.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.98,495.08,412.39,134.51"><head>Table 7</head><label>7</label><figDesc>Feature comparison of n-grams and noun chunks.</figDesc><table coords="8,93.91,522.64,407.46,106.95"><row><cell>1-gram</cell><cell>1-&amp; 2-gram</cell><cell>2-&amp; 3-gram</cell><cell>noun chunks</cell></row><row><cell>0.8890 president</cell><cell>0.6595 president</cell><cell>0.3317 president trump</cell><cell>0.7242 america</cell></row><row><cell>0.8189 white</cell><cell>0.5830 white</cell><cell>0.3019 white people</cell><cell>0.5982 people</cell></row><row><cell>0.7803 people</cell><cell>0.5420 trump</cell><cell>0.2826 vote supports</cell><cell>0.5747 white people</cell></row><row><cell>0.7361 border</cell><cell>0.4968 people</cell><cell>0.2506 laughing ent</cell><cell>0.5553 em</cell></row><row><cell>0.7026 niggas</cell><cell>0.4860 border</cell><cell>0.2506 emoji laughing ent</cell><cell>0.5405 illegal</cell></row><row><cell cols="3">-0.5680 automatically -0.4994 automatically checked -0.5223 automatically checked</cell><cell>-1.0312 person</cell></row><row><cell>-0.5355 bbc</cell><cell>-0.4882 bbc</cell><cell>-0.5013 emoji positive</cell><cell>-0.7812 y'</cell></row><row><cell>-0.5326 amp</cell><cell>-0.4020 cum</cell><cell>-0.4239 emoji negative</cell><cell>-0.6077 work</cell></row><row><cell>-0.5247 yal</cell><cell>-0.3851 sagittarius</cell><cell>-0.3539 followed automatically</cell><cell>-0.4635 bbc</cell></row><row><cell>-0.4966 cum</cell><cell>-0.3831 automatically</cell><cell cols="2">-0.3539 followed automatically checked -0.4578 sagittarius</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,671.91,231.20,7.77"><p>The three languages provided were English, Hindi, and German.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,108.93,671.92,188.05,7.77"><p>https://www.tensorflow.org/api_docs/python/tf/keras</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,108.93,671.88,144.16,7.77"><p>https://scikit-learn.org/stable/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,108.93,605.55,127.59,7.77"><p>https://imbalanced-learn.org/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="7,108.93,616.70,171.72,7.77"><p>https://spacy.io/usage/spacy-101#language-data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="7,108.93,627.85,397.28,7.77;7,89.29,638.81,360.27,7.77"><p>https://github.com/FLAIST/emosent-py. This was adapted, further developed, and made available for our work by D. Schwimmbeck from the Research Institute CODE, Bundeswehr University Munich, Germany.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="7,108.93,649.80,397.05,7.77;7,88.97,660.76,166.32,7.77"><p>We did not distinguish between one or more consecutive emojis: All consecutive occurrences of the same emoji were replaced by a corresponding counterpart.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="7,108.93,671.91,195.78,7.77"><p>https://spacy.io/usage/linguistic-features#noun-chunks</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="8,108.93,649.81,397.06,7.77;8,89.29,660.77,323.51,7.77"><p>n-grams were obtained by the standard word analyzer with stop words elimination for English, while the noun chunks by spaCy noun chunks. The first word was removed from them if it is a stop word.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9" coords="9,108.93,671.93,200.26,7.77"><p>https://spacy.io/usage/linguistic-features#lemmatization</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is partially funded by dtec.bw <rs type="funder">-Digitalization and Technology Research Center of the Bundeswehr</rs> within the project <rs type="projectName">MuQuaNet</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_aaFFYYF">
					<orgName type="project" subtype="full">MuQuaNet</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.92,186.39,394.97,9.46;10,112.92,199.94,358.73,9.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,190.37,186.39,204.56,9.46">Twitter Announces First Quarter 2021 Results</title>
		<ptr target="https://s22.q4cdn.com/826641620/files/doc_financials/2021/q1/Q1&apos;21-Earnings-Release.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,112.92,186.39,69.66,9.46">Yahoo! Finance</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,213.49,393.67,9.46;10,112.53,227.04,103.69,9.46" xml:id="b1">
	<monogr>
		<ptr target="https://www.coe.int/en/web/no-hate-campaign" />
		<title level="m" coord="10,112.92,213.49,229.82,9.46">Council of Europe, No Hate Speech Youth Campaign</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,240.59,114.35,9.46;10,242.42,240.59,265.37,9.46;10,112.92,254.14,13.54,9.46;10,142.79,254.14,18.54,9.46;10,177.66,254.14,30.28,9.46;10,224.26,254.14,30.60,9.46;10,274.59,254.14,25.04,9.46;10,315.95,254.14,25.35,9.46;10,357.63,254.14,148.96,9.46;10,112.92,267.69,372.44,9.46;10,112.92,281.23,261.67,9.46" xml:id="b2">
	<monogr>
		<ptr target="https://ec.europa.eu/info/policies/justice-and-fundamental-rights/combatting-discrimination/racism-and-xenophobia/eu-code-conduct-countering-illegal-hate-speech-online_en" />
		<title level="m" coord="10,242.42,240.59,265.37,9.46;10,112.92,254.14,13.54,9.46;10,142.79,254.14,18.54,9.46;10,177.66,254.14,30.28,9.46;10,224.26,254.14,26.23,9.46">The EU Code of conduct on countering illegal hate speech online</title>
		<imprint>
			<publisher>European Commission</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,294.78,393.06,9.46;10,112.92,308.33,23.79,9.46;10,163.46,308.33,25.04,9.46;10,210.44,308.33,25.35,9.46;10,257.73,308.33,248.86,9.46;10,112.92,321.88,255.49,9.46" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hern</surname></persName>
		</author>
		<ptr target="https://www.theguardian.com/technology/2016/may/31/facebook-youtube-twitter-microsoft-eu-hate-speech-code" />
		<title level="m" coord="10,168.22,294.78,337.76,9.46;10,112.92,308.33,19.03,9.46">Facebook, YouTube, Twitter and Microsoft sign EU hate speech code</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,335.43,393.07,9.46;10,112.92,348.98,393.34,9.46;10,112.92,362.53,130.54,9.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,408.63,335.43,97.36,9.46;10,112.92,348.98,150.05,9.46">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>SarracÃ©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="10,309.68,348.98,144.89,9.46">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="10,462.54,348.98,43.71,9.46;10,112.92,362.53,57.34,9.46">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,376.08,393.06,9.46;10,112.92,389.63,393.06,9.46;10,112.56,403.18,393.43,9.46;10,112.92,416.73,393.06,9.46;10,112.92,430.28,393.25,9.46;10,112.10,443.64,395.40,9.64;10,112.92,457.37,185.51,9.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,430.48,376.08,75.50,9.46;10,112.92,389.63,188.66,9.46">Overview of the EVALITA 2018 hate speech detection task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Dell'orletta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2263/paper010.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,145.84,403.18,360.15,9.46;10,112.92,416.73,393.06,9.46;10,112.92,430.28,285.07,9.46">Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</title>
		<title level="s" coord="10,243.56,443.64,161.81,9.64">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Caselli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Novielli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<meeting>the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">December 12-13, 2018. 2018</date>
			<biblScope unit="volume">2263</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,470.92,393.06,9.46;10,112.54,484.47,393.72,9.46;10,112.92,498.02,394.43,9.46;10,112.92,511.57,310.53,9.46" xml:id="b6">
	<monogr>
		<ptr target="https://www.aclweb.org/anthology/2020.osact-1.0" />
		<title level="m" coord="10,424.54,470.92,81.44,9.46;10,112.54,484.47,393.72,9.46;10,112.92,498.02,147.91,9.46">Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Al-Khalifa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Magdy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Darwish</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</editor>
		<meeting>the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resource Association</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,525.12,393.06,9.46;10,112.92,538.67,148.46,9.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,220.95,525.12,245.14,9.46">a survey on automatic detection of hate speech in text</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,481.08,525.12,24.90,9.46;10,112.92,538.67,86.65,9.46">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,552.22,393.06,9.46;10,112.92,565.77,394.43,9.46;10,112.92,579.32,393.06,9.46;10,112.41,592.87,393.96,9.46;10,112.92,606.42,393.06,9.46;10,112.56,619.96,137.26,9.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,458.39,552.22,47.59,9.46;10,112.92,565.77,394.43,9.46;10,112.92,579.32,287.13,9.46">Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis, Originally published in Bochumer Linguistische Arbeitsberichte</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>RoÃ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rist</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Cabrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kurowsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Wojatzki</surname></persName>
		</author>
		<idno>) 6-9</idno>
	</analytic>
	<monogr>
		<title level="m" coord="10,419.81,579.32,86.17,9.46;10,112.41,592.87,374.56,9.46">NLP4CMC III: 3rd Workshop on Natural Language Processing for Computer-Mediated Communication</title>
		<editor>
			<persName><forename type="first">Michael</forename><surname>BeiÃwenger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Wojatzki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016-09-22">22 September 2016. 2016</date>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.92,633.51,393.06,9.46;10,112.92,647.06,393.06,9.46;10,112.92,660.61,153.93,9.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,167.52,633.51,338.46,9.46;10,112.92,647.06,88.02,9.46">Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Waseem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,228.12,647.06,277.86,9.46;10,112.92,660.61,62.07,9.46">Proceedings of the First Workshop on NLP and Computational Social Science</title>
		<meeting>the First Workshop on NLP and Computational Social Science</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,88.05,393.46,9.46;11,112.92,101.60,394.87,9.46;11,112.92,115.14,394.43,9.46;11,112.92,128.69,394.97,9.46;11,112.92,142.24,170.25,9.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,462.94,88.05,43.44,9.46;11,112.92,101.60,394.87,9.46;11,112.92,115.14,82.29,9.46">Overview of the hasoc track at fire 2019: Hate speech and offensive content identification in indoeuropean languages</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mandlia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3368567.3368584</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,217.09,115.14,290.26,9.46;11,112.92,128.69,40.28,9.46">Proceedings of the 11th Forum for Information Retrieval Evaluation, FIRE &apos;19</title>
		<meeting>the 11th Forum for Information Retrieval Evaluation, FIRE &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,155.79,394.43,9.46;11,112.92,169.34,393.06,9.46;11,112.92,182.89,394.87,9.46;11,112.92,196.44,394.43,9.46;11,112.92,209.99,394.97,9.46;11,112.92,223.54,151.11,9.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,192.12,169.34,313.86,9.46;11,112.92,182.89,156.38,9.46">SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Rangel Pardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
		<ptr target="https://www.aclweb.org/anthology/S19-2007.doi:10.18653/v1/S19-2007" />
	</analytic>
	<monogr>
		<title level="m" coord="11,302.78,182.89,205.01,9.46;11,112.92,196.44,328.05,9.46">Proceedings of the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics</title>
		<meeting>the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,237.09,393.06,9.46;11,112.58,250.64,393.58,9.46;11,112.92,264.19,393.07,9.46;11,112.92,277.74,394.37,9.46;11,112.92,292.31,68.68,7.68" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,403.71,237.09,102.27,9.46;11,112.58,250.64,321.50,9.46">Overview of GermEval Task 2, 2019 Shared Task on the Identification of Offensive Language</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>StruÃ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Klenner</surname></persName>
		</author>
		<idno type="DOI">10.5167/uzh-178687</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,257.63,264.19,248.36,9.46;11,112.92,277.74,106.34,9.46">Proceedings of the 15th Conference on Natural Language Processing (KONVENS)</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Linguistics</surname></persName>
		</editor>
		<meeting>the 15th Conference on Natural Language Processing (KONVENS)<address><addrLine>NÃ¼rnberg/Erlangen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="354" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,304.83,393.06,9.46;11,112.92,318.38,279.71,9.46" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,307.62,304.83,198.36,9.46;11,112.92,318.38,48.05,9.46">Gradient-based learning applied to document recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,184.17,318.38,105.01,9.46">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,331.93,393.06,9.46;11,112.92,345.48,394.58,9.46;11,112.92,359.03,394.43,9.46;11,112.53,372.58,394.97,9.46;11,112.92,386.13,352.57,9.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,367.99,331.93,137.99,9.46;11,112.92,345.48,374.31,9.46">CONAN -COunter NArratives through nichesourcing: a multilingual dataset of responses to fight online hate speech</title>
		<author>
			<persName coords=""><forename type="first">Y.-L</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kuzmenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Tekiroglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1271</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1271.doi:10.18653/v1/P19-1271" />
	</analytic>
	<monogr>
		<title level="m" coord="11,112.92,359.03,394.43,9.46;11,112.53,372.58,189.29,9.46">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2819" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,399.68,393.06,9.46;11,112.92,413.23,393.06,9.46;11,112.92,426.78,262.13,9.46" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,324.29,399.68,181.69,9.46;11,112.92,413.23,128.87,9.46">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,265.05,413.23,240.94,9.46;11,112.92,426.78,170.54,9.46">Proceedings of the 11th International AAAI Conference on Web and Social Media, ICWSM &apos;17</title>
		<meeting>the 11th International AAAI Conference on Web and Social Media, ICWSM &apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,440.33,394.43,9.46;11,112.29,453.87,395.06,9.46;11,112.92,467.42,394.58,9.46;11,112.62,480.97,114.27,9.46" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,256.35,440.33,170.06,9.46">A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m" coord="11,189.80,453.87,312.54,9.46">3rd International Conference on Learning Representations, ICLR 2015</title>
		<title level="s" coord="11,287.35,467.42,135.36,9.46">Conference Track Proceedings</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,494.52,393.06,9.46;11,112.56,508.07,283.27,9.46" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,344.21,494.52,87.04,9.46">Sentiment of emojis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">Kralj</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>SmailoviÄ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sluban</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>MozetiÄ</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0144296</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,439.79,494.52,52.42,9.46">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">144296</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,521.62,394.43,9.46;11,112.92,535.17,394.43,9.46;11,112.92,548.72,393.06,9.46;11,112.92,562.27,393.06,9.46;11,112.92,575.82,242.59,9.46" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,229.32,548.72,276.66,9.46;11,112.92,562.27,242.16,9.46">Overview of PAN 2021: Authorship Verification,Profiling Hate Speech Spreaders on Twitter,and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>SarracÃ©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,377.83,562.27,128.15,9.46;11,112.92,575.82,168.03,9.46">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.92,589.37,394.43,9.46;11,112.92,602.92,393.07,9.46;11,112.92,616.47,394.97,9.46;11,112.92,630.01,198.42,9.46" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,329.13,589.37,173.72,9.46">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,244.71,602.92,261.27,9.46;11,112.92,616.47,124.55,9.46">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg/New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="123" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
