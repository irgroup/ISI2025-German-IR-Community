<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,411.81,15.42;1,88.59,106.66,141.30,15.42;1,89.29,129.00,157.29,11.96">Hate speech spreader detection using contextualized word embeddings Notebook for PAN at CLEF 2021</title>
				<funder ref="#_bAhUSma">
					<orgName type="full">RFBR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,83.70,11.96"><forename type="first">Evgeny</forename><surname>Finogeev</surname></persName>
							<email>finogeev@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.63,154.90,93.72,11.96"><forename type="first">Mariam</forename><surname>Kaprielova</surname></persName>
							<email>kaprielova@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Moscow Institute of Physics and Technology (MIPT)</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.28,154.90,86.29,11.96"><forename type="first">Artem</forename><surname>Chashchin</surname></persName>
							<email>chashchin@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Skolkovo Institute of Science and Technology (Skoltech)</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,168.85,98.41,11.96"><forename type="first">Kirill</forename><surname>Grashchenkov</surname></persName>
							<email>grashchenkov@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Skolkovo Institute of Science and Technology (Skoltech)</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Institute of Oceanology (IO RAS)</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.93,168.85,91.17,11.96"><forename type="first">George</forename><surname>Gorbachev</surname></persName>
							<email>gorbachev@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.09,168.85,71.31,11.96"><forename type="first">Oleg</forename><surname>Bakhteev</surname></persName>
							<email>bakhteev@ap-team.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Antiplagiat</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Moscow Institute of Physics and Technology (MIPT)</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Dorodnicyn Computing Center RAS</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,411.81,15.42;1,88.59,106.66,141.30,15.42;1,89.29,129.00,157.29,11.96">Hate speech spreader detection using contextualized word embeddings Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4CF8245D6558FBB25C7567730948109F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BERT</term>
					<term>contextualized word embeddings</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>he paper presents a method of hate speech spreaders recognition developed for the task of "Profiling Hate Speech Spreaders on Twitter" at the PAN@CLEF Conference 2021. Hate speech is an increasing problem nowadays. Due to the spread of the internet and the rise of social media, people with hostile views towards certain groups post hateful messages on social media resources. In this paper, we present a model to detect hate speech spreaders based on their Twitter posts. We aggregate contextualized embeddings of single tweets to form a vector representation for every user and employ classification methods to find users spreading hate speech. We analyze different embedding models based on BERT architecture for the problem. The submitted model achieves 67% in terms of accuracy for the English part of the dataset and 83% for the Spanish part of the dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Hate speech detection in social networks is a significant social issue nowadays. A large number of works is devoted to hate speech detection in the social media domain <ref type="bibr" coords="1,421.64,489.77,11.49,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,436.15,489.77,7.52,10.91" target="#b1">2,</ref><ref type="bibr" coords="1,446.69,489.77,7.65,10.91" target="#b2">3]</ref>. There are variety of methods of hate speech detection. Most of them consider the problem as a supervised document classification task <ref type="bibr" coords="1,213.43,516.87,11.28,10.91" target="#b0">[1]</ref>. The approaches can be divided into two categories: either based on manual feature engineering <ref type="bibr" coords="1,228.05,530.42,11.28,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,242.07,530.42,8.91,10.91" target="#b2">3]</ref> and using classic methods or deep learning-based models which employ neural networks to automatically learn abstract features from raw data <ref type="bibr" coords="1,473.24,543.97,11.36,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,487.32,543.97,7.57,10.91" target="#b4">5]</ref>.</p><p>Hate Speech Spreaders profiling task considers the problem of hate speech detection in social networks <ref type="bibr" coords="1,133.50,571.06,11.33,10.91" target="#b5">[6,</ref><ref type="bibr" coords="1,147.56,571.06,7.67,10.91" target="#b6">7]</ref>: given a set of tweets written by a user, one should establish, whether the user can potentially spread hate speech or not. The tweets are written in two languages: English and Spanish. The training dataset contains 200 sets of tweets for each language. There are 100 sets for users that can spread hate speech and 100 sets for ordinary users. The performance metric for this task is accuracy.</p><p>The main challenge of the current task is that the analysed object is not a single tweet, but a collection of messages posted by a user. Even if the developed method detects a content without hate speech in some of the user's posts, the same user still can be classified as a potential hate speech spreader. In this way, hate speech detection is similar to the previous fake news detection task <ref type="bibr" coords="2,109.95,181.81,11.29,10.91" target="#b7">[8]</ref>. The key idea for many approaches to such tasks is to aggregate information contained in all the texts written by the author. We employ a neural network-based approach for such aggregation.</p><p>Recent studies show that approaches, based on embedding generation and their further classification can be quite effective in hate speech detection. For example, in <ref type="bibr" coords="2,422.72,236.01,12.68,10.91" target="#b8">[9]</ref> authors present a solution involving hybrid embeddings based on TF-IDF for word-level feature extraction, LSTM for sentence-level feature extraction and also naïve Bayes to extract topics from tweets. Those embeddings are then used as an input for improved cuckoo search neural network. In <ref type="bibr" coords="2,488.23,276.66,17.76,10.91" target="#b9">[10]</ref> authors proposed an approach which first used LSTM to perform word embeddings and then CNN was used for hate speech classification. One of the most impressive deep learning-based architectures to obtain semantic information stored in short texts is BERT <ref type="bibr" coords="2,411.02,317.30,16.08,10.91" target="#b10">[11]</ref>. The embeddings obtained from BERT are used to classify whether a user can spread hate speech or not. In this paper, we employ different BERT-based architectures to obtain embeddings for every tweet in the collection. We also analyze model performance after fine-tuning on the external corpus of tweets <ref type="bibr" coords="2,121.06,371.50,16.25,10.91" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>The following section describes the proposed method of hate speech spreader detection.</p><p>Similar to the previous year's task <ref type="bibr" coords="2,263.68,443.67,16.41,10.91" target="#b12">[13]</ref>, we consider the current task as a classification problem, where the classified object is a collection of tweets.</p><p>There is a given dataset D = (𝑥 𝑖 , 𝑦 𝑖 ):</p><formula xml:id="formula_0" coords="2,150.58,492.71,294.11,15.55">𝑥 𝑖 = {𝑥 1 𝑖 , . . . , 𝑥 𝑚 𝑖 }, 𝑥 𝑗 𝑖 ∈ W + , 𝑗 ∈ {1, . . . , 𝑚}, 𝑦 𝑖 ∈ {0, 1},</formula><p>where W + corresponds to all the possible strings written in the given language. The label 𝑦 𝑖 = 1 corresponds to users that are likely to spread hate speech, 𝑦 𝑖 = 0 corresponds to ordinary users. Formally, the task is to find the binary classifier that minimizes an empirical risk on the dataset D:</p><formula xml:id="formula_1" coords="2,225.09,571.37,145.10,26.50">𝑓 = arg min 𝑓 ∈F ∑︁ 𝑥 𝑖 ,𝑦 𝑖 ∈D [𝑓 (𝑥 𝑖 ) ̸ = 𝑦 𝑖 ],</formula><p>where F is a set of all considered classification models.</p><p>For the proposed problem solution we employ a deep learning-based approach: each tweet is vectorized using a deep learning model. After that, we aggregate the obtained vectors and use the resulting averaged vector as a feature set for the classifier.</p><p>The proposed method is illustrated in Figure <ref type="figure" coords="2,300.79,659.27,3.73,10.91" target="#fig_0">1</ref>. The method consists of 3 main components: </p><formula xml:id="formula_2" coords="3,277.17,374.79,68.20,33.71">e 𝑗 𝑖 = 1 𝑚 𝑚 ∑︁ 𝑗=1 e 𝑖 .</formula><p>3. The resulting classifier that uses averaged tweet vector e 𝑖 as an input feature set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment Details</head><p>To validate our models we conducted a computational experiment. Since we use a standard BERT tokenizer, we did not use any special preprocessing for our method. For all the analyzed models we used 𝑘-fold cross-validation with 𝑘 = 10. The results are presented in Table <ref type="table" coords="3,478.17,599.23,3.72,10.91" target="#tab_0">1</ref>. The test accuracy was evaluated using TIRA environment <ref type="bibr" coords="3,329.54,612.78,16.25,10.91" target="#b13">[14]</ref>.</p><p>Inspired by the author profiling task from the previous year <ref type="bibr" coords="3,363.22,626.32,12.68,10.91" target="#b7">[8]</ref> we used a char 𝑛-gram based model as a baseline. We used principal component analysis <ref type="bibr" coords="3,354.67,639.87,17.90,10.91" target="#b14">[15]</ref> with component number 𝑑 to reduce the feature set and make the 𝑛-gram feature space denser. The n-gram order 𝑛 and the component number 𝑑 was selected using cross-validation.</p><p>Since the dataset contains texts in two languages, we initially decided to use a pretrained multilingual BERT model <ref type="bibr" coords="4,208.00,100.52,18.07,10.91" target="#b10">[11]</ref> for the vectorization. We analyzed its performance with two classifiers: support vector machine <ref type="bibr" coords="4,242.03,114.06,17.76,10.91" target="#b15">[16]</ref> and logistic regression. For each classification algorithm, the optimal parameters for cross-validation were selected using GridSearch. Based on the results in Table <ref type="table" coords="4,128.20,141.16,3.79,10.91" target="#tab_0">1</ref>, it is clear that this approach works well for Spanish, but shows poor performance on English data. We decided to use Multilingual BERT for the processing of Spanish and use a different model for English. In order to improve our quality in the English part of the dataset we analyzed the following models:</p><p>• LaBSE <ref type="bibr" coords="4,147.17,204.33,16.08,10.91" target="#b16">[17]</ref>, a multilingual model with BERT architecture. The main feature of this model is that all the languages supported by LaBSE share a common hidden space that can potentially improve our model generalization. • BERT-Base, the pretrained model that was trained only on the English texts;</p><p>• BERT-base tuned on the external corpus of the tweets. The main idea of this approach is to fine-tune the lexical and semantic properties of the model on the tweet corpus in order to make the model more receptive to the specific Twitter lexicon.</p><p>Note that since the training dataset has rather small information for BERT model tuning, we did not consider the idea of fine-tuning straightforwardly on the current training dataset. Therefore we only tuned the model on the external tweet collection in an unsupervised manner it was originally trained. Some tokens in the sentences were masked, and the model tried to predict them. The predicted tokens were fed into a softmax layer to get the output words. Such procedure does not require additional labeling of external data and allows BERT to focus more on the Twitter posts than the English and Spanish texts in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LaBSE vectorization.</head><p>Although the LaBSE model shares the common hidden space for all the languages including Spanish and English, we did not find any quality improvement in comparison to the basic architecture and other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BERT-base.</head><p>The pretrained BERT-base model was trained only on English texts, so we suggest that using it as a vectorizer for English tweets might improve accuracy. Our assumption that BERT-base single-language model shows better performance than the multilingual model on an English-only task is confirmed by cross-validation results. When using this model, we did not make any changes to the architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BERT-based model fine-tuned on the external tweet corpus.</head><p>Given that BERT model base was trained on a large collection of English texts from Wikipedia , we assume that it needs fine-tuning on the data related to our problem, since tweets often use specific slang, syntax, emoji etc. In order to improve the quality of vector representation we took a large corpus of tweets <ref type="bibr" coords="4,133.66,613.91,16.42,10.91" target="#b11">[12]</ref>, which contains 1,600,000 tweets in English, and fine-tuned the model on this dataset in masked language model task regime. For all 1,600,000 tweets from the additional dataset, we replaced links, hashtags and user mentions with tokens from the training dataset (#URL#, #HASHTAG#, #USER# respectively). We also added these tokens to the BERT tokenizer dictionary. The use of additional training improved the accuracy.</p><p>As we can see, the resulting model shows a competitive performance in comparison to the baseline model. The cross-validation accuracy has increased from 0.68 to 0.72 on English part of the dataset and from 0.79 to 0.8 on its Spanish part. We got a rather significant improvement on English data by tuning the model in an unsupervised manner on the external corpus of tweets. We also observe a slight increase in performance on Spanish tweets.</p><p>The submitted English model achieves 67% in terms of accuracy on the test set, while the Spanish model shows the accuracy 83%.</p><p>For further analysis, we made a t-SNE transformation <ref type="bibr" coords="5,341.95,181.81,17.92,10.91" target="#b17">[18]</ref> for each averaged user vector e 𝑖 in two dimensional space and visualized them according to their class. The result is shown in Figure <ref type="figure" coords="5,120.36,208.91,4.18,10.91" target="#fig_1">2</ref>,3 for English and Spanish, respectively. As we can see, the obtained projection poorly separates averaged user vectors, which indicates that this method needs to be potentially improved.</p><p>We also built an LDA topic model <ref type="bibr" coords="5,251.54,509.29,17.83,10.91" target="#b18">[19]</ref> for the English part of the dataset in order to analyze the topic distributions across the tweets. For the topic model, we used 10 topics. The resulting t-SNE projection is shown in Figure <ref type="figure" coords="5,253.51,536.39,3.79,10.91" target="#fig_2">3</ref>. We analyzed the words mostly corresponding to each topic. Although we could not find a total interpretability of the obtained topics we noticed that some of them correspond to the US politics ("Biden", "Trump", "President", "Wall", "American" in the top words of the topic), US elections ( "Biden", "Trump", "Election", "Voters", "Democrats", "Republicans", "Court" in the top words of the topic), COVID-19 ("Covid", "19", "Virus" in the top words of the topic). This makes us believe that clustering tweets using some topic modeling approach and employing information about topic distribution across the user tweets for the decision about hate speech spreading.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>The paper describes an approach to the problem of hate speech spreaders detection. We proposed a model to detect hate speech spreaders using contextualized embeddings of single tweets. We aggregate the obtained vectors and use their average vector as a feature set for the further classification. We also provide an analysis of different vectorization models based on the BERT architecture. The resulting model shows an accuracy of about 67% for the English test dataset and 83% for the Spanish test dataset. The future work includes a detailed analysis of topic distribution across the tweets and usage of this information in the final decision rule.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,497.40,200.46,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The scheme of the proposed approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,452.54,271.83,8.93;5,141.38,231.62,312.53,208.36"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The t-SNE projection for the English part of the dataset.</figDesc><graphic coords="5,141.38,231.62,312.53,208.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,89.29,305.11,274.03,8.93;6,141.38,84.19,312.53,208.36"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The t-SNE projection for the Spanish part of the dataset.</figDesc><graphic coords="6,141.38,84.19,312.53,208.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,89.29,571.03,416.69,8.93;6,89.29,583.04,416.69,8.87;6,89.29,594.99,356.40,8.87;6,140.13,331.96,312.51,231.64"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The t-SNE projection for topics obtained from the English part of the dataset. The light-green points correspond to the tweets about US politics, the black points correspond to the tweets about the US presidential elections, the orange points correspond to the tweets about COVID-19.</figDesc><graphic coords="6,140.13,331.96,312.51,231.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,418.20,273.43"><head>Table 1</head><label>1</label><figDesc>Overall results for the experiments.</figDesc><table coords="3,95.68,118.53,403.92,194.22"><row><cell cols="2">English part of the dataset</cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Cross-validation accuracy Test accuracy</cell></row><row><cell>Character n-grams, 𝑑 = 20, 𝑛 = 3</cell><cell>0.68</cell><cell>-</cell></row><row><cell>BERT-multilingual, SVM (kernel -RBF)</cell><cell>0.69</cell><cell>0.58</cell></row><row><cell>BERT-multilingual, Logistic regression</cell><cell>0.64</cell><cell>-</cell></row><row><cell>LaBSE, SVM (kernel -RBF)</cell><cell>0.63</cell><cell>-</cell></row><row><cell>BERT-base, SVM (kernel -RBF)</cell><cell>0.70</cell><cell>-</cell></row><row><cell>BERT-base, Logistic regression</cell><cell>0.68</cell><cell>-</cell></row><row><cell cols="2">BERT-base with fine-tuning, SVM (kernel -RBF) 0.72</cell><cell>0.67</cell></row><row><cell>BERT-base with fine-tuning, Logistic regression</cell><cell>0.68</cell><cell>-</cell></row><row><cell cols="2">Spanish part of the dataset</cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Cross-validation accuracy Test accuracy</cell></row><row><cell>Character n-grams, 𝑑 = 50, 𝑛 = 6</cell><cell>0.79</cell><cell>-</cell></row><row><cell>BERT-multilingual, SVM (kernel -RBF)</cell><cell>0.80</cell><cell>0.83</cell></row><row><cell>BERT-multilingual, Logistic regression</cell><cell>0.79</cell><cell>-</cell></row><row><cell>LaBSE, SVM (kernel -RBF)</cell><cell>0.8</cell><cell>-</cell></row></table><note coords="3,103.64,338.10,217.93,10.91;3,321.57,335.53,3.42,6.99;3,321.57,344.09,2.88,6.99;3,328.68,338.10,85.52,10.91;3,414.20,335.53,3.42,6.99;3,414.20,344.09,2.88,6.99;3,418.58,338.10,2.40,10.91;3,103.64,353.00,403.55,10.91"><p><p>1. BERT model that extracts embedding vector e 𝑗</p>𝑖 from every tweet 𝑥 𝑗 𝑖 . 2. Aggregation operation that averages the information across all the tweets of the author:</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is funded by <rs type="funder">RFBR</rs>, grant <rs type="grantNumber">19-29-14100</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bAhUSma">
					<idno type="grant-number">19-29-14100</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,309.83,393.33,10.91;7,112.66,323.38,214.37,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,192.23,309.83,313.76,10.91;7,112.66,323.38,59.25,10.91">Hate speech detection: A solved problem? the challenging case of long tail on twitter</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,179.86,323.38,63.24,10.91">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="925" to="945" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,336.93,393.33,10.91;7,112.66,350.47,393.57,10.91;7,112.33,364.02,68.33,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,241.13,336.93,264.85,10.91;7,112.66,350.47,301.33,10.91">Cyber hate speech on twitter: An application of machine classification and statistical modeling for policy and decision making</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,423.02,350.47,75.46,10.91">Policy &amp; internet</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="223" to="242" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,377.57,393.32,10.91;7,112.66,391.12,393.32,10.91;7,112.14,404.67,177.10,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,320.17,377.57,185.81,10.91;7,112.66,391.12,131.24,10.91">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,267.09,391.12,238.90,10.91;7,112.14,404.67,95.68,10.91">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,418.22,394.61,10.91;7,112.66,431.77,350.18,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,226.69,418.22,261.05,10.91">Using convolutional neural networks to classify hate-speech</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gambäck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">K</forename><surname>Sikdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,112.66,431.77,272.69,10.91">Proceedings of the first workshop on abusive language online</title>
		<meeting>the first workshop on abusive language online</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="85" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,445.32,393.33,10.91;7,112.66,458.87,359.21,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,328.62,445.32,177.36,10.91;7,112.66,458.87,190.00,10.91">To ban or not to ban: Bayesian attention networks for reliable hate speech detection</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Miok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Škrlj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Robnik-Šikonja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,310.95,458.87,105.08,10.91">Cognitive Computation</title>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,472.42,394.53,10.91;7,112.66,485.97,395.17,10.91;7,112.66,499.52,393.33,10.91;7,112.66,513.06,393.33,10.91;7,112.66,526.61,222.66,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,194.78,499.52,311.21,10.91;7,112.66,513.06,221.30,10.91">Overview of PAN 2021: Authorship Verification,Profiling Hate Speech Spreaders on Twitter,and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,357.51,513.06,148.47,10.91;7,112.66,526.61,150.17,10.91">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,540.16,393.33,10.91;7,112.66,553.71,393.60,10.91;7,112.66,567.26,125.73,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,406.65,540.16,99.33,10.91;7,112.66,553.71,154.06,10.91">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,311.51,553.71,142.17,10.91">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="7,461.81,553.71,44.45,10.91;7,112.66,567.26,56.73,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,580.81,393.61,10.91;7,112.66,594.36,307.05,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,322.17,580.81,184.10,10.91;7,112.66,594.36,48.74,10.91">Overview of the 8th author profiling task at pan 2020</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,169.16,594.36,176.25,10.91">Profiling fake news spreaders on twitter</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,607.91,393.33,10.91;7,112.66,621.46,393.33,10.91;7,112.48,635.01,252.97,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,340.11,607.91,165.88,10.91;7,112.66,621.46,324.64,10.91">Hate speech detection in twitter using hybrid embeddings and improved cuckoo search-based neural networks</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">E</forename><surname>Ayo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Folorunso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">T</forename><surname>Ibharalu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">A</forename><surname>Osinuga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,446.71,621.46,59.28,10.91;7,112.48,635.01,221.05,10.91">International Journal of Intelligent Computing and Cybernetics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,648.56,393.33,10.91;7,112.66,662.11,395.17,10.91;8,112.66,86.97,394.53,10.91;8,112.66,100.52,296.68,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,304.19,648.56,201.79,10.91;7,112.66,662.11,223.85,10.91">Hate speech detection using word embedding and deep learning in the arabic language context</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Castillo</surname></persName>
		</author>
		<idno type="DOI">10.5220/0008954004530460</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,363.89,662.11,143.94,10.91;8,112.66,86.97,344.22,10.91">Proceedings of the 9th Interna-tional Conference on Pattern Recognition Applications and Methods -ICPRAM</title>
		<meeting>the 9th Interna-tional Conference on Pattern Recognition Applications and Methods -ICPRAM<address><addrLine>SciTePress</addrLine></address></meeting>
		<imprint>
			<publisher>INSTICC</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="453" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,393.33,10.91;8,112.66,127.61,363.59,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="8,353.43,114.06,152.55,10.91;8,112.66,127.61,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,141.16,394.52,10.91;8,112.66,154.71,205.26,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,245.88,141.16,261.30,10.91;8,112.66,154.71,97.51,10.91">Twitter sentiment classification using distant supervision, CS224N project report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,217.18,154.71,38.01,10.91">Stanford</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,168.26,393.33,10.91;8,112.66,181.81,125.68,10.91" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="8,293.20,168.26,212.79,10.91;8,112.66,181.81,50.78,10.91">Fake news spreader detection using neural tweet aggregation</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bakhteev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ogaltsov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ostroukhov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,195.36,394.53,10.91;8,112.66,208.91,393.33,10.91;8,112.66,222.46,394.51,10.91;8,112.66,238.45,123.08,7.90" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,327.46,195.36,175.13,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
	</analytic>
	<monogr>
		<title level="m" coord="8,240.99,208.91,264.99,10.91;8,112.66,222.46,123.97,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,249.56,317.77,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,174.79,249.56,184.13,10.91">Pattern recognition and machine learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,263.11,370.78,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,208.31,263.11,104.06,10.91">Support vector machine</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,321.32,263.11,78.19,10.91">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,276.66,393.33,10.91;8,112.66,290.20,229.42,10.91" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="8,355.58,276.66,150.41,10.91;8,112.66,290.20,46.53,10.91">Language-agnostic bert sentence embedding</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01852</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,303.75,393.32,10.91;8,112.66,317.30,77.19,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,249.66,303.75,120.34,10.91">Visualizing data using t-sne</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,381.60,303.75,124.39,10.91;8,112.66,317.30,37.47,10.91">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,330.85,393.33,10.91;8,112.66,344.40,393.33,10.91;8,112.66,357.95,395.01,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,402.97,330.85,103.02,10.91;8,112.66,344.40,311.41,10.91">Bigartm: Open source library for regularized multimodal topic modeling of large collections</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Vorontsov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Apishev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Romov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dudarenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,447.00,344.40,58.98,10.91;8,112.66,357.95,267.39,10.91">International Conference on Analysis of Images, Social Networks and Texts</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="370" to="381" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
