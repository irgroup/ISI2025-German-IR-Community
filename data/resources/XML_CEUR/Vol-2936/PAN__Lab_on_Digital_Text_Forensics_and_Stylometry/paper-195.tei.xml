<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,342.60,15.42;1,89.29,106.66,325.58,15.42;1,89.29,128.58,394.71,15.43">Profiling Hate Speech Spreaders on Twitter: Exploiting Textual Analysis of Tweets and Combinations of Multiple Textual Representations</title>
				<funder>
					<orgName type="full">Google</orgName>
				</funder>
				<funder>
					<orgName type="full">NVIDIA</orgName>
				</funder>
				<funder>
					<orgName type="full">Fapemig</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">CAPES</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,156.89,178.23,11.96"><forename type="first">Claudio</forename><surname>Mois√©s Valiense De Andrade</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Federal University of Minas Gerais Belo Horizonte</orgName>
								<address>
									<settlement>Minas Gerais</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.16,156.89,122.54,11.96"><forename type="first">Marcos</forename><forename type="middle">Andr√©</forename><surname>Gon√ßalves</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Federal University of Minas Gerais Belo Horizonte</orgName>
								<address>
									<settlement>Minas Gerais</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">claudiovaliense</orgName>
								<orgName type="institution">CLEF</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,342.60,15.42;1,89.29,106.66,325.58,15.42;1,89.29,128.58,394.71,15.43">Profiling Hate Speech Spreaders on Twitter: Exploiting Textual Analysis of Tweets and Combinations of Multiple Textual Representations</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">C7A561C261DB9BE62954C88E97B347E9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>, Hate Speech, Supervised Algorithm</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our solution for the task "Profiling Hate Speech Spreaders on Twitter" promoted by PAN CLEF 2021. The task is to identify user profiles that promote hate speech on social media Twitter. Data for 200 users has been made available -each user has a set of 200 posts and the corresponding label (hate speech propagator or not). Our solution consists of exploiting several text representations and classifiers available in the literature. Based on the predictions of the classifiers estimated with nested cross-validation in the training set, we reach a consensus between the best results to obtain a final prediction. Our solution reached an accuracy of 63.0% for English language and 79% for Spanish. To guarantee the reproducibility of our solution, all the documentation and code is available on github 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper we describe our participation in PAN @ CLEF 2021 <ref type="bibr" coords="1,388.01,423.42,11.58,10.91" target="#b0">[1]</ref>. This edition looks for solutions to identify profiles of hate propagators <ref type="bibr" coords="1,298.17,436.97,11.28,10.91" target="#b1">[2]</ref>, where hate is defined as any communication that depreciates a person or a group. From the identification of the profiles, it is possible to avoid the spread of hate speech, keeping the social network healthier.</p><p>We treat this problem as a binary text classification task. In this context, a user profile is represented by the set of textual posts she has issued in the social network altogether. For the sake of classification, such textual data can be represented in several ways (e.g. TF-IDF, word embeddings, text graph), each representation capturing or focusing on a different aspect of the classification task. For instance, the traditional TF-IDF representation captures statistical aspects of the text and the specificity of certain words in the collection (IDF component). Word embeddings are vectorial representations of words, sentences and whole documents aimed at capturing word co-occurrence patterns and contextual information.</p><p>Our solution is simple yet very effective. We rely on a majority voting of several classifiers exploiting these different representation based on the assumption that those combinations (representation/classifier) are complementary and can be effectively combined for improving the classification task. We exploit 4 representations (word tfidf, char tfidf, vader, and roberta's word embeddings) along with two classifiers (svm and random forests), which are still very strong text classifiers, even when compared to recent deep neural networks, including recent Transformer architectures, as shown in recent work <ref type="bibr" coords="2,322.47,141.16,11.33,10.91" target="#b2">[3,</ref><ref type="bibr" coords="2,336.54,141.16,7.99,10.91" target="#b3">4]</ref>.Lastly, we rely on a majority voting (most frequent decision) for the final outcome.</p><p>Our experimental results show that solution can reach an accuracy of 63% for English language and 79% for Spanish, where the majority voting is always better or at least tied to the best single combination of (representation/classifier). This best combination, in both cases, English and Spanish, was obtained when using the char_tfidf representation along with Random Forests, showing the importance of dealing with noise in the data, especially social network textual data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>BERT proposed by Devlin et al. <ref type="bibr" coords="2,235.74,294.63,13.00,10.91" target="#b4">[5]</ref> is a framework that exploits several techniques existing in the literature. Among those techniques we highlight: 1) dynamic embeddings, where the word embedding is adjusted according to other words found in the sentence (that is, it seeks to capture a word¬¥s context); 2) term masking, consisting of a percentage of words that are exchanged for a fixed sequence of words aiming at finding out what the original terms are from these masked terms -the goal is to learn relationships between words; and 3) a Multi-head attention mechanism. In our solution we will use RoBERTa, a technique that uses BERT as a base but proposes several improvements, for example, using a longer training phase exploiting longer word sequences.</p><p>Several works <ref type="bibr" coords="2,166.89,416.58,11.23,10.91" target="#b5">[6,</ref><ref type="bibr" coords="2,180.86,416.58,8.88,10.91" target="#b6">7]</ref> propose stacking classifiers in order to assess the final impact. Different from traditional stacking, this article combines representations in order to benefit from the complementary information containing in each one of them.</p><p>Our work is more aligned with <ref type="bibr" coords="2,240.29,457.22,11.42,10.91" target="#b7">[8]</ref>, which also proposed to combine representations for the sake of citation classification. Differently from that work, in which the representations are simply concatenated before serving as input for a classifier, here we exploit a different combination rule, based on a majority voting of outputs of the application of different representations to different classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Representation Methodology</head><p>In this section we describe the methodology used to represent the data in our solution. Subsection 3.1 presents how we treat the dataset while subsections 3.2, 3.3, 3.4 and 3.5 describe the specific representations uses to represent the textual data, aimed at capturing different aspects of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset Representation</head><p>A dataset of 200 users was made available. For each user, there are 200 posts issued on the social network Twitter. We concatenated all these 200 messages together into a single document to represent a user profile. For each user, their label was made available (hate spreader or not). The data presented in Table <ref type="table" coords="3,215.24,148.18,5.07,10.91" target="#tab_0">1</ref> refers to the training and validation sets used in our solution.</p><p>Table <ref type="table" coords="3,126.74,161.73,5.01,10.91" target="#tab_0">1</ref> presents the two datasets made available for PAN@2021, one in English and another in Spanish. The respective columns describe: amount of documents (|D|), average amount of words per document (Avg(T)), amount of unique words in the collection (U(T)), average number of times a word appears in the dataset¬¥s documents (aka, rarity) (O(T)), number of classes (|C|) and number of documents in the largest (Max(C)) and smallest class (Min(C)).</p><p>As it can be seen in Table <ref type="table" coords="3,214.90,229.48,3.68,10.91" target="#tab_0">1</ref>, the data is balanced as the two classes have the same number of documents. Spanish has a larger vocabulary and the Spanish words appears in average in less documents, potentially making them more discriminative. This may be one of the reasons that classification results in Spanish were a bit better than in English, as we shall see. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Word TF-IDF</head><p>The TF-IDF representation <ref type="bibr" coords="3,214.45,421.26,13.00,10.91" target="#b8">[9]</ref> consists of two parts, the tf that quantifies the frequency of terms, and the idf, the inverse document frequency, that gives higher weight to words that occur less frequently in documents. The final score of a word t is obtained by tf * idf, which gives more importance to rare words considering the set of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Char TF-IDF</head><p>We made a modification in tf-idf, which we call char tf-idf, by defining sequences of characters to be analyzed. Those sequences become a potential new "word" present in the vocabulary. This modification aims to deal with typos, mispellings and other types of grammar and syntatical mistakes commonly found in social media text. For instance, "love" and "lovee" are considered the same word based on a 4-character string. We limit the creation of a sequence from 2 to 6 characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Vader</head><p>The Vader representation <ref type="bibr" coords="3,209.28,628.93,18.07,10.91" target="#b9">[10]</ref> is based on a lexicon dictionary where each word has three polarity scores: positive (0-1), neutral (0-1) or negative (0-1). A document is represented as a 3-dimensional vector, each vector position representing the proportion of words of each type of polarity, where the higher the value, the more the word is related to polarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Word Embedding</head><p>Word embeddings are vector representations of words, phrases and entire documents aimed at capturing patterns of co-occurrence of words and contextual information. In this work, we exploited RoBERTa <ref type="bibr" coords="4,178.43,134.63,17.99,10.91" target="#b10">[11]</ref> embeddings, a pre-trained learning algorithm to obtain vector representations for words. In RoBERTa¬¥s representation, each word has a 12-layer representation, where each layer has 768 dimensions. To represent a word ùë°, we concatenate the last 4 layers, resulting in a vector of 3072 positions. To represent a document d, we average the vectors of all words in the document. The document¬¥s representation is the input for the classification algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Combining Representations and Classifiers -Majority Voting</head><p>After creating the representations for a text, we used them as input for each classifier, Each representation and classifier pair generates a prediction for a document ùëë. Given ùëõ predictions for a document ùëë, the "frequency" algorithm selects the predictions of the 4 models that obtained the best result in the validation, verifies the most frequent one and sets it as the final prediction for the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Tuning Hyperparameter</head><p>After creating the dataset representation used as input to a classifier, training and actual classification of documents is carried out. For each dataset we apply a nested cross validation procedure as suggested by Varma and Simon <ref type="bibr" coords="4,286.97,421.89,16.09,10.91" target="#b11">[12]</ref>, using a 5x3 setting (5-fold cross-validation in the outer loop and 3-fold cross-validation in the inner loop). The internal cross validation is responsible for finding the best parameters for a given fold, used to build the model utilized to make predictions in the test set. We evaluated the parameters of the following classifiers:</p><p>‚Ä¢ Linear SVM, we varied the C parameter considering [10 -4 , 10 -3 , 10 -2 , 10 -1 , 10 0 , 10 1 , 10 2 , 10 3 , 10 4 ] ‚Ä¢ Random Forest, we evaluated the n estimator parameter considering the following values:</p><p>[10, 50, 100, 200, 500, 1000, 2000]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>We report in Table <ref type="table" coords="4,178.60,579.78,5.17,10.91" target="#tab_1">2</ref> the average accuracy results of the 5 test folds along with confidence intervals (with 95% confidence level) for both, the English and Spanish datasets, while the last line is the result of the test set submitted through the TIRA <ref type="bibr" coords="4,353.37,606.87,17.85,10.91" target="#b12">[13]</ref> system. Each line in the Table corresponds to a combination (representation, classifier) in a given language. For instance, line 1 of Table <ref type="table" coords="4,135.83,633.97,5.14,10.91" target="#tab_1">2</ref> presents the accuracy results of using the roberta representation as input for the SVM classifier for the English dataset. The penultimate line of the table for both, English and Spanish represent our Majority Voting heuristics results. And finally, the last line corresponds to the results in the Test set made available by the CLEF organizers for which we did not have labels at development time <ref type="foot" coords="5,208.59,98.76,3.71,7.97" target="#foot_0">1</ref> . As it can be seen, our experimental results show that our solution can reach an accuracy of 63% for English language and 79% for Spanish. The majority voting is always better or at least tied to the best single combination of (representation/classifier). In both cases, English and Spanish, the best individual results were produced by combining the char_tfidf representation with Random Forests.</p><p>The best results of the char_tfidf in both languages confirm our hypotheses that it is important to cope with noise and errors when dealing with social media textual data, especially Twitter data. The better results of the majority voting provides evidence for our hypothesis of complementarity among the representations and classifiers. And finally, the slightly better results for Spanish when compared to English may be due to larger Spanish vocabulary and presence of more discriminative words, but this hypothesis requires a more thorough investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>In this paper we described our participation in the task "Profiling Hate Speech Spreaders on Twitter" organized by PAN @ CLEF 2021. We use four complementary text representations along with two strong text classifiers available in the literature. Our simple majority voting heuristics that combines the decision of pairs (representation/classifier) achieves accuracy as high as 63% for English and 79% for Spanish, outperforming or tying the best individual combinations. This provides evidence for the complementarity of the strategies. Dealing with noise in social media network is also important to boost results. And results in Spanish demonstrated to be better than in English, requiring an additional investigation for determining the exact reasons for this behavior.</p><p>As future work we intend to perform an ablation or full factorial analysis to understand which elements of our solution contributed more to the final results, include other representations and classifiers, study other ways of combining them and, finally, take advantage of attention mechanisms to reinforce cross-representation common elements (e.g., words) that are discriminative in more than one representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,298.95,411.03,67.65"><head>Table 1</head><label>1</label><figDesc>Dataset statistics.</figDesc><table coords="3,95.27,328.29,404.75,38.30"><row><cell>Name</cell><cell>|D|</cell><cell>Avg(T)</cell><cell>U(T)</cell><cell>O(T)</cell><cell>|C|</cell><cell cols="2">Max(C) Min(C)</cell></row><row><cell>Pan21 English</cell><cell>200</cell><cell>2454.8</cell><cell>57556</cell><cell>8.4</cell><cell>2</cell><cell>100</cell><cell>100</cell></row><row><cell>Pan21 Spanish</cell><cell>200</cell><cell>2587.7</cell><cell>75038</cell><cell>6.9</cell><cell>2</cell><cell>100</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,88.99,128.66,361.69,285.46"><head>Table 2</head><label>2</label><figDesc>Result of average accuracy in validation data and 95% confidence interval (IC).</figDesc><table coords="5,144.60,160.23,26.54,8.93"><row><cell>Name</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,108.93,660.08,398.57,8.97;5,89.29,671.04,26.68,8.97"><p>The Test Set results do not contain confidence intervals as it was not part of our 5-fold cross-validation experiments.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially supported by <rs type="funder">CNPq</rs>, <rs type="funder">CAPES</rs>, <rs type="funder">Fapemig</rs>, <rs type="funder">NVIDIA</rs> and <rs type="funder">Google</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,112.66,353.26,394.53,10.91;6,112.66,366.81,395.17,10.91;6,112.66,380.36,393.33,10.91;6,112.66,393.91,393.33,10.91;6,112.66,407.46,222.66,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,194.78,380.36,311.21,10.91;6,112.66,393.91,221.30,10.91">Overview of PAN 2021: Authorship Verification,Profiling Hate Speech Spreaders on Twitter,and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wolska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,357.51,393.91,148.47,10.91;6,112.66,407.46,150.17,10.91">12th International Conference of the CLEF Association (CLEF 2021)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,421.01,393.33,10.91;6,112.66,434.55,393.60,10.91;6,112.66,448.10,125.73,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,406.65,421.01,99.33,10.91;6,112.66,434.55,154.06,10.91">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarrac√©n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,311.51,434.55,142.17,10.91">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="6,461.81,434.55,44.45,10.91;6,112.66,448.10,56.73,10.91">Notebook Papers, CEUR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,461.65,394.53,10.91;6,112.66,475.20,394.61,10.91;6,112.66,488.75,395.01,10.91;6,112.66,502.30,149.48,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,260.63,475.20,246.64,10.91;6,112.66,488.75,369.52,10.91">Extended pre-processing pipeline for text classification: On the role of meta-feature representations, sparsification and selective sampling</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Canuto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mangaravite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Resende</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Gon√ßalves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Da Rocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,492.43,488.75,15.23,10.91;6,112.66,502.30,71.52,10.91">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">102263</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,515.85,394.53,10.91;6,112.66,529.40,393.33,10.91;6,112.66,542.95,393.32,10.91;6,112.66,556.50,395.01,10.91;6,112.66,570.05,167.31,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,492.14,529.40,13.84,10.91;6,112.66,542.95,393.32,10.91;6,112.66,556.50,221.24,10.91">On the cost-effectiveness of neural and non-neural approaches and representations for text classification: A comprehensive comparative study</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mangaravite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Canuto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Resende</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fran√ßa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Da Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Gon√ßalves</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2020.102481</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,342.19,556.50,88.28,10.91">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">102481</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,583.60,393.33,10.91;6,112.66,597.15,363.59,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="6,353.43,583.60,152.55,10.91;6,112.66,597.15,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,112.66,610.69,393.54,10.91;6,112.66,624.24,257.79,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,324.38,610.69,181.82,10.91;6,112.66,624.24,43.49,10.91">Tweet sentiment analysis with classifier ensembles</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,164.91,624.24,116.15,10.91">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="170" to="179" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,112.66,637.79,395.17,10.91;6,112.66,651.34,393.33,10.91;6,112.66,664.89,250.67,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,260.61,637.79,247.21,10.91;6,112.66,651.34,333.86,10.91">On the cost-effectiveness of stacking of neural and nonneural methods for text classification: Scenarios and performance prediction</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R F</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Gon√ßalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,454.75,651.34,51.23,10.91;6,112.66,664.89,131.70,10.91">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,86.97,393.32,10.91;7,112.66,100.52,393.33,10.91;7,112.66,114.06,393.24,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,288.73,86.97,217.25,10.91;7,112.66,100.52,57.10,10.91">Combining representations for effective citation classification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M V</forename><surname>De Andrade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Gon√ßalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,195.02,100.52,310.96,10.91;7,112.66,114.06,52.65,10.91">Proceedings of the 8th International Workshop on Mining Scientific Publications</title>
		<meeting>the 8th International Workshop on Mining Scientific Publications<address><addrLine>Wuhan, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="54" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,127.61,394.53,10.91;7,112.48,141.16,146.10,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,165.80,127.61,337.39,10.91">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,112.48,141.16,114.18,10.91">Journal of documentation</title>
		<imprint>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,154.71,393.33,10.91;7,112.66,168.26,393.33,10.91;7,112.66,181.81,130.40,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,206.21,154.71,299.77,10.91;7,112.66,168.26,75.84,10.91">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,214.56,168.26,291.42,10.91;7,112.66,181.81,54.06,10.91">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,195.36,394.53,10.91;7,112.30,208.91,393.68,10.91;7,112.66,222.46,107.17,10.91" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="7,173.53,208.91,256.77,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,112.66,236.01,393.33,10.91;7,112.66,249.56,194.26,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,212.86,236.01,293.13,10.91;7,112.66,249.56,37.66,10.91">Bias in error estimation when using cross-validation for model selection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,158.43,249.56,89.91,10.91">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,263.11,394.53,10.91;7,112.66,276.66,393.33,10.91;7,112.66,290.20,326.25,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,327.46,263.11,175.13,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,240.99,276.66,264.99,10.91;7,112.66,290.20,123.40,10.91">Information Retrieval Evaluation in a Changing World, The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
