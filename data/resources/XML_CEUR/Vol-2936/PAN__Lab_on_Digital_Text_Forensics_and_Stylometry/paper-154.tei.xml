<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,372.51,15.42;1,89.29,106.66,221.20,15.42;1,89.29,129.00,157.29,11.96">Profiling Haters on Twitter using Statistical and Contextualized Embeddings Notebook for PAN at CLEF 2021</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,106.46,11.96"><forename type="first">Hamed</forename><forename type="middle">Babaei</forename><surname>Giglou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Tabriz</orgName>
								<address>
									<settlement>Tabriz</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.40,154.90,74.33,11.96"><forename type="first">Taher</forename><surname>Rahgooy</surname></persName>
							<email>trahgooy@students.uwf.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of West Florida</orgName>
								<address>
									<settlement>Florida</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.37,154.90,68.29,11.96"><forename type="first">Jafar</forename><surname>Razmara</surname></persName>
							<email>razmara@tabrizu.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Tabriz</orgName>
								<address>
									<settlement>Tabriz</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.30,154.90,85.54,11.96"><forename type="first">Mostafa</forename><surname>Rahgouy</surname></persName>
							<email>mostafa.rahgouy@partdp.ai</email>
							<affiliation key="aff2">
								<orgName type="department">Part AI Research Center</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,168.85,75.11,11.96"><forename type="first">Zahra</forename><surname>Rahgooy</surname></persName>
							<email>za.rahgooy@gmail.com</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Damghan University</orgName>
								<address>
									<settlement>Semnan</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,372.51,15.42;1,89.29,106.66,221.20,15.42;1,89.29,129.00,157.29,11.96">Profiling Haters on Twitter using Statistical and Contextualized Embeddings Notebook for PAN at CLEF 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">8A413ABCEC6E90C11F97CB608BAD759C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hate Speech</term>
					<term>Abusive Language</term>
					<term>Author Profiling</term>
					<term>Stylistic Features</term>
					<term>Word Embedding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hate Speech (HS) in social media such as Twitter is a complex phenomenon that attracted a significant body of research in the NLP. HS Spreaders (haters) aim to spread HS via social media. In this task, we aim to identify such haters. On one hand, our proposed class-dependent LDSE representation is fed to a linear SVM classifier to identify the haters based on general commonalities. On the other hand, stylistic features of individuals are captured by using extractive summarization of the tweets in conjunction with RoBERTa embedding before classifying them using another linear SVM classifier. Experimental results expressed as accuracies 0.67 and 0.80 over English and Spanish test sets respectively show efficacy of our approach in identifying the haters across different languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The social medial platform enables millions to publicly share user-generted content. Regardless of different content types, a critical point of these platforms, such as Twitter, Facebook, YouTube, and Instagram, is that users can discuss content. Unfortunately, any user engaging online will always facing the risk of being targeted or harassed via abusive language, hatred expressed in the form of racism or sexism, with possible impact on his/her and the community in general. The challenge of creating effective policies to identify and appropriately respond to harassment is compounded by the difficulty of studying the phenomena at scale. Hate speech is commonly defined as any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics.</p><p>To this end, in the Author Profiling task <ref type="bibr" coords="2,273.51,86.97,11.28,10.91" target="#b0">[1]</ref>, we aim at identifying possible hate speech spreaders (haters) on Twitter as a first step towards preventing hate speech from being propagated among online users. Also, this task runs based on a multilingual perspective for English and Spanish languages.</p><p>The rest of the paper is organized as follows. Section 2 presents related works. Section 3 describes the proposed method. Section 4 describes the dataset, experiments and discusses the obtained results. Finally, section 5 presents our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>The authors in <ref type="bibr" coords="2,160.09,226.89,12.99,10.91" target="#b1">[2]</ref> concluded that word embedding models like GloVe <ref type="bibr" coords="2,408.31,226.89,14.97,10.91" target="#b2">[3]</ref> and Word2Vec <ref type="bibr" coords="2,489.79,226.89,16.19,10.91" target="#b3">[4]</ref> are although widely used for toxic comment classification are in fact unable to handle out-ofvocabulary problem properly. However, word embeddings like FastText <ref type="bibr" coords="2,411.83,253.99,13.93,10.91" target="#b4">[5]</ref> were particularly suited for this task since it uses subword embedding. The ability to cope with unknown words is the reason why previous findings on the inferiority of word embeddings in comparison to word n-grams have become outdated. After introducing contextualized word embeddings such as BERT <ref type="bibr" coords="2,146.95,308.18,15.51,10.91" target="#b5">[6]</ref>, some of the limitations of all previous word embeddings are resolved. In SemEval-2021 at the Toxic Span Detection task <ref type="bibr" coords="2,304.01,321.73,12.97,10.91" target="#b6">[7]</ref> used GloVe, GPT-2 <ref type="bibr" coords="2,401.08,321.73,15.54,10.91" target="#b7">[8]</ref> and RoBERTa <ref type="bibr" coords="2,477.54,321.73,16.62,10.91" target="#b8">[9]</ref> to create empowered representation to overcome the out-of-vocabulary issue in the representation. They use the analogy that hateful words may never occur in the training time of the word embeddings like GloVe or Word2Vec, but however they are useful when they are combined with other representations since concatenations of them with LM models could create awareness signal to model.</p><p>Authors of <ref type="bibr" coords="2,148.76,403.03,17.76,10.91" target="#b9">[10]</ref> compared different deep learning and shallow approaches on a large comment dataset and propose an ensemble that outperforms all individual models. They combined different deep learning and traditional machine learning models with FastText, GloVe, wordngrams, and char-ngrams representation. They suggest further research in representing world knowledge with embeddings to improve the distinction between paradigmatic contexts. <ref type="bibr" coords="2,487.96,457.22,18.02,10.91" target="#b10">[11]</ref> proposed charachter n-grams, TFIDF, BoWV(bag of word vector) that uses GloVe embedding, FastText, and random embedding representations for hate speech detection in Twitter using deep learning approaches. They investigated various combinations of SVM, LogisticRegression, CNN, LSTM, Gradient Boosted Decision Trees to handle this task. They achieved a higher F1 score with a combination of LSTM, Random Embedding, and GBDT.</p><p>At Author Profiling shared task at PAN 2020 <ref type="bibr" coords="2,307.17,538.52,16.41,10.91" target="#b11">[12]</ref>, the <ref type="bibr" coords="2,348.45,538.52,18.07,10.91" target="#b12">[13]</ref> combined character and word n-grams via SVM, and they achieved best competition accuracy in Spanish. <ref type="bibr" coords="2,421.38,552.07,18.34,10.91" target="#b13">[14]</ref> also combined n-grams with stylistic features with LogisticRegression, and they achieved the best competition accuracy in English. <ref type="bibr" coords="2,181.50,579.17,17.86,10.91" target="#b14">[15]</ref> proposed a multi-feature representation that combines n-grams with word embeddings to enrich the representation for fake news spreader detection on Twitter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section, we describe the details of our proposed model. Our proposed approach aims to predict whether the user is keen to spread hate speech or not. proposed method. We used two different representations namely, contextualized representation using RoBERTa embedding, and character-based lower dimensionality statistical embedding (Char-LDSE) <ref type="bibr" coords="3,149.72,501.62,16.41,10.91" target="#b15">[16]</ref>. In the final, representations are fed into the classification modules. In the following, we described each component in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Contextualized Representation</head><p>The user content in this task consists of 200 tweets. To capture the user preferences in tweets and reduce the number of tweets to feed the word embeddings, we applied extractive text summarization. Next, we preprocessed the summary to feed RoBERTa embedding for creating a contextualized representation of user preferences. In the end, for the 𝑈 users, we had a representation of 𝑈 × 𝑅 768 to feed the classification module, where 𝑅 768 is the vectorized representation of summaries using word embedding. In the following, we describe summarization, preprocessing, and word embedding components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Extractive Text Summarization:</head><p>It involves selecting phrases and sentences from the original text and including it in the final summary. We used Gensim <ref type="bibr" coords="4,217.80,121.08,16.41,10.91" target="#b16">[17]</ref>, a Python library to summarize user tweets with summary ratio of 0.1 (selecting 20 tweets from user 200 tweets). The Gensim uses TextRank algorithm, which is based on PageRank algorithm for ranking search results.</p><p>1. Pre-process the given tweets (a built-in preprocessing in gensim). 2. Make a graph with tweets that are the vertices. 3. The graph has edges denoting the similarity between the two tweets at the vertices. 4. Run PageRank algorithm on this weighted graph. 5. Pick the highest-scoring vertices and append them to the summary. 6. Based on the ratio or the word count, the number of vertices to be picked is decided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Preprocessing:</head><p>The preprocessing consists removal of URLs, hashtags, mentions, reserved words (RT, FAV), emojis, smileys, punchuations, special characters, and numbers from tweets. Speficicaly for URLs, hashtags, and mentions the following masked tags, #USER#, #URL#, #HASHTAG#.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">RoBERTa:</head><p>It is an optimized version of BERT model. It builds on BERT's language masking strategy. RoBERTa modifies key hyperparameters in BERT, including removing BERT's next sentence pretraining objective and training with much larger mini-batches and learning rates. For the Egnlish language, we used the English version of RoBERTa base model, and for Spanish, we used SpanBERTa<ref type="foot" coords="4,163.74,421.23,3.71,7.97" target="#foot_0">1</ref> which is of the same size as BERT-Base and is trained on 18 GB of OSCAR's Spanish corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Char-LDSE Representation</head><p>Char-LDSE <ref type="bibr" coords="4,136.00,486.26,20.76,10.91" target="#b15">[16]</ref> representation is applied to capture the stylistic features of user tweets and the probability of term occurrences in hate and none-hate spreaders. First, preprocessing is applied to user tweets; next, a character n-gram matrix with TFIDF weight is created. TFIDF matrix is utilized to calculate the LDSE. Next, the weighted probability of terms per class was obtained. As a result, 𝑃 𝐶0 and 𝑃 𝐶1 embeddings are calculated for class 0 and class 1, respectively. In the end, using these embeddings, we calculated a matrix of 𝑈 × 𝐹 104 per class to feed classification models, Where 𝐹 104 is the vectorzied distribution of user 𝑈 weighted probabilities of terms in each class (for class 0, 𝑃 𝐶0 and for class 1 𝑃 𝐶1 was utilized separately)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Preprocessing:</head><p>The preprocessing consists removal of special characters and localization of the tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">TFIDF:</head><p>We apply the TFIDF weighting on the terms of the user tweets in the training set. We utilized charachter n-grams. Specifically, for English, we used range (2, 3), and for Spanish, we used a range of <ref type="bibr" coords="5,137.12,134.63,10.85,10.91" target="#b2">(3,</ref><ref type="bibr" coords="5,150.71,134.63,7.23,10.91" target="#b3">4)</ref>. These ranges are obtained using a manual search. As a result, we obtain the following matrix. </p><formula xml:id="formula_0" coords="5,162.38,172.43,61.76,65.89">𝑇 𝐹 𝐼𝐷𝐹 = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣</formula><formula xml:id="formula_1" coords="5,425.62,172.43,7.27,65.89">⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦</formula><p>Where each row in the matrix TFIDF represents a user 𝑈 𝑖 , each column represents vocabulary term 𝑡 and 𝑊 𝑖𝑗 represents its TFIDF weight and 𝛾 represents the assigned class (𝐶0 -class 0, 𝐶1 -class 1) of the user 𝑈 tweets. Also, 𝑛 and 𝑚 represent the number of the training set (users) and vocabulary size, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Lower Dimensionality Statistical Embedding (LDSE):</head><p>First, using matrix TFIDF, we obtain the class-dependent term weight embedding LDSE. This embedding contains the weights of each term 𝑡 for each class based on the following formulation.</p><formula xml:id="formula_2" coords="5,155.13,384.54,285.02,30.35">𝐿𝐷𝑆𝐸(𝑡, 𝑐) = ∑︀ 𝑢∈𝛾(𝑈𝑐)/𝑐=𝛾(𝑈𝑐) 𝑊 𝑢𝑡 ∑︀ 𝑢∈𝛾(𝑈𝑐) 𝑊 𝑢𝑡 , ∀𝑢 ∈ 𝑈, 𝑐 ∈ {𝐶0, 𝐶1}</formula><p>Next, we calculated LDSE for each class:</p><formula xml:id="formula_3" coords="5,229.29,450.10,136.69,44.26">𝑃 𝐶0 = 𝐿𝐷𝑆𝐸(𝑡, 𝑐) , ∀𝑐 ∈ 𝐶0 𝑃 𝐶1 = 𝐿𝐷𝑆𝐸(𝑡, 𝑐) , ∀𝑐 ∈ 𝐶1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Final Representation:</head><p>At the end, We employed the class-dependent LDSE, 𝑃 𝐶0 and 𝑃 𝐶1 to extract the final representation of user tweets as follows for each class seperately:</p><formula xml:id="formula_4" coords="5,214.87,573.65,165.54,10.69">𝑅𝑒𝑝1 = 𝐹 (𝑃 𝐶0 ) , 𝑅𝑒𝑝2 = 𝐹 (𝑃 𝐶1 )</formula><p>Where 𝐹 (𝑃 ) contains the set of features showed in the followings and described in Table <ref type="table" coords="5,501.09,592.94,5.07,10.91" target="#tab_1">1</ref> 𝐹 (𝑃 ) = {𝑚𝑎𝑥, 𝑚𝑖𝑛, 𝑠𝑡𝑑, 𝑝𝑟𝑜𝑏, 𝑄 1 , 𝑄 2 , 𝑄 3 , ..., 𝑄 100 } The minimum weight of 𝑊 (𝑡, 𝑐) from a user content std</p><p>The standard deviation of the weight of 𝑊 (𝑡, 𝑐) prob</p><p>The overall weight of 𝑊 (𝑡, 𝑐) from a user content devided by total number of terms 𝑄 1 , ..., 𝑄 100 calculating the Q-th quantile of the data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Classification Modules</head><p>There are many different types of ensembles; voting is one of them. It is one of the more general types. Voting involves training a learning algorithm to combine the predictions of several other learning algorithms. We used voting with the hard scheme, in which we trained three different classifiers with three different representations each. The Linear SVM with 𝐶 = 0.1 was utilized as a classifier algorithm for each representation that we obtained as described in Table <ref type="table" coords="6,465.84,356.83,4.97,10.91" target="#tab_3">3</ref> column Representation + Model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>In this section, we described the Author Profiling dataset. Next, we presented experimental results on the training set. Finally, we presented the proposed model's final results on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>Table <ref type="table" coords="6,116.68,505.83,5.17,10.91" target="#tab_2">2</ref> presents the statistics of the corpus that consists of 300 authors for each of the two languages, English and Spanish. For each author at least 200 Tweets collected. The corpus for each language is balanced, with 150 authors for each class (hater and none-hater spreaders).</p><p>Dataset have splited into training and test sets, following the 66/34 proportion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Results</head><p>We conducted a few experiments with Linear SVM and different representations. We mainly focused on 5-fold cross-validation mean accuracy. According to experiments for English, ensemble modeling with different representations outperforms single representation modeling. Even in some cases (in Fold-4 and Fold-5), it gains higher accuracy than individuals. It means even contextualized representation which performs week in overall with a mean accuracy of 0.625, contributes to the ensemble model in a positive way. The same patterns are presented in Spanish regarding the fact that the second model (Rep1:LDSE(𝑃 𝐶0 ) + Linear SVM) performs in a similar way that Ensemble works. Consequently, we relied upon the power of the ensemble approach for the final submission.</p><p>For early bird submission, we simply used XGBoost classifier with Char n-gram with TFIDF weights for the Spanish language. Howerver, we employed an SVM classifier with RBF kernel and LDSE representation with the tree-based feature selection model for English.</p><p>We particularly didn't rely on single representations because of the ambiguity of the user behaviors since hate spreaders may have multiple none-hate tweets in their own tweets too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Final Evaluation</head><p>Following the previous results, for the final evaluation at TIRA platform <ref type="bibr" coords="7,403.06,491.28,16.09,10.91" target="#b17">[18]</ref>, we applied statistical and contextual representations via ensemble models for hate speech spreaders detection. The obtained accuracy results for the final evaluation were as follows: in Spanish, 0.800; in English, 0.670; and 0.735 for both tasks. The official results are shown in Table <ref type="table" coords="7,413.70,531.93,5.17,10.91">4</ref> for early birds and final evaluation. We gained a better result for English at the early bird evaluation. However, for Spanish, we achieved higher accuracy at the final evaluation. In the final evaluation metrics, the best scores of the submissions between the early birds and final submissions of each participant and each language have been considered. This means that in our case, we achieved the best score for English in early bird and the best score for Spanish in the final submission, so, overall achieved accuracy is 0.735.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,436.92,179.51,8.93"><head>Figure 1 Figure 1 :</head><label>11</label><figDesc>Figure 1: Architecture of Proposed Method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,224.14,172.94,201.49,78.73"><head></head><label></label><figDesc>𝑊 (𝑛-2)2 ... 𝑊 (𝑛-2)𝑚 𝛾(𝑈 𝐶1 ) 𝑊 (𝑛-1)1 𝑊 (𝑛-1)2 ... 𝑊 (𝑛-1)𝑚 𝛾(𝑈 𝐶1 )</figDesc><table coords="5,224.14,172.94,201.49,78.73"><row><cell>𝑊 11</cell><cell>𝑊 12</cell><cell>...</cell><cell>𝑊 1𝑚</cell><cell>𝛾(𝑈 𝐶0 )</cell></row><row><cell>𝑊 21</cell><cell>𝑊 22</cell><cell>...</cell><cell>𝑊 2𝑚</cell><cell>𝛾(𝑈 𝐶0 )</cell></row><row><cell>...</cell><cell>...</cell><cell>...</cell><cell>...</cell><cell>...</cell></row><row><cell>𝑊 (𝑛-2)1 𝑊 𝑛1</cell><cell>𝑊 𝑛2</cell><cell>....</cell><cell>𝑊 𝑛𝑚</cell><cell>𝛾(𝑈 𝐶1 )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,90.49,343.43,48.99"><head>Table 1</head><label>1</label><figDesc>Set of features for each class (hater and none-hater) avgThe average weight of 𝑊 (𝑡, 𝑐) from a user content min</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,196.44,375.91,61.27"><head>Table 2</head><label>2</label><figDesc>Number of authors in the PAN-AP-21 corpus created for profiling hate spreaders on Twitter.</figDesc><table coords="6,218.88,224.53,157.52,33.18"><row><cell cols="4">Language Traning Testing Total</cell></row><row><cell>English</cell><cell>200</cell><cell>100</cell><cell>300</cell></row><row><cell>Spanish</cell><cell>200</cell><cell>100</cell><cell>300</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,410.79,231.88"><head>Table 3 5</head><label>3</label><figDesc>-Fold Cross Validation Results. In the table Rep1 is Char-LDSE (𝑃 𝐶0 ) and Rep2 is Char-LDSE (𝑃 𝐶1 )</figDesc><table coords="7,88.99,118.58,404.94,203.79"><row><cell cols="8">Lan Representation + Model Fold-1 Fold-2 Fold-3 Fold-4 Fold-5 Mean Accuracy</cell></row><row><cell></cell><cell>RoBERTa + Linear SVM</cell><cell>0.600</cell><cell>0.575</cell><cell>0.675</cell><cell>0.600</cell><cell>0.675</cell><cell>0.625</cell></row><row><cell>en</cell><cell>Rep1 + Linear SVM Rep2 + Linear SVM</cell><cell>0.700 0.650</cell><cell>0.625 0.575</cell><cell>0.650 0.600</cell><cell>0.650 0.650</cell><cell>0.750 0.800</cell><cell>0.675 0.655</cell></row><row><cell></cell><cell>Ensemble</cell><cell>0.700</cell><cell>0.625</cell><cell>0.650</cell><cell>0.675</cell><cell>0.825</cell><cell>0.695</cell></row><row><cell></cell><cell>RoBERTa + Linear SVM</cell><cell>0.650</cell><cell>0.725</cell><cell>0.700</cell><cell>0.525</cell><cell>0.650</cell><cell>0.650</cell></row><row><cell>es</cell><cell>Rep1 + Linear SVM Rep2 + Linear SVM</cell><cell>0.700 0.675</cell><cell>0.825 0.800</cell><cell>0.750 0.750</cell><cell>0.750 0.750</cell><cell>0.775 0.775</cell><cell>0.760 0.750</cell></row><row><cell></cell><cell>Ensemble</cell><cell>0.675</cell><cell>0.825</cell><cell>0.750</cell><cell>0.750</cell><cell>0.775</cell><cell>0.755</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Submission Results</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">Language Early Bird Submittion Final Submission Best</cell><cell></cell></row><row><cell></cell><cell>English</cell><cell>0.670</cell><cell></cell><cell></cell><cell>0.650</cell><cell>0.670</cell><cell></cell></row><row><cell></cell><cell>Spanish</cell><cell>0.730</cell><cell></cell><cell></cell><cell>0.800</cell><cell>0.800</cell><cell></cell></row><row><cell></cell><cell>Average</cell><cell>0.700</cell><cell></cell><cell></cell><cell>0.725</cell><cell>0.735</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,108.93,671.00,175.15,8.97"><p>https://github.com/chriskhanhtran/spanish-bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="8,108.93,671.00,167.80,8.97"><p>https://github.com/HamedBabaei/hate-speech</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Conclusion</head><p>In this paper, we proposed a model for Profiling Hate Speech Spreaders on the Twitter task in PAN 2021. We presented statistical and contextual representations via an ensemble approach for hate speech spreaders detection. In the final, we achieved an average accuracy of 0.735. Based on our manual evaluation, our approach is very capable of distinguishing hate/none-hate speech spreaders. The proposed algorithm implemented in Python and published on GitHub 2 repository for research community.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,237.65,393.33,10.91;8,112.66,251.20,393.33,10.91;8,112.33,264.75,345.15,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,406.65,237.65,99.33,10.91;8,112.66,251.20,145.39,10.91">Profiling Hate Speech Spreaders on Twitter Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">L D L P</forename><surname>Sarracén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,137.96,264.75,139.49,10.91">CLEF 2021 Labs and Workshops</title>
		<title level="s" coord="8,285.44,264.75,103.05,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J M M F P</forename><surname>Guglielmo Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,278.30,395.17,10.91;8,112.66,291.85,310.17,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,202.20,278.30,210.59,10.91">Toxic comment detection in online discussions</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krestel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,436.89,278.30,70.95,10.91;8,112.66,291.85,184.65,10.91">Deep Learning-Based Approaches for Sentiment Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="85" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,305.40,394.61,10.91;8,112.66,318.95,394.62,10.91;8,112.66,332.50,199.51,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,290.62,305.40,197.56,10.91">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,318.95,270.61,10.91">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,346.05,393.32,10.91;8,112.39,359.59,176.99,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="8,297.98,346.05,208.00,10.91;8,112.39,359.59,52.97,10.91">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,373.14,393.33,10.91;8,112.66,386.69,233.34,10.91" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<title level="m" coord="8,331.70,373.14,174.29,10.91;8,112.66,386.69,50.99,10.91">Enriching word vectors with subword information</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,400.24,393.33,10.91;8,112.66,413.79,311.37,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="8,326.58,400.24,179.40,10.91;8,112.66,413.79,181.08,10.91">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,427.34,394.62,10.91;8,112.66,440.89,394.53,10.91;8,112.66,454.44,122.77,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">B</forename><surname>Giglou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rahgooy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rahgouy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Razmara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13164</idno>
		<title level="m" coord="8,336.51,427.34,170.77,10.91;8,112.66,440.89,390.23,10.91">Uot-uwf-partai at semeval-2021 task 5: Self attention based bi-gru with multi-embedding representation for toxicity highlighter</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,467.99,393.33,10.91;8,112.66,481.54,174.94,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,407.93,467.99,98.05,10.91;8,112.66,481.54,143.02,10.91">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,495.09,395.17,10.91;8,112.66,508.64,395.01,10.91" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="8,137.85,508.64,241.29,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,522.18,393.33,10.91;8,112.66,535.73,393.33,10.91;8,112.33,549.28,395.33,10.91;8,112.66,562.83,372.02,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,297.10,522.18,208.89,10.91;8,112.66,535.73,97.24,10.91">Challenges for toxic comment classification: An in-depth error analysis</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Van Aken</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krestel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Löser</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5105</idno>
		<ptr target="https://www.aclweb.org/anthology/W18-5105.doi:10.18653/v1/W18-5105" />
	</analytic>
	<monogr>
		<title level="m" coord="8,231.63,535.73,274.36,10.91;8,112.33,549.28,231.04,10.91">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), Association for Computational Linguistics</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2), Association for Computational Linguistics<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,576.38,393.33,10.91;8,112.66,589.93,393.33,10.91;8,112.66,603.48,135.41,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,320.63,576.38,185.36,10.91;8,112.66,589.93,40.21,10.91">Deep learning for hate speech detection in tweets</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Badjatiya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,181.76,589.93,324.23,10.91;8,112.66,603.48,46.90,10.91">Proceedings of the 26th international conference on World Wide Web companion</title>
		<meeting>the 26th international conference on World Wide Web companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="759" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,617.03,393.33,10.91;8,112.66,630.58,394.53,10.91;9,112.28,86.97,395.38,10.91;9,112.66,100.52,154.66,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,313.58,617.03,192.40,10.91;8,112.66,630.58,223.32,10.91">Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,188.66,86.97,139.27,10.91">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="9,335.91,86.97,102.88,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,393.33,10.91;9,112.66,127.61,393.33,10.91;9,112.14,141.16,384.74,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,158.05,114.06,347.94,10.91;9,112.66,127.61,45.01,10.91">Using N-grams to detect Fake News Spreaders on Twitter-Notebook for PAN at CLEF 2020</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pizarro</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,416.64,127.61,89.34,10.91;9,112.14,141.16,47.32,10.91">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="9,167.44,141.16,103.05,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,154.71,393.61,10.91;9,112.66,168.26,394.53,10.91;9,112.66,181.81,394.52,10.91;9,112.66,195.36,248.17,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,202.53,154.71,303.74,10.91;9,112.66,168.26,282.77,10.91">An Ensemble Model Using N-grams and Statistical Featuresto Identify Fake News Spreaders on Twitter-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bolonyai</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,283.33,181.81,138.15,10.91">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="9,429.41,181.81,77.77,10.91;9,112.66,195.36,21.79,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,393.33,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,393.33,10.91;9,112.14,249.56,384.74,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,320.71,208.91,185.28,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,34.39,10.91">LSACoNet: A Combination of Lexical and Conceptual Features for Analysis of Fake News Spreaders on Twitter-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Giglou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Razmara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rahgouy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanaei</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,419.03,236.01,86.96,10.91;9,112.14,249.56,47.32,10.91">CLEF 2020 Labs and Workshops</title>
		<title level="s" coord="9,167.44,249.56,103.05,10.91">Notebook Papers, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,393.33,10.91;9,112.39,276.66,221.24,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10754</idno>
		<title level="m" coord="9,288.27,263.11,217.72,10.91;9,112.39,276.66,91.63,10.91">A low dimensionality representation for language variety identification</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,394.61,10.91;9,112.66,303.75,394.53,10.91;9,112.30,317.30,140.09,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,209.74,290.20,276.93,10.91">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,303.75,358.88,10.91">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,330.85,394.61,10.91;9,112.66,344.40,393.32,10.91;9,112.66,357.95,208.61,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,319.39,330.85,168.40,10.91">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,224.46,344.40,281.52,10.91;9,112.66,357.95,135.13,10.91">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
