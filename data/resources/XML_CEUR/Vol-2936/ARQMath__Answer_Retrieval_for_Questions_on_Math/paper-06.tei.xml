<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,88.22,413.50,8.01;1,89.29,107.08,178.23,11.96">Ensembling Ten Math Information Retrieval Systems MIRMU and MSM at ARQMath 2021</title>
				<funder>
					<orgName type="full">South Moravian Centre for International Mobility</orgName>
				</funder>
				<funder>
					<orgName type="full">Brno Ph.D</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.90,132.98,60.39,11.96"><forename type="first">VÃ­t</forename><surname>NovotnÃ½</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,161.93,132.98,76.36,11.96"><forename type="first">Michal</forename><surname>Å tefÃ¡nik</surname></persName>
							<email>stefanik.m@mail.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.93,132.98,66.29,11.96"><forename type="first">DÃ¡vid</forename><surname>LuptÃ¡k</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.86,132.98,73.82,11.96"><forename type="first">Martin</forename><surname>Geletka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,416.33,132.98,53.93,11.96"><forename type="first">Petr</forename><surname>Zelina</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,146.93,49.69,11.96"><forename type="first">Petr</forename><surname>Sojka</surname></persName>
							<email>sojka@fi.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
								<address>
									<addrLine>BotanickÃ¡ 68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,88.22,413.50,8.01;1,89.29,107.08,178.23,11.96">Ensembling Ten Math Information Retrieval Systems MIRMU and MSM at ARQMath 2021</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">FC39333A95AD616CDBC40C4CE7457CE8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>question answering</term>
					<term>math representations</term>
					<term>math-aware information retrieval</term>
					<term>word embeddings</term>
					<term>ensembling</term>
					<term>voting</term>
					<term>ranking</term>
					<term>data fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on the systems that the Math Information Retrieval group at Masaryk University (mirmu) and the team of Faculty of Informatics students (msm) prepared for task 1 (find answers) of the arqmath lab at the clef conference. We have prototyped ten math-aware information retrieval (mir) systems for the main question-answering task. We ensembled the results of the ten "weak" individual systems into committees and let them vote to provide answers to questions. We evaluated the proposed invidividual systems and ensembles, considering their diversity, hyperparameters, and representations used, and classified their approaches. We have shown the diversity of all systems and evaluated four voting algorithms to collect and rank the answers. Ensembling techniques consistently outperformed the base systems and showed the power of voting of diverse systems. Our prototypes help to understand the challenging problems of question answering in the stem domain and our novel reproducible evaluation framework sets a new direction in mir research. Finally, we formulate ten commandments for future work in the area.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This report describes the submissions Math Information Retrieval (mir) group at Masaryk University (mirmu) <ref type="bibr" coords="1,175.96,484.33,12.68,10.91" target="#b0">[1]</ref> with the team of Master students (msm) prepared for question answering task (task 1) of ARQMath 2021 lab <ref type="bibr" coords="1,248.24,497.88,11.48,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,262.67,497.88,7.65,10.91" target="#b2">3]</ref>. Encouraged with our previous results <ref type="bibr" coords="1,452.37,497.88,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,466.79,497.88,7.52,10.91" target="#b4">5,</ref><ref type="bibr" coords="1,477.26,497.88,9.03,10.91" target="#b5">6]</ref> and participation in NTCIR-10, NTCIR-11, NTCIR-12 Math information retrieval challenges, and recent ARQMath 2020 lab <ref type="bibr" coords="1,207.09,524.98,12.87,10.91" target="#b6">[7]</ref> results <ref type="bibr" coords="1,255.00,524.98,11.38,10.91" target="#b7">[8,</ref><ref type="bibr" coords="1,269.11,524.98,7.59,10.91" target="#b8">9]</ref>, we continued our efforts to tackle the challenging math question answering task with new approaches as ensembling techniques. This year we concentrated on the program of ten specific research questions and challenges: Q2: diversity of topics How varies different expressions of information needs as questions answered by information systems? How systems handle out-of-distribution questions, and how their performance varies w.r.t. topics?</p><p>Q3: ensembling Could ensembling techniques give consistently better results than individual systems?</p><p>Q4: ensemble voting strategies To which extent could ensembles and query classification benefit from the diversity of individual systems?</p><p>Q5: representation To which extent the query and document representation and indexing of the meaning of formulae influence the system's performance? How to collate the representation of text and formulae together? How to grab and disambiguate the meaning of symbols in the formulae?</p><p>Q6: attention To which extent the new attention-based approaches could be deployed for math question answering? How does it compare to the standard fine-tuned information retrieval approaches, developed for sole text retrieval?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q7: performance</head><p>To what extent are appropriate and valuable the standard information retrieval techniques as query expansion, keyword similarity metrics, or probabilistic approaches as BM25?</p><p>Q8: canonicalization Does the canonical representation of formulae matter in the math question answering task?</p><p>Q9: inference How to integrate the deduction into a math question answering system? Q10: explainability How to provide arguments of answer ranking based on the ensembling algorithm and scoring of individual systems?</p><p>To answer these questions, we collected ten individual math-aware systems for task 1. It was possible due to PV211 Introduction to Information Retrieval course student projects, and due to works of PV174 Seminar of Laboratory of Electronic and Multimedia Applications taught at the Faculty of Informatics, Masaryk University by the last author. Ten available systems, together with ground truth data from ARQMath 2020 evaluation lab gave us means to measure and evaluate their (hyper)parameters, different ensembling techniques, different representations, different data preprocessing techniques, different evaluation measures, different query expansion strategies, different reranking algorithms, and tackle prescribed questions with rigorous research methodology.</p><p>Our main objective was to gain insight into the research problems above and answer some of them. To this end, we submitted five result lists for each mirmu (by PV174 seminar) and msm (by PV211 course) teams.</p><p>We think that the key in solving the challenges lies in the accurate, evidence-based evaluation of available systems, and their parameters, preprocessing and representation of math-aware data and texts. We have compared our ten available systems using both unsupervised and supervised approaches for systems' hyperparameter tuning, representation learning. Finally, we have ensembled our submissions into four committees of mirmu individual systems that have achieved a better result on 2020 data than any of the single ensembled algorithms alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LaTeX Presentation MathML</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content MathML Prefix</head><p>In this paper, we report our experiments and achievements in detail. Section 2 describes the resources, data preprocessing, representations, and methods used. Section 3 on page 7 reports on ten individual systems and their settings. The gentle reader finds the description of our ensembling algorithms in Section 4 on page 14. We thoroughly discuss our results, insights we got, and future directions in sections 5 on page 19 and 6 on page 20.</p><p>"Don't ask the world to change. . . you change first. " Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets and Methods</head><p>This section will describe the math representations ingested by our information retrieval systems, the corpora used for training the models that power our systems, and the relevance judgments we used for parameter optimization, model selection, and performance estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Math Representations</head><p>There are variety of formats for math formulae representation and ranking <ref type="bibr" coords="3,427.43,452.58,17.96,10.91" target="#b9">[10]</ref> at our fingertips: L A T E X, Presentation MathML (pmml), Content MathML (cmml), Symbol Layout Tree (slt), Operator Tree (opt), <ref type="bibr" coords="3,184.76,479.68,18.03,10.91" target="#b10">[11]</ref> M-Terms, the prefix notation, and the infix notation. For pmml and cmml canonicalized <ref type="bibr" coords="3,179.51,493.23,17.86,10.91" target="#b11">[12]</ref> versions might also be used. Figure <ref type="figure" coords="3,358.73,493.23,5.04,10.91" target="#fig_0">1</ref> shows how the individual math representations are derived from L A T E X, which is prevalent author format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">L A T E X</head><p>As the most direct math representation, we used L A T E X, the standard and most frequent authoring format for math. Although L A T E X is easy to type and preferred by authors, it often encodes the presentation aspects of a math formula rather than its content. L A T E X is also a Turing-complete language and, therefore, impossible to parse in the general case statically. As a result, each formula is represented as a single token in the L A T E X representation. L A T E X is helpful as a baseline math representation and as a basis for deriving more fine-grained math representations described in the following sections. Although having each formula represented as a single token may not seem helpful, two of our ten systems (scm and Compubert) model subwords, which allows them to extract symbols out of the formulae.</p><p>To give an example, the formula ğ‘¥!! -ğ‘¦ 2 = 0 would be represented as a single token $x!! -y^2 = 0$ in L A T E X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Prefix Notation</head><p>To linearize the Operator Tree (opt), <ref type="bibr" coords="4,263.94,149.66,18.06,10.91" target="#b10">[11]</ref> we converted math formulae from opt into the prefix notation. The prefix notation corresponds to the list of visited nodes in the opt in the depth-first-search order, i.e., the topological sorting of the opt. Like L A T E X, the prefix notation is easy to type. Unlike L A T E X, the prefix notation is tokenized into math symbols and independent of a formula's presentation aspects.</p><p>To give an example, the formula ğ‘¥!! -ğ‘¦ 2 = 0 would be represented as the following spaceseparated list of tokens in the prefix notation:</p><formula xml:id="formula_0" coords="4,89.29,233.40,416.99,21.45">U!eq O!minus O!double-factorial V!x O!SUP V!y N!2 N!0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Document Collections</head><p>For training our models, we used the arXMLiv and Math Stack Exchange corpus. Our data preprocessing code is available online.<ref type="foot" coords="4,259.82,305.84,3.71,7.97" target="#foot_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">ArXMLiv</head><p>The arXMLiv 08.2019 corpus <ref type="bibr" coords="4,222.42,356.74,18.06,10.91" target="#b12">[13]</ref> contains 1,374,539 articles from the arXiv.org open-access archive converted from L A T E X to HTML5 and MathML. We split the corpus into four subsets: no_problem (150,701 articles), warning_1 (500,000 articles), warning_2 (328,127 articles), and error (395,711 articles), according to the severity of errors encountered when converting L A T E X to HTML5. We only used the no_problem, warning_1, and warning_2 subsets (978,828 articles) of the corpus to train our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Math Stack Exchange</head><p>The Math Stack Exchange collection V1.2 (m-se) provided by the organizers of the arqmath 2021 competition contains 2,466,080 posts from the Math Stack Exchange question answering website in HTML5 and L A T E X. Besides the answers <ref type="bibr" coords="4,317.36,500.73,12.54,10.91" target="#b0">(1,</ref><ref type="bibr" coords="4,329.89,500.73,16.72,10.91">445,</ref><ref type="bibr" coords="4,346.61,500.73,16.72,10.91">495)</ref>, which are the retrieval unit in task 1 of arqmath, the posts also contain questions (1,020,585) related to the answers and can be used for learning what a good answer for a question is.</p><p>Posts in the m-se collection contain 28,320,920 math formulae. In arqmath 2020, only 26,075,012 math formulae in pmml (92.07%) and 25,366,913 math formulae in cmml (89.57%) have been successfully converted and provided by the organizers as Formulas v1.0. To improve the conversion success rate, we performed our conversion from L A T E X to 26,705,527 math formulae in cmml (94.30%) and 27,232,230 math formulae in pmml (96.16%). In arqmath 2021, we collaborated with the organizers to provide 28,282,477 math formulae in both pmml and cmml (99.86%) as Formulas v2.0.</p><p>The m-se collection is structured and contains not only the body texts but also the titles, tags, comments, up-and down-votes, view counts, and authorship information, among other things. Although the collection provides a wealth of information, it is difficult to navigate and can cause choice overload for newcomers. To make the development of new systems easier, we simplified the corpus into two OOP classes ArqmathQuestionBase and ArqmathAnswerBase, in our pv211-utils Python library. <ref type="foot" coords="5,222.34,326.84,3.71,7.97" target="#foot_1">2</ref> We also created a Jupyter Notebook at the Google Colaboratory service<ref type="foot" coords="5,119.95,340.39,3.71,7.97" target="#foot_2">3</ref> as a template for quick development of new math information retrieval systems by our students using our pv211-utils library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Queries and Relevance Judgements</head><p>Official arqmath 2020 human-annotated task 1 and 2 relevance judgments produced by eight annotators with the fair agreement (ğœ… = 0.34) <ref type="bibr" coords="5,298.62,418.57,17.98,10.91" target="#b13">[14]</ref> are available. We used the relevance judgments for training, hyperparameter optimization, model selection, and performance estimation in our systems. For 77 topics from task 1, the documents were evaluated with a range from 0 (not relevant) to 3 (highly relevant) as the gain. The relevance judgements are highly imbalanced in favor of non-relevant answers: Out of all 39,124 judgements, there exist as many as 35,051 judgements (89.59%) with gain 0, 2,269 judgements (5.8%) with gain 1, 1,071 judgements (2.74%) with gain 2, and only 733 (1.85%) judgements with gain 3.</p><p>Out of the 39,124 judgements over 77 topics, we produced three primary subsets (see Figure <ref type="figure" coords="5,496.59,513.41,3.56,10.91" target="#fig_1">2</ref>):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Train (55)</head><p>The train subset contains a stratified sample of 55 topics (71.43%) and their associated 27,830 judgements (71.13%). We produced the stratified sample of 55 topics by taking three simple random samples of 19 computation topics, 7 concept topics, and 29 proof topics. To divide the topics into computation, concept, and proof categories, we used the detailed annotations provided by organizers <ref type="bibr" coords="5,318.95,590.52,18.07,10.91" target="#b14">[15]</ref> for topics of both years. We used the train subset for training supervised models in our systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation (11)</head><p>The validation subset contains a stratified sample of 11 topics (14.29%) and their associated 5,652 judgements (14.45%). We produced the stratified sample of 11 topics as in the train subset. We used the validation subset for either hyperparameter optimization or model selection in our systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test (11)</head><p>The test subset contains a stratified sample of 11 topics (14.29%) and their associated 5,642 judgements (14.42%). We produced the stratified sample of 11 topics as in the train and validation subsets. We used the test subset for performance estimation of our systems before their submission to ARQMath 2021.</p><p>Out of the three primary splits, we produced three secondary subsets (see Figure <ref type="figure" coords="6,467.70,187.40,5.17,10.91" target="#fig_1">2</ref> on the previous page):</p><p>Bigger train (66) By taking a union of the train and validation subsets, we produced the bigger train subset of 66 topics (85.71%) and their associated 33,482 judgements (85.58%). We used the bigger train subset for training supervised models in systems, where neither hyperparameter optimization nor model selection was required.</p><p>Smaller train (44) By taking a simple random sample of the train subset, we produced the smaller train subset of 44 topics (57.14%) and their associated 22,241 judgements (56.85%). We used the smaller train subset for training supervised models in systems, where both hyperparameter optimization and model selection were required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smaller validation (11)</head><p>By taking a simple random sample of the train subset, we produced the smaller train subset of 11 topics (14.29%) and their associated 5,589 judgements (14.29%). We used the smaller validation subset for hyperparameter optimization in systems, where both hyperparameter optimization and model selection were required.</p><p>We release our six subsets of topics and judgements in our arqmath-eval Python library.<ref type="foot" coords="6,497.53,408.07,3.71,7.97" target="#foot_3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Evaluation Measures</head><p>In hyperparameter optimization, model selection, and performance estimation, we used the normalized discounted cumulative gain prime (ndcg â€² ) to estimate information retrieval accuracy.</p><p>To determine the diversity of our systems, we used the Spearman's rank-correlation coefficient (ğœŒ) between the result lists of our systems averaged across the topics from task 1 of ARQMath 2020 and 2021 to measure the similarity of our systems for clustering. To select the optimal number of clusters, we used the silhouette score as a measure of clustering quality.</p><p>To measure the speed of our systems, we measured the wall clock time on a dedicated machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.">Normalized Discounted Cumulative Gain Prime</head><p>The normalized discounted cumulative gain prime (ndcg â€² <ref type="bibr" coords="6,342.35,589.75,16.76,10.91" target="#b15">[16]</ref>) is an evaluation measure specifically designed for information retrieval with incomplete judgements. ndcg â€² is defined as follows:</p><formula xml:id="formula_1" coords="6,127.34,626.30,200.37,34.74">ndcg â€² = avg ğ‘¡âˆˆğ‘‡ dcg' ğ‘¡ idcg ğ‘¡ , idcg = |relğ‘¡| âˆ‘ï¸ ğ‘–=1 gain ğ‘¡ (rel ğ‘¡,ğ‘– ) log 2 (ğ‘– + 1)</formula><p>, and dcg' =</p><formula xml:id="formula_2" coords="6,384.16,626.30,121.82,34.74">|res'ğ‘¡| âˆ‘ï¸ ğ‘–=1 gain ğ‘¡ (res' ğ‘¡,ğ‘– ) log 2 (ğ‘– + 1) ,<label>(1)</label></formula><p>where ğ‘‡ are the topics for a task, rel ğ‘¡ is a list of relevant documents for topic ğ‘¡ in the descending order of their gain up to position 1,000, res ğ‘¡ is a list of results produced for topic ğ‘¡ our system up to position 1,000, res' ğ‘¡ = rel ğ‘¡ âˆ© res ğ‘¡ , and gain ğ‘¡ (ğ‘…) is the gain of result ğ‘… for topic ğ‘¡.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2.">Spearman's Rank-Correlation Coefficient</head><p>Spearman's rank-correlation coefficient (ğœŒ) <ref type="bibr" coords="7,277.29,163.39,17.75,10.91" target="#b16">[17]</ref> is a general non-parametric measure of rank correlation. Spearman's ğœŒ between random variables ğ‘‹ and ğ‘Œ corresponds to Pearson's correlation coefficient (ğ‘Ÿ) between the rank variables rg ğ‘‹ and rg ğ‘Œ :</p><formula xml:id="formula_3" coords="7,125.32,213.70,380.66,28.22">ğœŒ = cov(rg ğ‘‹ , rg ğ‘Œ ) ğœ rg ğ‘‹ â€¢ ğœ rg ğ‘Œ and cov(rg ğ‘‹ , rg ğ‘Œ ) = E [ï¸€ (rg ğ‘‹ -E[rg ğ‘‹ ])â€¢(rg ğ‘Œ -E[rg ğ‘Œ ]) ]ï¸€ .<label>(2)</label></formula><p>In our experiments, rg ğ‘‹ and rg ğ‘Œ correspond to the ranks of the same answer in the result lists of two systems for a single topic from task 1 of arqmath 2021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3.">Silhouette Score</head><p>The silhouette score (ğ‘ ) <ref type="bibr" coords="7,199.57,315.06,18.07,10.91" target="#b17">[18]</ref> is an intrinsic measure of clustering quality that compares the intra-cluster cohesion (ğ‘) and the inter-cluster separation (ğ‘). The score ğ‘  is defined as follows:</p><formula xml:id="formula_4" coords="7,94.81,352.05,411.17,30.66">ğ‘ (ğ‘–) = ğ‘(ğ‘–) -ğ‘(ğ‘–) max{ğ‘(ğ‘–), ğ‘(ğ‘–)} , ğ‘(ğ‘–) = 1 |ğ¶ ğ‘– | -1 âˆ‘ï¸ ğ‘—âˆˆğ¶ ğ‘– ,ğ‘–Ì¸ =ğ‘— ğ‘‘(ğ‘–, ğ‘—), and ğ‘(ğ‘–) = min ğ‘—,ğ‘–Ì¸ =ğ‘— 1 |ğ¶ ğ‘˜ | âˆ‘ï¸ ğ‘—âˆˆğ¶ ğ‘˜ ğ‘‘(ğ‘–, ğ‘—),<label>(3)</label></formula><p>where ğ‘– is a data point, ğ¶ ğ‘– is the cluster of data point ğ‘–, and ğ‘‘(ğ‘–, ğ‘—) is the distance between data points ğ‘– and ğ‘—. In our experiments, data points were the ensembled systems, the distance measure ğ‘‘ was 1 -ğœŒ, and we selected the number of clusters that maximized the expected value E[ğ‘ ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4.">Wall Clock Time</head><p>The wall clock time is the time experienced by the user. We measure the wall clock time of the preprocessing, training, and information retrieval on a dedicated machine with two nvidia Tesla T4 gpus (16 GB vram), 377 GB ram, and four Intel(R) Xeonâ„¢ Gold 6230 cpus (80 cores at 2.10 GHz).</p><p>"The main thing is not study, but doing. " Chapters of the Fathers (Pirkei Avot, 1:17)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Individual Systems</head><p>In this section, we will describe the individual systems submitted by the mirmu and msm teams. We describe two best-performing systems of the msm team (mg and pz) and the mirmu team (scm and Compubert) in detail. We then briefly summarize the architectures and the results of our remaining systems on task 1 of arqmath 2021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">BM25 + (msm -mg)</head><p>The BM25 algorithm is often used as the first choice for many information retrieval tasks because of its simplicity and its better performance over tf-idf systems. In this section, we will describe our system based on the BM25 + model. Our experimental code is available online. <ref type="foot" coords="8,495.21,132.88,3.71,7.97" target="#foot_4">5</ref>BM25 + is an improvement over BM25 introduced by Lv and Zhai <ref type="bibr" coords="8,393.25,148.18,16.25,10.91" target="#b18">[19]</ref>. Together with other alternatives, such as BM25-L, BM25-adapt, and BM25-T, this improvement surpasses the basic BM25 algorithm on trec collections. <ref type="bibr" coords="8,252.75,175.28,17.76,10.91" target="#b19">[20]</ref> BM25 + estimates the relevance of a document ğ‘‘ for a query ğ‘ as follows:</p><formula xml:id="formula_5" coords="8,129.19,211.56,376.80,39.02">BM25 + (ğ‘‘, ğ‘) = âˆ‘ï¸ ğ‘¡âˆˆğ‘ log (ï¸‚ ğ‘ + 1 df ğ‘¡ )ï¸‚ â€¢ â› â (ğ‘˜ 1 + 1) â€¢ tf ğ‘¡,ğ‘‘ ğ‘˜ 1 â€¢ (ï¸ (1 -ğ‘) + ğ‘ (ï¸ ğ¿ d ğ¿avg )ï¸)ï¸ + t fd + ğ›¿ â â  ,<label>(4)</label></formula><p>where ğ‘˜ 1 , ğ‘, and ğ›¿ are hyperparameters, ğ‘ is the number of documents in the collection, df ğ‘¡ is the number of documents containing the term ğ‘¡, tf ğ‘¡,ğ‘‘ is frequency of term ğ‘¡ in document ğ‘‘, ğ¿ ğ‘‘ the length of document ğ‘‘ in words, and ğ¿ avg is the expected length of a document in words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Configuration</head><p>In our preprocessing, we tokenized text with math formulae in L A T E X by splitting on sequences of whitespaces. We then stemmed the individual tokens using the English Snowball stemmer available in the NLTK Python library. We represented each answer as the concatenation of its body with the title, body, and tags of its parent question. We used the implementation of BM25 + in the rank_bm25 Python library <ref type="foot" coords="8,235.59,388.16,3.71,7.97" target="#foot_5">6</ref> . We optimized the hyperparameters ğ‘˜ 1 , ğ‘, and ğ›¿ using grid search. The default parameters ğ‘˜ 1 = 1.5, ğ‘ = 0.75, and ğ›¿ = 1.0 achieved the best ndcg â€² on the bigger train subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Results</head><p>On the test subset, BM25 + achieved 0.464 ndcg â€² , which is the best result of all our individual systems. On the judgements for task 1 of arqmath 2021, BM25 + achieved 0.278 ndcg â€² , which is again the best result of all our individual systems.</p><p>Our preprocessing of the m-se collection took 50:15 minutes and the indexing took another 65 seconds. The average query time was 69.3 seconds with a minimum of 22.4 seconds for topic A.289 and a maximum of 318.9 seconds for topic A.216.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pyserini (msm -pz)</head><p>Pyserini <ref type="bibr" coords="8,127.38,583.82,17.76,10.91" target="#b20">[21]</ref> is an Apache-licensed Python library for reproducible information retrieval. It uses Anserini <ref type="bibr" coords="8,129.92,597.37,17.87,10.91" target="#b21">[22]</ref> for sparse representation-based retrieval and Faiss <ref type="bibr" coords="8,375.69,597.37,17.86,10.91" target="#b22">[23]</ref> for dense representationbased retrieval. Pyserini is quite fast, easy to use, and comes with several prebuilt indexes.</p><p>Creating custom indexes is supported as well. In this section, we will describe our system based on Pyserini. Our experimental code is available online. 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Configuration</head><p>In our preprocessing, we used the L A T E X representation of math formulae. We represented each answer as the concatenation of its body with three repetitions of the title and the tags of its parent question. The answers were then preprocessed and indexed by the Pyserini indexer, which is based on Anserini and Lucene, with the default settings: the removal of possessives, lowercasing, the removal of English stopwords, and stemming with the Porter stemmer.</p><p>The document relevance was estimated by the SimpleSearcher class, which corresponds to the BM25 model with the default hyperparameters ğ‘˜ 1 = 0.9 and ğ‘ = 0.4. Even though Pyserini supports many other options and extensions, such as the RM3 query expansion, other ranking models, and dense document reranking, our system used the default options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Results</head><p>On the test subset, Pyserini achieved 0.449 ndcg â€² , which is the second best result of all our individual systems. On the judgements for task 1 of arqmath 2021, Pyserini achieved 0.275 ndcg â€² , which is again the second best result of all our individual systems.</p><p>Our preprocessing and indexing of the m-se collection took 3:44 minutes. The average query time was 1.1 seconds with a minimum of 0.5 seconds for topic A.264 and a maximum of 2.6 seconds for topic A.221.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Soft Cosine Measure (mirmu -scm)</head><p>Math information retrieval systems often rely on Salton's tf-idf model <ref type="bibr" coords="9,417.42,425.04,16.41,10.91" target="#b23">[24]</ref>, which is interpretable, but which also reduces meaningful statements in human and mathematical languages to an unintelligible salad of key words and symbols. At arqmath 2020, we introduced the soft vector space of Sidorov et al. <ref type="bibr" coords="9,223.34,465.69,17.91,10.91" target="#b24">[25]</ref> and its soft cosine document similarity measure (scm, see Figure <ref type="figure" coords="9,120.20,479.24,5.04,10.91" target="#fig_3">4</ref> on the following page) and we achieved the best ndcg â€² on task 1 of arqmath 2020 of all our individual systems. <ref type="bibr" coords="9,209.55,492.78,11.39,10.91" target="#b8">[9,</ref><ref type="bibr" coords="9,223.67,492.78,44.66,10.91">Section 4]</ref> In this section, we will describe our system based on scm. Our experimental code is available online. 8  For ARQMath 2021, we also produced an online demo of the scm, 9 which allows the user to interactively explore a small set of topics 10 and their nearest answers. The demo also allows the user to compare two documents to see why they are considered similar by the scm, see Figure <ref type="figure" coords="9,501.01,546.98,4.97,10.91" target="#fig_2">3</ref> on the next page.  The representation of two documents, "Hi, world" and "Hello, world" in the tf-idf vector space model (vsm, left) and in the tf-idf soft vector space model (soft vsm, right). In the vsm, different terms correspond to orthogonal axes, making the document representations distant despite their semantic equivalence. In the soft vsm, different terms correspond to non-orthogonal axes, where the angle between the axes is proportional to the similarity of terms in a word embedding space (middle).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Configuration</head><p>In our preprocessing, we tokenized text with math formulae in the prefix notation by first splitting on whitespaces to separate text and math tokens. Then, we upper-cased the math tokens and we lower-cased the text tokens, so that they contained different subwords for the training of fastText embeddings (described below). We then performed a second tokenization of the text tokens to remove punctuation and numbers using the simple_preprocess function from the Gensim Python library <ref type="bibr" coords="11,210.90,86.97,16.25,10.91" target="#b25">[26]</ref>. We represented each answer as the concatenation of its body with three titles, the body, and the tags of its parent question.</p><p>As our source of similarity between words and symbols, we used our Medium fastText embeddings of text and math <ref type="foot" coords="11,219.03,125.86,7.41,7.97" target="#foot_6">11</ref> , which were trained on both the m-se collection and ArXMLiv and which achieved the best ndcg â€² on task 1 of arqmath 2020. [9, Section 4.4] From the fastText embeddings, we extracted a term similarity matrix <ref type="foot" coords="11,360.41,152.96,7.41,7.97" target="#foot_7">12</ref> using the optimal parameters Sym = âœ“, Dom = âœ“, and ğ¶ = 100 from arqmath 2020. <ref type="bibr" coords="11,343.47,168.26,11.36,10.91" target="#b8">[9,</ref><ref type="bibr" coords="11,357.55,168.26,51.88,10.91">Section 4.3]</ref> We optimized the smart weighting scheme of our tf-idf model using grid search. The Lnu.ltb weighting scheme with the pivoted document length normalization <ref type="bibr" coords="11,434.21,195.36,18.07,10.91" target="#b26">[27]</ref> at slope 0.2 achieved the best ndcg â€² on the bigger train subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Results</head><p>On the test subset, scm achieved 0.424 ndcg â€² , which is the third best result of all our individual systems. On the judgements for task 1 of arqmath 2021, scm achieved 0.250 ndcg â€² , which is the fourth best result of all our individual systems.</p><p>Our preprocessing of the m-se collection took 13:28 minutes. The training of the fastText embeddings took 01:45 hours and the construction of the term similarity matrix took another 32:39 minutes. The hyperparameter optimization took 04:42:34 hours. The average query time was 223.39 seconds with a minimum of 210.68 seconds for topic A.254 and a maximum of 270.18 seconds for topic A.273. Using a single matrix product to retrieve results for all 100 topics from task 1 of arqmath 2021 took only 353.0 seconds, which is 63.28Ã— faster than ad-hoc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Computational BERT (mirmu -Compubert)</head><p>Our Compubert system aims to utilize the expressive power of pre-trained Transformer models <ref type="bibr" coords="11,103.77,429.91,17.75,10.91" target="#b27">[28]</ref> and the results of applying the Transformer architecture to complex math-related tasks, such as computing derivatives and first-order differential equations. <ref type="bibr" coords="11,401.72,443.46,18.07,10.91" target="#b28">[29]</ref> In this section, we will describe Compubert and its results on task 1 of the arqmath 2020 competition. Our experimental code is available online. <ref type="foot" coords="11,256.22,468.80,7.41,7.97" target="#foot_8">13</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Matching Questions with Answers</head><p>In addition to math representation, we have to contend with additional challenges characteristic to information retrieval but alien to Transformers: While the original Transformer architecture <ref type="bibr" coords="11,109.56,546.98,17.75,10.91" target="#b27">[28]</ref> builds upon the Wordpiece text segmentation <ref type="bibr" coords="11,330.12,546.98,17.76,10.91" target="#b29">[30]</ref> that optimizes the representation of subwords (not unlike fastText in the scm), we also need to uniformly represent long spans of text.</p><p>We address this challenge with an approach introduced by Reimers and Gurevych <ref type="bibr" coords="11,468.86,574.08,17.91,10.91" target="#b30">[31]</ref> and shown in Figure <ref type="figure" coords="11,163.24,587.63,4.99,10.91">5</ref> on the following page. The underlying idea of their Sentence Transformers is to adjust the pre-trained language model so that the pooled representation of longer span of text respect an objective of given task. We experiment with multiple objectives that are relevant for information retrieval, such as Cosine Contrastive loss on pairs of question and answer, with different representations of formulae part and different selection of positive and negative samples of answers paired with given question. We conclude with a selection of a Multiple Negatives Ranking Loss on a L A T E X math representation, with a selection positive and negative anchors selected as we describe below.</p><p>This approach has shown to reach state-of-the-art results on an identification of duplicate questions in Quora,where the unified representations of questions are fine-tuned to be used to classify whether two questions are a duplicate of each other or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Model Training</head><p>In our approach, we iterate over questions and for each, we pick the positive anchor as the accepted answer of given question, and a batch of negative anchors as random accepted answers of other questions. We skip the questions with no accepted answer. Then, we include the positive anchor into the batch of the negative ones on a random position and we train the system to identify the position of the true accepted answer as a softmax of the embedded representation.</p><p>Setting the batch of the fixed size, we adjust the weights of the whole Transformer network by Cross-Entropy loss, as shown on Figure <ref type="figure" coords="12,277.52,618.20,3.66,10.91">5</ref>. In essence, this approach is similar to a traditional classification training of neural networks.</p><p>Specifically, we set a batch size of 64, meaning the system is required to pick out the accepted answer out of the 64 provided ones. Reimers and Gurevych <ref type="bibr" coords="12,367.28,658.85,17.91,10.91" target="#b30">[31]</ref> report that increasing the batch size as high as possible shows to improve a quality of the system, hence this is the biggest batch we can fit into our 15 GB of gpu memory. We measure a significant validation difference depending on the math representation, and we find the L A T E X representation to work the best. Additionally, by an example of bart <ref type="bibr" coords="13,255.76,127.61,16.33,10.91" target="#b32">[33]</ref>, we prepend the contents of questions and answers by "Question: " and "Answer: " respectively, so that the system can recognize the kind of item it aims to represent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.">Results</head><p>On the test subset, Compubert achieved 0.264 ndcg â€² , which is the fourth best result of all our individual systems. On the judgements for task 1 of arqmath 2021, Compubert achieved 0.262 ndcg â€² , which is the third best result of all our individual systems.</p><p>The training of the Compubert model took 20 hours. The subsequent inference and indexing of document vectors took another 1:27:57 hours. The average query time was 4.9 seconds with a minimum of 3.3 seconds for topic A.2921 and a maximum of 5.3 seconds for topic A. <ref type="bibr" coords="13,470.32,271.79,9.01,10.91" target="#b19">20</ref>.</p><p>"If what you seek is Truth, there is one thing you must have above all else. " "I know. An overwhelming passion for it. " "No. An unremitting readiness to admit you may be wrong. "</p><p>Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Other Systems (msm -mh, lm, mp, jk, am, and vs)</head><p>The remaining systems of the msm team in the descending order of their ndcg â€² on the test subset, are mh, lm, mp, jk, am, and vs. In this section, we will briefly summarize their architectures and results. Our experimental code is available online: mh <ref type="foot" coords="13,348.07,391.09,7.41,7.97" target="#foot_9">14</ref> , lm <ref type="foot" coords="13,373.09,391.09,7.41,7.97" target="#foot_10">15</ref> , mp <ref type="foot" coords="13,398.43,391.09,7.41,7.97" target="#foot_11">16</ref> , jk <ref type="foot" coords="13,420.90,391.09,7.41,7.97" target="#foot_12">17</ref> , am <ref type="foot" coords="13,447.28,391.09,7.41,7.97" target="#foot_13">18</ref> , and vs <ref type="foot" coords="13,489.94,391.09,7.41,7.97" target="#foot_14">19</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.">Configuration</head><p>In our preprocessing, everyone used the L A T E X representation of math formulae and tf-idf except for am, who used the prefix notation for the representation of math formulae and BM25. All systems were unsupervised except for mp, who optimized the hyperparameters of Roccio's pseudo-relevance feedback and pivoted document length normalization <ref type="bibr" coords="13,410.47,482.82,16.25,10.91" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2.">Results</head><p>On the test subset, our systems achieved between 0.127 and 0.268 ndcg â€² . On the judgements for task 1 of arqmath 2021, our systems achieved between 0.066 and 0.159 ndcg â€² .</p><p>The average query time was 22.0 seconds with a minimum of 2.9 seconds by jk for topic A.264 and a maximum of 329.5 seconds by am for topic A.291. "And as for you all, I will make your reward great as though you had accomplished all the work. " Chapters of the Fathers (Pirkei Avot, 2:2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Ensemble Systems</head><p>Different mir systems can agree on a small portion of the most relevant documents, reflecting different 'points of view' on the search problem. Depending on dozens of parameters, each individual system will miss the great majority of relevant documents. With ensembling and voting techniques, we can combine the strengths of different systems to produce more accurate results. Historically, there is a long tradition of boosting, <ref type="bibr" coords="14,304.55,198.20,16.31,10.91" target="#b33">[34,</ref><ref type="bibr" coords="14,323.57,198.20,12.23,10.91" target="#b34">35]</ref>, ensembling <ref type="bibr" coords="14,395.39,198.20,16.09,10.91" target="#b35">[36]</ref>, data fusion <ref type="bibr" coords="14,469.42,198.20,17.76,10.91" target="#b36">[37]</ref> and voting approaches <ref type="bibr" coords="14,173.51,211.74,16.43,10.91" target="#b37">[38,</ref><ref type="bibr" coords="14,192.67,211.74,14.03,10.91" target="#b38">39]</ref> in the information retrieval research.</p><p>A successful ensemble requires sufficient diversity of the individual systems, and math-aware systems are not exceptional in this behaviour. <ref type="bibr" coords="14,305.56,238.84,18.06,10.91" target="#b39">[40]</ref> Using Spearman's ğœŒ and the silhouette score (see Section 2.4 on page 6), we have clustered all non-baseline primary submissions to task 1 of arqmath 2020 except zbMATH who retrieved only a single answer for every topic. Figure <ref type="figure" coords="14,120.76,279.49,5.14,10.91">6</ref> on the next page shows that we have received only three clusters of systems, which indicates limited diversity. We have also clustered all our submissions to task 1 of arqmath 2021. Figure <ref type="figure" coords="14,144.97,306.59,4.97,10.91">7</ref> on the following page shows that we have received six clusters of systems, which indicates a notable increase in diversity. In Figure <ref type="figure" coords="14,318.41,320.14,5.17,10.91">8</ref> on page 16, we show that systems from the six clusters have different strengths and weaknesses: For example, Compubert receives the most consistent results across both text-and math-based topics, excels at short topics, but its performance deteriorates for long topics that don't fit into its context window. By contrast, tf-idf-and BM25-based systems excel at text-based topics, but their performance deteriorates for math-based topics. Systems that model soft matches, such as the scm, can exploit both short and long topics. Our experimental code for figures 7 and 8 is available online. 20, 21, 22  We have implemented, computed, and submitted three ensembling techniques: ibc described in Section 4.2 on page 16, wibc in Section 4.3 on page 17, and rbc in Section 4.4 on page 18. We have also implemented and computed one out-of-competition ensembling technique: rrf described in Section 4.1 on the following page. We have used our techniques to ensemble the result lists of all ten systems of the mirmu and msm teams. In this section, we will describe our ensembling techniques and their results on task 1 of arqmath 2021. To show that strength lies in diversity rather than numbers, we also report ndcg â€² using randomly selected systems from the six clusters in Figure <ref type="figure" coords="14,201.12,509.83,5.07,10.91">7</ref> as an ablation study.</p><p>To estimate the performance of our ensemble systems in the absence of judgements for task 1 of arqmath 2021, we ensembled all non-baseline primary submissions for task 1 of arqmath 2020 for performance estimation and we report ndcg â€² on the test subset in addition to ndcg â€² on the now-available judgements for task 1 of arqmath 2021. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Non-Weighted Ensemble Baseline (mirmu -rrf)</head><p>The reciprocal rank fusion (rrf) is an ensembling technique, which was shown by Cormack et al. <ref type="bibr" coords="15,112.00,419.71,17.91,10.91" target="#b40">[41]</ref> to outperform Condorcet and individual rank learning methods on the letor 3 dataset. Our experimental code is available online.<ref type="foot" coords="15,276.46,431.50,7.41,7.97" target="#foot_15">23</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Configuration</head><p>The rrf has the parameter ğ‘˜, which mitigates the impact of high rankings by outlier systems. Before applying the rrf to the test subset, we first optimized the value of ğ‘˜ on the bigger-train subset, and we received the optimal value ğ‘˜ = 644. Before applying the rrf to the topics for task 1 of arqmath 2021, we first optimized the value of ğ‘˜ on the test subset, and we received the optimal value ğ‘˜ = 275. See Figure <ref type="figure" coords="15,257.18,536.78,4.97,10.91">9</ref> on the next page for detailed results of the optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Results</head><p>On the test subset, rrf received 0.464 ndcg â€² , which is the second best result of all our systems, tied with BM25 + . On the judgements for task 1 of arqmath 2021, rrf achieved 0.309 ndcg â€² , which is the third best result of all our systems. Ensembling only six systems as part of our ablation study increased ndcg â€² from 0.309 to 0.313. Ensembling all non-baseline primary The results of optimizing the parameter ğ‘˜ (on the ğ‘¥ axis) of the rrf ensemble baseline using ndcg â€² (on the ğ‘¦ axis) on the bigger-train subset using all non-baseline primary submissions to task 1 of arqmath 2020 (left) and on the test subset using all ten systems of the mirmu and msm teams (right). The optimal values are ğ‘˜ = 644 on the left and ğ‘˜ = 275 on the right.</p><p>submissions increased ndcg â€² from 0.309 to 0.556: the best result reported in the arqmath 2021 competition.</p><p>On top of the time to produce the result lists of the ensembled systems, the average query time of rrf was 0.07 seconds with a minimum of 0.02 seconds for topic A.238 and a maximum of 0.59 seconds for topic A.207.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Non-Weighted Ensemble (mirmu -ibc)</head><p>At arqmath 2020, we introduced a simple parameter-free algorithm (ibc) for ensembling an arbitrary number of result lists into a single result list, which achieved the best ndcg â€² on task 1 of arqmath 2020 of all our individual systems. [9, Section 7] When we used our algorithm to ensemble the result lists all non-baseline primary submissions to task 1 of arqmath 2020, we received the highest ndcg â€² in the competition (0.419). Our experimental code is available online. <ref type="foot" coords="17,119.62,98.76,7.41,7.97" target="#foot_16">24</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Configuration</head><p>Majority judgement is a single-winner election method by Balinski and Laraki <ref type="bibr" coords="17,429.45,149.84,16.21,10.91" target="#b41">[42]</ref>, which elects the candidate with the highest median rating. In our ibc ensembling technique, the candidates are all answers in the m-se collection and their ratings are computed as 1000-rank /1000 with ranks taken from the result lists of the individual systems. Ties between several winners are first broken by selecting a random rating out of a uniform distribution of all ratings. Further ties are broken randomly. [9, <ref type="bibr" coords="17,202.33,217.59,43.38,10.91">Section 7]</ref>. The result list of ibc consists of the first 1,000 iteratively elected winners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Results</head><p>On the test subset, ibc received 0.452 ndcg â€² , which is the fourth best result of all our systems. On the judgements for task 1 of arqmath 2021, ibc achieved 0.286 ndcg â€² , which is also the fourth best result of all our systems. Ensembling only six systems as part of our ablation study increased ndcg â€² from 0.286 to 0.312. Ensembling all non-baseline primary submissions increased ndcg â€² from 0.286 to 0.514: the second best result reported in the arqmath 2021 competition.</p><p>On top of the time to produce the result lists of the ensembled systems, the average query time of ibc was 0.02 seconds with a minimum of 0.01 seconds for topic A.238 and a maximum of 0.24 seconds for topic A.234.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Weighted Ensemble (mirmu -wibc)</head><p>Our ibc ensembling technique assumes that all systems are equally trustworthy and qualified in their rating of the answers. Our wibc ensembling technique assigns weights to the individual systems. Our experimental code is available online. <ref type="foot" coords="17,317.36,450.38,7.41,7.97" target="#foot_17">25</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Configuration</head><p>Instead of electing the candidate with the highest median rating, wibc elects the candidate with the highest weighted median rating. Instead of breaking ties by selecting a random rating out of a uniform distribution of all ratings, we select a random rating out of a weighted uniform distribution. We use weights provided by our rbc ensembling technique from in Section 4.4 on the following page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Results</head><p>On the test subset, wibc received 0.456 ndcg â€² , which is the third best result of all our systems, slightly below the rrf ensemble baseline. On the judgements for task 1 of arqmath 2021, wibc achieved 0.332 ndcg â€² , which is the best result of all our systems. Ensembling only six systems as part of our ablation study slightly decreased ndcg â€² from 0.332 to 0.327, indicating that wibc can utilize both diversity and redundancy.</p><p>On top of the time to produce the result lists of the ensembled systems, the average query time of wibc was 0.2 seconds with a minimum of 0.1 seconds for topic A.270 and a maximum of 0.5 seconds for topic A.268.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ensembling by Regression (mirmu -rbc)</head><p>Both our ibc and wibc ensembling techniques decide on the rank of the answers from the m-se collection. In contrast, our rbc ensembling technique directly estimates the relevance of an answer. Our experimental code is available online. 26   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">Configuration</head><p>First, we trained a number of regression model (linear, sgd, ridge, Bayesian ridge, svr, ğ‘˜nn, pls, mlp) to predict the gain of train judgements from the ranks in the result lists of the individual systems. Secondly, we selected the best regression model (linear) using the validation subset. For the performance estimation of rbc, we produced a result list by taking the 1,000 answers with the highest predicted gain for each topic in the test subset. For the performance estimation of wibc, we used the coefficients of the regression model as system weights.</p><p>For the submission of rbc to arqmath 2021, we retrained the best regression model to predict the gain of test judgements from the ranks in the result lists of our individual systems. This is necessary, because our regression model has only been trained on the non-baseline primary submissions for task 1 of arqmath 2020, nor our ten systems of the mirmu and msm teams, and the only subset that had not yet been seen by our ten systems was the test subset. For the submission of wibc to arqmath 2021, we used the coefficients of the retrained regression model as system weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2.">Results</head><p>On the test subset, rbc received 0.551 ndcg â€² , which is the best result of all our systems. On the judgements for task 1 of arqmath 2021, rbc achieved 0.322 ndcg â€² , which is the second best result of all our systems, slightly below wibc. Ensembling only six systems as part of our ablation study increased ndcg â€² from 0.322 to 0.328.</p><p>On top of the time to produce the result lists of the ensembled systems, the average query time of rbc was 0.04 seconds with a minimum of 0.02 seconds for topic A.201 and a maximum of 0.06 seconds for topic A.212. "Meaning is only found when you go beyond meaning. " Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Figure <ref type="figure" coords="19,121.09,144.00,10.35,10.91" target="#fig_6">10</ref> shows that on the judgements for task 1 of arqmath 2021, our Ensemble systems received the best ndcg â€² out of all our systems. Both on the test set and on the judgements for task 1 of arqmath 2021, there is a large gap between the three systems that enriched their answers with the text of their parent questions (scm, pz, mg) and the remaining individual systems.</p><p>Unlike for other systems, the ndcg â€² for Compubert does not significantly decrease from the task subset to the judgements for task 1 of arqmath 2021. Due to the unique architecture of Compubert, we theorize that this is because the top 1,000 results of Compubert contain relevant answers, which have not been annotated for arqmath 2020.</p><p>Figure <ref type="figure" coords="19,130.98,569.33,10.04,10.91" target="#fig_7">11</ref> on the following page shows that the pz system based on the Anserini library <ref type="bibr" coords="19,488.15,569.33,17.84,10.91" target="#b21">[22]</ref> is not only very accurate, but also among our three fastest systems in terms of preprocessing and indexing, and our fastest system in terms of the average search time. "Wisdom tends to grow in proportion to one's awareness of one's ignorance. " Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>Motivated by our curiosity to answer our ten research questions, we have introduced ten diverse math-aware information systems. We have data-evidenced using collected systems and available ground truth that good voting strategies of ensembles of baseline systems have the capacity to outperform individual systems.</p><p>From our experiments, we formulate ten commandments for math-aware question answering tasks like ARQMath on Math Stack Exchange: C1: diversity of systems Use as diverse and as many different systems as you can.</p><p>C2: diversity of topics Bear in mind the specificity, diachronicity, context of topics, together with relevance judgements of similar topics. If available, take the seeker history and personality into account to disambiguate the information need.</p><p>C3: ensembling Diversity is powerful. Clever ensembling of different points of view into account is efficient approach to get better findings and decisions.</p><p>C4: ensemble voting strategies Voting strategies are important to weight different aspects of individual systems. It pays off to choose the appropriate ensembling techniques to consistently get better results.</p><p>C5: representation Representation matters. The better semantic metric we could design for text and math formulae, the better capture of the topic and answer meaning, and the better the performance! C6: attention Attention is not all you need, but attention-based models have huge capacity to learn both text and formulae representations and short inferences.</p><p>C7: performance Good system performance is a bonus to speed up the development and fine-tuning. Precompute as much as possible, and make the indexes sorted according the semantics. There is always a space for late optimization.</p><p>C8: canonicalization Give attention to the diversity of language and mathematical notation and use measures of the semantic similarity as much as you can.</p><p>C9: inference To tackle the exponential growth of knowledge, embrace inference into your (deep) models.</p><p>C10: explainability Insight, understanding the whole system and explainability for results matters not only to users for result evidence, but also for fine-tuning and system optimization.</p><p>Setting the tools, computing environment, and datasets are crucial for studying and researching complex information retrieval methods. <ref type="bibr" coords="21,289.19,350.30,16.39,10.91" target="#b42">[43]</ref>. Thanks to the open source tools, arqmath competition datasets, and the production environment set at the Faculty of Informatics, Masaryk University, ten student systems were prototyped. We were able to set up a framework for evaluation of not only varieties of individual mir systems and approaches, but also of their voting and ensembles. This sets the ground to speed up our understanding of innermost features of mir systems and paves the road to the better fulfilment of information needs of math-aware problem searchers.</p><p>Diversity rulez! Looking at complex problem from diverse viewpoints is a good thing and so is wise compounding and merging diverse approaches and their results!</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,172.08,330.29,4.82"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dependencies between math representations ingested by our systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,241.94,416.87,4.82;5,89.29,253.89,411.70,4.79;5,89.29,84.19,416.71,137.38"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: We split the 39,124 judgements over 77 topics from task 1 of arqmath 2020 into subsets for training, hyperparameter optimization, model selection, and performance estimation in our systems.</figDesc><graphic coords="5,89.29,84.19,416.71,137.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,89.29,309.63,416.69,4.82;10,89.29,321.58,416.70,4.79;10,88.93,333.54,163.93,4.79;10,89.29,84.19,416.72,204.23"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: An online demo of the scm system, which allows the user to interactively explore a small set of topics and their nearest answers. The demo also allows the user to compare two documents to see why they are considered similar by scm.</figDesc><graphic coords="10,89.29,84.19,416.72,204.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,89.29,489.61,416.87,4.82;10,89.29,501.56,418.36,4.79;10,89.29,513.52,416.87,4.79;10,89.29,525.47,416.69,4.79;10,89.29,537.43,416.12,4.79;10,125.55,358.57,341.68,132.76"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4:The representation of two documents, "Hi, world" and "Hello, world" in the tf-idf vector space model (vsm, left) and in the tf-idf soft vector space model (soft vsm, right). In the vsm, different terms correspond to orthogonal axes, making the document representations distant despite their semantic equivalence. In the soft vsm, different terms correspond to non-orthogonal axes, where the angle between the axes is proportional to the similarity of terms in a word embedding space (middle).</figDesc><graphic coords="10,125.55,358.57,341.68,132.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="15,89.29,172.09,416.69,4.82;15,89.29,184.04,416.70,4.79;15,89.29,196.00,164.16,4.79"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: A clustering of all primary submissions to task 1 of arqmath 2020 except zbMATH who retrieved only a single answer for every topic. Maximizing the silhouette score produces only three clusters, which indicates small diversity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="16,89.29,235.60,418.36,10.31;16,89.29,249.13,416.70,8.74;16,89.29,263.13,416.70,4.79;16,89.29,275.09,61.68,4.79"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Per-topic ndcg â€² (on the ğ‘¦ axis) of randomly selected systems from the six clusters in Figure 7 on the topics for task 1 of arqmath 2021, which we place on the ğ‘¥ axis according to the ratio of math tokens to all tokens (left) and according to the topic length in tokens (right) in the prefix math representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="19,89.29,431.03,416.69,8.44;19,88.99,446.60,269.15,4.79"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The ndcg â€² of our ten individual systems and our four ensemble methods on the test subset (top) and on the judgements for task 1 of arqmath 2021 (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="20,89.29,342.26,418.23,4.82"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Average query time and the training and preprocessing of the individual systems (log scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="12,89.06,91.42,416.92,256.77"><head></head><label></label><figDesc>Can anyone explain ... Compubert model and Multiple Batch Negatives objective, introduced by Reimers and Gurevych:<ref type="bibr" coords="12,134.64,307.54,16.46,4.79" target="#b30">[31]</ref> Compubert averages the Wordpiece embeddings<ref type="bibr" coords="12,360.36,307.54,16.46,4.79" target="#b31">[32]</ref> into a single representation of 768 floats, that is used similarly to classification: The model is trained to minimize Cross-entropy of softmax on the produced embedding, where an accepted answer holds expected value of one, and a random selection of other accepted answers holds expected value of zero.</figDesc><table coords="12,89.29,91.42,415.65,208.98"><row><cell cols="3">Sentence Transformer</cell><cell></cell><cell></cell><cell cols="2">[A 1 embedding]</cell></row><row><cell>[wordpiece embedding]</cell><cell>[wordpiece embedding] (Mean) Pooling model</cell><cell>[wordpiece embedding]</cell><cell>[Q embedding]</cell><cell>Cross-Entropy loss</cell><cell cols="2">[A2 embedding] [Ak embedding] [A64 embedding]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sentence Transformer</cell><cell></cell><cell>Sentence Transformer</cell></row><row><cell></cell><cell>BERT_Base</cell><cell></cell><cell></cell><cell>model</cell><cell></cell><cell>model</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">A relevant : Consider c 2 = a 2 +b 2 ...</cell><cell>A irrelevant : Ask elsewhere ...</cell></row><row><cell cols="2">Figure 5:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="12,90.49,261.36,10.91,9.11"><p>Q:</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,108.93,671.04,216.48,8.97"><p>https://github.com/MIR-MU/ARQMath-data-preprocessing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,108.93,660.08,334.20,8.97"><p>https://gitlab.fi.muni.cz/xstefan3/pv211-utils/-/blob/master/pv211_utils/arqmath/entities.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,108.93,671.04,268.38,8.97"><p>https://drive.google.com/file/d/1HA2Bm77nBiz-UTckaYousZLe8RhgaDP4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,108.93,671.04,357.91,8.97"><p>https://github.com/MIR-MU/ARQMath-eval, files scripts/qrel_task1-âŸ¨subset nameâŸ©-pv211-utils.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="8,108.93,660.02,305.80,8.97"><p>https://colab.research.google.com/drive/1lqSx2a4hVHFW9xL2KGiVJMEniVzhQXaO</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="8,108.93,670.98,161.89,8.97"><p>https://github.com/dorianbrown/rank_bm25</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_6" coords="11,108.93,649.09,268.06,8.97"><p>https://drive.google.com/file/d/1L6yz4cTyrPZgb-gkpLfAw-XTUVOK4tpZ</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_7" coords="11,108.93,660.05,267.00,8.97"><p>https://drive.google.com/file/d/1HIPIwYvEK-HsQgYpZ0lt7KE7L81AkUIQ</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_8" coords="11,108.93,671.01,303.35,8.97"><p>https://drive.google.com/drive/folders/1bxYwWzDX3z81S4TwUaTvqZBHtiMOngez</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_9" coords="13,108.93,616.20,297.75,8.97"><p>https://colab.research.google.com/drive/1f726gsoitMqrBeA_loRoDOceMjad8GqW</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_10" coords="13,108.93,627.16,299.66,8.97"><p>https://colab.research.google.com/drive/1JUkdLZRF7Qvr7uusg56bQdsnozPhE6mn</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_11" coords="13,108.93,638.12,300.83,8.97"><p>https://colab.research.google.com/drive/1iW7qonWsGzjTu8c7R2Ue8qaFVHakJkC3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_12" coords="13,108.93,649.07,296.44,8.97"><p>https://colab.research.google.com/drive/1rcHo2AsJO-XBTd5blRd6ROL4sgIyR2A1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_13" coords="13,108.93,660.03,305.71,8.97"><p>https://colab.research.google.com/drive/1t1ZtuamWdUERcevzSMGEF0s2WtLu9zwo</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_14" coords="13,108.93,670.99,296.83,8.97"><p>https://colab.research.google.com/drive/19-LfEQlNwkWvngPkK06Ys-6xrcqjY7Qg</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_15" coords="15,108.93,670.99,295.65,8.97"><p>https://colab.research.google.com/drive/187dVasy8dkKp-JJoLt_VCh_m6HP69NjP</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_16" coords="17,108.93,660.07,302.86,8.97"><p>https://colab.research.google.com/drive/1qEfMSE6GgcgF97U7LTx2xEXgt6y74GmV</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_17" coords="17,108.93,671.03,299.85,8.97"><p>https://colab.research.google.com/drive/1TZ9IXaQQ28GdzESjKbPDhg6ri5RDINgu</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>First author's work was graciously funded by the <rs type="funder">South Moravian Centre for International Mobility</rs> as a part of the <rs type="funder">Brno Ph.D</rs>. Talent project. We also thank the three anonymous reviewers for their insightful comments. We extend our gratitude to the arqmath 2021 organizers for keeping the research of math information retrieval aflame.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="21,112.66,615.39,393.61,10.91;21,112.66,628.93,393.33,10.91;21,112.66,642.48,394.52,10.91;21,112.33,656.03,394.37,10.91;21,112.66,669.58,234.52,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="21,255.12,615.39,251.14,10.91;21,112.66,628.93,153.15,10.91">Similarity Search for Mathematics: Masaryk University team at the NTCIR-10 Math Task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>LÃ­Å¡ka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>RÅ¯Å¾iÄka</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings10/pdf/NTCIR/MATH/06-NTCIR10-MATH-LiskaM.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="21,428.27,628.93,77.71,10.91;21,112.66,642.48,307.90,10.91">Proc. of the 10th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Kando</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Kishida</surname></persName>
		</editor>
		<meeting>of the 10th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Tokyo, Japan, Tokyo</addrLine></address></meeting>
		<imprint>
			<publisher>NII</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="686" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,86.97,393.33,10.91;22,112.28,100.52,394.91,10.91;22,112.66,114.06,393.33,10.91;22,112.66,127.61,393.32,10.91;22,112.41,141.16,388.52,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="22,340.22,86.97,165.76,10.91;22,112.28,100.52,128.22,10.91">Advancing Math-Aware Search: The ARQMath-2 Lab at CLEF 2021</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-72240-1_74</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,199.40,114.06,306.59,10.91;22,112.66,127.61,87.11,10.91;22,383.20,127.61,84.78,10.91">Advances in Information Retrieval -43rd European Conference on IR Research, ECIR 2021</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Perego</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</editor>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-04-01">March 28 -April 1, 2021. 2021</date>
			<biblScope unit="volume">12657</biblScope>
			<biblScope unit="page" from="631" to="638" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct coords="22,112.66,154.71,393.32,10.91;22,112.66,168.26,381.52,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="22,329.82,154.71,110.03,10.91">Overview of ARQMath-2</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,474.65,154.71,31.33,10.91;22,112.66,168.26,351.72,10.91">Second CLEF Lab on Answer Retrieval for Questions on Math (Working Notes Version)</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,181.81,393.33,10.91;22,112.66,195.36,394.53,10.91;22,112.66,208.91,347.45,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="22,206.85,181.81,154.82,10.91">The Art of Mathematics Retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>LÃ­Å¡ka</surname></persName>
		</author>
		<idno type="DOI">10.1145/2034691.2034703</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,391.66,181.81,114.32,10.91;22,112.66,195.36,224.46,10.91">Proceedings of the ACM Conference on Document Engineering, DocEng 2011</title>
		<meeting>the ACM Conference on Document Engineering, DocEng 2011<address><addrLine>Mountain View, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association of Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,222.46,393.33,10.91;22,112.66,236.01,393.33,10.91;22,112.66,249.56,397.48,10.91;22,112.36,265.55,121.09,7.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="22,266.71,222.46,239.28,10.91;22,112.66,236.01,37.33,10.91">MIaS: Math-Aware Retrieval in Digital Mathematical Libraries</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>RÅ¯Å¾iÄka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>NovotnÃ½</surname></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3269233</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,172.60,236.01,333.39,10.91;22,112.66,249.56,166.11,10.91">Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1923" to="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,276.66,393.33,10.91;22,112.66,290.20,393.33,10.91;22,112.33,303.75,393.65,10.91;22,112.66,317.30,346.99,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="22,311.39,276.66,194.59,10.91;22,112.66,290.20,187.27,10.91">Ensembling Ten Math Information Retrieval Systems: MIRMU and MSM at ARQMath</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>LuptÃ¡k</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>NovotnÃ½</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å tefÃ¡nik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-81097-9</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,142.31,303.75,206.74,10.91">Intelligent Computer Mathematics, CICM 2021</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Kamareddine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sacerdoti-Coen</surname></persName>
		</editor>
		<meeting><address><addrLine>Timisoara, Romania</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing Switzerland</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,330.85,393.33,10.91;22,112.66,344.40,394.52,10.91;22,112.66,357.95,395.17,10.91;22,112.66,371.50,393.33,10.91;22,112.66,385.05,360.48,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="22,332.54,330.85,102.17,10.91;22,463.29,330.85,42.70,10.91;22,112.66,344.40,193.31,10.91">CLEF Lab on Answer Retrieval for Questions on Math</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58219-7_15</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,478.64,357.95,29.19,10.91;22,112.66,371.50,286.43,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>NÃ©vÃ©ol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="169" to="193" />
		</imprint>
	</monogr>
	<note>Overview of ARQMath</note>
</biblStruct>

<biblStruct coords="22,112.66,398.60,393.32,10.91;22,112.66,412.15,394.53,10.91;22,112.66,425.70,395.00,10.91;22,112.66,439.25,17.97,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="22,376.41,398.60,129.57,10.91;22,112.66,412.15,38.20,10.91">Quo Vadis, Math Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>NovotnÃ½</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>Ayetiran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>LuptÃ¡k</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å tefÃ¡nik</surname></persName>
		</author>
		<ptr target="https://nlp.fi.muni.cz/raslan/2019/paper11-sojka.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="22,173.77,412.15,328.83,10.91">Proceedings of Recent Advances in Slavonic Natural Language Processing</title>
		<meeting>Recent Advances in Slavonic Natural Language Processing<address><addrLine>RASLAN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,452.79,393.33,10.91;22,112.66,466.34,394.52,10.91;22,112.66,479.89,322.46,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="22,306.34,452.79,103.64,10.91">Three is Better than One</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>NovotnÃ½</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Å tefÃ¡nik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>LuptÃ¡k</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_235.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="22,432.49,452.79,73.50,10.91;22,112.66,466.34,214.88,10.91">CEUR Workshop Proceedings: ARQMath task at CLEF conference</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2696</biblScope>
			<biblScope unit="page" from="1" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,493.44,394.53,10.91;22,112.66,506.99,393.33,10.91;22,112.66,520.54,225.82,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="22,272.62,493.44,230.43,10.91">Learning to Rank for Mathematical Formula Retrieval</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3462956</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,127.04,506.99,378.95,10.91;22,112.66,520.54,38.01,10.91">Proceedings of the 2021 ACM SIGIR international conference on theory of Information Retrieval</title>
		<meeting>the 2021 ACM SIGIR international conference on theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,534.09,393.33,10.91;22,112.66,547.64,393.33,10.91;22,112.66,561.19,393.33,10.91;22,112.66,574.74,394.72,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="22,207.26,534.09,298.73,10.91;22,112.66,547.64,69.16,10.91">Layout and Semantics: Combining Representations for Mathematical Formula Search</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Davila</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3077136.3080748</idno>
	</analytic>
	<monogr>
		<title level="m" coord="22,208.36,547.64,297.62,10.91;22,112.66,561.19,269.33,10.91">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1165" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,588.29,393.33,10.91;22,112.66,601.84,393.32,10.91;22,112.14,615.39,393.85,10.91;22,112.66,628.93,394.53,10.91;22,112.28,642.48,291.10,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="22,330.66,588.29,175.32,10.91;22,112.66,601.84,68.16,10.91">Normalization of Digital Mathematics Library Content</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>FormÃ¡nek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>LÃ­Å¡ka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>RÅ¯Å¾iÄka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-921/wip-05.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="22,437.43,601.84,68.56,10.91;22,112.14,615.39,393.85,10.91;22,112.66,628.93,389.78,10.91">24th OpenMath Workshop, 7th Workshop on Mathematical User Interfaces (MathUI), and Intelligent Computer Mathematics Work in Progress, number 921</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Davenport</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jeuring</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lange</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Libbrecht</surname></persName>
		</editor>
		<meeting><address><addrLine>Aachen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="91" to="103" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="23,112.66,86.97,394.03,10.91;23,112.66,100.52,393.33,10.91;23,112.66,114.06,122.26,10.91" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ginev</surname></persName>
		</author>
		<idno>arXiv.org</idno>
		<ptr target="https://sigmathling.kwarc.info/resources/arxmliv-dataset-082019/,SIGMathLing-SpecialInterestGroup" />
		<title level="m" coord="23,155.39,86.97,222.02,10.91">arXMLiv:08.2019 dataset, an HTML5 conversion of</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>on Math Linguistics</note>
</biblStruct>

<biblStruct coords="23,112.66,127.61,394.53,10.91;23,112.66,141.16,118.81,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="23,226.24,127.61,276.60,10.91">The measurement of observer agreement for categorical data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,112.66,141.16,47.75,10.91">Biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,154.71,394.62,10.91;23,112.31,168.26,393.67,10.91;23,112.66,181.81,50.36,10.91" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="23,175.24,154.71,245.54,10.91">ARQMath: Additional Information on Topics 1 and 2</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<ptr target="https://drive.google.com/drive/u/1/folders/1rE9f_xheR1RRKQYLlfYzV0-kDXEnRNae" />
		<imprint>
			<date type="published" when="2021-07-03">2021. 2021-07-03</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,195.36,395.17,10.91;23,112.66,208.91,309.91,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="23,199.80,195.36,308.04,10.91;23,112.66,208.91,121.28,10.91">On information retrieval metrics designed for evaluation with incomplete relevance assessments</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,242.56,208.91,96.07,10.91">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="447" to="470" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,222.46,395.17,10.91;23,112.66,236.01,388.01,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="23,173.50,222.46,278.84,10.91">The Proof and Measurement of Association between Two Things</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spearman</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/1412159" />
	</analytic>
	<monogr>
		<title level="j" coord="23,460.32,222.46,47.51,10.91;23,112.66,236.01,119.40,10.91">The American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="72" to="101" />
			<date type="published" when="1904">1904</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,249.56,393.53,10.91;23,112.66,263.11,341.24,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="23,186.62,249.56,319.57,10.91;23,112.66,263.11,34.00,10.91">Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,154.83,263.11,225.27,10.91">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,276.66,394.52,10.91;23,112.66,290.20,394.53,10.91;23,112.66,303.75,394.52,10.91;23,112.66,317.30,244.99,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="23,178.49,276.66,323.02,10.91">A Log-Logistic Model-Based Interpretation of TF Normalization of BM25</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-28997-2_21</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,192.52,303.75,153.78,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Cambazoglu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Murdock</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Lempel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="244" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,330.85,394.53,10.91;23,112.66,344.40,394.53,10.91;23,112.28,357.95,350.23,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="23,267.38,330.85,234.85,10.91">Improvements to BM25 and language models examined</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Puurula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Burgess</surname></persName>
		</author>
		<idno type="DOI">10.1145/2682862.2682863</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,127.55,344.40,375.70,10.91">Proceedings of the 2014 Australasian Document Computing Symposium, ADCS &apos;14</title>
		<meeting>the 2014 Australasian Document Computing Symposium, ADCS &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,371.50,393.33,10.91;23,112.33,385.05,393.66,10.91;23,112.66,398.60,269.59,10.91" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="23,355.76,371.50,150.23,10.91;23,112.33,385.05,359.89,10.91">Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno>CoRR abs/2102.10073</idno>
		<ptr target="https://arxiv.org/abs/2102.10073" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,412.15,393.32,10.91;23,112.66,425.70,393.32,10.91;23,112.66,439.25,395.01,10.91;23,112.41,452.79,207.13,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="23,221.40,412.15,284.58,10.91;23,112.66,425.70,37.79,10.91">Anserini: Enabling the Use of Lucene for Information Retrieval Research</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3077136.3080721</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,173.78,425.70,332.20,10.91;23,112.66,439.25,230.35,10.91">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,466.34,393.33,10.91;23,112.66,479.89,269.59,10.91" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="23,273.83,466.34,190.01,10.91">Billion-scale similarity search with GPUs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>JÃ©gou</surname></persName>
		</author>
		<idno>CoRR abs/1702.08734</idno>
		<ptr target="https://arxiv.org/abs/1702.08734" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,493.44,393.33,10.91;23,112.66,506.99,202.35,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="23,209.38,493.44,236.67,10.91">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,453.55,493.44,52.44,10.91;23,112.66,506.99,118.42,10.91">Information processing &amp; management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,520.54,394.61,10.91;23,112.66,534.09,393.45,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="23,338.71,520.54,168.56,10.91;23,112.66,534.09,190.76,10.91">Soft similarity and soft cosine measure: Similarity of features in vector space model</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>GÃ³mez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,312.33,534.09,109.84,10.91">ComputaciÃ³n y Sistemas</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="491" to="504" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,547.64,394.61,10.91;23,112.66,561.19,394.53,10.91;23,112.66,574.74,253.24,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="23,209.74,547.64,276.93,10.91">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Å˜ehÅ¯Å™ek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<idno type="DOI">10.13140/2.1.2393.1847</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,112.66,561.19,321.50,10.91">Proceedings of LREC 2010 workshop New Challenges for NLP Frameworks</title>
		<meeting>LREC 2010 workshop New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,588.29,393.33,10.91;23,112.66,601.84,203.13,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="23,305.44,588.29,139.08,10.91">Document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,453.07,588.29,52.92,10.91;23,112.66,601.84,119.19,10.91">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="619" to="633" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,615.39,394.53,10.91;23,112.66,628.93,394.53,10.91;23,112.66,642.48,393.32,10.91;23,112.66,656.03,394.03,10.91;23,112.41,669.58,158.18,10.91" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="23,175.33,628.93,108.17,10.91">Attention is All you Need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" />
	</analytic>
	<monogr>
		<title level="s" coord="23,314.47,642.48,191.52,10.91;23,112.66,656.03,35.63,10.91">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017">2017</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,86.97,393.33,10.91;24,112.66,100.52,393.33,10.91;24,112.33,114.06,202.41,10.91" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<idno>arXiv abs/1906.02762</idno>
		<ptr target="https://arXiv.org/abs/1906.02762" />
		<title level="m" coord="24,375.45,86.97,130.54,10.91;24,112.66,100.52,288.75,10.91">Understanding and improving transformer from a multi-particle dynamic system point of view</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,127.61,393.33,10.91;24,112.66,141.16,394.53,10.91;24,112.28,154.71,334.98,10.91" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="24,258.60,127.61,247.39,10.91;24,112.66,141.16,22.08,10.91">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,157.83,141.16,344.86,10.91">Proceedings of the 54th Annual Meeting of the ACL (Volume 1: Long Papers)</title>
		<meeting>the 54th Annual Meeting of the ACL (Volume 1: Long Papers)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,168.26,395.17,10.91;24,112.66,181.81,393.33,10.91;24,112.66,195.36,394.53,10.91;24,112.66,208.91,394.51,10.91;24,112.36,224.90,68.18,7.90" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="24,230.89,168.26,276.95,10.91;24,112.66,181.81,40.55,10.91">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1410.doi:10.18653/v1/D19-1410" />
	</analytic>
	<monogr>
		<title level="m" coord="24,176.84,181.81,329.15,10.91;24,112.66,195.36,298.41,10.91">Proceedings of the 2019 Conference on Empirical Methods in NLP and the 9th International Joint Conference on NLP (EMNLP-IJCNLP), ACL</title>
		<meeting>the 2019 Conference on Empirical Methods in NLP and the 9th International Joint Conference on NLP (EMNLP-IJCNLP), ACL<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,236.01,393.33,10.91;24,112.66,249.56,394.03,10.91;24,112.66,263.11,68.60,10.91" xml:id="b31">
	<monogr>
		<title level="m" type="main" coord="24,327.47,236.01,178.51,10.91;24,112.66,249.56,177.58,10.91">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>arXiv 1810.04805</idno>
		<ptr target="https://arXiv.org/abs/1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,276.66,395.17,10.91;24,112.66,290.20,395.17,10.91;24,112.66,303.75,394.62,10.91;24,112.66,317.30,349.34,10.91" xml:id="b32">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<ptr target="https://ui.adsabs.harvard.edu/abs/2019arXiv191013461L.arXiv:1910.13461" />
		<title level="m" coord="24,146.96,290.20,360.87,10.91;24,112.66,303.75,184.18,10.91">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,330.85,393.33,10.91;24,112.66,344.40,394.53,10.91;24,112.66,357.95,393.33,10.91;24,112.66,371.50,394.04,10.91;24,112.39,385.05,82.83,10.91" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="24,273.88,330.85,232.10,10.91;24,112.66,344.40,195.44,10.91">Winning The Transfer Learning Track of Yahoo!&apos;s Learning To Rank Challenge with YetiRank</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Kuralenok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pavlov</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v14/gulin11a.html" />
	</analytic>
	<monogr>
		<title level="m" coord="24,112.66,357.95,217.31,10.91;24,402.87,361.23,103.11,4.94;24,112.66,374.78,76.88,4.94">Proceedings of the Learning to Rank Challenge</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the Learning to Rank Challenge<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="63" to="76" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct coords="24,112.66,398.60,393.33,10.91;24,112.66,412.15,395.00,10.91" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="24,307.80,398.60,198.19,10.91;24,112.66,412.15,38.39,10.91">Adapting boosting for information retrieval measures</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-009-9112-1</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,159.76,412.15,94.28,10.91">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="254" to="270" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,425.70,393.33,10.91;24,112.66,439.25,395.01,10.91;24,112.66,452.79,149.51,10.91" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="24,249.00,425.70,256.98,10.91;24,112.66,439.25,96.07,10.91">Generalized Ensemble Model for Document Ranking in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I.-C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.2298/csis160229042w</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,216.98,439.25,199.13,10.91">Computer Science and Information Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="123" to="151" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,466.34,394.53,10.91;24,112.66,479.89,397.48,10.91;24,112.66,495.88,38.01,7.90" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="24,189.92,466.34,312.77,10.91">Automatic Ranking of Information Retrieval Systems Using Data Fusion</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nuray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Can</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2005.03.023</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,112.66,479.89,182.41,10.91">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="595" to="614" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,506.99,395.17,10.91;24,112.66,520.54,393.33,10.91;24,112.66,534.09,311.57,10.91" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="24,241.76,506.99,266.08,10.91;24,112.66,520.54,65.77,10.91">Majority Voting Re-ranking Algorithm for Content Based-Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mosbah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boucheham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,401.42,520.54,104.57,10.91;24,112.66,534.09,37.60,10.91">Metadata and Semantics Research</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Garoufallou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hartley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Gaitanou</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="121" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,547.64,394.62,10.91;24,112.66,561.19,394.53,10.91;24,112.66,574.74,326.76,10.91" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="24,230.30,547.64,254.89,10.91">Quality Biased Thread Retrieval Using the Voting Model</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Albaham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Salim</surname></persName>
		</author>
		<idno type="DOI">10.1145/2537734.2537752</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,112.66,561.19,362.58,10.91">Proceedings of the 18th Australasian Document Computing Symposium, ADCS &apos;13</title>
		<meeting>the 18th Australasian Document Computing Symposium, ADCS &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="97" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,588.29,393.53,10.91;24,112.66,601.84,397.48,10.91;24,112.36,617.83,121.09,7.90" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="24,252.40,588.29,253.79,10.91;24,112.66,601.84,185.02,10.91">Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Whitaker</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1022859003006</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,306.55,601.84,81.77,10.91">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,628.93,395.17,10.91;24,112.66,642.48,393.33,10.91;24,112.28,656.03,394.91,10.91;24,112.28,669.58,360.37,10.91" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="24,314.92,628.93,192.90,10.91;24,112.66,642.48,201.92,10.91">Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buettcher</surname></persName>
		</author>
		<idno type="DOI">10.1145/1571941.1572114</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,338.24,642.48,167.75,10.91;24,112.28,656.03,391.12,10.91">Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09</title>
		<meeting>the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="758" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,86.97,393.33,10.91;25,112.66,100.52,391.92,10.91" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="25,214.78,86.97,199.45,10.91">A theory of measuring, electing, and ranking</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Balinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Laraki</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0702634104</idno>
	</analytic>
	<monogr>
		<title level="j" coord="25,422.87,86.97,83.12,10.91;25,112.66,100.52,134.60,10.91">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="8720" to="8725" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,114.06,393.33,10.91;25,112.66,127.61,393.33,10.91;25,112.66,141.16,393.72,10.91;25,112.34,154.71,318.68,10.91" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="25,319.16,114.06,186.83,10.91;25,112.66,127.61,153.39,10.91">A Lightweight Environment for Learning Experimental IR Research Practices</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401395</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,288.57,127.61,217.42,10.91;25,112.66,141.16,338.93,10.91">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2113" to="2116" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
