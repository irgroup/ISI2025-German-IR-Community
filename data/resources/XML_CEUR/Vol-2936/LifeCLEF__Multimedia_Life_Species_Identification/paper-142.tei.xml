<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.40,84.74,305.62,15.42;1,89.29,106.66,179.56,15.42">Weighted Pseudo Labeling Refinement for Plant Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.95,134.97,73.35,11.96"><forename type="first">Youshan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<addrLine>113 Research Drive</addrLine>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,174.05,134.97,83.49,11.96"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<addrLine>113 Research Drive</addrLine>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.40,84.74,305.62,15.42;1,89.29,106.66,179.56,15.42">Weighted Pseudo Labeling Refinement for Plant Identification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">74E5B2F6034A51B76724FA5E13EF1968</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised domain adaptation</term>
					<term>Pseudo labeling refinement</term>
					<term>Plant identification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation (UDA) focuses on transferring knowledge from a labeled source domain to an unlabeled target domain. However, existing domain adaptation methods try to handle various DA scenarios that are subject to imbalanced labels or large domain discrepancy datasets. In this paper, we propose a weighted pseudo labeling refinement model (WPLR) to balance the dataset using a weighted cross-entropy loss. We also utilize the CORAL loss to further reduce the domain difference.</p><p>To improve the generalizability of the model, we develop an easy-to-hard pseudo labeling refinement process by probabilistic soft selection to suppress noisy predicted target labels. Experimental results demonstrate our WPLR model yields promising results on the PlantCLEF 2021 Challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automatic plant identification is helpful for the general audience in recognizing plant species without the expertise of botanists. Deep neural networks can improve recognition performance when a large number of labeled data are used for training but suffer from significant performance degradation when deployed in a new domain due to the problem of domain shift. However, the domain shift or domain mismatch problem exists for the plant identification problem in PlantCLEF. Due to the significant difference between herbarium and real photos, classification models often do not generalize well to the novel field photo domain.</p><p>To circumvent the domain shift issue, the unsupervised domain adaptation (UDA) method has been proposed, which can transfer the model trained on the labeled source domain to an unlabeled target domain. Existing deep learning methods can be categorized into two major tracks: discrepancy-based methods <ref type="bibr" coords="1,285.71,515.07,11.48,10.91" target="#b0">[1,</ref><ref type="bibr" coords="1,301.08,515.07,7.52,10.91" target="#b1">2,</ref><ref type="bibr" coords="1,312.49,515.07,9.03,10.91" target="#b2">3]</ref> and adversarial learning methods <ref type="bibr" coords="1,484.30,515.07,11.48,10.91" target="#b3">[4,</ref><ref type="bibr" coords="1,499.66,515.07,7.52,10.91" target="#b4">5,</ref><ref type="bibr" coords="1,89.29,528.62,7.65,10.91" target="#b5">6]</ref>. The former aligns the distributions of source and target domains by directly minimizing the difference metric between feature distributions of the two domains, such as Maximum Mean Discrepancy (MMD) <ref type="bibr" coords="1,212.05,555.72,11.56,10.91" target="#b0">[1]</ref>, CORrelation ALignment <ref type="bibr" coords="1,343.78,555.72,11.57,10.91" target="#b1">[2]</ref>, Kullback-Leibler divergence <ref type="bibr" coords="1,491.76,555.72,11.57,10.91" target="#b2">[3]</ref>, Jensen-Shannon divergence <ref type="bibr" coords="1,215.98,569.27,11.31,10.91" target="#b6">[7]</ref>, and Wasserstein distance <ref type="bibr" coords="1,347.03,569.27,11.31,10.91" target="#b7">[8]</ref>. The latter category methods are inspired by GANs <ref type="bibr" coords="1,168.16,582.82,11.28,10.91" target="#b8">[9]</ref>, and adversarial learning has shown its power in learning domain invariant representations. It consists of a domain discriminator and a feature extractor. The domain discriminator aims to distinguish the source domain from the target domain, while the feature extractor aims to learn domain-invariant representations to fool the domain discriminator <ref type="bibr" coords="2,495.78,114.06,11.40,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,89.29,127.61,7.52,10.91" target="#b4">5,</ref><ref type="bibr" coords="2,100.22,127.61,7.65,10.91" target="#b5">6]</ref>. There is also much exploration of adversarial learning methods, such as DANN <ref type="bibr" coords="2,486.67,127.61,16.42,10.91" target="#b9">[10]</ref>, MCD <ref type="bibr" coords="2,115.87,141.16,16.25,10.91" target="#b10">[11]</ref>, TADA <ref type="bibr" coords="2,170.11,141.16,16.25,10.91" target="#b11">[12]</ref>, SymNets <ref type="bibr" coords="2,235.60,141.16,16.25,10.91" target="#b12">[13]</ref>, and ACDA <ref type="bibr" coords="2,309.69,141.16,16.25,10.91" target="#b13">[14]</ref>.</p><p>Although many methods are proposed for domain adaptation, most of them are tested on small domain divergence datasets, which may have lower transferability to large-divergence datasets, and the data imbalance problem is not well addressed. To address these challenges, we offer two contributions:</p><p>1. We propose a weighted cross-entropy loss to balance the categorical data. To minimize the domain divergence, we utilize the existing CORAL loss. 2. To remove noisy pseudo labels in the target domain, we also employ an easy-to-hard pseudo labeling refinement process by probabilistic soft selection. We then form a highquality pseudo-labeled target domain to improve the generalizability of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>PlantCLEF 2021 is a large-scale dataset of the PlantCLEF 2021 task <ref type="bibr" coords="2,393.44,329.86,17.47,10.91" target="#b14">[15,</ref><ref type="bibr" coords="2,413.64,329.86,12.37,10.91" target="#b15">16]</ref>, organized in the context of the LifeCLEF 2021 challenge. Fig. <ref type="figure" coords="2,288.57,343.41,5.11,10.91" target="#fig_0">1</ref> shows some challenging images in this dataset.</p><p>Tab. 1 lists the statistics on PlantCLEF 2021 dataset. Due to the significant difference between herbarium and real photos, it is extremely difficult to identify the correct class. All images are the same as PlantCLEF 2020 dataset <ref type="bibr" coords="2,245.14,384.06,16.08,10.91" target="#b16">[17]</ref>, but it also introduces five "traits" covering exhaustively all species of the challenge.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>In this section, we will first introduce the problem and notation for UDA, and then introduce the different components of our Weighted Pseudo Labeling Refinement (WPLR) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem and notation</head><p>In this work, we consider the unsupervised domain adaptation (UDA) classification problem in the following setting. There exists a labeled source domain 𝒟 𝒮 = {𝒳 𝑖 𝒮 , 𝒴 𝑖 𝒮 } 𝒩 𝒮 𝑖=1 of 𝒩 𝒮 labeled samples in 𝐶 categories and a target domain 𝒟 𝒯 = {𝒳 𝑗 𝒯 } 𝒩 𝒯 𝑗=1 of 𝒩 𝒯 samples without any labels (i.e., 𝒴 𝒯 is unknown). The samples 𝒳 𝒮 and 𝒳 𝒯 obey the marginal distributions of 𝑃 𝒮 and 𝑃 𝒯 . The conditional distributions of the two domains are denoted as 𝑄 𝒮 and 𝑄 𝒯 . Due to the discrepancy between the two domains, the distributions are assumed to be different, i.e., 𝑃 𝒮 ̸ = 𝑃 𝒯 and 𝑄 𝒮 ̸ = 𝑄 𝒯 . Our ultimate goal is to learn a classifier 𝐹 under a feature extractor 𝐺, which reduces domain discrepancy and improves the generalization ability of the classifier to the target domain.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Weighted source classifier</head><p>The task in the source domain is trained using the typical cross-entropy loss. However, there are imbalanced numbers of samples of each category. To handle this issue, we develop a weighted source classifier to balance the weight of each category based on the source samples. We define the weight of each class in the following equation.</p><formula xml:id="formula_0" coords="4,238.96,418.86,267.03,39.00">𝑊 = 𝑚𝑒𝑑𝑖𝑎𝑛({ 𝒩 𝑐 𝒮 𝒩 𝒮 } 𝐶 𝑐=1 ) { 𝒩 𝑐 𝒮 𝒩 𝒮 } 𝐶 𝑐=1 ,<label>(1)</label></formula><p>where 𝒩 𝑐 𝒮 is the number of samples in each class, {</p><formula xml:id="formula_1" coords="4,311.22,467.21,78.77,19.24">𝒩 𝑐 𝒮 𝒩 𝒮 } 𝐶 𝑐=1 ∈ R 997×1</formula><p>is the frequency of images in each class, 𝑚𝑒𝑑𝑖𝑎𝑛(•) takes the median value of the frequency. The frequency value varies; the median represents the middle frequency better than mean would. Fig. <ref type="figure" coords="4,419.79,499.11,5.08,10.91" target="#fig_1">2</ref> shows the weight of each class (997 classes in total). Therefore, we develop the weighted cross-entropy loss for the labeled source domain in Eq. 2.</p><formula xml:id="formula_2" coords="4,200.21,550.03,305.78,34.08">ℒ 𝒲𝒮 = 1 𝒩 𝒮 𝒩 𝒮 ∑︁ 𝑖=1 𝑊 𝑖 × ℒ 𝑐𝑒 (𝐹 (𝐺(𝒳 𝑖 𝒮 )), 𝒴 𝑖 𝒮 ),<label>(2)</label></formula><p>where ℒ 𝑐𝑒 is the typical cross-entropy loss, 𝐹 is the classifier in Fig. <ref type="figure" coords="4,400.30,592.18,3.81,10.91" target="#fig_2">3</ref>, and 𝐹 (𝐺(𝒳 𝑖 𝒮 )) is the predicted label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">CORAL loss</head><p>CORrelation ALignment loss (CORAL) <ref type="bibr" coords="4,263.98,655.45,12.83,10.91" target="#b1">[2]</ref> is one frequently used distance-based loss function to minimize the difference between source and target domain. We also integrate CORAL loss during the training as follows,</p><formula xml:id="formula_3" coords="5,160.52,103.73,345.47,24.43">ℒ 𝐶𝑂𝑅𝐴𝐿 = 1 4𝑑 2 ||𝐶𝑂𝑉 (𝐹 (𝐺(𝒳 𝒮 ))) -𝐶𝑂𝑉 (𝐹 (𝐺(𝒳 𝒯 )))|| 2 𝐹 ,<label>(3)</label></formula><p>where 𝑑 is the feature dimensionality, 𝐶𝑂𝑉 (•) is the covariance matrices of the source and target features, and || • || 2 𝐹 denotes the squared matrix Frobenius norm. Therefore, our model is able to minimize the domain divergence between the source domain and the target domain during the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pseudo labeling refinement</head><p>To further reduce the domain difference, we also generate pseudo labels for the target domain. However, the detrimental effects of bad pseudo-labels are still significant. To mitigate this issue, we employ a 𝑇 times recurrent easy-to-hard pseudo-label refinement process to improve the quality of the pseudo-labels in the target domain via imposing a probabilistic soft selection <ref type="bibr" coords="5,490.85,262.62,16.34,10.91" target="#b17">[18,</ref><ref type="bibr" coords="5,89.04,276.17,12.32,10.91" target="#b18">19]</ref>.</p><p>The initial shared classifier 𝐹 is optimized by ℒ 𝒲𝒮 . For the inference, we can directly get predicted results for one target domain sample 𝐹 (𝐺(𝒳 𝑗 𝒯 )). Let Softmax(𝐹 (𝐺(𝒳 𝑗 𝒯 ))) be the predicted probability for each class, and 𝒴 𝑗 𝒫𝒯 = 𝑚𝑎𝑥(Softmax(𝐹 (𝐺(𝒳 𝑗 𝒯 )))) 𝑖𝑛𝑑𝑒𝑥 be its dominant class label, where 𝑚𝑎𝑥(•) 𝑖𝑛𝑑𝑒𝑥 return the index of the maximum probability value. Therefore, for the probabilistic soft selection, a higher quality pseudo label is defined as 𝑚𝑎𝑥(Softmax(𝐹 (𝐺(𝒳 𝑗 𝒯 )))) &gt; 𝑝 𝑡 , where 𝑝 𝑡 is a threshold probability in number of 𝑡 training. For 𝑇 times recurrent easy-to-hard pseudo-label refinement, for easy examples, 𝑝 𝑡 has a higher value and for hard examples, 𝑝 𝑡 has a lower value, hence</p><formula xml:id="formula_4" coords="5,375.47,386.02,91.30,11.42">𝑝 1 &gt; 𝑝 2 &gt; • • • &gt; 𝑝 𝑇 .</formula><p>In pseudo labeling refinement, we form a robust new pseudo-labeled domain in the following equation, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>{𝑄(𝒳</head><p>where 𝑄(•) represents the high quality, 𝑛 𝑝𝑡 is the number of higher quality pseudo labels for the target domain. We hence can mitigate detrimental effects of bad pseudo-labels using Eq. 4. Similar to Eq. 2, we define the pseudo-labeled target domain loss as:</p><formula xml:id="formula_6" coords="5,185.99,494.44,320.00,34.90">ℒ 𝒯 = 1 𝑛 𝑝𝑡 𝑛𝑝𝑡 ∑︁ 𝑗=1 𝑊 𝑗 × ℒ 𝑐𝑒 (𝐹 (𝐺(𝑄(𝒳 𝑗 𝒯 ))), 𝑄(𝒴 𝑗 𝒯 )),<label>(5)</label></formula><p>where 𝑊 is the weight of each class and ℒ 𝑐𝑒 is the cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">WPLR model</head><p>Fig. <ref type="figure" coords="5,108.06,585.19,5.06,10.91" target="#fig_2">3</ref> depicts the overall framework of our proposed WPLR model. Taken together, our model minimizes the following objective function:</p><formula xml:id="formula_7" coords="5,214.47,617.02,291.52,33.58">arg min (ℒ 𝒲𝒮 + ℒ 𝐶𝑂𝑅𝐴𝐿 + 𝑇 ∑︁ 𝑡=1 ℒ 𝑡 𝒯 )<label>(6)</label></formula><p>where ℒ 𝒲𝒮 is the weighted source classification loss, ℒ 𝐶𝑂𝑅𝐴𝐿 is the CORAL loss, and ℒ 𝒯 is the pseudo-labeled target domain classification loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation details</head><p>We first extract features from the last fully connected layer <ref type="bibr" coords="6,353.94,132.25,16.42,10.91" target="#b19">[20,</ref><ref type="bibr" coords="6,373.08,132.25,12.54,10.91" target="#b20">21,</ref><ref type="bibr" coords="6,388.35,132.25,14.02,10.91" target="#b21">22]</ref> of a retrained NASNet-Large <ref type="bibr" coords="6,118.14,145.80,18.07,10.91" target="#b22">[23]</ref> model. One image can be denoted by a feature vector with the size of 1 × 1000. Therefore, the feature representation of domain herbarium (H) has the size of 320, 750 × 1000, domain herbarium_photo_associations (A) has the size of 1, 816 × 1000, domain photo (P) has the size of 4, 482 × 1000, and domain test (T) has the size of 3, 186 × 1000. Domain H + A has the size of 322, 566 × 1000. In Tab. 2, H P represents learning knowledge from domain H, which is applied to domain P <ref type="bibr" coords="6,220.93,213.54,16.25,10.91" target="#b23">[24]</ref>. We implement our approach using PyTorch. The outputs of the three Linear layers are 1000, 1000 and |𝐶|, respectively. Parameters in recurrent pseudo labeling are 𝑇 = 5 and {𝑝 𝑡 } 5 𝑡=1 = [0.9, 0.8, 0.7, 0.6, 0.5]. Learning rate (0.001), batch size (64), optimizer (Adam) and number of epochs (𝒩 𝒮 /64) are determined by performance on the source domain. Experiments are performed with a GeForce 1080 Ti. We also compare our results with four domain adaptation methods: DANN <ref type="bibr" coords="6,166.10,294.84,16.25,10.91" target="#b9">[10]</ref>, ADDA <ref type="bibr" coords="6,222.01,294.84,11.43,10.91" target="#b4">[5]</ref>, NASNetLarge-𝐴𝐶𝐿 <ref type="bibr" coords="6,332.15,294.84,17.91,10.91" target="#b23">[24]</ref> and BA3US <ref type="bibr" coords="6,406.24,294.84,16.25,10.91" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Accuracy (%) on PlantCLEF 2021 dataset for photo domain</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head><p>A P H P H+A P DANN <ref type="bibr" coords="6,265.05,398.13,16.46,8.87" target="#b9">[10]</ref> 1.07 1.85 2.01 ADDA <ref type="bibr" coords="6,269.68,410.09,11.83,8.87" target="#b4">[5]</ref> 2.95 3.05 3.43 BA3US <ref type="bibr" coords="6,265.05,422.04,16.46,8.87" target="#b24">[25]</ref> 3.56 4.65 5.31 NASNetLarge-𝐴𝐶𝐿 <ref type="bibr" coords="6,265.05,434.00,16.46,8.87" target="#b23">[24]</ref> 5 Tab. 2 shows the results of our WPLR model of the photo domain. We report the accuracy of the whole photo domain (𝐴𝑐𝑐 = ∑︀ 𝒩 𝒯 𝑗=1 (𝒴 𝒯 𝑗 ^== 𝒴 𝒯 𝑗 )/𝒩 𝒯 × 100), where 𝒴 𝒯 ^is the predicted label for the target domain. Compared with all other four methods, our WPLR model achieves the highest accuracy in all three tasks, and especially in H+A P task.</p><p>We also carefully conduct an ablation study to demonstrate the effects of different loss functions on final classification accuracy. Notice that weighted source classification loss ℒ 𝒲𝒮 is required for UDA. "WPLR-ℒ 𝐶𝑂𝑅𝐴𝐿 -ℒ 𝒯 " is implemented without ℒ 𝐶𝑂𝑅𝐴𝐿 and ℒ 𝒯 . It is a simple model, which only reduces the source risk without minimizing the domain discrepancy using ℒ 𝒲𝒮 . "WPLR-ℒ 𝐶𝑂𝑅𝐴𝐿 " reports results without performing CORAL loss. "WPLR-ℒ 𝒯 " reports results without performing the 𝑇 time pseudo labeling refinement process. We can find that with the increasing number of loss functions, the accuracy of our model keeps improving. The effectiveness of loss functions on classification accuracy is ordered as ℒ 𝒯 &gt; ℒ 𝐶𝑂𝑅𝐴𝐿 . Therefore, the proposed weighted classification loss, CORAL loss, and easy-to-hard target domain pseudo labeling refinement approaches are effective in minimizing target domain risk and improving the accuracy. We also list the final performance of our model in the test domain in Tab. 3. Our model earns the second position in the PlantCLEF 2021 challenge. We provided a total of nine submissions; the MRR of the full test set ranged from 0.034 to 0.065, as a result of varying hyperparameters (different number of iterations, 𝑇 and 𝑝 𝑡 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>There are two compelling advantages of our WPLR model. First, we propose a weighted crossentropy loss to mitigate the imbalanced data issue in the source domain. Secondly, we develop an easy-to-hard refinement process to improve the quality of pseudo labels in the target domain. This strategy considers probabilistic soft selection, and it hence can push the shared classifier 𝐹 towards the target domain. Compared with other baselines in Tab. 2, the 𝑇 times easy-to-hard refinement process is effective in improving the classification accuracy and further reduces the domain discrepancy. However, our model only earns the second position in the challenge, and the results are a little bit lower than the Organizer's submission. One underlying reason is that our model cannot extract very robust invariant features. Therefore, we will consider designing a better feature extractor method and distill the domain invariant features across the two domains for future work. In addition, we would like to include more external data during the training (e.g., GBIF <ref type="bibr" coords="7,192.98,512.18,15.71,10.91" target="#b25">[26]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we propose a novel weighted pseudo labeling refinement (WPLR) method for domain adaptation to solve the plant identification problem. We develop a weighted crossentropy loss to balance the categorical data and utilize the CORAL loss to minimize the domain divergence. We also employ an easy-to-hard pseudo labeling refinement process by probabilistic soft selection. It can improve the quality of pseudo labels and remove the detrimental effects of bad labels. Experimental results demonstrate our proposed WPLR model is better than several baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,640.07,416.70,8.93;2,89.29,652.08,319.09,8.87;2,108.97,428.29,374.85,205.20"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example images of the herbarium domain and photo domain. The large discrepancy between the two domains causes difficulty in improving the performance of the model.</figDesc><graphic coords="2,108.97,428.29,374.85,205.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,89.29,648.26,144.50,8.93;3,171.89,437.70,249.00,198.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The weight of each class.</figDesc><graphic coords="3,171.89,437.70,249.00,198.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,89.29,259.25,416.69,9.15;4,89.29,271.20,416.69,9.65;4,89.29,283.16,416.95,9.65;4,89.29,295.11,297.12,9.65;4,387.87,292.36,3.30,6.12;4,386.41,300.08,4.52,6.12;4,393.26,295.11,26.71,8.74;4,420.79,292.36,3.30,6.12;4,419.97,300.08,4.52,6.12;4,426.82,295.11,8.86,8.74;4,435.68,291.76,11.42,6.12;4,435.68,299.93,13.79,6.12;4,451.69,295.38,55.96,8.87;4,89.29,307.07,390.64,9.14;4,106.27,84.19,380.25,167.85"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Architecture of the WPLR model. We first utilize NASNetLarge as the feature extractor 𝐺 to extract features from the two domains (𝐺(𝒳 𝒮 ) and 𝐺(𝒳 𝒯 )). The shared classifier 𝐹 is then trained using the extracted features. ℒ 𝒲𝒮 is the weighted source classification loss, ℒ 𝐶𝑂𝑅𝐴𝐿 is the CORAL loss, and ℒ 𝒯 is the pseudo-labeled target domain classification loss. {𝑄(𝒳 𝑗 𝒯 ), 𝑄(𝒴 𝑗 𝒯 )} 𝑛𝑝𝑡 𝑗=1 is the pseudolabeled target domain after 𝑇 times pseudo labeling refinement processes. Best viewed in color.</figDesc><graphic coords="4,106.27,84.19,380.25,167.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,90.49,377.00,82.95"><head>Table 1</head><label>1</label><figDesc>Statistics</figDesc><table coords="3,129.12,102.49,336.87,70.95"><row><cell>of the PlantCLEF 2021 dataset</cell><cell></cell><cell></cell></row><row><cell>Domain</cell><cell>Number of Samples</cell><cell>Number of Classes</cell></row><row><cell>Herbarium (H)</cell><cell>320,750</cell><cell>997</cell></row><row><cell>Herbarium_photo_associations (A)</cell><cell>1,816</cell><cell>244</cell></row><row><cell>Photo (P)</cell><cell>4,482</cell><cell>375</cell></row><row><cell>Test (T)</cell><cell>3,186</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,358.06,102.71"><head>Table 3</head><label>3</label><figDesc>MRR on PlantCLEF 2021 challenge for test domain</figDesc><table coords="7,148.22,118.58,298.84,74.62"><row><cell>Team</cell><cell>Full test set</cell><cell>Sub-set of the test set</cell></row><row><cell>Organizer's submission [15]</cell><cell>0.198</cell><cell>0.093</cell></row><row><cell>Neuon AI</cell><cell>0.181</cell><cell>0.158</cell></row><row><cell>LU (ours)</cell><cell>0.065</cell><cell>0.037</cell></row><row><cell>Domain_run</cell><cell>0.065</cell><cell>0.037</cell></row><row><cell>To_be</cell><cell>0.056</cell><cell>0.038</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,111.28,393.33,10.91;8,112.66,124.83,273.56,10.91" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<title level="m" coord="8,345.45,111.28,160.54,10.91;8,112.66,124.83,96.45,10.91">Deep domain confusion: Maximizing for domain invariance</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,112.66,138.38,394.61,10.91;8,112.66,151.93,318.34,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,197.26,138.38,290.00,10.91">Deep CORAL: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,151.93,187.84,10.91">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,165.48,393.32,10.91;8,112.66,179.03,393.33,10.91;8,112.66,192.57,244.06,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,262.31,165.48,243.67,10.91;8,112.66,179.03,83.57,10.91">Adversarial teacher-student learning for unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,246.50,179.03,259.49,10.91;8,112.66,192.57,119.21,10.91">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="5949" to="5953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,206.12,394.53,10.91;8,112.30,219.67,393.69,10.91;8,112.66,233.22,176.63,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,176.75,219.67,213.79,10.91">Domain-adversarial training of neural networks</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,399.43,219.67,106.56,10.91;8,112.66,233.22,82.55,10.91">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,246.77,394.52,10.91;8,112.66,260.32,394.53,10.91;8,112.66,273.87,90.72,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,304.20,246.77,198.53,10.91">Adversarial discriminative domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,128.46,260.32,373.96,10.91">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,287.42,393.33,10.91;8,112.66,300.97,393.33,10.91;8,112.66,314.52,173.73,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,263.50,287.42,242.49,10.91;8,112.66,300.97,80.94,10.91">Adversarial reinforcement learning for unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,216.60,300.97,289.39,10.91;8,112.66,314.52,85.98,10.91">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,328.07,393.33,10.91;8,112.66,341.62,352.69,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,271.31,328.07,159.33,10.91">Resource efficient domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.94,328.07,53.05,10.91;8,112.66,341.62,254.37,10.91">Proceedings of the 28th ACM International Conference on Multimedia</title>
		<meeting>the 28th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2220" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,355.17,393.33,10.91;8,112.66,368.71,393.33,10.91;8,112.66,382.26,340.63,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,430.61,355.17,75.38,10.91;8,112.66,368.71,316.66,10.91">DeepJDOT: Deep joint distribution optimal transport for unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bhushan Damodaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.24,368.71,53.74,10.91;8,112.66,382.26,252.15,10.91">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="447" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,395.81,394.53,10.91;8,112.34,409.36,393.64,10.91;8,112.66,422.91,132.21,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,161.80,409.36,122.30,10.91">Generative adversarial nets</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,307.59,409.36,198.39,10.91;8,112.66,422.91,33.92,10.91">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,436.46,394.53,10.91;8,112.66,450.01,394.53,10.91;8,112.66,463.56,17.62,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,263.83,436.46,238.98,10.91">Domain adaptive neural networks for object recognition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.09,450.01,269.31,10.91">Pacific Rim International Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="898" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,477.11,395.17,10.91;8,112.39,490.66,393.59,10.91;8,112.66,504.21,204.01,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,308.71,477.11,199.12,10.91;8,112.39,490.66,109.66,10.91">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,246.35,490.66,259.63,10.91;8,112.66,504.21,105.89,10.91">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3723" to="3732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,517.76,394.53,10.91;8,112.66,531.30,395.01,10.91;8,112.66,544.85,48.96,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,299.15,517.76,203.42,10.91">Transferable attention for domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,127.79,531.30,280.54,10.91">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5345" to="5352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,558.40,393.33,10.91;8,112.66,571.95,393.33,10.91;8,112.66,585.50,149.51,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,267.07,558.40,238.91,10.91;8,112.66,571.95,46.18,10.91">Domain-symmetric networks for adversarial domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,186.08,571.95,319.91,10.91;8,112.66,585.50,51.39,10.91">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5031" to="5040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,599.05,395.17,10.91;8,112.66,612.60,216.68,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,222.86,599.05,284.97,10.91;8,112.66,612.60,15.08,10.91">Adversarial continuous learning in unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,153.83,612.60,75.50,10.91">ICPR Workshops</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="672" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,626.15,395.17,10.91;8,112.66,639.70,394.53,10.91;8,112.66,653.25,22.69,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,242.47,626.15,265.36,10.91;8,112.66,639.70,16.50,10.91">Overview of PlantCLEF 2021: cross-domain plant identification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,153.35,639.70,348.45,10.91">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,666.80,393.33,10.91;9,112.66,86.97,394.52,10.91;9,112.66,100.52,393.32,10.91;9,112.66,114.06,393.33,10.91;9,112.66,127.61,360.25,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,247.88,100.52,258.10,10.91;9,112.66,114.06,305.78,10.91">Overview of LifeCLEF 2021: a system-oriented evaluation of automated species identification and species distribution prediction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dorso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Klinck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,441.19,114.06,64.80,10.91;9,112.66,127.61,330.51,10.91">Proceedings of the Twelfth International Conference of the CLEF Association (CLEF 2021)</title>
		<meeting>the Twelfth International Conference of the CLEF Association (CLEF 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,394.62,10.91;9,112.66,154.71,394.53,10.91;9,112.33,168.26,122.67,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,255.42,141.16,205.29,10.91">Overview of lifeclef plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,112.66,154.71,343.91,10.91">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">2020. Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct coords="9,112.66,181.81,393.33,10.91;9,112.66,195.36,393.32,10.91;9,112.66,208.91,248.38,10.91" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,219.87,181.81,286.12,10.91;9,112.66,195.36,44.50,10.91">Deep spherical manifold gaussian kernel for unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,179.95,195.36,326.03,10.91;9,112.66,208.91,149.23,10.91">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4443" to="4452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,222.46,393.33,10.91;9,112.66,236.01,393.33,10.91;9,112.66,249.56,382.03,10.91" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,232.33,222.46,273.65,10.91;9,112.66,236.01,160.63,10.91">Efficient pre-trained features and recurrent pseudo-labeling in unsupervised domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,300.97,236.01,205.02,10.91;9,112.66,249.56,282.87,10.91">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2719" to="2728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,263.11,395.17,10.91;9,112.66,276.66,393.33,10.91;9,112.66,290.20,393.33,10.91;9,112.66,303.75,75.03,10.91" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,317.53,263.11,190.30,10.91;9,112.66,276.66,393.33,10.91;9,112.66,290.20,222.87,10.91">Automated identification of hookahs (waterpipes) on Instagram: an application in feature extraction using convolutional neural network and support vector machine classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Allem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">B</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,343.42,290.20,162.57,10.91">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">10513</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,317.30,393.33,10.91;9,112.66,330.85,309.26,10.91" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="9,230.43,317.30,275.56,10.91;9,112.66,330.85,126.70,10.91">Modified distribution alignment for domain adaptation with pre-trained Inception ResNet</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02322</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,344.40,394.53,10.91;9,112.66,357.95,393.33,10.91;9,112.14,371.50,135.88,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,233.19,344.40,269.38,10.91">Impact of ImageNet model selection on domain adaptation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,129.65,357.95,376.34,10.91;9,112.14,371.50,47.32,10.91">Proceedings of the IEEE Winter Conference on Applications of Computer Vision Workshops</title>
		<meeting>the IEEE Winter Conference on Applications of Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,385.05,393.33,10.91;9,112.66,398.60,393.33,10.91;9,112.66,412.15,147.08,10.91" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,298.90,385.05,207.09,10.91;9,112.66,398.60,77.03,10.91">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,211.90,398.60,294.09,10.91;9,112.66,412.15,49.16,10.91">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,425.70,393.33,10.91;9,112.66,439.25,393.32,10.91;9,112.66,452.79,124.68,10.91" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,224.15,425.70,281.84,10.91;9,112.66,439.25,114.38,10.91">Adversarial consistent learning on partial domain adaptation of PlantCLEF 2020 challenge</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,250.23,439.25,255.75,10.91;9,112.66,452.79,93.98,10.91">CLEF: Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct coords="9,112.66,466.34,393.53,10.91;9,112.66,479.89,295.44,10.91" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02541</idno>
		<title level="m" coord="9,291.67,466.34,214.51,10.91;9,112.66,479.89,113.19,10.91">A balanced and uncertainty-aware approach for partial domain adaptation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,493.44,393.33,10.91;9,112.66,506.99,393.33,10.91;9,112.66,520.54,124.68,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,229.69,493.44,276.30,10.91;9,112.66,506.99,133.10,10.91">Recognition of the amazonian flora by inception networks with test-time class prior estimation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,268.28,506.99,237.71,10.91;9,112.66,520.54,93.98,10.91">Working Notes of CLEF 2019 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
