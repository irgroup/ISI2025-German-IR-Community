<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,403.46,15.42;1,88.78,106.66,81.57,15.43">Snake Species classification using Transfer learning Technique</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,89.29,134.97,80.34,11.96"><forename type="first">Karthik</forename><surname>Desingu</surname></persName>
							<email>karthik19047@cse.ssn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,182.27,134.97,115.20,11.96"><forename type="first">Mirunalini</forename><surname>Palaniappan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sri Sivasubramaniya Nadar College of Engineering</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,328.47,134.97,63.61,11.96"><forename type="first">Jitesh</forename><surname>Kumar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sri Venkateshwara College of Engineering</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,403.46,15.42;1,88.78,106.66,81.57,15.43">Snake Species classification using Transfer learning Technique</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4C3293493D1C8905C9BD464BB12AD25A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Transfer Learning</term>
					<term>Inception ResNet</term>
					<term>Gradient Boosting</term>
					<term>Snake Species Classification</term>
					<term>Metadata Inclusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Transfer learning is a technique that helps to utilise the knowledge of previously trained machine learning models by extending them to solve any related problem. This technique is predominantly used when there is either a scarcity of computational resource or limited availability of labelled data. Categorizing snake at the species level can be instrumental in treatment of snake bites and clinical management. We propose a deep learning model based on transfer learning technique to build a snake species classifier that uses snake photographic images in combination with their geographic location. We have used the Inception ResNet V2 as a feature extractor, extracted the feature vector for each input image and concatenated it with geographic feature information. The concatenated features are classified using a lightweight gradient boost classifier.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Snake species identification is essential for biodiversity, conservation and global health. Millions of snake bites occur globally every year, half of which cause snakebite envenoming (SBE), killing people and disabling more in different regions across the globe <ref type="bibr" coords="1,374.68,439.54,11.52,10.91" target="#b0">[1]</ref>. Taxonomic identification of the species helps the healthcare providers to articulate the symptoms, responses of the treatment and antivenom efficacy and also aid in clinical management <ref type="bibr" coords="1,405.71,466.63,11.40,10.91" target="#b1">[2,</ref><ref type="bibr" coords="1,419.84,466.63,7.60,10.91" target="#b2">3]</ref>. Identification of the snake species is difficult because of similarity in appearance, situational stress and fear of potential danger <ref type="bibr" coords="1,164.10,493.73,11.30,10.91" target="#b3">[4]</ref>. An automatic system that helps in recognizing the snake species from the photographic image and geographic information can be paramount in overcoming the above problems. Hence, we propose an automated system based on transfer learning techniques that utlilizes pre-trained weights of the Inception ResNet V2 <ref type="bibr" coords="1,334.31,534.38,12.68,10.91" target="#b4">[5]</ref> to extract input image features. The extracted features, in combination with the geographic features, are classified using a LightGBM <ref type="bibr" coords="1,89.29,561.48,11.43,10.91" target="#b5">[6]</ref>, a gradient boosting classifier.</p><p>The Inception ResNet V2 incorporates residual connections into the inception architecture to perform enhanced feature extraction from images. The Inception ResNet V2 is a convolution neural network which has 164 deep layers where multi-sized convolution filters are combined by residual connections which not only avoids the degradation caused by the deep layers but also reduces training time. The knowledge acquired by the model by training on the ImageNet data set <ref type="bibr" coords="2,126.26,127.61,12.84,10.91" target="#b6">[7]</ref> is utilized through transfer learning as a feature extractor.</p><p>Gradient boosting <ref type="bibr" coords="2,182.39,141.16,12.73,10.91" target="#b7">[8]</ref> is a machine learning technique that can be used for supervised classification problems to produce a prediction model. It is an ensemble of weak prediction models, typically decision trees, known for its prediction speed and accuracy with large and complex data sets. It minimizes the overall prediction error by iteratively generating optimized new models based on the loss function of the previous model. After concatenating the representation vectors of the input images with the geographic information, we trained a lightweight gradient boost classifier to predict the snake species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>As part of the LifeCLEF-2021 <ref type="bibr" coords="2,219.00,281.08,11.33,10.91" target="#b8">[9]</ref>, an evaluation campaign aimed at data-oriented challenges related to the identification and prediction of biodiversity, SnakeCLEF-2021 <ref type="bibr" coords="2,408.89,294.63,17.76,10.91" target="#b9">[10]</ref> is an image-based snake identification task. For this challenge, a large data set with 414,424 RGB photographic images belonging to 772 distinct snake species, taken in 188 countries is provided. Additionally, geographic metadata comprising of country and continent information is provided to facilitate classification. The data set is split into a training subset with 347,406 images, and a validation sub-set with 38,601 image, both having the same class distribution. The data set is highly imbalanced with a heavy long-tailed distribution. The most frequent class is represented with 22,163 images while the least frequent class by a mere 10 images. A large number of classes in combination with a high intra-class variance (depicted in Figure <ref type="figure" coords="2,374.49,403.03,5.02,10.91" target="#fig_0">1</ref> and low inter-class variance makes this an exigent machine learning classification task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Work</head><p>An investigation of the accuracy of five machine learning techniques -decision tree J48, nearest neighbors, k-nearest neighbors (k-NN), back-propagation neural network, and naive Bayesfor image-based snake species identification problem was performed in <ref type="bibr" coords="3,416.49,138.38,16.42,10.91" target="#b10">[11]</ref>. It revealed the efficacy of back-propagation neural networks which achieved a greater than 87% classification accuracy.</p><p>A Siamese network with three main components namely, twin network, similarity function and output neuron was proposed in <ref type="bibr" coords="3,254.87,192.57,18.06,10.91" target="#b11">[12]</ref> to classify the snake species. A pair of deep neural networks was proposed where one network extracts features from the test image while the other from a reference image. The features were compared using L1 distance similarity and the final output layer predicted the probability of the test image belonging to same class as the reference image.</p><p>Four different region-based convolution neural networks (R-CNN) architectures -Inception V2, MobileNet, ResNet and VGG16 were used in <ref type="bibr" coords="3,300.47,273.87,17.75,10.91" target="#b12">[13]</ref> for object detection and image recognition of 9 snake species of the Pseudalsophis genus. Among them, VGG16 and ResNet achieved the highest accuracy of 75%.</p><p>A detailed quantitative comparative study between a computer vision algorithm trained to identify 45 species and human experts was performed in <ref type="bibr" coords="3,332.41,328.07,16.09,10.91" target="#b13">[14]</ref>. The algorithm used an EfficientNet based model, fine-tuned using preprocessed images to achieve an accuracy between 72 and 87% depending on the test data set. The significant impact of geographic data in addition to visual information for snake species classification was also realized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>A transfer learning method is adopted to classify the snake species using the data set of snake images and geographic location metadata provided by SnakeCLEF-2021 <ref type="bibr" coords="3,403.96,440.89,11.24,10.91" target="#b8">[9,</ref><ref type="bibr" coords="3,417.88,440.89,12.23,10.91" target="#b9">10]</ref>. The pre-trained Inception ResNet V2, a deep learning convolution neural network is used to extract image features. These features are concatenated with the categorical geographic features and finally classified using a gradient boost classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Preprocessing</head><p>The input images were resized to 299 × 299 × 3 using bi-linear interpolation. To counter the effect of irrelevant factors in the context of the required task such as variation in lighting conditions among the photographs, the images were linearly normalized to values between 0 and 1.</p><p>Scale and rotation transformations, along with contrast and saturation variations were performed to make the model more generic, immune to the impact of positional and orientation based features and prevent memorization by enhancing image diversity. RandAugment <ref type="bibr" coords="3,468.83,612.56,17.75,10.91" target="#b14">[15]</ref> was used to augment the input images using the aforementioned transformations. RandAugment is parameterized by two values -the number of augmentation transformations to apply sequentially (N), and the magnitude for all the transformations (M). The values used in <ref type="bibr" coords="3,421.26,653.21,17.91,10.91" target="#b14">[15]</ref> for the ResNet model i.e N=3 and M=4 were chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Feature Extraction</head><p>The Inception ResNet V2 model was used to perform feature extraction. The model is loaded with weights obtained from pre-training on the ImageNet data set. The fully connected output layer was excluded from the base model. A 2D average pooling layer is appended to produce the representation vector of the input image.</p><p>The pre-processed images are fed to the so constructed convolution neural network to produce a feature vector. We have obtained 1536 features for each input image from the output layer. This vector is then augmented with the geographic metadata, containing country and continent information, to perform the snake species classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Gradient Boost Classifier</head><p>A decision tree ensemble classifier is trained using the metadata about the geographic location of the photograph along with the image feature vector obtained form the Inception ResNet V2. Gradient boosting algorithm is used to train the classifier. The parameters of the classifier are tuned over several runs to improve classification results.</p><p>Five-fold cross-validation is used to obtain a reliable evaluation of model performance for each configuration of parameters. The classifier is trained five times per run, each time selecting a different fold as the cross-validation set and training on the remaining four folds. The average of the performance parameters ( accuracy and F1 score ) over the five iterations is considered while tuning the parameters. Cross-entropy loss is used to monitor the model's convergence towards the objective in each fold. Early stopping is used to stop the boosting process if the loss starts to diverge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Details</head><p>The training subset consisting of 347,406 images was split into five folds for cross-validation while training the classifier. Since the data-set had a long-tailed distribution across classes, stratified sampling was used to ensure a proportional split and ensure inclusion of images from each class.</p><p>The pre-processed images from the training and validation set are fed into the proposed deep learning convolution neural network model. The model produces feature-vectors of size 1536 for each image.</p><p>The geographic location describing where the photographs were taken, specifically the continent and country, are encoded into numeric labels. This information is used as categorical features in classifier. For the images in which this data is unavailable, the features are encoded as 'nan'. The classifier imputes the missing values to the mode of the corresponding feature space. The representation vector consisting of 1538 features obtained for each image is used to train the decision tree ensemble classifiers by gradient boosting.</p><p>It was observed that learning rates higher than 0.05 lead to quicker divergence, suggesting the suitability of a slower learning rate using with more decision trees. Grid-search was performed by varying the learning rates in the range of 0.001 to 0.05 and the number of decision trees in the range 100 to 1000. Combinations having the least losses were chosen to further tune the tree-level parameters.</p><p>The maximum depth for the tree is left to be determined based on the training progress of the classifier and is not set strictly. This causes the depth to expand until the leaves are pure (has all samples belonging to the same class) or has reached the threshold of minimum number of samples required to split further. Due to the long-tailed distribution of the data set, some classes may require deeper branches to capture more information from the features. The potential over-fitting that may occur is controlled by tuning and setting an upper limit on the number of leaves by performing a grid search over values in range of 32 to 256. Some other notable tree-level parameters tuned were sub-sampling rate and column-sampling rate. Sub-sampling rate determines the fraction of training samples that are randomly sampled per tree and was tuned between 0.6 and 1.0. Column-sampling rate, on the other hand, specifies the fraction of features used to fit each decision tree and was tuned between 0.5 and 0.9. Both these parameters help prevent over-fitting. They are maintained sufficiently above 0.1 to prevent under-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>The country and continent metadata, used as categorical features in the classifier had a significant impact on the classification. Without the categorical data, the testing accuracy of the best run was 40.16%. This improved to 42.96% when contextual data was encoded as categorical features. Country information has the highest impact while continent information also has a notable influence on the classification. Figure <ref type="figure" coords="5,252.55,389.48,3.66,10.91" target="#fig_1">2</ref>, depicts the relative importance of the 20 most significant features of the 1538 features used for classification. The feature importance values are normalized and scaled between 0 and 100 to realise the relative impacts. Features named as f1, f2, etc. denote features extracted from the convolution neural network.</p><p>Through parameter tuning, the classifier's performance was improved over several runs. The F1-scores macro-averaged across the countries and macro-averaged over all classes were the prescribed the metrics <ref type="bibr" coords="5,208.12,470.77,16.27,10.91" target="#b9">[10]</ref>. Eight best runs were selected based on the prescribed metrics evaluated on the prescribed validation set. The metrics are evaluated as an average over the five iterations (for 5-fold cross validation) performed in each run. We have achieved a training accuracy of 71.32%, validation accuracy of 44.16% and a testing accuracy of 42.96% on the best run. The results are summarized in Tables <ref type="table" coords="5,279.17,524.97,5.07,10.91" target="#tab_0">1</ref> and<ref type="table" coords="5,306.12,524.97,5.07,10.91" target="#tab_1">2</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>below:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Future Work</head><p>The results depict the positive impact of integrating contextual country and continent data for snake species classification. Introducing more contextual data such as population counts of various species by region as class-wise probability priors <ref type="bibr" coords="6,358.32,628.93,16.31,10.91" target="#b15">[16]</ref>, climate information such as temperature and humidity, etc. may contribute to better classification results. Due to unavailability of sufficient computational resources during the SnakeCLEF-2021 contest period, the results were submitted before complete convergence of the classifier's training process. Post the deadline, significant improvements in classification accuracy were observed even with a slight increase in the number of iterations applied to train the gradient boost classifier. This suggests that the transfer learning approach adopted here is promising and further parameter tuning and complete training can greatly improve the model performance.</p><p>Further efforts to experiment with input image resolutions and alternative pre-trained weights <ref type="bibr" coords="7,89.29,154.71,18.07,10.91" target="#b16">[17]</ref> as well as including custom training layers to the frozen base model before extracting features <ref type="bibr" coords="7,127.60,168.26,17.91,10.91" target="#b17">[18]</ref> can contribute to the classification performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,89.29,620.93,416.69,8.93;2,89.29,632.93,340.11,8.87;2,173.47,439.29,245.85,175.05"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Four images of the Dispholidus Typus snake species with high visual deviation characterized by age and gender depicting an instance of high inter-class variance in the data set</figDesc><graphic coords="2,173.47,439.29,245.85,175.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,89.29,336.08,416.69,8.93;6,89.29,348.04,398.34,8.93;6,89.29,84.19,416.71,233.36"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relative importance on a scale of 0-100 of the 20 most impactful features used to train the classifier. The first two bars represent feature importance of country and continent respectively</figDesc><graphic coords="6,89.29,84.19,416.71,233.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,563.48,328.86,103.51"><head>Table 1</head><label>1</label><figDesc>Prediction metrics of the five best runs on the validation set</figDesc><table coords="5,174.93,592.88,242.92,74.12"><row><cell cols="4">Run F1-Score (Country) F1-Score (Overall) Accuracy</cell></row><row><cell>1</cell><cell>0.455</cell><cell>0.456</cell><cell>0.531</cell></row><row><cell>2</cell><cell>0.482</cell><cell>0.469</cell><cell>0.554</cell></row><row><cell>3</cell><cell>0.509</cell><cell>0.481</cell><cell>0.569</cell></row><row><cell>4</cell><cell>0.522</cell><cell>0.488</cell><cell>0.583</cell></row><row><cell>5</cell><cell>0.536</cell><cell>0.497</cell><cell>0.622</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,419.48,328.86,103.52"><head>Table 2</head><label>2</label><figDesc>Prediction metrics of the five best runs on the test set</figDesc><table coords="6,174.93,448.88,242.92,74.12"><row><cell cols="4">Run F1-Score (Country) F1-Score (Overall) Accuracy</cell></row><row><cell>1</cell><cell>0.246</cell><cell>0.164</cell><cell>0.428</cell></row><row><cell>2</cell><cell>0.247</cell><cell>0.166</cell><cell>0.430</cell></row><row><cell>3</cell><cell>0.249</cell><cell>0.159</cell><cell>0.428</cell></row><row><cell>4</cell><cell>0.249</cell><cell>0.162</cell><cell>0.432</cell></row><row><cell>5</cell><cell>0.252</cell><cell>0.162</cell><cell>0.432</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Thanks to the <rs type="institution">Machine Learning Research Group (MLRG), Deptartment of Computer Science and Engineering, Sri Sivasubramaniya Nadar College of Engineering, Chennai, India</rs> ( https: //www.ssn.edu.in/ ) for providing the GPU resources to implement the model</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,112.66,312.61,394.53,10.91;7,112.66,326.16,312.93,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,112.66,326.16,98.54,10.91">Snakebite envenoming</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Calvete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Warrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,220.38,326.16,141.57,10.91">Nature reviews Disease primers</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,339.71,394.52,10.91;7,112.66,353.26,385.80,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,260.40,339.71,242.33,10.91">Snake detection and classification using deep learning</title>
		<author>
			<persName coords=""><forename type="first">Zihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Sinnott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,127.29,353.26,341.32,10.91">Proceedings of the 54th Hawaii International Conference on System Sciences</title>
		<meeting>the 54th Hawaii International Conference on System Sciences</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,366.81,393.33,10.91;7,112.66,380.36,323.85,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,250.73,366.81,255.26,10.91;7,112.66,380.36,224.03,10.91">The disconnect between dna and species names: lessons from reptile species in the ncbi taxonomy database</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Leipe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Uetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,345.14,380.36,36.43,10.91">Zootaxa</title>
		<imprint>
			<biblScope unit="volume">4706</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,393.91,393.33,10.91;7,112.66,407.46,394.53,10.91;7,112.33,421.01,110.88,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,414.70,393.91,91.29,10.91;7,112.66,407.46,202.37,10.91">Most lay people can correctly identify indigenous venomous snakes</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">N S B W K H M D C W</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,322.82,407.46,179.65,10.91;7,112.33,421.01,17.26,10.91">American Journal of Emergency Medicine</title>
		<imprint>
			<biblScope unit="volume">2698</biblScope>
			<biblScope unit="page" from="3" to="A12" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>The</note>
</biblStruct>

<biblStruct coords="7,112.66,434.55,393.33,10.91;7,112.66,448.10,393.33,10.91;7,112.66,461.65,371.62,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,307.29,434.55,198.70,10.91;7,112.66,448.10,158.39,10.91">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/11231" />
	</analytic>
	<monogr>
		<title level="m" coord="7,279.77,448.10,226.22,10.91;7,112.66,461.65,64.85,10.91">Proceedings of the AAAI Conference on Artificial Intelligence 31</title>
		<meeting>the AAAI Conference on Artificial Intelligence 31</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,475.20,393.61,10.91;7,112.66,488.75,393.33,10.91;7,112.66,502.30,129.40,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,418.47,475.20,87.80,10.91;7,112.66,488.75,181.97,10.91">Lightgbm: A highly efficient gradient boosting decision tree</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,306.31,488.75,199.68,10.91;7,112.66,502.30,35.32,10.91">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3146" to="3154" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,515.85,393.33,10.91;7,112.66,529.40,394.53,10.91;7,112.66,542.95,250.61,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,346.64,515.85,159.35,10.91;7,112.66,529.40,65.95,10.91">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,224.82,529.40,277.69,10.91">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,556.50,393.33,10.91;7,112.66,570.05,119.88,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,183.03,556.50,270.85,10.91">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,462.85,556.50,43.13,10.91;7,112.66,570.05,38.67,10.91">Annals of statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,583.60,393.33,10.91;7,112.66,597.15,394.53,10.91;7,112.66,610.69,393.32,10.91;7,112.66,624.24,393.33,10.91;7,112.66,637.79,306.11,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,199.20,610.69,306.78,10.91;7,112.66,624.24,249.83,10.91">Overview of lifeclef 2021: a system-oriented evaluation of automated species identification and species distribution prediction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Isabelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-P</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dorso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,385.48,624.24,120.51,10.91;7,112.66,637.79,276.37,10.91">Proceedings of the Twelfth International Conference of the CLEF Association (CLEF 2021)</title>
		<meeting>the Twelfth International Conference of the CLEF Association (CLEF 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,112.66,651.34,394.62,10.91;8,112.28,86.97,393.70,10.91;8,112.66,100.52,288.62,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,376.16,651.34,131.11,10.91;8,112.28,86.97,288.08,10.91">Overview of snakeclef 2020: Automatic snake species identification with country-level focus</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bolon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,425.01,86.97,80.97,10.91;8,112.66,100.52,257.93,10.91">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,114.06,393.33,10.91;8,112.66,127.61,394.53,10.91;8,112.66,141.16,394.53,10.91;8,112.66,154.71,102.08,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,336.92,114.06,169.07,10.91;8,112.66,127.61,157.88,10.91">Image classification for snake species using machine learning techniques</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A H</forename><surname>Zahri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Yaakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,141.16,231.39,10.91">Computational Intelligence in Information Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Phon-Amnuaisuk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T.-W</forename><surname>Au</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Omar</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,168.26,394.61,10.91;8,112.66,181.81,394.52,10.91;8,112.66,195.36,394.61,10.91;8,112.66,208.91,337.56,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,273.26,168.26,215.28,10.91">Snake image classification using siamese networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Abeysinghe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Welivita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Perera</surname></persName>
		</author>
		<idno type="DOI">10.1145/3338472.3338476</idno>
		<ptr target="https://doi.org/10.1145/3338472.3338476.doi:10.1145/3338472.3338476" />
	</analytic>
	<monogr>
		<title level="m" coord="8,112.66,181.81,394.52,10.91;8,112.66,195.36,42.34,10.91">Proceedings of the 2019 3rd International Conference on Graphics and Signal Processing, ICGSP &apos;19</title>
		<meeting>the 2019 3rd International Conference on Graphics and Signal Processing, ICGSP &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,222.46,393.33,10.91;8,112.66,236.01,393.32,10.91;8,112.41,249.56,263.95,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,444.88,222.46,61.11,10.91;8,112.66,236.01,348.64,10.91">Revealing the unknown: Real-time recognition of galápagos snake species using deep learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Khatod</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Matijosaitiene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arteaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Gilkey</surname></persName>
		</author>
		<ptr target="https://www.mdpi.com/2076-2615/10/5/806" />
	</analytic>
	<monogr>
		<title level="j" coord="8,469.50,236.01,36.48,10.91">Animals</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,263.11,394.53,10.91;8,112.66,276.66,393.33,10.91;8,112.66,290.20,393.33,10.91;8,112.66,303.75,104.57,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,112.66,276.66,393.33,10.91;8,112.66,290.20,281.21,10.91">Supervised learning computer vision benchmark for snake species identification from photographs: Implications for herpetology and global health</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Moorthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Salathé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,407.34,290.20,98.64,10.91;8,112.66,303.75,51.98,10.91">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,317.30,395.16,10.91;8,112.66,330.85,285.74,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13719</idno>
		<title level="m" coord="8,291.86,317.30,215.96,10.91;8,112.66,330.85,153.74,10.91">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,344.40,393.53,10.91;8,112.66,357.95,393.53,10.91;8,112.30,371.50,202.98,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,352.59,344.40,153.60,10.91;8,112.66,357.95,140.11,10.91">Cnn-rnn: A unified framework for multi-label image classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,277.60,357.95,228.59,10.91;8,112.30,371.50,172.53,10.91">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,385.05,394.62,10.91;8,112.28,398.60,343.72,10.91" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ruiz De Castaneda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sharada</surname></persName>
		</author>
		<title level="m" coord="8,365.32,385.05,141.96,10.91;8,112.28,398.60,311.80,10.91">Overview of the snakeclef 2020: Automatic snake species identification challenge</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>CLEF task overview</note>
</biblStruct>

<biblStruct coords="8,112.66,412.15,395.00,10.91;8,112.28,425.70,393.71,10.91;8,112.66,439.25,394.04,10.91;8,112.26,452.79,394.92,10.91;8,112.36,468.79,180.44,7.90" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,139.02,425.70,366.96,10.91;8,112.66,439.25,164.99,10.91">Multispecies bioacoustic classification using transfer learning of deep convolutional neural networks with pseudo-labeling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lebien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Campos-Cerqueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dodhia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lavista</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Ferres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Velev</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aide</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.apacoust.2020.107375</idno>
		<ptr target="https://doi.org/10.1016/j.apacoust.2020.107375" />
	</analytic>
	<monogr>
		<title level="j" coord="8,286.10,439.25,79.76,10.91">Applied Acoustics</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page">107375</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
