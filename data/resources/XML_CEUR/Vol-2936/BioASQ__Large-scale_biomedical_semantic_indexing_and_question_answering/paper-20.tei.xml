<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,354.21,15.42;1,89.29,106.66,406.44,15.42;1,89.29,128.58,78.64,15.43;1,89.29,150.91,373.61,11.96">Query-Focused Extractive Summarisation for Finding Ideal Answers to Biomedical and COVID-19 Questions Macquarie University Participation at BioASQ Synergy and BioASQ9b Phase</title>
				<funder>
					<orgName type="full">National Computational Infrastructure</orgName>
					<orgName type="abbreviated">NCI</orgName>
				</funder>
				<funder ref="#_rdzrFeC">
					<orgName type="full">CSIRO</orgName>
				</funder>
				<funder>
					<orgName type="full">Australian Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,59.79,11.96"><forename type="first">Diego</forename><surname>Moll√°</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Macquarie University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CSIRO Data61</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,167.01,176.82,79.19,11.96"><forename type="first">Urvashi</forename><surname>Khanna</surname></persName>
							<email>urvashi.khanna@mq.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">Macquarie University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.84,176.82,55.57,11.96"><forename type="first">Dima</forename><surname>Galat</surname></persName>
							<email>dima.galat@gronade.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Macquarie University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.06,176.82,79.79,11.96"><forename type="first">Vincent</forename><surname>Nguyen</surname></persName>
							<email>vincent.nguyen@anu.edu.au</email>
							<affiliation key="aff1">
								<orgName type="laboratory">CSIRO Data61</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Australian National University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,190.76,78.25,11.96"><forename type="first">Maciej</forename><surname>Rybinski</surname></persName>
							<email>maciek.rybinski@data61.csiro.au</email>
							<affiliation key="aff2">
								<orgName type="institution">Australian National University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,354.21,15.42;1,89.29,106.66,406.44,15.42;1,89.29,128.58,78.64,15.43;1,89.29,150.91,373.61,11.96">Query-Focused Extractive Summarisation for Finding Ideal Answers to Biomedical and COVID-19 Questions Macquarie University Participation at BioASQ Synergy and BioASQ9b Phase</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">ABC5AFC7997D7E445F11F83393068BB3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BioASQ</term>
					<term>Synergy</term>
					<term>query-focused summarisation</term>
					<term>Biomedical</term>
					<term>COVID-19</term>
					<term>BERT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents Macquarie University's participation to the BioASQ Synergy Task, and BioASQ9b Phase B. In each of these tasks, our participation focused on the use of query-focused extractive summarisation to obtain the ideal answers to medical questions. The Synergy Task is an end-to-end question answering task on COVID-19 where systems are required to return relevant documents, snippets, and answers to a given question. Given the absence of training data, we used a query-focused summarisation system that was trained with the BioASQ8b training data set and we experimented with methods to retrieve the documents and snippets. Considering the poor quality of the documents and snippets retrieved by our system, we observed reasonably good quality in the answers returned. For phase B of the BioASQ9b task, the relevant documents and snippets were already included in the test data. Our system split the snippets into candidate sentences and used BERT variants under a sentence classification setup. The system used the question and candidate sentence as input and was trained to predict the likelihood of the candidate sentence being part of the ideal answer. The runs obtained either the best or second best ROUGE-F1 results of all participants to all batches of BioASQ9b. This shows that using BERT in a classification setup is a very strong baseline for the identification of ideal answers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Supervised approaches to query-focused summarisation have the inherent problem of the paucity of annotated data. This problem has been highlighted, for example, by <ref type="bibr" coords="1,452.90,540.58,11.58,10.91" target="#b0">[1]</ref>, and the biomedical domain is no exception. The BioASQ Challenge provides annotated data for multiple tasks, including question answering <ref type="bibr" coords="1,253.88,567.68,11.53,10.91" target="#b1">[2]</ref>. While small in comparison with other data sets (the training data set for BioASQ9b contains 3,742 questions), there may be enough to train or fine-tune systems that have been pre-trained with other data sets. The problem of paucity of annotated data, however, becomes critical for urgent tasks on new domains such as question answering on biomedical papers related to COVID-19. In early 2021, BioASQ organised the Synergy task where systems are required to develop various stages of an end-to-end question answering system. In particular, given a question phrased in plain English, participating systems were expected to retrieve relevant documents from the CORD-19 collection <ref type="bibr" coords="2,433.71,168.26,12.99,10.91" target="#b2">[3]</ref> and relevant snippets. Optionally, the systems could complete the final stage of question answering by returning exact and/or ideal answers. There was no annotated training data available for this very specific task.</p><p>This paper describes our contribution to the BioASQ Synergy task and phase B of the BioASQ9b challenge. <ref type="foot" coords="2,181.68,234.25,3.71,7.97" target="#foot_0">1</ref> For the BioASQ Synergy task, we use a system that has been trained on the BioASQ8b training data, whereas for phase B of the BioASQ9b challenge we explore the use of Transformer architectures. In particular, we integrate BERT variants and fine-tune them with the BioASQ9b training data.</p><p>Prior work reports the success of BERT architectures for various tasks, by simply adding a task-specific layer and fine-tuning the system <ref type="bibr" coords="2,313.98,303.75,11.58,10.91" target="#b3">[4]</ref>. BERT has also been used for finding the ideal answers in BioASQ. For example, <ref type="bibr" coords="2,284.81,317.30,12.99,10.91" target="#b4">[5]</ref> used BERT in both an unsupervised sentence cosine similarity setup and a supervised sentence regression setup, and <ref type="bibr" coords="2,402.30,330.85,12.68,10.91" target="#b5">[6]</ref> compared the use of BERT embeddings with word2vec embeddings in a setup that directly modelled the interaction between sentence embeddings of the question and the candidate sentence, and incorporated sentence position. In our participation in BioASQ9b Phase B, we experimented with a simpler architecture compared with <ref type="bibr" coords="2,218.46,385.05,11.58,10.91" target="#b5">[6]</ref>, and obtained results that were among the top participating systems 2 . These good results suggest that the internal Transformer-based architecture of BERT suffices to model the interaction between the question and the candidate sentence.</p><p>This paper is structured as follows. Section 2 describes our contribution to the Synergy task. Section 3 describes our participation in BioASQ9b. Section 4 summarises and concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Synergy</head><p>Our contribution to the Synergy task focused on leveraging the use of a pre-trained question answering system. In particular, we used one of the systems proposed by <ref type="bibr" coords="2,437.06,524.97,11.58,10.91" target="#b5">[6]</ref>, which was trained on the BioASQ8b training data, and was designed as a classifier that identified whether a candidate sentence was part of the ideal answer.</p><p>Figure <ref type="figure" coords="2,131.46,565.62,5.11,10.91" target="#fig_0">1</ref> shows the architecture of the question answering system. This corresponds to the system referred to as "NNC" by <ref type="bibr" coords="2,230.25,579.17,11.32,10.91" target="#b5">[6]</ref>. The input consists of a question, a candidate sentence, and the candidate sentence position. The system uses Word2Vec trained on PubMed data to obtain the word embeddings of the question and the sentence. These word embeddings are converted to sentence embeddings through a layer of bi-directional LSTM chains. The interaction between the question and the sentence embeddings is modelled by applying element-wise multiplication. The result of this multiplication is concatenated to the sentence embeddings and the sentence positions. There is an intermediate hidden layer with dropout, followed by the final classification layer. The loss function is binary cross-entropy, and the target labels (0 or 1) were generated based on the ROUGE-F1 score of the candidate sentence with respect to the corresponding ideal answer.</p><p>The hyperparameters of the system are: Number of epochs=10; batch size=1024; dropout=0.7; hidden layer size = 50; embeddings size=100; sentence length clipped to 300 tokens.</p><p>The following sequence of steps was used to generate the candidate sentences that were fed as input to the question answering system:</p><p>1. Obtain the list of candidate documents, sorted by relevance. For this, we used the search API provided by the organisers of the BioASQ Synergy task. We also experimented with the use of sentence BERT fine-tuned with the BioASQ data as described in Section 2.1. 2. Split the documents into sentences and select and rank the most relevant sentences. For this, we experimented with various methods described in Section 2.2. The resulting sentences were used as candidate sentences to be processed by the question answering system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Document Retrieval</head><p>We experimented with three different approaches to document retrieval. These are listed below and named for further reference in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DocAPI</head><p>Most of our runs used the search API provided by the organisers of the BioASQ Synergy task. In preliminary experiments, we observed that the default results returned by the API were correlated with the cosine similarity with the question. We therefore concluded that the API returned the results ranked by some sort of relevance. Consequently, we selected the top ùëõ documents, where ùëõ depended on the round number (50 for round 1, and 100 for every subsequent round).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DocNIR(untuned)</head><p>We submitted one run based on the Neural Index Retrieval (NIR) methodology outlined in <ref type="bibr" coords="4,169.60,142.82,11.57,10.91" target="#b6">[7]</ref>. This document retrieval method combines a traditional inverted index with a neural index of the document collection. Specifically, the document relevance scores for each query are obtained by interpolating the normalised BM25 scores (so, the relevance score based on the use of a traditional inverted index) with a cosine similarity score between the neural representations of the query and the document. The neural representations are obtained via a sBERT <ref type="bibr" coords="4,145.80,210.57,12.94,10.91" target="#b7">[8]</ref> model pre-trained on the target corpus and fine-tuned on a natural language inference task.<ref type="foot" coords="4,154.12,222.36,3.71,7.97" target="#foot_1">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DocNIR(tuned)</head><p>In round 4, we also experimented with document retrieval based on the use of sBERT <ref type="bibr" coords="4,134.45,266.43,12.99,10.91" target="#b7">[8]</ref> fine-tuned with the BioASQ data. The retrieval model is, in essence, similar to the NIR method outlined above. The main difference is that the sBERT model is additionally fine-tuned on the target task training data (specifically, the relevance feedback available from the previous rounds). Another notable difference is that we used the neural component only to re-score (still using the BM25 for interpolation) the top-200 documents retrieved by the BM25 model for each query (making it, effectively, a re-ranker).</p><p>The final runs used the top 10 documents, after removing those that were in previous feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Snippet Retrieval</head><p>We experimented with several approaches to identify and rank the relevant snippets as described below.</p><p>SnipCosine Our baseline snippet retrieval system was based on the tf.idf cosine similarity between the question and the input document sentences. In particular, each document retrieved by the document retrieval system (after removing false positives as indicated by the feedback form previous rounds) was split into sentences (using NLTK's sentence tokeniser). Then, for each document, the top 3 sentences were extracted. To identify the top 3 sentences, we used cosine similarity between the tf.idf vector of the question and the candidate sentence. For each document, the top 3 sentences were ranked by order of occurrence in the document (not by order of similarity). These sentences were then collated by order of document relevance.</p><p>SnipQA Our second approach used the BioASQ8b question answering system (Figure <ref type="figure" coords="4,485.83,563.36,4.20,10.91" target="#fig_0">1</ref>) to rank the document input sentences. The rationale for this approach was that the BioASQ8b question answering system had been trained to score sentences based on their likelihood of being part of the ideal answer, and we wanted to know whether such a system could be used, without fine-tuning, as a snippet re-ranker. As with the baseline system, the documents were split into sentences. These sentences were then scored using the question-answering system, and the top 3 sentences per document were selected and ranked by order of occurrence. The resulting sentences were then collated by order of document relevance.</p><p>SnipSBERT A third approach was based on the use of sBERT <ref type="bibr" coords="5,385.40,210.74,11.58,10.91" target="#b7">[8]</ref>, trained for passage retrieval. Using the full CORD-19 <ref type="foot" coords="5,226.68,222.54,3.71,7.97" target="#foot_2">4</ref> dataset we have tried to retrieve the most relevant snippets by minimising a cosine distance between a question and a sentence in the dataset. Two variants were implemented: SnipSBERT(a) used the output of the Synergy API and returned the top 3 snippets, whereas SnipSBERT(b) searched the CORD-19 data directly and returned the top 3 or top 5 snippets.</p><p>The final runs used the top 10 snippets, after removing those that were in previous feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Answer Generation</head><p>In all of our experiments, answer generation used the same process as illustrated in Figure <ref type="figure" coords="5,501.06,341.76,5.17,10.91" target="#fig_0">1</ref> to conduct query-focused extractive summarisation. In particular, as in the original paper <ref type="bibr" coords="5,89.29,368.86,11.58,10.91" target="#b5">[6]</ref>, given a question, sentence, and sentence position, the system predicted the probability that the sentence has high ROUGE-F1 score with the ideal answer. We obtained the relevant sentences using the methods for snippet retrieval detailed in Section 2.2. Then, irrelevant sentences (as indicated by feedback from previous rounds) were removed. The position of the remaining sentences was indicated by their order after the snippet retrieval stage and after removing irrelevant sentences. With this information, the question answering system returned the sentence score. The answer was obtained by selecting the top ùëõ sentences, and sorting them by order of appearance in the list of snippets. The value of ùëõ depended on the question type as listed in Table <ref type="table" coords="5,154.45,477.26,3.74,10.91" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Results of the Synergy Task</head><p>All runs submitted to the Synergy Task use the same approach to generate the ideal answers (Section 2.3) and we experimented with combinations of the approaches to retrieve the documents (Section 2.1) and the snippets (Section 2.2). The specific set up of each run, and the results, are detailed in Tables 2, 3, and 4.</p><p>In document retrieval (Table <ref type="table" coords="5,227.92,581.18,3.53,10.91" target="#tab_1">2</ref>), the NIR retrieval approaches outperformed the baseline that used the API provided by the BioASQ organisers. Also, we observed best results when the document retrieval system was tuned with the BioASQ data. Having said this, compared with the other submissions to the Synergy tasks, the document retrieval systems performed poorly, especially on rounds 2 to 4.  In snippet retrieval, some runs used the output of DocAPI, others used the output of Doc-NIR(untuned and tuned). We experimented with snippet re-ranking using SnipCosine and SnipQA as detailed in Table <ref type="table" coords="6,213.96,470.94,3.70,10.91" target="#tab_2">3</ref>. None of the runs used SnipSBERT because of problems meeting the format requirements. <ref type="foot" coords="6,198.62,482.74,3.71,7.97" target="#foot_3">5</ref> We observed variability of results in the runs that used the sequence DocAPI‚ÜíSnipQA due to the undeterministic nature of the question answering module. Overall, all results were very similar, and comparatively worse than the results of other runs. In fact, our runs were near the bottom of the leaderboard in rounds 2 to <ref type="bibr" coords="6,377.49,525.14,3.74,10.91" target="#b3">4</ref>.</p><p>In ideal answer generation, the input to the question answering module used a sequence of document retrieval followed by snippet retrieval as detailed in Table <ref type="table" coords="6,396.57,552.24,3.75,10.91" target="#tab_3">4</ref>. We also included runs that used SnipSBERT for snippet retrieval. Considering the poor results of the snippet retrieval stage, the ideal answer results were relatively good and they were approximately around the median of all submissions. This gives some indication that the question answering system, trained on medical data but not on data containing COVID-19, was relatively robust. Even though the absolute values of the ROUGE-S1 F1 scores were rather low, the average scores of the human evaluation of most of our runs were above 3 in a scale from 0 to 4.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">BioASQ9b Phase B</head><p>The system that participated in BioASQ9b Phase B focused on the use of BERT-based architectures for query-focused extractive summarisation. The experiments reported by <ref type="bibr" coords="7,449.21,536.27,12.88,10.91" target="#b5">[6]</ref> indicated that replacing Word2Vec with BERT in the system of Figure <ref type="figure" coords="7,348.97,549.82,4.97,10.91" target="#fig_0">1</ref> only gave a minor improvement of the results. Subsequent (unpublished) experiments also appeared to indicate that using BERT as an end-to-end system, without adding the multiplication layer between question and sentence, plus the addition of the sentence position for the final classification layer, leads to similar or better results. This motivated us to experiment with the use of BERT in the architecture shown in Figure <ref type="figure" coords="7,133.88,617.57,3.81,10.91" target="#fig_1">2</ref>. The new architecture is a simplification to that of Figure <ref type="figure" coords="7,410.87,617.57,3.81,10.91" target="#fig_0">1</ref>, where most of the computation, including determining the interaction between the question and the sentence, is carried out by BERT. We experimented with several BERT variants as described in Section 3.1. As with the system of Figure <ref type="figure" coords="7,218.36,658.21,5.01,10.91" target="#fig_0">1</ref> and the system by <ref type="bibr" coords="7,308.71,658.21,11.33,10.91" target="#b5">[6]</ref>, the system performs extractive summari-sation and it is trained to predict whether the candidate sentence has a high ROUGE-SU4 F1 score with the ideal answer. In particular, the label of the training set was 1 if the sentence was among the 5 sentences with highest ROUGE-SU4 F1 score, and 0 otherwise. The final ideal answer is obtained by selecting the top ùëõ sentences, and these sentences are presented in order of appearance in the input snippets. The value of ùëõ is as shown in Table <ref type="table" coords="8,412.29,141.16,3.74,10.91" target="#tab_0">1</ref>.</p><p>The question and sentence were fed to BERT in the standard approach defined by the creators of BERT <ref type="bibr" coords="8,128.68,168.26,11.34,10.91" target="#b3">[4]</ref>. In particular, the question and sentence were input as two separate text segments in the following order: first the "[CLS]" special token, then the question, then the sentence separator "[SEP]", and finally the candidate sentence.</p><p>Instead of passing the embedding of the "[CLS]" special token to the classification layer, we decided to use the embeddings of the tokens forming the candidate sentence. These embeddings were mean pooled in order to obtain the sentence embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">BERT Variants</head><p>We experimented with the following BERT variants. All of these variants were based on models made available by the Huggingface transformers repository <ref type="foot" coords="8,354.58,297.53,3.71,7.97" target="#foot_4">6</ref> .</p><p>BERT We used huggingface's model "bert-base-uncased".</p><p>BioBERT Given the medical nature of BioASQ, we tried BioBERT, which uses the same architecture as BERT base, and has been fine-tuned with PubMed articles <ref type="bibr" coords="8,387.98,370.35,11.28,10.91" target="#b8">[9]</ref>. We used huggingface's model "monologg/biobert_v1.1_pubmed". DistilBERT DistilBERT's architecture is a reduced version of BERT, which has been trained to replicate the soft predictions made by BERT <ref type="bibr" coords="8,296.71,426.21,16.14,10.91" target="#b9">[10]</ref>. The resulting system is faster to train, and reportedly nearly as accurate as BERT. We used huggingface's model "distilbert-base-uncased".</p><p>ALBERT ALBERT uses parameter reduction techniques that allow faster training and with lower memory consumption. This enables the use of larger numbers of transformer layers and larger embedding sizes <ref type="bibr" coords="8,194.05,495.62,16.25,10.91" target="#b10">[11]</ref>. We used huggingface's model "albert-xxlarge-v2".</p><p>ALBERT-SQuAD This variant of ALBERT has been fine-tuned with data from SQuAD, a well-known data set for question answering systems in the context of reading comprehension <ref type="bibr" coords="8,89.29,551.47,16.25,10.91" target="#b11">[12]</ref>. We used huggingface's model "mfeb/albert-xxlarge-v2-squad2".</p><p>ALBERT-QA This final variant of ALBERT was obtained using ALBERT-SQUAD as a starting point (using huggingface's model "mfeb/albert-xxlarge-v2-squad2"). Then, the model was fine-tuned by adding a SQuAD-style question answering classification layer and trained on the BioASQ training set, using the exact answers as labels. For this fine-tuning stage, only factoid questions were used. The system that implemented this fine-tuning is one of the systems described by <ref type="bibr" coords="8,148.04,647.98,16.25,10.91" target="#b12">[13]</ref>. In all of our experiments, we froze all BERT layers and only trained the hidden and classification layers. The reason for this decision was that, in preliminary experiments with unfrozen BERT layers, we observed the catastrophic forgetting effect where all the pre-trained information was lost, and decided to leave the study of fine-tuning strategies of the BERT layers for further work.</p><p>Table <ref type="table" coords="9,126.24,307.91,4.97,10.91" target="#tab_4">5</ref> shows the results of 10-fold cross-validation on the BioASQ9b training data. The table also shows the values of the differing hyperparameters of the best systems as found through grid search. The hyperparameters common to all systems were: batch size=32; hidden layer size=50; sentence length clipped to 250 tokens. Overall, all results are similar, but we can observe that BioBERT outperforms BERT, in line with most prior work (but in contrast with <ref type="bibr" coords="9,450.69,362.11,11.25,10.91" target="#b5">[6]</ref>). We can also observe an improvement of the results of the three ALBERT variants. This is possibly due to the larger architecture sizes. The fact that ALBERT-QA has a slightly better result than the other ALBERT variants is encouraging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Submission Results to BioASQ 9b Phase B</head><p>The runs submitted to BioASQ9b Phase B used all the BERT variants described in Section 3.1 except ALBERT-SQuAD.</p><p>The preliminary evaluation results, as reported in the BioASQ website, are shown in Table <ref type="table" coords="9,494.64,479.58,3.66,10.91" target="#tab_5">6</ref>. <ref type="foot" coords="9,501.96,477.83,3.71,7.97" target="#foot_5">7</ref>For each batch, our runs ranked among the top participating systems. In fact, ALBERT-QA was the top run of batch 3. This demonstrates that a straightforward use of BERT is a very strong baseline. As expected, BioBERT outperformed BERT. The experiments with ALBERT and ALBERT-QA in batches 4 and 5, however, were not as good as expected given our cross-validation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Summary and Conclusions</head><p>We have presented Macquarie University's contribution to the BioASQ Synergy task and BioASQ9b Phase B (Ideal Answers). For the synergy task, we have experimented with a question answering module that was designed for, and trained with, the data from BioASQ8b. Due to the need to produce an end-toend system, we tried various baseline document and snippet retrieval systems. Overall, despite the poor general quality of the document and snippet retrieval systems, the results of our submissions indicate that the question answering component can generalise well to questions related to COVID-19. Further work will focus on improving the quality of the document and snippet retrieval components.</p><p>The synergy task was organised in multiple rounds such that feedback from previous rounds was available for subsequent rounds in some questions. Our system incorporated this feedback only in a trivial manner, simply by removing documents or snippets that were identified as known negatives. There has been research on relevance feedback since at least 1971 <ref type="bibr" coords="10,456.35,403.85,16.08,10.91" target="#b13">[14]</ref>, which could be incorporated into the system. More recent approaches, such as using a twin neural network with a contrastive loss <ref type="bibr" coords="10,232.10,430.95,16.25,10.91" target="#b14">[15]</ref>, may work here.</p><p>The contribution to BioASQ9b Phase B focused on the use of BERT variants within a queryfocused extractive summarisation setting. The architecture concatenates the question and candidate sentence as two separate text segments, very much as is done in question-answering approaches with BERT, and the system is trained as a sentence classification system. We observe that such a simple architecture is a very strong baseline. Further work will focus on exploring further variants of BERT, and on enhancing the pre-training and fine-tuning stages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,262.28,343.14,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of the question answering system used for the Synergy task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,89.29,460.81,355.80,8.93"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of the question answering system used for BioASQ 9b, Phase B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,90.49,295.92,54.00"><head>Table 1</head><label>1</label><figDesc>Number of sentences selected, for each question type</figDesc><table coords="5,210.36,118.13,174.55,26.36"><row><cell></cell><cell cols="4">Summary Factoid Yesno List</cell></row><row><cell>n</cell><cell>6</cell><cell>2</cell><cell>2</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,90.49,417.65,154.78"><head>Table 2</head><label>2</label><figDesc>Document retrieval results of the submission to Synergy. Metric: F1. Legend: DocAPI 1 ; DocNIR(untuned) 2 ; DocNIR(tuned)3 .</figDesc><table coords="6,189.84,129.81,215.59,115.46"><row><cell>Run</cell><cell cols="4">Round 1 Round 2 Round 3 Round 4</cell></row><row><cell>Best</cell><cell>0.3457</cell><cell>0.3237</cell><cell>0.2628</cell><cell>0.2375</cell></row><row><cell>Median</cell><cell>0.2474</cell><cell>0.2387</cell><cell>0.1810</cell><cell>0.1839</cell></row><row><cell>Worst</cell><cell>0.0802</cell><cell>0.0560</cell><cell>0.0179</cell><cell>0.0168</cell></row><row><cell>MQ-1</cell><cell>0.2474 1</cell><cell>0.1654 1</cell><cell>0.0973 1</cell><cell>0.1053 1</cell></row><row><cell>MQ-2</cell><cell>0.2474 1</cell><cell>0.1654 1</cell><cell>0.0973 1</cell><cell>0.1053 1</cell></row><row><cell>MQ-3</cell><cell></cell><cell>0.1654 1</cell><cell>0.0973 1</cell><cell>0.1053 1</cell></row><row><cell>MQ-4</cell><cell></cell><cell>0.1654 1</cell><cell></cell><cell>0.1510 2</cell></row><row><cell>MQ-5</cell><cell></cell><cell></cell><cell></cell><cell>0.1762 3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,88.99,264.78,417.65,155.11"><head>Table 3</head><label>3</label><figDesc>Snippet retrieval results of the submission to Synergy. Metric:F1. Legend: DocAPI‚ÜíSnipCosine 1 ; DocAPI‚ÜíSnipQA 2 ; DocNIR(untuned)‚ÜíSnipCosine 3 ; DocNIR(tuned)‚ÜíSnipCosine 4 .</figDesc><table coords="6,189.84,304.42,215.59,115.46"><row><cell>Run</cell><cell cols="4">Round 1 Round 2 Round 3 Round 4</cell></row><row><cell>Best</cell><cell>0.2712</cell><cell>0.1885</cell><cell>0.2026</cell><cell>0.1909</cell></row><row><cell>Median</cell><cell>0.2021</cell><cell>0.1634</cell><cell>0.1645</cell><cell>0.1461</cell></row><row><cell>Worst</cell><cell>0.0396</cell><cell>0.0204</cell><cell>0.0037</cell><cell>0.0078</cell></row><row><cell>MQ-1</cell><cell>0.1414 1</cell><cell>0.0704 1</cell><cell>0.0462 1</cell><cell>0.0640 1</cell></row><row><cell>MQ-2</cell><cell>0.1380 2</cell><cell>0.0706 2</cell><cell>0.0462 2</cell><cell>0.0657 2</cell></row><row><cell>MQ-3</cell><cell></cell><cell>0.0709 2</cell><cell>0.0473 2</cell><cell>0.0634 2</cell></row><row><cell>MQ-4</cell><cell></cell><cell>0.0695 2</cell><cell></cell><cell>0.0798 3</cell></row><row><cell>MQ-5</cell><cell></cell><cell></cell><cell></cell><cell>0.0912 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,88.99,90.49,418.66,346.53"><head>Table 4</head><label>4</label><figDesc>Ideal answer results of the submission to Synergy. Metrics: ROUGE-SU F1 | Average human evaluation.Legend: DocAPI‚ÜíSnipCosine‚ÜíQA 1 ; DocAPI‚ÜíSnipQA‚ÜíQA 2 ; DocNIR(untuned)‚ÜíSnipCosine‚ÜíQA 3 ; DocNIR(tuned)‚ÜíSnipCosine‚ÜíQA4 ; SnipSBERT(a)‚ÜíQA5 ; SnipSBERT(b)‚ÜíQA 6 .</figDesc><table coords="7,94.44,154.04,391.86,282.97"><row><cell>Run</cell><cell>Round 1</cell><cell>Round 2</cell><cell>Round 3</cell><cell>Round 4</cell></row><row><cell>Best</cell><cell></cell><cell>0.0749 | 3.672</cell><cell>0.1170 | 4.185</cell><cell>0.1254 | 3.662</cell></row><row><cell>Median</cell><cell></cell><cell>0.0565 | 3.127</cell><cell>0.0883 | 3.517</cell><cell>0.0857 | 3.157</cell></row><row><cell>Worst</cell><cell></cell><cell>0.0096 | 0.667</cell><cell>0.0181 | 0.750</cell><cell>0.0221 | 0.705</cell></row><row><cell>MQ-1</cell><cell></cell><cell cols="3">0.0567 1 | 3.015 0.0883 1 | 3.517 0.0971 1 | 3.140</cell></row><row><cell>MQ-2</cell><cell></cell><cell cols="3">0.0565 2 | 2.965 0.0926 2 | 3.542 0.0912 2 | 3.157</cell></row><row><cell>MQ-3</cell><cell></cell><cell cols="3">0.0436 5 | 2.670 0.0467 6 | 3.062 0.0515 6 | 2.982</cell></row><row><cell>MQ-4</cell><cell></cell><cell>0.0500 6 | 3.047</cell><cell></cell><cell>0.0857 3 | 3.190</cell></row><row><cell>MQ-5</cell><cell></cell><cell></cell><cell></cell><cell>0.0757 4 | 3.060</cell></row><row><cell>sentence position</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">word embeddings</cell><cell cols="2">sentence embeddings</cell><cell></cell></row><row><cell>sentence</cell><cell></cell><cell>Mean</cell><cell></cell><cell>relu</cell><cell>‚à´Ô∏Ä sigmoid</cell></row><row><cell>BERT</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>question</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,88.99,90.49,382.84,125.73"><head>Table 5</head><label>5</label><figDesc>Results of 10-fold cross-validation using the BioASQ9b training data. Metric: ROUGE SU4 F1.</figDesc><table coords="9,146.25,118.18,302.77,98.04"><row><cell></cell><cell cols="2">Number of Parameters</cell><cell></cell><cell></cell><cell></cell></row><row><cell>System</cell><cell>Full</cell><cell cols="4">Trained Epochs Dropout SU4-F1</cell></row><row><cell>BERT</cell><cell>109,520,791</cell><cell>38,551</cell><cell>8</cell><cell>0.8</cell><cell>0.2779</cell></row><row><cell>BioBERT</cell><cell>108,348,823</cell><cell>38,551</cell><cell>1</cell><cell>0.7</cell><cell>0.2798</cell></row><row><cell>DistilBERT</cell><cell>66,401,431</cell><cell>38,551</cell><cell>1</cell><cell>0.6</cell><cell>0.2761</cell></row><row><cell>ALBERT</cell><cell>222,800,535</cell><cell>204,951</cell><cell>5</cell><cell>0.5</cell><cell>0.2866</cell></row><row><cell cols="2">ALBERT-SQuAD 222,800,535</cell><cell>204,951</cell><cell>5</cell><cell>0.7</cell><cell>0.2846</cell></row><row><cell>ALBERT-QA</cell><cell>222,800,535</cell><cell>204,951</cell><cell>5</cell><cell cols="2">0.4 0.2875</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,88.99,90.49,363.36,155.11"><head>Table 6</head><label>6</label><figDesc>Preliminary results of the submissions to BioASQ9b, Phase B.</figDesc><table coords="10,324.16,118.18,52.64,8.87"><row><cell>ROUGE-SU4</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,108.93,649.10,397.06,8.97;2,89.29,660.06,176.35,8.97"><p>Code associated with this paper is available at https://github.com/dmollaaliod/bioasq-synergy-public and https://github.com/dmollaaliod/bioasq9b-public.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,108.93,671.00,387.04,8.97"><p>We used the "manueltonneau/clinicalcovid-bert-nli" model from the huggingface transformers repository.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="5,108.93,671.01,148.65,8.97"><p>https://www.semanticscholar.org/cord19</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="6,108.93,660.06,397.06,8.97;6,89.29,671.02,91.59,8.97"><p>The Synergy task requires all snippets to include the character offsets. However, our implementation did not provide this information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="8,108.93,671.04,134.81,8.97"><p>https://huggingface.co/transformers/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="9,108.93,660.04,397.06,8.97;9,89.29,671.00,168.06,8.97"><p>Note that the results reported in the BioASQ website (http://bioasq.org) may change in the future after the test data is enriched with further annotations.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was undertaken with the assistance of resources and services from the <rs type="funder">National Computational Infrastructure (NCI)</rs>, which is supported by the <rs type="funder">Australian Government</rs>.</p><p>Research by <rs type="person">Vincent Nguyen</rs> is supported by the <rs type="programName">Australian Research Training Program</rs> and the <rs type="funder">CSIRO</rs> <rs type="grantName">Postgraduate Scholarship</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rdzrFeC">
					<orgName type="grant-name">Postgraduate Scholarship</orgName>
					<orgName type="program" subtype="full">Australian Research Training Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,669.58,381.48,10.91" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00104</idno>
		<title level="m" coord="10,190.93,669.58,173.37,10.91">Text summarization with latent queries</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,86.97,395.17,10.91;11,112.66,100.52,394.53,10.91;11,112.66,114.06,394.53,10.91;11,112.66,127.61,393.33,10.91;11,112.66,141.16,393.33,10.91;11,112.41,154.71,395.25,10.91;11,112.66,168.26,168.81,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,333.85,127.61,172.14,10.91;11,112.66,141.16,294.30,10.91">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Artieres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ngonga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
		<ptr target="http://www.biomedcentral.com/content/pdf/s12859-015-0564-6.pdf.doi:10.1186/s12859-015-0564-6" />
	</analytic>
	<monogr>
		<title level="j" coord="11,415.50,141.16,90.48,10.91">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,181.81,394.53,10.91;11,112.66,195.36,394.53,10.91;11,112.66,208.91,394.53,10.91;11,112.66,222.46,394.53,10.91;11,112.66,236.01,393.53,10.91;11,112.66,249.56,395.00,10.91;11,112.66,263.11,75.26,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,283.18,222.46,219.68,10.91">CORD-19: The COVID-19 open research dataset</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Reas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Burdick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Katsis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Murdick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sheehan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">D</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">X R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kohlmeier</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.nlpcovid19-acl.1" />
	</analytic>
	<monogr>
		<title level="m" coord="11,127.31,236.01,303.80,10.91">Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</title>
		<meeting>the 1st Workshop on NLP for COVID-19 at ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,276.66,393.33,10.91;11,112.66,290.20,393.33,10.91;11,112.66,303.75,393.32,10.91;11,112.66,317.30,393.33,10.91;11,112.66,330.85,394.03,10.91;11,112.66,344.40,234.20,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,323.15,276.66,182.83,10.91;11,112.66,290.20,186.91,10.91">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1423.doi:10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="11,327.87,290.20,178.11,10.91;11,112.66,303.75,393.32,10.91;11,112.66,317.30,99.97,10.91">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="11,112.66,357.95,393.33,10.91;11,112.66,371.50,394.53,10.91;11,112.28,385.05,393.71,10.91;11,112.66,398.60,334.87,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,230.59,357.95,275.40,10.91;11,112.66,371.50,199.56,10.91">NCU-IISR: Using a pre-trained language model and logistic regression model for bioasq task8b phase b</title>
		<author>
			<persName coords=""><forename type="first">J.-C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-H</forename><surname>Tsai</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_72.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,189.21,385.05,316.78,10.91;11,112.66,398.60,26.38,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,412.15,393.33,10.91;11,112.66,425.70,393.58,10.91;11,112.66,439.25,394.62,10.91;11,112.31,452.79,172.79,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,243.14,412.15,262.85,10.91;11,112.66,425.70,20.14,10.91">Query focused multi-document summarisation of biomedical texts</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moll√°</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2696/paper_119.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,398.00,425.70,108.25,10.91;11,112.66,439.25,247.10,10.91">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<meeting><address><addrLine>Thessaloniki</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,466.34,393.33,10.91;11,112.66,479.89,393.33,10.91;11,112.33,493.44,395.33,10.91;11,112.66,506.99,278.35,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,298.32,466.34,207.67,10.91;11,112.66,479.89,56.61,10.91">Pandemic literature search: Finding information on COVID-19</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rybinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xing</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.alta-1.11" />
	</analytic>
	<monogr>
		<title level="m" coord="11,192.35,479.89,313.64,10.91;11,112.33,493.44,314.43,10.91">Proceedings of the 18th Annual Workshop of the Australasian Language Technology Association, Australasian Language Technology Association</title>
		<meeting>the 18th Annual Workshop of the Australasian Language Technology Association, Australasian Language Technology Association<address><addrLine>Virtual</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,520.54,395.17,10.91;11,112.66,534.09,393.33,10.91;11,112.66,547.64,213.97,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,232.22,520.54,275.61,10.91;11,112.66,534.09,39.98,10.91">Sentence-BERT: Sentence embeddings using siamese BERTnetworks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,182.44,534.09,323.55,10.91;11,112.66,547.64,91.61,10.91">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">3982</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,561.19,393.33,10.91;11,112.66,574.74,393.33,10.91;11,112.66,588.29,394.51,10.91;11,112.66,604.28,127.03,7.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,398.01,561.19,107.98,10.91;11,112.66,574.74,316.05,10.91">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btz682.doi:10.1093/bioinformatics/btz682" />
	</analytic>
	<monogr>
		<title level="j" coord="11,439.07,574.74,66.92,10.91">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,615.39,394.52,10.91;11,112.66,628.93,393.33,10.91;11,112.33,642.48,194.20,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,295.53,615.39,211.65,10.91;11,112.66,628.93,111.60,10.91">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,246.02,628.93,259.97,10.91;11,112.33,642.48,64.38,10.91">33rd Conference on Neural Information Processing Systems (NeurIPS 2019)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,112.66,656.03,393.65,10.91;11,112.66,669.58,393.33,10.91;12,112.66,86.97,394.03,10.91;12,112.39,100.52,175.40,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,407.04,656.03,99.27,10.91;11,112.66,669.58,257.52,10.91">ALBERT: A lite BERT for self-supervised learning of language representations</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_H1eA7AEtvS.html" />
	</analytic>
	<monogr>
		<title level="m" coord="11,400.72,669.58,105.26,10.91;12,112.66,86.97,239.41,10.91">Proceedings of the 8th International Conference on Learning Representations</title>
		<meeting>the 8th International Conference on Learning Representations<address><addrLine>Virtual</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,114.06,393.53,10.91;12,112.66,127.61,393.33,10.91;12,112.66,141.16,395.17,10.91;12,112.66,154.71,395.00,10.91;12,112.66,168.26,138.14,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,245.77,114.06,260.41,10.91;12,112.66,127.61,29.70,10.91">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2124</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-2124.doi:10.18653/v1/P18-2124" />
	</analytic>
	<monogr>
		<title level="m" coord="12,166.12,127.61,339.86,10.91;12,112.66,141.16,49.38,10.91;12,286.92,141.16,192.00,10.91">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="12,112.66,181.81,393.33,10.91;12,112.66,195.36,393.32,10.91;12,112.66,208.91,394.90,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,207.78,181.81,298.21,10.91;12,112.66,195.36,53.86,10.91">Transformer-based language models for factoid question answering at BioASQ9b</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moll√°</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,438.33,195.36,67.66,10.91;12,112.66,208.91,271.47,10.91">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<meeting><address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,222.46,393.65,10.91;12,112.66,236.01,394.52,10.91;12,112.66,249.56,55.16,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,171.12,222.46,190.53,10.91">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,452.11,222.46,54.20,10.91;12,112.66,236.01,301.74,10.91">The SMART Retrieval System -Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,112.66,263.11,393.33,10.91;12,112.66,276.66,393.32,10.91;12,112.66,290.20,390.39,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,271.49,263.11,234.50,10.91;12,112.66,276.66,36.88,10.91">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2006.100</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,196.74,276.66,309.24,10.91;12,112.66,290.20,99.88,10.91">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
