<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.71,88.20,394.80,8.02;1,89.29,110.12,399.48,8.02">Vicomtech at MESINESP2: BERT-based Multi-label Classification Models for Biomedical Text Indexing</title>
				<funder>
					<orgName type="full">MCIU/AEI/FEDER, UE)</orgName>
				</funder>
				<funder ref="#_29w7GWv">
					<orgName type="full">SPRI</orgName>
				</funder>
				<funder ref="#_JtAwEWK">
					<orgName type="full">Basque Government)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,138.55,94.41,5.42"><forename type="first">Aitor</forename><surname>Garc√≠a-Pablos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SNLT group at Vicomtech Foundation</orgName>
								<orgName type="department" key="dep2">Basque Research and Technology Alliance (BRTA)</orgName>
								<address>
									<addrLine>Mikeletegi Pasealekua 57</addrLine>
									<postCode>20009</postCode>
									<settlement>Donostia, San-Sebasti√°n</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,194.31,138.55,62.00,5.42"><forename type="first">Naiara</forename><surname>Perez</surname></persName>
							<email>nperez@vicomtech.org</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SNLT group at Vicomtech Foundation</orgName>
								<orgName type="department" key="dep2">Basque Research and Technology Alliance (BRTA)</orgName>
								<address>
									<addrLine>Mikeletegi Pasealekua 57</addrLine>
									<postCode>20009</postCode>
									<settlement>Donostia, San-Sebasti√°n</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.75,138.55,79.93,5.42"><forename type="first">Montse</forename><surname>Cuadros</surname></persName>
							<email>mcuadros@vicomtch.org</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SNLT group at Vicomtech Foundation</orgName>
								<orgName type="department" key="dep2">Basque Research and Technology Alliance (BRTA)</orgName>
								<address>
									<addrLine>Mikeletegi Pasealekua 57</addrLine>
									<postCode>20009</postCode>
									<settlement>Donostia, San-Sebasti√°n</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.28,640.79,22.18,4.06"><surname>Pablos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SNLT group at Vicomtech Foundation</orgName>
								<orgName type="department" key="dep2">Basque Research and Technology Alliance (BRTA)</orgName>
								<address>
									<addrLine>Mikeletegi Pasealekua 57</addrLine>
									<postCode>20009</postCode>
									<settlement>Donostia, San-Sebasti√°n</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.71,88.20,394.80,8.02;1,89.29,110.12,399.48,8.02">Vicomtech at MESINESP2: BERT-based Multi-label Classification Models for Biomedical Text Indexing</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">79B203F2BA59BC88B91B358AD83EAD8E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Biomedical Text</term>
					<term>Automatic Indexing</term>
					<term>DeCS</term>
					<term>Spanish</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the Vicomtech NLP team in the MESINESP2 shared task. The challenge consists in the development of systems for the automatic indexing with DeCS codes of healthrelated documents in Spanish. The systems submitted by Vicomtech are multilabel classifiers based on pre-trained BERT models. We have experimented with multiple ways of representing the documents, such as encoding DeCS term glosses along with the input text. According to the official evaluation results, our systems are surpassed by other competing teams-despite being fast and achieving good precision, we fall behind especially in recall metrics. Overall, the task remains challenging even for the best performing systems and there is ample room to advance the state of the art for this particular task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The MESINESP2 shared task <ref type="bibr" coords="1,218.72,393.80,11.43,4.94" target="#b0">[1]</ref>, similar to the first MESINESP edition <ref type="bibr" coords="1,404.71,393.80,11.43,4.94" target="#b1">[2]</ref>, is an open BioASQ <ref type="bibr" coords="1,89.29,407.35,12.76,4.94" target="#b2">[3]</ref> competition to develop automatic systems for the semantic indexing of Spanish documents with DeCS 1 , a structured medical vocabulary derived from the Medical Subject Headings (MeSH) <ref type="bibr" coords="1,89.29,434.45,11.43,4.94" target="#b3">[4]</ref>. DeCS comprises 34,294 descriptors and qualifiers.</p><p>The shared task is divided into three subtracks, each targeted to a different type of healthrelated document: scientific literature, clinical trials and patents, respectively. We have participated in all the subtracks implementing variations of a Transformers-based <ref type="bibr" coords="1,441.77,475.10,12.86,4.94" target="#b4">[5]</ref> multi-label classification model. In particular, our models feature a pre-trained BERT model <ref type="bibr" coords="1,447.38,488.65,12.83,4.94" target="#b5">[6]</ref> to encode the input text and, in some versions, inject external knowledge (i.e. DeCS term glosses) to the model. Despite our scores lagging behind the best competing systems, our team ranks third in Subtrack 1 and second in Subtrack 2. Still, the overall challenge results show that there is room for improvement and future work.</p><p>The rest of the document is structured as follows. Section 2 introduces the data provided by the organizers of the challenge, with a special focus on the DeCS code imbalance and how we tackle this problem. Sections 3 and 4 describe our submitted systems and the training setup, respectively. Section 5 presents the official results. In Section 6, we discuss some decisions taken during the development and training phases, inherent flaws of our systems, and potential improvements. Finally, Section 7 provides some concluding remarks and future work hints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data description</head><p>MESINESP2 is organized into three subtracks, each focused on health-related documents of a different genre <ref type="bibr" coords="2,158.55,347.79,11.53,4.94" target="#b6">[7]</ref>. The sizes of the datasets per subtrack and split are shown in Table <ref type="table" coords="2,477.75,347.79,3.78,4.94" target="#tab_0">1</ref>. The information available for each document of the corpus is the following:</p><p>‚Ä¢ Document ID: a unique identifier for the document.</p><p>‚Ä¢ Title: the title of the document.</p><p>‚Ä¢ Abstract: the abstract of the document, which is the main source of text for the task. ‚Ä¢ Metadata: journal, year and database.</p><p>‚Ä¢ DeCS codes: the DeCS codes that characterize the content of the document.</p><p>The objective of the MESINESP competition is to develop a system capable of predicting the correct set of DeCS codes for any new document. From the total of 34,294 codes of the DeCS terminology, only around 22,000 are present in the training data. Furthermore, the frequency in which the codes occur is highly unbalanced: a minority of codes occur in more than 80% of the training documents, while the majority of codes are way more sparse, with less than a hundred examples in the whole dataset. This problem is exacerbated by the fact that we use a multi-label classification approach, so the codes cannot be easily balanced.</p><p>A naive sub-sampling or over-sampling approach would sample the codes grouped by documents, and the imbalance would persist. Further, the codes that barely appear in a few tens of documents in the whole corpus are very unlikely to be learnt by the model, due to the lack of representation. We have addressed this problem by applying a minimum support cut-off. That is, the codes with a frequency lower than a certain preset value are not taken into account for training. A large minimum support cut-off would lead to discard too many codes, while too small a cut-off value would keep many underrepresented labels in the output vocabulary.</p><p>In order to maintain an equilibrium between these too extremes, we have calculated a cut-off value that minimizes the number of codes in the resulting vocabulary while keeping as many </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">System description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Input representation</head><p>We use the titles and abstracts of the documents to be indexed as the main sources of information. In order to feed these fields to the BERT models that will generate the contextual word embeddings, we concatenate them using the usual BERT representation for two texts: the special [CLS] token, followed by the tokenised title, the special [SEP] token, the tokenised abstract, and a second [SEP] token (see Figure <ref type="figure" coords="3,298.91,455.80,3.57,4.94">1</ref>). BERT-base models have a hard limit of 512 tokens, including special characters. The average length of the abstracts in the training set after tokenisation with the corresponding BERT tokeniser is around 300 tokens, with a standard deviation of about 120 tokens. That is, a large percentage of the documents fit in the model. The few ones that do not are simply truncated. We assume that even in those cases in which the last words of the abstract are omitted, the amount of information encoded in the first few hundreds of words is enough to predict the most salient DeCS codes for a given document. This assumption is supported by the fact that, during some preliminary experiments, we did not observe major differences in the development set scores when varying the maximum allowed document length between 300 and 500 BERT tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Architectures</head><p>We have experimented with two different architectures. We henceforth refer to these systems as CSS and LabelGlosses. Both systems are multi-label classifiers built on top of a Transformers model. Given a document, they can predict any number of labels, from 0 to ùê∂, ùê∂ being the size  of the output vocabulary, i.e., 3,274 (in practice, each document is associated to a small number of labels-usually less than 10). The difference between the architectures lies in how they use the contextual word embeddings obtained from the Transformer model.</p><p>Figure <ref type="figure" coords="4,132.34,349.59,5.17,4.94" target="#fig_0">2</ref> shows a diagram of the CSS model. The token contextual-embeddings obtained from the BERT model need to be gathered or processed in a way that provides a fixed length representation, usually called document embedding, that serves as input to a classification head. There are different ways to obtain such a representation.</p><p>The most direct and straightforward approach is to use the special <ref type="bibr" coords="4,395.27,403.47,27.10,7.21">[CLS]</ref> token to act as the document summary. For a model built on a BERT-base architecture, the [CLS] token is a vector of 768 values. After some experimentation, the use of just this token led to poor results. Our hypothesis is that summarizing the whole document into 768 values aiming at discriminating several thousands of possible classes (i.e. DeCS codes) leads to a choke point. That is, the information represented in the [CLS] token alone is too compressed to serve as the input for a classifier with such a high number of output classes.</p><p>To overcome this problem, we draw on other tokens that are always present in every document due to the way we represent them: the [SEP] tokens. For each document, we concatenate the [CLS] token and the two [SEP] tokens into a single vector of 3 √ó 768 values (hence the name of the model). This larger document embedding is then used as input for the classification head.</p><p>The classification head is composed of a dense layer, followed by a nonlinear function, a dropout layer and a linear layer that maps the document-embedding size into a label space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">LabelGlosses model</head><p>The initial components of the LabelGlosses model are very similar to the CSS model, the difference between the thow architectures being that the LabelGlosses model contains an encoded representation of the glosses that describe the DeCS codes (see Figure <ref type="figure" coords="4,431.67,642.81,3.50,4.94" target="#fig_1">3</ref>). Table <ref type="table" coords="4,471.23,642.81,4.97,4.94" target="#tab_4">2</ref> shows some examples of such glosses.</p><p>Prior to the training phase, the DeCS glosses are encoded using the same pre-trained BERT   During training, the document embedding is obtained by averaging the contextual token embeddings from the BERT model. Then, this document embedding is combined with every gloss embedding, forming pairs: (ùëëùëúùëêùë¢ùëöùëíùëõùë°, ùëîùëôùëúùë†ùë† 1 ), (ùëëùëúùëêùë¢ùëöùëíùëõùë°, ùëîùëôùëúùë†ùë† 2 ), ..., (ùëëùëúùëêùë¢ùëöùëíùëõùë°, ùëîùëôùëúùë†ùë† ùê∂ ). Each pair consists of two vectors of size ùêª that are concatenated to obtain a single vector of size ùêª √ó 2. This combined vector is the input to a classification head.</p><p>The classification head of the LabelGlosses model is the same as the CSS model: a dense layer followed by a nonlinear function, a dropout layer and a linear layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Output handling</head><p>The output of the model (be it CSS or LabelGlosses) is an individual score ranging between 0 and 1 for each DeCS code in the output vocabulary. When the model is confident about predicting a certain code, its corresponding score gets closer to 1, and vice versa. A threshold needs to be chosen to decide when a given score must be interpreted as the model predicting the corresponding code for the given input.</p><p>With a threshold of 0, the model would predict all the codes regardless of the input, maximizing the recall but minimizing the precision. A threshold of 1 would mean that the model would never predict any code at all. In the absence of further information, a threshold of 0.5 is a reasonable default, but could be suboptimal.</p><p>In this work, we have used the development sets provided for each subtrack to find out the decision threshold that better balances the precision and recall, thus achieving the best possible F1-score for each trained model. The actual thresholds are reported in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Training setup and submitted systems</head><p>We have participated in all the task subtracks with several variations of the CSS and Label-Glosses models, listed in Table <ref type="table" coords="6,231.03,388.27,3.74,4.94" target="#tab_5">3</ref>.</p><p>For Subtrack 1, we used IXAmBERT <ref type="bibr" coords="6,265.64,401.82,12.95,4.94" target="#b7">[8]</ref> as the pre-trained core model, a BERT-base model pre-trained for Spanish, Basque and English. The runs of Subtracks 2 and 3 use the fine-tuned model resulting from Subtrack 1 as starting point for their own fine-tuning. The reason for this is that the training dataset for Subtrack 2 is small, while there is no training data at all for Subtrack 3 (see Table <ref type="table" coords="6,183.73,456.02,3.50,4.94" target="#tab_0">1</ref>). To measure the impact these choices might have, Subtrack 2 includes a submission that parts from IXAmBERT, and we submit to Subtrack 3 a run that has not been fine-tuned on the data.</p><p>The models have been trained using a GPU NVIDIA 2080ti of 11GB. The training run for a maximum of 200 epochs, with an early-stopping patience of 50 epochs. Under these conditions, the training of the CSS model required 3-4 days, while the training of the LabelGlosses model required around a week to get to the best result validated in the development set. Other training hyperparameters for the described systems are shown in Table <ref type="table" coords="6,370.97,550.86,3.74,4.94">4</ref>.</p><p>The resulting systems process the background sets (6,000 to 10,000 documents) in 2-3 minutes at a speed of ‚àº80 documents per second using 1 NVIDIA RTX 1080ti GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Table <ref type="table" coords="6,116.21,636.58,5.16,4.94" target="#tab_6">5</ref> shows the official results of the competition, including the results of all our runs and the results of the winner system per subtrack. Internal evaluations with the development set showed scores around 44 micro-averaged F1-score for Subtrack 1. However, in the test set our Early stopping patience 50 epochs Optimiser AdamW <ref type="bibr" coords="7,254.96,423.72,11.83,4.79" target="#b8">[9]</ref> Dropout rate 0.1 Learning rate 4E-5 Monitored metric micro F1-score Learning rate warm-up linear, 2 epochs Min. support cutoff 80 Non-linearity Mish <ref type="bibr" coords="7,242.06,459.58,16.46,4.79" target="#b9">[10]</ref> best system scores 38 points, 10 points below the best competing system in Subtrack 1, and 8 points in Subtrack 2. We achieve a reasonable level of precision, only 3 points below the winning system, but recall scores fall behind. This places us in the third and second position for Subtracks 1 and 2, respectively, after the groups of systems by two other teams.</p><p>Unsurprisingly, the results in Subtrack 3 are lower than in the other two, as the runs submitted to this subtrack have seen very little to no in-domain training data, and do not exploit any other source of domain knowledge. It is noteworthy that having fine-tuned the model on just 115 examples-i.e. the development examples available for this subtrack-has had a remarkable positive impact, increasing recall by 12 points (compare Run 3.1 and 3.2).</p><p>Using the LabelGlosses architecture in Subtrack 3 might have helped mitigate the lack of training data, although it seems unlikely given the difference between CSS and LabelGlosses in Subtrack 1. Our attempts to include expert knowledge in the system by encoding DeCS glosses have not had a beneficial impact on the results. In fact, the results obtained by the Label-Glosses runs are slightly lower for all the metrics. A final observation can be made for Runs 2.1 and 2.3, were the former's fine-tuning starts with IXAmBERT while the latter uses the CSS model resulting from Run 1. The knowledge captured from the Subtrack 1 data has helped raise all metrics, particularly recall (+4 points).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>During the training of our systems and their variations, we have made several noteworthy observations. First, the validation scores for all the systems progressed at different paces, some faster than others, towards a plateau of around 45-50 F1-score points in the development sets. Models and hyperparameter variations made little difference. We assume that this plateau is the limit of what the proposed models can learn to generalize from the training data, in particular for the least frequent DeCS codes. For this reason, we tried to inject external knowledge to the model by encoding DeCS term glosses. The proposed approach has not helped in this regard.</p><p>Second, our systems show a clear imbalance between precision and recall. We hypothesise that the imbalance is related, among others, to the exclusion of DeCS codes from the training data when applying the minimum support cut-off value, although further research would be necessary to confirm this or to uncover interactions between other elements of the systems that might be having this effect.</p><p>One such relevant element is the decision threshold, which we use to interpret the output of our models. For each model, we have computed the global threshold that maximises the F1-score in the corresponding development set. That is, the same threshold applies to all the modeled DeCS codes, regardless of the degree of confidence the model might have with respect to each individual code. Given the imbalance of code frequencies in the training data, the confidence is bound to vary greatly. Thus, a decision threshold better tailored to each DeCS code could benefit the precision-recall balance of the results.</p><p>It will be interesting to learn how the winning systems have addressed all these problems. For instance, the official results show that the group of systems that obtained the second position in Subtrack 1, surpassing our models, rank in third position in Subtrack 2, just behind our models. It would be interesting to study the cause for this variation and assess whether the difference lies in the approaches implemented or just in the training procedure.</p><p>Overall, the systems we have submitted, in particular the CSS model, are not complex, and the scores achieved are lower than expected given the results obtained on the development sets. However, our systems are lightweight and fast, being able to process about 80 documents per second in a commodity GPU, consuming less than 4GB of GPU memory, which enables real-time processing scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In these working notes we describe our participation in the MESINESP2 shared task, focused on the medical document indexing in Spanish. We have presented two systems based on Transformers, in particular using BERT-base pre-trained models to encode the text information and to perform a multi-label classification over the large DeCS codes vocabulary.</p><p>The simpler approach relies on combining special BERT-encoded tokens as input for a classification head. In this sense, it is a straightforward model that works fast. The second proposed approach shares key components, namely, the BERT-base model and the multilabel classification nature of the model. The main difference is that it adds an extra layer of DeCS code embeddings, which are meant to encode the meaning of each modelled DeCS code. The embeddings are initialized from the BERT-encoded glosses that provide human-readable definitions of the DeCS codes.</p><p>Despite our experiments on the development set having yielded scores around 44 F1-score points, our best results in the test set reach only around 38, falling 10 points behind the best competing system. Even with these lower results, our team achieves the third position among the competing teams in Subtrack 1, and the second position in Subtrack 2.</p><p>As future work, we have come across several issues that need to be addressed in order to better understand the performance of our systems and improve their results. Most interestingly, we have observed that regardless of the approach and hyperparameter variations, the models reached a similar plateau in the validation score in all our experiments. This suggests that our approaches meet their limit there, and that additional external knowledge is needed to cross it. Thus, we will focus on better and more efficient representations of the DeCS codes, for instance including their hierarchical nature. It would also be interesting to explore approaches related to semantic information retrieval.</p><p>In conclusion, the task remains challenging regardless of the model and approach, with the winning system having achieved scores lower than 50 F1-score points. Further research will be necessary to improve the state of the art of the task proposed by MESINESP2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,269.91,360.28,4.82"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of the CSS model for multi-label classification of the documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,292.98,416.69,4.82;5,89.29,304.94,313.01,4.79"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Architecture of LabelGlosses model. DeCS codes' glosses are encoded into embeddings and paired to each document-embedding as the input for the classification head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,88.99,92.49,364.27,126.68"><head>Table 1</head><label>1</label><figDesc>Size of the shared task corpus in terms of number of documents per subtrack and split</figDesc><table coords="2,142.01,124.06,311.26,95.12"><row><cell></cell><cell cols="4">Training Development Background Testing</cell></row><row><cell>Subtrack 1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Scientific literature</cell><cell>237,574</cell><cell>1,065</cell><cell>10,174</cell><cell>500</cell></row><row><cell>Subtrack 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Clinical trials</cell><cell>3,560</cell><cell>147</cell><cell>8,919</cell><cell>250</cell></row><row><cell>Subtrack 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Patents</cell><cell>0</cell><cell>115</cell><cell>6,000</cell><cell>150</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,182.04,88.08,224.42,150.94"><head></head><label></label><figDesc>2 code 3 code 4 code 5 code 6 code 7 classifier: dense linear + non-linearity + dropout + linear</figDesc><table coords="4,182.04,88.08,224.42,150.94"><row><cell>logits (C)</cell><cell>code 1</cell><cell></cell><cell></cell><cell>...</cell><cell>code C</cell></row><row><cell>document</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>embedding (3xH)</cell><cell></cell><cell></cell><cell>CSS</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>concat</cell><cell></cell><cell></cell></row><row><cell>word</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>embeddings (SxH)</cell><cell>[CLS]</cell><cell>title</cell><cell>[SEP]</cell><cell>abstract</cell><cell>[SEP]</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">pre-trained BERT encoder</cell><cell></cell></row><row><cell>tokens (S)</cell><cell>[CLS] [CLS]</cell><cell>title</cell><cell>[SEP]</cell><cell>abstract</cell><cell>[SEP]</cell></row></table><note coords="4,249.91,92.64,11.75,6.49"><p>code</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,88.96,338.27,418.70,279.72"><head>Table 2</head><label>2</label><figDesc>Examples of glosses for several DeCS terms, together with their code and name model that will be used for training. First, we strip all parenthetical content from the glosses, because such content is often a citation or other irrelevant boilerplate. The gloss encoding process consists in summing the contextual embeddings obtained from the tokens of each gloss, ignoring padding positions. The resulting vectors are used to initialize the DeCS gloss embeddings layer inside the model. This layer is of size ùê∂ √ó ùêª, ùê∂ begin the number of codes in the output vocabulary and ùêª the size of BERT embeddings (i.e. 768 for a BERT-base architecture). These embeddings are fine-tuned during training.</figDesc><table coords="5,95.27,369.65,406.40,129.82"><row><cell>Code</cell><cell>Term</cell><cell>Gloss</cell></row><row><cell>D003970</cell><cell>Diastema</cell><cell>Espacio entre dos dientes adyacentes en el mismo arco dental. (Dor-</cell></row><row><cell></cell><cell></cell><cell>land, 27th ed)</cell></row><row><cell>D007962</cell><cell>Leucocitos</cell><cell>C√©lulas sangu√≠neas blancas. Estas incluyen a los leucocitos granu-</cell></row><row><cell></cell><cell></cell><cell>lares (BASOFILOS, EOSINOFILOS y NEUTROFILOS) as√≠ como a los</cell></row><row><cell></cell><cell></cell><cell>leucocitos no granulares (LINFOCITOS y MONOCITOS).</cell></row><row><cell cols="3">DDCS034870 Mare√≥grafo Instrumento para registrar y medir las oscilaciones de las mareas.</cell></row><row><cell></cell><cell></cell><cell>(Material IV -Glosario de Protecci√≥n Civil, OPS, 1992)</cell></row><row><cell>D011203</cell><cell>Pobreza</cell><cell>Acci√≥n y efecto de empobrecer o empobrecerse. (Fuente: Diccionario</cell></row><row><cell></cell><cell></cell><cell>de la lengua espa√±ola. Real Academia Espa√±ola. Disponible en:</cell></row><row><cell></cell><cell></cell><cell>https://dle.rae.es/?id=ErpRftz)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,88.99,92.49,417.17,324.07"><head>Table 3</head><label>3</label><figDesc>Runs submitted to the competition, characterized by model architecture, pre-training of the encoder model, data split used for fine-tuning and inference threshold value</figDesc><table coords="7,88.99,136.01,405.17,280.54"><row><cell></cell><cell cols="2">Run Architecture</cell><cell>Pre-train</cell><cell>Fine-tuned on</cell><cell>Threshold</cell></row><row><cell>Subtrack 1</cell><cell>1.1</cell><cell>CSS</cell><cell cols="2">IXAmBERT Subtrack 1 trainset</cell><cell>0.25</cell></row><row><cell>Scientific literature</cell><cell>1.2</cell><cell>CSS</cell><cell cols="2">IXAmBERT Subtrack 1 trainset</cell><cell>0.30</cell></row><row><cell></cell><cell>1.3</cell><cell>CSS</cell><cell cols="2">IXAmBERT Subtrack 1 trainset</cell><cell>0.35</cell></row><row><cell></cell><cell>1.4</cell><cell cols="3">LabelGlosses IXAmBERT Subtrack 1 trainset</cell><cell>0.10</cell></row><row><cell></cell><cell>1.5</cell><cell cols="3">LabelGlosses IXAmBERT Subtrack 1 trainset</cell><cell>0.20</cell></row><row><cell>Subtrack 2</cell><cell>2.1</cell><cell>CSS</cell><cell cols="2">IXAmBERT Subtrack 2 trainset</cell><cell>0.25</cell></row><row><cell>Clinical trials</cell><cell>2.2</cell><cell>CSS</cell><cell cols="2">Run 1 CSS Subtrack 2 trainset</cell><cell>0.20</cell></row><row><cell></cell><cell>2.3</cell><cell>CSS</cell><cell cols="2">Run 1 CSS Subtrack 2 trainset</cell><cell>0.25</cell></row><row><cell></cell><cell>2.4</cell><cell>CSS</cell><cell cols="2">Run 1 CSS Subtrack 2 trainset</cell><cell>0.30</cell></row><row><cell>Subtrack 3</cell><cell>3.1</cell><cell>CSS</cell><cell>Run 1 CSS</cell><cell>none</cell><cell>0.05</cell></row><row><cell>Patents</cell><cell>3.2</cell><cell>CSS</cell><cell>Run 1 CSS</cell><cell>Subtrack 3 devset</cell><cell>0.05</cell></row><row><cell></cell><cell>3.3</cell><cell>CSS</cell><cell>Run 1 CSS</cell><cell>Subtrack 3 devset</cell><cell>0.10</cell></row><row><cell></cell><cell>3.4</cell><cell>CSS</cell><cell>Run 1 CSS</cell><cell>Subtrack 3 devset</cell><cell>0.15</cell></row><row><cell></cell><cell>3.5</cell><cell>CSS</cell><cell>Run 1 CSS</cell><cell>Subtrack 3 devset</cell><cell>0.20</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training hyperparameters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Hyperparameter Value</cell><cell></cell><cell cols="2">Hyperparameter Value</cell></row><row><cell cols="3">Max. sequence length 300</cell><cell cols="3">Max training epochs 200 epochs</cell></row><row><cell cols="2">Batch size 16</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.99,92.49,416.99,267.83"><head>Table 5</head><label>5</label><figDesc>Official results per subtrack and run (the subscript numbers next to the architecture names indicate the inference threshold values), including the best competing system per subtrack</figDesc><table coords="8,95.27,136.01,410.11,224.31"><row><cell></cell><cell>Run</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>Acc</cell></row><row><cell>Subtrack 1</cell><cell>1.1 CSS 0.25 w/ IXAmBERT</cell><cell cols="4">38.23 45.09 33.18 23.99</cell></row><row><cell>Scientific literature</cell><cell>1.2 CSS 0.30 w/ IXAmBERT</cell><cell cols="4">38.25 46.22 32.62 24.05</cell></row><row><cell></cell><cell>1.3 CSS 0.35 w/ IXAmBERT</cell><cell cols="4">38.01 47.10 31.86 23.90</cell></row><row><cell></cell><cell>1.4 LabelGlosses 0.10 w/ IXAmBERT</cell><cell cols="4">37.04 45.26 31.34 23.13</cell></row><row><cell></cell><cell>1.5 LabelGlosses 0.20 w/ IXAmBERT</cell><cell cols="4">37.46 45.60 31.79 23.23</cell></row><row><cell></cell><cell>Best System (BERTDeCS version 4)</cell><cell cols="4">48.37 50.77 46.18 32.61</cell></row><row><cell>Subtrack 2</cell><cell>2.1 CSS 0.25 w/ IXAmBERT</cell><cell cols="4">24.85 27.21 22.87 13.84</cell></row><row><cell>Clinical trials</cell><cell>2.2 CSS 0.20 w/ Run 1 CSS</cell><cell cols="4">28.10 28.88 27.36 16.31</cell></row><row><cell></cell><cell>2.3 CSS 0.25 w/ Run 1 CSS</cell><cell cols="4">28.19 29.33 27.15 16.36</cell></row><row><cell></cell><cell>2.4 CSS 0.30 w/ Run 1 CSS</cell><cell cols="4">28.07 29.24 26.78 16.29</cell></row><row><cell></cell><cell>Best System (BERTDeCS version 2)</cell><cell cols="4">36.40 36.66 36.14 22.42</cell></row><row><cell>Subtrack 3</cell><cell cols="5">3.1 CSS 0.05 w/ Run 1 CSS (no fine-tuning) 19.68 27.00 15.48 10.76</cell></row><row><cell>Patents</cell><cell>3.2 CSS 0.05 w/ Run 1 CSS</cell><cell cols="4">26.51 25.47 27.64 15.72</cell></row><row><cell></cell><cell>3.3 CSS 0.10 w/ Run 1 CSS</cell><cell cols="4">28.34 31.88 25.51 16.89</cell></row><row><cell></cell><cell>3.4 CSS 0.15 w/ Run 1 CSS</cell><cell cols="4">29.08 35.96 24.40 17.29</cell></row><row><cell></cell><cell>3.5 CSS 0.20 w/ Run 1 CSS</cell><cell cols="4">29.21 38.90 23.28 17.25</cell></row><row><cell></cell><cell>Best System (BERTDeCS version 2 )</cell><cell cols="4">45.14 44.87 45.41 30.05</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially funded by the projects <rs type="projectName">DeepText</rs> (<rs type="grantNumber">KK-2020-00088</rs>, <rs type="funder">SPRI</rs>, <rs type="funder">Basque Government)</rs> and <rs type="projectName">DeepReading</rs> (<rs type="grantNumber">RTI2018-096846-B-C21</rs>, <rs type="funder">MCIU/AEI/FEDER, UE)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_29w7GWv">
					<idno type="grant-number">KK-2020-00088</idno>
					<orgName type="project" subtype="full">DeepText</orgName>
				</org>
				<org type="funded-project" xml:id="_JtAwEWK">
					<idno type="grant-number">RTI2018-096846-B-C21</idno>
					<orgName type="project" subtype="full">DeepReading</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,112.66,186.72,394.53,4.94;10,112.66,200.27,395.00,4.94;10,112.66,213.82,394.53,4.94;10,112.66,227.36,151.46,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,312.32,200.27,191.17,4.94">Overview of BioASQ 2021-MESINESP track</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Estrada-Zavala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R.-T</forename><surname>Murasaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Primo-Pe√±a</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bojo-Canales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,112.66,213.82,394.53,4.94;10,112.66,227.36,115.57,4.94">Evaluation of Advance Hierarchical Classification Techniques for Scientific Literature, Patents and Clinical Trials</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,240.91,394.53,4.94;10,112.28,254.46,393.71,4.94;10,112.66,268.01,395.17,4.94;10,112.66,281.56,274.95,4.94" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,346.47,254.46,159.52,4.94;10,112.66,268.01,214.91,4.94">Overview of MESINESP8, a Spanish Medical Semantic Indexing Task within BioASQ</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rodriguez-Penagos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Asensio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Armengol-Estap√©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,371.76,268.01,136.07,4.94;10,112.66,281.56,201.59,4.94">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,295.11,394.53,4.94;10,112.66,308.66,395.17,4.94;10,112.66,322.21,220.84,4.94" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,112.66,308.66,94.98,4.94;10,237.47,308.66,270.36,4.94;10,112.66,322.21,183.78,4.94">The ninth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vandorou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">.</forename><surname>Paliouras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>Overview of BioASQ</note>
</biblStruct>

<biblStruct coords="10,112.66,335.76,395.17,4.94;10,112.66,349.31,107.55,4.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,183.90,335.76,140.30,4.94">Medical subject headings (mesh)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Lipscomb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,332.69,335.76,175.14,4.94;10,112.66,349.31,17.81,4.94">Bulletin of the Medical Library Association</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="265" to="266" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,362.86,395.17,4.94;10,112.66,376.41,393.33,4.94;10,112.28,389.95,395.39,4.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,152.27,376.41,116.34,4.94">Attention Is All You Need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">≈Å</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,296.00,376.41,209.98,4.94;10,112.28,389.95,231.73,4.94">Proceedings of the Thirty-first Conference on Advances in Neural Information Processing Systems</title>
		<meeting>the Thirty-first Conference on Advances in Neural Information Processing Systems<address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,403.50,393.33,4.94;10,112.33,417.05,393.65,4.94;10,112.66,430.60,393.32,4.94;10,112.66,444.15,357.71,4.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,321.08,403.50,184.91,4.94;10,112.33,417.05,192.59,4.94">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,330.38,417.05,175.60,4.94;10,112.66,430.60,393.32,4.94;10,112.66,444.15,102.30,4.94">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="10,112.66,457.70,393.33,4.94;10,112.66,471.25,393.33,4.94;10,112.66,484.80,117.92,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,278.20,457.70,227.79,4.94;10,112.66,471.25,128.32,4.94">MESINESP2 Corpora: Annotated Data for Medical Semantic Indexing in Spanish</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Antonio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,273.51,471.25,232.47,4.94;10,112.66,484.80,113.43,4.94">Funded by the Plan de Impulso de las Tecnolog√≠as de las del Lenguaje (Plan TL)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,498.35,393.33,4.94;10,112.66,511.90,393.33,4.94;10,112.41,525.45,322.01,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,346.95,498.35,159.04,4.94;10,112.66,511.90,285.23,4.94">Conversational Question Answering in Low Resource Scenarios: A Dataset and Case Study for Basque</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Otegi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,421.15,511.90,84.84,4.94;10,112.41,525.45,233.86,4.94">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="436" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,539.00,393.33,4.94;10,112.66,552.55,395.01,4.94;10,112.41,566.09,23.60,4.94" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,226.61,539.00,184.07,4.94">Decoupled Weight Decay Regularization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,438.28,539.00,67.71,4.94;10,112.66,552.55,349.10,4.94">Proceedings of the Seventh International Conference on Learning Representations (ICLR 2019)</title>
		<meeting>the Seventh International Conference on Learning Representations (ICLR 2019)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,112.66,579.64,394.53,4.94;10,112.66,593.19,131.09,4.94" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,170.04,579.64,332.40,4.94">Mish: A Self Regularized Non-Monotonic Neural Activation Function</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Misra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08681</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
