<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,412.55,15.42;1,89.29,106.66,281.16,15.42">Post-processing BioBERT And Using Voting Methods for Biomedical Question Answering</title>
				<funder ref="#_nDbback">
					<orgName type="full">FCT</orgName>
				</funder>
				<funder ref="#_yauQzUR #_5ENkCcb">
					<orgName type="full">LASIGE Research Unit</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,134.97,108.83,11.96"><forename type="first">Margarida</forename><forename type="middle">M</forename><surname>Campos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departamento de Informática</orgName>
								<orgName type="department" key="dep2">Faculdade de Ciências</orgName>
								<orgName type="laboratory">LASIGE</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.76,134.97,94.89,11.96"><forename type="first">Francisco</forename><forename type="middle">M</forename><surname>Couto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departamento de Informática</orgName>
								<orgName type="department" key="dep2">Faculdade de Ciências</orgName>
								<orgName type="laboratory">LASIGE</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,412.55,15.42;1,89.29,106.66,281.16,15.42">Post-processing BioBERT And Using Voting Methods for Biomedical Question Answering</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A4D9B0DABCEABC430F1704CF6BF65B66</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There have been remarkable advances in the field of Biomedical Question Answering (QA) through the application of Transfer Learning to overcome the scarcity of domain-specific corpora. The fine-tuning of BioBERT on general purpose larger datasets prior to fine-tuning on a specific biomedical task has proven to significantly improve performance. There are, however, a lot of post-processing techniques to the outputs of fine-tuned models to be explored.</p><p>In this paper we present our QA system, developed for the BioASQ 9th challenge -Task B, Phase B, developed by our team -LASIGE_ULISBOA. Using the outputs from the fine-tuning of BioBERT on both the Multi-Genre Natural Language Inference (MNLI) and the Stanford Question Answering Dataset (SQuAD) datasets. We compare different post processing strategies for prediction retrieval for Yes/No, Factoid, and List type questions.</p><p>We show that using Softmax in the proper location of the pipeline of answer retrieval leads to better performance and also increases the explainability of a prediction's confidence level in QA. We also present a method for applying voting system algorithms to choose candidates for List type answers, how they can increase MacroF1 score and how one can use them to optimize for either Precision or Recall. The obtained results, averaged over batches, were 0.798 MacroF1 for Yes/No, 0.478 MRR for Factoid, and 0.466 F1 for List.</p><p>The used software is available in an open access repository.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>BioASQ is an annual challenge that comprises different biomedical semantic indexing and question answering (QA) tasks. The presented system is a solution for Task B -Phase B, which consists of providing exact and ideal answers to questions, given related snippets. Biomedical QA is particularly challenging due to the highly domain-specific vocabulary and limited availability of curated datasets. In order to minimize these limitations we used BioBERT <ref type="bibr" coords="1,440.19,507.81,12.95,10.91" target="#b0">[1]</ref> as our base model and Transfer Learning -by fine tuning the base model on non-medical larger datasets, prior to training on the task's training data. There are three types of questions that require exact answers in Task B:</p><p>• Yes/No -binary answer</p><p>• Factoid -answer is a string</p><p>• List -answer is a list of strings, each identifying a different entity CLEF 2021 -Conference and Labs of the Evaluation Forum, September 21-24, 2021, Bucharest, Romania margarida.moreira.campos@gmail.com (M. M. Campos); fjcouto@edu.ulisboa.pt (F. M. Couto)</p><p>Our approach is concerned only with the retrieval of exact answers, and therefore it it was not designed to retrieve answers to Summary type questions or ideal answers (paragraph-sized summaries).</p><p>For factoid and list questions, predictions are always substrings of the provided passages (snippets), making the success of the previous task of snippet retrieval paramount to obtain good results.</p><p>Although the most significant advances in the area have been made by fine-tuning on different and bigger datasets or the development of new and complex transformers architectures <ref type="bibr" coords="2,475.40,181.81,11.33,10.91" target="#b1">[2]</ref>, we aim to show the importance of post-processing and the use of proper final layers for each task.</p><p>Considering that a tractable and meaningful measure of the level of confidence of a prediction is as important as the prediction itself, we present as well a proposal of said confidence level for Yes/No and Factoid questions.</p><p>All the software used can be found in https://github.com/lasigeBioTM/BioASQ9B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Our baseline approach was inspired in the work done by DMIS Laboratory (Korea University) for the previous edition of BioASQ challenge <ref type="bibr" coords="2,286.14,321.73,13.30,10.91" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">BioBERT</head><p>The base model for our system is BioBERT, a BERT <ref type="bibr" coords="2,316.78,371.46,16.66,10.91" target="#b3">[4]</ref> which was pre-trained using PubMed abstracts and PubMed Central (PMC) articles. BioBERT has obtained state-of-the-art results in several biomedical NLP tasks, including QA <ref type="bibr" coords="2,286.45,398.56,11.43,10.91" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Sequential Transfer Learning</head><p>Substantial advances have been made in Natural Language Processing (NLP), specially in domain-specific tasks with the use of Transfer Learning -using the learnt model from a task for a subsequent task <ref type="bibr" coords="2,190.57,475.38,11.58,10.91" target="#b4">[5]</ref>. The use of extra corpora to train is particularly important given the reduced size of the BioASQ dataset. Research has found that fine-tuning on the SQuAD dataset <ref type="bibr" coords="2,124.22,502.48,13.00,10.91" target="#b5">[6]</ref> improves the performance of QA systems where the correct answer is a segment of a provided passage. Another dataset that has proven important is the Multi-Genre Natural Language Inference (MNLI) <ref type="bibr" coords="2,212.00,529.58,14.51,10.91" target="#b6">[7]</ref>, which is widely used to improve questions of type Yes/No, but has also proven to be useful for factoid and list question types, as was shown by DMIS Laboratory (DMIS) <ref type="bibr" coords="2,169.82,556.68,14.12,10.91" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data &amp; Pre-Processing</head><p>MNLI Training data consists of pairs of sentences, each classified with a label from {𝐸𝑛𝑡𝑎𝑖𝑙𝑚𝑒𝑛𝑡, 𝐶𝑜𝑛𝑡𝑟𝑎𝑑𝑖𝑐𝑡𝑖𝑜𝑛, 𝑁 𝑒𝑢𝑡𝑟𝑎𝑙}. The cardinality of each label set can be found in Table <ref type="table" coords="2,450.31,649.82,3.66,10.91" target="#tab_0">1</ref>. Intuitively there is a mapping (MNLI ↔ 𝐵𝑖𝑜𝐴𝑆𝑄): 𝐸𝑛𝑡𝑎𝑖𝑙𝑚𝑒𝑛𝑡 ↔ 𝑌 𝑒𝑠 and 𝐶𝑜𝑛𝑡𝑟𝑎𝑑𝑖𝑐𝑡𝑖𝑜𝑛 ↔ 𝑁 𝑜.   This could suggest that training without the 𝑁 𝑒𝑢𝑡𝑟𝑎𝑙 pairs could improve performance, however our experiments showed that our system's performance did not benefit from this strategy, hence the entire dataset was used.</p><p>SQuAD Training data consists of pairs {𝑄𝑢𝑒𝑠𝑡𝑖𝑜𝑛, 𝑆𝑛𝑖𝑝𝑝𝑒𝑡} and the correct answer as well as its starting position. For training the QA model, the end position was identified and added as input.</p><p>BioASQ Training of the systems was done using BioASQ 8B training data, and evaluation was done on BioASQ 8B test batches. In Table <ref type="table" coords="3,274.76,458.66,5.02,10.91" target="#tab_1">2</ref> we can see the number of questions in the BioASQ training data, and in Figure <ref type="figure" coords="3,213.28,472.21,5.06,10.91" target="#fig_0">1</ref> we can see the distribution of the number of snippets associated to a question. Examples of questions can be found in Table <ref type="table" coords="3,352.11,485.76,3.72,10.91" target="#tab_2">3</ref>, and the number of train and test questions for each type of question can be found in Table <ref type="table" coords="3,354.44,499.31,3.81,10.91" target="#tab_3">4</ref>. It is important to mention that only 177 (20%) of the Yes/No questions have the label No, making the classification extremely imbalanced. To handle this, undersampling <ref type="bibr" coords="3,280.88,526.41,15.10,10.91" target="#b7">[8]</ref> of the Yes class was performed, resulting in an even smaller set of 354 unique questions. Oversampling the No class proved to be ineffective.</p><p>For list questions, each entity in the golden label was considered a correct answer for the given {𝑄𝑢𝑒𝑠𝑡𝑖𝑜𝑛, 𝑆𝑛𝑖𝑝𝑝𝑒𝑡} pair, i.e. a pair whose golden list contains 𝑚 entities will appear as 𝑚 distinct input observations, each labeled with a different correct answer. A summary of different type of inputs can be seen in Table <ref type="table" coords="3,287.23,594.15,3.74,10.91" target="#tab_4">5</ref>.</p><p>Both factoid and list inputs were converted to the mentioned SQuAD format -containing the answer's start and end positions. Observations whose snippets did not contain the correct answer were discarded.</p><p>As with all BERT inputs, {𝑄𝑢𝑒𝑠𝑡𝑖𝑜𝑛, 𝑆𝑛𝑖𝑝𝑝𝑒𝑡} pairs are added a [CLS] token in the beginning -for classification -and a separation token ([SEP]) is added in between the two input texts, as well as in the end of the input. Additional biomedical datasets could have been curated to be used for fine tuning the system, however this was not done due to time constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Fine Tuning</head><p>For the fine-tuning of BioBERT the best performing sequences of training reported in <ref type="bibr" coords="4,468.93,651.08,12.76,10.91" target="#b2">[3]</ref> were used. For Yes/No questions the sequence is BioBERT-MNLI-BioASQ, as for factoid and list  For training on the SQuAD corpus, the final classification layers are removed and the architecture of BertForQuestionAnswering model from the Transformers library is used. A simplified overview of Input/Output from BertForQuestionAnswering can be seen in Figure <ref type="figure" coords="5,450.70,552.62,3.81,10.91" target="#fig_1">2</ref>. In QA the input provided contains the start and end positions of the tokens representing the span of the correct answer within the passage. Training is done by creating two new vectorsstart logits and end logits of shape (𝑖𝑛𝑝𝑢𝑡_𝑙𝑒𝑛𝑔𝑡ℎ, 1) that represent the likelihood of each token being the start and end of the answer, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Post-Processing and Output Aggregation</head><p>Given that the same question can have multiple snippets associated to it, leading to different {𝑄𝑢𝑒𝑠𝑡𝑖𝑜𝑛, 𝑆𝑛𝑖𝑝𝑝𝑒𝑡} pairs as input, a strategy is needed to combine the different outputs  <ref type="figure" coords="6,365.61,162.94,4.63,8.87" target="#fig_3">4</ref> into single predictions. Each type of question demands a different approach, hence they are presented separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Yes/No</head><p>Let 𝑝 𝑖𝑗 and 𝑝 𝑖𝑗 represent the model's output probability of question 𝑖 given the snippet 𝑗 having answer Yes and No, respectively. The predicted answer will be the one with a highest mean probability over the 𝐽 snippets associated to question 𝑖. 𝑃 𝑖 represents the level of confidence that the provided answer is correct.</p><formula xml:id="formula_0" coords="6,100.20,316.77,389.33,32.14">𝑝 𝑖 = 1 𝐽 ∑︀ 𝐽 𝑗=1 𝑝 𝑖𝑗 𝑝 𝑖 = 1 𝐽 ∑︀ 𝐽 𝑗=1 𝑝 𝑖𝑗 𝑃 𝑖 = {︃ 𝑃 (𝑌 𝑒𝑠) = 𝑝 𝑖 , if 𝑝 𝑖 ≥ 𝑝 𝑖 𝑃 (𝑁 𝑜) = 𝑝 𝑖 , otherwise</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Factoid</head><p>The relevant outputs from the fine-tuned QA model are the start and end logits vectors. In Figure <ref type="figure" coords="6,120.36,399.20,5.07,10.91" target="#fig_2">3</ref> an output example from the BioASQ golden set from Batch 1 of task 8B can be seen. Let 𝑠 𝑙 𝑖𝑗 and 𝑒 𝑙 𝑖𝑗 be the start and end logits value corresponding to token 𝑇 𝑙 𝑖𝑗 , the 𝑙 𝑡ℎ of the 𝑗 𝑡ℎ snippet associated to question 𝑖, and 𝑃 𝑟𝑒𝑑 𝑖𝑗 and 𝑃 𝑟𝑜𝑏 𝑖𝑗 be the lists of predictions and associated confidence levels for the same input.</p><p>In order to choose the best prediction for each input, one should find the span (𝑎, 𝑏) that maximizes some combination of 𝑠 𝑎 𝑖𝑗 and 𝑒 𝑏 𝑖𝑗 . Given the logits are not normalized, to use merely the sum of start and end logits would result in an unfounded comparison between confidence levels for predictions of different snippets.</p><p>To minimize this discrepancy, our approach for each input was implemented as follows:</p><p>1. Create upper triangular matrix 𝑀 where, 𝑀 𝑝,𝑞 = 𝑠 𝑝 𝑖𝑗 + 𝑒 𝑞 𝑖𝑗 (See Figure <ref type="figure" coords="6,444.08,532.45,3.65,10.91" target="#fig_3">4</ref>), for 𝑞 ≥ 𝑝, guaranteeing end does not precede the start 2. Choose positions 𝑎 and 𝑏 that maximize 𝑀 𝑝,𝑞 3. If the expression resulting from the span from 𝑇 𝑎 𝑖𝑗 to 𝑇 𝑏 𝑖𝑗 satisfies admission rules, append expression to 𝑃 𝑟𝑒𝑑 𝑖𝑗 and 𝑀 𝑎,𝑏 to 𝑃 𝑟𝑜𝑏 𝑖𝑗 4. Remove entry 𝑀 𝑎,𝑏 from 𝑀 5. Repeat steps 2 to 4, until lists have length 𝑘, where 𝑘 is an hyperparameter chosen by the user 6. Apply the softmax function to vector 𝑃 𝑟𝑜𝑏 𝑖𝑗 of length 𝑘 To select the top 5 predictions for question 𝑖, we simply select the 5 expressions from the concatenation of the 𝐽 vectors 𝑃 𝑟𝑒𝑑 𝑖𝑗 with the 5 highest corresponding values in the concatenated 𝑃 𝑟𝑜𝑏 𝑖𝑗 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">List</head><p>Potential answers for list questions are retrieved using the same method as for factoid questions.</p><p>The process however requires some extra processing steps, given that for list questions different entities need to be discriminated.</p><p>To select the best list of candidates, we used voting systems treating each distinct obtained answer as a candidate and the frequency in the answers as votes. The systems of Single Transferable Vote (STV) and Preferential Block Voting (PBV) were tested, with STV having the best performance. Elections are performed in rounds, in each round candidates are categorized in states: Elected -if the candidate has already won, Rejected -if the candidate is already unable to win, Hopeful -if the candidate has neither won nor has yet been discarded.</p><p>Candidates for answers are obtained by splitting the predictions by all usual separator characters and words(e.g. ', ', 'and', ';', 'or'). We tested the approach of doing the splitting after the voting -treating full answers as candidates for the STV (STV + PostProcess), and doing the splitting before the voting -separate distinct entities are treated as a vote, with the score for the ranked ballot being the average score of all the answers that contain that entity. An example of ranked candidates before and after being processed can be seen in Tables <ref type="table" coords="7,410.73,591.32,4.97,10.91" target="#tab_5">6</ref> and<ref type="table" coords="7,437.18,591.32,3.66,10.91">7</ref>. E.g. the score of candidate "dizziness" will be the average of scores where the candidate is contained: 0.21, 0.20 and 0.18 (1 𝑠𝑡 ,2 𝑛𝑑 and 5 𝑡ℎ entries of Table <ref type="table" coords="7,288.81,618.42,3.50,10.91" target="#tab_5">6</ref>). Each snippet will contribute to the voting with a ballot of ranked candidates, which then enter the voting algorithm.</p><p>A potential handicap of using voting system algorithms for answer selection is the need to predefine the number of elected entities, since in an election the number of winners is established beforehand. This is not ideal since the correct number of answers for a given list question is not defined. Two characteristics of the implemented algorithms that allow us to minimize this problem are:</p><p>• If the number of non rejected candidates is inferior to the number of selected winners, these are elected • If there are ties in the election, all tied candidates are elected -even if this means electing a superior number of candidates Although these factors allow for some flexibility in the number of predictions, a more flexible approach can be used. Since elections are performed in rounds, one can define that the selected answers are the ones that are not rejected in the pre-final round, i.e., all candidates with states in {Hopeful,Elected}. When referencing this approach we call the number of candidates Hopeful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Software</head><p>Our team tried to replicate the results of 4 state of the art systems and found some reproducibility issues. Some of the causes were: outdated versions of packages, compatibility issues due to the use of conflicting code libraries like the use of both Tensorflow and PyTorch for different stages of the pipeline.</p><p>To avoid the aforementioned issues our implementation was done in a modularized fashion, built in Python 3.6 <ref type="bibr" coords="8,173.31,595.50,16.64,9.72" target="#b9">[10]</ref>, using the Pytorch <ref type="bibr" coords="8,277.35,595.50,18.56,9.72" target="#b10">[11]</ref> versions of model implementations from the Transformers <ref type="bibr" coords="8,145.62,609.05,14.08,9.72" target="#b8">[9]</ref> library as main structure. In spite of its fully Pytorch architecture, the system accepts as input Tensorflow <ref type="bibr" coords="8,209.37,622.60,18.53,9.72" target="#b11">[12]</ref> checkpoints (model's saved parameters).</p><p>Fine-tuning was performed using parallelization on 6 GPUs (Tesla M10) with 8GB of memory each. Total batch size is 18 (3 samples per GPU). Summary of the training details of the reported results can be found in Table 8 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Metrics</head><p>For evaluation and comparison of different models, the official BioASQ measures of performance were used <ref type="bibr" coords="9,136.65,301.08,16.25,10.91" target="#b12">[13]</ref>.</p><p>For Yes/No questions the official metric is the MacroF1 -mean of F1 score of both Yes and No classes. Accuracy is also calculated for completeness. Factoid questions are evaluated using Mean Reciprocal Rank (Metric). Strict Accuracy (SAcc) and Lenient Accuracy (LAcc) are also calculated. List questions are evaluated by the average F1 score of all questions, with the mean precision and recall also reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Results</head><p>In this section we present the experimental results of the referred approaches. Training was done in task 8B training set and evaluation was done in the aggregation of all 8B Phase B batches. Results are compared with the average (weighted by number of questions) of all DMIS systems results in the 5 batches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Yes/No</head><p>In Table <ref type="table" coords="9,129.89,538.40,5.17,10.91" target="#tab_7">9</ref> we can see the results of the different classification architectures for the Yes/No question type. Results are significantly better with the extra fully connected layer, before the final binary one. Experiments showed that performance differs slightly with the number of neurons of the middle layer if it lays between 128 and 512. Higher MacroF1 was obtained with 256 neurons ([CLS]-256-2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Factoid</head><p>For factoid questions performance increased substantially with the use of the k-candidates approach. The results can be seen in Table <ref type="table" coords="9,276.70,655.47,8.20,10.91" target="#tab_0">10</ref>. Best results were obtained with 𝑘 = 2 number of candidate answers per snippet. It is interesting to point out that for 𝑘 &gt; 4 the results almost do not differ. This is due to the fact that candidates of order higher than 4 typically have extremely low scores and end up with probabilities close to 0, therefore are discarded when the top 5 predictions are extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 10</head><p>Experimental results of Factoid models. Trained on training data for task 8B, evaluated on the task's 5 test batches. Start+End represents the classic approach of applying Softmax to both Start and End Logits prior to finding the scores' maximizing answers. Top k represents the approach of applying Softmax to the 𝑘 selected candidates. Different values of k are presented <ref type="bibr" coords="10,387.68,190.94,10.36,8.87" target="#b1">(2,</ref><ref type="bibr" coords="10,398.04,190.94,6.91,8.87" target="#b4">5,</ref><ref type="bibr" coords="10,404.94,190.94,10.36,8.87" target="#b9">10)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">List</head><p>In Table <ref type="table" coords="10,130.31,376.87,10.35,10.91" target="#tab_9">11</ref> we can see the results of experiments with the list questions. We can observe the impact of requesting different number of winners from the algorithm. Unsurprisingly, a larger number of winners leads to an increase in Recall and a decrease in Precision. Maximum performance (MacroF1) is obtained with the Hopeful strategy, for both processing strategies. Results show that splitting candidates prior to the voting leads to better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">BioASQ Official Results</head><p>A summary of the official results from BioASQ Task9B -Phase B can be seen in Table <ref type="table" coords="10,463.81,480.79,8.20,10.91" target="#tab_1">12</ref>, where we present the results of the top teams along with ours (LASIGE), considering the BioASQ ordering. The place in each batch is considered to be the place of the best scoring system for each team, considering all systems of each team as one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Unanswerability</head><p>An important aspect to look at when evaluating performance, is the unanswerability of some questions in the dataset. Several questions in the test sets have an answer which can not be extracted from the provided snippets. Ideally, to measure the actual performance of answer extracting systems, these would be removed from the test set. Examples of such questions can be seen in Table <ref type="table" coords="10,163.53,625.36,8.36,10.91" target="#tab_2">13</ref>.</p><p>For the test set of task 8B (resulting of the aggregation the 5 test batches), 22, 5% of factoid questions do not contain the golden answer in any provided snippet, and 25.3% of list questions have at least one entity that is not contained in the snippets. For Yes/No questions unanswerability would have to be manually done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Analysis of Results</head><p>All reported results were obtained using BioBERT Base (12 stacked encoding layers). Although we tested with BioBERT Large (24 stacked encoding layers), which usually obtains better results, the results were very poor. This is probably due to memory restrictions. Since BioBERT Large has over three times more trainable parameters, reductions in input size and batch size had to be made, which are probably the cause for the low performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Yes/No</head><p>The addition of a fully connected layer between the MNLI classification layer (3 neurons) and the BioASQ binary classification layer improved performance on the test set. This indicates that the relation between the knowledge obtained on the NLI data and the one needed for the BioASQ questions is not as obvious as one might expect. This is not uncommon when we are dealing with corpora from different domains (general purpose vs biomedical), and might also be related to the existence of unanswerable questions in the dataset that difficult model's learning of what represents agreement between question and snippet, since the inputs with no relation are inducing noise for the binary task.</p><p>In Figure <ref type="figure" coords="11,144.99,649.34,5.17,10.91" target="#fig_4">5</ref> we can see the distribution of the confidence levels for Yes (𝑃 (𝑌 𝑒𝑠)) and No (𝑃 (𝑁 𝑜)) predictions, compared between the actual value of the correct answer. Note that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 12</head><p>Summary of the official results from BioASQ Task9B -Phase B. The place in each batch is considered to be the place of the best scoring system for each team, and considering all systems of each team as one. Reported scores are taken from the overall best ranked system for each team. No model's discriminatory power (distance between 𝑃 (𝑌 𝑒𝑠) and 𝑃 (𝑁 𝑜)) is much greater for answers with Yes label. This can also be seen by looking at the differences between the F1 scores of both classes, noting that 𝐹 1 𝑦𝑒𝑠 is much higher than 𝐹 1 𝑛𝑜 across experiments. This is not surprising in NLI, as it is easier to identify entailment than it is to distinguish between contradiction and neutral relations. Entailment is usually distinctly expressed in the passage, whilst contradiction sometimes needs to be inferred from more complicated relations between sentences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Batch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Factoid</head><p>Looking at experimental results (Table10) we can see that sorting predictions using scores obtained by applying Softmax to the 𝑘 predictions for each snippet strongly improved all metrics. Moreover, we can look at the fitness of the scores by analysing Figure <ref type="figure" coords="13,453.10,397.15,5.17,10.91">6</ref> where we compare the distribution of confidence levels for predictions when the answer was in fact correct or not. We can see that for the classic approach there is an almost 100% overlap of incorrect scores with correct ones, which implies the scoring is not strong. Although there is still some expected overlap in the k-candidates approach, one can distinctly see a higher level of confidence for correct answers, indicating the validity of the proposed score as a confidence level metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">List</head><p>Using voting systems for the choice of list questions proved to be effective, and we can see in Table <ref type="table" coords="13,115.73,541.32,10.12,10.91" target="#tab_1">12</ref> that the proposed system obtained overall strong results for List type questions, with the exception of Batch 5. By using the Hopeful approach, one has flexibility in the number of entities that are selected, and in fact this approach has the best MacroF1 scores across experiments. With the application of the voting systems, opposed to using a predefined threshold for answer selection, we make use not only of the confidence level of each answers but also of the occurrence of the answer and its relative certainty amongst other answers from the same input. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper we used transfer learning to fine-tune BioBERT on general purpose datasets (MNLI and SQuAD) prior to fine-tuning on the BioASQ dataset. We showed how the post-processing of the model outputs greatly impacts performance, revealing that applying Softmax on the output scores from only the 𝑘 selected candidates, for obtaining predictions' confidence level improves overall performance and makes scores more meaningful. We also showed that using the Single Transferable vote system for electing list questions candidates for answers obtains promising results, outperforming the previous approach of selecting candidates merely based on a defined threshold.</p><p>To increase the current model's performance in the future, one can: enrich transfer learning sequences with additional biomedical domain corpora, train current system using BioBERT Large in larger memory GPUs, with same learning parameters (input size, learning rate and batch size). Another possibility is to adapt BERT architecture to allow for training of start and end logits combined, i.e., train QA for finding the exact span of the answer within the text -conditioning end of answer to its start -instead of training them separately and doing the conditioning in the post-processing phase.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,326.22,406.74,8.93;3,154.66,211.59,283.47,102.06"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of number of associated snippets per question, in training data from task 8B</figDesc><graphic coords="3,154.66,211.59,283.47,102.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,341.35,211.79,8.93;5,183.01,214.48,226.77,114.30"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Simplified representation of BERT for QA</figDesc><graphic coords="5,183.01,214.48,226.77,114.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,89.29,150.93,416.70,8.93;6,89.29,162.94,280.95,8.87;6,126.31,84.19,340.16,60.16"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of the output Start and End logits vectors for a snippet. Highlighted cells represent the allowed maximum score pairs, identically highlighted in Figure 4</figDesc><graphic coords="6,126.31,84.19,340.16,60.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,89.29,251.52,260.44,9.15;7,349.73,249.95,7.67,6.12;7,360.94,251.52,136.31,9.14;7,497.81,249.95,7.67,6.12;7,89.29,263.75,416.69,8.87;7,89.29,275.70,416.70,8.87;7,89.29,287.39,121.06,9.14;7,126.31,84.19,340.17,158.71"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Matrix 𝑀 where each entry represents the sum of 𝑖 𝑡ℎ position start logits vector, and 𝑗 𝑡ℎ position of end logits vector. Highlighted in red are scores that are not eligible -end position must be equal or greater to start position, and end position token must not contain a split word, identified with the characters ## (see Fig 3)</figDesc><graphic coords="7,126.31,84.19,340.17,158.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="13,89.29,302.17,326.10,8.93;13,214.51,147.88,163.77,141.73"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Confidence scores for Yes/No predictions split by correct golden label</figDesc><graphic coords="13,214.51,147.88,163.77,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="14,89.29,270.59,416.69,8.93;14,89.29,282.59,31.76,8.87;14,139.13,84.18,151.84,153.08"><head>( a )Figure 6 :</head><label>a6</label><figDesc>Figure 6: Distribution of prediction confidence scores for Factoid questions of the Task 8B -Phase B test set.</figDesc><graphic coords="14,139.13,84.18,151.84,153.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,96.46,153.11,94.82"><head>Table 1</head><label>1</label><figDesc>Statistics MNLI training data. Number of paired sentences per class</figDesc><table coords="3,122.57,138.18,97.63,53.10"><row><cell>Relation</cell><cell># Pairs</cell></row><row><cell>Entailment</cell><cell>130,899</cell></row><row><cell cols="2">Contradiction 130,903</cell></row><row><cell>Neutral</cell><cell>130,900</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,276.50,90.49,222.30,106.77"><head>Table 2</head><label>2</label><figDesc>Statistics of BioASQ 8b training data, used in training.</figDesc><table coords="3,325.26,158.90,117.84,38.36"><row><cell>Yes/No</cell><cell>881</cell><cell>10</cell></row><row><cell>Factoid</cell><cell>941</cell><cell>9</cell></row><row><cell>List</cell><cell>644</cell><cell>11</cell></row></table><note coords="3,276.80,114.45,181.19,8.87;3,276.80,126.40,177.43,8.87;3,310.56,143.89,159.18,9.14"><p>Number of unique questions(Q) and median number of related snippets (S) per question Question Type #𝑄 𝑀 𝑒𝑑𝑖𝑎𝑛#𝑆/𝑄</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,88.99,90.49,380.67,326.39"><head>Table 3</head><label>3</label><figDesc>Example of training questions, snippets and answers from BioASQ training data</figDesc><table coords="4,124.79,121.09,344.87,295.79"><row><cell></cell><cell>Question</cell><cell></cell><cell>Snippet</cell><cell>Gold</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Answer</cell></row><row><cell>Yes/No</cell><cell cols="2">Is Baloxavir effec-</cell><cell>"Baloxavir marboxil is a selec-</cell><cell>yes</cell></row><row><cell></cell><cell cols="2">tive for influenza?</cell><cell>tive inhibitor of influenza cap-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>dependent endonuclease. It has</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>shown therapeutic activity in pre-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>clinical models of influenza A</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>and B virus infections,including</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>strains resistant to current antivi-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ral agents. "</cell><cell></cell></row><row><cell>Factoid</cell><cell>Cemiplimab</cell><cell>is</cell><cell>"Cemiplimab is a PD-1 inhibitor</cell><cell>cutaneous</cell></row><row><cell></cell><cell cols="2">used for treatment</cell><cell>that is approved for treatment of</cell><cell>squamous</cell></row><row><cell></cell><cell cols="2">of which cancer?</cell><cell>metastatic or locally advanced cu-</cell><cell>cell carci-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>taneous squamous cell carcinoma. "</cell><cell>noma</cell></row><row><cell>List</cell><cell cols="2">Which organs are</cell><cell>"In systemic lupus erythemato-</cell><cell>kidney,</cell></row><row><cell></cell><cell cols="2">mostly affected in</cell><cell>sus (SLE), brain and kidney are</cell><cell>brain,</cell></row><row><cell></cell><cell>Systemic</cell><cell>Lupus</cell><cell>the most frequently affected or-</cell><cell>heart,skin</cell></row><row><cell></cell><cell cols="2">Erythematosus</cell><cell>gans. The heart is one of the</cell><cell></cell></row><row><cell></cell><cell>(SLE)?</cell><cell></cell><cell>most frequently affected organs in</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>SLE. Any part of the heart can</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>be affected, including the peri-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>cardium, myocardium, coronary</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>arteries, valves, and the conduction</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>system"</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,88.99,437.86,416.99,111.37"><head>Table 4</head><label>4</label><figDesc>Number of questions and snippets in training and test sets used for obtaining the reported experimental results.</figDesc><table coords="4,160.11,477.79,272.56,71.43"><row><cell>Type of Question</cell><cell cols="4">Train Questions Snippets Questions Snippets Test</cell></row><row><cell>Yes/No</cell><cell>881</cell><cell>11,976</cell><cell>152</cell><cell>1,262</cell></row><row><cell>Factoid</cell><cell>941</cell><cell>11,633</cell><cell>151</cell><cell>1,249</cell></row><row><cell>List</cell><cell>644</cell><cell>88,36</cell><cell>75</cell><cell>662</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,88.99,90.49,328.38,110.76"><head>Table 5</head><label>5</label><figDesc>Input form of each type of dataset used</figDesc><table coords="5,175.42,119.80,241.95,81.44"><row><cell></cell><cell>Input</cell></row><row><cell>MNLI</cell><cell>{Sentence A, Sentence B, Label}</cell></row><row><cell>Yes/No</cell><cell>{Question, Snippet, Label}</cell></row><row><cell>SQuAD</cell><cell></cell></row><row><cell>Factoid</cell><cell>{Question, Context, Answer start, Answer end}</cell></row><row><cell>List</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,88.99,90.49,421.77,108.69"><head>Table 6</head><label>6</label><figDesc>Example of ranked list candidate answers from one snippet and respective scores</figDesc><table coords="8,95.27,90.49,415.50,108.69"><row><cell></cell><cell></cell><cell>Table 7</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Example of ranked list candidate answers</cell></row><row><cell></cell><cell></cell><cell cols="2">after being split by seperators, considering</cell></row><row><cell>Predictions dizziness</cell><cell>Scores 0.21</cell><cell cols="2">the average score of all answers that contain each entity</cell></row><row><cell cols="2">dizziness, orthostatic hypotension 0.20</cell><cell>Predictions</cell><cell>Scores</cell></row><row><cell>orthostatic hypotension</cell><cell>0.20</cell><cell cols="2">orthostatic hypotension 0.20</cell></row><row><cell>hallucination</cell><cell>0.19</cell><cell>dizziness</cell><cell>0.197</cell></row><row><cell>hallucination, dizziness</cell><cell>0.18</cell><cell>hallucination</cell><cell>0.185</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,88.99,219.08,353.99,78.44"><head>Table 8</head><label>8</label><figDesc>Summary of hyperparameters used for the fine-tuning that led to the reported results.</figDesc><table coords="8,242.59,248.00,107.11,49.51"><row><cell>Epochs</cell><cell>3</cell></row><row><cell>Batch Size</cell><cell>18</cell></row><row><cell>Optimizer</cell><cell>Adam</cell></row><row><cell cols="2">Learning Rate 5 × 10 -5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,88.99,90.49,418.66,150.37"><head>Table 9</head><label>9</label><figDesc>Experimental results of Yes/No models. Trained on training data for task 8B, evaluated on the task's 5 test batches. [CLS]-3-2 architecture has the addition of a binary layer on top of the MNLI classification model, [CLS]-256-2 and [CLS]-512-2 has the addition of a fully connected layer of 256 and 512, respectively, before the extra binary layer. DMIS represents the average scores of DMIS Lab systems.</figDesc><table coords="9,151.91,158.62,288.97,82.23"><row><cell>Architecture</cell><cell>Acc</cell><cell>F1no</cell><cell>F1yes</cell><cell>MacroF1</cell></row><row><cell>[CLS]-3-2</cell><cell>0.7039</cell><cell>0.4828</cell><cell>0.7926</cell><cell>0.6377</cell></row><row><cell>[CLS]-3-256-2</cell><cell>0.7434</cell><cell>0.6286</cell><cell>0.8040</cell><cell>0.7163</cell></row><row><cell>[CLS]-3-512-2</cell><cell>0.7368</cell><cell>0.5745</cell><cell>0.8095</cell><cell>0.6920</cell></row><row><cell>DMIS</cell><cell>0.8513</cell><cell>0.8071</cell><cell>0.8733</cell><cell>0.8402</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,89.29,190.94,416.69,131.95"><head></head><label></label><figDesc>. DMIS represents the average scores of DMIS Lab systems.</figDesc><table coords="10,169.96,223.17,252.86,99.73"><row><cell>Strategy</cell><cell>k</cell><cell>SAcc</cell><cell>LAcc</cell><cell>MRR</cell></row><row><cell>Start + End</cell><cell>-</cell><cell>0.1060</cell><cell>0.2119</cell><cell>0.1485</cell></row><row><cell></cell><cell>2</cell><cell>0.3179</cell><cell>0.5232</cell><cell>0.3991</cell></row><row><cell>Top k</cell><cell>5</cell><cell>0.2195</cell><cell>0.5121</cell><cell>0.3390</cell></row><row><cell></cell><cell>10</cell><cell>0.2195</cell><cell>0.5121</cell><cell>0.3390</cell></row><row><cell>DMIS</cell><cell>-</cell><cell>0.3603</cell><cell>0.5656</cell><cell>0.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="11,88.99,90.49,418.66,227.64"><head>Table 11</head><label>11</label><figDesc>Experimental results of List models. Trained on training data for task 8B, evaluated on the task's 5 test batches. STV-PostProcess and STV-PreProcess refer to the strategies of using the Single Transferable Vote algorithm for answer candidates, considering answers splitted by separators after and before voting,respectevily. Elected represents the number of winners required for the voting, with Hopeful representing the strategy of selecting the non-rejected candidates as winners.DMIS represents the average scores of DMIS Lab systems.</figDesc><table coords="11,135.77,182.54,321.25,135.59"><row><cell>Method</cell><cell>Elected</cell><cell>Precision</cell><cell>Recall</cell><cell>MacroF1</cell></row><row><cell></cell><cell>2</cell><cell>0.5111</cell><cell>0.3437</cell><cell>0.3921</cell></row><row><cell>STV-PostProcess</cell><cell>5</cell><cell>0.3906</cell><cell>0.4766</cell><cell>0.4115</cell></row><row><cell></cell><cell>Hopeful</cell><cell>0.4944</cell><cell>0.3289</cell><cell>0.3751</cell></row><row><cell></cell><cell>2</cell><cell>0.4527</cell><cell>0.3306</cell><cell>0.3706</cell></row><row><cell>STV-PreProcess</cell><cell>5</cell><cell>0.4333</cell><cell>0.4167</cell><cell>0.4107</cell></row><row><cell></cell><cell>Hopeful</cell><cell>0.5</cell><cell>0.4167</cell><cell>0.4524</cell></row><row><cell>DMIS</cell><cell>-</cell><cell>0.4761</cell><cell>0.4206</cell><cell>0.3940</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by <rs type="funder">FCT</rs> through project <rs type="projectName">DeST: Deep Semantic Tagger project</rs>, ref. <rs type="grantNumber">PTDC/CCI-BIO/28685/2017</rs>, and the <rs type="funder">LASIGE Research Unit</rs>, ref. <rs type="grantNumber">UIDB/00408/2020</rs> and ref. <rs type="grantNumber">UIDP/00408/2020</rs>.</p><p>We would like to thank <rs type="person">Doctor Maria Fernandes</rs> from the <rs type="affiliation">University of Luxembourg</rs>, who provided us access to larger GPUs for running experiments, for all her help and support.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_nDbback">
					<idno type="grant-number">PTDC/CCI-BIO/28685/2017</idno>
					<orgName type="project" subtype="full">DeST: Deep Semantic Tagger project</orgName>
				</org>
				<org type="funding" xml:id="_yauQzUR">
					<idno type="grant-number">UIDB/00408/2020</idno>
				</org>
				<org type="funding" xml:id="_5ENkCcb">
					<idno type="grant-number">UIDP/00408/2020</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="15,112.66,111.28,393.33,10.91;15,112.66,124.83,394.61,10.91;15,112.31,138.38,384.52,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,361.64,111.28,144.35,10.91;15,112.66,124.83,246.65,10.91">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
		<ptr target="http://dx.doi.org/10.1093/bioinformatics/btz682.doi:10.1093/bioinformatics/btz682" />
	</analytic>
	<monogr>
		<title level="j" coord="15,366.63,124.83,64.30,10.91">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,151.93,395.17,10.91;15,112.66,165.48,273.50,10.91" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m" coord="15,148.16,165.48,107.76,10.91">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,179.03,393.33,10.91;15,112.66,192.57,365.37,10.91" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="15,390.74,179.03,115.25,10.91;15,112.66,192.57,234.98,10.91">Transferability of natural language inference to biomedical question answering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00217</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,206.12,393.33,10.91;15,112.66,219.67,311.37,10.91" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="15,326.58,206.12,179.40,10.91;15,112.66,219.67,181.08,10.91">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,233.22,393.33,10.91;15,112.66,246.77,167.92,10.91" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="15,302.98,233.22,203.01,10.91;15,112.66,246.77,43.52,10.91">How transferable are features in deep neural networks?</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1792</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,260.32,393.33,10.91;15,112.66,273.87,227.85,10.91" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<title level="m" coord="15,323.55,260.32,182.43,10.91;15,112.66,273.87,98.46,10.91">Squad: 100,000+ questions for machine comprehension of text</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,287.42,393.32,10.91;15,112.66,300.97,275.18,10.91" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<title level="m" coord="15,289.01,287.42,216.97,10.91;15,112.66,300.97,145.31,10.91">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,314.52,393.32,10.91;15,112.66,328.07,394.51,10.91;15,112.66,344.06,117.15,7.90" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="15,246.14,314.52,259.84,10.91;15,112.66,328.07,246.89,10.91">Undersampling approach for imbalanced training sets and induction from multi-label text-categorization domains</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dendamrongvit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kubat</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-14640-4_4</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,355.17,394.53,10.91;15,112.66,368.71,394.53,10.91;15,112.66,382.26,395.17,10.91;15,112.66,395.81,393.33,10.91;15,112.66,409.36,394.53,10.91;15,112.66,422.91,385.60,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,315.63,382.26,192.20,10.91;15,112.66,395.81,72.82,10.91">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m" coord="15,207.25,395.81,298.74,10.91;15,112.66,409.36,390.37,10.91">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,436.46,393.33,10.91;15,112.66,450.01,337.18,10.91" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="15,205.02,436.46,259.66,10.91">Python: A dynamic, open source programming language</title>
		<author>
			<orgName type="collaboration" coords="15,112.66,436.46,83.33,10.91">Python Core Team</orgName>
		</author>
		<ptr target="https://www.python.org/" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Python Software Foundation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,463.56,394.53,10.91;15,112.66,477.11,394.52,10.91;15,112.66,490.66,394.53,10.91;15,112.66,504.21,394.53,10.91;15,112.66,517.76,395.17,10.91;15,112.66,531.30,394.03,10.91;15,112.66,544.85,357.13,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="15,371.36,490.66,135.83,10.91;15,112.66,504.21,178.35,10.91">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="15,292.29,517.76,215.54,10.91;15,112.66,531.30,31.56,10.91">Advances in Neural Information Processing Systems 32</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,558.40,394.53,10.91;15,112.48,571.95,395.34,10.91;15,112.66,585.50,394.53,10.91;15,112.66,599.05,395.17,10.91;15,112.66,612.60,394.53,10.91;15,112.30,626.15,395.36,10.91;15,112.66,639.70,330.68,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="15,160.36,626.15,316.02,10.91">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/,softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,112.66,653.25,395.17,10.91;15,112.66,666.80,393.33,10.91;16,112.66,86.97,393.33,10.91;16,112.66,100.52,395.01,10.91;16,112.66,114.06,312.00,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,194.79,666.80,311.20,10.91;16,112.66,86.97,243.74,10.91">Overview of bioasq 2020: The eighth bioasq challenge on large-scale biomedical semantic indexing and question answering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rodriguez-Penagos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58219-7_16</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-58219-7_16" />
	</analytic>
	<monogr>
		<title level="m" coord="16,380.16,86.97,125.83,10.91;16,112.66,100.52,279.47,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
