<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,462.14,148.86,44.12,15.15;1,231.26,170.78,140.47,15.15">2006, the CL-SR track</title>
				<funder ref="#_5FUSzkH">
					<orgName type="full">Grant Agency of the Czech Academy of Sciences</orgName>
				</funder>
				<funder ref="#_8r2Sx58">
					<orgName type="full">Ministry of Education of the Czech Republic</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,234.78,204.67,51.92,8.74"><forename type="first">Pavel</forename><surname>Ircing</surname></persName>
							<email>ircing@kky.zcu.cz</email>
						</author>
						<author>
							<persName coords="1,309.39,204.67,58.83,8.74"><forename type="first">Luděk</forename><surname>Müller</surname></persName>
							<email>muller@kky.zcu.cz</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of West Bohemia at CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,462.14,148.86,44.12,15.15;1,231.26,170.78,140.47,15.15">2006, the CL-SR track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F4F6F89D26992BA9D3696D185B69E8DC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper describes the system build by the team from the University of West Bohemia for participation in the CLEF 2006 CL-SR track. We have decided to concentrate only on the monolingual searching in the Czech test collection. We have employed the Czech morphological analyser and tagger in order to perform necessary linguistic preprocessing (lemmatization and stop-word removal). As for the actual search system, we have employed the classical tf.idf approach with blind relevance feedback as implemented in the LEMUR toolkit. Since the results are currently very close to zero and appear to behave rather randomly, it is not possible to draw any conclusion at this moment. There are several hypothesis concerning the possible causes of the system failure that are currently a subject of investigation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the first participation of the University of West Bohemia group in CLEF (and, for that matter, first participation of the group in an IR evaluation campaign whatsoever). Thus, being novices in the IR field, we have decided to concentrate only on the monolingual searching in the Czech test collection where we have tried to make use of the two advantages that our team might have over the others -the knowledge of the language in question (Czech -our mother tongue) and the experience with automatic NLP of that language, together with the disposal of the necessary tools (morphological analyzer, tagger).</p><p>As for the actual search side of the task, it has been shown by various teams experimenting with the last year English test collection that good results can be achieved simply by using some freely available IR system (see for example <ref type="bibr" coords="1,279.65,704.56,10.30,8.74" target="#b2">[4]</ref>). We have decided to use the same strategy.</p><p>Although both the English and the Czech CL-SR collections consists of the (automatic) transcriptions 1 of the interviews with the Holocaust survivors, the Czech collection lacks the manually created topical segmentation that is available for the English data. This obviously makes the retrieval more complicated. Thus, in order to facilitate the initial experiments with the Czech collection, the track organizers provided also a so-called Quickstart collection with artificially defined "documents" that were created by sliding 3-minute window over the continuous stream of transcriptions with the 1-minute step. The total number of those "documents" in the collection is 11,377. Given the lack of time for experimentation, the presence of many other system parameters and the absence of the training topics, we did not explore any other segmentation possibilities beyond this Quickstart collection in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System description 2.1 Linguistic preprocessing</head><p>At least rudimentary linguistic processing of the document collection and topics (stemming, stopword removal) is considered to be indispensable in state-of-the-art IR systems. We have decided to use quite sophisticated NLP tools for that purposes -the morphological analyzer and tagger developed by the team around Jan Hajič <ref type="bibr" coords="2,270.16,306.00,9.96,8.74" target="#b0">[2]</ref>, <ref type="bibr" coords="2,283.45,306.00,9.96,8.74" target="#b1">[3]</ref>. The serial combination of these two tools assigns disambiguated lemma (basic word form) and morphological tag to the input word form and also provides the information about the stem-ending partitioning.</p><p>This is an example of the typical system output:</p><formula xml:id="formula_0" coords="2,131.51,359.17,339.98,8.30">&lt;f&gt;holokaustem&lt;MDl&gt;holokaust&lt;MDt&gt;NNIS7-----A----&lt;R&gt;holokaust&lt;E&gt;em</formula><p>where &lt;f&gt; introduces the actual word form, the &lt;MDl&gt; the corresponding lemma and the &lt;MDt&gt; the corresponding morphological tag (in this case the tag correctly describes the word holokaustem as the noun (N in the first position) having the masculine inanimate gender (I) and being in singular (S) instrumental (7) form). Finally, the &lt;R&gt; introduces the stem and &lt;E&gt; the ending of the word form in question. Note that although in this example the stem is identical to the lemma it is not the general rule and we believe that the lemmatization should be used instead of stemming in the IR experiments with highly inflectional languages such as Czech. Therefore all our submitted experiments use the lemmatized version of the collection and topics.</p><p>The information provided by the NLP tools was also exploited for the stop-word removal. As we were not able to find any decent stoplist of Czech words we have decided to remove words on the basis of their part-of-speech (POS). As can be seen from the example above, the POS information is present at the first position of the morphological tag. We removed from indexing all the words that were tagged as prepositions, conjunctions, particles and interjections (note that they are no articles in Czech).</p><p>Here is an example of one of the topic before and after the linguistic preprocessing. The original topic &lt;top&gt; &lt;num&gt;1286&lt;/num&gt; &lt;title&gt;Hudba v holokaustu&lt;/title&gt; &lt;desc&gt;Svědectví o tom, zda hudba pomáhala (duševně nebo i jinak) nebo překážela vězňům internovaným v koncentračních táborech.&lt;/desc&gt; &lt;narr&gt;Popis toho, jakou roli hrála hudba v životě vězňů.&lt;/narr&gt; &lt;/top&gt; gets processed into &lt;top&gt; &lt;num&gt;1286&lt;/num&gt; &lt;title&gt;hudba holokaust&lt;/title&gt; &lt;desc&gt;svědectví ten hudba pomáhat duševně jinak překážet vězeň internovaný koncentrační tábor&lt;/desc&gt; &lt;narr&gt;Popis ten jaký role hrát hudba život vězeň&lt;/narr&gt; &lt;/top&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval</head><p>For the actual IR we have used the freely available LEMUR toolkit [1] that allows to employ various retrieval strategies, including among others the classical vector space model and the language modeling approach.</p><p>We have decided to stick to the tf.idf model where both documents and queries are represented as weighted term vectors</p><formula xml:id="formula_1" coords="3,200.49,178.23,238.29,9.65">d i = (w i,1 , w i,2 , • • • , w i,n ) and q k = (w k,1 , w k,2 , • • • , w k,n</formula><p>), respectively (n denotes the total number of distinct terms in the collection). The inner-product of such weighted term vectors then determines the similarity between individual documents and queries. As there are many ways to compute the weights w i,j without any of them performing consistently better than the others, we employed the very basic formula</p><formula xml:id="formula_2" coords="3,259.31,242.74,82.28,23.23">w i,j = tf i,j • log d df j</formula><p>where tf i,j denotes the number of occurrences of the term t j in the document d i (term frequency), d is the total number of documents in the collection and finally df j denotes the number of documents that contain t j .</p><p>In order to boost the performance, we also used the simplified version of the Rocchio's blind relevance feedback implemented in LEMUR <ref type="bibr" coords="3,287.88,322.29,9.97,8.74" target="#b5">[7]</ref>. The original Rocchio's algorithm is defined by the formula</p><formula xml:id="formula_3" coords="3,239.88,353.04,122.70,9.65">q new = q old + α • d R -β • d R</formula><p>where R and R denote the set of relevant and non-relevant documents, respectively, and d R and d R denote the corresponding centroid vectors of those sets. In other words, the basic idea behind this algorithm is to move the query vector closer to the relevant documents and away from the non-relevant ones. In the case of blind feedback, the top M documents from the first-pass run are simply considered to be relevant. The LEMUR modification of this algorithm sets the β = 0 and keeps only the K top-weighted terms in d R .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of the runs</head><p>As we already mentioned in the Introduction, all the experiments were carried out on the Czech Quickstart collection, using only the Czech version of the queries. The linguistic preprocessing and the retrieval method as described in sections 2.1 and 2.2, respectively, were the same for all the runs submitted to the official evaluation. Those runs were the following: Since the official results of the other teams participating in the track revealed that using only the manual keywords gives the best results, we have generated this one additional run:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UWB mkTD</head><p>Query fields used: &lt;title&gt; (T) and &lt;description&gt; (D) Collection fields used: &lt;CZECHMANUKEYWORD&gt; only The total of six runs seems to be small to assess the behavior of the task. However, the reasons why we stopped additional runs are explained in detail in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and their analysis</head><p>There are 115 queries defined for searching in the Czech test collection. However, only 29 of them were manually evaluated by the assessors and used to generate the qrel files. Table <ref type="table" coords="4,454.59,337.06,4.98,8.74">1</ref> summarizes the results for the runs described above (the prefix UWB is omitted due to formatting issues). The mean Generalized Average Precision (GAP) is used as the evaluation metric -the details about this measure can be found in <ref type="bibr" coords="4,219.65,372.92,9.97,8.74" target="#b3">[5]</ref>.</p><p>Run aTD a akTD mk aTD mk a akTD mk a akTDN mkTD Mean GAP 0.0003 0.0003 0.0004 0.0004 0.0004 0.0015</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Mean GAP of the individual runs</head><p>As you can see from the table, the achieved results are very close to zero, especially for the runs employing any of the automatic fields. Moreover, when we tried the same runs with the original word forms or the stems instead of the lemmas we have discovered that the mean GAP generally remains unchanged but at the same time the GAP for individual topics varies quite wildly. This lead us to the hypothesis that the results are completely random. In order to prove or reject such hypothesis we have generated 100 different runs putting random 1,000 documents in the ranked list for each of the topics. The average mean GAP of these runs exceeds 0.0005 which is actually more than the results achieved by runs involving any of the automatic fields.</p><p>As for the run using only the manual keywords, the GAP is slightly better there but behaves no less wildly. Generally, the mean GAP result depends on the result achieved on the single topic (number 14312) as the rest of the GAPs is more or less zero. Moreover, when we accidentally run the non-lemmatized topics on the lemmatized collection, the GAP of that topic jumped from 0.0325 to 0.1000 causing the mean GAP to jump from 0.0015 to 0.0046.</p><p>Therefore we are prone to conclude that the results are indeed currently at the random level. The question is why is it so. The first possibility that comes to mind is some fundamental flaw in the design of the search system itself. This is quite improbable as all the three teams that participated in the track achieved comparable results and at least two of these teams (that means, all besides us) have a significant experience with designing the IR systems for similar evaluation campaigns.</p><p>According to our opinion, one of the reasons of the failure is the immense difficulty of the task in question. This difficulty stems mainly from the following factors:</p><p>1. The collection lacks the topical segmentation -segments in the Quickstart collection are in most cases not topically coherent.</p><p>2. The quality of the ASR transcriptions is rather poor (around 40% WER) -but that is a problem which is shared by both the Czech and the English collections.</p><p>3. The quality of the automatic keyword assignment is generally very low -this is probably caused by the fact that this assignment had to be done in a complicated cross-language manner due to the lack of annotated Czech training data (see <ref type="bibr" coords="5,387.34,167.81,10.29,8.74" target="#b4">[6]</ref>).</p><p>4. There appears to be a non-negligible vocabulary mismatch between the topics and the collection or even between the different fields in the collection. For example, just looking at the first two topics that were evaluated by the assessors we have discovered that in the topic 1181 the name of the infamous concentration camp "Auschwitz" was kept untranslated in the topics but it was translated into its Czech form ("Osvětim") in the &lt;CZECHMANUKEYWORD&gt; and &lt;CZECHAUTOKEYWORD&gt; fields<ref type="foot" coords="5,256.18,245.94,3.97,6.12" target="#foot_0">2</ref> , the word "Sonderkommando" was written with double "m" in the topics and in the &lt;ASRTEXT&gt; field and with single "m" in the keyword fields.</p><p>5. Some of the salient words from the topics hardly appear in the collection at all. For example, the most important word from the topic 1166 ("Hasidism", or its modifications) appears only 3 times in the entire collection, in all cases in the &lt;CZECHAUTOKEYWORD&gt; field and in all cases it is placed there incorrectly.</p><p>There is also a remote possibility that the problem is on the evaluation side. Anyway, all those issues will be a subject of a more detailed investigation in the near future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The Czech CL-SR track presents a first attempt to create and test the collection of the Czech spontaneous speech. As such (and given the inherent challenge of the task in question) seems to suffer some initial difficulties that have to be first precisely identified and then hopefully solved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.00,548.16,55.26,8.77;3,90.00,566.58,209.91,9.02;3,90.00,578.54,168.14,9.02;3,90.00,603.86,71.00,8.77;3,90.00,622.28,97.08,8.74;3,90.00,634.24,263.13,9.02;3,90.00,659.57,74.98,8.77;3,90.00,677.99,97.08,8.74;3,90.00,689.94,263.12,9.02;3,90.00,715.27,90.72,8.77;3,90.00,733.69,97.08,8.74;3,90.00,745.64,379.96,9.02;4,90.00,111.99,99.69,8.77;4,90.00,130.41,169.70,9.02;4,90.00,142.36,379.96,9.02"><head></head><label></label><figDesc>UWB aTDQuery fields used: &lt;title&gt; (T) and &lt;desc&gt; (D) Collection fields used: &lt;ASRTEXT&gt; only UWB a akTD Query fields used: TD Collection fields used: &lt;ASRTEXT&gt; and &lt;CZECHAUTOKEYWORD&gt; UWB mk aTD Query fields used: TD Collection fields used: &lt;CZECHMANUKEYWORD&gt; and &lt;ASRTEXT&gt; UWB mk a akTD Query fields used: TD Collection fields used: &lt;CZECHMANUKEYWORD&gt; and &lt;ASRTEXT&gt; and &lt;CZECHAUTOKEYWORD&gt; UWB mk a akTDN Query fields used: TD and &lt;narr&gt; (N) Collection fields used: &lt;CZECHMANUKEYWORD&gt; and &lt;ASRTEXT&gt; and &lt;CZECHAUTOKEYWORD&gt;</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="5,105.24,731.61,407.75,6.99;5,90.00,741.08,423.00,6.99"><p>Note that neither one of those variants is the original name of the Polish town in question -"Oświȩcim". Consequently, all three forms are routinely used by the Czech speakers and therefore appear in the ASR transcripts.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">Grant Agency of the Czech Academy of Sciences</rs> project No. <rs type="grantNumber">1ET101470416</rs> and the <rs type="funder">Ministry of Education of the Czech Republic</rs> project No. <rs type="grantNumber">LC536</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5FUSzkH">
					<idno type="grant-number">1ET101470416</idno>
				</org>
				<org type="funding" xml:id="_8r2Sx58">
					<idno type="grant-number">LC536</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,569.22,407.50,8.74;5,105.50,581.18,111.72,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,168.50,569.22,155.69,8.74">Disambiguation of Rich Inflection</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,339.75,569.22,168.71,8.74">Computational Morphology of Czech)</title>
		<meeting><address><addrLine>Karolinum, Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,601.10,407.50,8.74;5,105.50,613.06,407.50,8.74;5,105.50,625.01,148.36,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,253.15,601.10,259.84,8.74;5,105.50,613.06,175.23,8.74">Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barbora</forename><surname>Hladká</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,302.29,613.06,178.86,8.74">Proceedings of COLING-ACL Conference</title>
		<meeting>COLING-ACL Conference<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="483" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,644.94,407.50,8.74;5,105.50,656.89,407.50,8.74;5,105.50,668.85,22.70,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,340.22,644.94,172.78,8.74;5,105.50,656.89,128.64,8.74">University of Ottawa&apos;s Contribution to CLEF 2005, the CL-SR Track</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Muath</forename><surname>Alzghool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,255.35,656.89,177.33,8.74">Working notes for CLEF 2005 Workshop</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,688.77,407.50,8.74;5,105.50,700.73,407.50,8.74;5,105.50,712.68,163.89,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,250.72,688.77,262.28,8.74;5,105.50,700.73,213.41,8.74">One-Sided Measures for Evaluating Ranked Retrieval Effectiveness with Spontaneous Conversational Speech</title>
		<author>
			<persName coords=""><forename type="first">Baolong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,340.10,700.73,114.90,8.74">Proceedings of SIGIR 2006</title>
		<meeting>SIGIR 2006<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="673" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,112.02,407.50,8.74;6,105.50,123.98,236.28,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,294.87,112.02,150.03,8.74">Cross-Language Text Classification</title>
		<author>
			<persName coords=""><forename type="first">Scott</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,463.34,112.02,49.66,8.74;6,105.50,123.98,62.04,8.74">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="645" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,143.90,407.50,8.74;6,105.50,155.86,114.29,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,188.93,143.90,152.35,8.74">Notes on the Lemur TFIDF model</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,352.31,143.90,155.87,8.74">Note with lemur 1.9 documentation</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>School of CS, CMU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
