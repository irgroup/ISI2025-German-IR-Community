<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.07,148.86,358.89,15.15;1,130.24,170.78,342.52,15.15">Visual Micro-clustering Pre-processing for Cross-Language Ad hoc Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,270.14,204.68,62.66,8.74"><forename type="first">Masashi</forename><surname>Inoue</surname></persName>
							<email>m-inoue@nii.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Informatics</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,122.07,148.86,358.89,15.15;1,130.24,170.78,342.52,15.15">Visual Micro-clustering Pre-processing for Cross-Language Ad hoc Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B3AA29C165159FF1B18127622BE88FAD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>Measurement, Performance, Experimentation Image retrieval, Visual similarity, Micro-clustering, Pre-processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Images are visual representations. However, when one wants to retrieve them semantically, the visual content of the image is less useful than their textual annotations. When multilingual image collections are considered, there is a possibility of using visual features to overcome the gap between languages. In the ImageCLEF 2006 Photo ad hoc task, the effect of clustering-based pre-processing to enhance the matchabilities of textual queries and images was investigated. In our view, if images are nearly visually identical, then they should be regarded as images of similar relevance, even if they have different annotations.</p><p>Micro-clustering pre-processing was employed to implement this functionality. We experimentally investigated the effectiveness of the technique on a linguistically heterogeneous image collection that consisted of English and German-annotated images. In current preliminary setting, the use of micro-clustering for pre-processing did not help in the retrieval for either English or German topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We often suffer from insufficient recall in image retrieval as compared with the retrieval of textual documents. The number of digital images is rapidly increasing, but the number of relevant images is smaller than when dealing with text. The reasons for this are threefold: 1) the generation of digital images is less actively performed by people or organizations than is the production of digital text, 2) most images are not organized in a searchable form, and 3) existing image retrieval functionalities are not very powerful. These three factors are interwoven. In this paper, we propose a method to overcome these problems by expanding the search target from mono-lingual collections to multi-lingual collections with the aid of visual features.</p><p>In the case of image retrieval based on textual annotations without any translation, the target collection is limited to the images annotated in the query language. This limits a larger set of Figure <ref type="figure" coords="2,122.02,294.06,3.88,8.74">1</ref>: Larger number of images becomes accessible after the micro-clustering pre-processing in cross-language image retrieval. images because of differences between images on the same topic that are annotated in different languages. For example, when the Web is queried using a search engine with the keyword "sheep" and its Japanese translation, the result will contain some typical pictures of sheep in both search results. In addition to these common images, it may be noticed that the English query retrieves pictures of varieties of breed while the Japanese query finds more pictures related to eating. This suggests that even for the same concept, the available images are different when different languages are used. Cross-language information retrieval (CLIR) techniques may help by expanding the types of images accessible on some topics. Figure <ref type="figure" coords="2,281.93,421.52,4.98,8.74">1</ref> illustrates the concept.</p><p>The use of visual features is conducted in the framework of a "find similar" task. This procedure can be executed in two ways. First, is finding similar image pairs or groups prior to querying. The second method involves searching for the similar images after the initial result has been retrieved and sometimes makes use of users' feedback. We investigate the first option in this paper. This choice is based on considerations of efficiency. In comparison, similarity calculation between images based on visual features is heavier than that on textual features. Thus, it is usually desirable to conduct such computations off-line. An on-line method of applying the clustering method for image retrieval is by clustering the retrieved results. In the annotation-based image retrieval framework, Chen et al. applied the clustering method but as the post-processing after querying <ref type="bibr" coords="2,90.00,541.07,9.97,8.74" target="#b1">[2]</ref>.</p><p>In the following sections, we first introduce the systems used; particular emphasis is given to the micro-clustering pre-processing. Secondly, we describe the configuration of submitted runs. Thirdly, we show the retrieval results for the submitted runs and additional runs. Furthermore, we analyze these results with discussions. Finally, the paper presents the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System description 2.1 Retrieval Engine</head><p>The novelty of our method in the ImageCLEF2006 is solely in the pre-processing of the retrieval. The core ranking process has been conducted by an existing search engine. We used the Lemur Toolkit as the engine<ref type="foot" coords="2,186.51,686.38,3.97,6.12" target="#foot_0">1</ref> . The Lemur Toolkit is an information retrieval toolkit designed with language modeling in mind. We used a unigram language-modeling algorithm for building the document models, and Kullback-Leibler divergence for the ranking. The document models were smoothed using Dirichlet prior <ref type="bibr" coords="2,226.77,723.81,9.97,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Translation</head><p>Translation was applied to queries using the Systran machine translation (MT) system<ref type="foot" coords="3,466.62,128.85,3.97,6.12" target="#foot_1">2</ref> . Because of lack of direct translation functionality between German and Japanese in the MT system, English was used as the pivot language when querying German collections using Japanese topics. That is, Japanese queries were first translated into English, and then the English queries were translated into German.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visual Clustering</head><p>Two types of clustering can be imagined. One is macro-clustering or global partitioning, when the entire feature space is divided into sub-regions. The other is micro-clustering or local pairing, where data points nearby are linked so that they form a small group in a particular small region of the feature space. Figure <ref type="figure" coords="3,202.09,260.34,4.98,8.74" target="#fig_0">2</ref> shows the schematic difference between these two clustering methods. Micro-clustering was used to group images based on their visual similarities.</p><p>The use of the micro-clustering technique has been attempted for text processing where terms play central roles for clustering <ref type="bibr" coords="3,229.24,296.20,9.97,8.74" target="#b0">[1]</ref>. In this study, the concept of micro-clustering is used but the features and the similarity measure are different. The process of clustering is as follows. First, visual features are extracted from all images. Simple color histograms are used. Since the images are provided in true color JPEG format, the histograms are created for the red (R), green (G), and blue (B) elements of the images. This results in three vectors for each image: x r , x g , and x b . The length of each vector, or the size of the histogram, i = 256. These are concatenated and define a single feature matrix for each image: X = [x r , x g , x b ]. Thus, the size of feature matrix is i by j where j = 3.</p><p>Further, the similarities between images are calculated using the above feature values. The similarity measure employed was the two-dimensional correlation coefficient r between the matrices. Assuming two matrices A and B, the correlation coefficient is given as</p><formula xml:id="formula_0" coords="3,149.87,434.12,212.89,37.78">r = i j (A ij -Ā)(B ij -B) ( i j (A ij -Ā) 2 )( i j (B ij -B) 2 )</formula><p>where Ā and B are the mean values of A and B respectively.</p><p>Next, a threshold is set that determines which two or more images should belong to the same cluster. In other words, image pairs whose r score is larger than the threshold are considered identical during retrieval. At this stage, the threshold value is determined manually by inspecting the distribution of similarity scores so that relatively small numbers of images constitute clusters. Small clusters containing nearly identical images are preferred since visual similarity does not correspond to semantic similarity; however, visual identity often corresponds to the semantic identity. Finally, re-ranking of ranked lists given by the retrieval engine is conducted using the cluster information. A ranked list is searched from the top and when an image that belongs to a cluster is found, all other members of the cluster will be given the same score as the highly ranked one. This process is continued until the number of images in the list exceeds the pre-specified number, which is 1000 in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of the runs submitted</head><p>The details of the test collection used are given in <ref type="bibr" coords="3,321.13,670.32,9.97,8.74" target="#b2">[3]</ref>. There are 20, 000 images annotated in English and in German. Instead of viewing the collection as a single bilingual collection, it is regarded as a 20, 000 English collection and a 20, 000 German collection. Each annotation has seven fields but only the title and description fields were used.</p><p>Six runs were submitted for the initial evaluation. The query languages were English, German, and Japanese. The collection languages are English and German. The relationship between query   <ref type="table" coords="4,446.16,441.64,3.88,8.74" target="#tab_0">1</ref>. In the table, names of runs are assigned according to the following rules. The first element mcp comes from the proposed method, micro-clustering pre-processing, and represents our group. The second element bl indicates that the baseline method was used. When the micro-clustering pre-processing was applied, this element will be the value of the threshold. For example, 09 denotes the pairs with correlation coefficients greater than 0.9 form a cluster. The next element concerns the query language and the fields of the search topics. Runs using English queries with only title fields are marked by eng t. Similarly, the next element is the collection language and the fields of the annotations. Runs using the German collection with title and description fields are marked by ger td. When half of the English collection and half of the German collection are mixed together, the notation is half td, as shown in Table <ref type="table" coords="4,272.62,561.20,3.88,8.74" target="#tab_1">2</ref>. The last element is the configuration of the retrieval engine. The simple Kullback-Leibler divergence measure was used for ranking (skl ) and Dirichlet prior used for smoothing (dir ). In all runs, the same configuration was adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Language dependency</head><p>In baseline runs, the collection language is the determining factor in retrieval performance as shown in the table. Searching in English collection is better in any query language. Furthermore, the translated topics from German to English on the English collection worked better than monolingual German topics on the German collection. The results for Japanese topics were poor, because of low-performing machine translation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Use of Images to Bridge Languages</head><p>The advantage of the visual-similarity based pre-clustering becomes clear from the application in the linguistically heterogeneous image collections. Therefore, a linguistically heterogeneous collection was constructed by taking 10, 000 randomly chosen images from the English collection and the remaining 10, 000 images from the German collection. There were no overlapping images. Both English queries and German queries without translation were tested on this single collection with micro-clustering. Table <ref type="table" coords="5,217.72,300.43,4.98,8.74" target="#tab_1">2</ref> shows the result. It was observed that no improvement was given by the pre-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Clustering Result</head><p>As seen in Figure <ref type="figure" coords="5,174.52,358.33,3.88,8.74" target="#fig_1">3</ref>, the generated clusters were small and often of size two: a cluster being formed by a pair of images. We intended this by micro-clustering; we have quite small yet highly restricted clusters. The statistics of the size of cluster are as follows: mean = 12.72, standard deviation= 43.81, minimum= 0, median= 368, and maximum= 0. Some clusters have more than 100 members. Such non-micro clusters are not ideal because when one of their members appears in the list, the cluster dominates the entire ranked list after re-ranking. Thus, clusters bigger than 6 were truncated to size 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>At this point, improvement could not have been achieved by incorporating visual pre-processing. This failure might be because clusters of irrelevant images were used rather than relevant ones.</p><p>Because not all of initially retrieved images were relevant, some tactics to select only highly relevant images may be needed. Also, there is a trade-off between the quality of clustering and the degree of search target expansion, and the threshold value used may be conservative to avoid the inclusion of noisy clusters. Additional investigation is needed to clarify the effect of threshold values. The potential advantages of the approach outlined in this study compared to the usual query translation methods are as follows. First, there is no need to combine rankings given by multiple translated queries. Because the rank aggregation is difficult in IR, trial and error in the design of the merging strategies can be avoided. Second, systems do not have to be concerned about the languages. Even when the language distribution within the collection is unknown, the method can be used.</p><p>The limitation of our experimental setting should be noted. The test collection is built upon a random selection from two language collections. Thus, near identical images that might be originally created in a sequential manner could have been split into two languages. However, in reality, similar image pairs may exist only in one language. For example, if one photographer takes photos of an object, it is natural to assume that each of them is annotated in the same language. In future studies, more realistic linguistically heterogeneous collections shall be investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, the experimental runs on ImageCLEF2006 ad hoc task have been presented. The goal was to investigate if images annotated in different languages can be searched beyond the language barriers. A visual feature-based micro-clustering was used for the linkage of near identical images annotated in different languages. After this pre-processing, the retrieval was conducted as a monolingual retrieval. The experiment result does not favor this method.</p><p>Cross-language information access technologies have many potential application areas. However, it is not fully understood in what sort of search task they will bring most benefit <ref type="bibr" coords="6,473.76,364.39,9.97,8.74" target="#b3">[4]</ref>. Considering the language independent nature of visual representation, cross-language image retrieval can be one such task. Although the work conducted in the present study could not succeed, there could be other possibilities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,90.00,294.06,423.04,8.74;4,90.00,306.01,82.28,8.74;4,188.12,108.94,226.73,169.99"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Conceptual difference between Macro-and Micro-clustering. Black dots represent individual data points.</figDesc><graphic coords="4,188.12,108.94,226.73,169.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,272.79,423.07,8.74;6,90.00,284.74,220.73,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distribution of cluster sizes. The graph on the right hand side is the close-up of the graph on the left hand side within the rang 2 to 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,90.00,337.34,413.92,113.04"><head>Table 1 :</head><label>1</label><figDesc>A summary of submitted runs (run names and MAP scores).</figDesc><table coords="4,298.56,349.58,89.66,8.74"><row><cell>Document Language</cell></row></table><note coords="4,201.69,373.89,302.23,8.74;4,99.08,385.85,34.97,8.74;4,182.87,385.86,321.05,8.74;4,99.08,397.81,38.94,8.74;4,182.87,397.81,321.05,8.74;4,90.00,441.64,352.70,8.74"><p>bl.eng t.eng td.skl dir 0.1193 mcp.bl.eng t.ger td.skl dir 0.0634 German mcp.bl.ger t.eng td.skl dir 0.1069 mcp.bl.ger t.ger td.skl dir 0.0892 Japanese mcp.bl.jpn t.eng td.skl dir 0.0919 mcp.bl.jpn t.ger td.skl dir 0.0316 and document languages and submitted runs' names is summarized in the Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,119.50,423.05,69.21"><head>Table 2 :</head><label>2</label><figDesc>A summary of runs against the linguistically heterogeneous collection (run names and MAP scores).</figDesc><table coords="5,96.04,143.71,410.90,45.00"><row><cell></cell><cell cols="2">Half English Half German Document Collection</cell></row><row><cell>Query Language</cell><cell>Without pre-processing</cell><cell>With pre-processing</cell></row><row><cell>English</cell><cell cols="2">mcp.bl.eng t.half td.skl dir 0.0838 mcp.09.eng t.half td.skl dir 0.0586</cell></row><row><cell>German</cell><cell cols="2">mcp.bl.ger t.half td.skl dir 0.0509 mcp.09.ger t.half td.skl dir 0.0374</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.23,747.00,112.63,6.99"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.23,747.00,114.83,6.99"><p>http://babelfish.altavista.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.49,455.01,407.49,8.74;6,105.50,466.97,332.85,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,178.21,455.01,231.20,8.74">A method of cluster-based indexing of textual data</title>
		<author>
			<persName coords=""><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,436.12,455.01,76.86,8.74;6,105.50,466.97,254.11,8.74">Proc. of the 19th Conference on Computational Linguistics (COLING 2002)</title>
		<meeting>of the 19th Conference on Computational Linguistics (COLING 2002)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.49,486.89,407.57,8.74;6,105.50,498.85,407.26,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,325.22,486.89,187.84,8.74;6,105.50,498.85,93.41,8.74">CLUE: Cluster-based retrieval of images by unsupervised learning</title>
		<author>
			<persName coords=""><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,207.49,498.85,174.44,8.74">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1187" to="1201" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,518.77,407.63,8.74;6,105.51,530.73,407.50,8.74;6,105.51,542.68,210.56,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,105.51,530.73,354.24,8.74">Overview of the ImageCLEF 2006 photo retrieval and object annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,486.37,530.73,26.64,8.74;6,105.51,542.68,58.49,8.74">CLEF working notes</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,562.60,407.51,8.74;6,105.51,574.55,407.53,8.74;6,105.51,586.51,226.31,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,180.21,562.60,332.80,8.74;6,105.51,574.55,133.53,8.74">The remarkable search topic-finding task to share success stories of crosslanguage information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Masashi</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,266.32,574.55,246.72,8.74;6,105.51,586.51,109.03,8.74">New Directions in Multilingual Information Access: A Workshop at SIGIR 2006</title>
		<meeting><address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.51,606.43,407.57,8.74;6,105.51,618.39,337.38,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,277.48,606.43,235.60,8.74;6,105.51,618.39,135.76,8.74">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,249.47,618.39,97.04,8.74">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
