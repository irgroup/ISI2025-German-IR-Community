<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,125.53,148.86,351.94,15.15;1,101.50,170.78,400.01,15.15;1,265.76,192.69,71.49,15.15">University of Freiburg at ImageCLEF06 -Radiograph Annotation Using Local Relational Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,150.01,226.59,53.70,8.74"><forename type="first">Lokesh</forename><surname>Setia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Pattern Recognition and Image Processing (LMB)</orgName>
								<orgName type="institution">Albert-Ludwigs-University Freiburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,211.09,226.59,76.68,8.74"><forename type="first">Alexandra</forename><surname>Teynor</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Pattern Recognition and Image Processing (LMB)</orgName>
								<orgName type="institution">Albert-Ludwigs-University Freiburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.83,226.59,63.65,8.74"><forename type="first">Alaa</forename><surname>Halawani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Pattern Recognition and Image Processing (LMB)</orgName>
								<orgName type="institution">Albert-Ludwigs-University Freiburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,382.17,226.59,70.82,8.74"><forename type="first">Hans</forename><surname>Burkhardt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Pattern Recognition and Image Processing (LMB)</orgName>
								<orgName type="institution">Albert-Ludwigs-University Freiburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,125.53,148.86,351.94,15.15;1,101.50,170.78,400.01,15.15;1,265.76,192.69,71.49,15.15">University of Freiburg at ImageCLEF06 -Radiograph Annotation Using Local Relational Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3D81F43B27CB9B722CBB3AED7EFD40EF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>I.5 [Pattern Recognition]: I.5.3 Clustering</term>
					<term>I.5.4 Applications</term>
					<term>Algorithms, Experimentation Classification, Radiograph, Image Annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides details of the experiments performed by the LMB group at the University of Freiburg, Germany, for the medical automatic annotation task in the ImageCLEF 2006. We use local features calculated around interest points, which have recently recieved excellent results for various image recognition and classification tasks. We propose the use of relational features, which are highly robust to illumination changes, and thus quite suitable for X-Ray images. Results with various feature and classifier settings are reported. A significant improvement in results is seen when the relative positions of the interest points are also taken into account during matching. For the given test set, our best run had a classification error rate of 16.7 %, just 0.5 % higher than the best overall submission, and therewith was ranked second in the medical automatic annotation task at the ImageCLEF 2006.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Growing image collections of various kinds have led to the need for sophisticated image analysis algorithms to aid in classification and recognition. This is especially true for medical image collections, where the cost for manual classification of images collected through daily clinical routine can be overwhelming. Automatic classification of these images would spare the skilled human labour from this repetitive, error-prone task. As an example, a study carried out by the University Hospital in Aachen <ref type="bibr" coords="1,224.02,706.24,10.52,8.74" target="#b0">[1]</ref> revealed over 15% human errors in assignment of a specific tag, for X-ray images taken during normal clinical routine. Unless corrected, these images cannot be Figure <ref type="figure" coords="2,121.73,219.88,3.88,8.74">1</ref>: Intra-class variability within the class annotated as "x-ray, plain radiography, coronal, upper extremity (arm), hand, musculosceletal system".</p><p>found again with keyword search alone. Our group (LMB) participated in the ImageCLEF 2006 medical automatic annotation task. In this report, we describe our experiments and submitted runs using a local version of relational features which are very robust to illumination changes, and with different kinds of accumulators to aid in the matching process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Database</head><p>The database for the task was made available by the IRMA group from the University Hospital, Aachen, Germany. It consists of 10,000 fully classified radiographs taken randomly from medical routine. 1,000 radiographis for which classification labels were not available to the participants had to be classified. The aim is to find out how well current techniques can identify image modality, body orientation, body region, and biological system examined based on the images. The results of the classification step can be used for multilingual image annotations as well as for DICOM header corrections. The images are annotated with the complete IRMA code, a multi-axial code for image annotation. However, for the task, we used only a flat classification scheme with a total of 116 classes. Figure <ref type="figure" coords="2,215.07,450.49,4.98,8.74">1</ref> shows that a great deal of intra-class variability exists, mostly in illumination changes, small amounts of position and scale differences, and noise. On the other hand, Figure <ref type="figure" coords="2,151.08,474.40,4.98,8.74" target="#fig_0">2</ref> shows that the inter-class distance can be quite tight, as the four frontal chest categories are at least pairwise very similar to each other. The confusion matrix between these four classes indicates that more than 80 % of the images were correctly classified. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Local Features Generation</head><p>We use features inspired from invariant features based on group integration. Let G be the transformation group for the transformations against which the invariance is desired. For the case of radiograph images this would be the group of translations. For rotation, only partial invariance is desired as most radiographs are scanned upright. If an element g ∈ G acting on the images, the transformed image is denoted by gM. An invariant feature must satisfy F (gM) = F (M), ∀g ∈ G. Such invariant features can be constructed by integrating f (gM) over the transformation group G <ref type="bibr" coords="3,101.15,225.95,9.97,8.74" target="#b1">[2]</ref>.</p><formula xml:id="formula_0" coords="3,243.53,252.47,115.57,17.23">I(M) = 1/|G| G f (gM)dg</formula><p>Although the above features are invariant, they are not particularly discriminative, due to the fact that the integration runs over the whole image, which contains large insignificant regions. An intuitive extension is to use local features, which have recieved good results in several image processing tasks. The idea is to first use a so-called interest point detector, to select pixels with high information content in their neighbourhood. The meaning of "high information" differs from application to application. There are, for example, detectors which select points of high gradient magnitude, or corner points (points with multiple gradient orientations). A desirable characteristic expected from an interest-point detector is that it is robust towards the above mentioned transformations. In this work, we use the wavelet-based salient point detector proposed by Loupias and Sebe <ref type="bibr" coords="3,184.01,383.03,9.96,8.74" target="#b2">[3]</ref>.</p><p>For each salient point s = (x, y), we extract relational feature subvector around it, given as:</p><formula xml:id="formula_1" coords="3,211.34,418.90,180.32,9.65">R k = [ (x, y, r 1 , r 2 , φ, n)] k , k = 1, . . . , n</formula><p>Then,</p><formula xml:id="formula_2" coords="3,90.00,460.71,341.67,69.46">R k = rel(I(x 2 , y 2 ) -I(x 1 , y 1 )), where (x 1 , y 1 ) = (x + r 1 cos(k • 2π/n), y + r 1 sin(k • 2π/n)), and (x 2 , y 2 ) = (x + r 2 cos(k • 2π/n + φ), y + r 2 sin(k • 2π/n + φ))</formula><p>with the rel operator defined as:</p><formula xml:id="formula_3" coords="3,227.71,557.81,285.29,34.61">rel (x) =    1 if x &lt; - -x 2 if -≤ x ≤ 0 if &lt; x ,<label>(1)</label></formula><p>The relational functions were first introduced for texture analysis by Schael <ref type="bibr" coords="3,438.91,601.71,9.97,8.74" target="#b3">[4]</ref>, motivated by the local binary patterns <ref type="bibr" coords="3,203.19,613.67,9.96,8.74" target="#b4">[5]</ref>. For each (r 1 , r 2 , φ) combination a local subvector is generated. In this work, we use 3 sets of parameters, (0, 5, 0), (3, 6, π/2) and (2, 3, π), each with n = 12 to capture local information at different scales and orientations. The subvectors are concatenated to give a local feature vector for each salient point. The local feature vectors of all images are taken together and clustered using the k-means clustering algorithm. The number of clusters would be denoted here by N c , and is determined emperically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Building Global Feature Vector</head><p>An equally important step is that of estimating similarity between two image objects, once local features have been calculated for both of them. For the case that one expects to find for a given test image, a training image of basically the same object, correspondence-based matching algorithms are called for, i.e. for each test local feature vector, the best training vector and its location is recalled (e.g. through nearest neighbour). The location information can be put to use by doing a consistency check if the constellation of salient points build a valid model for the given class.</p><p>However, the large intra-class variability displayed by the radiograph images suggest that a global feature based matching would perform better, as small number of non-correspondencies would not penalize the matching process heavily. We build the following accumulator features from the cluster index image I(s), i.e. an image which contains for each salient point, its assigned cluster index only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">All-Invariant Accumulator</head><p>The simplest histogram that can be built from a cluster index image is a 1-D accumulator counting the number of times a cluster occurred for a given image. All spatial information regarding the interest point is lost in the process. The feature can be mathematically written as:</p><formula xml:id="formula_4" coords="4,194.45,339.89,213.61,9.68">F(c) = #{s | (I(s) = c)}, c = 1, . . . , N c</formula><p>In our experiments, the crossvalidation results were never better than 60 %. It is clear that critical spatial information is being lost in the process of histogram construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Rotation Invariant Accumulator</head><p>We first incorporate spatial information, by counting pairs of salient points lying within a certain distance range, and possessing particular cluster indices, i.e. a 3-D accumulator defined by:</p><formula xml:id="formula_5" coords="4,163.69,451.64,275.62,24.63">F(c 1 , c 2 , d) = #{ (s 1 , s 2 ) | (I(s 1 ) = c 1 ) ∧ (I(s 2 ) = c 2 ) ∧ (D d &lt; ||s 1 -s 2 || 2 &lt; D d+1 ) }</formula><p>where the extra dimension d runs from 1 to N d (number of distance bins).</p><p>The crossvalidation results improve to about 68 %, but it should be noted that this accumulator is rotation invariant (depends only on distance between salient points), while the images are upright. Incorporating unnecessary invariance leads to a loss of discriminative performance. Especially in this task of radiograph classification it can be seen that mirroring the position of interest points leads to a completely another class, for example, a left hand becomes a right hand, and so on. Thus we incorporate orientation information in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Orientation Variant Accumulator</head><p>We discussed this method in detail in <ref type="bibr" coords="4,257.18,604.40,9.97,8.74" target="#b5">[6]</ref>. The following cooccurrence matrix captures the statistical properties of the joint distribution of cluster membership indices which were derived from local features.</p><formula xml:id="formula_6" coords="4,161.34,650.06,278.67,39.57">F(c 1 , c 2 , d, a) = #{ (s 1 , s 2 ) | (I(s 1 ) = c 1 ) ∧ (I(s 2 ) = c 2 ) ∧ (D d &lt; ||s 1 -s 2 || 2 &lt; D d+1 ) ∧ (A a &lt; (s 1 , s 2 ) &lt; A a+1 ) }</formula><p>with the new dimension a running from 1 to N a (number of angle bins).</p><p>The size of the matrix is</p><formula xml:id="formula_7" coords="4,212.35,713.72,83.16,9.65">N c × N c × N d × N a .</formula><p>For 20 clusters, 10 distance bins and 4 angle bins, this leads to a feature vector of size 16000. The classification is done with the help of a multi-class </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and Conclusion</head><p>We submitted two runs for the ImageCLEF medical annotation task. Both runs used the accumulator defined in Section 3.2.3 and were equally sized, with N c = 20, N d = 10 and N a = 4. The only difference was in the number of salient points, N s , selected per image. The first run used N s = 1000, while the second used N s = 800. For the given test set, the runs achieved an error rate of 16.7 % and 17.9 % respectively, which means that our best run was ranked second overall for the task. There might have been some room left for better parameter tuning, but it was not performed due to lack of resources, and because there are quite a few parameters to tune. Thus, instead of a joint optimization, each parameter was only individually selected through emperical methods.</p><p>Figure <ref type="figure" coords="6,137.66,301.76,4.98,8.74" target="#fig_1">3</ref> shows the nearest neighbour results (L 1 norm) for four sample query images. It can be seen that mostly the features are very suited for the task. Local features are in general robust against occlusion and partial matching, which is in general advantageous for a recognition task. This is also true for the radiograph annotation task described in this paper, but there are exceptions. For example, the top left box contains a chest radiograph, and the radiographs with complete frontal chest, and partial frontal chest apparently belong to different classes (class number 108 and 29 respectively). It might be beneficial to use region specific extra features, once it is determined that the radiograph is e.g. one that of chest.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,643.98,423.00,8.74;2,90.00,655.93,423.00,8.74;2,90.00,667.89,67.31,8.74;2,293.42,547.35,89.48,72.00"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: One example image each from class number 108, 109, 110 and 111 respectively. Some classes are hard to distinguish by the untrained eye, but surprisingly perform quite well by automatic methods.</figDesc><graphic coords="2,293.42,547.35,89.48,72.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,90.00,630.03,423.01,8.74;5,90.00,641.99,423.00,8.74;5,90.00,653.94,422.50,9.65;5,90.00,665.90,131.62,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Top 8 nearest neighbour results for different query radiographs. The top left image in each box is the query image, results follow from left to right, then top to bottom. The image caption contains the image name and label in (brackets). Finally the distance according to the L 1 norm is displayed underneath.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,105.24,727.04,207.83,6.99"><p>http://lmb.informatik.uni-freiburg.de/lmbsoft/libsvmtl/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,440.21,402.51,8.74;6,110.48,452.17,402.52,8.74;6,110.48,464.12,322.57,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,160.01,452.17,279.73,8.74">Quality of DICOM header information for image categorization</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Gueld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">B</forename><surname>Wein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bredno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,463.25,452.17,49.74,8.74">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2002-05">2002. May 2002</date>
			<biblScope unit="volume">4685</biblScope>
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,484.05,402.52,8.74;6,110.48,496.00,402.52,8.74;6,110.48,507.96,152.43,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,198.39,484.05,169.14,8.74">Invariant features for gray scale images</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schulz-Mirbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,210.78,496.00,171.89,8.74">DAGM -Symposium &quot;Mustererkennung</title>
		<title level="s" coord="6,110.48,507.96,105.71,8.74">Reihe Informatik aktuell</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Sagerer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Posch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Kummert</surname></persName>
		</editor>
		<meeting><address><addrLine>Bielefeld</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,527.88,345.95,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,220.94,527.88,205.62,8.74">Wavelet-based salient points for image retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loupias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,547.81,402.52,8.74;6,110.48,559.76,245.67,8.74" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schael</surname></persName>
		</author>
		<title level="m" coord="6,163.91,547.81,317.57,8.74">Methoden zur Konstruktion invarianter Merkmale für die Texturanalyse</title>
		<meeting><address><addrLine>Freiburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
		<respStmt>
			<orgName>Albert-Ludwigs-Universität</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,110.48,579.69,402.52,8.74;6,110.48,591.65,402.53,8.74;6,110.48,603.60,197.87,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,317.53,579.69,195.46,8.74;6,110.48,591.65,178.29,8.74">Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,309.67,591.65,203.33,8.74;6,110.48,603.60,26.62,8.74">Proc. Sixth European Conference on Computer Vision</title>
		<meeting>Sixth European Conference on Computer Vision<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="404" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,623.53,402.52,8.74;6,110.48,635.48,402.53,8.74;6,110.48,647.44,402.53,8.74;6,110.48,659.39,114.32,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,357.63,623.53,155.37,8.74;6,110.48,635.48,229.16,8.74">Image Classification using Cluster-Cooccurrence Matrices of Local Relational Features</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Setia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Teynor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halawani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Burkhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,359.33,635.48,153.68,8.74;6,110.48,647.44,305.25,8.74">Proceedings of the 8th ACM International Workshop on Multimedia Information Retrieval (MIR 2006)</title>
		<meeting>the 8th ACM International Workshop on Multimedia Information Retrieval (MIR 2006)<address><addrLine>Santa Barbara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">October 26-27, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
