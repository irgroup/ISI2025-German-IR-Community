<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,118.68,148.63,365.85,15.51;1,99.72,170.59,403.66,15.51;1,237.48,192.43,128.05,15.51">Combining global features within a nearest neighbor classifier for content-based retrieval of medical images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.92,225.93,57.08,9.96"><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.35,225.93,66.02,9.96"><forename type="first">Christian</forename><surname>Thies</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.03,225.93,72.07,9.96"><forename type="first">Benedikt</forename><surname>Fischer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.92,225.93,91.30,9.96"><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,118.68,148.63,365.85,15.51;1,99.72,170.59,403.66,15.51;1,237.48,192.43,128.05,15.51">Combining global features within a nearest neighbor classifier for content-based retrieval of medical images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B8509F69197B9563C161FE40CEDAA3A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Image texture features, Deformation model, Classifier combination</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A combination of several classifiers using global features for the content description of medical images is proposed. Beside two texture features, downscaled representations of the original images are used, which preserve spatial information and utilize distance measures which are robust regarding common variations in radiation dose, translation, and local deformation. No query refinement mechanisms are used. The single classifiers are used within a parallel combination scheme, with the optimization set being used to obtain the best weighing parameters. For the medical automatic annotation task, a categorization rate of 78.6% is obtained, which ranks 12th among 28 submissions. When applied in the medical retrieval task, this combination of classifiers yields a mean average precision (MAP) of 0.0172, which is rank 11 of 11 submitted runs for automatic, visual only systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF 2006 <ref type="bibr" coords="1,168.48,643.77,10.45,9.96" target="#b0">[1]</ref> consists of several challenges for content-based retrieval on medical images. <ref type="foot" coords="1,508.56,642.73,3.97,6.26" target="#foot_0">1</ref>A medical automatic annotation task poses a classification problem of mapping 1,000 query images with no additional textual information onto one of 116 pre-defined categories. The mapping is to be learned based on a ground truth of 9,000 categorized reference images. To optimize classifier settings, an additional set of 1,000 categorized images is available.</p><p>For the retrieval task, the reference set contains over 50,000 images. Here, 30 queries are given, which encompass 63 images. These tasks reflect the real-life constraints of content-based image retrieval in medical applications, as image corpora are large, heterogeneous and additional textual information about an image, especially its content, is not always reliable due to improper configuration of the imaging devices, ambiguous naming schemes, and both inter-and intraobserver variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Annotation Task</head><p>The annotation task consists of 10,000 reference images grouped into 116 categories and 1,000 images to be automatically categorized. The category definition is based solely on the aspects of 1. imaging modality, i.e. identification of the imaging device (three different device types) 2. imaging direction, i.e. relative position of the body part towards the imaging device 3. anatomy of the body part examined, and 4. biological system, which encodes certain contrast agents and a coarse description of the diagnostic motivation for the imaging.</p><p>Thus, the category definition does not incorporate any diagnosis information, e.g. the detection of pathologies or their quantitative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image Features and their Comparison</head><p>Based on earlier experiments conducted on a similar image set, four types of features and similarity measures are employed <ref type="bibr" coords="2,193.43,377.85,9.91,9.96" target="#b1">[2]</ref>.</p><p>Castelli et al. propose a combination texture features based on global fractal dimension, coarseness, gray-scale histogram entropy, spatial gray-level statistics and several circular Moran autocorrelation functions <ref type="bibr" coords="2,203.42,413.73,10.00,9.96" target="#b2">[3]</ref>. This results in 43 feature values per image. To compare a pair of these feature vectors, Mahalanobis distance with an estimated diagonal covariance matrix Σ is used:</p><formula xml:id="formula_0" coords="2,161.76,446.65,351.28,30.57">d Mahalanobis (q, r) = (q -r) T • Σ -1 • (q -r) simplified = 43 i=1 (q i -r i ) 2 σ 2 i (1)</formula><p>Tamura et al. proposed a set of texture features to capture global texture properties of an image, namely coarseness, contrast, and directionality <ref type="bibr" coords="2,330.37,494.01,9.99,9.96" target="#b3">[4]</ref>. This information is stored in a threedimensional histogram, which is quantized into M = 6 × 8 × 8 = 384 bins. To capture this texture information at a comparable scale, the extraction is performed on downscaled images of size 256×256, ignoring their aspect ratio. The query image q(x, y) and the reference image r(x, y) are compared by applying Jensen-Shannon divergence <ref type="bibr" coords="2,328.60,541.89,10.45,9.96" target="#b4">[5]</ref> to their histograms H(q) and H(r):</p><formula xml:id="formula_1" coords="2,132.72,561.86,380.32,30.33">d JSD (q, r) = 1 2 M m=1 H m (q) log 2H m (q) H m (q) + H m (r) + H m (r) log 2H m (r) H m (q) + H m (r)<label>(2)</label></formula><p>To retain spatial information about the image content, downscaled representations of the original images are used and the accompanying distance measures work directly on intensity values. It is therefore possible to incorporate a priori knowledge into the distance measure by modelling typical variability in the image data, which does not alter the category that the image belongs to. The cross-correlation function (CCF) from signal processing determines the maximum correlation between two 2D image representations, each one of size h × h:</p><formula xml:id="formula_2" coords="2,104.52,688.58,408.52,34.05">s CCF (q, r) = max |m|,|n|≤d h x=1 h y=1 (r(x -m, y -n) -r) • (q(x, y) -q) h x=1 h y=1 (r(x -m, y -n) -r) 2 h x=1 h y=1 (q(x, y) -q) 2<label>(3)</label></formula><p>Here, q(x, y) and r(x, y) refer to intensity values at a pixel position on the scaled representations of q and r, respectively. Note that s CCF is a similarity measure and the values lie between 0 and 1.</p><p>CCF includes robustness regarding two very common variabilites among the images: translation, which is explicitly tested within the search window of size 2d + 1, and radiation dose, which is normalized by subtracting the average intensity values q and r. For the experiments, downscaling to 32 × 32 pixels and a translation window of size d = 4 is used, i.e. translation can vary from -4 to +4 pixels in both the x-and the y-direction.</p><p>While s CCF considers only global displacements, i.e. translations of entire images, and variability in radiation dose, it is suggested to model local deformations of medical images caused by pathologies, implants and normal inter-patient variability. This can be done with an image distortion model (IDM) <ref type="bibr" coords="3,196.46,206.97,10.00,9.96" target="#b5">[6]</ref>:</p><formula xml:id="formula_3" coords="3,95.04,238.22,418.00,31.49">d IDM (q, r) = X x=1 Y y=1 min |x ′ |,|y ′ |≤W1 |x ′′ |,|y ′′ |≤W2 ||r(x+ x ′ + x ′′ , y + y ′ + y ′′ )-q(x+ x ′′ , y + y ′′ )|| 2 (4)</formula><p>Again, q(x, y) and r(x, y) refer to intensity values of the scaled representations. Note that each pixel of q must be mapped on some pixel in r, whereas not all pixels of r need to be the target of a mapping. Two parameters steer d IDM : W 1 defines the size of the neighborhood when searching for a corresponding pixel. To prevent a totally unordered pixel mapping, it is useful to incorporate the local neighborhood as context when evaluating a correspondence hypothesis. The size of the context information is controlled by W 2 . For the experiments, W 1 = 2, i.e. a 5 × 5 pixel search window, and W 2 = 1, i.e. a 3 × 3 context patch are used. Also, better results are obtained if the gradient images are used instead of the original images, because the correspondence search will then focus on contrast and be robust to global intensity differences due to radiation dose. It should be noted that this distance measure is computationally expensive as each window size influences the computation time in a quadratic manner. The images are scaled to a fixed height of 32 pixels and the original aspect ratio is preserved.</p><p>In all, each image is represented by approximately 1024+1024+384+43 values, or roughly 3 KB memory space, as the scaled representations require one byte per intensity, while the histograms are stored using floating-point numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Nearest-Neighbor Classifier</head><p>To obtain a decision q → c ∈ {1 . . . C} for a query image q, a nearest neighbor classifier evaluating k nearest neighbors according to a distance measure is used (k-NN). It simply votes for the category which accumulated the most votes among the k reference images closest to q. This classifier also allows easy visual feedback in interactive queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classifier Combination</head><p>Prior experiments showed that the performance of the single classifiers can be improved significantly if their single decisions are combined <ref type="bibr" coords="3,282.97,589.41,10.00,9.96" target="#b1">[2]</ref>. This is especially true for classifiers which model different aspects of the image content, such as the global texture properties with no spatial information and the scaled representations, which retain spatial information. The easiest way is a parallel combination scheme, since it can be performed as a post-processing step after the single classifier stage <ref type="bibr" coords="3,173.50,637.29,9.91,9.96" target="#b6">[7]</ref>. Also, no assumptions are required for the application, whereas serial or sieve-like combinations require an explicit construction.</p><p>For comparability, the single classifier distance values d(q, r i ), i = 1 . . . N are first normalized over all references r n , n = 1 . . . N :</p><formula xml:id="formula_4" coords="3,240.24,693.45,272.80,27.37">d ′ (q, r i ) = d(q, r i ) N n=1 d(q, r n )<label>(5)</label></formula><p>For a similarity measure s, d ′ (q, r) := 1s(q, r) is used and the normalization is performed afterwards. The new distance measure based on (normalized) distance measures d ′ m , m = 1 . . . M is obtained by weighted summation:</p><formula xml:id="formula_5" coords="4,179.16,132.62,333.88,30.33">d combined (q, r) = M m=1 λ m • d ′ m (q, r), λ ∈ [0; 1], M m=1 λ m = 1 (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training and Evaluation on the Reference Set</head><p>The optimization (or development) set of 1,000 images is used to estimate the weights λ Castelli , λ Tamura , λ CCF , and λ IDM . The corresponding matrices D Castelli = (d Mahalanobis (q i , r j )) ij , D Tamura = (d JSD (q i , r j )) ij , S CCF = (s CCF (q i , r j )) ij , and D IDM = (d IDM (q i , r j )) ij are only computed once for the single classifiers. Afterwards, all combination experiments can be performed efficiently by processing the matrices. The stepsize during the search for the best weight combination is 0.05. For comparison with the experiments from the ImageCLEF 2005 annotation task, a run with the weights used in <ref type="bibr" coords="4,159.84,268.41,10.57,9.96" target="#b7">[8]</ref> is also submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Retrieval Task</head><p>The retrieval task uses 50,024 images for reference and consists of 30 queries, which are given as a combination of text information and query images, with some queries specifying both positive and negative example images. While the image data for the annotation task only contains grayscale images from mostly x-ray modalities (plain radiography, fluoroscopy, and angiography), the image material in this task is much more heterogeneous: It also contains photographs, ultrasonic imaging and even scans of illustrations used for teaching. The retrieval task demands a higher level of image understanding, since several of the 30 queries directly refer to the diagnosis of medical images, which is often based on local image details, e.g. bone fractures or the detection of emphysema in computed tomography (CT) images of the lungs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image Features and their Comparison</head><p>The content representations described in the previous section only use grayscale information, i.e. color images are converted into grayscale by using color weighting recommended by ITU-R:</p><formula xml:id="formula_6" coords="4,222.60,496.77,290.44,23.52">Y = 6969 • R + 23434 • G + 2365 • B 32768<label>(7)</label></formula><p>In general, however, color is the single most important discriminate feature type on stock-house media and the image corpus used for the retrieval task contains many photographs, color scans of teaching material, and microscopic imaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summation Scheme for Queries Consisting of Multiple Images</head><p>Some of the queries do not consist of a single example image, but use several images as a query pool Q: positive and negative examples. For such queries, a simple summation scheme is used to obtain an overall distance:</p><formula xml:id="formula_7" coords="4,131.16,641.81,381.88,31.73">d(Q, r) = |Q| i=1 w i • d ′ (q i , r), Q = i {(q i , w i )}, w i = 1 : q i positive example -1 : q i negative example (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>All results are obtained non-interactively, i.e. without relevance feedback by a human user, and without using textual information for the retrieval task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotation Task</head><p>Table <ref type="table" coords="5,117.72,272.73,4.98,9.96" target="#tab_0">1</ref> shows the categorization rates obtained for the 1,000 unknown images using single classifiers and their combination, both for 1-NN and a 5-NN. The categorization rate of 78.6% ranks 12th among 28 submitted runs for this task. The weights used in the ImageCLEF 2005 medical automatic annotation task (10,000 images from 57 categories) yield a categorization rate of 78.3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Retrieval Task</head><p>Since no ground truth for the automatic optimization of the parameters is available, a run using the optimized weighing parameters from the annotation task is submitted. The run yields a mean average precision (MAP) of 0.0172 and is ranked 11th among 11 submitted runs in the "visual only, automatic" category of this task. For comparison, the best run submitted for this category yields 0.0753 MAP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>The weighing coefficients used for the medical automatic annotation task of ImageCLEF 2005 are also suitable for the 2006 task. The exhaustive search for the optimal weighing coefficients does not yield a combination which provides significantly better results. While results for the retrieval task are satisfactory in queries based on grayscale radiographs, other queries, especially from photograpy imaging, have rather poor results, partly due to the lack of color features employed. Furthermore, a detailed visual evaluation might result in better tuning of the weighing parameters. This was dropped due to time constraints and it is also unrealistic for real-life applications. Therefore, the results can be considered as a baseline for fully automated retrieval algorithms without feedback mechanisms for parameter tuning. Several queries from the retrieval task demand a high level of image content understanding, as they are aimed at diagnosis-related information, which is often derived from local details in the image. The methods used in this work to describe the image content either preserve no spatial information at all (texture features by Tamura) or capture it at very large scale, omitting local details important for diagnosis-relevant questions. Using only the image information, such queries cannot be processed with satisfactory quality of the results with a one-level approach. For a better query completion, subsequent image abstraction steps are required.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,96.00,118.77,421.62,104.22"><head>Table 1 :</head><label>1</label><figDesc>Categorization rates (in percent) for the medical automatic annotation task. Castelli =0.05, w Tamura =0.25, w CCF =0.25, w IDM =0.45</figDesc><table coords="5,96.00,140.13,100.22,9.96"><row><cell>Content representation</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,746.42,407.53,7.97"><p>This work is part of the IRMA project, which is funded by the German Research Foundation, grant Le 1108/4.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.48,690.21,407.64,9.96;5,100.56,702.21,412.39,9.96;5,100.56,714.21,22.93,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,368.42,690.21,144.70,9.96;5,100.56,702.21,189.69,9.96">Overview of the ImageCLEFmed 2006 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hersh</forename><forename type="middle">W</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
			<pubPlace>Alicante, Spain</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">CLEF working notes</note>
</biblStruct>

<biblStruct coords="5,105.48,733.05,407.78,9.96;5,100.56,744.93,412.74,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,460.92,733.05,52.34,9.96;5,100.56,744.93,232.05,9.96">Comparison of global features for categorization of medical images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Leisten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,340.21,744.93,77.93,9.96">Proceedings SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">5371</biblScope>
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,111.33,407.54,9.96;6,100.56,123.33,412.81,9.96;6,100.56,135.21,22.93,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,414.72,111.33,98.30,9.96;6,100.56,123.33,147.11,9.96">Progressive Search and Retrieval in Large Image Archives</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Kontoyiannis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Turek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,255.36,123.33,188.56,9.96">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="253" to="268" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,155.25,407.73,9.96;6,100.56,167.13,301.62,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,253.82,155.25,227.45,9.96">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,489.14,155.25,24.07,9.96;6,100.56,167.13,210.34,9.96">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="472" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,187.05,407.61,9.96;6,100.56,199.05,412.62,9.96;6,100.56,210.93,20.10,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,310.95,187.05,202.14,9.96;6,100.56,199.05,86.49,9.96">Empirical evaluation of dissimilarity measures for color and texture</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,193.94,199.05,249.35,9.96">Proceedings International Conference on Computer Vision</title>
		<meeting>International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.49,230.85,407.49,9.96;6,100.56,242.85,359.23,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,233.17,230.85,279.81,9.96;6,100.56,242.85,10.44,9.96">Classification of medical images using non-linear distortion models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,117.72,242.85,143.10,9.96">Bildverarbeitung für die Medizin</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.49,262.77,407.55,9.96;6,100.56,274.77,266.70,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,235.72,262.77,174.12,9.96">Statistical pattern recognition: A review</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rpw</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,417.24,262.77,95.79,9.96;6,100.56,274.77,184.93,9.96">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="36" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.49,294.69,407.49,9.96;6,100.56,306.57,243.64,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,310.34,294.69,202.63,9.96;6,100.56,306.57,118.03,9.96">Content-based Retrieval of Medical Images by Combining Global Features</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,226.22,306.57,26.42,9.96">LNCS</title>
		<imprint>
			<biblScope unit="volume">4022</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
