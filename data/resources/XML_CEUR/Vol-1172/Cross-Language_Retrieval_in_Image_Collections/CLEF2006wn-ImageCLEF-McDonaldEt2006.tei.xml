<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,340.02,148.86,124.50,15.15;1,133.56,170.78,335.88,15.15;1,158.07,192.69,286.85,15.15">at CLEF 2006: Experiments for the ImageCLEF Photo Collection Standard Ad Hoc Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,208.84,226.59,46.24,8.74"><forename type="first">Kieran</forename><surname>Mc</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,312.50,226.59,81.65,8.74"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<email>gareth.jones@computing.dcu.ie</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Dublin City University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Centre for Digital Video Processing</orgName>
								<orgName type="department" key="dep2">School of Computing Dublin</orgName>
								<orgName type="institution">City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,340.02,148.86,124.50,15.15;1,133.56,170.78,335.88,15.15;1,158.07,192.69,286.85,15.15">at CLEF 2006: Experiments for the ImageCLEF Photo Collection Standard Ad Hoc Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0D63E4395BDD83644E987307BE18A640</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Measurement</term>
					<term>Experimentation Cross Language Image Retrieval</term>
					<term>Photo Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We provide a technical description of our submission to the CLEF 2006 Cross Language Image Retrieval(ImageCLEF) Photo Collection Standard Ad Hoc task. We performed monolingual and cross language retrieval of photo images using photo annotations with and without feedback, and also a combined visual and text retrieval approach. Topics are translated into English using the Babelfish online machine translation system. Our text runs used the BM25 algorithm, while our visual approach used simple low-level features with matching based on the Jeffrey Divergence measure. Our results consistently indicate that the fusion of text and visual features is best for this task, and that performing feedback for text consistently improves on the baseline non-feedback BM25 text runs for all language pairs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dublin City University's participation in the CLEF 2006 ImageCLEF Photo Collection Ad Hoc task adopted standard text retrieval using image metadata and text search topics, with and without pseudo relevance feedback (PRF) and a combination of text retrieval with low-level visual feature matching. The underlying text retrieval system is based on a standard Okapi model for document ranking and PRF <ref type="bibr" coords="1,171.76,692.26,9.96,8.74" target="#b0">[1]</ref>. Experiments are reported for monolingual English and German retrieval and bilingual searching with a range of topic languages. Topics were translated for cross-language retrieval using the online Babelfish machine translation engine. Three sets of experiments are reported: the first establishes baseline text retrieval performance without PRF, the second explore the effectiveness of PRF for text retrieval with this task, and finally the third set combines text retrieval and visual feature matching.</p><p>The results of our experiments demonstrate that PRF improves on the baseline in all cases with respect to both average precision and the number of relevant documents retrieved. Combined text retrieval with visual feature matching gives a further improvement in both of these retrieval effectiveness measures in all cases.</p><p>This remainder of this paper is organised as follows: Section 2 briefly outlines the details of our standard retrieval system and describes our novel PRF method, Section 3 details our submitted runs, Section 4 gives results and analysis of our experiments, and finally Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The introduction of a new collection for the CLEF 2006 Ad Hoc Photo retrieval task meant that there was no previous retrieval test collection to use for system development and tuning for these documents. We thus used the previous ImageCLEF St Andrew's collection and related experiments on the TRECVID datasets to guide our selection of fusion methods and retrieval parameters for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text Retrieval</head><p>The contents of the structured annotation for each photo (TITLE, DESCRIPTION, NOTES, LOCATION and DATE fields) were collapsed into a flat document representation. Documents and search topics were processed to remove stopwords from the standard SMART list [2], and suffix stripped using the Snowball implementation of Porter stemming for the English language <ref type="bibr" coords="2,90.00,416.30,24.27,8.74">[3] [4]</ref>. While for the German language topics and documents were stopped and stemmed using the Snowball German stemmer and stopword list <ref type="bibr" coords="2,307.00,428.26,9.97,8.74" target="#b1">[3]</ref>.</p><p>Based on these development experiments, the text feature was matched using the BM25 algorithm with parameters: k1 = 1.0, k2 = 0, and b = 0.5. When using relevance feedback, the top 15 documents were assumed pseudo-relevant and the top scoring 10 expansion terms calculated using the Robertson selection value <ref type="bibr" coords="2,246.33,476.08,10.51,8.74" target="#b0">[1]</ref> were added to the original topic. The original query terms were upweighted by a factor of 3.5 compared to the feedback query expansion terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Retrieval</head><p>The visual features were matched using the Jeffrey Divergence (a.k.a. Jensen-Shannon distance) matching function <ref type="bibr" coords="2,175.66,546.27,10.52,8.74" target="#b3">[5,</ref><ref type="bibr" coords="2,191.09,546.27,7.01,8.74" target="#b4">6]</ref>. We can interpret Jeffrey Divergence as measuring the efficiency of assuming that a common source generated both distributions -the query and the document.</p><p>Three following visual features were used: HSV colour histogram with 16x4x4 quantisation levels on a 5x5 regional image grid, Canny 8 edge + 1 bin for non-edges feature for each region of a 5x5 regional image grid, and a DCT histogram feature based on the first 5 coefficients quantised each into 3 values for a 3x3 regional image grid. More details on these features can be found in <ref type="bibr" coords="2,90.00,618.00,9.97,8.74" target="#b5">[7]</ref>.</p><p>The results for the three visual features were combined using the weighted variant (i.e. linear interpolation) of the CombSUM fusion operator <ref type="bibr" coords="2,303.11,641.91,9.96,8.74" target="#b6">[8]</ref>. The scores for each feature were normalised between 0 and 1 and then the weighted sum was calculated for each document across the three features. The weights used for the colour, edge and DCT feature were respectively: 0.50, 0.30 and 0.20.</p><p>The results from the two visual examples for each topic were fused using the CombMAX fusion operator, which took the maximum of the normalised scores from each separate visual result list <ref type="bibr" coords="2,90.00,713.64,9.97,8.74" target="#b6">[8]</ref>. Scores were first normalised in the separate visual result sets for each topic image to lie between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Text and Visual Retrieval Result Combination</head><p>Text and visual runs were fused using the weighted CombSUM fusion operator with weights 0.70 and 0.30 for text and image respectively. Scores were again normalised to lie between 0 and 1 in the separate text and visual result sets before fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of runs submitted</head><p>We submitted two mono-lingual runs for German and English and cross language runs for both these languages. For English photo annotations we submitted runs where the queries were in Russian, Portuguese, Dutch, Japanese, Italian, French, Spanish, German, Chinese. While for German photo annotations we only ran cross language queries for French and English queries. The queries were translated to the respective document target language using the online Babelfish[9] system based on SysTran.</p><p>For each language pair including the monolingual runs we evaluated three different approaches: text only queries with no feedback and with feedback, and a combined visual and text (with text feedback) run. This gave us a total of 39 runs submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Summary of Experimental Results</head><p>Results for our runs are shown in Table <ref type="table" coords="3,259.06,359.49,4.98,8.74" target="#tab_0">1</ref> From the table we can see that our multilingual fused text and visual submission performed very well, achieving either the second or top rank of submissions for each language pair in terms of Mean Average Precision (MAP). Text feedback increased the text only results in terms of MAP by on average 16.0%. Fusion with visual results increased these results on average by a further 9.2%. Our experiments produced consistent evidence across language pairs that text feedback and fusion with visual features is beneficial in Image Photo search.</p><p>Our monolingual English runs with text feedback and fused visual results performed relatively poorly, achieving 8th of 50 submissions in terms of MAP. The increased competition in the more popular monolingual English category relative to the multilingual categories as well as our limited approach in tuning a single parameter selection for all our submitted runs probably accounts for the relative decrease in effectiveness of our approach in the English monolingual category. Our system parameters were tuned for multilingual topics and in future we should tune separately for the monolingual case. For monolingual searches we would expect the effectiveness of the initial query to be higher than in the multilingual case, and therefore both the appropriate feedback and fusion parameters for combining text and visual results may differ significantly compared to the multilingual case. In our case, the initial English monolingual text query under-performed, but was increased by 20.3% by the text feedback approach we employed. This result was further improved by only 4% through fusion with visual results. We suspect that the optimal parameters for BM25 may differ significant between the monolingual and multilingual cases.</p><p>Our results consistently show that our fused text and image retrieval submission outperforms our text-only methods. The average relative improvement in MAP was 9.2%, maximum was 18.9% and minimum was 4.0%. The evaluation measures Mean Average Precision, total relevant documents retrieved and precision at document cut-offs 10, 20, 30 are improved for all tested language pairs when the text results are fused with image results compared to text alone. This indicates that our fusion approach is stable and produces reliable results. We suspect that our fusion parameters were a bit conservative in the importance given to the visual results for this task. But on the other hand, if we increase the importance of visual results, we may sacrifice some of the stability and consistency of our results. This will be investigated in followup experiments.</p><p>Our results also consistently show that our text runs are improved for all language pairs tested when using text feedback compared to without it. This is true for all language pairs and evaluation measures in Table <ref type="table" coords="3,171.84,730.11,3.88,8.74" target="#tab_0">1</ref>, except for precision at a cut-off of 10 documents for English queries against German documents. The decrease in precision is small and insignificant in this case and goes  <ref type="bibr" coords="4,138.54,682.60,6.07,8.74">)</ref>. Each run's effectiveness is tabulated with the evaluation measures: Mean Average Precision (MAP), precision at document cut-offs 10 (P@10), 20 (P@20) and 30 (P@30), the number of relevant documents retrieved for each run (Rel. Ret) and the ranking of the results in terms of MAP compared to all other submitted runs to ImageCLEF Photo 2006 task for the respective language pair. The relative increase in MAP (%chg) between text with feedback and without, and between fused visual and text to text alone (i.e. text with feedback) is also listed for each run.</p><p>against the overwhelming trend established by our results. At an average relative increase in MAP of 16.0%, a maximum of 28.8% and a minimum of 9.9% for the language pairs, the importance of text feedback is well established for text-based photo search by our results.</p><p>The lack of relevant tuning data because of the significant difference between this year and previous years ImageCLEF photo content and descriptions may have led to a less than optimal choice of parameter for fusing visual and text results. Post-ImageCLEF experiments should be able to quantify the improvements that can be made with better tuning or alternative fusion strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Our results for the ImageCLEF 2006 photo retrieval task show that fusing text and visual results achieves better effectiveness than text alone. We also demonstrated that PRF is important for improving the effectiveness of the text retrieval model with consistent improvement in results across language pairs. Future experiments will investigate fusion of text and visual features more deeply, since we believe this still has more to offer than we have shown in our current experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,90.00,113.68,423.01,577.66"><head>Table 1 :</head><label>1</label><figDesc>Retrieval results for our submitted monolingual and multilingual runs for the ImageCLEF Photo 2006 task. Each run is labelled by its Query-Document language pair, whether it used text feedback (FB) and the mediums fused: text only (TXT) or text fused with image search (TXT+IMG</figDesc><table coords="4,105.77,113.68,391.47,519.94"><row><cell>Lang-Pair</cell><cell>FB</cell><cell>Media</cell><cell>MAP</cell><cell>%chg.</cell><cell>P@10</cell><cell>P@20</cell><cell>P@30</cell><cell>Rel. Ret.</cell><cell>Rank</cell></row><row><cell cols="3">Monolingual Runs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">EN-EN FB TXT+IMG .2234</cell><cell cols="2">4.0% .3067</cell><cell cols="2">.2792 .2628</cell><cell>2205</cell><cell>8/50</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.2148 20.3% .3050</cell><cell cols="2">.2733 .2467</cell><cell cols="2">2052 10/50</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1786</cell><cell>•</cell><cell>.2550</cell><cell cols="2">.2275 .2100</cell><cell cols="2">1806 21/50</cell></row><row><cell cols="4">DE-DE FB TXT+IMG .1728</cell><cell cols="2">7.4% .2283</cell><cell cols="2">.2425 .2328</cell><cell>1812</cell><cell>2/8</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1609 12.7% .2283</cell><cell cols="2">.2300 .2083</cell><cell>1478</cell><cell>3/8</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1428</cell><cell>•</cell><cell>.2283</cell><cell cols="2">.2050 .2017</cell><cell>1212</cell><cell>4/8</cell></row><row><cell cols="6">Multilingual Runs with German Documents</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">EN-DE FB TXT+IMG .1219 14.8% .1850</cell><cell cols="2">.1750 .1694</cell><cell>1553</cell><cell>1/5</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="5">.1062 18.9% .1400↓ .1358 .1272</cell><cell>1121</cell><cell>2/5</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.0893</cell><cell>•</cell><cell>.1450</cell><cell cols="2">.1317 .1211</cell><cell>814</cell><cell>4/5</cell></row><row><cell cols="6">FR-DE FB TXT+IMG .1037 18.9% .1517</cell><cell cols="2">.1467 .1461</cell><cell>1605</cell><cell>1/3</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.0872 28.8% .1317</cell><cell cols="2">.1225 .1167</cell><cell>1192</cell><cell>2/3</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.0677</cell><cell>•</cell><cell>.1150</cell><cell cols="2">.1083 .0994</cell><cell>898</cell><cell>3/3</cell></row><row><cell cols="6">Multilingual Runs with English Documents</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">CH-EN FB TXT+IMG .1614 10.6% .2267</cell><cell cols="2">.2042 .1939</cell><cell>1835</cell><cell>2/10</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1459 17.0% .2033</cell><cell cols="2">.1908 .1706</cell><cell>1574</cell><cell>3/10</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1247</cell><cell>•</cell><cell>.1783</cell><cell cols="2">.1650 .1606</cell><cell>1321</cell><cell>6/10</cell></row><row><cell cols="4">DE-EN FB TXT+IMG .1887</cell><cell cols="2">5.8% .2600</cell><cell cols="2">.2575 .2411</cell><cell>2014</cell><cell>1/8</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1783 10.5% .2450</cell><cell cols="2">.2342 .2117</cell><cell>1807</cell><cell>2/8</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1614</cell><cell>•</cell><cell>.2233</cell><cell cols="2">.2025 .1894</cell><cell>1642</cell><cell>3/8</cell></row><row><cell>ES-EN</cell><cell cols="3">FB TXT+IMG .2009</cell><cell cols="2">6.0% .2633</cell><cell cols="2">.2525 .2467</cell><cell>2118</cell><cell>2/6</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1895 17.6% .2583</cell><cell cols="2">.2367 .2117</cell><cell>1940</cell><cell>3/6</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1612</cell><cell>•</cell><cell>.2183</cell><cell cols="2">.2075 .1978</cell><cell>1719</cell><cell>4/6</cell></row><row><cell cols="4">FR-EN FB TXT+IMG .1958</cell><cell cols="2">6.5% .2483</cell><cell cols="2">.2558 .2489</cell><cell>2026</cell><cell>2/7</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1838 13.3% .2367</cell><cell cols="2">.2308 .2150</cell><cell>1806</cell><cell>3/7</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1622</cell><cell>•</cell><cell>.2167</cell><cell cols="2">.2250 .1972</cell><cell>1652</cell><cell>4/7</cell></row><row><cell>IT-EN</cell><cell cols="5">FB TXT+IMG .1720 12.8% .2167</cell><cell cols="2">.2200 .2150</cell><cell>2017</cell><cell>2/14</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1525 15.2% .2150</cell><cell cols="2">.1833 .1711</cell><cell>1780</cell><cell>3/14</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1324</cell><cell>•</cell><cell>.1917</cell><cell cols="2">.1650 .1556</cell><cell>1602</cell><cell>9/14</cell></row><row><cell>JP-EN</cell><cell cols="5">FB TXT+IMG .1615 10.7% .2267</cell><cell cols="2">.2042 .1939</cell><cell>1848</cell><cell>2/10</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1459 17.0% .2033</cell><cell cols="2">.1908 .1706</cell><cell>1591</cell><cell>3/10</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1247</cell><cell>•</cell><cell>.1783</cell><cell cols="2">.1650 .1606</cell><cell>1321</cell><cell>8/10</cell></row><row><cell cols="4">NL-EN FB TXT+IMG .1842</cell><cell cols="2">6.7% .2467</cell><cell cols="2">.2342 .2194</cell><cell>1906</cell><cell>1/3</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1726 12.5% .2150</cell><cell cols="2">.2042 .1900</cell><cell>1665</cell><cell>2/3</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1534</cell><cell>•</cell><cell>.1817</cell><cell cols="2">.1775 .1706</cell><cell>1477</cell><cell>3/3</cell></row><row><cell cols="4">PT-EN FB TXT+IMG .1990</cell><cell cols="2">7.8% .2683</cell><cell cols="2">.2625 .2478</cell><cell>2032</cell><cell>2/6</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell cols="3">.1846 13.8% .2683</cell><cell cols="2">.2525 .2228</cell><cell>1824</cell><cell>3/6</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1622</cell><cell>•</cell><cell>.2483</cell><cell cols="2">.2217 .1956</cell><cell>1642</cell><cell>5/6</cell></row><row><cell cols="4">RU-EN FB TXT+IMG .1816</cell><cell cols="2">7.3% .2600</cell><cell cols="2">.2400 .2156</cell><cell>1982</cell><cell>2/8</cell></row><row><cell></cell><cell>FB</cell><cell>TXT</cell><cell>.1693</cell><cell cols="2">9.9% .2500</cell><cell cols="2">.2158 .1911</cell><cell>1760</cell><cell>3/8</cell></row><row><cell></cell><cell>•</cell><cell>TXT</cell><cell>.1541</cell><cell>•</cell><cell>.2333</cell><cell cols="2">.1867 .1694</cell><cell>1609</cell><cell>6/8</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,353.06,407.50,8.74;5,105.50,365.02,407.50,8.74;5,105.50,376.97,169.70,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,487.26,353.06,25.73,8.74;5,105.50,365.02,47.29,8.74">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,277.81,365.02,235.19,8.74;5,105.50,376.97,42.07,8.74">Proceedings of the Third Text REtrieval Conference (TREC-3)</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Third Text REtrieval Conference (TREC-3)</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,416.82,225.81,9.02" xml:id="b1">
	<monogr>
		<ptr target="http://snowball.tartarus.org/" />
		<title level="m" coord="5,105.50,416.82,70.82,8.74">Snowball toolkit</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,436.75,326.17,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,171.96,436.75,140.77,8.74">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,321.31,436.75,36.54,8.74">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="10" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,456.67,407.50,8.74;5,105.50,468.63,217.52,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,157.64,456.67,308.73,8.74">Diversity: Its measurement, decomposition, apportionment and analysis</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,473.15,456.67,39.85,8.74;5,105.50,468.63,138.09,8.74">Sankyha: The Indian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">A</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,488.55,407.51,8.74;5,105.50,500.51,121.24,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,139.93,488.55,217.95,8.74">Divergence measures based on the Shannon entropy</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,364.79,488.55,148.22,8.74;5,105.50,500.51,28.49,8.74">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,520.43,407.50,8.74;5,105.50,532.39,72.59,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,178.63,520.43,206.26,8.74">Discrete Language Models for Video Retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Dublin City University</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="5,105.50,552.31,407.50,8.74;5,105.50,564.27,223.67,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,226.59,552.31,144.86,8.74">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,379.48,552.31,133.52,8.74;5,105.50,564.27,153.16,8.74">Proceedings of the Third Text REtrieval Conference (TREC-1994)</title>
		<meeting>the Third Text REtrieval Conference (TREC-1994)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
