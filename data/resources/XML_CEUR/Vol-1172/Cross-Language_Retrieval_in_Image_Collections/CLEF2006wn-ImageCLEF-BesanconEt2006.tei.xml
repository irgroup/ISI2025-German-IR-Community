<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,95.28,98.63,412.61,15.51;1,161.64,120.59,279.87,15.51">Using Text and Image Retrieval Systems: Lic2m experiments at ImageCLEF 2006</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,219.60,153.97,79.01,9.96"><forename type="first">Romaric</forename><surname>Besan√ßon</surname></persName>
							<email>besanconr@zoe.cea.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CEA-LIST</orgName>
								<address>
									<addrLine>LIC2M ; BP 6</addrLine>
									<postCode>92265</postCode>
									<settlement>Fontenay-aux-Roses CEDEX</settlement>
									<country key="FR">FRANCE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.59,153.97,76.73,9.96"><forename type="first">Christophe</forename><surname>Millet</surname></persName>
							<email>milletc@zoe.cea.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CEA-LIST</orgName>
								<address>
									<addrLine>LIC2M ; BP 6</addrLine>
									<postCode>92265</postCode>
									<settlement>Fontenay-aux-Roses CEDEX</settlement>
									<country key="FR">FRANCE</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,95.28,98.63,412.61,15.51;1,161.64,120.59,279.87,15.51">Using Text and Image Retrieval Systems: Lic2m experiments at ImageCLEF 2006</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7E855A0E7CC64D6C981042CA9A20A078</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>I.4.7 [Computing Methodologies]: Image Processing and Computer Vision-Feature Measurement Measurement, Performance, Experimentation Linguistic Processing, Cross-lingual Text Retrieval, Content Based Image Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the ImageCLEF 2006 campaign, the LIC2M participated in the imageclefphoto ad hoc task. We perform experiments on merging the results of two independent search systems: a cross-language information retrieval system exploiting the text part of the query and a content-based image retrieval system exploiting the example images given with the query. The merging is performed a posteriori using a weighted sum of the scores given by each system. This kind of merging can improve the results, but gain in the submitted runs remains quite small, comparatively to our experiments of last campaigns. This is due to the relatively poor results of the CBIR part. A first analysis give some hints on possible improvements: example images are often chosen to be visually different to show several aspects of possible relevant images for the chosen topic, therefore the merge of CBIR results for each example image can be irrelevant. However, using only one example image (provided we can choose the best one), or using CBIR results for each example image, but only in correspondence with text results can improve the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CEA-LIST/LIC2M laboratory participated in ImageCLEF 2006 to perform experiments on merging strategies to integrate the results obtained from the cross-language text retrieval system and the content-based image retrieval (CBIR) system that are developed in our lab, using a simple merging strategy similar to the one used in previous ImageCLEF campaigns <ref type="bibr" coords="1,426.24,657.61,9.91,9.96" target="#b0">[1]</ref>.</p><p>We use text and visual information from the queries: the title provided for the text retrieval system, and the example images for the CBIR system. Both systems are general-domain systems and are used independently on each part of the query. Then, a posteriori merging strategies are applied on the results provided by each system.</p><p>We present in section 2 the retrieval systems for text and image and the merging strategies used. We present the results obtained in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval systems</head><p>Both text retrieval system and CBIR systems are the same that were used in previous ImageCLEF campaigns <ref type="bibr" coords="2,138.72,163.93,10.00,9.96" target="#b0">[1]</ref>. The basic principles of the systems are presented here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multilingual Text Retrieval System</head><p>The multilingual text retrieval system has not been specially adapted to work on the text of the ImageCLEF corpora, and has simply been used as is: no special treatment has been performed to take into account the structure of the documents (such as title, description, location,date): all fields containing some text have been taken as is. The system works as follows:</p><p>Document and query processing The documents and queries are processed through a linguistic analyzer, that extracts relevant linguistic elements such as lemmas, named entities and compounds. The elements extracted from the documents are indexed into inverted files. The elements extracted from the queries are used as query "concepts". Each concept is reformulated into a set of search terms for each target language (in the case of imageClefPhoto, only one target language was used) either using a monolingual expansion dictionary (that introduces synonyms and related words), or using a bilingual dictionary. Document Retrieval Each search term is searched in the index, and documents containing the term are retrieved. All retrieved documents are then associated with a concept profile, indicating the presence of query concepts in the document. This concept profile depends on the query concepts, and is language-independent (which allow merging results from different languages). Documents sharing the same concept profile are clustered together, and a weight is associated with each cluster according to its concept profile and to the weight of the concepts (the weight of a concept depends on the weight of each of its reformulated term in the retrieved documents). The clusters are sorted according to their weights and the first 1000 documents in this sorted list are retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Content-based Image Retrieval System</head><p>The content-based image retrieval system we used in ImageCLEF 2006 is the system PIRIA (Program for the Indexing and Research of Images by Affinity) <ref type="bibr" coords="2,373.05,523.45,11.54,9.96" target="#b2">[3]</ref>, developed in our lab. The query image is submitted to the system, which returns a list of images ranked by their similarity to the query image. The similarity is obtained by a metric distance that operates on every image signatures. These indexed images are compared according to several classifiers : principally Color, Texture and Form if the segmentation of the images is relevant. The system takes into account geometric transformations and variations like rotation, symmetry, mirroring, etc. PIRIA is a global one-pass system, feedback or "relevant/non relevant" learning methods are not used.</p><p>Color Indexing This indexer first quantifies the image, and then, for each quantified color, it computes how much this color is connex. It can also be described as a border/interior pixel classification <ref type="bibr" coords="2,148.20,645.01,10.00,9.96" target="#b4">[5]</ref>. The distance used for the color indexing is a classical L2 norm.</p><p>Texture Indexing A global texture histogram is used for the texture analysis. The histogram is computed from the Local Edge Pattern descriptors <ref type="bibr" coords="3,333.37,73.33,9.91,9.96" target="#b1">[2]</ref>. These descriptors describe the local structure according to the edge image computed with a Sobel filtering. We obtain a 512-bins texture histogram, which is associated with a 64-bins color histogram where each plane of the RGB color space is quantized into 4 colors. Distances are computed with a L1 norm.</p><p>Form Indexing The form indexer used consists of a projection of the edge image along its horizontal and vertical axes. The image is first resized in 100x100. Then, the Sobel edge image is computed and divided into four equal sized squares (up left, up right, bottom left and bottom right). Then, each 50x50 part is projected along its vertical and horizontal axes, thus giving a 400-bins histogram. The L2 distance is used to compare two histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Search and Merging Strategy</head><p>Both systems are used independently to retrieve documents from textual and visual information. For the CBIR results, since queries contain several images, a first merging has been performed to obtain a single image list from the results of each query image: the score associated to result images is set to the max of the scores obtained for each query image.</p><p>Results obtained by each system are then merged using a weighted sum of the scores obtained by each system. To make results from the different systems comparable, we tried several normalization functions, presented in Table <ref type="table" coords="3,217.10,300.85,3.90,9.96">1</ref>, where Œ± i is the weight associated with the scores of the i th system, RSV max is the the highest score obtained for a query, RSV min the lowest score, RSV avg the average score and RSV Œ¥ the standard deviation of the scores. These functions have for instance been tested by <ref type="bibr" coords="3,103.45,336.73,10.57,9.96" target="#b3">[4]</ref> for data fusion in the multilingual tracks of previous CLEF campaigns. The submitted runs used the normRSV merging function.</p><formula xml:id="formula_0" coords="3,128.16,371.41,346.69,46.21">sumRSV Œ± i * RSV i normRSVMax Œ± i * RSV i /RSV max normRSV Œ± i * (RSV i -RSV min )/(RSV max -RSV min ) Zscore Œ± i * [(RSV -RSV avg )/RSV Œ¥ + (RSV avg -RSV min )/RSV Œ¥ ]</formula><p>Table <ref type="table" coords="3,226.44,429.13,3.90,9.96">1</ref>: Different weightings for score merging</p><p>Based on the results from the previous campaigns, we also considered a conservative merging strategy: we use the results obtained by one system only to reorder the results obtained by the other, the score of a document is modified using the same merging coefficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results for the ImageClefPhoto task</head><p>We used, for the text retrieval part, textual queries in English, Spanish, French and German. We used English and German as independent target languages (as the annotations in both languages refer to the same images and form more an aligned corpus, it did not seem interesting to use both languages as a single multilingual corpus). We only submitted runs with the English target language. For the CBIR system, we tested the color and texture indexers.</p><p>We present in Table <ref type="table" coords="3,199.20,591.49,4.98,9.96" target="#tab_0">2</ref> the results obtained by the CBIR system alone and the text system alone.</p><p>We present in Table <ref type="table" coords="3,193.08,615.37,4.98,9.96" target="#tab_1">3</ref> the results obtained by the merging of the two systems, with a normRSV merging schema, and for different values of Œ± (Œ± being the weight associated with the text results, 1-Œ± to the image results). In this merging, we used the English topics with the English annotations and the color indexer. The runs submitted for merged results used Œ± = 0.7.</p><p>Results are given for the mean average precision (map) and the number of relevant documents retrieved (relret Comparative results for the CBIR system and the image system alone and the text system alone</p><p>We see from these results that this simple a-posteriori merging of text and image results based on a weighted sum of the scores can increase the mean average precision and number of relevant documents retrieved (best value of Œ± is around 0.9 or 0.8 However, the gain is still small, due to the fact that CBIR results are surprisingly quite poor. On one hand, we are investigating in more details the flaws of the indexers for this new image corpus. On the other hand, a first analysis of the results show that merging the CBIR results for the example images before merging with the text results is not a good idea: when several example images are given, they can provide different aspects of what the results should look like, and therefore can be as different as possible, in the range of relevant images. The merging of results base on purely visual similarity can be irrelevant in this case. The analysis of the CBIR results show that the rate of common images in the results for the different example images of a same topic does not exceed, in average, 16 to 18%. Table <ref type="table" coords="4,355.90,449.17,4.98,9.96" target="#tab_2">4</ref> present the results obtained using only one example image for each topic. The best example image has been taken (according to the reference), and the gain on mean average precision in this case is more than 11%. The problem still remains to find the best image example (in our results, the average precision obtained for each image example does not correlate well with the average score given by the CBIR system). Another solution to this problem can be to consider each result of an example image as an independent result, and merge all results according to the same schema. In this case, the weight associated to the text result is Œ± and the weight associated to each CBIR result is Œ±/n where n is the number of example images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The experiments performed by the LIC2M in the ImageCLEF 2006 campaign show that merging results from different media may increase the performance of a search system: a well-tuned a posteriori merging of the results obtained by two general purpose systems (no particular adaptation of the systems was made for the two tasks) can improve the mean average precision. An analysis of the CBIR results show that merging the results obtained for different example images can increase the noise in global results since example images are often chosen to be visually different to show several aspects of possible relevant images. Some solutions are proposed to cope with this aspect, such as taking only one example image (the best), or using all example image, but merging each with text results (not between them). Both solutions lead to better results in term of mean average precision.</p><p>More sophisticated solutions could be considered, such as working on the image analysis to try to determinate the similarities of the example images and find similar images in the collection based on these similarities, instead of considering each example image independently.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,158.76,675.13,6.61,9.96"><head>Table 2 :</head><label>2</label><figDesc>).</figDesc><table coords="4,98.64,59.77,405.73,69.72"><row><cell cols="2">CBIR results</cell><cell></cell><cell cols="3">text results for English</cell><cell cols="3">text results for German</cell></row><row><cell>indexer</cell><cell>map</cell><cell>relret</cell><cell>topics</cell><cell>map</cell><cell>relret</cell><cell>topics</cell><cell>map</cell><cell>relret</cell></row><row><cell>color</cell><cell cols="2">0.0468 961</cell><cell>eng</cell><cell cols="2">0.1427 1835</cell><cell>eng</cell><cell cols="2">0.0916 1445</cell></row><row><cell cols="2">texture 0.0363</cell><cell>887</cell><cell>spa</cell><cell>0.1416</cell><cell>1427</cell><cell>spa</cell><cell>0.127</cell><cell>1394</cell></row><row><cell></cell><cell></cell><cell></cell><cell>fre</cell><cell>0.1031</cell><cell>1380</cell><cell>fre</cell><cell>0.117</cell><cell>1302</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ger</cell><cell>0.1009</cell><cell>1067</cell><cell>ger</cell><cell>0.145</cell><cell>1381</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,135.84,204.49,331.51,136.80"><head>Table 3 :</head><label>3</label><figDesc>). Comparative results for Œ± in merging strategies</figDesc><table coords="4,135.84,226.09,331.51,93.72"><row><cell></cell><cell>eng</cell><cell></cell><cell></cell><cell>fre</cell><cell cols="2">spa</cell><cell>spa</cell><cell></cell></row><row><cell>Œ±</cell><cell>map</cell><cell>relret</cell><cell>map</cell><cell>relret</cell><cell>map</cell><cell>relret</cell><cell>map</cell><cell>relret</cell></row><row><cell>1</cell><cell>0.1427</cell><cell>1835</cell><cell>0.1031</cell><cell>1380</cell><cell>0.1416</cell><cell>1427</cell><cell>0.1009</cell><cell>1067</cell></row><row><cell cols="3">0.9 0.146 1951</cell><cell>0.108</cell><cell>1536</cell><cell>0.144</cell><cell>1702</cell><cell>0.0969</cell><cell>1397</cell></row><row><cell cols="2">0.8 0.146</cell><cell>1927</cell><cell cols="2">0.112 1545</cell><cell>0.14</cell><cell>1714</cell><cell>0.097</cell><cell>1399</cell></row><row><cell cols="2">0.7 0.14</cell><cell>1864</cell><cell>0.109</cell><cell>1536</cell><cell>0.136</cell><cell>1713</cell><cell>0.0978</cell><cell>1399</cell></row><row><cell cols="2">0.6 0.128</cell><cell>1807</cell><cell>0.105</cell><cell>1533</cell><cell>0.129</cell><cell>1715</cell><cell>0.0948</cell><cell>1399</cell></row><row><cell cols="2">0.5 0.112</cell><cell>1750</cell><cell>0.1</cell><cell>1499</cell><cell>0.125</cell><cell>1707</cell><cell>0.0906</cell><cell>1400</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,164.04,518.65,275.02,104.28"><head>Table 4 :</head><label>4</label><figDesc>Results merging text results with each image example</figDesc><table coords="4,257.64,518.65,87.90,82.44"><row><cell></cell><cell>eng</cell><cell></cell></row><row><cell>Œ±</cell><cell>map</cell><cell>relret</cell></row><row><cell>1</cell><cell>0.1427</cell><cell>1835</cell></row><row><cell cols="2">0.9 0.151</cell><cell>1974</cell></row><row><cell cols="2">0.8 0.156</cell><cell>1955</cell></row><row><cell cols="2">0.7 0.159</cell><cell>1914</cell></row><row><cell cols="2">0.6 0.156</cell><cell>1887</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,90.00,671.05,423.15,33.84"><head>Table 5 :</head><label>5</label><figDesc>Table 5 present the results obtained with this method. The gain in this case is around 8%, but this method does not need to determine a priori the best example image. Results merging text results with all image example</figDesc><table coords="5,257.64,59.77,87.90,82.44"><row><cell></cell><cell>eng</cell><cell></cell></row><row><cell>Œ±</cell><cell>map</cell><cell>relret</cell></row><row><cell>1</cell><cell>0.1427</cell><cell>1835</cell></row><row><cell cols="2">0.9 0.149</cell><cell>1990</cell></row><row><cell cols="2">0.8 0.153</cell><cell>1962</cell></row><row><cell cols="2">0.7 0.154</cell><cell>1915</cell></row><row><cell cols="2">0.6 0.149</cell><cell>1851</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.48,405.97,407.47,9.96;5,105.48,417.97,407.67,9.96;5,105.48,429.97,407.50,9.96;5,105.48,441.85,407.43,9.96;5,105.48,453.85,207.51,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,295.57,405.97,217.38,9.96;5,105.48,417.97,161.14,9.96">Data fusion of retrieval results from different media: experiments at ImageCLEF 2005</title>
		<author>
			<persName coords=""><forename type="first">Romaric</forename><surname>Besan√ßon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Millet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,129.36,442.19,383.55,9.18;5,105.48,454.19,76.40,9.18">Accessing Multilingual Information Repositories: 6th Workshop of the Cross-Language Evaluation Forum</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maarten</forename><surname>M√ºller</surname></persName>
		</editor>
		<editor>
			<persName><surname>De Rijke</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,473.77,407.78,9.96;5,105.48,485.77,235.45,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,279.28,473.77,229.80,9.96">Image classification using color, texture and regions</title>
		<author>
			<persName coords=""><forename type="first">Ya-Chun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shu-Yuan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,105.48,486.11,126.04,9.18">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2003-09">September 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,505.69,407.53,9.96;5,105.48,517.57,407.28,9.96;5,105.48,529.57,178.13,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,411.24,505.69,101.77,9.96;5,105.48,517.57,243.49,9.96">PIRIA : A general tool for indexing, search and retrieval of multimedia content</title>
		<author>
			<persName coords=""><forename type="first">Magali</forename><surname>Joint</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre-Alain</forename><surname>Mo√´llic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>H√®de</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pascal</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,371.51,517.91,136.66,9.18">SPIE Electroning Imaging 2004</title>
		<meeting><address><addrLine>San Jose, California USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-01">January 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,549.49,407.62,9.96;5,105.48,561.49,407.40,9.96;5,105.48,573.37,218.31,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,279.24,549.49,233.85,9.96;5,105.48,561.49,208.25,9.96">Report on CLEF-2005 evaluation campaign: monolingual, bilingual, and GIRT information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre-Yves</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,430.80,561.83,82.09,9.18;5,105.48,573.71,111.33,9.18">Working Notes for the CLEF 2005 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,593.29,407.54,9.96;5,105.48,605.29,407.50,9.96;5,105.48,617.63,407.53,9.18;5,105.48,629.17,131.67,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,410.87,593.29,102.15,9.96;5,105.48,605.29,307.67,9.96">A compact and efficient image retrieval approach based on border/interior pixel classification</title>
		<author>
			<persName coords=""><forename type="first">Renato</forename><forename type="middle">O</forename><surname>Stehling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mario</forename><forename type="middle">A</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><forename type="middle">X</forename><surname>Falc√£o</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,438.48,605.63,74.50,9.18;5,105.48,617.63,402.30,9.18">CIKM &apos;02: Proceedings of the eleventh international conference on Information and knowledge management</title>
		<meeting><address><addrLine>McLean, Virginia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
