<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.40,148.86,280.19,15.15;1,228.51,170.78,145.98,15.15">A Naïve Bag-of-Words Approach to Wikipedia QA</title>
				<funder ref="#_d6FuVrn">
					<orgName type="full">ICT EU-India</orgName>
				</funder>
				<funder ref="#_XcVsuKe">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-08-18">August 18, 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,228.50,204.67,70.63,8.74"><forename type="first">Davide</forename><surname>Buscaldi</surname></persName>
							<email>dbuscaldi@dsic.upv.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">de Sistemas Informticos y Computación (DSIC)</orgName>
								<orgName type="institution">Universidad Politcnica de Valencia</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.81,204.67,52.69,8.74"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">de Sistemas Informticos y Computación (DSIC)</orgName>
								<orgName type="institution">Universidad Politcnica de Valencia</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.40,148.86,280.19,15.15;1,228.51,170.78,145.98,15.15">A Naïve Bag-of-Words Approach to Wikipedia QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-08-18">August 18, 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">10213C593F24F58696E80DBCE4159B89</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Algorithms, Experimentation Question Answering, Wikipedia</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a simple approach to the Wikipedia Question Answering pilot task in CLEF 2006. The approach ranks the snippets, retrieved using the Lucene search engine, by means of a similarity measure based on bags of words extracted from both the snippets and the articles in wikipedia. Our participation was in the monolingual English and Spanish tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering (QA) based on Wikipedia (WiQA) is a novel task, proposed as a pilot task in CLEF 2006. Wikipedia recently caught the attention of various researchers <ref type="bibr" coords="1,432.31,587.64,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,446.08,587.64,7.75,8.74" target="#b0">1]</ref> as a resource for the QA task, in particular for the direct extraction of answers. WiQA is a quite different task, since it is aimed at helping the readers/authors of Wikipedia rather than finding answers to user questions. In the words of the organizers 1 , the purpose of the WiQA pilot is "to see how IR and NLP techniques can be effectively used to help readers and authors of Wikipages get access to information spread thoughout Wikipedia rather than stored locally on the pages". An author of a given Wikipage can be interested in collecting information about the topic of the page that is not yet included in the text, but is relevant and important for the topic, so that it can be used to update the content of the Wikipage. Therefore, an automatic system will provide the author with information snippets extracted from Wikipedia with the following characteristics:</p><p>• unseen: not already included in the given source page;</p><p>1 http://ilps.science.uva.nl/WiQA/Task/index.html</p><p>• new : providing new information (not outdated);</p><p>• relevant: worth the inclusion in the source page.</p><p>In our previous work, we analyzed the link between Wikipedia and the Question Answering task from another point of view: using Wikipedia in order to help finding answers <ref type="bibr" coords="2,454.05,163.83,9.96,8.74" target="#b1">[2]</ref>. Although the task is completely different from the WiQA, we achieved some experience in extracting useful informations from Wikipedia by means of a standard textual search engine such as Lucene <ref type="foot" coords="2,485.49,186.16,3.97,6.12" target="#foot_0">2</ref> .</p><p>In this paper we describe the system we developed for the WiQA pilot task, that is mostly based on the Lucene search engine and our previous experience in mining knowledge from Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>In Figure <ref type="figure" coords="2,133.01,266.41,4.98,8.74">1</ref> we show the architecture of our system. A WiQA topic (i.e., a title of a source page to Figure <ref type="figure" coords="2,235.76,544.88,3.88,8.74">1</ref>: Architecture of our WiQA system. be expanded) is passed as a phrase (e.g. "Patriarch of Alexandria") to the Lucene search module, which performs a standard search over the previously indexed collection of Wikipedia articles (the collections are the English and Spanish versions of the Ludovic Denoyer's Wikipedia XML corpora <ref type="bibr" coords="2,125.56,614.06,10.30,8.74" target="#b2">[3]</ref>). Lucene returns a set of snippets ranked accordingly to the usual tf •idf weighting.The snippets at this points include those belonging to the source page, which are removed from the result set. Subsequently, the ranking module rearranges the snippets in the optimal ranking, that is the final result. The following section describes how the ranking is done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bag-of-Words Ranking</head><p>In our previous works on Wikipedia and QA we attempted to emulate a human use of Wikipedia by means of simple Lucene queries based on pages' titles. The WiQA task presents almost the same characteristics, every topics being itself a page title. Our approach is straightforward and needs only to pass to Lucene a phrase query containing the source page title.</p><p>The user behaviors emulated by our system are the following:</p><p>1. The user searches for pages containing the title of the page he is willing to expand;</p><p>2. The user analyzes the snippets, discarding the ones being too similar to the source page.</p><p>In the first case, passing the title as phrase to Lucene is enough for most topics. We observed that some topics needed a better analysis of title contents, such as the 7th of the English monolingual test set:"Minister of Health (Canada)", however these cases were not so many with respect to the total number of topics.</p><p>In the second case, the notion of similarity between a snippet and a page is the key for obtaining unseen (and relevant) snippets. Note that we decided to bound together relevance and the fact of not being already present in the page; we did not implement any method in order to determine whether the snippets contain outdated informations or not. In our system, the similarity between a snippet and the page is calculated by taking into account the number of terms they share. Therefore, we define the similarity f sim (p, s) between a page p and a snippet s as:</p><formula xml:id="formula_0" coords="3,260.08,324.22,252.92,22.31">f sim (p, s) = |p ∩ s| |s|<label>(1)</label></formula><p>Where |p ∩ s| is the number of terms contained in both p and s, and |s| is the number of terms contained in the snippet. This measure is used to rearrange the ranking of snippets by penalizing those being too similar to the source page. If w l is the standard tf • idf weight returned by Lucene, then the final weight w of the snippet s with respect to page p is:</p><formula xml:id="formula_1" coords="3,238.64,416.50,274.36,9.65">w(s, p) = w l • (1 -f sim (p, s))<label>(2)</label></formula><p>The snippets are then ranked according to the values of w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The obtained results are shown in Table <ref type="table" coords="3,265.77,493.19,3.88,8.74" target="#tab_0">1</ref>. The most important measure is the average yield, that is, the average number of "good" snippets per topic among top 10 snippets returned. The best average yield of the systems participating to the task was up to 3.4 for the English monolingual subtask. The Average yield is calculated as the total number of important novel non-repeated </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Further Work</head><p>The results obtained in Spanish were worse than those obtained in English. We suppose this is due to the smaller size of the Spanish Wiki (117MB in contrast to 939MB): information is spread over a smaller number of pages, reducing the chance of obtaining valuable snippets. Our next steps in the WiQA task will be the inclusion of a similarity distance based on n-grams, resembling the one we already used for the JIRS Passage Retrieval engine <ref type="bibr" coords="4,372.79,135.93,9.97,8.74" target="#b3">[4]</ref>. We also hope to be able to participate in future cross-language tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,142.88,287.66,317.26,242.10"><head></head><label></label><figDesc></figDesc><graphic coords="2,142.88,287.66,317.26,242.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,559.83,423.01,126.50"><head>Table 1 :</head><label>1</label><figDesc>Results obtained by our system. topics, divided by the number of topics. The MRR is the Mean Reciprocal Rank or the first important non-repeated snippet. The precision is calculated as the number of important novel non-repeated snippets, divided by the total number of snippets per topic. Our system returned always a number of snippets ≤ 10.</figDesc><table coords="3,90.00,581.49,313.48,68.97"><row><cell cols="2">Language Average yield</cell><cell cols="2">MRR Precision</cell></row><row><cell>English</cell><cell cols="2">2.6615 0.4831</cell><cell>0.2850</cell></row><row><cell>Spanish</cell><cell cols="2">1.8225 0.3661</cell><cell>0.2273</cell></row><row><cell>snippets for all</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,105.24,735.58,91.27,6.99"><p>http://lucene.apache.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">R2D2 CICYT</rs> (<rs type="grantNumber">TIC2003-07158-C04-03</rs>) and <rs type="funder">ICT EU-India</rs> (<rs type="grantNumber">ALA/95/23/2003/077-054</rs>) research projects for partially supporting this work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_d6FuVrn">
					<idno type="grant-number">TIC2003-07158-C04-03</idno>
				</org>
				<org type="funding" xml:id="_XcVsuKe">
					<idno type="grant-number">ALA/95/23/2003/077-054</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.50,269.37,407.51,8.74;4,105.50,281.33,362.07,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,155.85,281.33,156.47,8.74">Using wikipedia at the trec qa track</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Valentin</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karin</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Schlobach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,333.34,281.33,103.84,8.74">TREC 2004 Proceedings</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,301.25,407.50,8.74;4,105.50,313.21,193.02,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,253.66,301.25,259.34,8.74;4,105.50,313.21,16.65,8.74">Mining knowledge from wikipedia for the question answering task</title>
		<author>
			<persName coords=""><forename type="first">Davide</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,143.18,313.21,102.96,8.74">LREC 2006 Proceedings</title>
		<imprint>
			<date type="published" when="2006-07">July 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,333.14,398.18,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,281.79,333.14,123.52,8.74">The Wikipedia XML Corpus</title>
		<author>
			<persName coords=""><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,414.55,333.14,57.90,8.74">SIGIR Forum</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,353.06,407.51,8.74;4,105.50,365.02,296.80,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,383.25,353.06,129.76,8.74;4,105.50,365.02,136.43,8.74">A passage retrieval system for multilingual question answering</title>
		<author>
			<persName coords=""><forename type="first">Jose</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emilio</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>LNAI-Springer Verlag</publisher>
			<biblScope unit="page">3658</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,384.94,407.50,8.74;4,105.50,396.90,346.98,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,334.99,384.94,173.44,8.74">Resource analysis for question answering</title>
		<author>
			<persName coords=""><forename type="first">Lucian</forename><surname>Vlad Lita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Warren</forename><forename type="middle">A</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,117.95,396.90,282.38,8.74">ACL 2004 Proceedings. Association of Computational Linguistics</title>
		<imprint>
			<date type="published" when="2004-07">July 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
