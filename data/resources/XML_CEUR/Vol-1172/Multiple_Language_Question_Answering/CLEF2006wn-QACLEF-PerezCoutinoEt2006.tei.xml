<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.48,73.87,252.49,12.90;1,158.76,89.83,277.86,12.90">A Shallow Approach for Answer Selection based on Dependency Trees and Term Density</title>
				<funder ref="#_CjNSHcw">
					<orgName type="full">Vanguard Engineering Puebla SA de CV, CONACYT</orgName>
				</funder>
				<funder>
					<orgName type="full">Human Language Technologies Laboratory of INAOE</orgName>
				</funder>
				<funder ref="#_ueGUuY4">
					<orgName type="full">SNI-Mexico</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.92,119.26,96.90,9.15"><forename type="first">Manuel</forename><surname>Pérez-Coutiño</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Vanguard Engineering Puebla (VEng)</orgName>
								<address>
									<addrLine>Recta a Cholula 308-4, CP 72810, San Andrés Cholula</addrLine>
									<region>Pue</region>
									<country key="MX">México</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.04,119.26,108.58,9.15"><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica Luis Enrique Erro No</orgName>
								<address>
									<postCode>CP, 72840</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Sta. Ma. Tonantzintla</orgName>
								<address>
									<settlement>Pue</settlement>
									<country key="MX">México</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.92,119.26,90.22,9.15"><forename type="first">Aurelio</forename><surname>López-López</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica Luis Enrique Erro No</orgName>
								<address>
									<postCode>CP, 72840</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Sta. Ma. Tonantzintla</orgName>
								<address>
									<settlement>Pue</settlement>
									<country key="MX">México</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.56,130.78,97.98,9.15"><forename type="first">Luis</forename><surname>Villaseñor-Pineda</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica Luis Enrique Erro No</orgName>
								<address>
									<postCode>CP, 72840</postCode>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Sta. Ma. Tonantzintla</orgName>
								<address>
									<settlement>Pue</settlement>
									<country key="MX">México</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.96,130.78,118.66,9.15"><forename type="first">Aarón</forename><surname>Pancardo-Rodríguez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Vanguard Engineering Puebla (VEng)</orgName>
								<address>
									<addrLine>Recta a Cholula 308-4, CP 72810, San Andrés Cholula</addrLine>
									<region>Pue</region>
									<country key="MX">México</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.48,73.87,252.49,12.90;1,158.76,89.83,277.86,12.90">A Shallow Approach for Answer Selection based on Dependency Trees and Term Density</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5F9F945AD1ADFE2F21B70BE87E9681A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Question Answering for Spanish, Lexical-Syntactic Context, Natural Language Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the experiments performed for the QA@CLEF-2006 within the joint participation of the eLing Division at VEng and the Language Technologies Laboratory at INAOE. This year our laboratories have participated in the Spanish monolingual task, continue with their previous work described in <ref type="bibr" coords="1,255.72,271.69,111.70,11.04" target="#b22">[Pérez-Coutiño et al., 2005]</ref>. The aim of these experiments was to observe and quantify the possible improvement at the final step of the Question Answering prototype when some syntactic features were taken into the decision process. In order to reach this goal, a shallow approach to answer ranking based on the term density measure has been included. This measure weighs the number of question terms which have a syntactic dependency to one candidate answer within a relevant passage to the given question. Once the term density has been computed for each candidate answer, their weights along to the weights gathered in the previous steps are merged by a lineal combination to gather the final weight for each candidate answer. Finally, the answer selection process arranges candidate answers based on their weights, selecting the top-n as the Question Answering system answers. The approach described has shown a small but interesting improvement against the same Question Answering prototype without this module. Nevertheless, there are many variables to consider for a substantial improvement of the whole Question Answering system, and particularly at the initial steps, where passage retrieval and candidate answer selection are determinant for the improvement of system's recall.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the last years, the research of Question Answering (QA) systems for European languages has shown an incremental growing both in interest as well as in complexity. Particularly, QAs for Spanish has been formally evaluated within the CLEF initiative since 2003 <ref type="bibr" coords="1,265.20,635.29,87.56,11.04" target="#b13">[Magnini et al., 2003]</ref> when just one QA system for Spanish was proposed. In QA@CLEF-2004 <ref type="bibr" coords="1,199.92,646.81,88.17,11.04" target="#b15">[Magnini et al., 2004]</ref>, there were a total number of five proposed QA systems for Spanish developed by four research groups from Spain and the one developed by <ref type="bibr" coords="1,419.16,658.33,69.47,11.04">INAOE (Mexico)</ref>. Finally in QA@CLEF-2005 <ref type="bibr" coords="1,157.20,669.85,79.88,11.04" target="#b29">[Vallin et al., 2005]</ref>, the total number of proposed QAs arose to seven, developed by six research groups from Spain, one developed by INAOE, and the joint participation between INAOE and the Polytechnic University of Valencia (Spain). Those QA systems have explored different approaches to cope with the whole QA problem, analyzing several methodologies from purely data-driven <ref type="bibr" coords="1,394.20,704.29,85.21,11.04" target="#b31">[Vicedo et al., 2003;</ref><ref type="bibr" coords="1,483.00,704.29,41.36,11.04;1,70.92,715.81,82.64,11.04" target="#b17">Montes-y-Gómez et al., 2005]</ref> to in-depth natural language processing (NLP) <ref type="bibr" coords="1,352.32,715.81,80.23,11.04" target="#b9">[Ferrés et al., 2005]</ref>. Despite the methods used within some particular QA approach, the improvement of factoid questions resolution has been measured.</p><p>Starting on 2003, the QA research interests within the Language Technologies laboratory at INAOE have been directed in two main lines, on one hand, the development of QA systems for Spanish applying shallow NLP techniques in order to gather information models from which the system is able to extract answers to factoid questions. On the other hand, the development of full data-driven approaches to cope with the extraction of answers for both, factoid and definition questions. Those approaches have obtained encouraging results within CLEF campaigns, including the best overall accuracy for Spanish monolingual task at QA@ <ref type="bibr" coords="2,439.15,128.53,53.50,11.04">CLEF-2005</ref><ref type="bibr" coords="2,495.60,128.53,29.00,11.04;2,70.92,140.05,80.73,11.04">[Perez-Coutiño et al., 2005]</ref>.</p><p>This paper shows the prototype developed as a shared effort between the recently formed eLing Division at VEng<ref type="foot" coords="2,94.20,161.51,3.24,7.18" target="#foot_0">1</ref> and the Language Technologies laboratory at INAOE. This approach continues with the previous work of the authors <ref type="bibr" coords="2,118.44,174.49,112.88,11.04">[Perez-Coutiño et al., 2005]</ref> to cope with factoid questions resolution. The aim of these experiments was to observe and quantify the possible improvement at the final step of a Question Answering prototype (i.e. at the answer selection step), as a consequence of introducing some syntactic features to the decision process. In order to reach this goal, the following key points have been included in the QA prototype: i) A syntactic parser based on dependency grammars for offline processing; ii) a shallow technique to weigh the number of question terms which have a syntactic dependency to one candidate answer within a relevant passage to the given question (aka term density); iii) a lineal combination for merging the term density of each candidate answer along to the weights gathered in the previous steps to obtain its final weight. Once all these values are computed, the answer selection process arranges candidate answers based on their weights, selecting the top-n as the Question Answering system answers. The approach described in this document has shown a small but interesting improvement up to 15% against the same Question Answering prototype without this module. Nevertheless, there are many variables to consider for a substantial improvement of the whole Question Answering system, and particularly at the initial steps, where passage retrieval and candidate answer selection are determinant for the improvement of system's recall.</p><p>The rest of the paper is organized as follows, section two summarizes the architecture of the prototype; section three exposes the details of the new elements within the prototype architecture; section four discusses training and official results achieved by the system at QA@CLEF-2006. Finally section five draws the preliminary conclusions of these experiments and discusses further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Prototype Architecture</head><p>As stated before, the system developed is based on the previous works of the authors <ref type="bibr" coords="2,435.84,413.29,88.65,11.04;2,70.92,424.81,21.57,11.04" target="#b22">[Pérez-Coutiño et al., 2005]</ref>, where the most important modification relies on the inclusion of syntactic features to the decision process at the answer selection module. Figure <ref type="figure" coords="2,232.44,436.33,4.98,11.04" target="#fig_0">1</ref> shows the main blocks of the system. It could be noticed that factoid and definition questions are handled independently. This report is focused in the factoid questions resolution process, while details of the processes involved in the creation and use of definition patterns aimed to answering definition questions can be found in <ref type="bibr" coords="2,216.96,470.77,113.24,11.04" target="#b7">[Denicia-Carral et al., 2006]</ref> <ref type="foot" coords="2,330.12,471.30,3.00,6.65" target="#foot_1">2</ref> .</p><p>Factoid question treatment consists of the following steps: question processing, which includes the extraction of named entities and lexical context in the question, as well as question classification to define the semantic class of the answer expected to respond to a given question; documents processing, where the preprocessing of the supporting document collection is done in parallel by a passage retrieval system (PRS)and a shallow NLP, including the syntactic analysis of the document collection; searching, where a set of candidate answers is obtained from the modeled passages retrieved by the PRS; and finally answer extraction, where candidate answers are weighted and ranked in order to produce the final answer recommendation of the system. Next paragraphs summarize the initial steps of the prototype whilst section three and four discuss the new ones.</p><p>2.1 Question Processing. Our prototype implements this step following a straight forward approach involving the next steps:</p><p>1. Question is parsed with a set of heuristic rules in order to get its semantic class. 2. Question is tagged with the MACO POS tagger <ref type="bibr" coords="2,299.64,622.69,108.44,11.04" target="#b5">[Carreras and Padró, 2002]</ref> 3. Question's named entities are identified and classified using MACO. The first step is responsible of identify the semantic class of the expected answer. In the experiments performed with the training data set, we found that when the number of classes was minimal (just 3 classes: date, quantity and proper noun) it was possible to achieve similar results in precision to those achieved when we use more than five classes, for instance person, organization, location, date, quantity and other. Steps 2 and 3 produce information used later during the searching step, mainly to match questions and candidate answer context, contributing to the weighted schema. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Documents</head><p>Processing. This year the prototype included an additional element for the syntactic parsing of the document collection. Thus the processing of target documents is composed of three parts, first the whole document collection is tagged with MACO <ref type="bibr" coords="3,235.73,483.37,116.93,11.04" target="#b5">[Carreras and Padró, 2002]</ref>, gathering the POS tags as well as named entities identification and classification for each document in the collection. In the second part of the process, and in parallel to the first one, the whole document collection is tagged with the FDG Parser from Conexor<ref type="foot" coords="3,518.64,506.10,3.24,5.96" target="#foot_2">3</ref> , which is based in the Functional Dependency Grammar discussed in <ref type="bibr" coords="3,354.84,517.93,125.23,11.04" target="#b27">[Järvinen &amp; Tapanainen, 1997]</ref>. The final part of this step is performed by the JIRS <ref type="bibr" coords="3,245.04,529.45,119.36,11.04" target="#b11">[Gómez-Soriano et al., 2005]</ref> passage retrieval system (PRS), which create the index for the searching process. The index gathered by JIRS and the tagged collection are aligned phrase by phrase for each document in the collection. This way, the system could retrieve later the relevant passages for a given question with JIRS, and then use their tagged form for the answer extraction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.3</head><p>Searching. This step is performed in two parts. The first part consists of the retrieving of relevant passages for the given question. This step is performed by JIRS, taking as input the question without previous processing. JIRS is a PSR specially suited for question answering systems. JIRS ranks the retrieved passages based on the computation of a weight for each passage. The weight of a passage is related to the lager n-gram structure of the question that can be found in the passage itself. The larger the n-gram structure, the greater the weight of the passage. A complete discussion of the similarity metrics used by JIRS and details of its evaluation can be found in <ref type="bibr" coords="3,81.12,660.37,115.27,11.04" target="#b11">[Gómez-Soriano et al., 2005]</ref>.</p><p>Once the relevant passages are selected, the second part requires the POS and Parsing tagged forms of each passage in order to gather the representation used to extract candidates answers. Tagged passages are represented as described in <ref type="bibr" coords="3,134.40,694.93,113.12,11.04" target="#b18">[Pérez-Coutiño et al., 2004]</ref> where each retrieved passage is modeled by the system as a factual text object whose content refers to several named entities even when it is focused on a central topic. As mentioned, named entities could be one of these: persons, organizations, locations, dates, quantities and miscellane-ous<ref type="foot" coords="4,84.84,71.58,3.00,6.65" target="#foot_3">4</ref> . The model assumes that the named entities are strongly related to their lexical context, especially to nouns (subjects) and verbs (actions). Thus, a passage can be seen as a set of entities and their lexical context. Such representation is used later in order to match question's representation with the best set of candidates gathered from passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Answer Extraction.</head><p>One of the drawbacks found in our previous work was the lost of precision during answer extraction step. Once the system applies different criteria to obtain a set of candidate answers, it computes for each candidate answers a lexical weight in order to rank the best candidate answers (see formula 1) and then select the top-n as the system answers. However, there were situations where several candidate answers could have the same weight. In order to avoid such situations, we have included syntactic information to compute an additional weight which is later combined with the lexical weight to obtain the final one used to rearrange the candidate answers. Next section discusses this concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i=1..k; k=number of passages retrieved by JIRS (1)</head><p>Where lex ω is the assigned weight for a candidate answer; q t is 1 if the semantic class of the candidate answer is the same that the question's one and 0 in other case; n is a normalization factor based on the number of acti- vated features, q NE is the set of named entities in the question and A NE is the set of named entities in the con- text of the candidate answer; q C is the question's context and A C is the candidate answer's context; ) ( i A P F is the frequency of occurrence of the candidate answer in the passage i;</p><formula xml:id="formula_0" coords="4,353.88,373.51,26.41,13.73">) (P F A</formula><p>is the total frequency of occurrence of the candidate answer in the passages retrieved by JIRS; and</p><formula xml:id="formula_1" coords="4,336.84,392.45,29.01,20.68">1 1 - - k P i</formula><p>is an inverse relation for the passage ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Adding Syntactic Features</head><p>In order to improve the precision at the answer selection step, we have experimented with the inclusion of a shallow approach based on the use of some syntactic features. The main characteristic of this approach relies on the kind of information used to compute an additional weight to rearrange the set of candidate answers previously selected by a lexical supported method. This approach is flexible given that one of the factors taken in mind was to realize the amount of errors that a parser could yield.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Key observations of the method.</head><p>There are different approaches to the use of syntactic information within the QA task. Some of them try to found a direct similarity between question structure and those of the candidate answers. This kind of similarity is commonly supported by a set of syntactic patterns which are expected to be matched by the answers. Some systems applying this approach are described in <ref type="bibr" coords="4,396.36,563.17,90.61,11.04" target="#b3">[Bertagna et al., 2004;</ref><ref type="bibr" coords="4,489.96,563.17,34.57,11.04;4,70.92,574.69,38.53,11.04" target="#b23">Roger et al., 2005;</ref><ref type="bibr" coords="4,112.80,574.69,117.31,11.04" target="#b0">Aunimo &amp; Kuuskoski, 2005]</ref>. Other proposals, like the one presented by Tanev <ref type="bibr" coords="4,443.16,574.69,81.32,11.04" target="#b26">[Tanev et al., 2005]</ref> apply transformations to the syntactic tree of the question in order to approximate it to the trees of the relevant passages, where it is supposed that an answer is present.</p><p>Despite the degree of effectiveness of those approaches, their principal drawback comes up when the parsing is deficient. With this limitation in mind, and trying to work around the gap of parsers for Spanish, our proposal is supported by the following observations of the dependency trees obtained by means of DFG parser.</p><p>1. There are important structural differences between questions dependency trees and those gathered from their relevant passages. 2. For a given question, its dependency tree states both, functional and structural dependencies starting from the main verb within the sentence, clearly delimiting other relations like subject, agent, object, etc. Contrasting this fact, dependency trees gathered from the relevant passage of the given question, could be seen as a forest, where functional and structural relations -which could possible lead the process to the accurate answer-are broken from one tree to another.</p><p>3. Finally, dependency trees gathered from the relevant passages to a given question could enclose a high number of question terms related to several candidate answers. Figure <ref type="figure" coords="5,113.64,96.01,4.98,11.04">2</ref> shows some examples of these observations. Notice the differences between question and relevant passage structures. Besides, the analysis of the question shows the second case, whilst the passage tree could be seen as a forest. Finally, the tree where the answer is found "Take That" does not contain any question terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2a.</head><p>Example of syntactic trees gathered from a question and one of its relevant passages. The answer is isolated from the rest of the terms within the dependency tree.</p><p>This example shows the tree gathered from the relevant passage to the question: ¿Qué político liberal fue ministro de Sanidad italiano entre 1989 y 1993? Notice that the accurate answer "De Lorenzo", occurs within this tree, and relates several question terms to it. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Term Density.</head><p>In order to cope with these observations, we propose a straight forward metric to capture and weigh up the question terms which are nearest to a candidate answer within a relevant passage. Formula 2 shows those relations, which we have named the term density within a dependency tree.</p><p>Given:</p><formula xml:id="formula_2" coords="5,107.88,613.98,180.80,29.93">{ } n t t t Q ... , 2 1 = , the questions terms (lemmas) { } k w w w W ... , 2 1 =</formula><p>, the passages' terms (lemmas) W C i ⊂ , the terms (lemmas) of the i-th candidate answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A subtree (</head><p>)</p><formula xml:id="formula_3" coords="5,150.48,665.17,326.60,86.85">h h w w w w x ... : , ,...,*,... 1 1 α depends on α x Then, ( ) ( ) α δ x w C w t f n C i Q t j i q , , 1 ∈ ∀ ⇔ = ∑ ∈ ∀ ; ( ) ( )      = else t ó x t t f j j j , 0 * , , 1 α (2)</formula><p>The algorithm applied in order to compute the term density for a candidate answer involves the following steps.</p><p>1. For each relevant passage of a given question 1.1. Retrieve the dependency tree for that passage 1.2. For each candidate answer within the passage 1.2.1. Retrieve the subtree where the candidate answer occurs 1.2.2. Apply formula 2 ( q δ ) 1.2.3. Compute the maximum q δ for each candidate answer, then preserve it if it is greater than 0.5, in other case, q δ =0 Finally, computes the total weight of each candidate answer merging the lexical and syntactic weights with formula 3.</p><p>( ) ( ) ( )</p><formula xml:id="formula_4" coords="6,204.48,215.76,234.08,14.75">i q i lex i C C C βδ αω ω + = (3)</formula><p>Where ω lex is the result of computing formula 1; α and β coefficients has been selected experimentally, giving </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>This section discusses some results achieved with training questions as well as the experiment ran for the evaluation of the proposed prototype within the Spanish monolingual task at the QA@CLEF-2006.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training Experiments</head><p>These experiments were performed over several training sets including the evaluation set of last year QA@CLEF. Through training experiments of the QA prototype we can observe a significant improvement in the final answer selection step. For the case of training with the QA@CLEF-2005 evaluation set, the accuracy of the system was increased over 7% for factoid questions, whilst the improvement in temporal restricted factoid questions achieved a 15%. These percentages represent a good progress giving that over the last years the rate of improvements in the results of Spanish factoid questions evaluation has been gradually.</p><p>Table <ref type="table" coords="6,107.64,429.01,4.98,11.04" target="#tab_0">1</ref> shows some examples of the increasing rank for candidate answers with high term density. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>This year the evaluation of QA systems at CLEF included factoid, definition, temporal and list questions. The organizers provide to participants with a set of 200 unclassified questions, i.e. there were not markers to indicate the type of expected answer. Another novelty was that teams must provide answers with the specific passage where the answer was extracted from. The later was used to facilitate the evaluation of answers. We participate in the evaluation with one run. The configuration applied considers three classes of possible answers, Date, Quantity and Proper Nouns; the system analyzes the first 100 1-line passages retrieved by JIRS; the lexical context used was formed with nouns, named entities, verbs, and adjectives, and the size of the window context is 8 words. Table <ref type="table" coords="6,194.04,675.73,4.98,11.04" target="#tab_1">2</ref> shows the results of the evaluation.</p><p>Despite the fact that our results (for factual questions) were only over 2% better than last year, we believe that the approach described could be a good starting point to the introduction of syntactic information to the answer selection process. Some errors observed while training include the confusion of accurate answers by candidate answers that have a term density similar or greater to the right answer. A detailed analysis of these results will help us to take the next direction in our research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This work has presented a method for the inclusion of syntactic information within the final process of answer selection in a QA system. The approach relies in the use of a flexible metric which allows measuring the amount of question terms which have a syntactic dependence to the candidate answers. Although official evaluation does not reach the expectation, preliminary results have demonstrated a significant improvement in the answer selection step. This drive us to think that it could be possible to apply syntactic information in several ways in order to cope with the problem of partial or even more, deficient syntactic trees (in particular dependence trees).</p><p>Despite the low increasing in the official evaluation, the methods applied at different steps of the QA process are stable; this conclusion can be dropped from the fact that the prototype has reached its last year performance.</p><p>It is important to realize that the additions to our QA prototype presented in this document are limited by the previous processes. This means that the proposed method is not able to extract new candidate answers. Therefore our next steps into QA systems development must be done in the direction of improving system's recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,70.92,409.11,453.76,9.97;3,70.92,419.43,453.52,9.97;3,70.92,429.75,453.66,9.97;3,70.92,440.07,154.29,9.97;3,142.20,130.20,308.76,276.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Block diagram of the system. Factoid and definition questions are treated independently. Factual questions require the following stages: question processing, documents processing, searching and answer selection. Notice the inclusion of a parser to the NLP tools and the resulting index tagged syntactically. Definition questions use a set of patterns for definition extraction and definition selection process.</figDesc><graphic coords="3,142.20,130.20,308.76,276.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,93.96,491.05,407.38,11.04;5,93.96,502.57,39.09,11.04;5,93.96,352.92,142.08,125.88"><head>Figure 2b .</head><label>2b</label><figDesc>Figure 2b. Example of one tree with several question terms related to its candidate answer (De Lorenzo).</figDesc><graphic coords="5,93.96,352.92,142.08,125.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,70.92,259.69,47.91,11.04;6,147.84,259.40,5.35,11.85;6,143.52,259.40,2.97,11.85;6,137.52,259.40,5.35,11.85;6,130.20,261.00,5.87,10.29;6,119.76,260.55,6.75,10.88;6,154.44,259.69,19.38,11.04;6,205.20,259.63,5.36,11.87;6,200.76,259.63,2.98,11.87;6,194.04,259.63,5.36,11.87;6,185.52,261.23,5.88,10.30;6,175.68,260.79,5.87,10.88;6,212.04,259.69,226.29,11.04"><head>.</head><label></label><figDesc>This way the syntactic weight has a greater confidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,70.92,452.50,451.68,101.11"><head>Table 1 .</head><label>1</label><figDesc>Examples of rank increasing for candidates answers with high term density. Training set used was the evaluation set of the QA@CLEF-2005.</figDesc><table coords="6,122.88,479.65,350.46,73.96"><row><cell>Question No. 29 115 139 161</cell><cell>Candidate and Right Answer De Lorenzo 64 (días) Yoweri Kaguta Museveni Jacques Delors</cell><cell>Previous Rank TO New Rank 5 th TO 1 st 15 th TO 1 st 10 th TO 1 st 3 rd a 1 st</cell><cell>w lex (C i ) δ q (C i ) 0.5472 0.5000 0.5157 w(C i ) 0.5440 0.5714 0.5622 0.9367 0.8888 0.9048 0.8505 0.8000 0.8168</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,152.28,70.90,290.78,149.55"><head>Table 2 .</head><label>2</label><figDesc>Results of submitted run.</figDesc><table coords="7,152.28,90.94,290.78,129.51"><row><cell>Run</cell><cell>Vein061eses</cell></row><row><cell>Right</cell><cell>84 (45F + 35D + 0 TRF)</cell></row><row><cell>Wrong</cell><cell>102</cell></row><row><cell>ineXact</cell><cell>3</cell></row><row><cell>Unsupported</cell><cell>5</cell></row><row><cell>Overall Accuracy</cell><cell>42.11%</cell></row><row><cell>Factoid Questions</cell><cell>30.82%</cell></row><row><cell>Definition Questions</cell><cell>83.33%</cell></row><row><cell>Temporally Restricted Factoid Questions</cell><cell>0%</cell></row><row><cell>Overall Confidence Weighted Score</cell><cell>0.33582</cell></row><row><cell>(CWS) over F, D, and TR</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,76.44,691.71,448.14,9.97;2,78.00,702.75,446.52,9.97;2,78.00,713.67,115.92,9.97"><p>The eLing Division at Vanguard Engineering is a private effort of recent foundation to develop business applications based on Language Technologies and Knowledge Management. In order to receive further information contact to ManuelPérez- Coutiño (mapco AT v-eng.com)  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,70.92,724.38,453.74,10.30;2,78.00,735.75,446.64,9.97;2,78.00,746.67,328.17,9.97"><p>2 In order to avoid redundancy between reports this year we decided to leave the discussion of answering definition questions out of the scope of this report. The reader can find a discussion of the method evaluated for definition questions in this volume under the title "INAOE at CLEF 2006: Experiments in Spanish Question Answering".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,76.20,746.67,229.77,9.97"><p>http://www.conexor.com with an online demo of their software.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,76.20,746.62,370.30,10.04"><p>The semantic classes used rely on the capability of the named entity classifier used in our experiments.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was done under partial support of <rs type="funder">Vanguard Engineering Puebla SA de CV, CONACYT</rs> (Project Grants <rs type="grantNumber">U39957-Y</rs> and <rs type="grantNumber">43990</rs>), <rs type="funder">SNI-Mexico</rs>, and the <rs type="funder">Human Language Technologies Laboratory of INAOE</rs>. We also like to thanks to the CLEF as well as <rs type="institution">EFE agency</rs> for the resources provided.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CjNSHcw">
					<idno type="grant-number">U39957-Y</idno>
				</org>
				<org type="funding" xml:id="_ueGUuY4">
					<idno type="grant-number">43990</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,76.05,469.93,123.10,11.04" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Kuuskoski</forename><surname>Aunimo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,202.20,469.93,322.38,11.04;7,70.92,481.45,443.38,11.04;7,70.92,502.93,4.37,11.04" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,312.48,469.93,212.10,11.04;7,70.92,481.45,210.19,11.04">Question Answering using Semantic Annotation, 6th Workshop of the Cross-Language Evaluation Forum</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Aunimo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kuuskoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,289.11,481.45,46.39,11.04">CLEF 2005)</title>
		<meeting><address><addrLine>Peters C; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,75.29,502.93,90.14,11.04" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Bertagna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,169.56,502.93,355.02,11.04;7,70.92,514.33,453.46,11.04;7,70.92,525.85,180.18,11.04" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,311.76,505.00,196.77,8.88">QA at ILC-UniPi: Description of the Prototype</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bertagna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Chiran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,70.92,514.33,331.85,11.04">Working Notes for the Cross Language Evaluation Forum Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Borri</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
	<note>CLEF-2004</note>
</biblStruct>

<biblStruct coords="7,75.06,547.45,104.90,11.04" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Padró</forename><surname>Carreras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,182.64,547.45,341.98,11.04;7,70.92,558.85,345.33,11.04" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,291.12,549.52,233.50,8.88;7,70.92,560.92,37.67,8.88">A Flexible Distributed Architecture for Natural Language Analyzers</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Padró</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,126.12,558.85,113.12,11.04">Proceedings of the LREC&apos;02</title>
		<meeting>the LREC&apos;02<address><addrLine>Las Palmas de Gran Canaria, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,75.10,580.33,119.74,11.04" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Denicia-Carral</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,201.00,580.33,323.48,11.04;7,70.92,591.85,453.46,11.04;7,70.92,603.37,436.77,11.04" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,133.56,593.92,248.04,8.88">A Text Mining Approach for Definition Question Answering</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Denicia-Carral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>García-Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,443.76,591.85,80.62,11.04;7,70.92,603.37,311.01,11.04">Proceedings for the Fifth International Conference on Natural Language Processing (FinTal 2006)</title>
		<meeting>for the Fifth International Conference on Natural Language Processing (FinTal 2006)<address><addrLine>Turku, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08">August 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.97,619.81,74.75,11.04" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Ferrés</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,152.28,619.81,372.32,11.04;7,70.92,631.33,453.44,11.04;7,70.92,642.85,88.18,11.04" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,397.68,621.88,126.92,8.88;7,70.92,633.40,50.01,8.88">The TALP-QA system for Spanish at CLEF</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ferrés</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kanaan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ageno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,149.88,631.33,284.62,11.04">6th Workshop of the Cross-Language Evaluation Forum (CLEF 2005)</title>
		<meeting><address><addrLine>Peters C; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">2005. September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,78.19,659.41,112.92,11.04" xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Gómez-Soriano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,193.80,659.41,330.80,11.04;7,70.92,670.81,453.54,11.04;7,70.92,682.33,216.21,11.04" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,497.52,661.48,27.08,8.88;7,70.92,672.88,244.21,8.88">A Passage Retrieval System for Multilingual Question Answering</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gómez-Soriano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanchis-Arnal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,377.04,670.81,147.42,11.04;7,70.92,682.33,119.89,11.04">the 8th International Conference on Text, Speech and Dialog, TSD</title>
		<imprint>
			<publisher>Springer LNAI</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,75.56,703.81,85.68,11.04" xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Magnini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,164.76,703.81,359.82,11.04;7,70.92,715.33,453.57,11.04;7,70.92,726.73,140.49,11.04" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,113.16,717.40,266.66,8.88">The Multiple Language Question Answering Track at CLEF 2003</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Romagnoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vallin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,402.60,715.33,117.59,11.04">CLEF-2003 Workshop Notes</title>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08">August 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.56,71.05,85.20,11.04" xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Magnini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,164.04,71.05,360.33,11.04;8,70.92,82.57,453.46,11.04;8,70.92,93.97,453.56,11.04;8,70.92,105.49,99.93,11.04" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,124.92,84.64,284.76,8.88">Overview of the CLEF 2004 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vallin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Erbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,429.84,82.57,94.54,11.04;8,70.92,93.97,239.69,11.04">Working Notes for the Cross Language Evaluation Forum Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Borri</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
	<note>CLEF-2004</note>
</biblStruct>

<biblStruct coords="8,75.84,126.97,120.44,11.04" xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,199.20,126.97,325.14,11.04;8,70.92,138.49,453.56,11.04;8,70.92,150.01,453.57,11.04;8,70.92,161.41,136.05,11.04" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,235.21,140.56,289.27,8.88;8,70.92,152.08,112.31,8.88">INAOE-UPV Joint Participation at CLEF 2005: Experiments in Monolingual Question Answering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pérez-Coutiño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gómez-Soriano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanchis-Arnal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,195.60,150.01,284.72,11.04">6th Workshop of the Cross-Language Evaluation Forum (CLEF 2005)</title>
		<meeting><address><addrLine>Peters C; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.28,183.01,110.44,11.04" xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Pérez-Coutiño</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,189.36,183.01,335.12,11.04;8,70.92,194.41,453.49,11.04;8,70.92,205.93,453.57,11.04" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,141.18,196.48,246.00,8.88">Toward a Document Model for Question Answering Systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pérez-Coutiño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,399.24,194.41,125.17,11.04;8,70.92,205.93,331.50,11.04">Advances in Web Intelligence: proceedings / Second International Atlantic Web Intelligent Conference AWIC04</title>
		<meeting><address><addrLine>Cancun, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.92,217.45,296.13,11.04" xml:id="b20">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="8,172.32,217.45,23.84,11.04">LNAI</title>
		<editor>
			<persName><forename type="first">Jesus</forename><surname>Favela</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3034</biblScope>
			<biblScope unit="page" from="145" to="154" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.28,238.93,107.80,11.04" xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Pérez-Coutiño</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,185.76,238.93,338.61,11.04;8,70.92,250.45,453.46,11.04;8,70.92,261.85,378.81,11.04" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="8,75.54,252.52,354.23,8.88">Experiments for tuning the values of lexical features in Question Answering for Spanish</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pérez-Coutiño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,441.36,250.45,83.02,11.04;8,70.92,261.85,194.83,11.04">6th Workshop of the Cross-Language Evaluation Forum (CLEF 2005)</title>
		<meeting><address><addrLine>Peters C; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.53,283.45,73.94,11.04" xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Roger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,152.16,283.45,372.33,11.04;8,70.92,294.85,453.68,11.04;8,70.92,306.37,164.61,11.04" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tomás</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aliqan</surname></persName>
		</author>
		<title level="m" coord="8,70.92,294.85,432.79,11.04">Spanish QA System at CLEF-2005. 6th Workshop of the Cross-Language Evaluation Forum (CLEF 2005)</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Peters C</publisher>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.65,327.85,75.39,11.04" xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Tanev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,153.96,327.85,370.64,11.04;8,70.92,339.37,453.46,11.04;8,70.92,350.77,376.29,11.04" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="8,417.24,329.92,107.36,8.88;8,70.92,341.44,341.85,8.88">Exploiting Linguistic Indices and Syntactic Structures for Multilingual Question Answering: ITC-irst at CLEF</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kouylekov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,415.56,339.37,108.82,11.04;8,70.92,350.77,194.83,11.04">2005, 6th Workshop of the Cross-Language Evaluation Forum (CLEF 2005)</title>
		<meeting><address><addrLine>Peters C; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,124.32,372.37,400.28,11.04;8,70.92,383.77,271.17,11.04" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="8,292.44,374.44,152.46,8.88">A Non-Projective Dependency Parser</title>
		<author>
			<persName coords=""><forename type="first">]</forename><surname>Järvinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tapanainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Järvinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,463.80,372.37,60.80,11.04;8,70.92,383.77,241.80,11.04">Proceedings of the 5th Conference on Applied Natural Language Processing</title>
		<meeting>the 5th Conference on Applied Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,74.96,405.37,76.92,11.04" xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Vallin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,155.16,405.37,369.34,11.04;8,70.92,416.77,453.54,11.04;8,70.92,428.29,453.63,11.04;8,70.92,439.81,254.49,11.04" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="8,269.88,418.84,254.58,8.88;8,70.92,430.36,20.21,8.88">Overview of the CLEF 2005 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vallin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Aunimo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sacaleanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,115.80,428.29,348.50,11.04">Working Notes for the Cross Language Evaluation Forum Workshop (CLEF-2005)</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria; ISTI-CNR, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,75.52,461.29,83.31,11.04" xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Vicedo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,163.08,461.29,361.53,11.04;8,70.92,472.81,263.25,11.04" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="8,388.44,463.36,128.02,8.88">Question Answering in Spanish</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Izquierdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,70.92,472.81,115.91,11.04">CLEF-2003 Workshop Notes</title>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08">August 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
