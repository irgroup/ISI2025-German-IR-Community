<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
				<funder ref="#_fQ5g4vX">
					<orgName type="full">Spanish Ministry of Science and Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,179.76,100.29,52.61,9.16"><forename type="first">Jesús</forename><surname>Herrera</surname></persName>
							<email>jesus.herrera@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.04,100.29,61.00,9.16"><forename type="first">Álvaro</forename><surname>Rodrigo</surname></persName>
							<email>alvarory@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.20,100.29,59.90,9.16"><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
							<email>anselmo@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.16,100.29,58.08,9.16"><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
							<email>felisa@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C90C506162B45183777550905CF41741</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.2 [Ar tificial Intelligence]: I.2.7 Natural Language Processing: Text analysis -Language parsing and understanding Question Answering</term>
					<term>Answer Validation</term>
					<term>Textual Entailment</term>
					<term>Entity Recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports the participation of the Spanish Distance Learning University (UNED) in the First Answer Validation Exercise (AVE) celebrated within the Cross Language Evaluation Forum (CLEF) 2006 edition. The system works for the Spanish language. It is based on a Support Vector Machine (SVM) classification of the pairs &lt;text, hypothesis&gt; given by the organization. This classification is accomplished by means of a set of features obtained from lexical analysis. Yet Another Learning Environment (Yale 3.0) was used for the SVM classification. Freeling was the toolkit elected for lemmatization and named entities recognition. Two runs were submitted and the results obtained, as defined by the organizers, were the following: precision run1 = 0.467, recall run1 = 0.7168, F run1 = 0.5655, precision run2 = 0.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The system presented to the First AVE is based on the ones developed for the First <ref type="bibr" coords="1,407.76,430.29,11.75,9.16" target="#b3">[4]</ref> and the Second <ref type="bibr" coords="1,489.60,430.29,11.75,9.16" target="#b4">[5]</ref> Recognizing Textual Entailment (RTE) Challenges. This is because the parallelism between both exercises. The AVE was defined in the way that a given answer to a question must be validated by means of the information contained in the question, the answer and the text supporting the answer. This information was elaborated by the organization in order to present it in the form of a pair of texts, namely text and hypothesis. The objective of the exercise is to automatically determine if one of the snippets -the text -entails the other one -the hypothesis -; if so, it is said that the answer given to the question is validated considering the information given by the supporting text. For the RTE Challenge, the participant systems must determine the existence of entailment between pairs of texts <ref type="bibr" coords="1,263.28,510.69,11.15,9.16" target="#b0">[1]</ref> <ref type="bibr" coords="1,274.43,510.69,11.15,9.16" target="#b1">[2]</ref>. Thus, the systems participating in the RTE Challenge should be able to participate in the AVE. In the system here described, the basic ideas from the ones presented to the RTE Challenges were kept, but the new system was designed and developed according to the available resources for the Spanish language, lacking some subsystems implemented in the ones cited above such, for example, dependency analysis. In short, the techniques involved in this new system are the following:</p><p>• Ratio of coincidence between words, unigrams, bigrams and trigrams, respectively, from the texts and their correspondant hypothesises.</p><p>• Detection of entailment between numeric expressions of the texts and the hypothesises.</p><p>• Detection of entailment between named entities of the texts and the hypothesises.</p><p>• Support Vector Machine classification in order to determine the final decision about textual entailment between pairs of text and hypothesis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System description</head><p>The proposed system is based on surface techniques of lexical analysis, i.e., lemmatization and recognition of named entities. The system accepts pairs of text snippets (text and hypothesis) at the input and gives a boolean value at the output: YES if the text entails the hypothesis and NO otherwise. This value is obtained by the application of a learned model by a SVM classifier. System's components, whose graphic representation is shown in figure <ref type="figure" coords="2,407.04,413.73,3.66,9.16" target="#fig_0">1</ref>, are the following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Linguistic processing</head><p>A named entities recognition was accomplished, using Freeling 1 , in order to detect numeric expressions and named entities of the texts and hypothesises. In addition, the lemmas of every text and hypothesis were obtained using Freeling, too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Lexical entailment</head><p>The entailment module takes the information given by the entities recognizer and computes the following features:</p><p>• Entailment between numeric expressions. Numeric expressions from the corpus are detected by means of an entities recognizer. Thus, a numeric expression N1 entails a numeric expression N2 if the range associated to N2 encloses the range of N1. When a numeric expression in the hypothesis is not entailed by one or more numeric expressions in the text, then the system responses that there is not entailment between numeric expressions in the pair. Also, the module computes the ratio of numeric expressions from every hypothesis entailed by any numeric expression from its text.</p><p>• Entailment between named entities. Named entities from the corpus are detected by means of an entities recognizer. Thus, a named entity NE1 entails a named entity NE2 if NE2 is contained in N1. When a named entity in the hypothesis is not entailed by one or more named entities in the text, then the system responses that there is not entailment between named entities in the pair. Also, the module computes the ratio of named entities from every hypothesis entailed by any named entity from its text.</p><p>A plain text matching module that calculates the percentage of words, unigrams (lemmas), bigrams (lemmas) and trigrams (lemmas), respectively, from the hypothesis entailed by lexical units (words or ngrams) from the text, considering them as bags of lexical units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Entailment decision</head><p>A SVM classifier, from Yet Another Learning Environment (Yale 3.0) <ref type="bibr" coords="3,348.72,143.97,10.53,9.16" target="#b2">[3]</ref>, was applied in order to train a model from the development corpus given by the organization and to apply it to the test corpus. The model was trained by means of a set of features obtained from the other modules of the system; these ones, for every pair &lt;text, hypothesis&gt; , are the following:</p><p>1. Percentage of words of the hypothesis in the text (treated as bags of words).</p><p>2. Percentage of unigrams (lemmas) of the hypothesis in the text (treated as bags of unigrams).</p><p>3. Percentage of bigrams (lemmas) of the hypothesis in the text (treated as bags of bigrams).</p><p>4. Percentage of trigrams (lemmas) of the hypothesis in the text (treated as bags of trigrams).</p><p>5. Existence or absence of any numeric expression within the hypothesis entailed by any numeric expression within the text.</p><p>6. Existence or absence of any named entity within the hypothesis entailed by any named entity within the text.</p><p>7. Ratio of numeric expressions within the hypothesis entailed by any numeric expression within the text.</p><p>8. Ratio of named entities within the hypothesis entailed by any named entity within the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Description of the runs submitted</head><p>Two runs were submitted to the First AVE. Run 1 was obtained using all the features described in section 2.4, computed from the development corpus, to train a model with the SVM.</p><p>Run 2 was obtained using only the features 1, 2, 3 and 4 described in section 2.4, computed from the development corpus, to train a model with the SVM.</p><p>The reason that motivated the election of features for run 1 and run 2 was to show the importance of considering named entities and numeric expressions for this kind of exercises, as described in <ref type="bibr" coords="3,384.48,479.73,10.53,9.16" target="#b4">[5]</ref>.</p><p>Thus, both models were applied to the appropriate features calculated from the test corpus in order to obtain a pair of predictions (run 1 and run 2) for the existence or absence of textual entailment for every pair &lt;text, hypothesis&gt; .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results plus analysis of the results</head><p>Three evaluation measures were applied to the participating systems: precision (the ratio between the number of pairs correctly labeled with YES as the predicted value for the entailment and the total number of pairs labeled with YES as the predicted value), recall (the ratio between the number of pairs correctly labeled with YES as the predicted value for the entailment and the total number of pairs having YES as their real value of entailment) and Fmeasure (giving the same weight to precision and recall). While the development time, two models were obtained by training the SVM: one of them using all the features described in section 2.4 (such as run 1) and the other one using only the features 1, 2, 3 and 4 described in section 2.4 (such as run 2). The model was trained by means of a part of the development corpus and tested by means of the other part or that corpus. For this experiment, the evaluation measures above mentioned show the values below.</p><p>• It is remarkable the recall achieved by the system. The difference between precision and recall values is due to the high amount of YES predictions given by the system when there is not entailment in fact. This amount of YES predictions is quite similar to the amount of NO predictions given when there is not entailment. Then, the system must be improved in order to increase the amount of correct NO predictions.</p><p>In order to have an idea about the performance of this system with respect to other contemporary textual entailment recognizers, accuracy -evaluation measure of the RTE Challenge <ref type="bibr" coords="4,334.08,477.33,11.75,9.16" target="#b0">[1]</ref>[2] -was calculated for it during the development time, showing values ranging 0.66 and 0.70. These values are in the stateoftheart of this kind of systems <ref type="bibr" coords="4,485.52,488.85,10.70,9.16" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This first experience with textual entailment recognizers for the Spanish language shows quite interesting results. Despite the developed system is not very complex, based on lexical analysis, its accuracy values suggest that it is well situated in the stateoftheart of this kind of systems. A first question arises when comparing the present system with more complex ones previously developed by the authors for the English language <ref type="bibr" coords="4,307.20,590.13,11.75,9.16" target="#b3">[4]</ref> [5]: why so different systems achieve similar results? It is not easy to answer; the language, the kind of task and the different external resources used for the development are some factors that can affect the overall results.</p><p>As future work, this system should be improved in order to increase the amount of NO predictions given when there is not entailment in fact. For this, new features should be searched to study their contribution to the overall performance of the system and under what circumstances is interesting to consider or not every feature.</p><p>An associated task arises from the need of resources for the new languages involved in textual entailment tasks. Thus, it is necessary to develop and make available new tools such as, for example, dependency analyzers, with the quality of the ones existing for the English language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,74.64,330.93,125.20,9.16;2,56.64,71.28,432.24,257.04"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. System's architecture</figDesc><graphic coords="2,56.64,71.28,432.24,257.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,92.64,669.09,88.00,9.16;3,110.64,692.13,93.12,9.16;4,110.64,72.69,78.48,9.16;4,110.64,95.73,61.92,9.16;4,74.64,119.49,106.00,9.16;4,110.64,142.53,93.12,9.16;4,110.64,165.57,78.48,9.16;4,110.64,188.37,61.92,9.16;4,56.64,211.41,215.68,9.16;4,74.64,235.17,68.08,9.16;4,110.64,258.21,88.08,9.16;4,110.64,281.25,78.48,9.16;4,110.64,304.05,61.92,9.16;4,74.64,327.81,68.08,9.16;4,110.64,350.85,93.12,9.16;4,110.64,373.89,78.48,9.16;4,110.64,396.93,61.92,9.16"><head></head><label></label><figDesc>Run 1 (development): o precision = 0.6431 o recall = 0.8967 o F = 0.7490 • Run 2 (development): o precision = 0.6149 o recall = 0.8545 o F = 0.7152 The results for the submitted runs were the following: • Run 1 (test): o precision = 0.467 o recall = 0.7168 o F = 0.5655 • Run 2 (test): o precision = 0.4652 o recall = 0.7079 o F = 0.5615</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially supported by the <rs type="funder">Spanish Ministry of Science and Technology</rs> within the project: <rs type="grantNumber">TIC2003 07158C0402</rs> <rs type="projectName">Multilingual Answer Retrieval Systems and Evaluation, SyEMBRA</rs>, and a <rs type="grantName">UNED PhD grant</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_fQ5g4vX">
					<idno type="grant-number">TIC2003 07158C0402</idno>
					<orgName type="grant-name">UNED PhD grant</orgName>
					<orgName type="project" subtype="full">Multilingual Answer Retrieval Systems and Evaluation, SyEMBRA</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,60.42,133.65,431.10,9.16;5,74.40,144.53,418.00,9.69;5,74.40,156.05,343.56,9.69" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,443.04,133.65,48.48,9.16;5,74.40,144.93,229.09,9.16">The Second PASCAL Recognising Textual Entailment Challenge</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barhaim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,329.76,144.53,162.64,9.69;5,74.40,156.05,229.66,9.69">Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment</title>
		<meeting>the Second PASCAL Challenges Workshop on Recognising Textual Entailment<address><addrLine>Venezia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-04">April 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,60.42,169.65,431.10,9.16;5,74.40,180.53,417.28,9.69;5,74.40,192.45,90.84,9.16" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,242.88,169.65,232.93,9.16">The PASCAL Recognising Textual Entailment Challenge</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,74.40,180.53,309.97,9.69">Proceedings of the First PASCAL Recognizing Textual Entailment Workshop</title>
		<meeting>the First PASCAL Recognizing Textual Entailment Workshop<address><addrLine>Southampton, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-04">April 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,60.42,205.65,430.86,9.16;5,74.40,216.93,417.24,9.16;5,74.40,228.45,249.96,9.16" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="5,284.64,205.65,206.64,9.16;5,74.40,216.93,117.28,9.16">Yale 3.0, Yet Another Learning Environment. User Guide, Operator Reference</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Klinkenberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mierswa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Ritthoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Dortmund, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Dortmund, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="5,60.42,241.65,431.34,9.16;5,74.40,252.53,417.24,9.69;5,74.40,264.45,194.76,9.16" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,211.68,241.65,280.08,9.16;5,74.40,252.93,34.75,9.16">Textual Entailment Recognition Based on Dependency Analysis and WordNet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,138.24,252.53,348.61,9.69">Proceedings of the First PASCAL Recognizing Textual Entailment Workshop</title>
		<meeting>the First PASCAL Recognizing Textual Entailment Workshop<address><addrLine>Southampton, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-04">April 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,60.42,277.25,431.82,9.69;5,74.40,288.53,417.24,9.69;5,74.40,300.45,69.48,9.16" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,260.88,277.65,151.33,9.16">UNED at PASCAL RTE2 Challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,430.80,277.25,61.44,9.69;5,74.40,288.53,319.66,9.69">Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment</title>
		<meeting>the Second PASCAL Challenges Workshop on Recognising Textual Entailment<address><addrLine>Venezia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-04">April 2006</date>
			<biblScope unit="page">3843</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
