<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.26,146.21,400.46,18.08;1,171.71,168.13,259.56,18.08">BRUJA System. The University of Jaén at the Spanish task of CLEFQA 2006</title>
				<funder ref="#_AzkJVjg">
					<orgName type="full">Spanish Government (MCYT)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.35,203.19,124.06,10.46"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>García-Cumbreras</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,328.57,203.19,78.07,10.46"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña-López</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,189.40,217.13,82.95,10.46"><forename type="first">Martínez</forename><surname>Fernando</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.66,217.13,71.18,10.46"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Santiago</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.11,217.13,57.50,10.46"><surname>Perea-Ortega</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.26,146.21,400.46,18.08;1,171.71,168.13,259.56,18.08">BRUJA System. The University of Jaén at the Spanish task of CLEFQA 2006</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3F3FBFB1F8F363C3D06E5E4D51E33300</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Algorithms, Languages, Performance, Experimentation Information Retrieval, Question Answering for Spanish, Named Entity Recognition, Natural Language Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents our first participation in the bilingual English-Spanish track at CLEF QA 2006. The Multilingual BRUJA system is presented, a Question Answering (QA) system that works with questions in several languages and also collections in several languages. The BRUJA system is currently in its first phase of develop, so we have only run one official experiment with questions into English and the collection into Spanish. The results obtained shown that the prototype and its answer extraction phase, have to be finished and improved. An overall accuracy of 20.53% in not a good result and the system is in progress.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A Question Answering (QA) system seeks and shows the user an accurate and concise answer, given a free-form question, and using a large text data collection.</p><p>The use of Cross Language Information Retrieval Systems (CLIR) is growing, and also the application of these ones into other general systems, such as Question Answering or Question Classification.</p><p>A CLIR system is an Information Retrieval System that works with collections in several languages, and extract relevant documents or passages <ref type="bibr" coords="1,331.40,670.89,9.96,10.46" target="#b1">[2]</ref>.</p><p>The Cross-Language Evaluation Forum (CLEF) includes a multilingual forum to evaluate Question Answering Systems that works with several languages <ref type="bibr" coords="1,363.17,694.80,12.79,10.46" target="#b2">[3]</ref>. This is the first participation for the SINAI research group at the CLEF-QA task. We have accomplished a bilingual task, from English to Spanish.</p><p>The goal of this bilingual task is to answer a set of questions, where there is a questions language (English) and a different collection language (Spanish), so it is necessary to translate the set of questions.</p><p>We present the BRUJA system (in Spanish, Búsqueda de Respuestas University of JAén), a prototype of a complete multilingual QA system, based on NLP tools <ref type="bibr" coords="2,422.53,158.36,9.96,10.46" target="#b3">[4]</ref>, that works with questions in several languages (actually three languages, English, Spanish and French) and also with collections in several languages (the same three).</p><p>We have combine different modules, in order to evaluate the system in different points, that are explained in the following sections.</p><p>Next Section describes the system architecture and some details of each module. In Section 3 we explain the main experiments and the results. Finally, conclusions and further works are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>In this section our multilingual QA system is presented.</p><p>The development of the BRUJA system is in its first phase, so some modules are not finished yet and others are tuned and corrected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>The BRUJA system is a prototype of a complete multilingual Question Answering system, that works with questions into Spanish, English or French, and the collection datasets are also into these three languages.</p><p>Basically, when a new question arise it is translated to the other languages and the original questions and its translations are launched over its collection index. Then it is necessary to merge the monolingual lists of relevant documents or passages and one multilingual relevant list is returned, like an usual Cross Language Information Retrieval system (CLIR).</p><p>In some steps we use English as the pivot language, and we apply online machine translators if it is necessary.</p><p>In the figure <ref type="figure" coords="2,162.25,474.60,4.98,10.46" target="#fig_0">1</ref> we can see the architecture of the BRUJA system.</p><p>In the following sections we describe each module in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Translation and Question Analysis</head><p>This is the first phase of the QA system.</p><p>When a new question arise we detect its language, and if it is different from English we translated it to English. We use SYMTRAM (our Machine Translation system that works with different online machine translators and implements some heuristics).</p><p>We do that because our preprocessing methods work with English questions, in order to improve the result of this phase. We make the preprocessing phase using the GATE architecture (REF).</p><p>For the main process and for the next one, the Question Classification, some lexical, syntatic and semantic features and the keywords are extracted.</p><p>After that, we run our Question Classification (QC) subsystem, that classify the question in a general class (ABBR, DESC, ENTY, HUM, LOC or NUM). Other experiments give us a high confidence in its module, with results around a 90% of F-score <ref type="bibr" coords="2,377.15,652.38,9.96,10.46" target="#b0">[1]</ref>. Our Question Classifier is based on machine learning, automatic online translators and different language features. It works with English collections and English monolingual questions or bilingual pairs (Spanish to English or French to English).</p><p>As data of this first phase we obtain relevant features, such as the focus of the questions, and the general class of the question. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relevant passages versus relevant documents</head><p>In the Information Retrieval subsystem we first preprocess the collections, using also GATE, and then we index these collections. In order to improve the results of this step we index documents using LEMUR (REF) and passages using the IR-n (REF) system developed at the University of Alicante.</p><p>After that we combine the results with a simple voting system. We sum the score of each individual relevant docid.</p><p>The idea of the multilingual system is that it would have to join the lists of relevant passages from the different languages, to obtain one multilingual list. Because the merging module has not finished yet we have only worked with the Spanish list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Passage selection improvement</head><p>Before to extract the answers we try to improve the passage selection. By default we take only the 10 first passages for each question. The idea is to decrease the time consumption of the general system.</p><p>In this phase we apply some heuristics that depends of the question class.</p><p>For instance if the class of a question is LOC we expect that the answer is a location. In this case we take the ten first passages that contains any location. To do that we apply some Named Entity Recognition methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Answers extraction</head><p>The final step of the QA system is the answer extraction. This module takes the list of relevant passages and extract and score the possible answers for each question.</p><p>In the first step some patterns and heuristics are applied. The second step of the subsystem will be based on logic and machine learning, but it is under development.</p><p>In order to check the first prototype we have only tried to answer factual questions and some patterns for definitional questions.</p><p>For the factual ones some rules have been implemented, based on the question class. For instance for HUM questions Person Entities have been identified and extracted from the first ten relevant passages; for LOC questions Location Entities.</p><p>In order to score the final answers a simple method has been applied. If the keywords of the question appear in the passage the score of the answers increase.</p><p>For the definitional questions some patterns are applied, for instance:</p><p>• Question:</p><p>-What is Linux? (Qué es Linux?, in Spanish)</p><p>• Some patterns:</p><p>-Linux is DEF -DEF, Linux -Linux, DEF Finally, for the answers file, if the score is below 0.5, we consider that it is an incorrect answer, and NIL is written.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes the result obtained with the simple run sent and the evaluation. The proposed system was applied to the set of 200 questions, although only factual questions and some definitional have been used.</p><p>Table <ref type="table" coords="4,132.34,654.62,4.98,10.46" target="#tab_0">1</ref> shows the results for our run.</p><p>The results shown that the answer extraction module don't work properly, and only a low percent of factual questions have good answers.</p><p>For Factoid questions a simple manual analysis of the experiment gave us some reasons about the results obtained.</p><p>• Some questions have not real relevant passages. This happen, for instance, when the focus words have not identified well, and the others keywords appear in the relevant passage.</p><p>• In the cases where relevant passages contains the possible answer we count on the goodness of the Named Entity Recognition system, and sometimes it fails or didn't recognize the entities.</p><p>For Definition questions the same manual analysis give us some reasons. The main one is that there are a lot of patterns, and the use of only some of them is not enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future work</head><p>For our first participation in QA@CLEF track we proposed a prototype of a multilingual QA system, that works with English and Spanish questions, to search Spanish relevant documents.</p><p>For this prototype only the answers extraction was in its first phase, so the results are obviously not good, but with the experimentation made we will evaluate the multilingual system in different points.</p><p>As future work we will finish and tuning each module. The next important task is to evaluate the experiments made this year and develop the answer extraction module based on logic and machine learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,218.52,462.65,165.96,10.46;3,190.95,109.09,221.07,340.10"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: BRUJA system architecture</figDesc><graphic coords="3,190.95,109.09,221.07,340.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,161.43,109.34,280.15,139.92"><head>Table 1 :</head><label>1</label><figDesc>General results for the bilingual English-Spanish run</figDesc><table coords="4,161.43,109.34,24.22,10.46"><row><cell>Right</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgments</head><p>This work has been supported by <rs type="funder">Spanish Government (MCYT)</rs> with grant <rs type="grantNumber">TIC2003-07158-C04-04</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AzkJVjg">
					<idno type="grant-number">TIC2003-07158-C04-04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,425.74,387.16,12.98;5,105.50,440.22,407.50,10.46;5,105.50,452.17,229.17,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,310.37,428.26,182.29,10.46;5,105.50,440.22,217.57,10.46">Bruja: Question classification for spanish. using machine translation and an english classifier</title>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>García Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ureña</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,343.40,440.22,169.60,10.46;5,105.50,452.17,199.03,10.46">Conference of the European Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,472.10,407.50,10.46;5,105.50,484.05,164.44,10.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,238.69,472.10,165.60,10.46">Cross-Language Information Retrieval</title>
		<editor>Gregory Grefenstette</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer academic publishers</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>Boston, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,503.97,407.52,10.46;5,105.50,515.94,407.51,10.46;5,105.50,527.89,403.96,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,271.18,503.97,179.90,10.46">Question answering pilot task at clef 2004</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,390.58,515.94,122.43,10.46;5,105.50,527.89,127.62,10.46">Advances in Cross-Language Information Retrieval, CLEF</title>
		<title level="s" coord="5,263.14,527.89,152.87,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="445" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,547.82,407.51,10.46;5,105.50,559.77,407.51,10.46;5,105.50,571.72,407.50,10.46;5,105.50,583.68,119.02,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,481.46,547.82,31.55,10.46;5,105.50,559.77,129.66,10.46">Aliqan, spanish qa system at clef-2005</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tomás</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,171.53,571.72,252.37,10.46">Advances in Cross-Language Information Retrieval, CLEF</title>
		<title level="s" coord="5,452.81,571.72,60.19,10.46;5,105.50,583.68,88.72,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
