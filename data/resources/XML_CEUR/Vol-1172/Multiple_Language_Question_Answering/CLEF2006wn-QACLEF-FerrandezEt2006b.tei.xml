<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.63,146.21,421.72,18.08;1,157.76,168.13,287.45,18.08">A Knowledge-based Textual Entailment Approach applied to the QA Answer Validation at CLEF 2006</title>
				<funder ref="#_tRHFfDx">
					<orgName type="full">Spanish Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,141.32,200.67,53.49,12.98"><forename type="first">Ó</forename><surname>Ferrández</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.67,203.19,49.66,10.46"><forename type="first">R</forename><forename type="middle">M</forename><surname>Terol</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.85,203.19,40.41,10.46"><forename type="first">R</forename><surname>Muñoz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.97,203.19,79.77,10.46"><forename type="first">P</forename><surname>Martínez-Barco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,411.43,203.19,51.65,10.46"><forename type="first">M</forename><surname>Palomar</surname></persName>
							<email>mpalomar@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Software and Computing Systems</orgName>
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.63,146.21,421.72,18.08;1,157.76,168.13,287.45,18.08">A Knowledge-based Textual Entailment Approach applied to the QA Answer Validation at CLEF 2006</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A806B06E2A6A47E0B61E0C413596D8B5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Algorithms</term>
					<term>Semantic Similarity</term>
					<term>Experimentation</term>
					<term>Measurement</term>
					<term>Performance Question Answering</term>
					<term>Answer Validation</term>
					<term>Textual Entailment</term>
					<term>WordNet</term>
					<term>Semantic Relations</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Answer Validation Exercise (AVE) is a pilot track within the Cross-Language Evaluation Forum (CLEF) 2006. The AVE competition provides an evaluation framework for answer validations in Question Answering (QA). In our participation in AVE, we propose a system that has been initially used for other task as Recognising Textual Entailment (RTE). The aim of our participation is to evaluate the improvement our system brings to QA. Moreover, due to the fact that these two task (AVE and RTE) have the same main idea, which is to find semantic implications between two fragments of text, our system has been able to be directly applied to the AVE competition. Our system is based on the representation of the texts by means of logic forms and the computation of semantic comparison between them. This comparison is carried out using two different approaches. The first one managed by a deeper study of the Word-Net relations, and the second uses the measure defined by Lin in order to compute the semantic similarity between the logic form predicates. Moreover, we have also designed a voting strategy between our system and the MLEnt system, also presented by the University of Alicante, with the aim of obtaining a joint execution of the two systems developed at the University of Alicante. Although the results obtained have not been very high, we consider that they are quite promising and this supports the fact that there is still a lot of work on researching in any kind of textual entailment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Answer Validation Exercise (AVE) is a pilot track within the Cross-Language Evaluation Forum (CLEF) 2006. The aim of AVE is to provide an evaluation framework for answer validations in Question Answering (QA) systems. This automatic Answer Validation would be useful for improving the performance of QA systems, helping humans in the assessment of QA systems output, improving QA systems self-score, developing better criteria for collaborative QA systems, etc.</p><p>The organizers of AVE took an answer plus a snippet given by a QA system, and they built a hypothesis turning the question plus the answer into an affirmative form. If the given text (a snippet or a document) semantically entails this hypothesis, then the answer is expected to be correct. They provided pairs text-hypothesis for the participants which have to determine if the entailment holds. The final purpose is quite similar to the purpose of other challenges as the PASCAL Recognising Textual Entailment <ref type="bibr" coords="2,276.30,194.22,9.96,10.46" target="#b0">[1]</ref>.</p><p>In a nutshell, the participant systems must emulate human assessments of QA responses and decide whether an answer is correct or not according to a given snippet.</p><p>In our participation in AVE, we want to evaluate the positive impact that our system can produce in the context of QA. Initially, our system was developed for Recognising Textual Entailment (RTE) by means of snippets in English language. However, due to the fact that these two task (AVE and RTE) have the same main idea, which is to find semantic implications between two fragments of text, our system has been able to be directly applied to the AVE competition.</p><p>The rest of this paper is organized as follows. The following section presents the description of our system and its components. Section 3 illustrates the experiments carried out and the results obtained. Finally, section 4 wraps up the paper with some conclusions and future work proposals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>As we have mentioned in the previous section, the system that we describe here has already been used to solve Textual Entailment. A detailed description of our system is depicted in <ref type="bibr" coords="2,466.27,380.50,9.96,10.46" target="#b5">[6]</ref>. In this paper, we only make a brief overview of the components that our system is composed of, and how these components work in order to find an entailment relation between two text fragments.</p><p>Our system has two main components: (i) the first one obtains the logic forms associated to each text; and (ii) the second computes the semantic similarity between the aforementioned logic forms. These components will be detailed in the followings paragraphs. The process our system follows is the following:</p><p>1. It obtains the logic forms from the two given texts.</p><p>2. It computes the semantic similarity between the generated logic forms. This step will provide a semantic weight that will determine a true or false entailment.</p><p>3. It compares the semantic weight obtained in the previous step to an empiric threshold acquired from the development corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Derivation of the Logic Forms</head><p>A logic form can be defined as a set of predicates related among them which have been inferred from a sentence. The aim of using logic forms is to simplify the sentence treatment process.</p><p>In our approach, we use a format for representing logic forms similar to the format of the lexical resource called Logic Form Transformation of eXtended WordNet (LFT) <ref type="bibr" coords="2,411.68,618.06,9.96,10.46" target="#b1">[2]</ref>. And the process to infer the logic form associated of a sentence is through applying NLP rules to the dependency relationship of the words. Thus, the first step is to obtain the dependency relationships between the words of the sentence. We use MINIPAR <ref type="bibr" coords="2,286.98,653.93,9.96,10.46" target="#b3">[4]</ref>, a broad-coverage parser, in order to obtain these dependency relationships.</p><p>Once the dependency relationships have been acquired, the next step is the analysis of these dependencies by means of several NLP rules that transform the dependency tree into its logic form associated.</p><p>To sum up, the derivation of logic forms consists of a compositional process that starts in the leaves of the dependency tree, continues through the ramifications and ends in the root of the dependency tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Computation of Similarity Measures</head><p>The main idea of this component is that the verbs generally govern the meaning of sentences. For this reason, this method is initially focused on analysing semantic relations between the verbs of the two logic forms derived from the text and the hypothesis respectively. And secondly, if there is a relation between the verbs, then the method will analyse the similarity relations between all predicates depending on the two verbs. In the case of there is not semantic relations between the verbs, this method will not analyse any more logic form predicate.</p><p>In order to obtain the similarity between the predicates of the logic forms, two approaches have been implemented:</p><p>• Based on WordNet relations: we determine if two predicates are related through the composition of the WordNet relationships. We consider hyponymy, entailment and synonymy WordNet relations between the predicates from the text to the hypothesis. And, if there is a path which connects these two predicates, we conclude that these predicates are semantically related with a specific weight. The length of the path that relates the two different predicates must be lower or equal than 4. Each WordNet relation has assigned a weight, and the weight of the path is calculated as the product of the weights associated to the relations connecting the two predicates.</p><p>• Based on Lin's measure <ref type="bibr" coords="3,237.57,336.15,11.46,10.46" target="#b4">[5]</ref>: in this case, the semantic similarities were computed using Lin's similarity measure as is implemented in WordNet::Similarity<ref type="foot" coords="3,414.14,347.03,3.97,7.32" target="#foot_0">1</ref> [7]. Lin's similarity measure augments the information content of the least common subsumer (LCS<ref type="foot" coords="3,458.83,358.99,3.97,7.32" target="#foot_1">2</ref> ) of the two concepts with the sum of the information content of the concepts themselves. The Lin's measure scales the information content of the LCS by this sum.</p><p>A Word Sense Disambiguation module was not employed in deriving the WordNet relations between any two predicates. Only the first 50% of the WordNet senses were taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">UA-voting</head><p>As the University of Alicante has two systems based on different techniques which solve the recognition of Textual Entailment. We want to evaluate each system in the very recent AVE task individually as well as check how a combination of these two systems could improve the results. The systems involved in this experiment were: our system explained in this paper and the system presented by Kozareva et al. <ref type="bibr" coords="3,218.52,509.95,9.96,10.46" target="#b2">[3]</ref>, called MLEnt.</p><p>For the purpose of testing this combination, we sent a run combining the outputs of the two systems. This combination was carried out for English language and we merged the outputs with the simplest method to combine systems, a voting strategy.</p><p>We composed the final output by means of three different outputs. The final result suggested by our voting strategy must coincide with two individual outputs. The three considered outputs were: our output with the module of semantic similarity using Lin's measure and two outputs provided by MLEnt regarding two different experiments about skip-grams and the longest common subsequence technique<ref type="foot" coords="3,187.80,604.51,3.97,7.32" target="#foot_2">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>For the development and test of our system, we used the corpus provided by the AVE organizers. The corpora consist of a set of pair text-hypothesis built semi-automatically from QA@CLEF 2006 responses and the results returned by the participants will be evaluated against the QA human assessments.</p><p>The development corpus for English has around 2870 pairs test-hypothesis, but only 168 are revised manually. We only used the revised pairs in order to adjust our system for the AVE task. The test data contains 2088 pairs, and all the results obtained are shown in Table <ref type="table" coords="4,467.85,134.45,3.87,10.46" target="#tab_0">1</ref>. In this table, we illustrate the results achieved by our two semantic similarity approaches individually (see section 2.2) and the results obtained regarding UA-voting experiment (see section 2.3). As we can observe in Table <ref type="table" coords="4,223.91,307.58,3.87,10.46" target="#tab_0">1</ref>, all the results are quite similar with respect to F-measure. Using the approach based on Lin's semantic similarity measure our system achieved better recall than using the approach about WordNet relations. However, these differences are insignificant to decide what approach works better for the AVE task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Development data Precision YES pairs</head><p>The run corresponding to the combination of the two systems developed at the University of Alicante did not achieve the expected results. These results prove that we have to investigate other ways in order to combine the outputs of the systems, other voting strategies or, perhaps to join the two different technologies of each system in order to create only one system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>In this paper, we have presented a system based on the representation of the texts by means of logic forms and the computation of semantic comparison between them. This comparison is carried out using two different approaches. The first one managed by a deeper study of the WordNet relations between the predicates of the text and the hypothesis, and the second uses the measure defined by Lin <ref type="bibr" coords="4,121.68,493.85,10.52,10.46" target="#b4">[5]</ref> in order to compute the semantic similarity between the logic form predicates.</p><p>This system has already been applied to Recognising Textual Entailment (see <ref type="bibr" coords="4,446.69,505.81,10.30,10.46" target="#b5">[6]</ref>), but in this case the aim of applying it to the AVE task was to check the improvement our system brings to QA. Moreover, we also present in this paper a voting strategy combining the two systems developed at the University of Alicante: our system and the system presented by Kozareva et al. <ref type="bibr" coords="4,90.01,553.63,10.52,10.46" target="#b2">[3]</ref> for the AVE task.</p><p>The results obtained have not been very high, but quite promising. However, we want to attach great importance to the fact that, in the RTE-2 Challenge <ref type="bibr" coords="4,378.47,577.54,10.52,10.46" target="#b0">[1]</ref> our system achieved 60% in average precision, but for the AVE task the result has decreased dramatically. This supports the claim that research in any kind of textual entailment is still at the very first steps and so, there is a long way to go.</p><p>As a future work, We want to investigate in depth the corpus provided by AVE and find the cases that our system fails and why. Possibly, in order to solve these deficiencies of our system, we need to improve our method by investigating in more detail the syntactic trees of the text and the hypothesis and how the addition of other NLP tools such as a Named Entity Recognizer could help in detecting entailment between two segments of text. Finally, with this kind of knowledge we will be able to integrate our system within a module performing answer validation for QA.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,149.79,181.72,300.33,112.96"><head>Table 1 :</head><label>1</label><figDesc>AVE 2006 officials results for English language</figDesc><table coords="4,327.57,181.72,122.55,9.41"><row><cell>Recall YES pairs F-measure</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,713.55,185.97,8.37"><p>http://www.d.umn.edu/∼tpederse/similarity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.24,723.05,267.05,8.37"><p>LCS is the most specific concept that two concepts share as an ancestor</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,105.24,732.56,93.17,8.37"><p>For further details see<ref type="bibr" coords="3,189.47,732.56,8.94,8.37" target="#b2">[3]</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research has been partially funded by the <rs type="funder">Spanish Government</rs> under project <rs type="projectName">CICyT</rs> number <rs type="grantNumber">TIC2003-07158-C04-01</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_tRHFfDx">
					<idno type="grant-number">TIC2003-07158-C04-01</idno>
					<orgName type="project" subtype="full">CICyT</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,199.08,407.51,10.46;5,105.50,211.03,407.50,10.46;5,105.50,222.99,405.31,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,173.64,211.03,280.89,10.46">The Second PASCAL Recognising Textual Entailment Challenge</title>
		<author>
			<persName coords=""><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,463.34,211.03,49.66,10.46;5,105.50,222.99,325.83,10.46">Proceedings of the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</title>
		<meeting>the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,242.91,407.52,10.46;5,105.50,254.88,407.50,10.46;5,105.50,266.83,143.02,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,313.38,242.91,199.64,10.46;5,105.50,254.88,105.34,10.46">WordNet 2 -A Morphologically and Semantically Enhanced Resource</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">I</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,230.56,254.88,277.93,10.46">Proceedings of ACL-SIGLEX99: Standardizing Lexical Resources</title>
		<meeting>ACL-SIGLEX99: Standardizing Lexical Resources<address><addrLine>Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,286.75,407.50,10.46;5,105.50,298.71,407.50,10.46;5,105.50,310.66,169.97,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,282.54,286.75,230.46,10.46;5,105.50,298.71,108.99,10.46">MLEnt: The Machine Learning Entailment System of the University of Alicante</title>
		<author>
			<persName coords=""><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrés</forename><surname>Montoyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,222.16,298.71,290.84,10.46;5,105.50,310.66,80.52,10.46">Proceedings of the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</title>
		<meeting>the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="16" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,330.59,407.50,10.46;5,105.50,342.54,233.41,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,141.60,330.59,175.79,10.46">Dependency-based evaluation of minipar</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,339.53,330.59,173.46,10.46;5,105.50,342.54,32.71,10.46">Workshop on the Evaluation of Parsing Systems</title>
		<meeting><address><addrLine>Southampton, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-04">April 2005</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,362.47,407.50,10.46;5,105.50,374.42,407.51,10.46;5,105.50,386.38,223.91,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,163.56,362.47,215.05,10.46">An Information-Theoretic Definition of Similarity</title>
		<author>
			<persName coords=""><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,400.31,362.47,112.68,10.46;5,105.50,374.42,265.59,10.46">ICML &apos;98: Proceedings of the Fifteenth International Conference on Machine Learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,106.88,403.79,406.14,12.98;5,105.50,418.26,407.52,10.46;5,105.50,430.21,407.50,10.46;5,105.50,442.17,121.08,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,130.97,418.26,382.05,10.46;5,105.50,430.21,52.69,10.46">An Apporach based on Logic Forms and WordNet relationships to Textual Entailment Preformance</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Óscar Ferrández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Terol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patricio</forename><surname>Mu Noz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Martínez-Barco</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,167.90,430.21,345.10,10.46;5,105.50,442.17,31.63,10.46">Proceedings of the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</title>
		<meeting>the Second PASCAL Recognising Textual Entailment Challenge, RTE-05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="22" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,462.09,407.51,10.46;5,105.50,474.05,407.51,10.46;5,105.50,486.00,216.38,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,370.61,462.09,142.40,10.46;5,105.50,474.05,117.97,10.46">WordNet::Similarity -Measuring the Relatedness of Concepts</title>
		<author>
			<persName coords=""><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Michelizzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,242.51,474.05,270.51,10.46;5,105.50,486.00,98.62,10.46">Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04)</title>
		<meeting>the Nineteenth National Conference on Artificial Intelligence (AAAI-04)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07">July 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
