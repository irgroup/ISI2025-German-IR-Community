<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.92,86.06,363.64,14.82;1,110.10,116.42,375.21,14.82">GeoCLEF 2006: the CLEF 2006 Cross-Language Geographic Information Retrieval Track Overview</title>
				<funder>
					<orgName type="full">POSI)</orgName>
				</funder>
				<funder ref="#_MpnwnXD">
					<orgName type="full">Portuguese FCT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.46,152.82,48.08,9.02"><forename type="first">Fredric</forename><surname>Gey</surname></persName>
							<email>gey@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.71,152.82,46.43,9.02"><forename type="first">Ray</forename><surname>Larson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.35,152.82,65.80,9.02"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
							<email>m.sanderson@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Information Studies</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,170.52,164.34,66.44,9.02"><forename type="first">Kerstin</forename><surname>Bischoff</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.69,164.34,60.88,9.02"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.24,164.34,97.47,9.02"><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.74,175.86,53.13,9.02"><forename type="first">Diana</forename><surname>Santos</surname></persName>
							<email>diana.santos@sintef.no</email>
							<affiliation key="aff3">
								<orgName type="department">Linguateca</orgName>
								<orgName type="institution">SINTEF ICT</orgName>
								<address>
									<country key="NO">NORWAY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.04,175.86,50.90,9.02"><forename type="first">Paulo</forename><surname>Rocha</surname></persName>
							<email>paulo.rocha@di.uminho.pt</email>
							<affiliation key="aff3">
								<orgName type="department">Linguateca</orgName>
								<orgName type="institution">SINTEF ICT</orgName>
								<address>
									<country key="NO">NORWAY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.52,325.14,57.53,9.02"><forename type="first">Giorgio</forename><forename type="middle">M</forename><surname>Di</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.19,325.14,50.88,9.02"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.92,86.06,363.64,14.82;1,110.10,116.42,375.21,14.82">GeoCLEF 2006: the CLEF 2006 Cross-Language Geographic Information Retrieval Track Overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D8023B3F66D93276FE445B004FB6E1DF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>After being a pilot track in 2005, GeoCLEF advanced to be a regular track within CLEF 2006. The purpose of GeoCLEF is to test and evaluate cross-language geographic information retrieval (GIR): retrieval for topics with a geographic specification. For GeoCLEF 2006, twenty-five search topics were defined by the organizing groups for searching English, German, Portuguese and Spanish document collections. Topics were translated into English, German, Portuguese, Spanish and Japanese. Several topics in 2006 were significantly more geographically challenging than in 2005. Seventeen groups submitted 149 runs (up from eleven groups and 117 runs in GeoCLEF 2005). The groups used a variety of approaches, including geographic bounding boxes, named entity extraction and external knowledge bases (geographic thesauri and ontologies and gazetteers).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Existing evaluation campaigns such as TREC and CLEF have not, prior to 2005, explicitly evaluated geographical relevance. The aim of GeoCLEF is to provide the necessary framework in which to evaluate GIR systems for search tasks involving both spatial and multilingual aspects. Participants are offered a TREC style ad hoc retrieval task based on existing CLEF collections. GeoCLEF 2005 was run as a pilot track to evaluate retrieval of multilingual documents with an emphasis on geographic search on English and German document collections. Results were promising, but it was felt that more work needed to be done to identify the research and evaluation issues surrounding geographic information retrieval from text. Thus 2006 was the second year in which GeoCLEF was run as a track within CLEF. For 2006, two additional document languages were added to GeoCLEF, Portuguese and Spanish. GeoCLEF was a collaborative effort by research groups at the University of California, Berkeley (USA) , the University of Sheffield (UK), University of Hildesheim (Germany), Linguateca (Norway and Portugal), and University of Alicante (Spain). Seventeen research groups (increased from eleven in 2005) from a variety of backgrounds and nationalities submitted 149 runs (up from 117 in 2005) to GeoCLEF.</p><p>Geographical Information Retrieval (GIR) concerns the retrieval of information involving some kind of spatial awareness. Given that many documents contain some kind of spatial reference, there are examples where geographical references (geo-references) may be important for IR. For example, to retrieve, re-rank and visualize search results based on a spatial dimension (e.g. "find me news stories about riots near Dublin City"). In addition to this, many documents contain geo-references expressed in multiple languages which may or may not be the same as the query language. For example, the city of Cologne (English) is also Köln (German), Colónia in Portuguese from Portugal, Colônia in Brazilian Portuguese, and Colonia (Spanish). Queries with names such as this may require an additional translation step to enable successful retrieval.</p><p>For 2006, Spanish and Portuguese, in addition to German and English, were added as document languages, while topics were developed in all four languages with topic translations provided for the other languages. In addition the National Institute of Informatics of Tokyo, Japan translated the English version of the topics to Japanese. There were two Geographic Information Retrieval tasks: monolingual (English to English, German to German, Portuguese to Portuguese and Spanish to Spanish) and bilingual (language X to language Y, where X or Y was one of English, German, Portuguese or Spanish and additionally X could be Japanese).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document collections used in GeoCLEF</head><p>The document collections for this year's GeoCLEF experiments are all newswire stories from the years 1994 and 1995 used in previous CLEF competitions. Both the English and German collections contain stories covering international and national news events, therefore representing a wide variety of geographical regions and places. The English document collection consists of 169,477 documents and was composed of stories from the British newspaper The Glasgow Herald (1995) and the American newspaper The Los Angeles Times (1994). The German document collection consists of 294,809 documents from the German news magazine Der Spiegel (1994/95), the German newspaper Frankfurter Rundschau (1994) and the Swiss news agency SDA (1994/95). Although there are more documents in the German collection, the average document length (in terms of words in the actual text) is much larger for the English collection. In both collections, the documents have a common structure: newspaper-specific information like date, page, issue, special filing numbers and usually one or more titles, a byline and the actual text. The document collections were not geographically tagged or contained any other location-specific information. For Portuguese, GeoCLEF 2006 utilized two newspaper collections, spanning over 1994-1995, for respectively the Portuguese and Brazilian newspapers Público (106,821 documents) and Folha de São Paulo (103,913 documents). Both are major daily newspapers in their countries. Not all material published by the two newspapers is included in the collections (mainly for copyright reasons), but every day is represented. The collections are also distributed for IR and NLP research by Linguateca as the CHAVE collection (www.linguateca.pt/CHAVE/, see URL for DTD and document examples).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generating Search Topics</head><p>A total of 25 topics were generated for this year's GeoCLEF. Topic creation was shared among the four organizing groups, each group creating initial versions of their proposed topics in their language, with subsequent translation into English. In order to support topic development, Ray Larson indexed all collections with his Cheshire II document management system and this was made available to all organizing groups for interactive exploration of potential topics. While the aim had been to prepare an equal number of topics in each language, ultimately only two topics (GC026 and GC027) were developed in English. Other original language numbers were German, 8 topics (GC028 to GC035), Spanish, 5 topics (GC036 to GC040) and Portuguese, 10 topics (GC041 to GC050). This section will discuss the processes taken to create the spatially-aware topics for the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic generation</head><p>In GeoCLEF 2005 some criticism arose about the lack of geographical challenges of the topics (favouring keyword-based approaches) and the German task was inherently more difficult because several topics had no relevant documents in the German collections. Therefore geographical and cross-lingual challenge and equal distribution across language collections was considered central during topic generation. Topics should vary according to the granularity and kind of geographic entity and should require adequate handling of named entities within the process of translation (e.g. regarding decompounding, transliteration or translation).</p><p>For English topic generation, Fred Gey simply took two topics he had considered in the past (Wine regions around rivers in Europe and Cities within 100 kilometers of Frankfurt, Germany) and developed them. The latter topic (GC027) evolved into an exact specification of the latitude and longitude of Frankfurt am Main (to distinguish it from Frankfurt an der Oder) in the narrative section. Interactive exploration verified that documents could be found which satisfied these criteria on the basis of geographic knowledge by the proposer (i.e. the Rhine and Moselle valleys of Germany and cities Heidelberg, Koblenz, Mainz, and Mannheim near Frankfurt).</p><p>The German group at Hildesheim started with brain storming on interesting geographical notions and looking for potential events via the Cheshire II Interface, we unfortunately had to abandon all smaller geographic regions soon. Even if a suitable number of relevant documents could be found in one collection, most times there were few or no respective documents in the other language collections. This may not be surprising, because within the domain of news criteria like (inter)national relevance, prominence, elite nation or elite person besides proximity, conflict/negativism and continuity etc. (for an overview see Eidlers <ref type="bibr" coords="3,338.99,188.19,11.83,8.74" target="#b1">[2]</ref>) are assumed to affect what will become a news article. Thus, the snow conditions or danger of avalanches in Grisons (canton in Switzerland) may be reported frequently by the Swiss news agency SDA or even German newspapers, whereas the British or American newspapers may not see the relevance for their audience. In addition, the geographically interesting issue of tourism in general is not well represented in the German collection. As a result well known places and larger regions as well as international relevant or dramatic concepts had to be focused on, although this may not reflect all user needs for GIR systems (see also ). In order not to favor systems relying purely on keywords we concentrated on more difficult geographic entities like historical or political names used to refer geographically to a certain region and imprecise regions like the Ruhr or the Middle East. Moreover some topics should require the use of external geographic knowledge e.g. to identify cities onshore of the Sea of Japan or the Tropics. The former examples introduce ambiguity or translation challenges as well. Ruhr could be the river or the area in Germany and the Middle East may be translated to German Mittlerer Osten, which is nowadays often used, but would denote a slightly different region. The naming of the Sea of Japan is difficult as it depends on the Japanese and Western perspective, whereas in Korea it would be named East Sea (of Korea). After checking such topic candidates for relevant documents in other collections we proposed eight topics, which we thought would contribute to a topic set varying in thematic content and system requirements.</p><p>The GeoCLEF topics proposed by the Portuguese group (a total of 10) were discussed between Paulo Rocha and Diana Santos, according to an initial typology of possible geographical topics (see below for a refined one) and after having scrutinized the frequency list of proper names in both collections, manually identifying possible places of interest. Candidate topics were then checked in the collections, using the Web interface to the AC/DC project <ref type="bibr" coords="3,97.37,441.14,11.46,8.74" target="#b6">[7]</ref>, to investigate whether they were well represented. We included some interesting topics from a Portuguese (language) standpoint, including "ill-defined" or at least little known regions in an international context, such as norte de Portugal (North of Portugal) or Nordeste brasileiro (Brazilian Northeast). Basically, they are very familiar and frequently used concepts in Portuguese, but have not a purely geographical explanation. Rather, they have a strongly cultural and historical motivation. We also inserted a temporally dependent topic (outdated Champion's Cup, now Champion's League -and already in 1994-1995 as well, but names continue their independent life in newspapers and in folk's stock of words). This topic is particularly interesting, since it in addition concerns "European" football, where one of the partners is (non-geographically-European) Israel.</p><p>We also strove to find topics which included more geographical relations than mere "in" (homogeneous region), as well as different location types as far as grain and topology are concerned. As to the first concern, note that although "shipwrecks in the Atlantic Ocean" seem to display an ordinary "in"-relation, shipwrecks are often near the coasts, and the same is still more applicable about topics such as "fishing in Newfoundland", where it is presupposed that you fish on the sea near the place (or that you are concerned with the impact of fishing to Newfoundland). Likewise, anyone who knows what ETA stands for would at once expect that "ETA's activities in France" would be mostly located in the French Basque country (and not anywhere in France).</p><p>For the second concern, that of providing different granularity and/or topology, note that the geographical span of forest fires is clearly different from that of lunar of solar eclipses (a topic suggested by the German team). As to form of the region, the "New England universities" topic circumscribes the "geographical region" to a set of smaller conceptual "regions", each represented by a university. Incidentally, this topic displays another complication, because it involves a multiword named entity: not only "New England" is made up of two different words but both are very common and have a specific meaning on its own (in English and Portuguese alike). This case is further interesting because it would be as natural to say New England in Portuguese as Nova Inglaterra, given that the name is not originally Portuguese.</p><p>We should also report interesting problems caused by translation into Portuguese from topics originally stated in other languages (they are not necessarily translation problems, but were spotted because we had to look into the particular cases of those places or expressions). For example, Middle East can be equally translated by Próximo Oriente and Médio Oriente, and it is not politically neutral how precisely in that area some places are described. For example, we chose to use the word Palestina (together with Israel) and leave out Gaza Strip (which, depending on political views, might be considered a part of both). What is interesting here is that the political details are absolutely irrelevant for the topic in question (which deals with archaeological findings), but the GeoCLEF organizers (in common) decided to specify a lower level, or a higher precision description, of every location/area mentioned, in the narrative, so that a list of Middle East countries and regions had to be supplied, and agreed upon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Format of topic description</head><p>The format of GeoCLEF 2006 differed from that of 2005. No explicit geographic structure was used this time, although such a structure was discussed by the organizing groups. Two example topics are shown in Figure <ref type="figure" coords="4,505.29,222.69,3.77,8.74" target="#fig_0">1</ref>. As can be seen, after the brief descriptions within the title and description tags, the narrative tag contains detailed description of the geographic detail sought and the relevance criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Several kinds of geographical topics</head><p>We came up with a tentative classification of topics according to the way they depend on place (in other words, according to the way they can be considered "geographic"), which we believe to be one of the most interesting results of our participation in the choice and topic formulation for GeoCLEF. Basically, this classification was done as an answer to the overall too simplistic assumption of first GeoCLEF <ref type="bibr" coords="4,376.79,562.11,15.07,8.74" target="#b2">[3]</ref>, namely the separation between subject and location as if the two were independent and therefore separable pieces of information. (Other comments to the unsuitability of the format used in GeoCLEF can be found in Santos and Cardoso <ref type="bibr" coords="4,471.45,585.09,12.94,8.74" target="#b7">[8]</ref>, and will not be repeated here.) While it is obvious that in some (simple) cases geographical topics can be modeled that way, there's much more to place and to the place of place in the meaning of a topic than just that, as we hope this categorization can help making clear:  geographical relations among (places associated to) events (Did Waterloo occur more north than the battle of X? Were the findings of Lucy more to the south than those of the Cromagnon in Spain?) 8 relations between events which require their precise localization (was it the same river that flooded last year and in which killings occurred in the XVth century?)</p><p>Note that we here are not even dealing with the obviously equally relevant interdependence of the temporal dimension, already mentioned above, and which was actually extremely conspicuous in the preliminary discussions among this year's organizing teams, concerning the denotation of "former Eastern bloc countries" and "former Yugoslavia" now (that is, in <ref type="bibr" coords="5,236.00,188.19,17.91,8.74">[1994]</ref><ref type="bibr" coords="5,258.39,188.19,22.38,8.74">[1995]</ref>. In a way, as argued in Santos and Chaves <ref type="bibr" coords="5,450.28,188.19,13.08,8.74" target="#b8">[9]</ref>, which countries or regions to accept as relevant depends ultimately on the user intention (and need). Therefore, pinning down the meaning of a topic depends on geographical, temporal, cultural, and even personal constraints, that are intertwined in a complex way, and more often than not do not allow a clear separation. To be able to make sense of these complicated interactions and arrive at something relevant for a user by employing geographical reasoning seems one of the challenges that lies ahead in future GeoCLEF tracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approaches to Geographic Information Retrieval</head><p>The participants used a wide variety of approaches to the GeoCLEF tasks, ranging from basic IR approaches (with no attempts at spatial or geographic reasoning or indexing) to deep NLP processing to extract place and topological clues from the texts and queries. Specific techniques used included:</p><p>• Ad-hoc techniques (blind feedback, German word decompounding, manual query expansion)</p><p>• Gazetteer construction (GNIS, World Gazetteer)</p><p>• Gazetteer-based query expansion • Question-answering modules utilizing passage retrieval • Geographic Named Entity Extraction • Term expansion using Wordnet • Use of geographic thesauri (both manually and automatically constructed)</p><p>• Resolution of geographic ambiguity • NLP -part-of-speech tagging</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance assessment</head><p>English assessment was shared by Berkeley and Sheffield Universities. German assessment was done by the University of Hildesheim, Portuguese assessment by Linguateca, and Spanish assessment by University of Alicante. All organizing groups utilized the DIRECT System provided by the University of Padua. The Padua system allowed for automatic submission of runs by participating groups and for automatic assembling of the GeoCLEF assessment pools by language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English relevance assessment</head><p>The English document pool extracted from 73 monolingual and 12 bilingual (language X to) English runs consisted of 17,9xx documents to be reviewed and judged by our 5 assessors or about 3,600 documents per assessor. In order to judge topic GC027 (Cities within 100km of Frankfurt), Ray Larson used data from the GeoNames Information System along with the Cheshire II geographic distance calculation function, to extract and prepare a spreadsheet of populated places whose latitude and longitude was within a distance of 100 km of the latitude and longitude of Frankfurt. This spreadsheet contained 5342 names and was made available to all groups doing assessment. If a document in the pool contained the name of a German city or town, it was checked against the spreadsheet to see if it was within 100km of Frankfurt. Thus documents with well-known names (Mannheim, Heidelberg) were easily recognized, but Mecklenberg (where the German Grand Prix auto race is held) was not so easily recognized. In reading the documents in the pool, we were surprised to find many Los</p><p>Angeles Times documents about secondary school sports events and scores in the pool. A closer examination revealed that these documents contained the references to American students who had the same family name as German cities and towns. It is clear that geographic named entity disambiguation from text still needs some improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>German relevance assessment</head><p>For the pool of German monolingual and bilingual runs X2German 14.094 documents from the newspaper Frankfurter Rundschau, the Swiss news agency SDA and the news magazine Spiegel had to be assessed. Every assessor had to judge a number of assigned topics. Decisions on dubious cases were left open and then discussed within the group and/or the other language co-ordinators. Since many topics had clear, predefined criteria as specified in title, description and narrative, searching first the key concepts and their synonyms within the documents and then identifying their geographical reference led to rejecting the bulk of documents as irrelevant.</p><p>Depending on the geographic entity asked for, manual expansion, e.g., the country names of the Middle East and their capitals, was done to query the DIRECT System provided by the University of Padua. Of course, such a list could never be complete and available resources would not be comprehensive enough to capture all possible expansions (e.g. we could not verify the river Code on the island of Java). Thus skimming over the text was often necessary to capture the documents main topic and geographical scope.</p><p>While judging relevance was generally easier for the short news agency articles of SDA with their headlines, keywords and restriction to one issue, Spiegel articles took rather long to judge, because of their length and essay-like stories often covering multiple events etc. without a specific narrow focus. Many borderline cases for relevance resulted from uncertainties about how broad/narrow a concept term should be interpreted and how explicit the concept must be stated in the document (e.g. do parked cars destroyed by a bomb correspond to a car bombing? Are attacks on foreign journalists and the Turkish invasion air attacks to be considered relevant as fulfilling the concept of combat?). Often it seems that for a recurring news issue it is assumed that facts are already known, so they are not explicitly cited. To keep the influence of order effects minimal is critical here. Similarly, assessing relevance regarding the geographical criterion brought up a discussion on specificity wrt implicit inclusion. In all cases, reference to the required geographic entity had to be explicitly made, i.e., a document reporting about Fishing in the Norwegian Sea or the Greenland Sea without mentioning e.g. a certain coastal city in Greenland or Newfoundland was not considered relevant. Moreover, the borders of oceans and its minor seas are often hard to define (e.g. does Havana, Cuba border the Atlantic Ocean?). Figuring out the location referred to was frequently difficult, when the city mentioned first in an article could have been the domicile of the news agency or/and the city some event occurred in. This was especially true for GC040 active volcanoes and for GC027 cities within 100km from Frankfurt, with Frankfurt being the domicile of the Frankfurter Rundschau, which formed part of the collection. Problems with fuzzy spatial relations or imprecise regions on the other hand did not figure very prominently as they were defined in the extended narratives (e.g. "near" Madrid includes only Madrid and its outskirts) and the documents to be judged did not contain critical cases. However, one my have argued against the decision to exclude all districts of Frankfurt as they do not form own cities, but have a common administration.</p><p>The topic on cities around Frankfurt (GC027) was together with GC050 about cities along the Danube and the Rhine the most difficult one to judge. Although a list of relevant cities containing more than 4000 names was provided by Ray Larson, this could not be used efficiently for relevance assessment to query the DIRECT system. Moreover, the notion of an event or a description made assessment even more time-consuming. We queried about 40 or 50 prominent relevant cities and actually read every document except tabular listings of sports results or public announcements in tabular form. Since the Frankfurter Rundschau is also a regional newspaper, articles on nearby cities, towns and villages are frequent. Would one consider the selling of parking meters to another town an event? Or a public invitation to fruit picking or the announcement of a new vocational training as nurse? As the other assessors did not face such a problem, we decided to be rather strict, i.e. an event must be something popular, public and have a certain scope or importance (not only for a single person or a certain group) like concerts, strikes, flooding or sports. In a similar manner, we agreed on a narrower interpretation of the concept of description for GC026 and for GC050 as something unique or characteristic to a city like statistical figures, historical reviews or landmarks. What would be usually considered a description was not often found due to the kind of collection, likewise relevant documents for GC045 tourism in Northeast Brazil were also few. While the SDA news agency articles will not treat travelling or tourism, such articles may sometimes be found in Frankfurter Rundschau or Spiegel, but there is no special section on that issue.</p><p>Finally, for topic GC027 errors within the documents from the Frankfurter Rundschau will have influenced retrieval results: some articles have duplicates (sometimes even up to four versions), different articles thrown together in one document (e.g. one about Frankfurt and one about Wiesbaden), sentences or passages of articles are missing. Thus a keyword approach may have found many relevant documents, because Frankfurt was mentioned somewhere in the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Portuguese Relevance Assessment</head><p>Details of Portuguese group's assessment are as follows: The assessor tried to find the best collection of keywords -based on the detailed information in the narrative and his/her knowledge of the geographical concepts and subjects involved -and queried the DIRECT system. Often there was manual refinement of the query after finding new spellings in previous hits (note that our collections are written in two different varieties of Portuguese). For example, for topic GC050, "cities along the Danube and the Rhine", the following (final) query was used: where both particular cities were mentioned, as well as words like cidade (city), Frankfurt, distância (distance), and so on. Obviously, the significant passages for all hits were read, to assess whether the document actually mentioned cities near Frankfurt.</p><formula xml:id="formula_0" coords="7,142.68,232.71,34.97,8.74">Danúbio</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GeoCLEF Performance 1 Participants and Experiments</head><p>As shown in Table <ref type="table" coords="7,148.44,427.47,3.74,8.74" target="#tab_2">1</ref>, a total of 17 groups from 8 different countries submitted results for one or more of the GeoCLEF tasks -an increase on the 13 participants of last year. A total of 149 experiments were submitted, which is an increase on the 117 experiments of 2005. There is almost no variation in the average number of submitted runs per participant: from 9 runs/participant of 2005 to 8.7 runs/participant of this year.   Four different topic languages were used for GeoCLEF bilingual experiments. As always, the most popular language for queries was English; German and Spanish tied for the second place. Note that Spanish is a new collection added this year. The number of bilingual runs by topic language is shown in Table <ref type="table" coords="8,444.86,661.65,3.75,8.74" target="#tab_7">4</ref>. Monolingual retrieval was offered for the following target collections: English, German, Portuguese, and Spanish. As can be seen from Table <ref type="table" coords="9,216.69,262.71,3.76,8.74" target="#tab_5">3</ref>, the number of participants and runs for each language was quite similar, with the exception of English, which has the greatest participation. Table <ref type="table" coords="9,365.28,274.17,5.01,8.74" target="#tab_8">5</ref> shows the top five groups for each target collection, ordered by mean average precision. Note that only the best run is selected for each group, even if the group may have more than one top run. The table reports: the short name of the participating group; the run identifier, specifying whether the run has participated in the pool or not; the mean average precision achieved by the run; and the performance difference between the first and the last participant. Table <ref type="table" coords="9,421.88,320.19,5.01,8.74" target="#tab_8">5</ref> regards runs using title + description fields only.</p><p>Note that the top five participants contain both "newcomer" groups (i.e. groups that had not previously participated in GeoCLEF) and "veteran" groups (i.e. groups that had participated in previous editions of GeoCLEF), with the exception of monolingual Portuguese where only "veteran" groups were subscribed. Both pooled and not pooled runs are in the best entries for each track.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bilingual Experiments</head><p>The bilingual task was structured in four subtasks (X → DE, EN, ES or PT target collection). Table <ref type="table" coords="11,471.34,686.79,5.01,8.74" target="#tab_9">6</ref> shows the best results for this task with the same logic of Table <ref type="table" coords="11,284.11,698.31,3.77,8.74" target="#tab_8">5</ref>. Note that the top five participants contain both "newcomer" groups and "veteran" groups, with the exception of monolingual Portuguese and Spanish where only "veteran" groups were subscribed. For bilingual retrieval evaluation, a common method is to compare results against monolingual baselines: • X DE: 70% of best monolingual German IR system</p><p>• X EN: 74% of best monolingual English IR system • X ES: 73% of best monolingual Spanish IR system • X PT: 47% of best monolingual Portuguese IR system Note that the apparently different result for Portuguese may be explained by the fact that the best group in the monolingual experiments did not submit runs for bilingual experiments. If one compares the results per groups, sanmarcos's run of Spanish to Portuguese had even better results than their monolingual Portuguese run, while berkeley's English to Portuguese achieved a similar performance degradation as the one reported for the other bilingual experiments (74%). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,70.62,437.13,399.37,8.74"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Topics GC027: Cities within 100 Kilometers of Frankfurt and GC034: Malaria in the Tropics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,78.18,249.01,23.99,5.62;4,87.78,257.05,76.79,5.62;4,87.78,265.03,254.39,5.62;4,87.78,273.01,388.79,5.62;4,78.18,281.05,119.99,5.62;4,87.78,289.03,407.99,5.62;4,78.18,297.01,427.18,5.62;4,78.18,305.05,422.38,5.62;4,78.18,313.03,23.99,5.62;4,82.98,321.01,28.79,5.62;4,78.18,329.05,23.99,5.62;4,78.18,337.03,86.39,5.62;4,78.18,345.01,215.99,5.62;4,78.18,353.05,407.98,5.62;4,78.18,361.03,403.18,5.62;4,78.18,369.01,417.59,5.62;4,78.18,377.05,393.58,5.62;4,78.18,385.03,417.58,5.62;4,78.18,393.01,321.59,5.62;4,78.18,400.99,28.79,5.62;5,103.56,73.23,421.27,8.74;5,103.56,84.69,195.15,8.74;5,81.96,96.21,5.01,8.74"><head></head><label></label><figDesc>within 100km of Frankfurt&lt;/EN-title&gt; &lt;EN-desc&gt;Documents about cities within 100 kilometers of the city of Frankfurt in Western Germany&lt;/EN-desc&gt; &lt;EN-narr&gt;Relevant documents discuss cities within 100 kilometers of Frankfurt am Main Germany, latitude 50.11222, longitude 8.68194. To be relevant the document must describe the city or an event in that city. Stories about Frankfurt itself are not relevant&lt;/EN-narr&gt; &lt;/top&gt; &lt;top&gt; &lt;num&gt; GC034 &lt;/num&gt; &lt;EN-title&gt; Malaria in the tropics &lt;/EN-title&gt; &lt;EN-desc&gt; Malaria outbreaks in tropical regions and preventive vaccination &lt;/EN-desc&gt; &lt;EN-narr&gt; Relevant documents state cases of malaria in tropical regions and possible preventive measures like chances to vaccinate against the disease. Outbreaks must be of epidemic scope. Tropics are defined as the region between the Tropic of Capricorn, latitude 23.5 degrees South and the Tropic of Cancer, latitude 23.5 degrees North. Not relevant are documents about a single person's infection.&lt;/EN-narr&gt; &lt;/top&gt; geographical relations among places (how are the Himalayas related to Nepal? Are they inside? Do the Himalaya mountains cross Nepal's borders? etc.) 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,70.62,84.69,437.56,8.74"><head>Figures 2 to 5</head><label>5</label><figDesc>Figures 2 to 5 show the interpolated recall vs. average precision for top participants of the monolingual tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,139.38,360.33,316.80,8.10"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Monolingual English top participants. Interpolated Recall vs. Average Precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="10,138.66,640.71,318.25,8.10"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Monolingual German top participants. Interpolated Recall vs. Average Precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,133.14,337.35,329.26,8.10;11,125.64,122.28,344.50,206.46"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Monolingual Portuguese top participants. Interpolated Recall vs. Average Precision.</figDesc><graphic coords="11,125.64,122.28,344.50,206.46" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,138.90,624.39,317.77,8.10;11,125.64,357.66,344.50,258.06"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Monolingual Spanish top participants. Interpolated Recall vs. Average Precision.</figDesc><graphic coords="11,125.64,357.66,344.50,258.06" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="13,125.64,173.94,344.50,154.80"><head></head><label></label><figDesc></figDesc><graphic coords="13,125.64,173.94,344.50,154.80" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,70.62,232.71,454.36,66.22"><head></head><label></label><figDesc>Reno Ulm Ingolstadt Regensburg Passau Linz Krems Viena Bratislava Budapeste Vukovar Novi Sad Belgrado Drobeta-Turnu Severin Vidin Ruse Brăila Galaţi Tulcea Braila Galati Basel Basiléia Basileia Estrasburgo Strasbourg Karlsruhe Carlsruhe Mannheim Ludwigshafen Wiesbaden Mainz Koblenz Coblença Bona Bonn Colónia Colônia Cologne Düsseldorf Dusseldorf Dusseldórfia Neuss Krefeld Duisburg Duisburgo Arnhem Nederrijn Arnhemia Nijmegen Waal Noviomago Utrecht Kromme Rijn Utreque Rotterdam Roterdão. A similar strategy was used for cities within 100 km from Frankfurt am Main (GC027),</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,126.00,485.13,343.59,236.62"><head>Table 1 .</head><label>1</label><figDesc>GeoCLEF 2006 participants -new groups are indicated by *</figDesc><table coords="7,126.00,504.60,343.59,217.15"><row><cell>Participant</cell><cell>Institution</cell><cell>Country</cell></row><row><cell>alicante</cell><cell>University of Alicante</cell><cell>Spain</cell></row><row><cell>berkeley</cell><cell>University of California, Berkeley</cell><cell>United States</cell></row><row><cell>daedalus*</cell><cell>Daedalus Consortium</cell><cell>Spain</cell></row><row><cell>hagen</cell><cell>University of Hagen</cell><cell>Germany</cell></row><row><cell cols="2">hildesheim* University of Hildesheim</cell><cell>Germany</cell></row><row><cell>imp-coll*</cell><cell>Imperial College London (imp-coll)*</cell><cell>United Kingdom</cell></row><row><cell>jaen*</cell><cell>University of Jaen</cell><cell>Spain</cell></row><row><cell>ms-china*</cell><cell cols="2">Microsoft China -Web Search and Mining Group China</cell></row><row><cell>nicta</cell><cell>NICTA, University of Melbourne</cell><cell>Australia</cell></row><row><cell>rfia-upv</cell><cell>Universidad Politècnica de Valencia</cell><cell>Spain</cell></row><row><cell>sanmarcos</cell><cell>California State University, San Marcos</cell><cell>United States</cell></row><row><cell>talp</cell><cell>TALP -Universitat Politècnica de Catalunya</cell><cell>Spain</cell></row><row><cell>u.buffalo*</cell><cell>SUNY at University of Buffalo</cell><cell>United States</cell></row><row><cell cols="2">u.groningen* University of Groningen</cell><cell>The Netherlands</cell></row><row><cell>u.twente*</cell><cell>University of Twente</cell><cell>The Netherlands</cell></row><row><cell>unsw*</cell><cell>University of New S. Wales</cell><cell>Australia</cell></row><row><cell>xldb</cell><cell>Grupo XLDB -Universidade de Lisboa</cell><cell>Portugal</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,70.62,73.23,274.46,8.74"><head>Table 2</head><label>2</label><figDesc>reports the number of participants by their country of origin.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,208.74,96.75,178.06,139.06"><head>Table 2 .</head><label>2</label><figDesc>GeoCLEF 2006 participants by country</figDesc><table coords="8,228.72,115.86,138.06,119.96"><row><cell>Country</cell><cell># Participants</cell></row><row><cell>Australia</cell><cell>2</cell></row><row><cell>China</cell><cell>1</cell></row><row><cell>Germany</cell><cell>2</cell></row><row><cell>Portugal</cell><cell>1</cell></row><row><cell>Spain</cell><cell>5</cell></row><row><cell>The Netherlands</cell><cell>2</cell></row><row><cell>United Kingdom</cell><cell>1</cell></row><row><cell>United States</cell><cell>3</cell></row><row><cell>TOTAL</cell><cell>17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,70.62,263.67,448.30,66.28"><head>Table 3</head><label>3</label><figDesc>provides a breakdown of the experiments submitted by each participant for each of the offered tasks. With respect to last year there is an increase in the number of runs for the monolingual English task (73 runs in 2006 wrt 53 runs of 2005) and a decrease in the monolingual German (16 runs in 2006 wrt 25 runs in 2005); on the other hand, there is a decrease for both bilingual English (12 runs in 2006 wrt 22 runs in 2005) and bilingual German (11 runs in 2006 wrt 17 runs in 2005). Note that the Spanish and the Portuguese collections have been introduced this year.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,120.12,344.31,355.26,266.51"><head>Table 3 .</head><label>3</label><figDesc>GeoCLEF 2006 experiments by task -new collections are indicated by*</figDesc><table coords="8,120.12,364.86,355.26,245.96"><row><cell>Participant</cell><cell cols="8">Monolingual Tasks DE EN ES* PT* X2DE X2EN X2ES* X2PT* Bilingual Tasks</cell><cell>TOTAL</cell></row><row><cell>alicante</cell><cell></cell><cell>4</cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>7</cell></row><row><cell>berkeley</cell><cell>2</cell><cell>4</cell><cell>2</cell><cell>4</cell><cell>2</cell><cell></cell><cell>2</cell><cell>2</cell><cell>18</cell></row><row><cell>daedalus</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>15</cell></row><row><cell>hagen</cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell>10</cell></row><row><cell>hildesheim</cell><cell>4</cell><cell>5</cell><cell></cell><cell></cell><cell>4</cell><cell>5</cell><cell></cell><cell></cell><cell>18</cell></row><row><cell>imp-coll</cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell></row><row><cell>jaen</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell>10</cell></row><row><cell>ms-china</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>nicta</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>rfia-upv</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell></row><row><cell>sanmarcos</cell><cell></cell><cell>5</cell><cell>5</cell><cell>4</cell><cell></cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>21</cell></row><row><cell>talp</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>u.buffalo</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell></row><row><cell>u.groningen</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>u.twente</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>unsw</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>xldb</cell><cell></cell><cell>5</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10</cell></row><row><cell>TOTAL</cell><cell>16</cell><cell>73</cell><cell>15</cell><cell>13</cell><cell>11</cell><cell>12</cell><cell>5</cell><cell>4</cell><cell>149</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,70.62,73.29,330.75,161.32"><head>Table 4 .</head><label>4</label><figDesc>Bilingual experiments by topic language</figDesc><table coords="9,70.62,93.36,330.75,141.26"><row><cell></cell><cell>Track</cell><cell cols="3">Source Language DE EN ES PT</cell><cell>TOTAL</cell></row><row><cell></cell><cell>Bilingual X2DE</cell><cell>11</cell><cell></cell><cell></cell><cell>11</cell></row><row><cell></cell><cell>Bilingual X2EN</cell><cell>7</cell><cell>5</cell><cell></cell><cell>12</cell></row><row><cell></cell><cell>Bilingual X2ES</cell><cell>3</cell><cell></cell><cell>2</cell><cell>5</cell></row><row><cell></cell><cell>Bilingual X2PT</cell><cell>2</cell><cell>2</cell><cell></cell><cell>4</cell></row><row><cell></cell><cell>TOTAL</cell><cell>7 16</cell><cell>7</cell><cell>2</cell><cell>32</cell></row><row><cell>2</cell><cell>Monolingual Experiments</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,73.14,414.63,457.13,335.93"><head>Table 5 .</head><label>5</label><figDesc>Best entries for the monolingual track (title+description topic fields only). Additionally, the performance difference between the best and the last (up to 5) placed group is given (in terms of average precision) -new groups are indicated by *</figDesc><table coords="9,316.02,445.14,74.24,9.02"><row><cell>Participant Rank</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="12,70.62,179.01,464.61,382.78"><head>Table 6 .</head><label>6</label><figDesc>Best entries for the bilingual task (title+description topic fields only). The performance difference between the best and the last (up to 5) placed group is given (in terms of average precision) -new groups are indicated by * 9 show the interpolated recall vs. average precision graph for the top participants of the different bilingual tasks.</figDesc><table coords="12,318.54,209.46,74.24,9.02"><row><cell>Participant Rank</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments:</head><p>The English assessment was by the GeoCLEF organizers was volunteer labor -none of us has funding for GeoCLEF work. Assessment was performed by <rs type="person">Hans Barnum</rs>, <rs type="person">Nils Bailey</rs>, <rs type="person">Fredric Gey</rs>, <rs type="person">Ray Larson</rs>, and <rs type="person">Mark Sanderson</rs>. German assessment was done by <rs type="person">Claudia Bachmann</rs>, <rs type="person">Kerstin Bischoff</rs>, <rs type="person">Thomas Mandl</rs>, <rs type="person">Jens Plattfaut</rs>, <rs type="person">Inga Rill</rs> and <rs type="person">Christa Womser-Hacker</rs> of <rs type="affiliation">University of Hildesheim</rs>. Portuguese assessment was done by <rs type="person">Paulo Rocha</rs>, <rs type="person">Luís Costa</rs>, <rs type="person">Luís Cabral</rs>, <rs type="person">Susana Inácio</rs>, <rs type="person">Ana Sofia Pinto</rs>, <rs type="person">António Silva</rs> and <rs type="person">Rui Vilela</rs>, all of Linguateca (thanks to grant <rs type="grantNumber">POSI/PLP/43931/2001</rs> from <rs type="funder">Portuguese FCT</rs>, co-financed by <rs type="funder">POSI)</rs>, and Spanish by <rs type="person">Andrés Montoyo Guijarro</rs>, <rs type="person">Oscar Fernandez</rs>, <rs type="person">Zornitsa Kozareva</rs>, <rs type="person">Antonio Toral</rs> of <rs type="affiliation">University of Alicante</rs>. Japanese translation of the English topics was provided by <rs type="person">Noriko Kando</rs>. The future direction and scope of GeoCLEF will be heavily influenced by funding and the amount of volunteer effort available.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MpnwnXD">
					<idno type="grant-number">POSI/PLP/43931/2001</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Statistical Testing</head><p>We used the MATLAB Statistics Toolbox, which provides the necessary functionality plus some additional functions and utilities. We use the ANalysis Of VAriance (ANOVA) test. ANOVA makes some assumptions concerning the data be checked. Hull <ref type="bibr" coords="14,221.41,709.83,11.68,8.74" target="#b3">[4]</ref> provides details of these; in particular, the scores in question should be approximately normally distributed and their variance has to be approximately the same for all runs. Two tests for goodness of fit to a normal distribution were chosen using the MATLAB statistical toolbox: the Lilliefors test <ref type="bibr" coords="15,70.62,73.23,11.68,8.74" target="#b0">[1]</ref> and the Jarque-Bera test <ref type="bibr" coords="15,183.69,73.23,10.64,8.74" target="#b4">[5]</ref>. In the case of the GeoCLEF tasks under analysis, both tests indicate that the assumption of normality is violated for most of the data samples (in this case the runs for each participant).</p><p>In such cases, a transformation of data should be performed. The transformation for measures that range from 0 to 1 is the arcsin-root transformation:</p><p>( )</p><p>x arcsin which Tague-Sutcliffe <ref type="bibr" coords="15,162.97,138.21,16.69,8.74" target="#b9">[10]</ref> recommends for use with precision/recall measures. Table <ref type="table" coords="15,115.83,316.95,5.01,8.74">7</ref> shows the results of the Lilliefors test before and after applying the Tague-Sutcliffe transformation. After the transformation the analysis of the normality of samples distribution improves significantly, with the exception of the bilingual Bulgarian. Each entry shows the number of experiments whose performance distribution can be considered drawn from a Gaussian distribution, with respect to the total number of experiment of the track. The value of alpha for this test was set to 5%. The same table shows also the same analysis with respect to the Jarque-Bera test. The value of alpha for this test was set to 5%. The difficulty to transform the data into normally distributed samples derives from the original distribution of run performances which tend towards zero within the interval [0,1].</p><p>The following tables, from Table <ref type="table" coords="15,225.58,420.45,5.01,8.74">8</ref> to Table <ref type="table" coords="15,268.61,420.45,8.35,8.74">13</ref>, summarize the results of this test. All experiments, regardless the topic language or topic fields, are included. Results are therefore only valid for comparison of individual pairs of runs, and not in terms of absolute performance. Each table shows the overall results where all the runs that are included in the same group do not have a significantly different performance. All runs scoring below a certain group performs significantly worse than at least the top entry of the group. Likewise all the runs scoring above a certain group perform significantly better than at least the bottom entry in that group. Each table contains also a graph which shows participants' runs (y axis) and performance obtained (x axis). The circle indicates the average performance while the segment shows the interval in which the difference in performance is not statistically significant; for each graph the best group is highlighted.</p><p>Note that there are no tables for Bilingual German and Bilingual Portuguese since, according to the Tukey T, all the experiments of these tasks belong to the same group. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head><p>X X unswNarrMap X Table <ref type="table" coords="17,159.31,96.75,3.38,8.10">9</ref>. Monolingual German: experiment groups according to the Tukey T Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head><p>Table <ref type="table" coords="17,150.97,436.83,7.51,8.10">10</ref>. Monolingual Portuguese: experiment groups according to the Tukey T Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head><p>Table <ref type="table" coords="18,157.33,96.75,7.51,8.10">11</ref>. Monolingual Spanish: experiment groups according to the Tukey T Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head><p>Table <ref type="table" coords="18,165.13,437.67,7.51,8.10">12</ref>. Bilingual English: experiment groups according to the Tukey T Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head><p>X X HIGeodeenrun13 X Table <ref type="table" coords="19,164.59,96.75,7.51,8.10">13</ref>. Bilingual Spanish: experiment groups according to the Tukey T Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID Groups</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions and Future Work</head><p>The test collection developed for GeoCLEF is the first GIR test collection available to the GIR research community. GIR is receiving increased notice both through the GeoCLEF effort as well as due to the GIR </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="19,84.75,712.37,391.43,9.02" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="19,147.57,712.37,138.41,9.02">Practical Nonparametric Statistics</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Conover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,87.29,73.23,437.56,8.74;20,70.62,84.69,454.30,8.74;20,70.62,96.21,366.12,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="20,137.27,73.23,166.24,8.74">The role of news factors in media use</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eilders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="20,445.53,84.69,79.38,8.74;20,70.62,96.21,306.95,8.74">Institutionen und Vermittlungsprozesse des Wissenschaftszentrums Berlin für Sozialforschung</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>Berlin</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Wissenschaftszentrum Berlin für Sozialforschung gGmbH (WZB ; Forschungsschwerpunkt Sozialer Wandel</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="20,86.37,119.19,438.59,8.74;20,70.62,130.71,454.31,8.74;20,70.62,142.23,264.55,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="20,384.13,119.19,140.84,8.74;20,70.62,130.71,233.34,8.74">GeoCLEF: the CLEF 2005 crosslanguage geographic information retrieval track overview</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,323.34,130.71,197.08,8.74">Cross-Language Evaluation Forum: CLEF 2005</title>
		<title level="s" coord="20,111.80,142.23,169.96,8.74">Lecture Notes in Computer Science LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,86.32,165.21,438.69,8.74;20,70.62,176.73,454.35,8.74;20,70.62,188.19,454.29,8.74;20,70.62,199.71,48.93,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="20,139.19,165.21,271.03,8.74">Using statistical testing in the evaluation of retrieval experiments</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,227.46,176.73,297.51,8.74;20,70.62,188.19,278.89,8.74">Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development on Information Retrieval (SIGIR 1993)</title>
		<editor>
			<persName><forename type="first">Robert</forename><surname>Korfhage</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Edie</forename><surname>Rasmussen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Willett</surname></persName>
		</editor>
		<meeting>the 16th Annual International ACM SIGIR Conference on Research and Development on Information Retrieval (SIGIR 1993)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="329" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,84.85,222.69,440.16,8.74;20,70.62,234.21,304.88,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="20,364.98,222.69,160.02,8.74;20,70.62,234.21,63.36,8.74">Introduction to the Theory and Practice of Econometrics</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">E</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lutkepohl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="20,86.56,257.19,438.42,8.74;20,70.62,268.71,454.30,8.74;20,70.62,280.17,454.23,8.74;20,70.62,291.69,42.57,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="20,235.88,257.19,289.09,8.74;20,70.62,268.71,337.89,8.74">Inside the evaluation process of the cross-language evaluation forum (CLEF): Issues of multilingual topic creation and multilingual relevance assessment</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,426.84,268.71,98.08,8.74;20,70.62,280.17,294.50,8.74">Proceedings of the third International Conference on Language Resources and Evaluation, LREC</title>
		<meeting>the third International Conference on Language Resources and Evaluation, LREC<address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="573" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,86.74,314.67,438.24,8.74;20,70.62,326.19,454.25,8.74;20,70.62,337.71,454.26,8.74;20,70.62,349.17,212.60,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="20,204.01,314.67,276.04,8.74">Providing internet access to portuguese corpora: the ac/dc project</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,70.62,337.71,449.75,8.74">Proceedings of the Second International Conference on Language Resources and Evaluation, LREC 2000</title>
		<editor>
			<persName><forename type="first">Maria</forename><surname>Gavrilidou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">George</forename><surname>Carayannis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stella</forename><surname>Markantonatou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stelios</forename><surname>Piperidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gregory</forename><surname>Stainhauer</surname></persName>
		</editor>
		<meeting>the Second International Conference on Language Resources and Evaluation, LREC 2000<address><addrLine>Athens</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06-02">31 May-2 June 2000. 2000</date>
			<biblScope unit="page" from="205" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,86.08,372.21,438.80,8.74;20,70.62,383.67,454.28,8.74;20,70.62,395.19,95.59,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="20,215.53,372.21,222.29,8.74">Portuguese at CLEF 2005: Reflections and challenges</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,457.74,372.21,67.14,8.74;20,70.62,383.67,348.03,8.74">Cross Language Evaluation Forum: Working Notes for the CLEF 2005 Workshop (CLEF 2005)</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09-23">21-23 September 2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,85.80,418.17,439.01,8.74;20,70.62,429.69,454.26,8.74;20,70.62,441.14,91.19,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="20,211.44,418.17,229.24,8.74">The place of place in geographical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chaves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,162.48,429.69,277.23,8.74">Workshop on Geographic Information Retrieval (GIR06), SIGIR06</title>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ross</forename><surname>Purves</surname></persName>
		</editor>
		<meeting><address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08-10">10 August 2006. 2006</date>
			<biblScope unit="page" from="5" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,90.04,464.18,434.89,8.74;20,70.62,475.64,304.52,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="20,167.25,464.18,274.54,8.74">The Pragmatics of Information Retrieval Experimentation, Revisited</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tague-Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,167.13,475.64,138.49,8.74">Readings in Information Retrieval</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Willett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="205" to="216" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
