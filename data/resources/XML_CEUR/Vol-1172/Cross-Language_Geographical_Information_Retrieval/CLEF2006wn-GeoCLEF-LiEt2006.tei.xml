<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.24,131.23,211.66,12.24">MSRA Columbus at GeoCLEF 2006</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.36,152.01,46.29,8.50"><forename type="first">Zhisheng</forename><surname>Li</surname></persName>
							<email>zsli@mail.ustc.edu.cn</email>
						</author>
						<author>
							<persName coords="1,228.20,152.01,50.86,8.50"><forename type="first">Chong</forename><surname>Wang</surname></persName>
							<email>chwang@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Microsoft Research Asia</orgName>
								<orgName type="department" key="dep2">Sigma Center</orgName>
								<address>
									<addrLine>4F, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.70,152.01,35.21,8.50"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xingx@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Microsoft Research Asia</orgName>
								<orgName type="department" key="dep2">Sigma Center</orgName>
								<address>
									<addrLine>4F, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.53,152.01,53.33,8.50"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
							<email>wyma@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Microsoft Research Asia</orgName>
								<orgName type="department" key="dep2">Sigma Center</orgName>
								<address>
									<addrLine>4F, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sci. &amp; Tech. of China</orgName>
								<address>
									<postCode>230026</postCode>
									<settlement>Hefei</settlement>
									<region>Anhui</region>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.24,131.23,211.66,12.24">MSRA Columbus at GeoCLEF 2006</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B268FEC5F697C4A5D4D50A9338F59D5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages -Query Languages Measurement, Performance, Experimentation Location name extraction and disambiguation, geographic focus detection, implicit location, geographic information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of Columbus Project of Microsoft Research Asia (MSRA) in the Geo-CLEF 2006 (a cross-language geographical retrieval track which is part of Cross Language Evaluation Forum). For location extraction from the corpus, we employ a gazetteer and rule based approach. We use the MSRA's IREngine as our text search engine. Both text indexing and geo-indexing (implicit location indexing and grid indexing) are considered in our system. We only participated in the Monolingual GeoCLEF evaluation (EN-EN) and submitted five runs based on different methods, including MSRAWhitelist, MSRAManual, MSRAExpansion, MSRALocal and MSRAText. In MSRAWhitelist, we expanded the unrecognized locations (such as former Yugoslavia) to several countries manually. In MSRAManual, based on the MSRAWhitelist, we manually modified several queries since these queries are too "natural language" and the keywords of the queries seldom appear in the corpus. In MSRAExpansion, first we use the original queries to search the corpus. Then we extract the locations from the returned documents and calculate the times each location appears in the documents. Finally we will get the top 10 most frequent location names and combine them with the original geo-terms in the queries. However, this may introduce some unrelated locations. In MSRALocal, we do not use white list or query expansion method to expand the query locations. We just utilize our location extraction module to extract the locations automatically from the queries. In MSRAText, we just utilize our pure text search engine "IREngine" to process the queries. The experimental results show that MSRAManual is the best run among the five ones and then the MSRAWhitelist approach. MSRALocal and MSRAText perform similarly. The MSRAExpansion performs worst due to the introduced unrelated locations. One conclusion is that if we only extract the locations from the topics automatically, the retrieval performance does not improve significantly. Another conclusion is that automatic query expansion will weaken the performance. This is because the topics are too difficult to be handled and the corpus may be not large enough. Perhaps, the automatic query expansion may perform better in the web-scale corpus. And we find that if the queries are formed manually, the performance will be improved significantly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In common web search and mining, location information is usually discarded. However, people need to consider locations all the time, such as eating, traveling and shopping. The goal of the Columbus Project is to utilize the location information into web search and mining to better facilitate users to acquire the knowledge related to locations and suggest a location-aware way to organize the information.</p><p>The main technologies in Columbus Project are listed below:</p><p>• Location Extraction and Disambiguation -a fundamental problem of developing technologies for extracting and disambiguating locations from the documents, including texts and web pages; • Geo-Indexing and Geo-Ranking -with extracted locations, developing indexing and ranking methods for search, such as spatial indexing and integrating text ranking into spatial ranking;</p><p>• Mining geographical knowledge -mining the relationships between common knowledge and location information;</p><p>• Visualization for search results or mining results -developing better technologies for visualizing the geo-information on map or virtual earth for easy browsing, navigating and information acquiring. This is the first time for Columbus project to participate in GeoCLEF 2006 <ref type="bibr" coords="2,385.96,217.70,10.37,8.50" target="#b6">[7]</ref>. GeoCLEF is aimed at providing necessary platform for evaluating the geographic information retrieval. We only participated in the Monolingual GeoCLEF evaluation (EN-EN) and submitted five runs based on different methods.</p><p>The rest of the paper is organized as follows. We present a description of our system in section 2 and depict our monolingual GeoCLEF experiments (EN-EN) in section 3. Section 4 presents the experimental results and analysis. Conclusions and future work are discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Geographic Information Retrieval System Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Geo Knowledge Base</head><p>We use internal geographic Database as our basic gazetteer. This gazetteer contains basic information about the locations all over the world, including location name, location type, location importance and the hierarchical relationship between the locations. We utilize this gazetteer to extract the locations, to disambiguate the locations and detect the focuses of documents. Besides this gazetteer, we also use some other resources to improve the performance, including stop word list, person name list, white list and location indicator list. The method to generate the stop word list is in 2.2.3. The white list and location indicator list is maintained manually, while the person name list is downloaded from the internet. And we integrated all these resources as a Geo Knowledge Base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Location Extraction Module</head><p>Location Extraction module aims to extract locations and also disambiguate them from unstructured text. We manually composed the rules to address this task. Figure <ref type="figure" coords="2,302.59,458.61,4.87,8.50">1</ref> is the workflow of the location extraction. It includes several parts: text parsing, geo-parsing, geo-disambiguating and geo-coding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Workflow of location extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Text-parsing</head><p>In this step, we use a simple text-parsing method to parse the original text into a single-space separated word-token string. All useless tags and symbols are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Geo-parsing</head><p>There are several ways to find the location candidates in this step. We use a gazetteer-based approach and only find the candidates that appear in the gazetteer. We follow the longest match principle. For example, if "New York" is detected, the substring "York" is not reported. In order to match the location names in the text with the ones in our gazetteer fast, we utilize a parsing-prefix table which is a list used to store the prefixes of the candidates of locations in the text. During the process, we need to maintain the parsing-prefix table until the longest location name is found. An example of location extraction can be seen in figure <ref type="figure" coords="3,177.35,521.25,3.65,8.50" target="#fig_0">2</ref>.</p><p>Mary works in New York and she is a journalist. New York York and and "New York and" is not a prefix and "New York" is a location.</p><p>York is a prefix. When the next word-token is "and", "New York and" is not a prefix and "New York" is a location, then the updating of prefix-table stops and "New York" returns as a location candidate.</p><p>For updating the parsing-prefix table, we need to create a location-prefix hash-table, which stores all the possible prefixes of the location names in the gazetteer, e.g. the prefix for "New York" are "New" and "New York". Then in the matching process, we just need to look up the word-token in the location-prefix hash-table to check whether it's a prefix of a location. If the word-token is a prefix, it indicates that a location may be found and we insert it into the parsing-prefix table. The geoparsing algorithm is as follows.</p><p>Our algorithm scans the word token list from the beginning by gazetteer-lookup operation. Once a possible prefix is met, the parsing-prefix table will be created and the corresponding word token will be inserted into it. If the next word token will be a new prefix together with the existed prefixes in table, the prefix table will be updated. Otherwise, if a prefix in the table has been a location name, the update operation will stop and we will get the longest location name from the parsing-prefix table and transform it to a geo token, at the same time the prefix table will be cleared. Finally, the algorithm will stop when it meet the end of the word token list.</p><p>In this algorithm, we utilize the location-prefix table during the location-extraction process so that the text can be parsed linearly. The impossible location names, whose prefixes are not in the location-prefix hash-table, won't be looked up. So the dictionary-lookup operation times decrease significantly and the geo-parsing speed will be much faster than previous approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Geo-Disambiguation</head><p>The ambiguity of our gazetteer is very serious, e.g. "is", "all" are also place names. The reason for disambiguating is that many different locations have the same name and there are some location names which are not used as locations, such as person names. We employ a rule-based approach and utilize stop word list, person name list and white list to disambiguate the candidates.</p><p>Our stop word list is generated from the corpus of the GeoCLEF 2006 data sets, which are collections of newspapers from LA Times (Year 1994) and Glasgow Herald (Year 1995). We applied following criteria to obtain the stop word list:</p><p>• Names that appeared too frequently, but always appeared as lower-case. Then these location names should be put into the stop word list, e.g. "is", "all". • The location or its entity type is not very important, but it appears too frequently. It has a large probability to be non location word. Like "Leaf" is a river but in most of the cases, it should be a stop word.</p><p>Besides the automatic-generated stop words, we also maintain a manual stop word list. The manual stop word list contained the stop words that cannot be generated by the method described before.</p><p>The white list contained some historic names, organization names or other alias that do not exist in our gazetteer, like "Korea", "former Eastern Bloc", "former Yugoslavia", "Middle East". We map these words to multiple EntityIDs in our gazetteer, for example: Korea-&gt; South Korea (ID: 134) + North Korea (ID: 131). Through the mapping, the white list can be treated nearly the same as the common items in the gazetteer, only lack of hierarchy relationships.</p><p>We also applied a confidence-based framework in the geo-disambiguation. We assign each location name a confidence score. First we run the rules in the following orders, and then combine the confidence scores in different steps.</p><p>• Stop word rule: we remove the location candidates if they appear in the stop word list.</p><p>• Location Indicator rule (xx means locations): such as xx city, and there is a rule list with corresponding confidence scores. • Non-Location Indicator rule (mainly person indicator rules): such as Mr., and there is also a rule list with corresponding confidence scores.</p><p>• Complete Person Name rule: If the location candidate is a person name in the Person Name list, and from the context we find that there is a whole person name there, this location candidate is removed.</p><p>• Default Popular Person Name rule: If the location candidate is a very popular person name, and there are no positive rules to indicate it is a location, this candidate is removed.</p><p>• Default rule: If there are no strong rules to remove the location candidate, it will be assigned a moderate score according to population, importance and location hierarchical level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Geo-Coding</head><p>In this step, after we disambiguated the location names, we need to assign the exact meanings to them. Many different places have same names, e.g. "London" is the capital in England, but also a place in United States of America. Figure <ref type="figure" coords="4,502.51,722.72,4.87,8.50">3</ref> shows a visual illustration of Geo-Coding. We utilize the heuristic methods to determine the exact meanings of the disambiguated locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3. A visual illustration of Geo-Coding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Geographic Focus Detecting Module</head><p>When the locations' exact positions are determined, we want to get the focus of the documents. We adopted the algorithm described in <ref type="bibr" coords="5,103.09,400.05,10.38,8.50" target="#b4">[5]</ref>. Its main idea is to accumulate the score of each node in the hierarchical tree from bottom to up, and to sort all the nodes whose score are not equal to zero. Then we can get a list of focuses about the documents. The location with the biggest score is the most possible focus. For example, a document, mainly talking about Redmond economics, also has some relationship with Seattle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Geo-Indexing Module</head><p>The indexing module of a GIR system usually composes of two parts: text index and geo-index. On the other hand, a geographical query usually consists of three parts: textual terms, spatial relationship and geographical terms. For example, one query in GeoCLEF 2006 is "Snowstorms in North America", where "Snowstorms" indicates what the user intends to know, "in" represents the spatial relationship and "North America" is the scope of the area that the user is interested in. We can retrieve a set of documents related to the textual terms (Snowstorms) through the text index and another set of documents whose geographical focuses are related to the query area through geographical index. These two sets will be merged and ranked according to a combined ranking function. In our system, we suppose the query location input is through text, not map.</p><p>In our system, explicit locations and implicit locations <ref type="bibr" coords="5,279.60,563.91,11.40,8.50" target="#b8">[9]</ref> are indexed together and different geo-confidence scores are assigned to them. The advantage of this mechanism is that no query expansion is necessary and implicit location information can be computed offline for fast retrieval.</p><p>In <ref type="bibr" coords="5,63.60,601.94,10.38,8.50" target="#b5">[6]</ref>, the authors concluded that the most common geographical relationship used in queries is "in". Actually, if no spatial relationship exists in the query, we can safely assume the relationship is "in". Also, when a user wants to know information about "Independence movement in Quebec" (a query in GeoCLEF 2006), it means he/she wants to get the information covered by the query geographical area "Quebec", and would feel uncomfortable if a GIR system returns documents about "Independence movement in Canada" or "Independence movement in North America". Therefore, in our indexing algorithm, the implicit locations will not be expanded to lower levels because users usually don't need information about upper locations when they seek for information. When "Canada" appears in one document, the document ID shouldn't be appended to the inverted lists of "Quebec" or other children locations of "Canada". In order to obtain the implicit locations, we first adopt the focus detecting algorithm described in <ref type="bibr" coords="5,249.22,692.96,10.33,8.50" target="#b4">[5]</ref>. Afterwards we add the ancestors of these explicit focuses as implicit locations, but with lower confidence scores.</p><p>In our system, we adopt two types of geo-indexes: one is called focus-index, which utilizes the inverted index to store all the explicit, and implicit locations of documents (see Figure <ref type="figure" coords="6,280.15,119.84,3.62,8.50" target="#fig_2">4</ref>); the other is called grid-index, which divides the surface of the Earth into 1000 × 2000 grids. The documents will be indexed by these grids according to their focuses. The reason for adopting grid-index is that some topics in GeoCLEF 2006 can't be solved only by focus-index due to the spatial relationship other than "in" (such as "near").  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Geo-Ranking module</head><p>For the ranking module, we adopt IREngine, developed by MSRA, as our basic search engine. Then we integrated the georanking module into it. The basic ranking function for text-ranking module is BM25. The ranking algorithm is as follows.</p><p>For focus-index, the matched docID list can be retrieved by looking up the locationID in the inverted index. For grid-index, we can get the docID list by looking up the grids that the query location covers. We first retrieve two lists of documents relevant to the textual terms and the geographical terms respectively, and then merge them to get the final results. A combined ranking function R combined = R text × α+ R geo × (1-α), where R text is the textual relevance score and R geo is the georelevance score. Experiments show that textual relevance scores should be weighted higher than geo-relevance scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Monolingual GeoCLEF Experiments (English -English)</head><p>In table <ref type="table" coords="6,84.85,481.65,3.68,8.50" target="#tab_0">1</ref>, we show all the five runs submitted to GeoCLEF. When the topic field is "Title", we just use the EN-title element of the topic to generate the query of the run. When the topic field is "Title + Description", this means that the EN-title and EN-desc are both used in the run. When the topic field is "Title + Description + Narrative", this means that EN-title, EN-desc and EN-narr are all used. And the "Description" field in Table <ref type="table" coords="6,302.64,515.79,4.87,8.50" target="#tab_0">1</ref> gives a simple explanation of the methods used in the runs. Priorities are assigned by us, where priority 1 is the highest and 5 the lowest. In MSRAWhitelist, we used the EN-title elements of the topics to generate the queries. For some special queries, e.g. "Credits to the former Eastern Bloc", "Arms sales in former Yugoslavia", "Eastern Bloc" and "former Yugoslavia" are not in our gazetteer, so we utilized the geo knowledge base to get the corresponding sovereigns of these geo-entities. Then we can make a white list manually for the geo-terms of these queries.</p><p>In MSRAManual, we generated the queries with EN-title and EN-desc elements of the topics. However for some queries, e.g. "Wine regions around rivers in Europe", "Tourism in Northeast Brazil", if we just input the "wine regions" or "Tourism", very few documents will return. So we manually modified the textual terms of such queries, e.g. "Tourism" -&gt; "tourism tourist tour traveling travel".</p><p>In MSRAExpansion, we generated the queries with EN-title and EN-desc elements of the topics. Different from MSRAManual, the queries are automatically expanded based on the pseudo-feedback technique. First we use the original queries to search the corpus. Then we extract the locations from the returned documents and calculate the times each location appears in the documents. Finally we will get the top 10 most frequent location names and combine them with the original geo-terms in the queries. For example, "former Yugoslavia" will be expanded to be "Croatia, United States, Russia, Sarajevo, Balkan, Edinburgh, Tuzla, Belgrade, Germany, Zagreb". Then we can see "Croatia, Sarajevo, Belgrade, Zagreb, Tuzla" are really parts of "former Yugoslavia", however, unrelated locations, such as "United States", also appeared. The reason is that they appeared together with "former Yugoslavia" frequently in the corpus and it's difficult to find a criterion to remove them.</p><p>In MSRALocal, we used the EN-title elements of the topics to generate the queries. And we do not use geo knowledge base or query expansion method to expand the query locations. We just utilize our location extraction module to extract the locations automatically from the queries.</p><p>In MSRAText, we generated the queries with EN-title, EN-desc and EN-narr elements of the topics. We just utilize our pure text search engine "IREngine" to process the queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>Figure <ref type="figure" coords="7,80.71,337.05,4.87,8.50" target="#fig_3">5</ref> is the interpolated Recall vs Average Precision for the five runs. MSRAManual is the best run among the five ones as expected, because the queries are modified manually. The worst one is MSRAExpansion. The reason is that many unrelated locations are added to new queries after pseudo feedback for some topics.  MSRAManual improves the performance significantly compared with MSRALocal. For example, for the GC045 "Tourism in Northeast Brazil", the MAP in MSRALocal is 0.0%, but in MSRAManual it's 26.96%. This is because, as discussed in Section 3, very few documents contain the keyword "Tourism". We manually modified "Tourism" to "tourism tourist tour traveling travel" and improved the performance of this query significantly. For the GC037 "Archeology in the Middle East", the MAP is from 6.45% to 27.31%, and the reason is similar to that of GC045.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MSRAWhitelist MSRAManual</head><note type="other">MSRAExpansion MSRALocal MSRAText</note><p>The MAP of MSRAExpansion drops a little compared with MSRALocal, since the expansion introduced unrelated locations. Perhaps, if we have a large corpus, the performance of the expansion approach would improve, since the top-ranked documents might include more relative locations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>One conclusion is that if we only extract the locations from the topics automatically, the retrieval performance does not improve significantly. Another conclusion is that automatic query expansion will weaken the performance. This is because the topics are too difficult to be handled and the corpus may be not large enough. Perhaps, the automatic query expansion may perform better in the web-scale corpus. And we find that if the queries are formed manually, the performance will be improved significantly.</p><p>In the future we will improve the system in the following aspects: 1) geographical indexing and ranking; 2) automatic query processing; 3) geographical disambiguation algorithm; 4) visualization for the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,52.50,694.86,483.45,8.77;3,52.50,706.32,485.65,8.77;3,52.50,717.72,227.14,8.77"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An example of location extraction. "New York" and "York" are prefixes in the prefix table.When the next word-token is "and", "New York and" is not a prefix and "New York" is a location, then the updating of prefix-table stops and "New York" returns as a location candidate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,167.58,339.78,260.08,8.77"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Inverted index of both explicit and implicit locations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,126.66,280.80,341.79,8.77"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The Interpolated RECALL vs AVERAGE PRECISION for all five runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,82.74,542.34,424.46,127.20"><head>Table 1 . Run Information Run-ID Topic Fields Description Priority</head><label>1</label><figDesc></figDesc><table coords="6,82.74,574.17,413.03,95.38"><row><cell>MSRAWhitelist</cell><cell>Title</cell><cell>using geo knowledge base</cell><cell>1</cell></row><row><cell>MSRAManual</cell><cell>Title + Description</cell><cell>using geo knowledge base and manual</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>query construction</cell><cell></cell></row><row><cell>MSRAExpansion</cell><cell>Title + Description</cell><cell>using query expansion</cell><cell>3</cell></row><row><cell>MSRALocal</cell><cell>Title</cell><cell>without geo knowledge base and query</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>expansion</cell><cell></cell></row><row><cell>MSRAText</cell><cell>Title + Description + Narrative</cell><cell>using pure text</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,52.50,296.25,490.24,54.04"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note coords="8,86.47,296.25,456.21,8.50;8,52.50,307.65,490.20,8.50;8,52.50,318.99,490.24,8.50;8,52.50,330.39,490.24,8.50;8,52.50,341.79,111.93,8.50"><p>shows the MAP and R-Precision for all the runs. MSRAManual outperforms the other runs in both MAP and R-Precision. The performances for MSRALocal and MSRAText are very similar to each other. It indicates that only extracting locations from the topics as geo-terms without any expansion won't improve MAP much. However, MSRAWhitelist outperforms than MSRALocal by about 9% in MAP. The reason is that we only made white list for several topics and it won't affect the MAP much.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,159.48,455.82,258.05,101.70"><head>Table 2 . MAP &amp; R-Precision for five runs</head><label>2</label><figDesc></figDesc><table coords="8,159.48,472.14,258.05,85.38"><row><cell>RUN-ID</cell><cell>MAP</cell><cell>R-Precision</cell></row><row><cell>MSRAWhitelist</cell><cell>20.00%</cell><cell>23.52%</cell></row><row><cell>MSRAManual</cell><cell>23.95%</cell><cell>25.45%</cell></row><row><cell>MSRAExpansion</cell><cell>15.21%</cell><cell>18.53%</cell></row><row><cell>MSRALocal</cell><cell>18.37%</cell><cell>22.45%</cell></row><row><cell>MSRAText</cell><cell>18.35%</cell><cell>21.23%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,70.02,691.77,393.67,8.50" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,250.67,691.77,156.40,8.50">Web-a-where: Geotagging Web Content</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amitay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Har'el</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sivan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,413.70,691.77,45.58,8.50">SIGIR 2004</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,70.02,707.07,467.28,8.50;8,70.02,718.41,73.56,8.50" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,223.88,707.07,252.74,8.50">Efficient Query Processing in Geographical Web Search Engines</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Markowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,483.28,707.07,48.62,8.50">SIGMOD&apos;06</title>
		<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,108.51,434.69,8.50" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,227.38,108.51,161.49,8.50">Indexing and Ranking in Geo-IR Systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Andrade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,395.68,108.51,27.74,8.50">GIR&apos;05</title>
		<meeting><address><addrLine>Bremen, Germany</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,123.81,462.03,8.50;9,70.02,135.15,22.04,8.50" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,115.90,123.81,189.49,8.50">Cross-Language Retrieval Experiments at CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="9,332.31,123.81,139.15,8.50">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2785</biblScope>
			<date type="published" when="2002">2002. 2003</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,150.45,459.49,8.50;9,70.02,161.85,74.27,8.50" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,273.34,150.45,217.08,8.50">Detecting Geographical Locations from Web Resources</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,497.14,150.45,27.74,8.50">GIR&apos;05</title>
		<meeting><address><addrLine>Bremen, Germany</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,177.09,339.39,8.50" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,184.12,177.09,126.82,8.50">Analyzing Geographical Queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,317.45,177.09,27.69,8.50">GIR&apos;04</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,192.39,172.42,8.50" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Geoclef</surname></persName>
		</author>
		<ptr target="http://ir.shef.ac.uk/geoclef/" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,207.69,465.50,8.50;9,70.02,219.09,273.83,8.50" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,297.88,207.69,237.64,8.50;9,70.02,219.09,79.11,8.50">The SPIRIT Spatial Search Engine: Architecture, Ontologies and Spatial Indexing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">I</forename><surname>Abdelmoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="9,155.77,219.09,139.10,8.50">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3234</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.02,234.33,464.62,8.50;9,70.02,245.73,88.16,8.50" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,283.91,234.33,247.24,8.50">Indexing implicit locations for geographic information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,70.02,245.73,27.70,8.50">GIR&apos;06</title>
		<meeting><address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
