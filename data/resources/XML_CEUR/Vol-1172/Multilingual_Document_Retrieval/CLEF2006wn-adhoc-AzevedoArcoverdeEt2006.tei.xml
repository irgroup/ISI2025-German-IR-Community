<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,124.09,148.86,354.83,15.15;1,180.41,170.78,242.20,15.15">Using Noun Phrases for Local Analysis in Automatic Query Expansion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,216.56,203.31,68.12,10.48"><forename type="first">João</forename><surname>Marcelo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Ciências de Computação e Estatística Instituto de Ciências Matemáticas e de Computação</orgName>
								<orgName type="institution">Universidade de São Paulo -Campus de São Carlos</orgName>
								<address>
									<addrLine>Caixa Postal 668</addrLine>
									<postCode>13560-970</postCode>
									<settlement>São Carlos</settlement>
									<region>SP</region>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.57,203.31,97.86,10.48"><forename type="first">Azevedo</forename><surname>Arcoverde</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Ciências de Computação e Estatística Instituto de Ciências Matemáticas e de Computação</orgName>
								<orgName type="institution">Universidade de São Paulo -Campus de São Carlos</orgName>
								<address>
									<addrLine>Caixa Postal 668</addrLine>
									<postCode>13560-970</postCode>
									<settlement>São Carlos</settlement>
									<region>SP</region>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.19,217.26,90.27,10.48"><forename type="first">Maria</forename><surname>Das Graças</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Ciências de Computação e Estatística Instituto de Ciências Matemáticas e de Computação</orgName>
								<orgName type="institution">Universidade de São Paulo -Campus de São Carlos</orgName>
								<address>
									<addrLine>Caixa Postal 668</addrLine>
									<postCode>13560-970</postCode>
									<settlement>São Carlos</settlement>
									<region>SP</region>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.37,217.26,64.44,10.48"><forename type="first">Volpe</forename><surname>Nunes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Ciências de Computação e Estatística Instituto de Ciências Matemáticas e de Computação</orgName>
								<orgName type="institution">Universidade de São Paulo -Campus de São Carlos</orgName>
								<address>
									<addrLine>Caixa Postal 668</addrLine>
									<postCode>13560-970</postCode>
									<settlement>São Carlos</settlement>
									<region>SP</region>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.21,314.89,82.60,10.48"><forename type="first">Wendel</forename><surname>Scardua</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Ciências de Computação e Estatística Instituto de Ciências Matemáticas e de Computação</orgName>
								<orgName type="institution">Universidade de São Paulo -Campus de São Paulo</orgName>
								<address>
									<addrLine>Caixa Postal 66.281</addrLine>
									<postCode>13083-970</postCode>
									<settlement>São Paulo</settlement>
									<region>SP</region>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,124.09,148.86,354.83,15.15;1,180.41,170.78,242.20,15.15">Using Noun Phrases for Local Analysis in Automatic Query Expansion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F56FEE0F2492F82DFF4F77375978C9FD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>phrases</term>
					<term>blind relevance feedback</term>
					<term>local analysis</term>
					<term>query expansion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Blind relevance feedback constitutes a widely used technique to improve the performance of IR systems. Its result is directly influenced by the correct choice of the potentially qualified features used to expand the initial query. It is well known the power of noun phrases in the role of descriptors with high discriminatory and informative potential. This work presents a local analysis technique to automatic query expansion through the use of noun phrases extracted from the pseudo-relevant set, for the Ad-Hoc, monolingual (Portuguese) track. Even though the technique is language independent, specific resources for Portuguese were used to the noun phrases extraction through the use of Machine Learning techniques. In our experiments with a specific IR system, it has been observed an improvement in the results obtained over 38% of the topics, and also its depreciation over some others topics. However, this fact constitutes a clear evidence of how the use of NLP techniques can influence such processes, showing real possibilities for improving the presented technique.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language is characterized by the imprecision of the terms used in the text, which constitutes the main vehicle of acquisition and dissemination of the human knowledge. Interpretation and meaning attribution are almost always defective and ambiguous processes. The information retrieval systems available nowadays reflect the linguistic phenomenon of this nature, especially related to the user's expectation of coherent answers to his/her information needs. The query formulation process constitutes a challenge to these systems. In a IR system, the query is defined as the elaboration process of the user information need. For the IR models most commonly used in Web environment, the query formulation through the use of keywords appears as the main language for human-machine communication process. It is a intuitive language, of easy manipulation and allows the ordering of the set of documents returned by the query according some relevance judgment. This ordering is a difficult task, either because of the user's inability to efficiently articulate his/her information need, or the own nature of the human language.</p><p>Besides the difficulty of query elaboration, the process to select relevant documents normally involves interactive cycles between the user and the system, including, most of times, reformularizations of the initial query. One strategy to simplify this process is to expand the initial query with related terms, trying to feed the system with a more elaborated context, minimizing the problems due to the human language.</p><p>The remaining of this article is as follows: Section 2 presents a broad vision of the query expansion problem such that we can put our technique among the most known approaches; Section 3 presents a method for noun phrase extraction based on machine learning approach; Section 4 describes our experiment with pseudo-relevance feedback; Section 5 presents the evaluation of the method according well established metrics for IR systems; and Section 6 concludes the article with some observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Query Expansion</head><p>The process of reformulating the initial query must address a selection criterion to choose the new descriptors that will compose the expanded query, as well as a strategy to recalculate its weights together with those from the initial query. The decision of how many descriptors to pick up is a problem one must analyze experimentally. The point is that the descriptors must convey a qualitative semantic power that distinguish them from the others, towards within the context where they were identified.</p><p>The query expansion can be done through the use of the entire collection of documents or through an external knowledge database. Although many researchers succeeded in the use of external databases to query expansion <ref type="bibr" coords="2,258.26,465.67,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,271.72,465.67,7.01,8.74" target="#b6">7]</ref>, the cost of its attainment and maintenance generally restrict them to domain specific applications.</p><p>There are basically two main approaches to query expansion: a) interactive -when the user interacts with the system, feeding information about the relevance of the returned documents; and b) automated -when there is no interaction from the user throughout the process. In the first approach, one say that there is relevance feedback. The second approach (automated), it has been said there be pseudo-relevance feedback. The scope of analyzed documents used to expand the initial query can be global, when the entire collection is garned, or local, when only a subset of the collection is used, mainly the top "n" ordered documents returned from the initial query.</p><p>The automated and local analysis constitutes a tendency to automate the query expansion process for domain independent collections of reasonable dimension, producing improvements to the recall and precision of IR systems <ref type="bibr" coords="2,258.87,597.17,14.61,8.74" target="#b9">[10]</ref>. It has the advantage of the exploratory power of the local context supplied by the query, becoming more appropriate than the global analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Noun Phrases identification</head><p>The noun phrases are broadly known as the set of elements that referrers to concepts, objects or facts from the real world and, therefore, carry high discriminatory information <ref type="bibr" coords="2,428.09,675.85,9.97,8.74" target="#b5">[6]</ref>. These linguistic structures have been widely used in many computational problems, for example, in a controlled vocabulary indexing procedure. Here they are used to the query expansion process in a specific IR system, representing the most important descriptors from which the new expanded query will be constructed.</p><p>The problem of recognizing and extracting the noun phrases of free texts have been evolved from the use of symbolic computational programs to the statistical ones. In part the reason from which this evolution can be explained is attributed to the matureness of the supervised Machine Learning (ML) techniques, as soon as trustworthy examples are presented.</p><p>These ML techniques have surpassed the performance of the applications that employs manually created and maintained grammatical rules, what has been characterized as a hassle process and, in many situations, do not easily share between different applications.</p><p>This work considers only the lexical noun phrases -those which the nucleus is a name. We had used the system developed by <ref type="bibr" coords="3,220.34,207.66,9.97,8.74" target="#b8">[9]</ref>, based on TBL (Transformation Based Learning) <ref type="bibr" coords="3,448.62,207.66,9.96,8.74" target="#b0">[1]</ref>, customized for the Portuguese language.</p><p>The idea behind the algorithm is to generate an ordered list of transformation rules, that gradually fixes errors in a training corpus, produced by an inexact initial classification. From each new iteration, the rule chosen to compose the list of learned rules is that which will trigger more error reduction in the training corpus classification, as shown in Figure <ref type="figure" coords="3,403.33,267.44,3.88,8.74" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setting</head><p>Our team (NILC<ref type="foot" coords="3,161.78,511.19,3.97,6.12" target="#foot_0">1</ref> ) has participated in Clef 2006 for the Ad-Hoc, monolingual, Portuguese language track for the very first time, with its IR system designed to explore the power of noun phrases as the main descriptors of an hybrid indexing scheme, which aims to combine statistical and linguistic knowledge extracted from the corpus.</p><p>The method presented in our two runs submitted to the task explored both how the hibrid text representation can produce good effectiveness and how query expansion could be done within this model. This report emphasizes the second point, for two reasons: i ) query expansion over a linguistically motivated index is a completely new branch of research to our actual context; and ii ) the two runs submitted to the track can be compared each other to evaluate the performance the second run took over the first one, which has not used query expansion. Both runs used the same indexing scheme.</p><p>For the query expansion we used pseudo-relevance feedback to automatically expand the initial query without demanding interactions between the user and the whole process. The local analysis was done within top twenty first documents returned from the initial query, ordered by a slight variation of the Okapi BM25 <ref type="bibr" coords="3,211.02,680.14,15.72,8.74" target="#b7">[8]</ref> ranking algorithm. This value is empiric and can vary according to the collection itself and to the topic and relevance judgments related to it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Collection, topics and initial queries</head><p>In Clef 2006, two collections were disposed for the Ad-Hoc, monolingual for Portuguese track, including issues from Brazil and Portugal, that differ each other by many peculiarities that must be addressed in a linguistic context, varying from typography differences within terms, from other word mismatch phenomenon (synonym and polissemy). These variations can influence the initial query precision and recall, thus the overall query expansion process. The corpus is composed by four collections: Folha94, Folha95, Publico94 e Publico95<ref type="foot" coords="4,337.54,188.61,3.97,6.12" target="#foot_1">2</ref> , totalizing 210.736 free text documents (approximatelly 560 Mb).</p><p>Besides, it was disposed 50 search topics from different subjects, along with their respective descriptions. These descriptions were manually processed to derive the initial queries set, one for each topic. Each initial query is composed by one Boolean expression over the main descriptors identified along the description text.</p><p>One important operation named "term proximity" was implemented, once it is useful to store the absolute position for each document term at indexing time. This allow to compute the following Boolean expression:</p><formula xml:id="formula_0" coords="4,180.82,285.83,133.18,9.65">C n = +d 1 -d 2 + (d 3 \n d 4 )</formula><p>, where n ∈ Z. In this query, C n searches for all documents that holds the term d 1 and do not hold the term d 2 and hold d 3 and d 4 distant from each other, at most, n terms, no metter the order between them. This operation is essential to work with the noun phrases nucleus, considering some relative term distance between them, assuming that this distance is a clue to its contextual correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pre-processing the collection</head><p>The collection required three different levels of pre-processing before indexing, which took approximately 70 hours using 4 dedicated Pentium-IV machines (3.2 GHz CPU and 2Gb RAM), one for each collection. This was a very challenging step of building a linguistically motivated index.</p><p>First of all, the text was delimited by sentences, structuring one sentence per line. Following this segmentation, each term from each sentence were tokenized and morphologically analyzed. In this phase we proceed with the morphologic disjunctions, for example, "do = de + o", "àquele = a + aquele", "dentre = de + entre", etc.</p><p>In the second level of pre-processing, the text was POS-tagged using a language modeling proposed by MXPOST<ref type="foot" coords="4,191.18,473.99,3.97,6.12" target="#foot_2">3</ref> , associating each token to its grammatical function based on its context evidences. The training corpus used to induce the classifier holds 41.883 sentences extracted from Mac-Morpho<ref type="foot" coords="4,145.93,497.90,3.97,6.12" target="#foot_3">4</ref> , from the LacioWeb<ref type="foot" coords="4,239.95,497.90,3.97,6.12" target="#foot_4">5</ref> project.</p><p>The third level of our pre-processing architecture was responsible to identify and tag the noun phrases for each labeled sentence, for each document of the entire collection. Therefore, it also flagged the nucleus for each noun phrase (which can be formed by multiple lexical words). It was used the TBL (Transformation Based Learning) algorithm <ref type="bibr" coords="4,343.59,547.30,9.97,8.74" target="#b0">[1]</ref>, as we have already briefly described in the last Section. It was used a corpus of 4.393 sentences selected from Mac-Morpho<ref type="foot" coords="4,476.51,557.68,3.97,6.12" target="#foot_5">6</ref> , which were thoroughly revised by <ref type="bibr" coords="4,212.11,571.21,9.97,8.74" target="#b1">[2]</ref>. Following <ref type="bibr" coords="4,275.55,571.21,9.97,8.74" target="#b8">[9]</ref>, the process described to identify the noun phrases reaches approximately 87% of F-measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Controlled indexing vocabulary</head><p>Once the collection is pre-processed, the indexing phase takes place. It requires basic linguistic operations such as case-folding, accents mapping and stopwords removal. Once the terms are syntactically labeled, it is possible to take some decisions in order to reduce the size of the space-terms through the use of a controlled vocabulary indexing scheme. For example, numerical sequences are not indexed, unless if they were part of some noun phrase nucleus. Analogously, we can treat the same way monetary values, percentages, etc. All the verbs were indexed in their infinitive form, that measure saved a large amount of disk space, second only to the numerical sequences. In our indexing scheme, all the multi-word noun phrases were also indexed as a single descriptor, together with their unigram terms. This approach takes an alternative fast ranking algorithm to weight these structures at search time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Pseudo-relevance feedback</head><p>The proposal of the method is to free the user from interacting with the system, even though this interaction may happen spontaneously at the time the system shows the new reformulated query, before its re-submission through an interface. At this point the user visualizes the new Boolean expression, optionally change and re-submit to the system, giving turn to the expansion interaction. This submition could be completely automated and transparent to the user. However, for experimental reasons, we have decided to track the way the query was reformulated and have the power to influence it.</p><p>One relevant challenge is the exploration of alternatives to identify which noun phrases supplies the best context to efficiently contribute to query reformulation. One important problem is to choose which parts of the documents from which will be extracted the noun phrases that will act as potential candidates as descriptors in the expanded query. We can extract from the entire document or from the top relevant passages. We observed that the documents from the collection share a uniform size, as well each document reflects only one topic, with some exceptions. We have decided for a third alternative: to select only those candidates that are near to the signaled occurrence triggered from the initial query. This is because words with similar meanings tend to occur in similar contexts <ref type="bibr" coords="5,196.30,385.45,12.33,8.74" target="#b4">[5]</ref>. Thus, the objective is to minimize the noise generated from those descriptors that are far from the context and, therefore, probably refer to a different topic. Thus we have extracted all the noun phrases from the sentence where exists at least one match triggered from the Boolean search expression, as well from the adjacent sentences (one above and one below). These values are also parameterized into the system and can vary among the experiments.</p><p>In order to select an enough amount of descriptors (also determined experimentally) to compose the new query, we attributed to the noun phrases weights that reflect their evidence in the text. To calculate the weight of the noun phrase, only the nucleus was considered, discarding their determinants and modifiers.</p><p>The weight of a noun phrase s in a document d follows the Equation (1), according to <ref type="bibr" coords="5,484.27,493.04,9.97,8.74" target="#b2">[3]</ref>.</p><formula xml:id="formula_1" coords="5,253.81,512.03,259.19,30.32">w s,d = f s,d × n i=1 w ti,d<label>(1)</label></formula><p>where:</p><p>• f s,d is the frequency of occurrence of s in d and;</p><p>• w ti,d is the weight of the n-th term t i from the s nucleus in d;</p><p>Each noun phrase chosen from the sentences has its nucleus splited by unigram terms. These terms suffer a lemmatization process to provide a natural conflation among them. The lemas extracted from the nucleus produces a better weight schema than if it were done without lemmatizing the terms.</p><p>The lemmas are weighted according to their frequency in the noun phrases of the document. Optionally, we can multiply this value by a factor idf , that measures the rarity of this lemma in the pseudo-relevant set. The frequency of occurrence of the noun phrase s in d is the sum of how many times this multi-term structure occurs in the document.</p><p>Once the weight of each lemma had been calculated, as well the frequency of each noun phrase s in document d, the weight of s in d is the product of its respective frequency by the sum of the weight of their lemmas. Then it is possible to rank the set of noun phrases from the pseudorelevant documents according to its weight, in descendent order, and pick up the first top n noun phrases. These are the descriptors that will compose the new expanded query, rearranged in a new Boolean search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>Each query (expanded or not) formulated over one topic returns a set of documents ordered by some relevance criterion. Each returned document is a record that obeys a predefined output layout to be submitted to a specific system that will judge the correctness of the claimed relevance. The set of all records grouped by topic constitutes a run. Each run reflects the behavior of the IR system for all disposable topics.</p><p>The presenting work generated two different runs to be evaluated against the relevance judgments by the Clef team. Also, the runs shall be compared one against another, which constitutes the objective of this article. They are: i ) NILC01 -all the initial queries (one for each topic) with no expansion, and ii ) NILC02 -with query expansion. The runs evaluated by the Clef judges reported metric values that match those evaluated by the trec eval<ref type="foot" coords="6,393.09,284.76,3.97,6.12" target="#foot_6">7</ref> program, using the same relevance judgments. This is useful for future manipulations on the process by our team, without depending on external procedures, until the next Clef campaign.</p><p>We have focused on the traditional metrics used to evaluate IR system: i ) MAP (Mean Average Precision) -that express the mean of the precision after each relevant document has been retrieved. This metric emphasizes the earlier relevant documents retrieved; ii ) precision -expresses how many relevant documents were retrieved in relation to the number of retrieved documents; iii ) recallexpresses how many relevant documents were retrieved in relation to the entire collection.</p><p>Only 19 from 50 topics (38%) have expressed better MAP compared to the first run (initial queries). There was only one draw for one topic that did not return results in the first run and, therefore, could not be expanded. It was verified that 30 topics from the second run presented a loss of precision (MAP) compared to the first run. This means that, despite of expansion had presented more relevant documents for the majority of topics, it also returned much more irrelevant documents over time, scattering the relevant ones among them, harming the ranking for the returned set. This justifies the loss of precision at interpolated levels of recall.</p><p>The MAP metric for both runs can be expressed by topic in a bar chart, as shown in Figure <ref type="bibr" coords="6,497.51,465.67,11.62,8.74" target="#b1">(2)</ref>. The NILC01 MAP is of 35.20%, and for the NILC02 run is of 29.01%. The precision and recall are mapped in an area chart, as shown in Figure <ref type="bibr" coords="6,289.13,489.58,11.62,8.74" target="#b2">(3)</ref>, that figures out the trade-off between precision for each level of recall, in a percentage scale, for all topics. No intervention was made in the parameters that prevails the behavior of the IR system while NILC02 run was processing all topics at once. After the experiment was submitted, it was perceived that the initial query quality is the main factor to influence the query expansion. There are others factors that intervenes in the process over each topic, such as i ) the number of noun </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The IR field has always used basic NLP techniques to aid document structuring process. However, only in the past few years researches have pointed out advances related to a more sophisticated generation of NLP techniques that justify the cost for its use, comparing to the traditional approaches.</p><p>This work investigated evidences that serves as a base to the hypothesis that applying linguistic knowledge methods is viable, contributing to the traditional statistical methods available. It was presented one technique of local analysis for query expansion without user intervention, according to a linguistically motivated model based on noun phrases. These structures carry information with a highly discriminative power, therfore playing a better role as descriptors in text representation models.</p><p>The obtained results encourage us to the individual manipulation of each expanded query for each topic before submitting it to the system. This may allow achieving better combinations of system parameters, revealing more conclusive results regarding the experiment.</p><p>The high computational cost (time and space complexity) demanded by the preprocessing and indexing stages allow the use of linguistic resources on appropriate data structures to be better explored by the user at search time. The time for expanding the query triggered at execution phase, using previously indexed linguistic knowledge, is highly acceptable and does not negatively intervene in user experience.</p><p>There are open research possibilities to explore how other processes could be benefited by the use of linguistically motivated text representations, using noun phrases, for example, specially for the Portuguese language. One example could be to evaluate the impact of these structures in automatic text categorization processes, that can be used to filter irrelevant documents at search time, contributing to increase the effectiveness of such IR systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,210.69,446.04,181.62,8.74;3,181.50,288.13,240.00,142.80"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Transformation Based Learning</figDesc><graphic coords="3,181.50,288.13,240.00,142.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,242.91,659.02,117.16,8.74;6,147.45,522.23,308.10,121.68"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MAP over topics</figDesc><graphic coords="6,147.45,522.23,308.10,121.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,212.87,238.21,177.25,8.74;7,146.66,108.86,309.68,114.24"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Precision at each 10% of recall</figDesc><graphic coords="7,146.66,108.86,309.68,114.24" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,711.02,57.92,6.99"><p>nilc.icmc.usp.br</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.24,695.06,407.76,9.00;4,90.00,706.54,244.53,6.99"><p>complete editions from 1994 and 1995 of journals P ÚBLICO (www.publico.pt) and Folha de São Paulo (www.folha.com.br), compiled by Linguateca (www.linguateca.pt)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,105.24,716.04,162.06,6.99"><p>Maximum Entropy, de Adwait Ratnaparkhi</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,105.24,725.55,189.89,6.99"><p>http://www.nilc.icmc.usp.br/lacioweb/corpora.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,105.24,735.05,144.72,6.99"><p>http://www.nilc.icmc.usp.br/lacioweb/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,105.24,744.56,189.89,6.99"><p>http://www.nilc.icmc.usp.br/lacioweb/corpora.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,105.24,738.28,136.42,6.99"><p>Chris Buckley -http://trec.nist.gov/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.48,654.54,402.51,8.74;7,110.48,666.50,352.57,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,148.68,654.54,364.32,8.74;7,110.48,666.50,134.16,8.74">Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,253.40,666.50,113.08,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="565" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,686.42,402.52,8.74;7,110.48,698.38,402.52,8.74;7,110.48,710.33,231.64,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,431.10,686.42,81.90,8.74;7,110.48,698.38,269.82,8.74">A anotação de um corpus para o aprendizado supervisionado de um modelo de sn</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Garrãoo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Silveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,400.40,698.38,112.60,8.74;7,110.48,710.33,112.55,8.74">Proceedings of the III TIL / XXV Congresso da SBC</title>
		<meeting>the III TIL / XXV Congresso da SBC<address><addrLine>São Leopoldo -RS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,730.26,402.52,8.74;7,110.48,742.21,384.16,8.74" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gonzalez</surname></persName>
		</author>
		<title level="m" coord="7,171.37,730.26,313.06,8.74">Termos e Relacionamentos em Evidência na Recuperação de Informação</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Universidade Federal do Rio Grande do Sul (UFRGS</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Tese de Doutorado</note>
</biblStruct>

<biblStruct coords="8,110.48,112.02,402.52,8.74;8,110.48,123.98,402.52,8.74;8,110.48,135.93,223.61,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,321.46,112.02,191.54,8.74;8,110.48,123.98,153.90,8.74">Recuperação de informação e expansão automática de consulta com thesaurus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A I</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">L</forename><surname>Strube De Lima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,284.87,123.98,228.13,8.74;8,110.48,135.93,53.46,8.74">XXVII Conferência Latinoamericana de Informática (CLEI&apos;2001)</title>
		<meeting><address><addrLine>Mérida, Venezuela</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,155.86,317.75,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,156.79,155.86,159.78,8.74">Mathematical Structures of Language</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<pubPlace>New York -USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,175.78,402.51,8.74;8,110.48,187.74,281.96,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,177.44,175.78,330.95,8.74">Sintagmas nominais: uma nova proposta para a recuperação de informação</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kuramoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.48,187.74,227.37,8.74">DataGramaZero -Revista de Ciência da Informação</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,207.66,402.53,8.74;8,110.48,219.62,402.52,8.74;8,110.48,231.57,402.52,8.74;8,110.48,243.53,402.51,8.74;8,110.48,255.48,275.53,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,301.11,207.66,211.90,8.74;8,110.48,219.62,39.86,8.74">Evaluation of a thesaurus-based query expansion technique</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A S</forename><surname>Pizzato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">L</forename><surname>Strube De Lima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,110.48,231.57,402.52,8.74;8,110.48,243.53,85.44,8.74">Proceedings of the 6th Workshop on Computacional Processing of the Portuguese Language -Written and Spoken</title>
		<title level="s" coord="8,204.28,243.53,153.97,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mamede</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Baptista</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Trancoso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Volpe</surname></persName>
		</editor>
		<editor>
			<persName><surname>Nunes</surname></persName>
		</editor>
		<meeting>the 6th Workshop on Computacional Processing of the Portuguese Language -Written and Spoken<address><addrLine>Faro, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="volume">2721</biblScope>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,275.41,402.52,8.74;8,110.48,287.36,294.42,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,249.60,275.41,263.40,8.74;8,110.48,287.36,148.52,8.74">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,279.72,287.36,25.86,8.74">SIGIR</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,307.29,402.52,8.74;8,110.48,319.24,402.52,8.74;8,110.48,331.20,109.95,8.74" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N</forename><surname>Santos</surname></persName>
		</author>
		<title level="m" coord="8,175.71,307.29,337.29,8.74;8,110.48,319.24,82.40,8.74">Aprendizado de Máquina na identificação de sintagmas nominais: o caso do português brasileiro</title>
		<meeting><address><addrLine>Rio de Janeiro</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Instituto Militar de Engenharia (IME)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Dissertação de Mestrado</note>
</biblStruct>

<biblStruct coords="8,110.47,351.12,402.52,8.74;8,110.48,363.08,229.77,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,213.36,351.12,299.64,8.74;8,110.48,363.08,32.82,8.74">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,151.81,363.08,97.04,8.74">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
