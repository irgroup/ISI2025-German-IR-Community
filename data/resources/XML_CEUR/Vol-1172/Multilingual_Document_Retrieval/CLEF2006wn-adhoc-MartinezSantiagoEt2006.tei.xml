<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.47,146.21,320.04,18.08;1,104.39,168.13,394.21,18.08;1,212.09,190.05,178.81,18.08">SINAI at CLEF 2006 Ad Hoc Robust Multilingual Track: query expansion using the Google search engine</title>
				<funder ref="#_bhqhSW5">
					<orgName type="full">Spanish Government (MCYT)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,95.98,225.11,121.82,10.46"><forename type="first">Fernando</forename><surname>Martínez-Santiago</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Jaén</orgName>
								<address>
									<settlement>Jaén</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.68,225.11,91.12,10.46"><forename type="first">Arturo</forename><surname>Montejo-Ráez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Jaén</orgName>
								<address>
									<settlement>Jaén</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.95,225.11,124.06,10.46"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>García-Cumbreras</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Jaén</orgName>
								<address>
									<settlement>Jaén</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,463.26,225.11,103.86,10.46"><forename type="first">L</forename><surname>Alfonso Ureña-López</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Jaén</orgName>
								<address>
									<settlement>Jaén</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.47,146.21,320.04,18.08;1,104.39,168.13,394.21,18.08;1,212.09,190.05,178.81,18.08">SINAI at CLEF 2006 Ad Hoc Robust Multilingual Track: query expansion using the Google search engine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B308DDDB2A6CE0B044619D2205A37A8C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This year, we have participated on Ad-Hoc Robust Multilingual track with the aim to evaluate two issues of CLIR systems. Firstly, this paper describes the method followed for query expansion in a multilingual environment by using web search results provided by the Google engine in order to increment retrieval robustness. Unfortunately, the results obtained are disappointing. The second issue reported is relative to the robustness of several usual merging algorithms. We have found that 2-step RSV merging algorithms perform better than others algorithms when geometric precision is applied.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Robust retrieval has been a task in the TREC evaluation forum <ref type="bibr" coords="1,372.57,433.33,9.96,10.46" target="#b4">[5]</ref>. One of the most performant systems proposed involves query expansion through web assistance <ref type="bibr" coords="1,382.33,445.28,10.52,10.46" target="#b7">[8,</ref><ref type="bibr" coords="1,395.87,445.28,7.75,10.46" target="#b6">7,</ref><ref type="bibr" coords="1,406.64,445.28,7.01,10.46" target="#b5">6]</ref>. We have followed the approach of Kwok and his collegues and applied it for robust multilingual retrieval.</p><p>Pseudo-relevance feedback has been traditionally used to generate new queries from the results obtained from a given source query. In this way, the search is launched twice: one for obtaining first relevant documents wherefrom new query terms are extracted, and a second turn to obtain final retrieval results. This method has been found useful to resolve queries producing small result sets, and is a way to expand queries with new terms that can make the scope of the search wider. But pseudo-relevance feedback is not that useful when queries are so difficult that very few or no documents are obtained at first stage (the so-called weak queries). In that case, there is a straighforward solution: use another and richer collection to expand the query. Here, Internet plays a central role: it is a huge amount of web pages where almost any query, no matter how difficult it is, may be related to some subset of those pages. This approach has obtained remarkable results in monolingual IR systems evaluated in TREC conferences. Unexpectedly, in a multilingual scenario the obtained results are very poor and we think that our implementation of the approach must be tunned for CLEF queries, in spite of our conviction that an intensive tuning work is unrealistic for real-world systems. In addition, such as we suspected, the quality of the expanded terms depend on the selected language.</p><p>On the other hand, we have evaluated several merging algorithms from the perspective of robustness: round-Robin, raw scoring, normalized raw scoring, logistic regression, raw mixed 2step RSV, mixed 2-step RSV based on logistic regression and mixed 2-step RSV based on bayesian logistic regression. We have found that round-Robin, raw scoring and methods based on logistic regression perform worse than 2-step RSV merging algorithms.</p><p>The rest of the paper has been organized into three main sections: first, we describe the experimentation framework, then we report our bilingual experiments with web-based expansion queries, and finally we describe the multilingual experiments and the way the geometric precision affects to several merging algorithms.</p><p>In this section we describe briefly the architecture of the multilingual system, translation approaches, query preprocessing and merging approaches.</p><p>Our Multilingual Information Retrieval System uses English as the selected topic language, and the goal is to retrieve relevant documents for all languages in the collection, listing the results in a single, ranked list. In this list there is a set of documents written in different languages retrieved as an answer to a query in a given language, English in our case. There are several approaches for this task, such as translating the whole document collection to an intermediate language or translating the question to every language found in the collection. Our approach is the latter: we translate the query for each language present in the multilingual collection. Thus, every monolingual collection must be preprocessed and indexed separately. The preprocessing and indexing tasks are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing and translation resources</head><p>In CLEF 2006 the multilingual task is made up by six languages: Dutch, English, French, German, Italian and Spanish. The pre-processing of the collections is the usual in CLIR, taking into account lexicographical and morphological idiosyncratic of every language. The pre-processing is summarized in table 1.</p><p>• English has been pre-processed as usually done in past years. Stop-words have been eliminated and we have used the Porter algorithm <ref type="bibr" coords="2,309.36,367.93,17.72,10.46" target="#b11">[11]</ref> as it is implemented in the ZPrise system.</p><p>• Dutch, German and Swedish are agglutinative languages. Thus, we have used the decompounding algorithm depicted in <ref type="bibr" coords="2,258.07,399.81,14.61,10.46" target="#b10">[10]</ref>. Stopword list and stemmer algorithm have been obtained in the Snowball site<ref type="foot" coords="2,234.80,410.69,3.97,7.32" target="#foot_0">1</ref> .</p><p>• The resources for French and Spanish have been updated by using the stop-word lists and stemmers from http://www.unine.ch/info/clef. The translation from English has been carried out by using Reverso<ref type="foot" coords="2,226.46,454.52,3.97,7.32" target="#foot_1">2</ref> software.</p><p>• Dutch and Swedish translations have been carried out by using online FreeTrans service Reverso Reverso Reverso FreeTrans</p><p>Once collections have been pre-processed, they are indexed with the IR-N [14], a IR system based on passage retrieval. OKAPI model has also been used for the on-line re-indexing process required by the calculation of 2-step RSV, using the OKAPI probabilistic model (fixed empirically at b = 0.75 and k1 = 1.2) <ref type="bibr" coords="2,200.48,626.85,14.61,10.46" target="#b12">[12]</ref>. As usual, we have not used blind feedback because the improvement is very poor for these collections, the precision is even worse for some languages (English and Swedish).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Merging strategies</head><p>This year we have selected the following merging algorithms: round-Robin, raw scoring, normalized raw scoring, logistic regression, raw mixed 2-step RSV, mixed 2-step RSV based on logistic regression and mixed 2-step RSV based on bayesian logistic regression:</p><p>• Round-Robin fashion. The documents are interleaved according to rank obtained for each document by means of monolingual information retrieval processing. Thus, given a multilingual collection and N languages, the first document for each monolingual retrieval list will constitute M first documents, the second document of each list will constitute the next M documents, and so on. In this case, the hypothesis is the homogeneous distribution of relevant documents across the collections. This merging process decreases precision about 40% because of the merging process <ref type="bibr" coords="3,274.81,246.48,15.50,10.46" target="#b15">[15,</ref><ref type="bibr" coords="3,293.62,246.48,11.62,10.46" target="#b18">18]</ref>.</p><p>• Raw-scoring. This method produces a final list sorted by document score computed independently for each monolingual collection. This method works well whether each collection is searched by the same or a very similar search engine and query terms are distributed homogeneously over all the monolingual collections. Heterogenous term distribution will mean that query weights may vary widely among collections <ref type="bibr" coords="3,358.89,314.23,9.96,10.46" target="#b8">[9]</ref>, and therefore this phenomenon may invalidate the raw-score merging hypothesis.</p><p>• Normalized scoring. An attempt to make document scores comparable is by normalizing in some way the document score reached for each document:</p><p>-Given a monolingual collection, by dividing each RSV by the maximum RSV reached in such a collection:</p><formula xml:id="formula_0" coords="3,248.18,399.75,264.82,24.03">RSV i = RSV i max(RSV ) , 1 &lt;= i &lt;= N<label>(1)</label></formula><p>-A variant of the previous method is to divide each RSV by the difference between the maximum and minimum document score values <ref type="bibr" coords="3,347.84,452.31,15.50,10.46" target="#b17">[17]</ref> reached for each collection:</p><formula xml:id="formula_1" coords="3,218.74,474.73,294.26,24.03">RSV i = RSV i -min(RSV ) max(RSV ) -min(RSV ) , 1 &lt;= i &lt;= N (2)</formula><p>• Original 2-step RSV merging strategy consists of calculating a new RSV (Retrieval Status Value) for each document in the ranked lists at every monolingual list. The new RSV, called two-step RSV, is calculated by reindexing the retrieved documents according to a vocabulary generated from query translations, where words are aligned by meaning, i.e. each word is aligned with its translations <ref type="bibr" coords="3,300.87,557.04,14.61,10.46" target="#b10">[10]</ref>. The query is translated using an approach based on Machine Translation (MT), when available. Note that since MT translates the whole of the phrase better than word for word, the 2-step RSV merging algorithm is not directly feasible with MT. Thus, we proposed a straightforward and effective algorithm in order to align the original query and its translation at term level.</p><p>Although the proposed algorithm to align phrases and translations at term level works well, it does not obtain fully aligned queries. In order to improve the system performance when some terms of the query are not aligned, we generate two subqueries. The first one is made up by the aligned terms only and the other one is formed with the non-aligned terms. Thus, for each query every retrieved document obtains two scores. The first score is obtained by using the 2-step RSV merging algorithm over the first subquery. In contrast, the second subquery is used in a traditional monolingual system with the respective monolingual list of documents. Therefore, we have two scores for each query, one is global for all languages and the other is local for each language. Thus we have to integrate both values. As a way to deal with partially aligned queries (i.e. queries with some terms not aligned), we have used raw mixed 2-step RSV and logistic regression:</p><p>-Raw mixed 2-step RSV method:</p><formula xml:id="formula_2" coords="4,225.05,127.15,287.95,14.88">RSV i = α • RSV align i + (1 -α) • RSV nonalign i (3)</formula><p>where RSV align i is the score calculated by means of aligned terms, as original 2-step RSV method shows.On the other hand, RSV nonalign i is calculated locally. Finally, α is a constant (usually fixed to α = 0.75).</p><p>-Logistic regression: <ref type="bibr" coords="4,224.07,189.78,15.50,10.46" target="#b16">[16]</ref> proposes a merging approach based on logistic regression. Logistic regression is a statistical methodology for predicting the probability of a binary outcome variable according to a set of independent explanatory variables. The probability of relevance to the corresponding document D i will be estimated according to both the original score and logarithm of the ranking. Based on these estimated probabilities of relevance, the monolingual list of documents will be interleaved forming a single list:</p><formula xml:id="formula_3" coords="4,204.64,272.21,308.36,25.29">P rob[D i is rel|rank i , rsv i ] = e α+β 1 •ln(rank i )+β 2 •rsv i 1 + e α+β 1 •ln(rank i )+β 2 •rsv i (4)</formula><p>The coefficients α, β 1 and β 2 are unknown parameters of the model. The usual methods when fitting the model tend to be maximum likelihood or iteratively re-weighted least squares methods. Because this approach requires fitting the underlying model, the training set (topics and their relevance assessments) must be available for each monolingual collection. In the same way that the score and ln(rank) evidence was integrated by using logistic regression (Formula 4), we are able to integrate RSV align and RSV nonalign values:</p><formula xml:id="formula_4" coords="4,196.06,387.26,312.69,29.27">P rob[D i is rel|Θ] = e α+β1•ln(ranki)+β2•rsv align i +β3•rsv nonalign i 1 + e α+β 1 •rsv align i +β 2 •rsv nonalign i (<label>5</label></formula><formula xml:id="formula_5" coords="4,508.76,396.74,4.24,10.46">)</formula><p>where Θ = rank i , rsv align i , rsv nonalign i and RSV align i and RSV nonalign i are calculated as Formula 3. Again, training data must be available in order to fit the model. This is a serious drawback, but this approach allows integrating not only aligned and non-aligned scores but also the original rank of the document: </p><formula xml:id="formula_6" coords="4,165.15,479.50,170.42,19.17">P rob[D i is rel|Θ] = e α+β 1 •ln(rank i )+β</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Query expansion using the Internet as resource</head><p>Expanding user queries by using web search engines such as Google has been successfully used for improving robustness of retrieval systems over collections in English language. Due to the multilinguality of the web, we have assumed that this could be extended to additional languages, though the smaller amount of non-english web pages could represent an important drawback. In figure <ref type="figure" coords="4,117.33,661.14,4.98,10.46">1</ref> the process for query expasion by using the Internet is drawn. The process is splitted into the following steps:</p><p>1. Web query generation. First, we take the original query and generate a set of words that will be used to search the web. Since queries in CLIR contain title and description fields, it is important to define how terms are taken from these fields. Depending whether we consider the title field or the description field, the generation of the query varies:</p><p>• From title. Experiments expanding queries based just on the title field take all the terms in the field in lower case joined with the AND operator.</p><p>• From description. For those experiments where the description field is the source of terms to generate the web query, a selection of terms has to be done. For that, stop words are removed (using a different list according to the language the description is written in) and the top 5 ranked terms are taken to compose, as for the title field, an AND query. The score computed for each term to rank them obeys the following formula:</p><formula xml:id="formula_7" coords="5,267.16,206.24,245.84,26.01">w k = (F k /D k ) 1.5 log(max{2000, D k }) (7)</formula><p>where w k is the weight of term k F k is the frequency of term k (number of ocurrence in the description field) D k is the document frecuency of term k (number of fields the term appears in)</p><p>Figure <ref type="figure" coords="5,227.44,452.18,3.91,10.57">1</ref>: Using the Internet for query expansion 2. Web search Once the web query has been composed, the web search engine is called to retrieve relevant documents. For this, the Google API (Application Programming Interface) enables the use of its search engine facilities inside our programs. Thus, we can automate the process of query expansion through Google using its Java API. This web search is done specifying the language of the documents expected for the retrieval. Therefore, a filter on the language is set on the Google engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Term selection from web results</head><p>Google returns documents in order of relevance in groups of 10 items; our implementation takes into account the 20 top ranked items (thus, the first two pages of search results). Each item points to an URL but also contains the so-called "snippet", which is a selection of text fragments from the original pages containing the terms involved in the web search (i.e. the query terms). This kind of summary is intented to let the user better follow those links that are of its real interest. In our implementation of query expansion by using web documents we have performed experiments using just the snippets as retrieved text in order to propose new query terms, and also experiments where terms are selected from full web page content (dowloading the document from the returned URL).</p><p>In both cases (selection of terms from snippets or selection from full web pages), the final set of terms is the composite of those 60 terms with the highest frequency after discarding stop words. Of course, in the case of full web pages, the HTML tags are also conveniently eliminated. To generate the final expanded query, terms are repeated according to its frequency (normalized to that of the least frequent term in the group of 60 selected terms).</p><p>As an example of the queries generated by the described process, for a title with words "inondation pays bas allemagne" the resulting expansion would produce the text: pays pays pays pays pays pays pays pays pays pays pays pays pays pays pays pays pays bas bas bas bas bas bas bas bas bas bas bas bas bas allemagne allemagne allemagne allemagne allemagne allemagne allemagne inondations inondations inondations france france france inondation inondation inondation sud sud cles cles belgique belgique grandes grandes histoire middot montagne delta savent fluviales visiteurs exportateur engag morts pend rares projet quart amont voisins ouest suite originaires huiti royaume velopp protection luxembourg convaincues galement taient dues domination franque xiii tre rent commenc temp monarchie xii maritime xive proviennent date xiiie klaas xiie ques connu or sinter ans anglophones</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiments and results</head><p>For every language we have generated four different collections of queries, one without expansion and three with web-based expansion:</p><p>1. base -No expansion, the original query is used and its results taken as base case 2. sd-esnp -Expansion using the original description field for web query generation and final terms selected from snippets 3. st-esnp -Expansion using the original title field for web query generation and final terms selected from snippets 4. st-efpg -Expansion using the original title field for web query generation and final terms selected from full web pages Results obtained are discouraging as all our expansions lead to worse measurements of both Rprecision and average precision. Figures <ref type="figure" coords="6,265.47,473.63,4.98,10.46">2</ref> and<ref type="figure" coords="6,291.76,473.63,4.98,10.46" target="#fig_0">3</ref> show graphically values obtained when evaluating on these measures. For technical reasons the expansion of type st-efpg for Dutch was not generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: R-precision measurements</head><p>In a robust evaluation the key measure should the geometric average precision since it emphasizes the effect of improving retrieved documents on weak queries, as the task itself defines. For future work we plan to study the value obtained on such a measure when using expanded queries and when merging retrieved items in a multilingual retrieval, as it is difficult to explain the godness of our approach on the robust task without it.</p><p>From the results above some conclusions can be extracted. The main one is that the title field is a much more suitable source of items for a web-based expansion. Indeed, for many authors the title can be considered as the set of query terms that the users should pass to a search engine. Thus, web query generation from the description field even using sophisticated formulae is, as results reflect, a worse choice when a title field is available.</p><p>The second observation is on the fact of very similar results independently on the final selection of terms, that is, it seems that the decision of taking final terms either from snippets or from full web pages text does not determine significant differences on results obtained. This issue needs further investigation since expanded queries are quite different on the last half of the selected terms (those that are less frequent) and these results make us think of the system not profiting from the full set of terms passed.</p><p>As last underlined point, we find that results depends on the language under study. We think this is due to differences on the size of existing collections of pages for each language found in the web, and that could explain the slightly better results in the case of English compared to the rest of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multilingual experiments</head><p>As the section 2 is depicted, the merging algorithm is the only difference between all our multilingual experiments. Table <ref type="table" coords="7,223.12,597.87,4.98,10.47" target="#tab_2">2</ref> show the obtained results in terms of 11-pt average precision, R-precision and the new measure geometric precision. From the point of view of the average precision, the more interesting result is the relatively poor result obtained by the methods based on machine learning. Thus, mixed 2-step RSV-LR and mixed 2-step RSV-BLR performs slightly worse than mixed 2-step RSV-LC in spite of this last approach does not use any training data. As usual, logistic regression performs better than round-Robin and raw scoring, but the difference is not as relevant as other years. Thus, we think that difficult queries are not learned as good as usual queries, probably because, given a hard query, the relation between score, ranking and relevance of a document is not clear at all, therefore machine learning approaches are not capable to learn a good enough prediction function. In the same way, this year there are not only hard queries, but also very heterogeneous queries too, from the point of view of average precision. Thus, the distribution of average precision is very smooth and it makes more difficult extracting useful information from the training data. Since the 2-step RSV overcomes largely the rest of tested merging algorithms when they are evaluated by using geometric precision measure, we think that 2-step RSV merging algorithm is better suited than other merging algorithms in order to improve the robustness of CLIR systems. In this way, if we use geometric precision to evaluate de CLIR system, the difference of performance between results by using 2-step RSV and the rest of merging algorithms is higher than by using traditional 11Pt-AvP or R-precision measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have reported our experimentation for Ad-Hoc Robust Multilingual track CLEF task about web-based query expansion for other languages than English. Firstly, we try to apply the expansion of queries by using web search engine such as Google. This approach has obtained remarkable results in monolingual IR systems evaluated in TREC conferences. But in a multilingual scenario the obtained results are very poor and we think that our implementation of the approach must be tunned for CLEF queries, in spite of our belief in that an intensive tuning work is unrealistic for real-world systems. In addition, such as we suspected, the quality of the expanded terms depend on the selected language. The second issue reported is relative to the robustness of several usual merging algorithms. We have found that Round-Robin, raw scoring and methods based on logistic regression performs worst from the point of view of robustness. On the other hand, 2-step RSV merging algorithms perform better than the others algorithms when geometric precision is applied. Anyway, we think that the development of a robust CLIR system does not require special merging approaches, it "only" requires good merging approaches. Maybe that other CLIR problems such as translation strategies or the development or an effective multilingual query expansion should be revisited in order to obtain such a robust CLIR model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,209.03,295.96,185.09,10.47"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Average precision measurements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,108.60,474.45,397.61,101.03"><head></head><label></label><figDesc>3 .</figDesc><table coords="2,108.60,516.26,378.47,59.22"><row><cell cols="6">Table 1: Language preprocessing and translation approach</cell><cell></cell></row><row><cell></cell><cell>Dutch</cell><cell cols="4">English French German Spanish</cell><cell>Italian</cell></row><row><cell>Preprocessing</cell><cell></cell><cell cols="4">stop words removed and stemming</cell><cell></cell></row><row><cell>Decompounding</cell><cell>yes</cell><cell>no</cell><cell>no</cell><cell>yes</cell><cell>no</cell><cell>yes</cell></row><row><cell cols="2">Translation approach FreeTrans</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,118.58,117.46,365.83,108.64"><head>Table 2 :</head><label>2</label><figDesc>Multilingual results. Raw mixed 2-step RSV is the</figDesc><table coords="8,118.58,129.16,365.83,96.94"><row><cell>Merging approach</cell><cell cols="3">11Pt-AvgP R-precision Geometric Precision</cell></row><row><cell>round-robin</cell><cell>23.20</cell><cell>25.21</cell><cell>10.12</cell></row><row><cell>raw scoring</cell><cell>22.12</cell><cell>24.67</cell><cell>10.01</cell></row><row><cell>normalized Raw scoring</cell><cell>22.84</cell><cell>23.52</cell><cell>10.52</cell></row><row><cell>logistic regression</cell><cell>25.07</cell><cell>27.43</cell><cell>12.32</cell></row><row><cell>raw mixed 2-step RSV</cell><cell>27.84</cell><cell>32.70</cell><cell>15.70</cell></row><row><cell>mixed 2-step RSV based on LR</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mixed 2-step RSV based on BLR</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,670.57,407.87,8.37;2,90.00,680.04,312.96,8.37"><p>Snowball is a small string-handling language in which stemming algorithms can be easily represented. Its name was chosen as a tribute to SNOBOL. Available at http://www.snowball.tartarus.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,689.54,173.93,8.37"><p>Reverso is available on-line at www.reverso.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,699.04,212.52,8.37"><p>FreeTrans is available on-line at www.freetranslation.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,105.24,745.85,268.14,8.37"><p>BBR software available at http://www.stat.rutgers.edu/ madigan/BBR.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>This work has been supported by <rs type="funder">Spanish Government (MCYT)</rs> with grant <rs type="grantNumber">TIC2003-07158-C04-04</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bhqhSW5">
					<idno type="grant-number">TIC2003-07158-C04-04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,105.50,650.62,317.41,10.46" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,179.89,650.62,149.78,10.46">The TREC Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">TREC Report</note>
</biblStruct>

<biblStruct coords="8,105.50,669.84,407.50,10.46;8,105.50,681.79,236.69,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,259.20,669.84,253.80,10.46;8,105.50,681.79,51.73,10.46">Improving Weak Ad-Hoc Retrieval by Web Assistance and Data Fusion</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,165.07,681.79,23.94,10.46;8,218.35,681.79,26.43,10.46">AIRS</title>
		<imprint>
			<biblScope unit="volume">3689</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct coords="8,105.50,701.02,407.51,10.46;8,105.50,712.98,83.34,10.46" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="8,315.75,701.02,197.26,10.46;8,105.50,712.98,27.84,10.46">TREC2004 Robust Track Experiments using PIRCS</title>
		<imprint>
			<date type="published" when="2004">2004. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.50,732.21,407.51,10.46;8,105.50,744.16,139.65,10.46" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dinstl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="8,329.42,732.21,183.59,10.46;8,105.50,744.16,110.89,10.46">TREC2003 Robust, HARD and QA Track Experiments using PIRCS</title>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,105.50,110.53,317.41,10.46" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,179.89,110.53,149.78,10.46">The TREC Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">TREC Report</note>
</biblStruct>

<biblStruct coords="9,105.50,130.46,407.50,10.46;9,105.50,142.41,236.69,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,259.20,130.46,253.80,10.46;9,105.50,142.41,51.73,10.46">Improving Weak Ad-Hoc Retrieval by Web Assistance and Data Fusion</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,165.07,142.41,23.94,10.46;9,218.35,142.41,26.43,10.46">AIRS</title>
		<imprint>
			<biblScope unit="volume">3689</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct coords="9,105.50,162.34,407.51,10.46;9,105.50,174.29,83.34,10.46" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="9,315.75,162.34,197.26,10.46;9,105.50,174.29,27.84,10.46">TREC2004 Robust Track Experiments using PIRCS</title>
		<imprint>
			<date type="published" when="2004">2004. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,105.50,194.22,407.51,10.46;9,105.50,206.18,139.65,10.46" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dinstl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Deng</surname></persName>
		</author>
		<title level="m" coord="9,329.42,194.22,183.59,10.46;9,105.50,206.18,110.89,10.46">TREC2003 Robust, HARD and QA Track Experiments using PIRCS</title>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,105.50,226.11,407.50,10.46;9,105.50,238.06,192.04,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,167.00,226.11,197.32,10.46">Latent Semantic Indexing (LSI) and TREC-2</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,373.65,226.11,99.43,10.46">Proceedings of TREC&apos;2</title>
		<meeting>TREC&apos;2<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,300.86,238.06,95.37,10.46" xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Nist</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Harman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,257.99,402.52,10.46;9,105.50,269.94,372.88,10.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,340.31,257.99,172.70,10.46;9,105.50,269.94,124.85,10.46">A merging strategy proposal: two step retrieval status value method</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martinez-Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,238.78,269.94,93.25,10.46">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="93" />
			<date type="published" when="2006-01">Jan 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,289.86,349.94,10.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,168.65,289.86,138.01,10.46">An algorithm for sufix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,314.14,289.86,36.55,10.46">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,309.79,402.53,10.46;9,105.50,321.74,308.73,10.46" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,319.58,309.79,193.42,10.46;9,105.50,321.74,25.02,10.46">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,140.09,321.74,176.90,10.46">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,341.67,402.52,10.46;9,105.50,353.62,276.18,10.46" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,153.11,341.67,355.42,10.46">Cross-Language information retrieval: experiments based on CLEF 2000 corpora</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,105.50,353.62,176.89,10.46">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="75" to="115" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,373.55,402.52,10.46;9,105.50,385.50,218.76,10.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,446.84,373.55,66.16,10.46;9,105.50,385.50,131.35,10.46">IR-n System, a Passage Retrieval Architecture</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mariano</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hector</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Espi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,244.68,385.50,17.48,10.46">TSD</title>
		<imprint>
			<biblScope unit="page" from="57" to="64" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,405.43,402.53,10.46;9,105.50,417.39,407.50,10.46;9,105.50,429.34,125.67,10.46" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,267.67,405.43,240.75,10.46">Searching distributed collections with inference networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,105.50,417.39,319.70,10.46">Proceedings of the 18th International Conference of the ACM SIGIR&apos;95</title>
		<meeting>the 18th International Conference of the ACM SIGIR&apos;95<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,449.27,402.52,10.46;9,105.50,461.22,206.27,10.46" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,214.36,449.27,238.82,10.46">Database merging strategy based on logistic regression</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Calve</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,460.91,449.27,52.09,10.46;9,105.50,461.22,121.24,10.46">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,481.15,402.52,10.46;9,105.50,493.10,407.51,10.46;9,105.50,505.06,332.13,10.46" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,408.57,481.15,104.44,10.46;9,105.50,493.10,149.96,10.46">The impact of database selec-tion on distributed searching</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Viles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,373.80,493.10,139.21,10.46;9,105.50,505.06,184.17,10.46">Proceedings of the 23rd International Conference of the ACM-SIGIR&apos;2000</title>
		<meeting>the 23rd International Conference of the ACM-SIGIR&apos;2000<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="232" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,524.98,402.52,10.46;9,105.50,536.93,407.50,10.46;9,105.50,548.90,407.51,10.46;9,105.50,560.85,52.72,10.46" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="9,344.67,524.98,132.24,10.46">The collection fusion problem</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Johnson-Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,180.05,536.93,251.77,10.46">Proceedings of the 3th Text Retrieval Conference TREC-3</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the 3th Text Retrieval Conference TREC-3<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>National Institute of Standards and Technology</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
	<note>Special Publication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
