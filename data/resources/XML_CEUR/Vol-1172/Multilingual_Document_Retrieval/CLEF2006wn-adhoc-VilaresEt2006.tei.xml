<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.62,148.63,421.41,15.60;1,179.95,170.63,242.88,16.35">CoLesIR at CLEF 2006: Rapid Prototyping of an N -gram-Based CLIR System</title>
				<funder ref="#_5QMTaNX">
					<orgName type="full">Dirección Xeral de Investigación, Desenvolvemento e Innovación (Programa de Recursos Humanos grants)</orgName>
				</funder>
				<funder ref="#_nwDD9F3">
					<orgName type="full">Xunta de Galicia</orgName>
				</funder>
				<funder ref="#_U8SKTkm">
					<orgName type="full">Ministerio de Educación y Ciencia and FEDER</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,143.70,204.56,65.41,9.02"><forename type="first">Jesús</forename><surname>Vilares</surname></persName>
							<email>jvilares@udc.es</email>
						</author>
						<author>
							<persName coords="1,339.51,204.56,86.50,9.02"><forename type="first">Michael</forename><forename type="middle">P</forename><surname>Oakes</surname></persName>
							<email>michael.oakes@sunderland.ac.uk</email>
						</author>
						<author>
							<persName coords="1,352.91,218.51,59.73,9.02"><forename type="first">John</forename><forename type="middle">I</forename><surname>Tait</surname></persName>
							<email>john.tait@sunderland.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="institution">Universidade da Coruña Campus de Elviña</orgName>
								<address>
									<postCode>15071</postCode>
									<settlement>-La Coruña (</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Sunderland St. Peter&apos;s Campus</orgName>
								<address>
									<addrLine>St. Peter&apos;s Way Sunderland</addrLine>
									<postCode>SR6 0DD</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.62,148.63,421.41,15.60;1,179.95,170.63,242.88,16.35">CoLesIR at CLEF 2006: Rapid Prototyping of an N -gram-Based CLIR System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">036D2DC35226A793494702BD9C87417C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-Indexing methods, Linguistic processing</term>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Query formulation</term>
					<term>J.5 [Arts and Humanities]: Language translation Algorithms, Measurement, Performance, Experimentation Cross-Language Information Retrieval, character n-grams, translation algorithms, alignment algorithms, association measures</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this our first joint participation as the CoLesIR group, our team has participated in the Portuguese monolingual ad-hoc task and in all robust ad-hoc tasks -all monolingual tasks, the English-to-German bilingual task, and the multilingual task.</p><p>We have developed an n-gram model inspired by the previous work of the Johns Hopkins University Applied Physics Lab. Our approach makes generalized use of freely available resources -such as the Europarl parallel corpus, the GIZA++ wordalignment toolkit, and the Terrier retrieval platform-, and employs a new n-gram direct translation technique. This new technique takes as input previously existing aligned word lists and obtains as output aligned n-gram lists. It can also handle word translation probabilities, as in the case of statistical word alignments.</p><p>This new n-gram-based approach shares the main advantages of the original proposal. This solution avoids the need for word normalization during indexing or translation, and it can also deal with out-of-vocabulary words. Since it does not rely on language-specific processing, it can be applied to very different languages, even when linguistic information and resources are scarce or unavailable. Our proposal adds to these characteristics a higher speed during the n-gram alignment process.</p><p>Unfortunately, lack of time did not allow us to get our n-gram direct translation system ready on time. This way, we could submit only those initial results to be used as baselines in the future evaluation of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>CoLesIR group is an interuniversity research group created for joint participation in the CLEF competition. It is composed of members of the Compilers and Languages Research Group (CoLe)<ref type="foot" coords="2,508.52,143.86,3.97,6.65" target="#foot_0">1</ref> of the Universities of A Coruña and Vigo (Spain), and members of the Information Retrieval Group<ref type="foot" coords="2,117.77,167.77,3.97,6.65" target="#foot_1">2</ref> of the University of Sunderland (United Kingdom). Although we have participated separately in CLEF <ref type="bibr" coords="2,160.14,181.10,15.47,9.96" target="#b16">[17,</ref><ref type="bibr" coords="2,178.94,181.10,12.71,9.96" target="#b15">16,</ref><ref type="bibr" coords="2,194.97,181.10,12.71,9.96" target="#b12">13,</ref><ref type="bibr" coords="2,211.01,181.10,11.60,9.96" target="#b11">12]</ref>, this is our first joint participation.</p><p>The Spanish CoLe group has been working for several years on the application of Natural Language Processing (NLP) techniques to Information Retrieval (IR) <ref type="bibr" coords="2,390.64,205.00,15.47,9.96" target="#b17">[18,</ref><ref type="bibr" coords="2,408.79,205.00,12.71,9.96" target="#b16">17,</ref><ref type="bibr" coords="2,424.19,205.00,11.60,9.96" target="#b15">16]</ref>, and recently has entered into the field of Machine Translation (MT) <ref type="bibr" coords="2,315.63,216.96,9.94,9.96" target="#b2">[3]</ref>. The possibility of applying its experience in these fields to the field of Cross-Language Information Retrieval (CLIR), and the support given for this purpose by the Sunderland University IR Group, led to the birth of this joint group So, this paper describes our first research experiences in the field of Cross-Language Information Retrieval. A CLIR system based in the employment of n-grams not only as indexing units, but also as translating units, is presented.</p><p>The article is outlined as follows. Section 2 presents previous work on the application of ngrams to CLIR systems. Next, section 3 describes our n-gram-based CLIR system. Section 4 shows the results obtained in our participation in both the Portuguese monolingual and robust tasks of the CLEF 2006 ad-hoc track. Unfortunately, lack of time did not allow us to get our ngram direct translation system ready on time. This way, we could only submit those initial results to be used as baselines for the future evaluation of our approach. Finally, Section 5 presents our conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Approaches on N -gram-Based Translation</head><p>Our proposal has been inspired by the previous work of the Johns Hopkins University Applied Physics Lab (JHU/APL) about the employment of overlapping character n-grams for indexing documents <ref type="bibr" coords="2,140.77,439.10,10.50,9.96" target="#b8">[9,</ref><ref type="bibr" coords="2,155.55,439.10,7.74,9.96" target="#b7">8,</ref><ref type="bibr" coords="2,167.58,439.10,12.71,9.96" target="#b9">10,</ref><ref type="bibr" coords="2,184.57,439.10,11.60,9.96" target="#b10">11]</ref>. Their interest came from the possibilities that overlapping character n-grams may offer particularly in the case of non-English languages <ref type="bibr" coords="2,395.09,451.05,9.94,9.96" target="#b7">[8]</ref>: to provide a surrogate means to normalize word forms and to allow one to manage languages of very different natures without further processing, such as agglutinative languages as in the case of Turkish, or languages lacking word separator characters such as Japanese. Moreover, this knowledge-light approach does not rely on language-specific processing, and it can be used even when linguistic information and resources are scarce or unavailable.</p><p>In the case of monolingual retrieval, the employment of n-grams is quite simple, since the documents to be indexed are just tokenized into overlapping n-grams instead of the usual words. This way, the word potato, for example, is split into its different overlapping compounding n-grams: -pot-, -ota-, -tat-and -ato-. These resulting n-grams are then indexed by the retrieval engine. The same tokenizing process will be made with queries, allowing matching between documents and queries.</p><p>In the case of translingual retrieval, the document indexing process remains the same, but two phases are now required during query processing: one for translation and another one for ngram splitting. In their initial cross-language experiments, JHU/APL firstly translated the source language query into the target language using Machine Translation (MT) techniques, parallel collections or bilingual dictionaries <ref type="bibr" coords="2,241.82,642.34,9.94,9.96" target="#b8">[9]</ref>. The resulting translated query was then split into n-grams, which were submitted to the retrieval engine.</p><p>Further experiments were made using a new n-gram-based translation approach. This so-called direct n-gram translation technique used n-grams instead of words as translation units. The objective pursued was to avoid some of the limitations of classical dictionary-based translation, such as the need for word normalization, the problems of translating multiple word expressions and the inability to handle out-of-vocabulary words <ref type="bibr" coords="2,279.22,714.07,14.59,9.96" target="#b10">[11]</ref>. This n-gram translation algorithm takes as input a parallel corpus, aligned at the paragraph (or document) level and extracts candidate translations as follows <ref type="bibr" coords="3,135.81,123.41,14.58,9.96" target="#b9">[10]</ref>. Firstly, for each candidate n-gram term to be translated, paragraphs containing this term in the source language are identified. Next, their corresponding paragraphs in the target language are also identified and, using a statistical measure similar to mutual information, a translation score is calculated for each of the terms occurring in one of such target language texts. Finally, the target n-gram with the higher translation score is selected as the potential translation of the source n-gram. The whole process is quite slow: it is said that the process takes several days in the case of working with 5-grams, for example <ref type="bibr" coords="3,328.85,195.14,14.58,9.96" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our approach</head><p>Taking as our model the system developed by JHU/APL, we have developed our own n-gram based retrieval system for testing our ideas. This system has been built using freely available resources when possible in order to make it more transparent and to minimize effort.</p><p>This way, instead of the ad-hoc retrieval system employed by the original design <ref type="bibr" coords="3,461.24,285.77,9.94,9.96" target="#b8">[9]</ref>, we have opted for using the open-source Terrier platform [1]. This decision was supported by the satisfactory results obtained with n-grams using other indexing engines <ref type="bibr" coords="3,384.72,309.68,14.58,9.96" target="#b14">[15]</ref>.</p><p>The second point of difference with respect to the original approach comes from the translation resources to be used. JHU/APL employed bilingual word-lists extracted from a huge parallel corpus of their own <ref type="bibr" coords="3,175.38,345.55,15.47,9.96" target="#b9">[10]</ref> created by mining the web of the Official Journal of the European Union 3 . However, since our group has no access to such a large parallel corpus, we had to employ a smaller one, the well-known Europarl corpus <ref type="bibr" coords="3,254.59,369.46,9.94,9.96" target="#b3">[4]</ref>. This corpus was extracted from the proceedings of the European Parliament covering April 1996 to September 2003, containing up to 28 million words per language. It includes versions in 11 European languages: Romanic (French, Italian, Spanish, Portuguese), Germanic (English, Dutch, German, Danish, Swedish), Greek and Finnish.</p><p>Finally, with respect to the n-gram translation algorithm itself, since the alignment algorithm of the original approach was too slow for our purposes, we opted for a slightly different approach consisting of two phases. In the first phase, the slowest one, word-level alignment of the text was made employing a statistical alignment model. For this purpose, the parallel corpus was processed through the well-known GIZA++ toolkit <ref type="bibr" coords="3,321.98,465.10,14.59,9.96" target="#b13">[14]</ref>, obtaining the translation probabilities between the different source and target language words which have been aligned by the software tool. Next, prior to the second phase, several heuristics can be applied -if desired-for refining or modifying such word-to-word translation scores. We can remove, for example, those candidate translations with a translation probability less than a previously established threshold, or we can combine the scores of bidirectional alignments <ref type="bibr" coords="3,311.85,524.87,10.50,9.96" target="#b4">[5]</ref> -source-target language and target-source language-instead of just the direct one -source-target language. Finally, in the second phase, n-gram translation scores are computed employing associative measures <ref type="bibr" coords="3,410.53,548.78,9.94,9.96" target="#b6">[7]</ref>, taking as input the translation probabilities calculated by GIZA++.</p><p>At this point, and in order to illustrate accurately the process involved during this second phase, we will take as basis how associative measures are calculated and how they could be used for generating bilingual dictionaries automatically taking as input parallel collections aligned at paragraph level. In this illustrating context, given a word pair (word u , word v ) -word u standing for the source language word, and word v for its candidate target language translation-, their cooccurrence frequency can be organized in a contingency table resulting from a cross-classification of their cooccurrences in the aligned corpus:</p><formula xml:id="formula_0" coords="3,101.09,665.44,289.72,76.78">V = wordv V = wordv U = wordu O 11 O 12 = R 1 U = wordu O 21 O 22 = R 2 = C 1 = C 2 = N 3 http://europa.eu</formula><p>In this table, instances whose first component belongs to type word u -i.e., the number of aligned paragraphs where the source language paragraph contains word u -are assigned to the first row of the table, and tokens whose second component belongs to type word v -i.e., the number of aligned paragraphs where the target language paragraph contains word v -are assigned to the first column. The cell counts of this contingency table are called the observed frequencies: O 11 : Number of aligned paragraphs where the source language paragraph contains word u and the target language paragraph contains word v .</p><p>O 12 : Number of aligned paragraphs where the source language paragraph contains word u but the target language paragraph does not contain word v .</p><p>O 21 : Number of aligned paragraphs where the source language paragraph does not contain word u but the target language paragraph contains word v .</p><p>O 22 : Number of aligned paragraphs where the source language paragraph does not contain word u and the target language paragraph does not contain word v either.</p><p>The sum of all these four observed frequencies -or sample size N -is equal to the total number of pairs of words considered. R 1 and R 2 are the row totals of the observed contingency table, while C 1 and C 2 are the corresponding column totals. Such row and column totals are also called marginal frequencies, and O 11 is called the joint frequency. Equations for all association measures are given in terms of the observed frequencies, marginal frequencies, and the expected frequencies E 11 , ..., E 22 (under the null hypothesis that word u and word v are statistically independent). The expected frequencies can easily be computed from the row and column totals:</p><formula xml:id="formula_1" coords="4,222.50,399.46,156.31,43.60">V = wordv V = wordv U = wordu E 11 = R 1 C 1 N E 12 = R 1 C 2 N U = wordu E 21 = R 2 C 1 N E 22 = R 2 C 2 N</formula><p>Once the contingency table has been built, different association measures can be easily calculated for each pair of words. After this, the most promising pairs can be inserted into the automatically generated bilingual dictionary by selecting them from those with the highest association measures. In our case, two classical measures will be applied for this purpose: mutual information and Dice coefficient, defined by equations 1 and 2, respectively:</p><formula xml:id="formula_2" coords="4,132.14,528.25,380.84,23.96">M I(word u , word v ) = log O 11 E 11 (1) Dice(word u , word v ) = 2O 11 R 1 + C 1<label>(2)</label></formula><p>At this point, we have described how to compute and employ association measures for the automatic generation of bilingual dictionaries from parallel corpora aligned at paragraph level. However, in our proposal, we do not have aligned paragraphs but aligned words -a source word and its candidate translation-, both composed by n-grams. Our first idea could be just to adapt the contingency table to that context. Consequently, we can consider that we are now dealing with n-gram pairs (n-gram u , n-gram v ) cooccurring at aligned words instead of word pairs (word u , word v ) cooccurring at aligned paragraphs. So, contingency tables should be redefined according to this new situation: O 11 , for example, should be re-formulated as the number of aligned words where the source language word contains n-gram u and the target language word contains n-gram v .</p><p>This first solution seems logical, and it is intuitive and easy to understand. Nevertheless, we find a problem. In the case of aligned paragraphs formed of words, we had real instances of word cooccurrences at the paragraphs aligned. However, in our proposal we do not have real instances of n-gram cooccurrences at aligned words -as it may be expected-, but just probable ones, since GIZA++ -the tool employed for the initial word-level alignment-is based on a statiscal alignment model which computes a translation probability for each cooccurring pair of words. So, the same word may appear as being aligned with several translation candidates, each one with its corresponding probability. For example, taking the English words milk and milky, and the Spanish words leche (milk), lechoso (milky) and tomate (tomato), a possible output alignment would be: This way, it may be considered that the source 4-gram -milk-does not really cooccur with the target 4-gram -lech-, since the alignment between its containing words milk and leche, and milky and lechoso is not certain. Nevertheless, it seems much more probable that the translation of the 4-gram -milk-was -lech-rather than -toma-, for example, since the probability of the alignment of their containing words -milk and tomato-is much smaller than that of the words containing -milk-and -lech--the pairs milk and leche and milky and lechoso. Taking this idea as basis, our proposal consists of weighting the likelihood of a cooccurrence according to the probability of its corresponding alignment.</p><p>Taking again the previous milk-milky example, we can consider the overlapping 4-grams that compose each word. Thus, we would obtain an alignment like this: source word candidate translation probability</p><formula xml:id="formula_3" coords="5,183.54,376.78,220.16,26.90">-milk- -lech--eche- 0.98 -milk--ilky -lech--echo--chos--hoso- 0.92 -milk- -toma--omat--mate- 0.15</formula><p>So, the contingency tables corresponding to the n-gram pairs (-milk-, -lech-) and (-milk-, -toma-) are as follows: It can be seen in the example that the O 11 observed frequency corresponding to the n-gram pair (-milk-, -lech-) is not 2 as it could be expected, but 1.90. This is because it appears in 2 alignments, milk with leche and milky with lechoso, but each cooccurrence in a alignment must also be weighted according to its translation probability like this: 0.98 (probability of the alignment of milk with leche) + 0.92 (probability of the alignment of milky with lechoso) = 1.90.</p><formula xml:id="formula_4" coords="5,124.44,454.59,256.13,26.80">V = -lech- V = -lech- U = -</formula><p>Once the contingency tables have been obtained, the Dice coefficients corresponding to each n-gram pair can be computed. As expected, the association measure of the pair (-milk-, -lech-) -the correct one-is much higher than that of the pair (-milk-, -toma-) -the wrong one:</p><p>Dice(-milk-, -lech-)= 2 * 1.90 6.09+2.82 = 0.43 Dice(-milk-, -toma-)= 2 * 0.15 6.09+0.15 = 0.05</p><p>If we consider that a real existing cooccurrence instance -such as those of the word-based algorithm used for illustrating-corresponds to a 100% probability, we can think about the original word-based algorithm for building the contingency table and calculating word-level associative measures as a particular case of the generalized algorithm we have proposed.</p><p>This new approach we have proposed for n-gram direct translation increases the speed of the process, concentrating most of the complexity in the word-level alignment phase. This first step acts as a initial filter, since only those n-gram pairs corresponding to aligned words will be considered, whereas in the original JHU/APL approach all n-gram pairs corresponding to aligned paragraphs were considered. On the other hand, since the n-gram alignment phase is much faster, different n-gram alignment techniques can be easily tested. Another advantage of this approach is that the n-gram alignment process can take as input previously existing lists of aligned words or even bilingual dictionaries, theoretically improving the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this our first joint participation as CoLesIR group, we have taken part in two tasks of the ad-hoc track: the Portuguese monolingual task, and the robust task. Unfortunately, the lack of time did not allow us to tune accurately our retrieval system, either to complete our n-gram direct translation tool. So, we can show here only the results intended to be used as baselines for future tests. This way, no tuning has been made with respect to the possibility of removing high or lowfrequency n-grams, the employment of relevance feedback, or the use of pre or post-translation expansion techniques in the case of translingual runs <ref type="bibr" coords="6,323.12,447.77,14.58,9.96" target="#b9">[10]</ref>.</p><p>So, documents were just split into n-grams and indexed, as were the queries. Before that, the text had been converted into lowercase and punctuation marks were removed <ref type="bibr" coords="6,445.79,471.67,14.59,9.96" target="#b9">[10]</ref>. Diacritics, however, have been kept in this first first set of experiments.</p><p>The open-source Terrier platform [1] has been employed as retrieval engine using a InL2<ref type="foot" coords="6,508.53,494.21,3.97,6.65" target="#foot_2">4</ref> ranking model <ref type="bibr" coords="6,158.23,507.54,9.94,9.96" target="#b1">[2]</ref>. No stopword removal or query expansion have been applied at this point. The same running parameters have been used for all the experiments performed. With respect to the n-gram length, we decided to use 4-grams as a compromise size after studying the results previously obtained by the JHU/APL group <ref type="bibr" coords="6,286.56,543.40,10.50,9.96" target="#b8">[9,</ref><ref type="bibr" coords="6,300.39,543.40,7.73,9.96" target="#b7">8,</ref><ref type="bibr" coords="6,311.45,543.40,12.71,9.96" target="#b9">10,</ref><ref type="bibr" coords="6,327.48,543.40,12.71,9.96" target="#b10">11]</ref> using different n-gram lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Portuguese Monolingual Task</head><p>The possibility of working with Portuguese caught our attention because of its proximity to Galician language. Our Spanish part, the CoLe group, has been working for many years on NLP and IR in Galician, a Romance language spoken in Galicia, in the North-West of Spain, where it is co-oficial language. Nevertheless, the lack of freely available resources for this language has limited such work, particularly in the case of IR. This way, the existence of a Portuguese corpus for IR evaluation is very interesting because of the proximity of both languages, Galician and Portuguese, since they were a single language in their origin, and their linguistic phenomena are still very similar today.</p><p>The document collection used for this task comprises news published during 1994 and 1995 by the newspapers Público -Portuguese-and Folha de São Paulo -Brazilian. See column PT of Table <ref type="table" coords="6,117.30,709.24,4.97,9.96" target="#tab_2">1</ref> for more details. The test set includes 50 topics (C301-C350). Only title and description fields were used in the submitted queries. Unlike the rest of our experiments, two ranking models were used this time: the previously referred to InL2 model, and the hypergeometric model named DLH <ref type="foot" coords="7,369.64,443.52,3.97,6.65" target="#foot_3">5</ref> . The results obtained are shown in Table <ref type="table" coords="7,127.86,456.85,3.87,9.96" target="#tab_3">2</ref>, columns PT I and PT D , respectively. The performance of the system is measured using the parameters contained in each row: number of documents retrieved, number of relevant documents expected, number of relevant documents retrieved, average precision (non-interpolated) for all relevant documents (averaged over queries), R-precision, binary preference, geometric average precision, precision at 11 standard levels of recall, and precision at N documents retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Robust Task</head><p>Since our CLIR system is still in its first stages, we preferred to test it with the most commonly used languages in CLIR before trying more exotic or less-known languages. This is the main reason for participating in the robust task. The robust task is essentially an ad-hoc task which makes use of the topics and collections used from CLEF 2001 to CLEF 2003. The data collections, whose content is described in Table <ref type="table" coords="7,216.30,598.77,3.87,9.96" target="#tab_2">1</ref>, are formed by newspapers and newswires written in six languages: German (DE ), English (EN ), Spanish (ES ), French (FR), Italian (IT ) and Dutch (NL). The test set is formed by 160 topics (C041-C200). This initial set has been divided into two subsets: a so-called training topics subset -formed by topics C050-C059, C070-C079, C100-C109, C120-C129, C150-159, C180-189-, to be used for tuning purposes, and a so-called test topics subset -formed by the rest of the topics-, for testing purposes. Again, only title and description fields were used in the submitted queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Monolingual experiments</head><p>We have participated in all the monolingual subtasks of the robust task: German (DE ), English (EN ), Spanish (ES ), French (FR), Italian (IT ) and Dutch (NL). Results are shown in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Bilingual experiments</head><p>In this case, we have just participated in the English-to-German bilingual subtask. Since our direct n-gram translation tool was not ready on time, we opted for a similar approach to that used by JHU/APL group in their first translingual retrieval experiments <ref type="bibr" coords="8,406.55,473.95,9.94,9.96" target="#b8">[9]</ref>. This way, the source language query is first translated into the target language before splitting it into n-grams to be submitted to the retrieval engine. In our case we have used Altavista's Babel Fish<ref type="foot" coords="8,443.66,496.48,3.97,6.65" target="#foot_4">6</ref> for translating the queries. Columns ENDE of Table <ref type="table" coords="8,257.73,509.81,4.97,9.96" target="#tab_5">3</ref> show the results obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Multilingual experiments</head><p>In this final multilingual task, English has been used as the source language, whereas all six available collections are used for retrieving. As we explained, our direct n-gram translation tool could not be used because it was not ready on time. Our initial baseline runs were submitted instead.</p><p>As before, source language -English-queries were translated into each of the target languages using Altavista's Babel Fish. Once translated, they were split into n-grams for querying their corresponding target language collection. Next, the different rankings retrieved for each target language collection are normalized. The similarity value or retrieval status value (RSV) of the i th document retrieved is normalized by the maximum and minimum of the ranking <ref type="bibr" coords="8,444.34,649.75,10.50,9.96" target="#b5">[6]</ref> as follows:</p><formula xml:id="formula_5" coords="8,239.01,669.50,273.97,23.53">RSV i = RSV i -RSV min RSV max -RSV min<label>(3)</label></formula><p>where RSV i is the original similarity value, RSV i is the normalized one, and RSV min and RSV max are the minimal and maximal similarity values of that ranking, respectively. Once normalized, all individual rankings are merged into the final output ranking to be retrieved.</p><p>Columns ENxx of Table <ref type="table" coords="9,213.09,111.46,4.97,9.96" target="#tab_5">3</ref> show the results obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and future work</head><p>This paper describes our initial work in the field of Cross-Language Information Retrieval. Using our past experience in the application of Natural Language Processing techniques to Information Retrieval, and our recent work in Machine Translation (MT), we have developed an n-gram-based system which uses such subwords not only as indexing units, but also as translating units. This work has been inspired in the previous work of the Johns Hopkins University Applied Physics Lab <ref type="bibr" coords="9,147.55,226.00,10.50,9.96" target="#b8">[9,</ref><ref type="bibr" coords="9,162.31,226.00,7.74,9.96" target="#b7">8,</ref><ref type="bibr" coords="9,174.30,226.00,12.71,9.96" target="#b9">10,</ref><ref type="bibr" coords="9,191.27,226.00,11.60,9.96" target="#b10">11]</ref>. However, its the training algorithm was too slow for our purposes. Thus we decided to develop our own n-gram based retrieval system for testing our ideas. Freely available resources have been used when possible in its design in order to make it more transparent and to minimize effort. For speeding up the training process, we have opted for a slightly different algorithm to the original one, now consisting of two phases. In the first phase, the slowest one, word-level alignment of the text is made through a statistical alignment tool. In the second phase, n-gram translation scores are computed employing association measures taking as input the translation probabilities calculated in the previous phase. This new approach increases the speed of the training of the process, concentrating most of the complexity in the word-level alignment phase. Another advantage is that the n-gram alignment process can take as input previously existing aligned word lists or even bilingual dictionaries, which should improve the results.</p><p>Unfortunately lack of time did not allow us to get our n-gram direct translation system ready on time. Thus we have only included those baseline results to be used in the future evaluation of our approach.</p><p>With respect to future work, we intend to complete and test both our n-gram direct translation system and our retrieval module as soon as possible. Once the base system is working, we intend to test the behavior of new association measures <ref type="bibr" coords="9,304.58,417.28,14.59,9.96" target="#b18">[19]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,120.78,114.99,358.27,76.26"><head>Table 1 :</head><label>1</label><figDesc>Statistics of test collections (by task and language)</figDesc><table coords="6,120.78,114.99,358.27,49.11"><row><cell>Task</cell><cell>Monolingual</cell><cell></cell><cell></cell><cell cols="2">Robust</cell><cell></cell><cell></cell></row><row><cell>Language</cell><cell>PT</cell><cell>DE</cell><cell>EN</cell><cell>ES</cell><cell>FR</cell><cell>IT</cell><cell>NL</cell></row><row><cell>Size (in MB)</cell><cell>564</cell><cell>668</cell><cell>579</cell><cell>1,086</cell><cell>331</cell><cell>363</cell><cell>540</cell></row><row><cell># of docs.</cell><cell>210,734</cell><cell>294,809</cell><cell>169,477</cell><cell>454,045</cell><cell>129,806</cell><cell>157,558</cell><cell>190,604</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,98.08,115.07,403.99,296.00"><head>Table 2 :</head><label>2</label><figDesc>Baseline results for monolingual runs: Portuguese and robust monolingual tasks</figDesc><table coords="7,98.08,115.07,403.99,269.29"><row><cell></cell><cell cols="2">Portuguese</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Robust monolingual</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Training topics</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Test topics</cell></row><row><cell></cell><cell cols="2">PTI PTD</cell><cell>DE</cell><cell>EN</cell><cell>ES</cell><cell>FR</cell><cell>IT</cell><cell>NL</cell><cell>DE</cell><cell>EN</cell><cell>ES</cell><cell>FR</cell><cell>IT</cell><cell>NL</cell></row><row><cell># Retr.</cell><cell>50k</cell><cell>50k</cell><cell>60k</cell><cell>60k</cell><cell>60k</cell><cell>60k</cell><cell>60k</cell><cell>60k</cell><cell cols="5">100k 100k 100k 100k 100k 100k</cell></row><row><cell># Rel. exp.</cell><cell cols="2">2,677 2,677</cell><cell cols="6">2,252 1,150 2,908 1,351 1,197 1,946</cell><cell cols="5">3,641 1,533 5,008 2,190 1,930 2,717</cell></row><row><cell># Rel. retr.</cell><cell cols="2">2,152 2,173</cell><cell cols="6">2,080 960 2,509 1,257 1,099 1,766</cell><cell cols="5">3,227 1,379 4,105 2,025 1,758 2,374</cell></row><row><cell>Non-int. Pr.</cell><cell cols="2">35.18 32.69</cell><cell cols="6">36.11 27.61 30.75 33.64 29.03 37.30</cell><cell cols="5">37.21 37.64 40.17 39.51 32.23 41.60</cell></row><row><cell>R-Pr.</cell><cell cols="2">35.73 32.23</cell><cell cols="6">35.99 27.11 30.74 31.62 27.63 37.84</cell><cell cols="5">36.49 36.21 40.03 37.56 32.06 39.85</cell></row><row><cell>Binary Pref.</cell><cell cols="2">35.26 33.22</cell><cell cols="6">38.32 32.23 39.44 34.39 29.33 36.24</cell><cell cols="5">40.78 39.58 50.27 42.19 36.38 40.17</cell></row><row><cell>Geo. Pr.</cell><cell cols="2">20.95 18.66</cell><cell cols="6">24.25 4.89 15.13 19.73 10.40 23.25</cell><cell cols="5">14.80 8.41 18.85 11.91 8.23 16.40</cell></row><row><cell>0% Re.</cell><cell cols="2">70.32 67.77</cell><cell cols="6">72,54 52,51 68,31 63,36 53,66 76,98</cell><cell cols="5">65,97 63,96 71,62 68,41 61,40 75,33</cell></row><row><cell>10% Re.</cell><cell cols="2">57.77 54.83</cell><cell cols="6">58,49 45,38 55,57 53,95 48,22 65,32</cell><cell cols="5">57,08 58,49 61,36 60,81 52,75 64,76</cell></row><row><cell>20% Re.</cell><cell cols="2">50.75 47.39</cell><cell cols="6">50,26 39,33 47,22 48,07 44,34 55,75</cell><cell cols="5">51,59 52,10 55,85 53,03 45,71 58,71</cell></row><row><cell>30% Re.</cell><cell cols="2">45.81 41.92</cell><cell cols="6">43,36 36,30 40,87 41,76 38,07 49,08</cell><cell cols="5">45,07 47,75 51,15 47,19 40,23 51,64</cell></row><row><cell>40% Re.</cell><cell cols="2">40.39 36.97</cell><cell cols="6">39,17 31,01 33,65 37,58 32,20 43,41</cell><cell cols="5">41,80 44,23 46,85 43,86 35,97 46,38</cell></row><row><cell>50% Re.</cell><cell cols="2">35.95 34.03</cell><cell cols="6">36,62 28,21 28,00 35,37 30,24 39,25</cell><cell cols="5">38,62 39,58 43,08 40,99 33,01 42,53</cell></row><row><cell>60% Re.</cell><cell cols="2">31.86 29.59</cell><cell cols="6">33,31 22,18 24,66 30,61 26,55 30,43</cell><cell cols="5">34,91 32,79 38,32 35,97 28,36 35,79</cell></row><row><cell>70% Re.</cell><cell cols="2">27.81 25.73</cell><cell cols="6">29,50 19,66 20,43 24,10 22,17 25,21</cell><cell cols="5">31,28 29,44 33,88 32,68 24,94 32,01</cell></row><row><cell>80% Re.</cell><cell cols="2">21.54 20.35</cell><cell cols="6">23,25 16,32 17,22 21,25 18,72 21,36</cell><cell cols="5">26,85 25,30 28,16 28,77 21,38 28,64</cell></row><row><cell>90% Re.</cell><cell cols="2">15.20 13.50</cell><cell cols="6">18,40 14,36 13,14 17,62 13,82 16,47</cell><cell cols="5">19,40 20,28 18,03 23,71 17,71 22,59</cell></row><row><cell>100% Re.</cell><cell>6.53</cell><cell>6.53</cell><cell cols="6">10,01 9,40 6,95 13,86 10,23 8,99</cell><cell cols="5">13,14 17,30 10,51 18,86 13,03 16,29</cell></row><row><cell>5 docs.</cell><cell cols="2">51.20 45.20</cell><cell cols="6">49.67 32.67 44.00 34.00 32.00 50.67</cell><cell cols="5">44.20 37.00 48.00 40.80 36.40 53.60</cell></row><row><cell>10 docs.</cell><cell cols="2">47.20 44.40</cell><cell cols="6">43.17 27.33 38.33 28.67 28.17 42.67</cell><cell cols="5">41.20 28.60 43.10 35.20 31.60 43.50</cell></row><row><cell>15 docs.</cell><cell cols="2">44.40 44.00</cell><cell cols="6">40.11 23.22 36.67 25.67 26.22 37.56</cell><cell cols="5">38.53 24.93 39.40 30.47 27.93 38.80</cell></row><row><cell>20 docs.</cell><cell cols="2">42.50 41.70</cell><cell cols="6">36.83 21.42 34.67 24.50 23.75 34.00</cell><cell cols="5">36.30 21.85 35.95 27.80 25.50 34.90</cell></row><row><cell>30 docs.</cell><cell cols="2">39.60 37.87</cell><cell cols="6">32.72 18.28 30.22 22.17 21.61 29.00</cell><cell cols="5">31.87 18.20 32.33 23.87 21.83 30.13</cell></row><row><cell>100 docs.</cell><cell cols="2">24.32 23.00</cell><cell cols="6">19.40 10.58 19.90 12.77 12.07 16.83</cell><cell cols="5">19.22 9.26 20.69 12.95 11.14 15.41</cell></row><row><cell>200 docs.</cell><cell cols="2">15.54 14.92</cell><cell cols="6">13.30 6.58 13.53 8.43 7.40 11.05</cell><cell cols="5">12.27 5.61 13.82 8.00 6.91 9.39</cell></row><row><cell>500 docs.</cell><cell>7.61</cell><cell>7.59</cell><cell cols="6">6.60 3.03 7.33 4.00 3.46 5.46</cell><cell cols="5">5.92 2.61 7.32 3.81 3.25 4.42</cell></row><row><cell>1,000 docs.</cell><cell>4.30</cell><cell>4.35</cell><cell cols="6">3.47 1.60 4.18 2.09 1.83 2.94</cell><cell cols="5">3.23 1.38 4.11 2.03 1.76 2.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,470.04,726.74,35.10,9.96"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table coords="8,211.70,115.01,176.84,44.58"><row><cell></cell><cell cols="2">ENDE</cell><cell cols="2">ENxx</cell></row><row><cell></cell><cell>train</cell><cell>test</cell><cell>train</cell><cell>test</cell></row><row><cell># Retr.</cell><cell>60k</cell><cell>100k</cell><cell>60k</cell><cell>100k</cell></row><row><cell># Rel. exp.</cell><cell cols="2">2,252 3,641</cell><cell cols="2">10,804 17,019</cell></row><row><cell># Rel. retr.</cell><cell cols="2">1,710 2,599</cell><cell>5,968</cell><cell>8,877</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,90.00,387.31,422.61,21.92"><head>Table 3 :</head><label>3</label><figDesc>Baseline results for translingual runs: English to German robust bilingual task (ENDE ) and robust multilingual task with English as source language (ENxx )</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.25,734.13,101.38,7.35"><p>http://www.grupocole.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.25,743.64,177.41,7.35"><p>http://www.cet.sunderland.ac.uk/IR/ir.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="6,105.25,740.25,304.53,7.97"><p>Inverse Document Frequency model with Laplace after-effect and normalization 2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="7,105.25,746.35,186.58,7.97"><p>http://ir.dcs.gla.ac.uk/wiki/HypergeometricModel</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="8,105.25,742.45,126.72,7.35"><p>http://babelfish.altavista.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research has been partially supported by <rs type="funder">Ministerio de Educación y Ciencia and FEDER</rs> (<rs type="grantNumber">TIN2004-07246-C03-02</rs>), <rs type="funder">Xunta de Galicia</rs> (<rs type="grantNumber">PGIDIT05PXIC30501PN</rs>, <rs type="grantNumber">PGIDIT05SIN044E</rs>), and <rs type="funder">Dirección Xeral de Investigación, Desenvolvemento e Innovación (Programa de Recursos Humanos grants)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_U8SKTkm">
					<idno type="grant-number">TIN2004-07246-C03-02</idno>
				</org>
				<org type="funding" xml:id="_nwDD9F3">
					<idno type="grant-number">PGIDIT05PXIC30501PN</idno>
				</org>
				<org type="funding" xml:id="_5QMTaNX">
					<idno type="grant-number">PGIDIT05SIN044E</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,211.70,167.29,42.97,6.65;8,271.14,167.29,46.49,6.65;8,336.09,167.29,50.46,6.65;8,211.70,175.27,19.17,6.65;8,271.15,175.27,46.49,6.65;8,336.10,175.27,50.46,6.65;8,211.70,183.23,42.88,6.65;8,271.14,183.23,46.49,6.65;8,336.09,183.23,50.46,6.65;8,211.70,191.20,30.18,6.65;8,271.15,191.20,44.50,6.65;8,336.10,191.20,50.46,6.65;8,211.70,205.55,24.78,6.65;8,271.16,205.55,46.49,6.65;8,336.11,205.55,50.46,6.65;8,211.70,213.52,28.74,6.65;8,271.16,213.52,46.49,6.65;8,336.11,213.52,50.46,6.65;8,211.70,221.49,28.74,6.65;8,271.16,221.49,46.49,6.65;8,336.11,221.49,50.46,6.65;8,211.70,229.46,28.74,6.65;8,271.16,229.46,46.49,6.65;8,336.11,229.46,50.46,6.65;8,211.70,237.43,28.74,6.65;8,271.16,237.43,46.49,6.65;8,336.11,237.43,50.46,6.65;8,211.70,245.40,28.74,6.65;8,271.16,245.40,46.49,6.65;8,336.11,245.40,50.46,6.65;8,211.70,253.37,28.74,6.65;8,271.16,253.37,46.49,6.65;8,336.11,253.37,50.46,6.65;8,211.70,261.34,28.74,6.65;8,271.16,261.34,46.49,6.65;8,339.44,261.34,47.13,6.65;8,211.70,269.31,28.74,6.65;8,271.16,269.31,46.49,6.65;8,339.44,269.31,14.16,6.65;8,371.77,269.31,14.16,6.65;8,211.70,277.28,28.74,6.65;8,274.49,277.28,43.16,6.65;8,339.44,277.28,14.16,6.65;8,371.77,277.28,14.16,6.65;8,211.70,285.25,32.71,6.65;8,274.49,285.25,42.52,6.65;8,339.44,285.25,14.16,6.65;8,371.77,285.25,14.16,6.65;8,211.70,299.60,24.18,6.65;8,271.16,299.60,46.49,6.65;8,336.11,299.60,50.46,6.65;8,211.70,307.57,28.16,6.65;8,271.16,307.57,46.49,6.65;8,336.11,307.57,50.46,6.65;8,211.70,315.54,28.16,6.65;8,271.16,315.54,46.49,6.65;8,336.11,315.54,50.46,6.65;8,211.70,323.50,28.16,6.65;8,271.16,323.50,46.49,6.65;8,336.11,323.50,50.46,6.65;8,211.70,331.48,28.16,6.65;8,271.16,331.48,46.49,6.65;8,336.11,331.48,50.46,6.65;8,211.70,339.44,32.13,6.65;8,271.16,339.44,46.49,6.65;8,336.11,339.44,50.46,6.65;8,211.70,347.42,32.13,6.65;8,273.15,347.42,42.52,6.65;8,336.11,347.42,50.46,6.65;8,211.70,355.39,32.13,6.65;8,273.15,355.39,42.52,6.65;8,336.11,355.39,50.46,6.65;8,211.70,363.36,38.35,6.65;8,273.14,363.36,42.52,6.65;8,338.09,363.36,14.16,6.65;8,370.42,363.36,14.16,6.65;9,90.00,538.28,75.45,12.93" xml:id="b0">
	<analytic>
		<title/>
		<idno>54.38 51.63 71.28 66.50 10% Re. 44.14 40.98 39.63 44.44 20% Re. 36.21 36.31 32.20 37.27 30% Re. 31.39 32.49 27.27 30.78 40% Re. 27.83 29.44 23.33 26.89 50% Re. 24.46 27.38 18.28 22.05 60% Re. 21.51 22.85 13.45 17.04 70% Re. 18.51 19.63 9.56 13.26 80% Re. 13.72 16.50 4.67 8.72 90% Re. 9.02 10.66 2.60 4.73 100% Re. 5.76 6.45 0.33 0.24 5 docs. 35.00 32.60 43.67 43.60 10 docs. 33.17 28.70 41.00 43.60 15 docs. 30.89 25.80 39.44 41.67 20 docs. 27.83 24.90 38.08 40.40 30 docs. 23.61 22.80 36.33 37.33 100 docs. 14.00 13.54 27.52 28.04 200 docs. 9.76 9.02 22.13 22.10 500 docs. 5.16 4.58 14.94 13.66 1,000 docs. 2.85 2.60 9.95 8.88</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,211.70,167.29,42.97,6.65;8,211.70,183.23,39.54,6.65;8,211.70,191.20,30.18,6.65">Non-int. Pr</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">24 31</biblScope>
			<biblScope unit="page" from="37" to="59" />
			<date>02</date>
		</imprint>
	</monogr>
	<note>Geo. Pr.</note>
</biblStruct>

<biblStruct coords="9,110.46,582.61,402.18,9.96;9,110.47,594.56,402.15,9.96;9,110.47,606.51,88.99,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,280.00,582.61,232.64,9.96;9,110.47,594.56,189.01,9.96">Probabilistic models of Information Retrieval based on measuring divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,313.60,594.56,194.36,9.96">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.46,626.44,402.13,9.96;9,110.47,638.40,402.07,9.96;9,110.47,650.35,357.67,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,366.36,626.44,146.24,9.96;9,110.47,638.40,109.51,9.96">Measuring the impact of cognates in parallel text alignment</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Víctor</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Darriba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tiago</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ildefonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,242.40,638.40,270.15,9.96;9,110.47,650.35,55.28,9.96">Proc. of 12th Portuguese Conference on Artificial Intelligence (EPIA 2005)</title>
		<meeting>of 12th Portuguese Conference on Artificial Intelligence (EPIA 2005)<address><addrLine>Covilha, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2005-08">December 5-8. 2005</date>
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.46,670.27,71.77,9.96;9,203.24,670.27,41.11,9.96;9,259.92,670.27,252.75,9.96;9,110.47,682.23,402.20,9.96;9,110.47,694.19,82.20,9.96;9,207.78,694.19,188.38,9.96;9,417.66,694.19,95.03,9.96;9,110.47,706.14,401.92,9.96;9,110.47,718.09,26.51,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,203.24,670.27,41.11,9.96;9,259.92,670.27,252.75,9.96;9,110.47,682.23,15.91,9.96">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="http://www.iccs.inf.ed.ac.uk/~pkoehn/publications/europarl/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,160.67,682.23,305.67,9.96">Proc. of the 10th Machine Translation Summit (MT Summit X)</title>
		<meeting>of the 10th Machine Translation Summit (MT Summit X)<address><addrLine>Phuket, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-08">September 12-16, 2005. 2005. August 2006</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,111.46,402.15,9.96;10,110.48,123.41,402.14,9.96;10,110.47,135.36,344.54,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,342.60,111.46,152.13,9.96">Statistical phrase-based translation</title>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,110.48,123.41,369.66,9.96">NAACL &apos;03: Proc. of the 2003 Conference of the North American Chapter of the ACL</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,155.29,402.16,9.96;10,110.47,167.25,252.71,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,171.92,155.29,182.56,9.96">Analyses of multiple evidence combination</title>
		<author>
			<persName coords=""><forename type="first">Joon</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,375.51,155.29,81.34,9.96">Proc. of SIGIR &apos;97</title>
		<meeting>of SIGIR &apos;97<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1997">July 27-31. 1997</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,187.17,402.13,9.96;10,110.47,199.12,376.45,9.96" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,319.93,187.17,192.66,9.96;10,110.47,199.12,43.42,9.96">Foundations of Statistical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge (Massachusetts) and London (England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,219.05,402.10,9.96;10,110.47,231.00,402.08,9.96;10,110.47,242.96,49.50,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,269.58,219.05,170.63,9.96">Scalable multilingual information access</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,120.71,231.00,147.84,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2003">2003</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,262.89,402.14,9.96;10,110.47,274.84,253.09,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,270.81,262.89,241.79,9.96;10,110.47,274.84,61.77,9.96">Character N-gram Tokenization for European Language Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,180.87,274.84,92.86,9.96">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,294.77,402.15,9.96;10,110.48,306.72,402.11,9.96;10,110.48,318.67,185.20,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,277.53,294.77,235.08,9.96;10,110.48,306.72,45.66,9.96">JHU/APL experiments in tokenization and non-word translation</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,250.54,306.72,154.27,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="85" to="97" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,338.60,402.17,9.96;10,110.47,350.56,402.10,9.96;10,110.48,362.51,151.44,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,277.71,338.60,234.92,9.96">Cross-Language Retrieval Using HAIRCUT at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,221.72,350.56,153.41,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="50" to="59" />
			<date type="published" when="2004">2004. 2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,382.44,402.15,9.96;10,110.48,394.39,402.10,9.96;10,110.47,406.35,265.99,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,340.67,382.44,171.93,9.96;10,110.48,394.39,116.35,9.96">COLE experiments at QA@CLEF 2004 Spanish monolingual track</title>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><surname>Méndez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jesús</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Cabrero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,324.01,394.39,155.75,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="544" to="551" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,426.28,402.16,9.96;10,110.48,438.23,402.08,9.96;10,110.48,450.18,225.07,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,293.32,426.28,219.30,9.96;10,110.48,438.23,72.62,9.96">Regular sound changes for Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Souvik</forename><surname>Oakes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,281.26,438.23,156.24,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="263" to="270" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,470.11,402.10,9.96;10,110.48,482.07,402.03,9.96;10,110.48,494.02,61.12,9.96" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,268.18,470.11,244.37,9.96;10,110.48,482.07,28.23,9.96">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName coords=""><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ney</surname></persName>
		</author>
		<ptr target="http://www.fjoch.com/GIZA++.html" />
		<imprint>
			<date type="published" when="2003-08">2003. August 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,513.94,402.14,9.96;10,110.47,525.90,296.51,9.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,183.36,513.94,329.24,9.96;10,110.47,525.90,31.25,9.96">Cross-Language Information Retrieval: experiments based on CLEF 2000 corpora</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,150.62,525.90,176.44,9.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="75" to="115" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,545.82,402.17,9.96;10,110.47,557.78,402.09,9.96;10,110.47,569.74,293.13,9.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,383.75,545.82,128.88,9.96;10,110.47,557.78,141.53,9.96">COLE experiments at CLEF 2003 Spanish monolingual track</title>
		<author>
			<persName coords=""><forename type="first">Jesús</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Ribadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,351.34,557.78,156.88,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="345" to="357" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,589.66,402.16,9.96;10,110.47,601.61,402.12,9.96;10,110.47,613.57,331.24,9.96" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,450.93,589.66,61.68,9.96;10,110.47,601.61,202.73,9.96">COLE experiments at CLEF 2002 Spanish monolingual track</title>
		<author>
			<persName coords=""><forename type="first">Jesús</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Ribadas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Vilares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,397.44,601.61,115.15,9.96;10,110.47,613.57,30.42,9.96">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="265" to="278" />
			<date type="published" when="2003">2003</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin-Heidelberg-New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,633.49,402.18,9.96;10,110.47,645.45,402.13,9.96;10,110.47,657.40,402.12,9.96;10,110.47,669.36,49.50,9.96" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,375.80,633.49,136.84,9.96;10,110.47,645.45,27.98,9.96">On pattern-matching as query facility</title>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Ribadas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Graña</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,284.90,645.45,227.70,9.96;10,110.47,657.40,65.36,9.96">Topics in Computational Linguistics and Intelligent Text Processing</title>
		<title level="s" coord="10,183.10,657.40,150.60,9.96">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin-Heidelberg-New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.46,689.28,402.18,9.96;10,110.47,701.24,296.02,9.96" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,240.36,689.28,272.27,9.96;10,110.47,701.24,78.26,9.96">Co-occurrence retrieval: A flexible framework for lexical distributional similarity</title>
		<author>
			<persName coords=""><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,197.08,701.24,112.94,9.96">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="475" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
