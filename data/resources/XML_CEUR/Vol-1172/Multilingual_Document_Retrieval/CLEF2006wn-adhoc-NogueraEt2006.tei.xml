<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.68,146.21,413.61,18.08;1,132.34,168.13,338.32,18.08">Passage Retrieval vs. Document Retrieval in the Monolingual Task with the IR-n system</title>
				<funder ref="#_qHXmeA5">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_yCSZHuf">
					<orgName type="full">Valencia Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,224.69,203.19,60.83,10.46"><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,308.21,203.19,70.10,10.46"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Información Departamento de Lenguajes y Sistemas</orgName>
								<orgName type="laboratory">Grupo de investigación en Procesamiento del Lenguaje Natural y Sistemas de</orgName>
								<orgName type="institution">Informáticos</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.68,146.21,413.61,18.08;1,132.34,168.13,338.32,18.08">Passage Retrieval vs. Document Retrieval in the Monolingual Task with the IR-n system</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7D10129F4F0F15BA3AF0C30906FC382E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Experimentation</term>
					<term>Measurement</term>
					<term>Performance Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper describes our participation in monolingual tasks at CLEF 2006. We have submitted results for the following languages: English, French, Portuguese and Hungarian. We focused on studying different weighting schemes (okapi and dfr) and retrieval strategies (passage retrieval and document retrieval) to improve retrieval performance. After an analysis of our experiments and of the official results at CLEF, we find that our different configurations (French, Portuguese and Hungarian) achieve considerably improved scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In our sixth participation at CLEF, we focused on evaluating: a new weighting model (dfr), retrieval based on passages/documents and setting the best configuration to each language. Specifically, we participated in the following languages: English, French, Portuguese and Hungarian. IR-n system <ref type="bibr" coords="1,163.52,613.11,10.52,10.46" target="#b4">[5]</ref> was developed in 2001. It is a Passage Retrieval (PR) system which uses passages with a fixed number of sentences. This provides the passages with some syntactical content. Previous researches with the IR-n system ([6] <ref type="bibr" coords="1,323.40,637.01,10.52,10.46" target="#b6">[7]</ref> [8] <ref type="bibr" coords="1,349.03,637.01,10.79,10.46" target="#b8">[9]</ref>) are based on detecting the suitable size for each collection ( to experiment with test collection ), but determining the similarity of a document based on the passage with more similarity. Last year <ref type="bibr" coords="1,373.72,660.93,15.50,10.46" target="#b9">[10]</ref> we proposed a new method 'combined size passages' in order to improve the performance of the system combining different size passages. This year we implemented a new similarity measure in the system and we tested our system with different configurations to each language.</p><p>Futhermore, our team participated in other tasks at CLEF-2006 as GeoCLEF, CL-SR... and we also applied PR systems in other tasks, such as Question Answering (QA) <ref type="bibr" coords="1,431.55,720.71,9.96,10.46" target="#b2">[3]</ref>. This paper is organized as follows: next section describes IR-n system and its new changes. Following, we describe the task developed at CLEF 2006 by our system and the training. And finally, we present the achieved results and the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IR-n system</head><p>In this section the main characteristics of the IR-n system are presented and details are given on the resources and the techniques of the system used in CLEF 2006.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Resources: stemmers and stopword lists</head><p>We used the stemmers and stopwords lists available on the web http://www.unine.ch/info/clef. We highlight that Hungarian collections are encoded in UTF-8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Weighting models</head><p>IR-n system uses several similarity measures. This year, the weighting model dfr <ref type="bibr" coords="2,441.45,305.68,10.52,10.46" target="#b0">[1]</ref> was included, but we also used okapi weighting model <ref type="bibr" coords="2,258.77,317.63,13.19,10.46" target="#b3">[4]</ref>.</p><p>The document ranking produced by each weighting model is represented using the same general expression, namely as the product of a document-based term weight by a query-based term weight:</p><formula xml:id="formula_0" coords="2,243.04,365.46,269.96,21.32">sim(q, d) = t∈q∧p w t,p • w t,q<label>(1)</label></formula><p>List of variables Here is described the list of variables used in the following formulas. 2, 3:</p><p>• f t,p is the frequency of the term t on the passage p,</p><p>• f t,q is the frequency of the term t on the query q,</p><p>• n is the number of documents in the collection,</p><p>• n t is the number of documents which t appears,</p><p>• c, k 1 , b and k 3 are constant values,</p><p>• ld is the length of the document,</p><p>• avg ld is the average of the length of the documents</p><p>Okapi Using the okapi model, the relevance score of a passage p for query q is given by:</p><formula xml:id="formula_1" coords="2,238.13,598.87,274.87,105.61">w t,p = (k 1 + 1) • f t,p K • f t,p w t,q = (k 3 + 1) • f t,q k 3 • f t,q • w t K = (1 -b) + b • ld avr l d w t = log 2 n -n t + 0.5 n t + 0.5<label>(2)</label></formula><p>DFR Using this model, the weight of a passage p for query q is given by:</p><formula xml:id="formula_2" coords="3,166.12,144.41,250.09,39.64">w t,q = f t,q w t,p = (log 2 (1 + w t ) + w t,p • log 2 ( 1 + w t w t )) • f t + 1 n t • (w t,p + 1)</formula><formula xml:id="formula_3" coords="3,286.33,183.96,226.67,48.51">w t,p = f t,p • log 2 (1 + c • avr ld ld ) w t = f t n (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query expansion</head><p>Most IR systems use query expansion techniques <ref type="bibr" coords="3,313.15,263.64,10.52,10.46" target="#b1">[2]</ref> based on adding the most frequent terms contained in the most relevant documents to the original query. The IR-n architecture allows us to use query expansion based on either the most relevant passages or the most relevant documents.</p><p>In previous researches, we obtained better results using the most relevant passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training</head><p>This section describes the training process which has been carried out in order to obtain the best features to improve the performance of the system. Firstly, the collections and resources are described. The following section explains the specific experiments which we have carried out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collections</head><p>This year our system has participated in the following monolingual tasks: English, French, Portuguese and Hungarian. Table <ref type="table" coords="3,225.68,436.42,4.98,10.46" target="#tab_0">1</ref> shows the characteristics of the language collections. • SDAvg is the average of sentences in each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>• WDAvg is the average of words in each document.</p><p>• WSAvg is the average of words in each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>The aim of the experiment phase is set up the optimum value of the input parameters for each collection. For training has been used the collections CLEF-2005 (English, French, Portuguese and Hungarian). Query expansion techniques have also been used in all languages. In addition, we describe the input parameter of the system:</p><p>• Size passage (sp): We established two size passage: 8 (normal passage) or 30 (big passage).</p><p>• Weighting model (wm): We use two weighting models: okapi and dfr.</p><p>• Opaki parameters: these are k 1 , b and avg ld (k 3 is fixed as 1000).</p><p>• Dfr parameters: these are c and avg ld .</p><p>• Query expansion parameters: If exp has value 1, this denotes we use relevance feedback based on passages in this experiment. But, if exp has value 2, the relevance feedback is based on documents. Moreover, np and nd denote the k terms extracted from the best ranked passages (np) or documents (nd) from the original query.</p><p>• Evaluation measure: Mean average precision (avgP) is the evaluation measure used in order to evaluate the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">English</head><p>As we can see at We submitted four runs for each language in our participation (except for English that we have submitted 1 run) in CLEF 2006. The best parameters, i.e. those that gave the best results in system training, were used in all cases. This is the description of the runs that we submitted at CLEF 2006:</p><p>• yy-xx-zexp -yy is the passage size -xx is the weighting model used (dfr or okapi) -z is the expansion query (not used 'nexp')</p><p>The official results for each run are showed in Table <ref type="table" coords="6,340.95,175.09,3.87,10.46" target="#tab_5">7</ref>. Like other systems which use query expansion techniques, these models also improve performance with respect to the base system. Our results are appreciably above average in all languages, except for English where they are sensible below the average. This results present that the percentage of improvement in Portuguese is 15.43% in avgP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this seventh CLEF evaluation campaign, we proposed a different configuration for the English, French, Portuguese and Hungarian languages (see table <ref type="table" coords="6,337.42,564.83,3.87,10.46" target="#tab_4">6</ref>). In order to enhance retrieval performance, we have evaluated different weighting models using also a query expansion approach based on passages and documents. The results of this evaluation indicate that for the French, Portuguese and Hungarian languages proved to be effective (see table <ref type="table" coords="6,233.85,612.66,4.43,10.46" target="#tab_5">7</ref>) because the results are above average. However, the English language has obtained results sensible below average.</p><p>For Portuguese language, the best results are obtained by okapi weighting model. For other languages (English, French and Hungarian), the best results are obtained by dfr (see table <ref type="table" coords="6,487.61,648.52,3.87,10.46" target="#tab_5">7</ref>).</p><p>The best passage size for French was 9, although for other languages (English, Portuguese and Hungarian) was 30 (this passage size is comparable to IR based on the complete document).</p><p>As in previous evaluation campaigns, pseudo-relevance feedback based on passages improves mean average precision statistics for all languages, even though this improvement is not always statistically significant.</p><p>Lastly, we outline the future directions that we plan to undertake are evaluate languages as Bulgarian or Spanish. Therefore, as future work we also consider to research into different ways of providing Natural Language information to basic IR and evaluating the impact of each approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,101.46,459.07,399.93,119.60"><head>Table 1 :</head><label>1</label><figDesc>Data Collections</figDesc><table coords="3,101.46,459.07,399.93,97.73"><row><cell></cell><cell>Collections</cell><cell>NDocs</cell><cell>Size</cell><cell cols="3">SDAvg WDAvg WSAvg</cell></row><row><cell>English</cell><cell cols="3">The Angeles Times 94 169477 579 MB</cell><cell>25</cell><cell>529</cell><cell>20</cell></row><row><cell></cell><cell>Glasgow Herald 95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>French</cell><cell>Le Monde 94/95</cell><cell cols="2">177452 487 MB</cell><cell>17</cell><cell>388</cell><cell>21</cell></row><row><cell></cell><cell>SDA French 94/95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Portuguese</cell><cell>Público 94/95</cell><cell cols="2">210734 564 MB</cell><cell>18</cell><cell>433</cell><cell>23</cell></row><row><cell></cell><cell>Folha 94/95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Hungarian</cell><cell>Magyar Hirlap 02</cell><cell>49530</cell><cell>105 MB</cell><cell>11</cell><cell>245</cell><cell>20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,302.27,423.01,444.71"><head>Table 3 :</head><label>3</label><figDesc>table 2, the best weighting scheme is dfr. Therefore, the passage size 8 obtains 0.5403 as average precision. Training results French 2005</figDesc><table coords="4,90.00,336.89,423.00,310.07"><row><cell cols="9">sp wm c avgld k1 b exp np nd</cell><cell>avgP</cell></row><row><cell>8</cell><cell>dfr</cell><cell>4</cell><cell>600</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4940</cell></row><row><cell>30</cell><cell>dfr</cell><cell>4</cell><cell>600</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5063</cell></row><row><cell>8</cell><cell cols="2">dfr 4</cell><cell>600</cell><cell></cell><cell></cell><cell>2</cell><cell cols="2">10 10 0.5403</cell></row><row><cell>30</cell><cell>dfr</cell><cell>4</cell><cell>600</cell><cell></cell><cell></cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>0.5384</cell></row><row><cell></cell><cell></cell><cell cols="7">Table 2: Training results English 2005</cell></row><row><cell>3.2.2 French</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="9">For French language, the best weighting scheme is okapi with 9 as passage size. This configuration</cell></row><row><cell cols="4">has obtained 0.3701 as average precision.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>sp</cell><cell>wm</cell><cell cols="3">c avgld k1</cell><cell>b</cell><cell cols="3">exp np nd</cell><cell>avgP</cell></row><row><cell>8</cell><cell>dfr</cell><cell>3</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3090</cell></row><row><cell>30</cell><cell>dfr</cell><cell>3</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3105</cell></row><row><cell>50</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3102</cell></row><row><cell>8</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell></cell><cell></cell><cell>2</cell><cell cols="2">10 10</cell><cell>0.3686</cell></row><row><cell>30</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell></cell><cell></cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>0.3607</cell></row><row><cell>9</cell><cell>okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.2 0.3</cell><cell></cell><cell></cell><cell>0.2964</cell></row><row><cell>8</cell><cell>okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.2 0.3</cell><cell></cell><cell></cell><cell>0.2954</cell></row><row><cell>9</cell><cell>okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.5 0.3</cell><cell></cell><cell></cell><cell>0.3011</cell></row><row><cell cols="2">9 okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.5 0.3</cell><cell>1</cell><cell>5</cell><cell>10 0.3701</cell></row><row><cell cols="2">30 okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.5 0.3</cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>0.3603</cell></row></table><note coords="4,90.00,706.18,87.84,10.46;4,90.01,724.57,423.00,10.46;4,90.00,736.52,328.56,10.46"><p><p>3.2.3 Hungarian</p>The best weighting scheme is dfr to Hungarian language, whereas the passage size is 30 to Hungarian. The best average precision obtained by this configuration is 0.3644.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,90.00,219.68,423.02,218.98"><head>Table 4 :</head><label>4</label><figDesc>Training results Hungarian 20053.2.4 PortugueseThe best configuration by Portuguese language is the same as Hungarian language (dfr as weighting scheme and 30 as size passage). The average precision obtained with this configuration is 0.3948.</figDesc><table coords="5,164.14,315.02,274.73,123.63"><row><cell cols="5">sp wm c avgld k1</cell><cell>b</cell><cell cols="2">exp np nd</cell><cell>avgP</cell></row><row><cell>8</cell><cell>dfr</cell><cell>6</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell>0.3362</cell></row><row><cell>30</cell><cell>dfr</cell><cell>4</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell>0.3484</cell></row><row><cell>30</cell><cell>dfr</cell><cell>6</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell>0.3457</cell></row><row><cell>50</cell><cell>dfr</cell><cell>4</cell><cell>300</cell><cell></cell><cell></cell><cell></cell><cell>0.3474</cell></row><row><cell>8</cell><cell>dfr</cell><cell>6</cell><cell>300</cell><cell></cell><cell></cell><cell>1</cell><cell>10 10</cell><cell>0.3733</cell></row><row><cell>30</cell><cell>dfr</cell><cell>4</cell><cell>300</cell><cell></cell><cell></cell><cell>1</cell><cell>5</cell><cell>10 0.3948</cell></row><row><cell>8</cell><cell>okapi</cell><cell></cell><cell>300</cell><cell cols="2">1,5 0,3</cell><cell></cell><cell>0.3283</cell></row><row><cell>8</cell><cell>okapi</cell><cell></cell><cell>300</cell><cell cols="2">1,5 0,3</cell><cell>1</cell><cell>10 10</cell><cell>0.3676</cell></row><row><cell cols="2">30 okapi</cell><cell></cell><cell>300</cell><cell cols="2">1,5 0,3</cell><cell>1</cell><cell>10 10</cell><cell>0.3793</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,90.00,450.06,423.01,160.19"><head>Table 5 :</head><label>5</label><figDesc>Training results Portuguese 20053.2.5 Experiments summaryIn conclusion, the table 6 shows the best configuration for each language. These configurations were used at CLEF 2006.</figDesc><table coords="5,100.41,548.39,402.18,61.86"><row><cell>language</cell><cell>run</cell><cell cols="5">sp wm C avgld k1</cell><cell>b</cell><cell>exp np nd avgP</cell></row><row><cell>English</cell><cell>8-dfr-exp</cell><cell>8</cell><cell>dfr</cell><cell>4</cell><cell>600</cell><cell></cell><cell></cell><cell>2</cell><cell>10 10 0.5403</cell></row><row><cell>French</cell><cell cols="3">9-okapi-exp 9 okapi</cell><cell></cell><cell>300</cell><cell cols="2">1.5 0.3</cell><cell>1</cell><cell>5</cell><cell>10 0.3701</cell></row><row><cell>Hungarian</cell><cell>30-dfr-exp</cell><cell>30</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell></cell><cell></cell><cell>2</cell><cell>10 10 0.3644</cell></row><row><cell cols="2">Portuguese 30-dfr-exp</cell><cell>30</cell><cell>dfr</cell><cell>4</cell><cell>300</cell><cell></cell><cell></cell><cell>1</cell><cell>5</cell><cell>10 0.3948</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,90.00,621.65,307.25,68.14"><head>Table 6 :</head><label>6</label><figDesc>Configurations used at CLEF 2006</figDesc><table coords="5,90.00,674.73,180.68,15.06"><row><cell>4 Results at CLEF-2006</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,180.51,243.91,241.99,245.13"><head>Table 7 :</head><label>7</label><figDesc>CLEF 2006 official results. Monolingual tasks.</figDesc><table coords="6,193.41,243.91,216.17,223.26"><row><cell></cell><cell>Run</cell><cell>AvgP</cell><cell>Dif</cell></row><row><cell>English</cell><cell cols="2">CLEF Average 38.73</cell></row><row><cell></cell><cell>30-dfr-exp</cell><cell>38.17</cell><cell>-1.44%</cell></row><row><cell>French</cell><cell cols="2">CLEF Average 37.09</cell></row><row><cell></cell><cell>30-dfr-exp</cell><cell>37.13</cell></row><row><cell></cell><cell>8-dfr-exp</cell><cell>38.28</cell><cell>+3.2%</cell></row><row><cell></cell><cell>9-okapi-exp</cell><cell>35.28</cell></row><row><cell></cell><cell>30-okapi-exp</cell><cell>37.80</cell></row><row><cell cols="3">Portuguese CLEF Average 37.32</cell></row><row><cell></cell><cell>30-dfr-exp</cell><cell>41.95</cell></row><row><cell></cell><cell>8-dfr-exp</cell><cell>42.06</cell></row><row><cell></cell><cell>8-okapi-exp</cell><cell>42.41</cell></row><row><cell></cell><cell>30-okapi-exp</cell><cell cols="2">43.08 +15.43%</cell></row><row><cell cols="3">Hungarian CLEF Average 33.37</cell></row><row><cell></cell><cell>30-dfr-exp</cell><cell>35.32</cell><cell>+5.5%</cell></row><row><cell></cell><cell>8-dfr-exp</cell><cell>34.25</cell></row><row><cell></cell><cell>30-dfr-nexp</cell><cell>30.60</cell></row><row><cell></cell><cell>8-dfr-nexp</cell><cell>29.50</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This research has been partially funded by the <rs type="funder">Spanish Government</rs> under project <rs type="projectName">CICyT</rs> number <rs type="grantNumber">TIC2003-07158-C04-01</rs> and by the <rs type="funder">Valencia Government</rs> under project number <rs type="grantNumber">GV06-161</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_qHXmeA5">
					<idno type="grant-number">TIC2003-07158-C04-01</idno>
					<orgName type="project" subtype="full">CICyT</orgName>
				</org>
				<org type="funding" xml:id="_yCSZHuf">
					<idno type="grant-number">GV06-161</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.47,199.08,402.53,10.46;7,110.48,211.03,341.55,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,275.69,199.08,237.32,10.46;7,110.48,211.03,186.06,10.46">Probabilistic Models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,305.85,211.03,48.36,10.46">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,230.96,402.54,10.46;7,110.48,242.91,402.52,10.46;7,110.48,254.88,402.52,10.46;7,110.48,266.83,352.80,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,259.19,230.96,253.83,10.46;7,110.48,242.91,122.83,10.46">Combining Query Translation and Document Translation in Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.26,254.88,277.14,10.46">4th Workshop of the Cross-Language Evaluation Forum, CLEF</title>
		<title level="s" coord="7,453.89,254.88,59.11,10.46;7,110.48,266.83,88.72,10.46">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="108" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,286.75,402.54,10.46;7,110.48,298.71,402.54,10.46;7,110.48,310.66,402.52,10.46;7,110.48,322.61,402.51,10.46;7,110.48,334.57,237.34,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,359.51,286.75,153.50,10.46;7,110.48,298.71,85.79,10.46">Passage Filtering for Open-Domain Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Noguera</forename><surname>Elisa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Ferrández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.45,310.66,366.55,10.46;7,110.48,322.61,201.61,10.46">Advances in Natural Language Processing, Proceedings of 5th International Conference on Natural Language Processing FinTAL</title>
		<title level="s" coord="7,392.83,322.61,120.17,10.46;7,110.48,334.57,30.49,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tapio</forename><surname>Pahikkala</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006-08">August 2006</date>
			<biblScope unit="volume">4139</biblScope>
			<biblScope unit="page" from="756" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,354.49,402.55,10.46;7,110.48,366.46,402.53,10.46;7,110.48,378.41,402.53,10.46;7,110.48,390.36,96.39,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,150.64,354.49,285.21,10.46">Fusion of Probabilistic Models for Effective Monolingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,348.99,366.46,164.02,10.46;7,110.48,378.41,137.66,10.46">4th Workshop of the Cross-Language Evaluation Forum, CLEF 2003</title>
		<title level="s" coord="7,257.66,378.41,155.96,10.46">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,410.29,402.53,10.46;7,110.48,422.24,124.06,10.46" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="7,154.74,410.29,300.64,10.46">IR-n: Un Sistema de Recuperación de Información Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Alicante</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="7,110.47,442.17,402.53,10.46;7,110.48,454.12,163.12,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,321.96,442.17,191.04,10.46;7,110.48,454.12,18.15,10.46">IR-n: A Passage Retrieval System at CLEF-2001</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vicedo</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,150.04,454.12,23.52,10.46">CLEF</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="244" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,474.05,402.53,10.46;7,110.48,486.00,251.98,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,413.82,474.05,99.19,10.46;7,110.48,486.00,18.15,10.46">IR-n System at CLEF-2002</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Luis Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ferrández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,150.04,486.00,113.64,10.46">Proceedings of CLEF 2002</title>
		<meeting>CLEF 2002</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,505.93,402.53,10.46;7,110.48,517.89,144.28,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,271.48,505.93,222.87,10.46">Cross-Language Experiments with the IR-n System</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,110.48,517.89,113.64,10.46">Proceedings of CLEF 2003</title>
		<meeting>CLEF 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,537.81,402.53,10.46;7,110.48,549.77,402.52,10.46;7,110.48,561.72,402.51,10.46;7,110.48,573.67,24.77,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,422.07,537.81,90.94,10.46;7,110.48,549.77,71.95,10.46">IR-n r2 : Using normalized passages</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><forename type="middle">M</forename><surname>Terol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,394.07,549.77,118.93,10.46;7,110.48,561.72,236.22,10.46">Cross Language Evaluation Forum: Working Notes for the CLEF 2004 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Borri</surname></persName>
		</editor>
		<meeting><address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IST-CNR</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,593.60,402.53,10.46;7,110.48,605.55,218.35,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,273.10,593.60,239.90,10.46;7,110.48,605.55,52.33,10.46">Combining Passages in the Monolingual Task with the IR-n System</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,184.55,605.55,113.64,10.46">Proceedings of CLEF 2005</title>
		<meeting>CLEF 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
