<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.72,204.67,64.01,8.74"><forename type="first">Prasad</forename><surname>Pingali</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Research Centre IIIT</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.41,204.67,72.87,8.74"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Language Technologies Research Centre IIIT</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1B08318042D963E9552F8BFF159A0AB8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Ad-hoc cross language text retrieval, Indian languages, Hindi, Telugu</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the experiments of Language Technologies Research Centre (LTRC) 1 as part of their participation in CLEF 2 2006 ad-hoc document retrieval task. This is our first participation in the CLEF evaluation tasks and we focused on Afaan Oromo, Hindi and Telugu as query languages for retrieval from English document collection. In this paper we discuss our Hindi and Telugu to English CLIR system and the experiments at CLEF.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-language information retrieval (CLIR) research involves the study of systems that accept queries (or information needs) in one language and return objects of a different language. These objects could be text documents, passages, images, audio or video documents. Cross-language information retrieval focused on the cross-language issues from information retrieval (IR) perspective rather than the machine translation (MT) perspective. The motivation for a separate research into such systems was that CLIR was not merely coupling of IR and MT, and a lot of processing usually performed in machine translation systems may not be necessary for CLIR. Also on the other hand, machine translation systems rely on syntactically well formed sentences as input to the system, which may not be a realistic assumption for an IR system, as most of the IR queries tend to be very short and many times without any syntactic correctness and hence very little context to perform syntactic parsing or disambiguate automatically. However, some times keyword based queries might also contain valid phrases which could be the level of language syntax one could rely on for CLIR systems. Some of the key technical issues <ref type="bibr" coords="2,247.63,112.02,10.52,8.74" target="#b2">[3]</ref> for cross language information retrieval can be thought of as</p><p>• How can a query term in L 1 be expressed in L 2 ?</p><p>• What mechanisms determine which of the possible translations of text from L 1 to L 2 should be retained?</p><p>• In cases where more than one translation are retained, how can different translation alternatives be weighed?</p><p>In order to address these issues, many different techniques were tried in various CLIR systems in the past. These techniques can be broadly classified <ref type="bibr" coords="2,341.48,239.54,10.52,8.74" target="#b6">[7]</ref> as controlled vocabulary based and free text based systems at a very high level. However, it is very difficult to create, maintain and scale a controlled vocabulary for CLIR systems in a general domain for a large corpus. Therefore very quickly researchers realized it would be essential to come up with models that can be built from the full text of the corpus. The free text based system research can be broadly classified on the corpus-based and knowledge-based aspects. This classification comes from the type of information resources used by the CLIR systems in order to address the above mentioned issues. For example, knowledge based systems might use bilingual dictionaries or ontologies which form the hand-crafted knowledge readily available for the systems to use. On the other hand corpusbased systems may use parallel or comparable corpora which are aligned at word level, sentence level or passage level to learn models automatically. Hybrid systems were also built combining the knowledge based and corpus based approaches. Apart from these approaches, the extension of monolingual IR techniques such as vector based models, relevance modeling techniques <ref type="bibr" coords="2,481.15,383.00,10.52,8.74" target="#b4">[5]</ref> etc., to cross language IR were also explored.</p><p>In this paper we discuss our experiments on CLIR for Indian languages to English, where the queries are in Indian languages and the documents to be retrieved are in English. Experiments were conducted using queries in two Indian languages using the CLEF 2006 experimental setup. The two languages chosen were Hindi which is predominantly spoken in north India and Telugu which is predominantly spoken in southern part of India. In the rest of the paper we discuss CLIR and related work in these Indian languages and also our own experiments at CLEF 2006.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Very little work has been done in the past in the areas of IR and CLIR involving Indian languages. In the year 2003 a surprise language exercise <ref type="bibr" coords="2,285.65,533.41,10.52,8.74" target="#b7">[8]</ref> was conducted at ACM TALIP<ref type="foot" coords="2,433.98,531.84,3.97,6.12" target="#foot_2">3</ref> . The task was to build CLIR systems for English to Hindi and Cebuano, where the queries were in English and the documents were in Hindi and Cebuano. Five teams participated in this evaluation task at ACM TALIP providing some insights into the issues involved in processing Indian language content. A few other information access systems were built apart from this task such as cross language Hindi headline generation <ref type="bibr" coords="2,204.57,593.19,9.96,8.74" target="#b1">[2]</ref>, English to Hindi question answering system <ref type="bibr" coords="2,413.40,593.19,15.50,8.74" target="#b10">[11]</ref> etc. We previously built a monolingual web search engine for various Indian languages which is capable of retrieving information from multiple character encodings <ref type="bibr" coords="2,294.35,617.10,14.61,8.74" target="#b9">[10]</ref>. However, no work was found related to CLIR involving Telugu or any other Indian language other than Hindi.</p><p>Some research was previously done in the areas of machine translation involving Indian languages <ref type="bibr" coords="2,122.38,652.96,9.96,8.74" target="#b0">[1]</ref>. Most of the Indian language MT efforts involve studies on translating various Indian languages amongst themselves or translating English into Indian language content. Hence most of the Indian language resources available for our work are largely biased to these tasks. This led to the challenge of using resources which enabled translation from English to Indian languages for a task involving translation from Indian languages to English.</p><p>The problem statement of CLIR task discussed in this paper is as defined in the ad-hoc track of CLEF 2006. The ad-hoc track tests mono-and cross-language textual document retrieval. The bilingual task on target collections in English would test systems where the topics are supplied in a variety of languages including Amharic, Afaan Oromo, Hindi, Telugu and Indonesian. In this paper we discuss our system for Hindi and Telugu languages therefore the system will be provided with a set of 50 topics in Hindi and Telugu where each topic represents an information need for which English text documents need to be retrieved and ranked. An example topic in Telugu would look as shown below.</p><formula xml:id="formula_0" coords="3,90.00,229.48,421.80,129.62">&lt;top&gt; &lt;num&gt; C302 &lt;/num&gt; &lt;TE-title&gt; ãÏ f s g i o m g &lt;/TE-title&gt; &lt;TE-desc&gt; ãÏ f s g i o m g i v D ãk Ý©v ¯i v Òe &lt;/TE-desc&gt; &lt;TE-narr&gt; n ©©Î ¯i ãÏ f s g i o m g iD ãÏ f s g i o m g ß ± ¸ ' ¨Ï Ê Ïf e i ¸ v Ýé ¤ fF ãÏ f s g i o m g i n ©©Î e D g xq f o m g i k Íi f ®ÞF &lt;/TE-narr&gt; &lt;/top&gt;</formula><p>Each topic comes with a unique number identifying the topic, a title, a description and a narrative. A title is typically a few words in length and is characteristic of a real world IR query. The description of a topic contains more detailed description of what the user is looking for, as a natural language statement. A narrative contains a little more information than the description in the sense that it also give additional information of what is relevant and what is not relevant. Such information would be very useful for systems which use both relevance as well as irrelevance information into their models. The system should use these topics as input or manually a set of keywords can be generated by a human and provided to the system. In this paper we restrict our problem to automatically retrieving the relevant documents with the input topics. The system is expected to provide an output of 1000 documents for each topic in a ranked order which are evaluated against a set of manually created relevance judgements. The possible judgements for each retrieved documents could either be relevant or irrelevant. In other words the relevance judgements are binary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>Our submission to CLEF 2006 uses a vector based ranking model with bilingual lexicon using word translations combined with a set of heuristics for query refinement after translation. The ranking is achieved using a vector based ranking model using TFIDF ranking algorithm. We used the lucene framework to index the English documents. All the English documents were stemmed and stop words were eliminated to obtain the index terms. These terms were indexed using the Lucene<ref type="foot" coords="3,120.58,618.75,3.97,6.12" target="#foot_3">4</ref> search engine using the TFIDF similarity metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Query Translation</head><p>The only resources we had access to were English-Hindi and English-Telugu cross language dictionaries <ref type="foot" coords="3,115.54,676.98,3.97,6.12" target="#foot_4">5</ref> which were primarily used in English to Indian language machine translation research. The English-Hindi dictionary was conviniently formatted for machine processing, however the English-Telugu dictionary was a digitized version of a human readable dictionary. In order to convert the human readable dictionary to machine processable form, a set of regular expressions were used.</p><p>Similar approaches were previously tried to convert human readable dictionaries into a form easily processable by machines <ref type="bibr" coords="4,199.14,123.98,9.97,8.74" target="#b5">[6]</ref>. We removed a set of standard high frequency suffixes both from the queries and dictionaries before-hand. The set of prefixes we used for Hindi are similar to those mentioned in <ref type="bibr" coords="4,150.06,147.89,9.96,8.74" target="#b3">[4]</ref>. For Telugu, we used the set of suffixes as shown in Table <ref type="table" coords="4,418.99,147.89,3.88,8.74" target="#tab_0">1</ref>.</p><p>kÈD ÈD ©D e D $iD iD $iD $ißD ißD i D i¸D ß ± D ßD $Ïq D q D ¸D f q D v D ËD v D $D %D &amp;D 'D (D eD fD hD iD pD &amp;f The terms remaining after suffix removal are looked up in bilingual dictionary which is a English to Indian language dictionary. A set of multiple English meanings for a given query term would be obtained for a given Indian language term. Many of the terms may not be found in the bilingual lexicon since the term is a proper name or a word from a foreign language or a valid Indian language word which just did not occur in the dictionary. In some of the cases dictionary lookup for a term might also fail because of improper stemming or suffix removal. Indian languages are agglutinative languages, especially Telugu is highly agglutinative which would demand a good stemming algorithm. However, due to lack of availability of such a resource we used suffix removal technique with a set of high frequency suffixes. For lookup failure cases where the word was a proper name, a transliteration from Indian language to English was attempted. The transliteration was first performed with a set of phoneme mappings between Indian langauge and English. While this technique might succeed in a few cases, in many cases this may not transliterate into the right English term. Therefore we used approximate string matching algorithms of the obtained transliteration against the lexicon from the corpus. We used the double metaphone <ref type="bibr" coords="4,457.05,390.68,10.52,8.74" target="#b8">[9]</ref> algorithm as well as Levenstein's approximate string matching algorithm to obtain possible transliterations for the query term which was not found in the dictionary. The intersection set from these two algorithms were added to the translated English query terms. This algorithm for query translation and transliteration addresses the first issue of representing query in language L 1 in language L 2 as was previously mentioned in section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Query Refinement and Retrieval</head><p>Once the translation and transliteration tasks are performed on the input Hindi and Telugu queries, we tried to address the second issue for CLIR from our list as mentioned in section 1. We tried to prune out the possible translations for the query in an effort to reduce the possible noise in translations. In order to achieve this, we used a pseudo-relevance feedback based on the top ranking documents above a threshold using the TFIDF retrieval engine. The translated English query was issued to the lucene search engine and a set of top 'n' documents were retrieved. The translated English terms that did not occur in these documents were pruned out in an effort to reduce the noisy translations. We chose 'n' to be 10 documents to refine the translated query. The final query after refinement process was issued to the lucene search engine to obtain the top 1000 TFIDF ranked documents. As evident from our approach, no efforts were made to identify the irrelevant documents in the search process. For this reason we did not use the narrative information in the topics for any of our runs. It is also evident that we did not make any efforts to weigh the various terms in the possible translations which is the third issue for CLIR as mentioned in section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Discussion</head><p>The evaluation document set consists of 113,005 documents from Los Angeles Times of 1994 and 56,472 documents from Glasgow Herald of 1995. A set of 50 topics representing the information need were given in Hindi and Telugu. A set of human relevance judgements for these topics were generated by assessors at CLEF. These relevance judgements are binary relevance judgements and are decided by a human assessor after reviewing a set of pooled documents using the relevant document pooling technique. The system evaluation framework is similar to the Cranfield style system evaluations and the measures are similar to those used in TREC<ref type="foot" coords="5,412.77,234.33,3.97,6.12" target="#foot_5">6</ref>  <ref type="bibr" coords="5,421.30,235.90,14.62,8.74" target="#b11">[12]</ref>. Four runs were submitted related to the Indian languages, two with Hindi queries and two with Telugu queries.</p><p>A run was performed using only title and a run was performed using both title and description for each of these languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">CLEF 2006 Evaluation for Hindi-English and Telugu-English CLIR</head><p>The run statistics for the 4 runs submitted to CLEF 2006 are described in table 2. Clearly the geometric average precision metrics and its difference from mean average precision metrics here suggests the lack of robustness in our system. There were certain topics that performed very well while there were many topics where the performance was very low. Interestingly not much difference exists between the title runs and the title-description runs. This is surprising and suggests that most of the information for CLIR is coming from the titles. Another interesting finding with respect to the title and title-description runs is the ranking of these metrics. Clearly b-pref measure (which is a more recent metric) suggests that the title run was superior to titledescription run, however all the other three metrics, the mean average precision, R-precision and geometric average precision suggest that the title-description run was better than the title run. The overall relatively low performance of the system with Indian language queries when compared to Afaan Oromo (an Ethiopian language we experimented with), suggests that a number of topics have low performance statistics, which was also evident from the topicwise score breakups. This is indicative of the fact that simple techniques such as dictionary lookup with minimal lemmatization such as suffix removal may not be sufficient for Indian language CLIR. Also we can observe that Telugu has performed much lower than Hindi suggesting the need for a good stemming and stem dictionaries. It was found from a previous corpora analysis of Indian languages that the number of unique words found in equal sized corpus of Hindi and Telugu, suggests that Telugu language is more agglutinative than Hindi, resulting in 4 times more number of unique words than Hindi. This suggests that the need for broader coverage of dictionary and good morphological analyzer is inevitable for Telugu CLIR in order to achieve a reasonable performance. The interpolated recall with average precision graphs as shown in figure <ref type="figure" coords="5,428.55,569.10,4.98,8.74" target="#fig_0">1</ref> suggests that the effect of ranking has not been much in the system. The sloping of the curve seems to be consistent all across, as opposed to a rapid sloping for the first few recall points. A good ranking algorithm would consistently push relevant documents to the top ranks, thereby resulting in a rapid sloping of the curve for the first few recall points. Relatively a slight effect of ranking can be found for Hindi when compared to Telugu, however the overall indication seems to be that the ranking function is not an effective ranking mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>Our experiments suggest that simple extensions of vector based algorithms such as TFIDF may not result in effective CLIR systems for Indian language queries. Any additional information added from corpora either resulting in source language query expansion or target language query expansion or both could help. An aligned bilingual parallel corpus would be an ideal resource to have in order to apply certain machine learning approaches. However monolingual corpora based learning can be still tried as a backoff. Also need for better Indian language processing is clearly evident from our experiments. We plan to extend our system using monolingual Indian language corpora to enable source language query expansion and also factor in target language query expansion.  HNT run using Hindi title, HNTD run using Hindi title and description, TET run using Telugu title, TETD run using Telugu title and description.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,90.00,674.99,423.00,8.74;7,90.00,686.94,423.01,8.74;7,90.00,698.90,224.05,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Interpolated Recall vs Average Precision for Hindi-English and Telugu-English runs. HNT run using Hindi title, HNTD run using Hindi title and description, TET run using Telugu title, TETD run using Telugu title and description.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,120.90,211.35,361.20,8.74"><head>Table 1 :</head><label>1</label><figDesc>Telugu suffixes (full vowels may be replaced with short vowel equivalents)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,153.54,110.79,291.51,80.04"><head>Table 2 :</head><label>2</label><figDesc>Run Statistics</figDesc><table coords="5,153.54,110.79,291.51,58.18"><row><cell>Run</cell><cell>MAP</cell><cell cols="2">R-Prec GAP B-Pref</cell></row><row><cell>Hindi Title</cell><cell cols="2">12.32% 13.14%</cell><cell>2.40% 12.78%</cell></row><row><cell>Hindi Title + Description</cell><cell cols="2">12.52% 13.16%</cell><cell>2.41% 10.91%</cell></row><row><cell>Telugu Title</cell><cell>8.09%</cell><cell>8.39%</cell><cell>0.34% 8.36%</cell></row><row><cell cols="2">Telugu Title + Description 8.16%</cell><cell>8.42%</cell><cell>0.36% 7.84%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,737.50,272.95,6.99"><p>LTRC is a research centre at IIIT, Hyderabad, India. http://ltrc.iiit.ac.in</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,105.24,747.00,227.93,6.99"><p>Cross Language Evaluation Forum. http://clef-campaign.org.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,719.71,361.58,6.99"><p>ACM Transactions on Asian Language Information Processing. http://www.acm.org/pubs/talip/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,105.24,733.35,91.27,6.99"><p>http://lucene.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,105.24,742.86,174.53,6.99"><p>http://ltrc.iiit.net/onlineServices/Dictionaries/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,105.24,738.44,176.89,6.99"><p>Text Retrieval Conferences, http://trec.nist.gov</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,226.56,402.53,8.74;6,110.48,238.52,402.52,8.74;6,110.48,250.47,276.69,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,426.67,226.56,86.34,8.74;6,110.48,238.52,122.43,8.74">Machine translation activities in India: A survey</title>
		<author>
			<persName coords=""><forename type="first">Akshar</forename><surname>Bharati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rajeev</forename><surname>Sangal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dipti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amba P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,268.75,238.52,244.25,8.74;6,110.48,250.47,246.16,8.74">the Proceedings of workshop on survey on Research and Development of Machine Translation in Asian Countries</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,270.40,402.52,8.74;6,110.48,282.35,402.52,8.74;6,110.48,294.31,43.73,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,341.05,270.40,171.96,8.74;6,110.48,282.35,20.76,8.74">Cross-language headline generation for hindi</title>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,142.79,282.35,320.29,8.74">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="289" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,314.23,402.52,8.74;6,110.48,326.19,208.14,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,305.09,314.23,166.14,8.74">Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,346.11,402.52,8.74;6,110.48,358.07,402.53,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,394.70,346.11,113.86,8.74">Hindi CLIR in thirty days</title>
		<author>
			<persName coords=""><forename type="first">Leah</forename><forename type="middle">S</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nasreen</forename><surname>Abduljaleel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,110.48,358.07,310.74,8.74">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="142" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,377.99,402.53,8.74;6,110.48,389.95,402.53,8.74;6,110.48,401.91,402.52,8.74;6,110.48,413.86,25.73,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,364.62,377.99,130.56,8.74">Cross-lingual relevance models</title>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Choquette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,110.48,389.95,402.53,8.74;6,110.48,401.91,178.68,8.74">SIGIR &apos;02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,433.79,402.51,8.74;6,110.48,445.74,402.52,8.74;6,110.48,457.70,402.51,8.74;6,110.48,469.65,216.45,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,276.64,433.79,236.36,8.74;6,110.48,445.74,150.92,8.74">Converting on-line bilingual dictionaries from humanreadable to machine-readable form</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,284.96,445.74,228.04,8.74;6,110.48,457.70,371.19,8.74">SIGIR &apos;02: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="405" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,489.58,402.52,8.74;6,110.48,501.53,252.98,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,176.98,489.58,238.10,8.74">Alternative approaches for cross language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,434.83,489.58,78.17,8.74;6,110.48,501.53,196.25,8.74">AAAI Symposium on Cross Language Text and Speeck Retrieval</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,521.46,402.52,8.74;6,110.48,533.41,223.32,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,196.03,521.46,136.54,8.74">The surprise language exercises</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,342.06,521.46,170.95,8.74;6,110.48,533.41,140.63,8.74">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="84" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,553.34,399.42,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,160.06,553.34,180.87,8.74">The Double-Metaphone Search Algorithm</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,350.09,553.34,100.54,8.74">C/C++ User&apos;s Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.47,573.26,402.52,8.74;6,110.48,585.22,402.53,8.74;6,110.48,597.17,388.27,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,395.03,573.26,117.97,8.74;6,110.48,585.22,159.58,8.74">Webkhoj: Indian language ir from multiple character encodings</title>
		<author>
			<persName coords=""><forename type="first">Prasad</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jagadeesh</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,294.31,585.22,218.70,8.74;6,110.48,597.17,135.86,8.74">WWW &apos;06: Proceedings of the 15th international conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="801" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.47,617.10,402.52,8.74;6,110.48,629.05,402.53,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,276.39,617.10,231.97,8.74">Hindi-english cross-lingual question-answering system</title>
		<author>
			<persName coords=""><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,110.48,629.05,310.74,8.74">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.47,648.98,402.52,8.74;6,110.48,660.93,402.52,8.74;6,110.48,672.89,186.64,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,285.06,648.98,158.47,8.74">The text retrieval conferences (trecs)</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,463.34,648.98,49.66,8.74;6,110.48,660.93,108.32,8.74">Proceedings of a workshop on held at</title>
		<meeting>a workshop on held at<address><addrLine>Baltimore, Maryland; Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="241" to="273" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
