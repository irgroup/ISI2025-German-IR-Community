<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.78,115.96,335.80,12.62;1,179.14,133.89,257.08,12.62;1,246.43,151.82,122.49,12.62">A Weighted Rule-Based Model for File Forgery Detection: UA.PT Bioinformatics at ImageCLEF 2019</title>
				<funder>
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_RzuETuE">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_vYxCtwS">
					<orgName type="full">Portugal 2020</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.25,189.49,90.50,8.74"><forename type="first">João</forename><forename type="middle">Rafael</forename><surname>Almeida</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DETI / IEETA</orgName>
								<orgName type="institution">University of Aveiro</orgName>
								<address>
									<settlement>Aveiro</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Information and Communications Technologies</orgName>
								<orgName type="institution">University of A Coruña</orgName>
								<address>
									<settlement>A Coruña</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.87,189.49,53.77,8.74"><forename type="first">Pedro</forename><surname>Freire</surname></persName>
							<email>pedrofreire@ua.pt</email>
						</author>
						<author>
							<persName coords="1,135.57,201.45,57.45,8.74"><forename type="first">Olga</forename><surname>Fajarda</surname></persName>
						</author>
						<author>
							<persName coords="1,310.19,201.45,77.89,8.74"><forename type="first">José</forename><forename type="middle">Luís</forename><surname>Oliveira</surname></persName>
							<email>olga.oliveira@ua.pt</email>
							<affiliation key="aff0">
								<orgName type="department">DETI / IEETA</orgName>
								<orgName type="institution">University of Aveiro</orgName>
								<address>
									<settlement>Aveiro</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.78,115.96,335.80,12.62;1,179.14,133.89,257.08,12.62;1,246.43,151.82,122.49,12.62">A Weighted Rule-Based Model for File Forgery Detection: UA.PT Bioinformatics at ImageCLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">46459D3122221E17B6BAF29D4E79E28F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>File Forgery Detection</term>
					<term>Rule-based models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With today's digital technology, disparate kinds of data can be easily manipulated. The forgery commonly hides information, by altering files' extensions, files' signatures, or by using steganography. Consequently, digital forensic examiners are faced with new problems in the detection of these forged files. The lack of automatised approaches to discover these infractions encourages researchers to explore new computational solutions that can help its identification. This paper describes the methodologies used in the ImageCLEFsecurity 2019 challenge, which were mainly rule-based models. The rules and all of their underlying mechanisms created for each task are described. For the third task, was used a random forest algorithm due to the poor performance of these rules.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ImageCLEF <ref type="bibr" coords="1,211.94,496.09,10.52,8.74" target="#b6">[7]</ref> initiative launched a new security challenge, called Image-CLEFsecurity, addressing the problem of automatically identifying forged files and stego images <ref type="bibr" coords="1,209.97,520.00,14.61,8.74" target="#b9">[10]</ref>. This challenge is divided into three sub-tasks: 1) forged file discovery, 2) stego image discovery and 3) secret message discovery. The forged files discovery sub-task is the first task of the challenge and it is independent from the remaining two tasks. The goal of this task is to automatically detect files whose extension and signature has been altered; more specifically, to identify the files with extension PDF that are, actually, image files (with extension JPG, PNG, and GIF). The objective of the second sub-task is to identify the images that hide steganographic content and the goal of the third task is to retrieve these hidden messages.</p><p>In this paper, we present the several approaches that we used to address this challenge. The main solution is based on an orchestration of specialised rulebased models. For each model, a set of rules was defined with the purpose of identifying a specific file or message. Additionally, when there are insufficient rules to provide a good result, other complementary strategies have been combined, namely a random forest classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials and Methods</head><p>For each task, a training set and a test set were provided. The training set of the first task is composed of 2400 files, 1200 of which are PDF files. The remaining files, despite having PDF extension, belong to one of three classes: JPEG, PNG, GIF, each with 400 files. In the second and third tasks, the training sets include 1000 JPEG images, 500 of which are stego images and the others are clean images. In the case of the third task, the stego images contain five different text messages. Regarding the test sets, the first task is comprised of 1000 files and the second and third tasks are composed of 500 images.</p><p>In this section, we present the five methods that were used to solve each task of the challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Rule-Based Approach</head><p>A typical rule-based system is constructed through a set of if-then rules <ref type="bibr" coords="2,465.10,391.40,15.50,8.74" target="#b13">[14]</ref> which help identify conditions and patterns in the problem domain. However, the use of simple conditions may not be enough to obtain the best results. Sometimes, to accomplish a more accurate outcome, those rules need to be balanced, with weights. The subject of rule weights in fuzzy rule-based models for classifications is not new, and its positive effect has already been proven <ref type="bibr" coords="2,391.03,451.17,9.96,8.74" target="#b7">[8]</ref>.</p><p>We propose a rule-based weighted system with a set of models (figure <ref type="figure" coords="2,468.96,463.13,3.87,8.74" target="#fig_0">1</ref>), which are specialised in classifying a specific entry. Each model generates a confidence score regarding the match of the received input with its conditions. The orchestrator collects all the results and chooses the model that gives the best score. When more than one models give similar good confidence scores for different classes, the weights of the rules are readjusted and a new classification cycle is performed to help separating the classes' scores. These readjustments will, hopefully, allow the right output to stand out.</p><p>The rules and the weight of the rules are specific to each problem and scenario. Therefore, we used this approach as our base method for all the tasks. The rules and the methods to classify the rules are specified in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Distortion Pattern Matching</head><p>Steganographic techniques permit hiding, within an image, information that should be perceptually and statistically undetectable <ref type="bibr" coords="2,373.08,644.16,11.15,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,384.23,644.16,11.15,8.74" target="#b10">11]</ref>. However, some of these techniques, may not respect these two principles entirely, namely tools like Jsteg, Outguess, F5, JPHide, and Steghide. These tools use the least significant bit (LSB) insertion technique and distort the fidelity of the cover image by choosing the quantized DCT coefficients as their concealment locations <ref type="bibr" coords="3,448.14,349.75,14.61,8.74" target="#b10">[11]</ref>.</p><p>Our approach aims to identify flaws of the used method by searching for a common pattern among all the stego images.</p><p>While scanning the training set of the second task for common patterns, it was possible to identify that several stego images had a distortion pattern of 8x8 pixels size, that could easily be identified with the naked eye, as described in figure <ref type="figure" coords="3,162.46,424.01,4.98,8.74" target="#fig_1">2</ref> and figure <ref type="figure" coords="3,217.84,424.01,3.87,8.74" target="#fig_2">3</ref>.  We created a function to scan an image for this pattern and to count the number of occurrences. The function determines that a certain image had a message if the number of patterns found is greater than the specified threshold. Its output was used as a parameter into our weighted rule-base model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Metadata Pattern Searcher</head><p>Another approach used to assist the creation of rules for our rule-based model was a pre-analysis of the file's metadata. This analysis aimed to discover patterns that could be used as rules in the model. For instance, in the JPEG images of the training set of the second task, a set of bits were detected which identified the images with a hidden message.</p><p>The pattern search was mainly done with the metadata, ignoring the image bitstream. The rational was that the altered files could be signed in the metadata to quickly identify which files are of interest. This simple signature would go unnoticed and it would increase the decoding procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Random Forests for Rule Definition</head><p>Random forest is a supervised learning algorithm developed by Breiman <ref type="bibr" coords="4,446.92,498.41,9.96,8.74" target="#b2">[3]</ref>, who was influenced by the work of Amit and Geman <ref type="bibr" coords="4,350.35,510.37,9.96,8.74" target="#b0">[1]</ref>. This algorithm constructs a large number of decision trees, considering a random subset of features for each split, and makes a prediction by combining the predictions of the different decision trees. Caruana and Niculescu-Mizil <ref type="bibr" coords="4,327.54,546.23,10.52,8.74" target="#b3">[4]</ref> performed an empirical comparison of supervised learning and concluded that random forest was one of the algorithms that gave the best average performance.</p><p>The random forest algorithm has several positive characteristics <ref type="bibr" coords="4,434.76,583.24,10.52,8.74" target="#b4">[5]</ref> for this challenge, namely it can be used for high-dimensional problems and it gives an estimation of the importance of variables. Moreover, it just needs two parameters: the number of trees in the forest (ntree) and the number of features in the random subset used in each split (mtry).</p><p>We used the random forest algorithm in order to help solve the third task and our implementation is described in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Manual Tuning</head><p>In large data sets, manual classification is unrealistic. However, since the training and test set are small, we decide to try a manual validation. This approach consists mainly in a verification of the rule-based output, followed by manual adjustments considered relevant. This method was, essentially, used in the second task.</p><p>When analysing the training set, the 8x8 pixel distortion pattern described in 2.2 was identified. Using the rule-based model in the early stages, made it possible to define rules to reach a precision of 1. However, the recall was low. Therefore, we isolated the images not detected as forged and tried to identify these distortions in the image manually. This procedure increased our recall significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The described methods were combined and led to several submissions in the different tasks. The performance of the submissions was evaluated using the traditional metrics: precision, recall, and F1, in the first two tasks and edit distance in the third task.</p><p>In the first task, the precision was defined as the quotient between the number of altered images correctly detected and the total number of files identified as changed. In its turn, the recall was the quotient between the number of altered images correctly detected and the total number of files modified.</p><p>For the second task, the definition of precision and recall was similar. The precision was the quotient between the number of images with hidden messages correctly detected and the total number of images with hidden messages identified. The recall was the quotient between the number of images with hidden messages correctly detected and the total number of images with hidden messages.</p><p>Finally, the third task used the edit distance to measure the efficiency into recovering the message. This distance is the minimum-weight count of edit operations that transforms a string in another one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task 1: Identify Forged Images</head><p>Detecting the type of file is a process that can be done using three different file characteristics: the file's extension, the magic number, and the file's content <ref type="bibr" coords="5,467.31,572.43,9.96,8.74" target="#b8">[9]</ref>. The most straightforward technique to hide a file is changing the file's extension and the magic number, which is a set of standard bytes that signs the file. With this technique, the operation system is unable to open the file. Therefore, four models are built, each one specialised in identifying a file type (PDF, PNG, JPG or GIF). Each model produces a score reflecting the confidence that the analysed file is of the given type. These scores are sent to the orchestrator, who classifies the type of file based on the scores received.</p><p>The initial approach considered standard flags in the file structure, such as the last bytes or the number of occurrences of a set of bytes. For instance, a JPEG file has the hexadecimal 0xFFDA at least once in its structure because this is the flag that indicates where the image binary starts. Table <ref type="table" coords="6,436.26,154.86,4.98,8.74" target="#tab_0">1</ref> presents the flags for the end of file for each file type. For this first task, we used the rule of identifying the end of file flag and obtained an F1 measure of 1.0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task 2: Identify Stego Images</head><p>In JPEG images there are two different stages of compression: lossy and lossless.</p><p>Embedding steganographic content inside images that uses lossy compression increases the possibility of that content to be partly lost, which means that, it is not feasible to hide a message on a lossy stage. Therefore, in the case of JPEG files, the steganography should take place on the lossless stage. The DCT and the quantization phase form part of the lossy stage, while the Huffman encoding used to further compress the data is lossless. <ref type="bibr" coords="6,332.61,451.08,14.61,8.74" target="#b12">[13]</ref>.</p><p>After scanning the training set of the second task for common parts that distinguishes stego images binary data from non-stego images, it was possible to observe some patterns and specify the weights of the rules that identifies stego images. The patterns and their weights are described on table 2. We could observe that all the patterns appeared in the Huffman table sequences, i.e. after the marker DHT. The sequences in a JPEG file are identified by a two-byte code described in table <ref type="table" coords="6,215.38,534.93,3.87,8.74" target="#tab_2">3</ref>.  This task was also solved using the rule based-model where the images with a score equal to or greater than 0.70 were considered as altered. However, in this case, strategies and different ways to extract information from the images were combined. Initially, a metadata pattern searcher to compare the metadata fields' content was developed. From this analysis, in all the images with a hidden message, the set of bits represented in the rules displayed in table 2 were found. However, these rules produced several false positives, achieving, using the training set, a recall of 1.0 and a precision of 0.75.</p><p>Due to the lack of precision, we attempt to identify the distortion pattern in the images, the method described in section 2.2. Without the rules used in the first approach and using a threshold of at least one pixel-block with the distortion, this method produced a precision of 0.53 and a recall of 0.60 in the training set. It was also the best score obtained from all runs using this approach isolated.</p><p>Then, to increase the precision, the decision was made to combine the rules of the first approach with this analyser. The image analyser method was only used when an image was classified through the first approach as having a hidden message. This decreased the recall to 0.604 and the precision remained in the 0.75, the best precision result so far. The decrease of the recall and the bad results in isolated scenarios led to the abandonment of this approach and to focusing only on ways to increase the quality of the rules.</p><p>At this stage, a submission was made, obtaining an F1 measure of 0.933 and a precision of 0.874.</p><p>In the next attempts some manual rectifications were made in the output retrieved from the rule-based system, by observing the images classified as having a message. Some submission were made following only the rule-based approach mixed with the manual validation, and the best result was 0.98, both for F1 and precision.</p><p>As a last attempt, the decision was made to re-run the metadata pattern searcher to be more precise. Now, it analysed all the metadata as a binary, ignoring which were the fields or its content. With these changes, the method found a new pattern, which produced a new rule, represented in table 4, made it possible to achieve F1 measure of 1 in the training and test sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task 3: Retrieve the Message</head><p>The goal of the third task was to retrieve the hidden text messages from the stego images. To address this task, initially freely available steganographic tools were used, specifically, Hide'N'Send, Image Steganography<ref type="foot" coords="8,388.54,422.54,3.97,6.12" target="#foot_0">3</ref> , QuickStego, SSuite Picsel<ref type="foot" coords="8,163.26,434.49,3.97,6.12" target="#foot_1">4</ref> , Steghide<ref type="foot" coords="8,214.37,434.49,3.97,6.12" target="#foot_2">5</ref> , and SteganPEG <ref type="bibr" coords="8,298.56,436.07,14.61,8.74" target="#b14">[15]</ref>. However, none of the steganographic tools were able to retrieve the hidden text messages.</p><p>In our second approach, the RGB matrix was analyzed. First, each colour component was individually inspected, examining the least and the two least significant bits, in order to detect if they could compose ASCII codes of letters in the alphabet, more precisely, the ASCII character in the range from 65 to 90, and from 97 to 122. As these procedures did not provide a pattern for the stored messages, the decision was made to look to the pixel as a whole, inspecting the three colour component combined. We, also, tried to use the two least significant bits from the four pixels that are in the centre of each 8x8 pixel block.</p><p>The second approach could not retrieve the hidden messages from the image files and therefore an attempt to find a pattern using the DCT matrix was made, by inspecting the least and the two least significant bits from the value in the first cell of an 8x8 block. The change of the least or the two least significant bit of these values would create a small change in the block brightness, which would explain the distortion identified in the 8x8 pixel block. None of the procedures described so far could find a pattern in the images of the training set with the same hidden text message. Therefore, the random forest algorithm in an attempt to find a pattern in the binary of the image files was used. The 500 stego images of the training set have, as hidden message, one of five messages. Consequently, the next step was to consider a multiclass classification problem which consists in classifying each stego image into one of the five messages. Initially, for our first model, we used as features the frequency, in percentage, with which each ASCII character appears in the binary of the image files. For the second model, in addition to the features used in the first model, the percentage of 0s and 1s in the binary of the image files were used.</p><p>To train the models we used the R package caret <ref type="bibr" coords="9,352.17,238.55,15.50,8.74" target="#b11">[12]</ref> and used cross-validation the chose the optimal value of the parameters ntree and mtry. In what concerns the performance of the models, this was evaluated using 10-fold cross-validation. Table <ref type="table" coords="9,162.16,274.41,4.98,8.74" target="#tab_4">5</ref> presents the parameters used and the accuracy of each model. From the results, the random forest models were unable to find a pattern in the binary of the image files. In the absence of alternatives, the two random forest models to classify the image files of the test set were used, despite the fact that this task was not a classification problem. The first step was to use the rule based-model defined in the second task to identify the stego images of the test set and, subsequently, the random forest models to classify the images identified as containing a hidden message. For the submissions, all the images in the test set should have a string appointed and therefore an empty string to the images identified as having no hidden message was assigned. Using the first model, an edit distance of 0.588 was obtained and using the second model an edit distance of 0.587. Our best edit distance (0.598) was achieved by assigning the string "name John Fraud " to all images we identified as stego images and an empty string to the other images of the test set. These results reflect the fact that we could correctly identify the images with no hidden messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper presents the methodologies to identify forged files and stenographic images used in the ImageCLEFsecurity challenge. These methods were developed specifically for the tasks of this challenge, which does not invalidate them being used for other data sets. In the first task, an F1 measure of 1 was obtained. This excellent result was accomplished mainly because the changes done to the files were only the traditional ones, and with simple rules, it was possible to identify each type. The second task also had a submission with F1 measure of 1. In this case, we could identify a signature in the altered images. On the other hand, in the third task, the best submission had an edit distance of 0.598, mainly due to the success of identifying empty strings, i.e., images without a message. The purposed methodology works if it is possible to define the right rules. The problem in this task was the difficulty to find the stenographic algorithm used.</p><p>This challenge allowed for the identification of problems in the developed approach, and most importantly, ways to improve some of these issues. A future work originated from this year's participation could be the creation of a rule generator to fed the rule-based models. The message identification task may be improved by creating a database of strategies used by stenographic attackers, mixed with machine learning approach that look into neighbourhood pixel colour.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,230.88,287.08,153.60,8.74;3,144.66,115.84,326.04,159.72"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Proposed rule-based system.</figDesc><graphic coords="3,144.66,115.84,326.04,159.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,593.73,169.46,8.74;3,134.77,605.68,169.46,8.74;3,134.77,617.64,41.23,8.74;3,134.77,453.85,163.20,128.35"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Distortion patterns observed on a training image of task 2 (with a zoom of 670%).</figDesc><graphic coords="3,134.77,453.85,163.20,128.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,311.13,593.73,169.46,8.74;3,311.13,605.68,34.90,8.74;3,311.13,450.04,132.30,132.16"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Pixel block of 8x8 with distortion pattern.</figDesc><graphic coords="3,311.13,450.04,132.30,132.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,197.62,222.06,220.11,87.65"><head>Table 1 :</head><label>1</label><figDesc>Rule used in task one.</figDesc><table coords="6,197.62,237.91,220.11,71.79"><row><cell cols="2">File format Ending of file (Hexadecimal values)</cell></row><row><cell>GIF</cell><cell>0x3B</cell></row><row><cell>JPG</cell><cell>0xFFD9</cell></row><row><cell>PNG</cell><cell>0x49454E44AE426082</cell></row><row><cell>PDF</cell><cell>0x454F46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,155.27,576.28,304.82,82.62"><head>Table 2 :</head><label>2</label><figDesc>Weighted rules used in Task 2 for the first submission.</figDesc><table coords="6,155.27,590.77,304.82,68.13"><row><cell cols="2">Rule Searched on</cell><cell>Hex matching value</cell><cell>Weight</cell></row><row><cell>1</cell><cell>DHT</cell><cell>0x3435363738393a434445464748494a53545556 5758595a636465666768696a737475767778797a</cell><cell>0.35</cell></row><row><cell>2</cell><cell>DHT</cell><cell>0x35363738393a434445464748494a535455565 758595a636465666768696a737475767778797a</cell><cell>0.35</cell></row><row><cell>3</cell><cell>DHT</cell><cell>0xf2f3f4f5f6f7f8f9fa</cell><cell>0.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,218.69,127.36,177.99,181.30"><head>Table 3 :</head><label>3</label><figDesc>Common JPEG file markers<ref type="bibr" coords="7,383.39,127.36,9.96,8.74" target="#b5">[6]</ref>.</figDesc><table coords="7,221.96,143.27,171.43,165.40"><row><cell cols="3">Marker id Short value Description</cell></row><row><cell>SOI</cell><cell>0xFFD8</cell><cell>start of image</cell></row><row><cell>APPn</cell><cell>0xFFEn</cell><cell>application data</cell></row><row><cell>DQT</cell><cell>0xFFDB</cell><cell>quant.tables</cell></row><row><cell>DHT</cell><cell>0xFFC4</cell><cell>Huffmantables</cell></row><row><cell>SOF</cell><cell>0xFFCn</cell><cell>start of frame</cell></row><row><cell>SOS</cell><cell>0xFFDA</cell><cell>start of scan</cell></row><row><cell>DRI</cell><cell>0xFFDD</cell><cell>restart interval</cell></row><row><cell>RSTn</cell><cell>0xFFDn</cell><cell>restart</cell></row><row><cell>COM</cell><cell>0xFFFE</cell><cell>comment</cell></row><row><cell>EOI</cell><cell>0xFFD9</cell><cell>end of image</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,155.27,233.78,304.82,98.23"><head>Table 4 :</head><label>4</label><figDesc>Final weighted rules used in Task 2.</figDesc><table coords="8,155.27,248.27,304.82,83.74"><row><cell cols="2">Rule Searched on</cell><cell>Hex matching value</cell><cell>Weight</cell></row><row><cell>1</cell><cell>DHT</cell><cell>0x3435363738393a434445464748494a53545556 5758595a636465666768696a737475767778797a</cell><cell>0.35</cell></row><row><cell>2</cell><cell>DHT</cell><cell>0x35363738393a434445464748494a535455565 758595a636465666768696a737475767778797a</cell><cell>0.15</cell></row><row><cell>3</cell><cell>DHT</cell><cell>0xf2f3f4f5f6f7f8f9fa</cell><cell>0.15</cell></row><row><cell>4</cell><cell>APP0</cell><cell>0x00600060</cell><cell>0.35</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,185.51,318.01,244.34,68.80"><head>Table 5 :</head><label>5</label><figDesc>Random forest models' parameters and results.</figDesc><table coords="9,228.59,330.32,158.17,56.49"><row><cell></cell><cell cols="2">Parameters</cell><cell></cell></row><row><cell>Models</cell><cell cols="2">ntree mtry</cell><cell>Accuracy</cell></row><row><cell>First model</cell><cell>247</cell><cell>82</cell><cell>31,57%</cell></row><row><cell cols="2">Second model 374</cell><cell>59</cell><cell>31,33%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="8,144.73,634.88,197.25,7.86"><p>https://incoherency.co.uk/image-steganography/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="8,144.73,645.84,253.38,7.86"><p>https://www.ssuiteoffice.com/software/ssuitepicselsecurity.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="8,144.73,656.80,129.18,7.86"><p>http://steghide.sourceforge.net/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the projects <rs type="projectName">NETDIAMOND</rs> (<rs type="grantNumber">POCI-01-0145-FEDER-016385</rs>) and <rs type="projectName">SOCA</rs> (<rs type="grantNumber">CENTRO-01-0145-FEDER-000010</rs>), co-funded by <rs type="programName">Centro 2020 program</rs>, <rs type="funder">Portugal 2020</rs>, <rs type="funder">European Union</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_RzuETuE">
					<idno type="grant-number">POCI-01-0145-FEDER-016385</idno>
					<orgName type="project" subtype="full">NETDIAMOND</orgName>
				</org>
				<org type="funded-project" xml:id="_vYxCtwS">
					<idno type="grant-number">CENTRO-01-0145-FEDER-000010</idno>
					<orgName type="project" subtype="full">SOCA</orgName>
					<orgName type="program" subtype="full">Centro 2020 program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,428.44,337.64,7.86;10,151.52,439.38,176.58,7.89" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,242.41,428.44,234.59,7.86">Shape quantization and recognition with randomized trees</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,151.52,439.40,80.65,7.86">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1545" to="1588" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,450.06,337.63,7.86;10,151.52,461.02,329.07,7.86;10,151.52,471.98,109.87,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,354.88,450.06,125.71,7.86;10,151.52,461.02,276.70,7.86">Data hiding inside jpeg images with high resistance to steganalysis using a novel technique: Dct-m3</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Attaby</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Alsammak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,436.36,461.02,44.23,7.86;10,151.52,471.98,81.19,7.86">Ain Shams Engineering Journal</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,482.62,278.40,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,205.30,482.64,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,273.90,482.64,69.14,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,493.31,337.63,7.86;10,151.52,504.26,329.07,7.86;10,151.52,515.22,142.09,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,292.85,493.31,187.74,7.86;10,151.52,504.26,57.08,7.86">An empirical comparison of supervised learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,231.24,504.26,249.36,7.86;10,151.52,515.22,30.97,7.86">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,525.89,337.64,7.86;10,151.52,536.84,154.17,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,318.84,525.89,63.12,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,405.01,525.89,75.59,7.86;10,151.52,536.84,30.97,7.86">Ensemble machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="157" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,547.51,337.63,7.86;10,151.52,558.46,329.07,7.86;10,151.52,569.42,141.30,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,193.92,547.51,286.67,7.86;10,151.52,558.46,14.98,7.86">Forensic analysis of ordered data structures on the example of jpeg files</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gloe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,185.59,558.46,295.01,7.86;10,151.52,569.42,28.85,7.86">2012 IEEE International Workshop on Information Forensics and Security (WIFS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="139" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,580.09,337.63,7.86;10,151.52,591.04,329.07,7.86;10,151.52,602.00,329.07,7.86;10,151.52,612.96,329.07,7.86;10,151.52,623.92,329.07,7.86;10,151.52,634.88,329.07,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,329.07,7.86;11,151.52,119.67,329.07,7.86;11,151.52,130.63,216.27,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,268.29,634.88,212.30,7.86;10,151.52,645.84,124.23,7.86">ImageCLEF 2019: Multimedia retrieval in medicine, lifelogging, security and nature</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,297.67,645.84,182.92,7.86;10,151.52,656.80,329.07,7.86;11,151.52,119.67,122.46,7.86">Proceedings of the 10th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="11,305.55,119.67,171.07,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09-09">2019. September 9-12 2019</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="11,142.96,141.59,337.64,7.86;11,151.52,152.52,274.73,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,269.36,141.59,211.24,7.86;11,151.52,152.55,29.48,7.86">Effect of rule weights in fuzzy rule-based classification systems</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nakashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,188.29,152.55,151.25,7.86">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="506" to="515" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,163.51,337.63,7.86;11,151.52,174.47,329.07,7.86;11,151.52,185.43,100.39,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,299.94,163.51,176.98,7.86">File type identification for digital forensics</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Papadourakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,166.15,174.47,293.83,7.86">International Conference on Advanced Information Systems Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="266" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,196.39,337.98,7.86;11,151.52,207.34,329.07,7.86;11,151.52,218.30,329.07,7.86;11,151.52,229.26,196.92,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,259.98,207.34,200.13,7.86">Overview of the ImageCLEFsecurity 2019 task</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cuevas Rodrguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/(2019" />
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,218.30,295.59,7.86">CLEF2019 Working Notes. CEUR Workshop Proceedings (CEUR-WS.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,240.22,337.97,7.86;11,151.52,251.18,329.07,7.86;11,151.52,262.14,309.33,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,351.10,240.22,129.49,7.86;11,151.52,251.18,121.33,7.86">A steganographic technique for highly compressed jpeg images</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K A</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Deris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Mohamad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,293.71,251.18,186.88,7.86;11,151.52,262.14,170.21,7.86">The Second International Conference on Informatics Engineering &amp; Information Science</title>
		<meeting><address><addrLine>ICIEIS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,273.10,337.98,7.86;11,151.52,284.03,163.87,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,222.32,273.10,220.64,7.86">Building predictive models in r using the caret package</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,450.24,273.10,30.35,7.86;11,151.52,284.06,85.68,7.86">Journal of statistical software</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,295.02,337.98,7.86;11,151.52,305.98,329.07,7.86;11,151.52,316.91,83.64,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,288.76,295.02,191.83,7.86;11,151.52,305.98,135.02,7.86">Jpeg compression steganography &amp; crypography using image-adaptation technique</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Khare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,294.12,305.98,186.47,7.86">journal of advances in information technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="141" to="145" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,327.89,337.98,7.86;11,151.52,338.83,191.64,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,275.51,327.89,205.08,7.86;11,151.52,338.85,13.93,7.86">Rule-based systems: a granular computing perspective</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gegov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cocea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,172.00,338.85,84.33,7.86">Granular Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="259" to="274" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,349.81,337.97,7.86;11,151.52,360.77,329.07,7.86;11,151.52,371.73,129.19,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,335.70,349.81,127.30,7.86">Steganpeg steganography+ jpeg</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">L</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Subramanyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,360.77,329.07,7.86;11,151.52,371.73,26.92,7.86">2011 International Conference on Ubiquitous Computing and Multimedia Applications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="42" to="48" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
