<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,221.81,115.96,171.74,12.62;1,192.74,133.89,229.89,12.62;1,234.74,151.82,145.88,12.62">Solving Life Puzzle with Visual Context-based Clustering and Habit Reference</title>
				<funder>
					<orgName type="full">Software Engineering Laboratory, University of Science, Vietnam National University -Ho Chi Minh City</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.24,189.65,81.11,8.74"><forename type="first">Trung-Hieu</forename><surname>Hoang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science</orgName>
								<orgName type="institution" key="instit2">VNU-HCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh city</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.90,189.65,73.09,8.74"><forename type="first">Mai-Khiem</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science</orgName>
								<orgName type="institution" key="instit2">VNU-HCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh city</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.55,189.65,80.81,8.74"><forename type="first">Vinh-Tiep</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Information Technology</orgName>
								<orgName type="institution" key="instit2">VNU-HCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh city</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.92,189.65,71.73,8.74"><forename type="first">Minh-Triet</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science</orgName>
								<orgName type="institution" key="instit2">VNU-HCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh city</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,221.81,115.96,171.74,12.62;1,192.74,133.89,229.89,12.62;1,234.74,151.82,145.88,12.62">Solving Life Puzzle with Visual Context-based Clustering and Habit Reference</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2E9FB6926CD584181B1B8523E08B9665</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Life puzzle</term>
					<term>Meta-data image clustering</term>
					<term>Image retrieval</term>
					<term>Bag-of-Visual-Words</term>
					<term>Root SIFT features</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Lifelogging has taken a wide range of interest from research communities due to the increasing number of wearable and personal devices. With a large amount of data collected every day, an essential task is to organize, manage, and retrieve data efficiently. Therefore, from a collection of photos, it is necessary to rearrange them in some order that may represent a meaning sequence of events in daily life. This motivates the task of Life Puzzle in ImageCLEFlifelog 2019. To solve this task, we propose a novel method to exploit personal habits in their daily routine activities. First we group images into several clusters based on the their visual similarity and extracted visual concepts. For each image cluster, we utilize our Bag-of-Visual-Words framework to query similar scenes from personal lifelog data to predict the possible time instant in a day of the cluster. Using our proposed method, we achieve the first place at Multimedia retrieval in CLEF -"Solve my life puzzle" challenge with competitive Kendall's T score up to 0.4 and the final score of 0.55.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lifelog data is a valuable source of information to provide a better understanding of people's daily activities, habits, and behaviours. Everyday, each people may, intentionally or unintentionally, create a huge amount of useful lifelog data in various formats, such as photos, video clips, audio clips, text notes, or activities logs in computers or mobile devices. Among these data format, Visual data is one of the most important and interesting sources to analyze people's daily activities.</p><p>Sometimes, visual lifelog data are provided as a collection of photos without any specific temporal order. In this case, it is important to arrange the given photos in some meaning meaningful order that reflects a reasonable sequence of daily activities. This is the motivation for the "Solve my life puzzle" challenge in the ImageCLEFlifelog 2019 <ref type="bibr" coords="2,256.49,142.90,9.96,8.74" target="#b4">[5]</ref>. In this challenge, participants are given samples of lifelog data, which are comprised of images along with metadata (i.e biometrics and GPS location), and are tasked to re-organize the given data in an ascending timeframe order and predict four categories, with respect to four timespans of a day (morning, afternoon, night, mid-night).</p><p>In the ideal case, we aim to recover the original sequence of photos corresponding to the real sequence of events that actually happen in a day of a user. However, in practice, we may not find exactly the original photo sequence but we may rearrange a collection of photos in different reasonable sequences, each of which can preserve the partial chronological order of images or image groups. It should be noticed that an image sequence which may be appropriate for one user may not be suitable for another user. One user may go shopping before going work, while another user may have a different order of these two activities/events. Therefore, we decide to exploit personal habits of a user to estimate the appropriate timespan of certain activity/event with reference to his or her personal history lifelog data. By looking into the habit of a user, i.e. the daily routines of activities that a user may perform repeatedly in many days, we may infer the most likely image sequences from different possible choices.</p><p>With the relatively discrete flow of concepts, it is challenging not only to machine learning-based models but also humans, to compare the chronological order of images. Acknowledging the nature of this shortcoming, we choose to divert our approach from processing images independently to a clustering approach. This would narrow down the discreteness to an acceptable continuity of concepts' flow, which allows groups to be sorted efficiently at the group level.</p><p>Our key idea is that two images with high similarity regarding visual and metadata information are likely to occur in the same environment at the same timespan within a day. Thus, we first cluster images into multiple groups based on the similarity of visual and metadata information. Currently, we do not propose an approach to sort images in a single group and this will be left for future improvements. After clustering all images into separate groups, information regarding the temporal positions of those groups can be further exploited by looking back to the user's history with the image similarity retrieval mechanism using our Bag-of-Visual-Words retrieval framework <ref type="bibr" coords="2,360.23,539.30,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="2,372.41,539.30,7.00,8.74">8]</ref>.</p><p>We use our propose method to solve the Life Puzzle in ImageCLEFlifelog 2019. Our method achieves the best score in three criteri: Kendall's T , part of day, and final score. However, our method still needs further improvements to evaluate the temporal relationship of photos in each single group and to subdivide a group of photos into multiple event instances.</p><p>The content of this paper is as follows. In section 2, information about Solve my Life Puzzle challenge as well as several possible approaches are discussed. Details about our approaches in this challenge are introduced in Section 3. Experimental results together with our discussions are introduced in Section 1.</p><p>Sections 5 contains our conclusions and future works in order to enhance the performance of the proposed system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Life Puzzle and Possible Approaches</head><p>To promote recent works in lifelogging problems from research groups across the world, several challenges in lifelog data retrieval had been conducted in recent years. ImageCLEFlifelog 2018 <ref type="bibr" coords="3,268.93,238.50,10.52,8.74" target="#b3">[4]</ref> which was the second edition of <ref type="bibr" coords="3,425.59,238.50,10.52,8.74" target="#b1">[2]</ref> consist of two challenge. Lifelog moment retrieval (LMRT) focuses on retrieving a specific moment in the past of a logger and daily living understanding (ADLT) aims to understand daily living in a period. From that competition, various ways to understand lifelogging data have been introduced and improved from the previous competition, with the majority of the approaches combining visual and metadata (textual, location and other information) to solve the task.</p><p>Solve my Life Puzzle challenge was first introduced in ImageCLEFlifelog 2019 <ref type="bibr" coords="3,134.77,336.93,10.52,8.74" target="#b2">[3]</ref> besides LMRT, this challenge focuses on analyzing given images along with associated metadata (e.g., biometrics, location, etc.) in a collection of images of a given day to reconstruct the correct time frame of a day and rearrange them in chronological order. To facilitate image understanding, task organizers also provides useful categories and attributes provided by Place CNN <ref type="bibr" coords="3,445.31,384.75,15.50,8.74" target="#b12">[13]</ref> and object detection results by Faster R CNN <ref type="bibr" coords="3,321.41,396.70,15.50,8.74" target="#b9">[10]</ref> trained on <ref type="bibr" coords="3,389.09,396.70,9.96,8.74" target="#b5">[6]</ref>. In this challenge, participants are given 10 queries in the test set. Each query has 25 images in a day with metadata provided. Same examples of the queries and our solutions for them are presented in Section 1.</p><p>There are several promising approaches to arrange images in reasonable sequence based on their temporal order. We can exploit the order of action/subactivity in an event/activity to sort images in one event/activity. However, this approach may be useful when photos are taken at a small enough interval, thus photos are usually from a single event/activity.</p><p>Another approach is to exploit personal habits to estimate which timespans may be appropriate for a photo. This approach is motivated by the observation that people usually repeat to perform an activity in the same context, at the same place, and at the same timespan of the day or the same day in the week, etc. As the photos in each query of the Life Puzzle of ImageCLEFlifelog 2019 are sparsely sampled in one day (25 images in a day), we decide to follow the habit-based approach.</p><p>We adopt the Bag-of-Visual-Words retrieval framework <ref type="bibr" coords="3,401.11,596.34,10.52,8.74" target="#b8">[9]</ref> to retrieve the visually similar photos in the past history of the same lifelogger, then predict the probability for a query photo to occur in a certain timespan of a day. Our idea of applying Bag-of-Visual-Words framework to retrieve useful information in the past corresponding to a new given photo was initiated in our proposal system to retrieve similar images for reminiscence <ref type="bibr" coords="3,347.84,656.12,12.78,8.74">[8]</ref>. 3 Our Proposed System</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of Proposed Solution</head><p>In this section, firstly we list some of the main problems to sort images in a reasonable temporal sequence as follows:</p><p>-(P1) Sorting images in one event/activity: it is necessary for the system to understand the meaning of that activity and the ordering of sub-actions in that activity. For instance, cooking should come after taking foods or drink out of a fridge and before eating breakfast. -(P2) Sorting images in the same scene: Images should be sorted according to the visual similarity (fine grain clustering) or location information (coarse grain clustering). If a system can only use the location information, it is difficult to distinguish different scenes in the same geographical region. For example, if a user in different rooms in the same building, we cannot organize the photos simply based on GPS information. -(P3) Sorting multiple events and actions in chronological order: the problem is how can we determine the temporal order between events and actions. In some cases, it is possible to point out the topological relationship between several pairs of events and actions, but it is extremely difficult to have a complete relationship set between every events or activities.</p><p>To solve puzzle problem for images taken at a sparse sampling rate, i.e. images are note taken at short enough time interval to belong to the same activity/event, we focus our proposed solution on the two main problems (P2) and (P3).</p><p>Figure <ref type="figure" coords="4,182.25,620.25,4.98,8.74" target="#fig_0">1</ref> illustrates the main components of our proposed system. By extracting visual features together with metadata of each query image, a clustering system can group the input images into several clusters that have the most similarity compared to others (c.f. Section 3.2). After this step, query images are processed at the group level only. A visual-based retrieval system can look up past scenarios in the history of the same lifelogger and return possible timeframes of each image. The possible timeframe of an image group is determined by the voting scheme from the possible timeframes of each image in the group (c.f. Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Images Clustering</head><p>In our first phase, with all the metadata set given for each image, we cluster all of them in a small number of image groups for each photo collection (25 images) in each query. Our assumption is that photos in an image group are usually belongs to the same scene and in the same timespan. In fact, this assumption may be violated if the lifelogger stay in the same environment (office, room, shop) multiple times, i.e. event instances, in a day. However, we do not have enough visual information and given metadata to better sub-divide a group of images based on the event instances in the same environment.</p><p>In our experiments, the number of clusters ranges from 4 to 7, which are basically based on the similarities of the rough concepts. This work can be done by utilizing special concepts and attributes from Places 365 (e.g., indoor lighting, natural light, open area, working, eating, etc., together with GPS location home, work, transport. We can also employ our visual clustering scheme <ref type="bibr" coords="5,412.32,363.22,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="5,429.48,363.22,12.73,8.74" target="#b10">11]</ref> to group images based on their visual similarity. Two examples of clustering images in the photo collection of a query are illustrated in Figure <ref type="figure" coords="5,362.00,387.13,4.98,8.74" target="#fig_1">3</ref> and Figure <ref type="figure" coords="5,421.10,387.13,3.87,8.74" target="#fig_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Image Retrieval with Bag-of-Visual-Words Retrieval Framework</head><p>After the first phase, we already split images into multiple clusters, a.k.a. image groups, each of which is expected to belong to the same environment/context. For each image in a cluster, we use our Bag-of-Visual-Words (BoVW) retrieval framework <ref type="bibr" coords="5,158.69,475.65,10.52,8.74" target="#b8">[9]</ref> and get a ranklist of most similar images from the reference database of the past history of the same lifelogger. In our experiments, we utilize the training dataset of the Lifelog Moment Retrieval task (LMRT) of ImageCLEFlifelog 2019 as the reference database.</p><p>From the retrieved ranklist corresponding to an image, we can infer the score for each timespan when the activity in the image may be appropriate to occur. We use the voting scheme with all the scores for all possible timespans of images in a photo cluster to determine the most appropriate timespan for a cluster.</p><p>We can define a timespan to cover from 1 to 2 hours, then compare the temporal order between two clusters. Finally, we sort all clusters with reference to their temporal topological order. We also use this method with 4 pre-defined timespans to determine the part of day for each cluster.</p><p>Figure <ref type="figure" coords="5,182.78,619.97,4.98,8.74">2</ref> illustrates our method to determine the timespan for an image cluster with respect to a reference database of the history of the same user.</p><p>For the implementation of the BoVW retrieval framework, we use Hessian-Affine detector <ref type="bibr" coords="5,204.21,656.12,10.52,8.74" target="#b6">[7]</ref> to detect keypoints in an image and Root SIFT descriptor Fig. <ref type="figure" coords="6,154.40,345.39,4.13,7.89">2</ref>. Our method using Image retrieval with Bag-of-Visual-Words to determine the timespan for an image cluster.</p><p>[1] to represent the local feature in the neighbor region of a keypoint. We train a large vocabulary of one million visual words by an unsupervised clustering algorithm. The code-book is trained and stored in a server for later use to find pair of most similar images. In the second state, for each cluster, representative images are processed with the same detector and descriptor. After extraction, these features are quantized according to the pre-trained codebook using a softassignment strategy where each feature is assigned to the three nearest visual words. At this time, the query image is represented as a sparse BOW vector similar to those from the gallery. This vector is then independently compared to all gallery vectors using Euclidean distances. Database images having no visual words in common are irrelevant and are, therefore, filtered out quickly using the inverted index structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Task Description</head><p>The test dataset provided by organizers consists of 10 queries. There are 25 images taken at different times of day in each query. Metadata including GPS location, Scene CNN attributes, activities, etc., are provided corresponding to each image. No timestamps are given in the metadata. The challenge is how to sort all images in each query in chronological order with given information. Beside ordering, each image must be classified in 4 main categories regarding different times of the day, including morning (4h00 AM to 11h59 AM), afternoon (12h00 PM to 4h59 PM), evening (5h00 PM to 10h59 PM), night.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Examples</head><p>Several query cases with further explanations examples will be given in this section to illustrate our method. Query ID 6: By using GPS location, Scene CNN attributes and visual features information, 25 images of the query number 6 are clustered into 4 main groups in Figure <ref type="figure" coords="7,177.83,495.23,3.87,8.74" target="#fig_1">3</ref>.</p><p>-Obviously, images were taken indoor and have a home tag in their GPS label are placed in the first group. -Images taken inside a car, with a representing of steering wheel belongs to the second group. -Images taken outdoor, with natural light belong to the third group -Images taken indoor, with office equipment like a laptop, papers, pen, etc.</p><p>are categorized in the last group</p><p>Query ID 9: Similar to query ID 6, 25 images of the query number 9 are clustered in to 5 main groups in Figure <ref type="figure" coords="7,309.16,620.25,4.98,8.74" target="#fig_2">4</ref> -Images with appearances of a car are placed into the first group, due to the dominant area compared to other concepts represented in the respective images. -Images taken inside the office have a uniform distribution of detected office supplies' concepts -Images taken on the street are characterized with high contrast and clear boundary between dark road and bright sky, with buildings. -Some images contain a grill with its related concepts (i.e beef), are grouped into this group. -Remaining images are taken at logger's home position. In order to place these image groups in a timeline, different approaches have been conducted. Together with BoW images retrieval, we observe and conclude that a normal person is likely to start a day in a bathroom or have breakfast inside a kitchen. That person then needs to travel by car to his or her office by a vehicle. After walking from the car-park and having coffee with colleges, that person then stays and have various activities inside an office building. Obviously, the person is likely to finish his day at home and watch television. Regarding the grill activities, likely scenarios have been found in the database, logger usually has this kind of activity in the afternoon.</p><p>Our system's heuristic is based on the main concepts and metadata of each image to separate them into clusters. Hence, we do not deal with images in intra-cluster order yet and focus on inter-cluster order. By looking at the main concepts of a given image, we find out that it is extremely difficult to clarify the real position of each image in the timeline. For instance, with images in the second group of query 6, it is impossible to conclude the user was driving from home to the office or going back home after a working day. Similarly, we can only assume an image taken inside the logger's home may belong to the early morning or late at night. It is almost impossible to clarify unless the system can pay its attention to special details like the lighting from windows or artificial lights are turned on inside the image given (Figure <ref type="figure" coords="9,359.81,347.39,3.87,8.74" target="#fig_3">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>The official results from challenge's organizers are given in Table <ref type="table" coords="9,430.53,423.55,3.87,8.74" target="#tab_0">1</ref>. For each team, we present their run with the highest final score. The details of submission result can be found at <ref type="bibr" coords="9,237.47,447.46,9.96,8.74" target="#b2">[3]</ref>. According to the table, our system has the highest performance among other team submissions in all three criteria: Kendall's T , part of day, and final score.</p><p>Despite having competitive results in this challenge, the system definitely needs improvements. Currently, images belong to the same group are return in ascending filename order due to the lack of taking in specific metadata types. This leaves a potential headroom for improvements, as should more data be used for optimal retrieval instead of relying on visual information only. Future approaches can solve this remaining problem by further digest in other metadata. Re-ordering lifelog images in chronological order is a challenging problem due to the various activities that can happen in the same place across multiple time frame and the limitation of visual information. Although we cannot propose a complete solution to sort every single image in this challenge, our team proposes a method which can place clustered images in order.</p><p>Our clustering method based on the similarity of visual features and metadata of given images. Sorting inter-cluster of images can be proceeded by exploiting information in the past by using Bag-of-Visual-Words with Root SIFT features which can find the most similarity images in the image database. Our work achieved the first place winner in this year challenge with this approach.</p><p>However, there are some aspects of future improvement. The overall performance of our system can be improved if the clustering system is more robust, at that time, we can try to increase the number of clusters in each query. Besides, additional metadata utilization also proves to be a potential headroom for improvement of intra-group information retrieval in similar systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,223.74,304.14,167.88,7.89;4,134.77,115.83,345.82,173.53"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of our proposed system.</figDesc><graphic coords="4,134.77,115.83,345.82,173.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,134.77,409.22,345.83,7.89;7,134.77,420.21,29.26,7.86;7,134.77,220.92,345.83,173.53"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Four clusters of query ID 6, each row consists of random images from each cluster.</figDesc><graphic coords="7,134.77,220.92,345.83,173.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,134.77,345.07,345.83,7.89;8,134.77,356.05,29.26,7.86;8,134.77,115.84,345.80,214.46"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Five clusters of query ID 9, each row consists of random images from each cluster.</figDesc><graphic coords="8,134.77,115.84,345.80,214.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,134.77,261.56,345.83,7.89;9,134.77,272.55,198.35,7.86;9,134.77,115.83,345.83,130.96"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Indoor images time-frame is predictable only by looking at special characteristics like lighting from windows or artificial lights.</figDesc><graphic coords="9,134.77,115.83,345.83,130.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,134.77,115.84,345.83,214.78"><head></head><label></label><figDesc></figDesc><graphic coords="6,134.77,115.84,345.83,214.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,153.85,582.50,297.10,77.77"><head>Table 1 .</head><label>1</label><figDesc>The official results of the Solve my life Puzzle challenge.</figDesc><table coords="9,153.85,603.29,297.10,56.99"><row><cell>Team</cell><cell>Kendall's T</cell><cell>Part of Day</cell><cell>Score</cell></row><row><cell>HCMUS</cell><cell>0.40</cell><cell>0.70</cell><cell>0.55</cell></row><row><cell>BIDAL</cell><cell>0.19</cell><cell>0.55</cell><cell>0.37</cell></row><row><cell>DAMILAB</cell><cell>0.02</cell><cell>0.47</cell><cell>0.25</cell></row><row><cell>Organiser</cell><cell>0.05</cell><cell>0.49</cell><cell>0.27</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="institution">AIOZ Pte Ltd</rs> for supporting our research team. This research is partially supported by the research funding for the <rs type="funder">Software Engineering Laboratory, University of Science, Vietnam National University -Ho Chi Minh City</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,459.26,337.64,7.86;10,151.52,470.22,329.07,7.86;10,151.52,481.18,329.07,7.86;10,151.52,492.14,313.47,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,223.29,459.26,253.74,7.86">Three things everyone should know to improve object retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2354409.2355123" />
	</analytic>
	<monogr>
		<title level="m" coord="10,166.51,470.22,314.08,7.86;10,151.52,481.18,82.09,7.86;10,305.21,481.18,40.56,7.86">Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2911" to="2918" />
		</imprint>
	</monogr>
	<note>CVPR &apos;12</note>
</biblStruct>

<biblStruct coords="10,142.96,503.17,337.63,7.86;10,151.52,514.13,329.07,7.86;10,151.52,525.08,329.07,7.86;10,151.52,536.04,254.98,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,167.90,514.13,308.16,7.86">Overview of ImageCLEFlifelog 2017: Lifelog Retrieval and Summarization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="10,168.00,525.08,296.33,7.86">CLEF2017 Working Notes. CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,547.07,337.63,7.86;10,151.52,558.03,329.07,7.86;10,151.52,568.99,329.07,7.86;10,151.52,579.95,329.07,7.86;10,151.52,590.91,62.74,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,249.22,558.03,231.37,7.86;10,151.52,568.99,121.61,7.86">Overview of ImageCLEFlifelog 2019: Solve my life puzzle and Lifelog Moment Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="10,295.72,568.99,184.87,7.86;10,151.52,579.95,96.31,7.86">CLEF2019 Working Notes. CEUR Workshop Proceedings, CEUR-WS</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12">September 09-12 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,601.93,337.64,7.86;10,151.52,612.89,329.07,7.86;10,151.52,623.85,67.45,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,442.93,601.93,37.66,7.86;10,151.52,612.89,325.51,7.86">Overview of imagecleflifelog 2018: Daily living understanding and lifelog moment retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,165.60,623.85,24.69,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,634.88,337.63,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,329.07,7.86;11,151.52,119.67,329.07,7.86;11,151.52,130.63,329.07,7.86;11,151.52,141.59,329.07,7.86;11,151.52,152.55,329.07,7.86;11,151.52,163.51,329.07,7.86;11,151.52,174.47,329.07,7.86;11,151.52,185.43,216.27,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,268.29,141.59,212.30,7.86;11,151.52,152.55,124.23,7.86">ImageCLEF 2019: Multimedia retrieval in medicine, lifelogging, security and nature</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,297.67,152.55,182.92,7.86;11,151.52,163.51,329.07,7.86;11,151.52,174.47,122.46,7.86">Proceedings of the 10th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="11,305.55,174.47,171.07,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09-09">2019. September 9-12 2019</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="11,142.96,196.39,337.64,7.86;11,151.52,207.34,329.07,7.86;11,151.52,218.28,290.27,7.89" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="11,328.62,207.34,151.96,7.86;11,151.52,218.30,28.22,7.86">Microsoft COCO: common objects in context</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<idno>CoRR abs/1405.0312</idno>
		<ptr target="http://arxiv.org/abs/1405.0312" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,229.26,337.64,7.86;11,151.52,240.20,329.07,7.89;11,151.52,251.18,9.22,7.86;11,181.62,251.18,18.43,7.86;11,220.93,251.18,24.58,7.86;11,266.39,251.18,214.20,7.86;11,151.52,262.14,203.17,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,297.01,229.26,183.58,7.86;11,151.52,240.22,35.09,7.86">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="DOI">10.1023/B:VISI.0000027790.02288.f2</idno>
		<ptr target="https://doi.org/10.1023/B:VISI.0000027790.02288" />
	</analytic>
	<monogr>
		<title level="j" coord="11,204.14,240.22,210.42,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004-10">Oct 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,273.10,337.63,7.86;11,151.52,284.06,329.07,7.86;11,151.52,295.02,329.07,7.86;11,151.52,305.98,329.07,7.86;11,151.52,316.93,166.72,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,311.09,273.10,169.49,7.86;11,151.52,284.06,181.66,7.86">Nowandthen: a social network-based photo recommendation tool supporting reminiscence</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fjeld</surname></persName>
		</author>
		<idno type="DOI">10.1145/3012709.3012738</idno>
		<ptr target="https://doi.org/10.1145/3012709.3012738" />
	</analytic>
	<monogr>
		<title level="m" coord="11,352.89,284.06,127.70,7.86;11,151.52,295.02,224.00,7.86">Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia</title>
		<meeting>the 15th International Conference on Mobile and Ubiquitous Multimedia<address><addrLine>Rovaniemi, Finland, De-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">cember 12-15, 2016. 2016</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,327.89,337.64,7.86;11,151.52,338.85,329.07,7.86;11,151.52,349.78,329.06,7.89;11,151.52,360.77,186.55,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,428.91,327.89,51.68,7.86;11,151.52,338.85,325.51,7.86">A combination of spatial pyramid and inverted index for large-scale image retrieval</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Duong</surname></persName>
		</author>
		<idno type="DOI">10.4018/IJMDEM.2015040103</idno>
		<ptr target="https://doi.org/10.4018/IJMDEM.2015040103" />
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,349.81,38.26,7.86">IJMDEM</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="37" to="51" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,371.73,337.98,7.86;11,151.52,382.69,329.07,7.86;11,151.52,393.65,329.07,7.86;11,151.52,404.61,329.07,7.86;11,151.52,415.56,209.67,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,321.05,371.73,159.55,7.86;11,151.52,382.69,194.83,7.86">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2969239.2969250" />
	</analytic>
	<monogr>
		<title level="m" coord="11,374.71,382.69,105.88,7.86;11,151.52,393.65,305.98,7.86;11,244.80,404.61,31.47,7.86">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
	<note>NIPS&apos;15</note>
</biblStruct>

<biblStruct coords="11,142.62,426.52,337.98,7.86;11,151.52,437.48,329.07,7.86;11,151.52,448.44,329.07,7.86;11,151.52,459.40,329.07,7.86;11,151.52,470.36,78.85,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,453.58,426.52,27.01,7.86;11,151.52,437.48,324.84,7.86">Lifelog moment retrieval with visual concept fusion and text-based query expansion</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Duy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vo-Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2125/paper109.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,166.58,448.44,314.01,7.86;11,151.52,459.40,14.22,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,481.32,337.98,7.86;11,151.52,492.28,329.07,7.86;11,151.52,503.24,329.07,7.86;11,151.52,514.19,329.07,7.86;11,151.52,525.15,166.72,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,367.91,481.32,112.68,7.86;11,151.52,492.28,125.58,7.86">Lifelogging retrieval based on semantic concepts fusion</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Duy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tran</surname></persName>
		</author>
		<idno type="DOI">10.1145/3210539.3210545</idno>
		<ptr target="https://doi.org/10.1145/3210539.3210545" />
	</analytic>
	<monogr>
		<title level="m" coord="11,307.70,492.28,172.89,7.86;11,151.52,503.24,243.05,7.86">Proceedings of the 2018 ACM Workshop on The Lifelog Search Challenge, LSC@ICMR 2018</title>
		<meeting>the 2018 ACM Workshop on The Lifelog Search Challenge, LSC@ICMR 2018<address><addrLine>Yokohama, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-11">June 11, 2018. 2018</date>
			<biblScope unit="page" from="24" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,536.11,337.97,7.86;11,151.52,547.07,329.07,7.86;11,151.52,558.03,111.11,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,399.52,536.11,81.07,7.86;11,151.52,547.07,145.67,7.86">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,303.98,547.07,176.62,7.86;11,151.52,558.03,82.44,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
