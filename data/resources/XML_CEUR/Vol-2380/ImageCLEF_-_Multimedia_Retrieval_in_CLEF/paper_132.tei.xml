<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.05,108.98,279.26,22.43;1,261.97,126.91,91.41,22.43">Big Data For Lifelog Moments Retrieval Improvement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,145.06,170.06,91.30,11.07"><forename type="first">Fatma</forename><forename type="middle">Ben</forename><surname>Abdallah</surname></persName>
							<email>ben.abdallah.fatma@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering School of Sfax (ENIS)</orgName>
								<orgName type="laboratory">REGIM-Lab.: REsearch Groups in Intelligent Machines</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Higher Institute of Technological Studies</orgName>
								<orgName type="institution">ISET Kairouan</orgName>
								<address>
									<postCode>3199 Raccada</postCode>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,253.25,170.06,50.29,11.07"><forename type="first">Ghada</forename><surname>Feki</surname></persName>
							<email>ghada.feki@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering School of Sfax (ENIS)</orgName>
								<orgName type="laboratory">REGIM-Lab.: REsearch Groups in Intelligent Machines</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.10,170.06,76.31,11.07"><forename type="first">Anis</forename><surname>Ben Ammar</surname></persName>
							<email>anis.ben.ammar@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering School of Sfax (ENIS)</orgName>
								<orgName type="laboratory">REGIM-Lab.: REsearch Groups in Intelligent Machines</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,420.32,170.06,49.97,11.07;1,293.12,182.02,24.65,11.07"><forename type="first">Chokri</forename><forename type="middle">Ben</forename><surname>Amar</surname></persName>
							<email>chokri.benamar@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering School of Sfax (ENIS)</orgName>
								<orgName type="laboratory">REGIM-Lab.: REsearch Groups in Intelligent Machines</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.05,108.98,279.26,22.43;1,261.97,126.91,91.41,22.43">Big Data For Lifelog Moments Retrieval Improvement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B989DC05A1A18FAD086F68467A51A85B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep-learning</term>
					<term>Transfer-learning</term>
					<term>Big Data</term>
					<term>NoSQL</term>
					<term>Lifelog</term>
					<term>Moments Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ImageCLEF lifelog Moment Retrieval Task promotes research for lifelogging retrieval by providing a benchmark with an evaluation process that allows a comparative analysis of lifelog methods, approaches and tools. In this paper, we describe our participation at the ImageCLEF lifelog LMRT 2019. Findings from our initial experiments in the LMRT sub-task in ImageCLEFlifelog2018 have motivated us to improve our deep learning-based processing for lifelog image retrieval approach using NoSQL database. The new version employs a distributed database and framework for storing and processing large volumes of data. We try to reduce user involvement during the ne-tuning phase by using the ground truth for the development dataset. We implement our architecture using Matlab, Cassandra, and Spark. The best results were given by the rst run with precision@10=0.28. This run is based on ne-tuning Googlenet with the weights freeze of the 110 rst layers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lifelogging is a concept that has emerged in recent years to translate people's interest in the daily logging of their lives. The lifelogging is intended for private use, unlike social networks which are also kinds of lifelogs. Many devices and applications are available to monitor our training, diet, health, sleep, etc. The information collected by these devices and applications is characterized by the heterogeneity and the multimodality which make the research process in this mass of data a complex and non-trivial task. Considering this context, several workshops, panels, and evaluation campaign oers research tasks to deal with the problem of retrieving, summarizing and visualizing lifelogging data. Given the huge amount of digital data, it has become necessary to develop new methods to manage and analyze them. Big Data is about nding, capturing, storing, sharing and presenting this data. To satisfy the need of heavy data processing, NoSQL is a database query language for Big Data. Several NoSQL database exist with document store (CouchDB, MongoDB, TerraStore, eXist, Virtuoso), key-value store (DynamoDB, Voldemort, Azure Table <ref type="table" coords="2,334.56,189.23,31.01,11.07">Storage</ref>, MongoDB), graph store (AllegroGraph, InniteGraph) and, tabular store (Cassandra, Hadoop / Hbase, Hypertable). Since that storing into tables allows greater ease of developpement with a SQL-like language with CQL, our choice focused on Apache Cassandra. Our research to date has focused on proposing a deep learning-based processing approach for lifelog image retrieval <ref type="bibr" coords="2,307.05,249.01,18.59,11.07">[24]</ref>. Compared to our initial approach <ref type="bibr" coords="2,134.77,260.96,9.96,11.07" target="#b2">[3]</ref>, our participation in the ImageCLEF Lifelog Moment Retrieval Task 2019 (LMRT) <ref type="bibr" coords="2,175.00,272.92,10.51,11.07" target="#b7">[8]</ref> which is part of the Conference and Labs of the Evaluation Forum (CLEF 2019) <ref type="bibr" coords="2,195.64,284.87,10.51,11.07" target="#b8">[9]</ref> has two main improvements. First, we use the ground truth of the development dataset to automatically dispatch images into categories for the ne-tuning. Second, we use Apache Cassandra a NoSQL-based database management system (DBMS) designed to handle massive amounts of data. Cassandra Query Language (CQL) only implements a subset of SQL, so we use Spark with Cassandra to operate data analytics that CQL doesn't provide. From an initial query, our approach can automatically extract from it relevant concepts based on Long-Term-Short-Memory(LSTM). After that, the retrieval phase consists in searching the extracted query concepts in the le containing the image concepts. The runs submitted in the LMRT 2019 vary in the generation of image concepts. For the rst run, we ne-tune Googlenet with the weight freeze of the rst 110 layers. For the second run, we ne-tune Googlenet without freezing. For the third run, we ne-tune Alexnet. For the fourth and fth run, we use respectively Googlenet and Alexnet to classify all the images of the test dataset. For the sixth run, we used only the textual features given by the organizers. The best results were given by the rst run with F1-measure=0.188, ranked sixth in the challenge. The remainder of this paper is divided into ve sections. In section 2, we present existing retrieval architectures using ne-tuning. In section 3, we detail our approach. Section 4 presents the experimental results of our implementation. Section 5 provides some concluding remarks and suggests future works <ref type="bibr" coords="2,134.77,555.63,6.72,13.45" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Training models to have human-like capabilities requires a lot of resources in terms of data and time. To optimize this learning, we must pool knowledge from one model to another by practicing transfer learning and especially ne-tuning. Mainly, in the case of image processing, we re-use the layers of a model that has already learned that we xed, the last layers as for it will change according to the learning data and will rene according to input data. Babenko et al. <ref type="bibr" coords="2,203.68,654.62,10.51,11.07" target="#b0">[1]</ref> have demonstrated a signicant improvement in the search performance of the neural network when it is trained on a dataset which is similar to the one encountered during the test phase. Bases of this observation, we focused our study on existing retrieval architectures using ne-tuning. Authors in <ref type="bibr" coords="3,186.20,153.36,15.50,11.07" target="#b12">[13]</ref> proposed a CNN framework for clothes image retrieval in recommendation system. The rst framework's module use Alexnet pre-trained on Imagenet for learning rich mid-level visual representations. The second one, netune the Alexnet network on clothing dataset using backpropagation. Finally, the images are retrieved via hierarchical deep search. Authors in <ref type="bibr" coords="3,422.35,201.18,15.49,11.07" target="#b13">[14]</ref> proposed to ne-tune CNN for image retrieval from a large collection of images using 3D reconstruction and siamese architecture. In <ref type="bibr" coords="3,322.71,225.10,9.96,11.07" target="#b4">[5]</ref>, the authors investigate the use of CNN-based features for food retrieval. They use the last fully connected layer of Resnet-50 as a feature extractor. The most similar approach to our lifelog image retrieval context is proposed in <ref type="bibr" coords="3,278.92,260.96,14.61,11.07" target="#b16">[17]</ref>. The authors developed a general framework to translate lifelog images into features. They choose to ne-tune VGG-16 pre-trained on ImageNet1K<ref type="foot" coords="3,253.39,283.60,3.97,7.94" target="#foot_0">3</ref> by replacing the last layer which contains 1000 neurons with 634, followed by sigmoid activation instead of softmax function. Other frameworks/systems for lifelog image retrieval were proposed in <ref type="bibr" coords="3,416.31,308.78,15.49,11.07" target="#b15">[16,</ref><ref type="bibr" coords="3,433.46,308.78,27.67,11.07">1820]</ref> and rely only on CNN and DNN pre-trained on Imagenet to extract feature. Finetuning method outperforms those use only pre-trained CNN on Imagenet1K, Places365<ref type="foot" coords="3,177.01,343.38,3.97,7.94" target="#foot_1">4</ref> or MSCOCO <ref type="foot" coords="3,240.44,343.38,3.97,7.94" target="#foot_2">5</ref> . These armations are conrmed by the experimental results conducted in section 4.</p><p>3 Proposed Approach: Big Data For Lifelog Moments Retrieval</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>We based our proposed approach on our previous participation in LMRT 2018 <ref type="bibr" coords="3,134.77,458.61,9.96,11.07" target="#b6">[7]</ref>. However, the main dierence between the two approaches is that the new version employs a distributed database and framework for storing and processing large volumes of data. Furthermore, we automate the images dispatching for the ne-tuning phase by using the ground truth for the development dataset. The ImageCLEF LMRT dataset, in addition to containing images, includes a set of metadata consisting of biometrics, historic glucose index, semantic locations visited, physical activities, attributes predicted by using the Place CNN trained on SUNattribute dataset and also trained on Place 365 dataset, the class name, the bounding box and the score of the 25 objects with the highest score in each image predicted by using Faster R-CNN <ref type="bibr" coords="3,313.81,566.21,15.49,11.07" target="#b14">[15]</ref> trained on the COCO dataset. To exploit these huge lifelog metadata description, we use CQL Query with Spark connector. From an initial query, our approach can automatically extract from its relevant concepts based on Long-Term-Short-Memory(LSTM). After that, the retrieval phase consists in searching the extracted query concepts in the le containing the image concepts. Fig. <ref type="figure" coords="4,155.75,129.45,4.98,11.07" target="#fig_0">1</ref> presents the overview of our proposed approach for lifelog moments retrieval. Our approach has ve main phases: Nevertheless, several topics do not appear in the GT. For the topic in a toyshop and seeking food in the fridge, we choose manually the images. For the topic coee time, we used the images from the imageCLEF LMRT 2018.</p><p>For the CNN parameters, we used the same setting as last participation last year <ref type="bibr" coords="4,186.74,547.66,11.84,11.07" target="#b2">[3]</ref>. In fact, we replace the last three layers of the network: a fully connected layer, a softmax layer, and a classication output layer. Besides, during the training process with 70% of the images for training and 30% for validation, we use data augmentation to prevent the network from overtting. After the training, we classify all the images from the dataset and generate CSV le containing for each image the concept with the highest score.</p><p>CQL Query: For each lifelogger u1 and u2, two tables were provided: the minute-based Query Analysis: To extract relevant concepts from the given query, we build labeled textual descriptions of queries moments. For that purpose, we used the development and the test set topics of the NTCIR-12 <ref type="bibr" coords="5,423.30,249.25,14.60,11.07" target="#b10">[11]</ref>, NTCIR-13, imageCLEF LRT 2017 <ref type="bibr" coords="5,273.60,261.20,10.50,11.07" target="#b5">[6]</ref> and imageCLEF LMRT 2018 that we have combined. We obtained a csv le which contains for each topic title, the topic description and the relevant concepts associated with the topic. We convert the concepts to numeric vectors by training a word embedding. After that, we create and train an LSTM network based on the sequences of word vectors. The concepts used in query analysis phase are the same as the one dened in ne-tuning phase.</p><p>LSTM Classication: We choose to use LSTM in our architecture to predict concepts for any given user query and not only those given by the organizers. We aim to be general and global. For example, we take the case of a lifelogger searching for the moments who shows him driving. He writes either the title or the description and the trained LSTM will return the concepts steering wheel, windshield.</p><p>Retrieval: The retrieval phase consists of matching the extracted concepts from the LSTM with the concept from the rst phase of ne-tuning. For example, with the concepts steering wheel, windshield gived from the previous LSTM classication phase, we perform a simple matching of these concepts in the CSV le generated during the rst phase. After that, we sort decreasingly the result to obtain the highest score values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results obtained</head><p>We submitted 6 runs on the LMRT subtask 2019 summarized in Table <ref type="table" coords="5,446.91,558.98,3.87,11.07" target="#tab_1">1</ref>.</p><p>The runs submitted in the LMRT 2019 vary in the generation of image concepts.</p><p>For the rst run, we ne-tune Googlenet with the weight freeze of the rst 110 layers. For the second run, we ne-tune Googlenet without freezing. For the third run, we ne-tune Alexnet. For the fourth and fth run, we use respectively Googlenet and Alexnet to classify all the images of the test dataset. For the sixth run, we used only the textual features given by the organizers. Fig. <ref type="figure" coords="5,421.44,630.71,4.98,11.07" target="#fig_2">2</ref> presents the detailed results of all teams that participated to the ImageCLEF LMRT tasks. Ocial ranking metrics is the F1-measure@10, which gives equal importance to diversity (via CR@10) and relevance (via P@10). The best team HCMUS obtained F1-measure@10=0.61 with an interactive approach <ref type="bibr" coords="6,401.52,257.29,14.61,11.07" target="#b11">[12]</ref>. For our team REGIMLAB, which proposed only automatic approach, the best results were given by the rst run with F1-measure=0.188, ranked sixth in the challenge. The results of the runs submitted to the LMRT 2019 subtask are detailed in tables 2, 3 and 4.  </p><formula xml:id="formula_0" coords="6,158.16,479.73,246.85,38.72">H C M U S Z J U T C V R B I D A L D C U A T S R E G I M L A B U P B T U C -M I -S t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis of the results</head><p>By analyzing F1-measure@10 results for each query Fig. <ref type="figure" coords="6,377.12,618.76,4.13,11.07">3</ref>, we note that a neural network that is trained on a dataset which is similar to the one encountered during the test phase demonstrated a signicant improvement in the search performance. Furthermore, ne-tuning with Googlenet with freezing the weights of Table <ref type="table" coords="7,272.28,118.14,4.13,5.89">2</ref>. Precision at X (P@X)</p><p>Cut-o P@5 P@10 P@20 P@30 P@40 P@50 RUN_1 0. F1-measure at X (F1@X)</p><p>Cut-o F1@5 F1@10 F1@20 F1@30 F1@40 F1@50 RUN_1 0.168 0.188 0. We also see that for the second topic Find any moment when u1 was driving home from the oce, the run 6 which is based on CQL overpass the best run. This is due to the consideration of the latitude and longitude of volunteer's position described in the lifelog metadata description.</p><p>Considering the precision measure in Fig. <ref type="figure" coords="7,317.59,558.98,4.40,11.07">4</ref> which assess the proportion of relevant documents found among all documents found by the system, we can notice a considerable dierence from one query to another. The accuracy depends essentially on the examples that were provided during the transfer learning. The three rst runs that are based on ne-tuning achieved a precision@10=1 for the query : Find the moment when either u1 or u2 was watching football on the TV . Besides, despite the fact that the ne-tuned images for the class coffee come from another lifelogger, we achieved a precision@10=0.7 for the query :Find the moment when u1 was having coee in a cafe . This paper presents our approach for lifelog moment retrieval at the ImageCLEF Lifelog Moment Retrieval Task 2019. The new version, compared to the previous participation at the LMRT 2018, employs a distributed database and framework for storing and processing large volumes of data. The best performance was reached by an interactive approach which incite us to include the user in the process.</p><p>The time limit and technical problems did not allow us to submit all the planned runs. So as future work, we will combine visual and textual features to improve the results. We also plan to perform neural network training on more powerful computers with more GPUs to reduce learning time. Besides, we should lter the dataset before the ne-tuning by removing uninformative and blurry images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>The research leading to these results has received funding from the Ministry of Higher Education and Scientic Research of Tunisia under the grant agreement number LR11ES48.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,248.06,402.30,119.24,10.75;4,138.15,176.45,345.84,212.99"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Proposed architecture</figDesc><graphic coords="4,138.15,176.45,345.84,212.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,401.23,479.93,24.78,21.00;6,425.26,479.90,35.78,32.81;6,297.46,521.54,34.56,5.28;6,149.18,472.29,2.88,4.80;6,144.64,457.13,7.21,4.80;6,144.64,441.97,7.21,4.80;6,144.64,426.82,7.21,4.80;6,144.64,411.66,7.21,4.80;6,144.64,396.50,7.21,4.80;6,144.64,381.35,7.21,4.80;6,144.64,366.19,7.21,4.80;6,144.64,351.03,7.21,4.80;6,443.68,373.52,13.04,4.32;6,443.68,384.64,16.67,4.32;6,443.68,395.75,15.38,4.32"><head></head><label></label><figDesc>e f a n -T a u b e r t U</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,220.67,539.93,170.94,10.75"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. ImageCLEF LMRT Ocial results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,216.87,317.60,181.63,10.75"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. F1-measure@10 scores on the test set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,213.97,654.62,266.62,11.07"><head></head><label></label><figDesc>table and the categories and concepts table. We import for each lifelogger a table in the DBMS Cassandra, then we use Scala on Spark to write CQL query. By analyzing topics in the test set, we nd that each one can be divided into 5 axes to facilitate the retrieval process : user, concept, activity, location, and irrelevance. These 5 axes can be translate to a CQL query : Select column from user table where condition. The column contains the activity, the concepts and the location. In the condition we can use NOT IN to express irrelevance, IN, CONTAINS or LIKE to express matching with concepts. The possibilities are numerous.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,147.84,113.96,319.67,95.93"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="6,147.84,113.96,319.67,95.93"><row><cell></cell><cell cols="2">. Submitted Runs</cell></row><row><cell>Run</cell><cell>Name</cell><cell>Parsing Type of information</cell></row><row><cell cols="2">RUN_1 Fine-tuning Googlenet with freeze</cell><cell>Automatic Visual</cell></row><row><cell cols="3">RUN_2 Fine-tuning Googlenet without freeze Automatic Visual</cell></row><row><cell cols="2">RUN_3 Fine-tuning with Alexnet</cell><cell>Automatic Visual</cell></row><row><cell cols="2">RUN_4 Classifying with Googlenet</cell><cell>Automatic Visual</cell></row><row><cell cols="2">RUN_5 Classifying with Alexnet</cell><cell>Automatic Visual</cell></row><row><cell cols="3">RUN_6 Baseline : CQL on organizers concepts Automatic Textual</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,196.11,147.12,223.13,224.23"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table coords="7,196.11,147.12,223.13,189.21"><row><cell>280 0.280 0.240 0.237 0.233 0.222</cell></row><row><cell>RUN_2 0.260 0.250 0.235 0.220 0.218 0.214</cell></row><row><cell>RUN_3 0.260 0.250 0.240 0.227 0.223 0.220</cell></row><row><cell>RUN_4 0.100 0.090 0.100 0.103 0.093 0.088</cell></row><row><cell>RUN_5 0.080 0.070 0.070 0.067 0.063 0.064</cell></row><row><cell>RUN_6 0.060 0.070 0.055 0.040 0.043 0.040</cell></row><row><cell>Table 3. Cluster Recall at X (CR@X)</cell></row><row><cell>Cut-o CR@5 CR@10 CR@20 CR@30 CR@40 CR@50</cell></row><row><cell>RUN_1 0.136 0.158 0.179 0.189 0.225 0.230</cell></row><row><cell>RUN_2 0.125 0.142 0.153 0.186 0.222 0.222</cell></row><row><cell>RUN_3 0.092 0.103 0.197 0.219 0.250 0.256</cell></row><row><cell>RUN_4 0.026 0.048 0.142 0.159 0.159 0.170</cell></row><row><cell>RUN_5 0.072 0.088 0.104 0.120 0.136 0.136</cell></row><row><cell>RUN_6 0.055 0.076 0.087 0.087 0.103 0.125</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,144.73,632.94,110.84,10.75"><p>http://www.image-net.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,144.73,643.90,174.90,10.75"><p>http://places2.csail.mit.edu/download.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,654.86,96.05,10.75"><p>http://cocodataset.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,167.11,314.24,313.48,10.75;9,175.68,325.20,304.92,10.75;9,175.68,336.16,304.92,10.75;9,175.68,347.12,25.59,10.75" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,342.31,325.20,138.29,10.75;9,175.68,336.16,68.50,10.75">Neural Codes for Image Retrieval Computer Vision</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Slesarev</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chigorin</surname></persName>
		</author>
		<editor>A. &amp; Lempitsky, V. Fleet</editor>
		<editor>D., Pajdla</editor>
		<editor>T., Schiele, B. &amp; Tuytelaars, T.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="584" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,358.19,313.48,10.75;9,175.68,369.15,304.91,10.75;9,175.68,380.11,304.92,10.75;9,175.68,391.07,87.91,10.75" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,425.07,358.19,55.52,10.75;9,175.68,369.15,286.84,10.75">A new model driven architecture for deep learning-based multimodal lifelog retrieval</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">B</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,175.68,380.11,264.61,10.75">poster Proceedings: International Conference WSCG, CSRN 2803</title>
		<meeting><address><addrLine>Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,402.14,313.48,10.75;9,175.68,413.10,304.91,10.75;9,175.68,424.05,140.57,10.75" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,454.87,402.14,25.72,10.75;9,175.68,413.10,241.11,10.75">Regim Lab Team at ImageCLEF Lifelog Moment Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">B</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ezzarka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,446.54,413.10,34.05,10.75;9,175.68,424.05,80.95,10.75">Working Notes of CLEF 2018</title>
		<meeting><address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,435.12,313.47,10.75;9,175.68,446.08,304.91,10.75;9,175.68,457.04,304.91,10.75;9,175.68,468.00,49.78,10.75" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,416.35,435.12,64.23,10.75;9,175.68,446.08,284.41,10.75">Multilevel Deep Learning-Based Processing for Lifelog Image Retrieval Enhancement</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">B</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,175.68,457.04,235.88,10.75">Proceedings of the IEEE International Conference SMC</title>
		<meeting>the IEEE International Conference SMC<address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1348" to="1354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,479.07,313.47,10.75;9,175.68,490.03,304.92,10.75;9,175.68,500.99,304.91,10.75;9,175.68,511.95,178.83,10.75" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,271.05,490.03,209.54,10.75;9,175.68,500.99,26.15,10.75">Learning CNN-based Features for Retrieval of Food Images</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,210.79,500.99,226.66,10.75">New Trends in Image Analysis and Processing, ICIAP</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Ciocca</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Napoletano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Schettini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Battiato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Leo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Gallo</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,523.02,313.48,10.75;9,175.68,533.98,304.91,10.75;9,175.68,544.94,204.17,10.75" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,175.68,533.98,125.61,10.75">Overview of ImageCLEFlifelog</title>
		<author>
			<persName coords=""><forename type="first">D.-T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,329.99,533.98,150.60,10.75;9,175.68,544.94,104.47,10.75">Lifelog Retrieval and Summarization CLEF2017 Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,556.01,313.48,10.75;9,175.68,566.97,304.91,10.75;9,175.68,577.93,304.92,10.75;9,175.68,588.88,18.43,10.75" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,175.68,566.97,304.91,10.75;9,175.68,577.93,117.04,10.75">Overview of ImageCLEFlifelog 2018: Daily Living Understanding and Lifelog Moment Retrieval CLEF</title>
		<author>
			<persName coords=""><forename type="first">D.-T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<ptr target="CEUR-WS.org/ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="s" coord="9,294.91,577.93,57.42,10.75">Working Notes</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,599.95,313.48,10.75;9,175.68,610.91,304.91,10.75;9,175.68,621.87,304.92,10.75;9,175.68,632.83,86.77,10.75" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,330.83,610.91,149.76,10.75;9,175.68,621.87,241.35,10.75">Overview of ImageCLEFlifelog 2019: Solve my life puzzle and Lifelog Moment Retrieval CLEF</title>
		<author>
			<persName coords=""><forename type="first">D.-T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V.-T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="s" coord="9,419.09,621.87,57.27,10.75">Working Notes</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,167.11,643.90,313.48,10.75;9,175.68,654.86,304.91,10.75;10,175.68,117.74,304.92,10.75;10,175.68,128.70,304.91,10.75;10,175.68,139.65,304.91,10.75;10,175.68,150.61,304.91,10.75;10,175.68,161.57,304.92,10.75;10,175.68,172.53,304.91,10.75;10,175.68,183.49,279.90,10.75" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,175.68,161.57,304.92,10.75;10,175.68,172.53,304.91,10.75;10,175.68,183.49,34.57,10.75">ImageCLEF 2019: Multimedia Retrieval in Medicine, Lifelogging, Security and Nature Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D.-T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,217.16,183.49,168.89,10.75">LNCS Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,194.45,313.82,10.75;10,175.68,205.41,304.92,10.75;10,175.68,216.37,263.01,10.75" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,246.05,205.41,152.37,10.75">Overview of NTCIR-13 Lifelog-2 Task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T D</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,405.92,205.41,74.67,10.75;10,175.68,216.37,172.14,10.75">Proceedings of the Thirteenth NTCIR conference (NTCIR-13)</title>
		<meeting>the Thirteenth NTCIR conference (NTCIR-13)<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,227.33,313.82,10.75;10,175.68,238.28,304.91,10.75;10,175.68,249.24,289.92,10.75" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,175.68,238.28,145.00,10.75">Overview of NTCIR-12 Lifelog Task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,328.26,238.28,152.33,10.75;10,175.68,249.24,229.90,10.75">Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 12th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,260.20,313.82,10.75;10,175.68,271.16,304.91,10.75;10,175.68,282.12,304.91,10.75;10,175.68,293.08,157.43,10.75" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,336.47,271.16,144.12,10.75;10,175.68,282.12,17.24,10.75">HCMUS at the NTCIR-14 Lifelog-3 Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Duy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vo-Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,199.95,282.12,280.64,10.75;10,175.68,293.08,97.41,10.75">Proceedings of the 14th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 14th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,304.04,313.82,10.75;10,175.68,315.00,304.91,10.75;10,175.68,325.96,304.91,10.75;10,175.68,336.91,144.50,10.75" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,427.16,304.04,53.44,10.75;10,175.68,315.00,304.91,10.75">Rapid Clothing Retrieval via Deep Learning of Binary Codes and Hierarchical Search</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,175.68,325.96,304.91,10.75;10,175.68,336.91,34.92,10.75">Proceedings of the 5th ACM on International Conference on Multimedia Retrieval</title>
		<meeting>the 5th ACM on International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="499" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,347.87,313.82,10.75;10,175.68,358.83,304.92,10.75;10,175.68,369.79,304.91,10.75;10,175.68,380.75,145.55,10.75" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,253.96,358.83,226.63,10.75;10,175.68,369.79,206.19,10.75">CNN Image Retrieval Learns from BoW : Unsupervised Fine-Tuning with Hard Examples Computer Vision</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,388.97,369.79,23.24,10.75">ECCV</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,391.71,313.82,10.75;10,175.68,402.67,304.91,10.75;10,175.68,413.63,126.71,10.75" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,337.08,391.71,143.51,10.75;10,175.68,402.67,304.91,10.75;10,175.68,413.63,73.87,10.75">Faster r-cnn: Towards real-time object detection with region proposal networks Advances in neural information processing systems</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,424.59,313.82,10.75;10,175.68,435.54,304.91,10.75;10,175.68,446.50,52.85,10.75" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,386.60,424.59,93.99,10.75;10,175.68,435.54,131.38,10.75">LIG-MRIM at NTCIR-12 Lifelog Semantic Access Task</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Safadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Qunot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Chevallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,327.37,435.54,118.05,10.75">The 12th NTCIR Conference</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,457.46,313.82,10.75;10,175.68,468.42,304.91,10.75;10,175.68,479.38,304.91,10.75;10,175.68,490.34,25.59,10.75" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,269.02,468.42,211.57,10.75;10,175.68,479.38,46.47,10.75">VCI2R at the NTCIR-13 Lifelog-2 Lifelog Semantic Access Task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Del Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Subbaraju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,246.51,479.38,171.98,10.75">Thirteenth NTCIR conference (NTCIR-13)</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,501.30,313.82,10.75;10,175.68,512.26,304.91,10.75;10,175.68,523.22,168.68,10.75" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,285.43,501.30,195.16,10.75;10,175.68,512.26,47.81,10.75">VTIR at the NTCIR-12 2016 Lifelog Semantic Access Task</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,244.99,512.26,235.60,10.75;10,175.68,523.22,78.47,10.75">The 12th NTCIR Conference, Evaluation of Information Access Technologies</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,534.18,313.82,10.75;10,175.68,545.13,304.92,10.75;10,175.68,556.09,100.44,10.75" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,175.68,545.13,203.54,10.75">Pbg at the ntcir-13 lifelog-2 lat, lsat, and lest tasks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Nishimura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Akagi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Takimoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Toda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,385.92,545.13,94.68,10.75;10,175.68,556.09,7.85,10.75">Proceedings of NTCIR-13</title>
		<meeting>NTCIR-13<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,166.77,567.05,313.82,10.75;10,175.68,578.01,304.92,10.75;10,175.68,588.97,304.91,10.75;10,175.68,599.93,171.62,10.75" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,466.75,567.05,13.84,10.75;10,175.68,578.01,304.92,10.75;10,175.68,588.97,115.43,10.75">Organizer Team at ImageCLEFlifelog 2017: Baseline Approaches for Lifelog Retrieval and Summarization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,314.74,588.97,165.85,10.75;10,175.68,599.93,71.58,10.75">CLEF2017 Working Notes (CEUR Workshop Proceedings)</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
