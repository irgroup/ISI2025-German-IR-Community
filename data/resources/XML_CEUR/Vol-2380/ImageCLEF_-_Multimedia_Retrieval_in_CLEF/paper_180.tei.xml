<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,126.84,152.95,335.81,12.33;1,465.84,150.91,2.25,8.26">AI600 Lab at ImageCLEF 2019 Concept Detection Task </title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,232.92,192.13,49.18,8.75"><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
							<email>iwangxinyi@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of International Trade and Economics</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.66,192.13,54.18,8.75"><forename type="first">Ningning</forename><surname>Liu</surname></persName>
							<email>ningning.liu@uibe.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology and Management</orgName>
								<orgName type="institution">University of International Business and Economics</orgName>
								<address>
									<postCode>100029</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,126.84,152.95,335.81,12.33;1,465.84,150.91,2.25,8.26">AI600 Lab at ImageCLEF 2019 Concept Detection Task </title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3CA16B0354E7FBDF5024473B9201C7C5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Concept Detection</term>
					<term>Bag of Visual Words</term>
					<term>Logistic Regression</term>
					<term>Im-ageCLEF 2 Experiments 2.1 Data description</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the participation of AI600 Lab in the Im-ageCLEF 2019 Concept Detection task. We adopted an approach based on bagof-visual-words model and logistic regression, using different SIFT descriptors as visual features. The classifiers were trained with different features respectively and weighted results were presented. Our best result ranked 26 th among 58 runs and 7 th out of 11 participant teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the previous ImageCLEF medical tasks, a lot of remarkable works have been proposed. While traditional methods and features were used <ref type="bibr" coords="1,368.51,455.17,7.51,8.75" target="#b0">[1]</ref><ref type="bibr" coords="1,376.02,455.17,3.76,8.75" target="#b1">[2]</ref><ref type="bibr" coords="1,379.78,455.17,7.51,8.75" target="#b2">[3]</ref>, methods based on deep learning were also introduced <ref type="bibr" coords="1,269.96,467.17,7.54,8.75" target="#b2">[3]</ref><ref type="bibr" coords="1,281.26,467.17,7.54,8.75" target="#b3">[4]</ref>. In this year, ImageCLEF 2019 <ref type="bibr" coords="1,422.77,467.17,11.58,8.75" target="#b4">[5]</ref> Concept Detection task <ref type="bibr" coords="1,184.51,479.17,11.78,8.75" target="#b5">[6]</ref> aims on interpreting and summarizing the insight of radiology medical images automatically. For this task, we focused on multi-label classification with traditional visual features. The remainder of this paper is organized as follows: Section 2 introduces the detailed process of our experiment. Section 3 summarizes all of our submissions. Finally, in Section 4, we make a brief conclusion of our results. tained 56,629, 14,157 and 10,000 radiology images. The training and validation sets were accompanied by UMLS concepts extracted from the original image caption. No external data were used in our participation.</p><p>The training and validation sets were labeled with a total of 5,528 different concepts. We obtained the frequency distribution of all concepts. The distribution is showed in Table <ref type="table" coords="2,193.57,210.61,3.78,8.75" target="#tab_0">1</ref>. Most of the concepts rarely appeared in the dataset. Only 58 of the 5,528 concepts were labeled with for more than 1000 times. Some major concepts appeared frequently in the image set while most concepts were difficult to detect. Besides, we noticed that many labels are linked and correlated. For instance, images labeled with Concept B in Table <ref type="table" coords="2,274.58,372.13,4.98,8.75" target="#tab_1">2</ref> were always labeled with Concept A. Among the concepts which were annotated with for more than 100 times in the training set, there were 157 pairs of concepts with strict inclusion relation. This relation was used for detecting some minor concepts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual features and Bag-of-Visual-Words model</head><p>We employed 4 kinds of SIFT descriptors as visual features: SIFT <ref type="bibr" coords="2,404.39,583.09,10.68,8.75" target="#b7">[8]</ref>, C-SIFT <ref type="bibr" coords="2,456.34,583.09,10.70,8.75" target="#b8">[9]</ref>, HSV-SIFT <ref type="bibr" coords="2,171.12,595.09,16.76,8.75" target="#b9">[10]</ref> and RGB-SIFT. A series of key points of all kinds of descriptors were extracted from each image. To build a bag-of-visual-words (BoVW) model, 2 million key points were randomly selected from the training set as the template key points of visual codebooks. To overcome the memory limitation, we calculated visual codebooks using mini batch k-means <ref type="bibr" coords="2,257.05,643.09,15.46,8.75" target="#b10">[11]</ref>, a variant of k-means algorithm. Compared to kmeans algorithm, mini batch k-means can reduce the amount of computation and work faster. We tried various codebook sizes, or numbers of cluster centroids, and eventually used two different sizes: k = 10,000 and k = 20,000.</p><p>For all images, histograms of features were calculated with different codebooks. Each extracted key point in an image was assigned to its closest clustering in the codebook by calculating the Euclidean distance to the cluster centroids. Then the frequency of different clusters was calculated as the representations of images.</p><p>Finally, the Term Frequency -Inverse Document Frequency (tf-idf) weights of visual words frequency matrices were calculated and normalized by the L1-norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classification</head><p>We employed a two-round classification. As the distribution of concepts was unbalanced, we dropped most of the concepts and only considered major concepts which appeared in the training set more than a frequency threshold, F. F ranged from 800 to 1,500. After the first stage of classification, the matrices fed into the model were augmented with ground truth or predicted values of the appearances of major labels, then some minor concepts which were subsets of the concepts predicted and appeared more than 100 times were predicted. This improved the performance of the model slightly.</p><p>We applied logistic regression as we deemed it a competitive and faster method of classification compared to support vector machine or k-Nearest Neighbor cluster. For this multi-label classification task, we trained classifiers for each concept separately. Each time we only used one feature for training and prediction. The final submissions were generated from the probabilistic results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Experimental environment</head><p>Our experiment was conducted under Ubuntu 18.04 operating system with Python 2.7.15. The mini batch k-means clustering and logistic regression algorithm were implemented using scikit-learn library <ref type="bibr" coords="3,295.82,478.69,15.40,8.75" target="#b11">[12]</ref>. Some necessary libraries, such as NumPy, Pandas and SciPy were also used. All SIFT visual features were extracted with ColorDescriptor software (version 4.0) <ref type="bibr" coords="3,302.97,502.69,15.38,8.75" target="#b12">[13]</ref>.</p><p>3 Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The submitted runs</head><p>We submitted 7 runs to ImageCLEF 2019 concept detection task, with 1 run of single feature model and 6 runs of ensemble models. For the ensemble model we weighted the results of single feature model. The weights of [SIFT, C-SIFT, HSV-SIFT, RGB-SIFT] were [0.3, 0.2, 0.2, 0.3]. For the probability threshold p, we proposed a method for optimal threshold selection. The probability threshold we used made the concept distribution of the results on test set similar to the concept distribution of best predictions on validation set which had higher F1-scores <ref type="bibr" coords="3,334.22,651.61,15.40,8.75" target="#b13">[14]</ref>. We picked a few thresholds in a small range. The details of submitted runs are as follows. 1557059794, except that the size of visual codebook k = 20,000. 4. ai600_result_weighing_1557062212: the same as the ai600_result_weighing_ 1557059794, except that the frequency threshold F = 1,000. In total, 58 major concepts, as well as 25 minor concepts were used and predicted. 5. ai600_result_weighing_1557062494: the same as the ai600_result_weighing_ 1557059794, except that the probability threshold p = 0.1. 6. ai600_result_weighing_1557107054: the same as the ai600_result_weighing_ 1557059794, except that the frequency threshold F = 1,500. In total, 35 major concepts, as well as 8 minor concepts were used and predicted. 7. ai600_result_weighing_1557107838: the same as the ai600_result_weighing_ 1557059794, except that the frequency threshold F = 1,000 and the probability threshold p = 0.1. In total, 58 major concepts, as well as 25 minor concepts were used and predicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>The results obtained by our 7 runs are given in Table <ref type="table" coords="4,345.82,464.65,3.78,8.75" target="#tab_2">3</ref>. All 7 runs were graded successfully. The best result of our runs scored a F1-score of 0.1656, which ranked 26 th out of 58 runs and 7 th out of 11 teams. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper we have presented the methods we have used in the ImageCLEF 2019 Concept Detection task. We applied multi-label classification based on bag-of-visualwords model with color descriptors and logistic regression. From our experimental results we can conclude the following: (i) while RGB-SIFT descriptors performed best among the color descriptors, the weighted model improved the performance greatly; (ii) using the semantic relations among the concepts, the two-stage classification is able to detect some concepts which are small in number, and on the validation set it can improve the F1-score for about 1%; (iii) with the approach we proposed, it is still challenging to predict concepts with a very limited number of image samples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,136.08,162.61,334.53,8.75;4,154.08,174.61,316.54,8.75;4,154.08,186.61,316.67,8.75;4,154.08,198.61,155.35,8.75;4,136.08,210.61,334.57,8.75;4,154.08,222.61,316.53,8.75;4,154.08,234.61,316.57,8.75;4,154.08,246.61,266.04,8.75;4,136.08,258.61,334.47,8.75"><head>1 .</head><label>1</label><figDesc>ai600_result_rgb_1556989393: single feature model based on RGB-SIFT. The size of visual codebook k = 10,000. The frequency threshold F = 1,200, with 46 major concepts and 14 minor concepts used for training and prediction. The probability threshold p = 0.1. 2. ai600_result_weighing_1557059794: the combination of SIFT, C-SIFT, HSV-SIFT and RGB-SIFT. The size of visual codebook k = 10,000. The frequency threshold F = 1,200, with 46 major concepts and 14 minor concepts used for training and prediction. The probability threshold p = 0.2. 3. ai600_result_weighing_1557061479: the same as the ai600_result_weighing_</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,187.32,258.52,221.03,85.39"><head>Table 1 .</head><label>1</label><figDesc>Frequency statistics of the concepts in training set</figDesc><table coords="2,187.32,276.61,221.03,67.31"><row><cell>Frequency</cell><cell>Number</cell><cell>Proportion</cell></row><row><cell>0-10</cell><cell>3718</cell><cell>67.26%</cell></row><row><cell>10-100</cell><cell>1261</cell><cell>22.81%</cell></row><row><cell>100-1000</cell><cell>491</cell><cell>8.88%</cell></row><row><cell>&gt;=1000</cell><cell>58</cell><cell>1.05%</cell></row><row><cell>Total</cell><cell>5528</cell><cell>100.00%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,124.68,432.04,332.97,96.79"><head>Table 2 .</head><label>2</label><figDesc>Examples</figDesc><table coords="2,124.68,432.04,332.97,96.79"><row><cell cols="4">of concept pairs of Concept B(subset)-Concept A(superset)</cell></row><row><cell>Concept B</cell><cell>Freq.</cell><cell>Concept A</cell><cell>Freq.</cell></row><row><cell cols="3">C0729233: dsct of thoracic aorta 843 C0817096: thoracics</cell><cell>7470</cell></row><row><cell>C3244306: operations</cell><cell cols="2">248 C0543467: surgically</cell><cell>1386</cell></row><row><cell>C0175676: echotomography</cell><cell cols="3">925 C0041618: medical sonography 3257</cell></row><row><cell>C0392148: presences</cell><cell cols="2">783 C0150312: found</cell><cell>1354</cell></row><row><cell>C0203379: 4d echocardiogr</cell><cell cols="2">734 C0183129: echocardiographs</cell><cell>1495</cell></row><row><cell>……</cell><cell>……</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,140.64,512.56,307.13,108.31"><head>Table 3 .</head><label>3</label><figDesc>The results of submitted runs.</figDesc><table coords="4,140.64,530.65,307.13,90.23"><row><cell>Submission Id</cell><cell>Run</cell><cell>F1-Score</cell></row><row><cell>27071</cell><cell>ai600_result_rgb_1556989393</cell><cell>0.1345022</cell></row><row><cell>27074</cell><cell>ai600_result_weighing_1557059794</cell><cell>0.1628424</cell></row><row><cell>27075</cell><cell>ai600_result_weighing_1557061479</cell><cell>0.1656261</cell></row><row><cell>27076</cell><cell>ai600_result_weighing_1557062212</cell><cell>0.1588862</cell></row><row><cell>27077</cell><cell>ai600_result_weighing_1557062494</cell><cell>0.1562828</cell></row><row><cell>27095</cell><cell>ai600_result_weighing_1557107054</cell><cell>0.1603341</cell></row><row><cell>27096</cell><cell>ai600_result_weighing_1557107838</cell><cell>0.1511505</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,132.66,330.52,337.97,7.90;5,141.72,341.56,104.64,7.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,260.90,330.52,180.85,7.90">IPL at ImageCLEF 2017 Concept Detection Task</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Valavanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Stathopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,448.64,330.52,21.99,7.90;5,141.72,341.56,49.91,7.90">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,352.48,337.95,7.90;5,141.72,363.52,185.16,7.90" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,262.70,352.48,207.91,7.90;5,141.72,363.52,49.87,7.90">IPL at ImageCLEF 2018: A kNN-based Concept Detection Approach</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Valavanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kalamboukis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,198.12,363.52,74.04,7.90">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,374.56,337.89,7.90;5,141.72,385.48,328.86,7.90;5,141.72,396.52,48.84,7.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,217.67,374.56,252.87,7.90;5,141.72,385.48,214.50,7.90">Feature Learning with Adversarial Networks for Concept Detection in Medical Images: UA.PT Bioinformatics at ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pinho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="5,387.00,385.48,83.58,7.90;5,141.72,396.52,21.00,7.90">CLEF working notes, CEUR</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,407.56,337.90,7.90;5,141.72,418.48,249.14,7.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,276.97,407.56,193.59,7.90;5,141.72,418.48,114.06,7.90">ImageSem at ImageCLEF 2018 Caption Task: Image Retrieval and Transfer Learning</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,261.98,418.48,74.15,7.90">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,429.52,337.92,7.90;5,141.72,440.56,328.89,7.90;5,141.72,451.48,328.91,7.90;5,141.72,462.52,329.11,7.90;5,141.72,473.56,328.76,7.90;5,141.72,484.48,329.04,7.90;5,141.72,496.24,328.92,7.90;5,141.72,507.16,328.87,7.90;5,141.72,518.20,214.09,7.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,426.13,473.56,44.35,7.90;5,141.72,484.48,279.74,7.90">ImageCLEF 2019: Multimedia Retrieval in Medicine, Lifelogging, Security and Nature</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,443.77,484.48,26.99,7.90;5,141.72,496.24,328.92,7.90;5,141.72,507.16,242.20,7.90">Proceedings of the Tenth International Conference of the CLEF Association (CLEF 2019)</title>
		<title level="s" coord="5,141.72,518.20,152.25,7.90">LNCS Lecture Notes in Computer Science</title>
		<meeting>the Tenth International Conference of the CLEF Association (CLEF 2019)<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="5,132.66,529.24,337.79,7.90;5,141.72,540.16,292.80,7.90" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,386.13,529.24,84.32,7.90;5,141.72,540.16,157.70,7.90">Overview of the Im-ageCLEFmed 2019 Concept Detection Task</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,305.67,540.16,74.19,7.90">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,551.20,338.12,7.90;5,141.72,562.24,328.87,7.90;5,141.72,573.16,328.82,7.90;5,141.72,584.20,328.90,7.90;5,141.72,595.24,82.55,7.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,369.93,551.20,100.85,7.90;5,141.72,562.24,162.05,7.90">Radiology Objects in COntext (ROCO): A Multimodal Image Dataset</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Nensa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,311.03,562.24,159.56,7.90;5,141.72,573.16,328.82,7.90;5,141.72,584.20,55.85,7.90">Proceedings of the MICCAI Workshop on Large-scale Annotation of Biomedical data and Expert Label Synthesis (MICCAI LABELS 2018)</title>
		<title level="s" coord="5,203.80,584.20,155.32,7.90">Lecture Notes in Computer Science (LNCS</title>
		<meeting>the MICCAI Workshop on Large-scale Annotation of Biomedical data and Expert Label Synthesis (MICCAI LABELS 2018)</meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11043</biblScope>
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,606.16,338.15,7.90;5,141.72,617.08,209.34,7.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,189.71,606.16,207.45,7.90">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,403.60,606.16,67.21,7.90;5,141.72,617.08,83.78,7.90">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.66,628.84,337.97,7.90;5,141.72,639.88,256.80,7.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,283.21,628.84,183.99,7.90">Performance evaluation of local color invariants</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">D</forename><surname>Burghouts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,141.72,639.88,155.84,7.90">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="48" to="62" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.36,650.92,338.21,7.90;5,141.72,661.84,328.95,7.90;5,141.72,672.88,151.89,7.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,295.17,650.92,175.40,7.90;5,141.72,661.84,101.62,7.90">Scene classifification using a hybrid generative/discriminative approach</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Muoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,250.23,661.84,220.44,7.90;5,141.72,672.88,19.26,7.90">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="712" to="727" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.36,150.52,338.18,7.90;6,141.72,161.56,328.90,7.90" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,188.16,150.52,108.76,7.90">Web-scale k-means clustering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,303.23,150.52,167.31,7.90;6,141.72,161.56,91.45,7.90;6,298.81,161.56,38.24,7.90">Proceedings of the 19th International Conference on World Wide Web</title>
		<meeting>the 19th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1177" to="1178" />
		</imprint>
	</monogr>
	<note>WWW &apos;10</note>
</biblStruct>

<biblStruct coords="6,132.36,172.48,338.39,7.90;6,141.72,183.52,328.89,7.90;6,141.72,194.56,328.87,7.90;6,141.72,205.48,205.82,7.90" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,290.62,194.56,147.01,7.90">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,444.23,194.56,26.36,7.90;6,141.72,205.48,111.13,7.90">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.36,216.52,338.23,7.90;6,141.72,227.56,328.74,7.90;6,141.72,238.48,132.77,7.90" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,325.94,216.52,144.66,7.90;6,141.72,227.56,82.47,7.90">Evaluating Color Descriptors for Object and Scene Recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,230.75,227.56,236.28,7.90">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.36,249.52,338.18,7.90;6,141.72,260.56,328.88,7.90;6,141.72,271.48,48.84,7.90" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,156.52,260.56,224.95,7.90">LIRIS-Imagine at ImageCLEF 2012 Photo Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandréa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bichot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Tellez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,389.37,260.56,77.68,7.90">CLEF working notes</title>
		<imprint>
			<publisher>CEUR</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
