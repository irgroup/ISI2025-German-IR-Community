<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.88,152.65,333.84,12.64;1,147.60,170.65,314.22,12.64;1,254.16,188.65,101.22,12.64">ImageCLEF 2019: A 2D Convolutional Neural Network Approach for Severity Scoring of Lung Tuberculosis using CT Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,256.80,227.56,55.54,8.96"><forename type="first">Nandhinee</forename><surname>Pr</surname></persName>
							<email>nandhinee16066@cse.ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<postCode>-603110</postCode>
									<settlement>Kalavakkam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.16,227.56,66.82,8.96"><forename type="first">Jahnavi</forename><surname>Srividya</surname></persName>
							<email>jahnavisrividya17061@cse.ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<postCode>-603110</postCode>
									<settlement>Kalavakkam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.88,152.65,333.84,12.64;1,147.60,170.65,314.22,12.64;1,254.16,188.65,101.22,12.64">ImageCLEF 2019: A 2D Convolutional Neural Network Approach for Severity Scoring of Lung Tuberculosis using CT Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61CFF61A856646C1A796C5B77805A5B5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Severity scoring</term>
					<term>Lung tuberculosis</term>
					<term>Pre-processing</term>
					<term>Lung-mask</term>
					<term>CNN</term>
					<term>AUC</term>
					<term>Accuracy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tuberculosis (TB) is an air-borne disease, which affects the lungs and often spreads through sputum. According to the report of World Health Organization 9 million people world-wide are affected with TB. Tuberculosis can be cured easily when diagnosed in its early stage and with accurate CT Analysis. As an effort to form a technical forum for effective analysis and diagnosis, ImageCLEF released the Tuberculosis 2019 tasks, each dealing with one aspect of understanding and tackling the disease. We have taken up one sub-task that aims at assessing the severity of the tuberculosis disease as low or high. The task is implemented using a deep neural network approach using 2-D Convolutional Neural Network (CNN) with appropriate preprocessing. The CT volumes are segmented with the provided masks and further pre-processed with the aid of med2image, a python utility to obtain slices of CT scans, prior to training the model. The best run of the proposed CNN model resulted with an accuracy of 0.607 and an AUC of 0.626. The achieved result is placed 9 th in the overall leaderboard of the ImageCLEF 2019 Tuberculosis challenge for severity scoring .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tuberculosis (TB) is an airborne disease that affects the lungs. Often spread through sputum, cough and infected droplets, it is quite widespread affecting about 9 million world-wide. The treatment depends upon the degree of infection, i.e the severity <ref type="bibr" coords="1,460.56,573.16,10.69,8.96">[1]</ref>.</p><p>The severity evaluation has been executed by medical practitioners via a diverse set of devices including mycobacterial culture test, pleural fluid and cerebrospinal fluid analysis, lesion patterns obtained from radiological images of lungs besides individualistic factors such as the patient's age, prior treatment etc. Computed Tomography (CT) is widely used for analysis of the lesion patterns. Besides being prone to errors, a manual approach can prove to be costly, both in terms of capital and time. A computerized method, on the other hand upholds time efficiency and precision. In this paper, a Convolutional Neural Network (CNN) approach for severity scoring of lung tuberculosis based on CT scans is discussed with results. This work is a subtask of the tuberculosis tasks of ImageCLEF 2019 <ref type="bibr" coords="2,313.08,198.16,10.89,8.96" target="#b0">[2,</ref><ref type="bibr" coords="2,327.36,198.16,7.18,8.96" target="#b5">8]</ref>. This work establishes a standard scale against which evaluation of the CT in subject can be done for determining the severity.</p><p>The sections span across following: Section 1 gives a brief introduction about the importance of this problem and the necessity to find the severity of tuberculosis. Section 2 gives a glimpse of the dataset and how it is spread across the two classes and Section 2.1 details about the data preprocessing procedures. Section 3 explains the proposed model using convolutional neural network with the parameters chosen for analysis. In Section 4, the results of various runs are discussed. Finally, Section 5 concludes this paperwork and looks into the futuristic aspects for further improvisation of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>In this edition of ImageCLEF 2019 TB tasks, the dataset contains 335 chest CT scans of TB patients along with a set of clinically relevant metadata, where data of 218 patients are used for training and 117 for testing. For all patients, 3D CT images are stored in the compressed NIFTI (Neuroimaging Informatics Technology Initiative) file format with a slice size of 512Ã—512 pixels and the number of slices varies from 50 to 400 for each patient. This file format stores raw voxel intensities in Hounsfield Units (HU) as well the corresponding image metadata like image dimensions, voxel size in physical units, slice thickness, etc. The selected metadata includes the following binary measures: disability, relapse, symptoms of TB, comorbidity, bacillary, drug resistance, higher education, ex-prisoner, alcoholic, smoking and severity score ranges from 1 to 5 assigned by medical doctors. To treat this task as a binary classification problem, the severity scores are grouped as high severity with scores 1, 2 and 3, and low severity with scores 4 and 5. Moreover, for all patients automatic extracted masks of the lungs are provided. In Table <ref type="table" coords="2,408.72,524.08,3.76,8.96" target="#tab_0">1</ref>, the number of patients of each severity class in the training set and the number of patients in test set is given <ref type="bibr" coords="2,182.04,547.24,10.69,8.96" target="#b0">[2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Total patients 218</head><p>From the given dataset, sample images of type "high severity" class and "low severity" class is shown in Figure <ref type="figure" coords="2,263.52,670.24,4.98,8.96" target="#fig_0">1</ref> and<ref type="figure" coords="2,288.48,670.24,3.76,8.96" target="#fig_1">2</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Preprocessing</head><p>The dataset for the TB tasks are given in compressed NIfTI (Neuroimaging Informatics Technology Initiative) format. Initially, the file is decompressed and the slices were extracted using med2image, a Python utility. For each Nifti image we obtain a certain number of slices ranging from 50 to 400 jpeg images. The lung masks provided by the organizers are used, to avoid potential confusion resulting from identification of similar structures resembling lungs in other parts of CT images. The next step involves masking the images. The given masks are converted to grayscale format and each pixel is checked individually; if the pixel is not black it is converted to white. In this way, a final mask is created, with pixels of two values such as black (0) or white (255). Now the original scan of the lung is converted to grayscale and each pixel of it is multiplied with the corresponding pixel in the created final mask using bitwise and operation. Thus, the lungs are segmented from the original scans <ref type="bibr" coords="3,134.64,665.20,10.69,8.96" target="#b2">[4]</ref>. On the other hand, not all slices necessarily contain relevant information that can be useful to identify severity of TB. For the same reason, it is essential to filter slices to preserve only those that can be informative and contain relevant information. Upon visual inspection, slices ranging between 55 and 85 are used and other slices were eliminated from further processing. The slices being ordered, the 31 most informative usually fall at the center of the list. The workflow of the preprocessing stages is given in Figure <ref type="figure" coords="4,279.48,198.16,3.76,8.96" target="#fig_2">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Convolutional Neural network takes an image as input, passes it through a series of convolutional layers, nonlinear activation layers, pooling (downsampling) and a fully connected layer to output the classification labels. It differs from normal neural network in two aspects: atleast one convolutional layer and filters. The model for TB severity scoring is created using 2-D convolutional neural network using software libraries Keras <ref type="bibr" coords="4,195.96,506.08,11.71,8.96" target="#b3">[5]</ref> with Tensorflow [6] for backend. The 3D images of the procured CT scans are sliced and converted to 2D images in the preprocessing stage. The network is designed with three 2D convolution layers, rectified linear unit (ReLU) activation function and each convolution layer followed the max pooling layer. These led to a complete layer structure which is connected to 1000 outputs with weight by the dense layer with ReLU activation. Finally, these activations run through a softmax layer, which output a tensor of size 2, for each category.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>The CNN model is trained by varying the hyperparameters such as epochs and optimizer loss type as binary cross entropy. changing the epoch value and the optimizer ferent runs of CNN model by varying the hyperparameters is given in Table <ref type="table" coords="5,177.96,471.09,27.52,8.10">Table 2</ref>   The result of submitted four runs are listed in Table <ref type="table" coords="6,357.00,610.96,4.98,8.96" target="#tab_2">3</ref> test dataset with necessary parameters. as similar to training and validation, for all 117 patients. The probability of high severity for each patient is calculated from the average of "probability of high" of all 31 slices of the specific patient. For example, the class pr in testing, for slice number 60 is represented as having low severity and "1." is the probability of having high severity. We find the The result of submitted four runs are listed in Table <ref type="table" coords="6,357.00,610.96,3.76,8.96" target="#tab_2">3</ref>, for training, validation and test dataset with necessary parameters. In testing, 31 slices per patient is considered as similar to training and validation, for all 117 patients. The probability of high severity for each patient is calculated from the average of "probability of high" of all 31 slices of the specific patient. For example, the class probability of patient ID 77 in testing, for slice number 60 is represented as [0.1.]. Here, "0." is the probability of having low severity and "1." is the probability of having high severity. We find the inary cross entropy RMSProp convoluation layers and max pooling is shown for training, validation and patient is considered as similar to training and validation, for all 117 patients. The probability of high severity for each patient is calculated from the average of "probability of high" of all obability of patient ID 77 Here, "0." is the probability of having low severity and "1." is the probability of having high severity. We find the probability of having high severity for each of 31 slices of the patient and then computed the average of it. The average probability of high severity for patient ID 77 in each run is given in Table <ref type="table" coords="7,240.72,174.16,3.76,8.96" target="#tab_3">4</ref>.</p><p>The test dataset results are evaluated using two metrics namely accuracy and Area Under ROC Curve (AUC) and ranking is carried out among the participated teams. For better visualization, the same information is plotted and shown as graphs in Figures <ref type="figure" coords="7,167.40,506.68,4.98,8.96" target="#fig_8">6</ref> and<ref type="figure" coords="7,192.72,506.68,4.98,8.96" target="#fig_9">7</ref> using Tableau Tool. In Figure <ref type="figure" coords="7,324.84,506.68,3.76,8.96" target="#fig_8">6</ref>, the value of evaluation metrics for test set is given for all four runs. From the graph, it is clearly visible that run 3 has higher AUC and accuracy than remaining runs. In Figure <ref type="figure" coords="7,373.08,530.68,3.76,8.96" target="#fig_8">6</ref>, the accuracy for training, validation and testing dataset are given for all four runs. From the graph, it is clearly visible that run 3 has higher value in all the cases. In addition, run 4 has higher training and validation accuracy, but the test accuracy is low than run 2, might have occurred due to the chosen filter size of each layer.  In the ImageCLEF 2019 Tuberculosis-Severity scoring subtask, 4 runs are submitted and the best run of our team is ranked 9th in overall among the teams participated is given in Table 5 <ref type="bibr" coords="9,235.80,174.16,10.60,8.96" target="#b1">[3]</ref>. When the results of all runs are sorted by descending related to AUC for SVR subtask, we have obtained 29 th , 31 st , 35 th and 43 rd rank for the four runs submitted by our team <ref type="bibr" coords="9,172.32,520.60,10.89,8.96" target="#b0">[2,</ref><ref type="bibr" coords="9,185.76,520.60,7.26,8.96" target="#b4">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, analysis of severity scoring (SVR) subtask for lung tuberculosis using 2D Convolutional Neural Network is implemented. The classification results obtained for the given set 3D CT Images are submitted for evaluation. In our approach, preprocessing of the dataset has been carried out to convert the images into 2D slices, and the images are split into training and validation set. The proposed model is built using CNN, trained and validated using tuning the hyperparameters for four different runs. From the runs submitted, the primary run is ranked 9 th place among the team participations.</p><p>CNN is a preferred approach, since it facilitates automatic detection of the low level and high level features, from large training dataset. However, a large dataset might prove disadvantageous in terms of memory during the training phase. This can be overcome by the use of a GPU and choosing optimal hyperparameters. In future, the proposed model can be improvised by considering all the slices of the CT images, to build the train model using GPU and transfer learning approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.64,267.81,170.58,8.10;3,134.64,285.81,340.14,8.10;3,134.64,297.81,24.09,8.10;3,251.64,147.48,109.56,111.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. "High Severity" Patient ID 196 Slice 66 Left-CT Scan of Lung from dataset, Middle-Corresponding mask of the lung, Right-Masked image.</figDesc><graphic coords="3,251.64,147.48,109.56,111.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.64,444.09,169.02,8.10;3,134.64,462.09,340.14,8.10;3,134.64,474.09,24.09,8.10;3,257.88,330.12,99.60,104.64"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. "Low Severity" Patient ID 181 Slice 65 Left-CT Scan of Lung from dataset, Middle-Corresponding mask of the lung, Right-Masked image.</figDesc><graphic coords="3,257.88,330.12,99.60,104.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.64,389.97,169.11,8.10;4,136.20,213.48,340.20,160.80"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. General flow of the preprocessing stage</figDesc><graphic coords="4,136.20,213.48,340.20,160.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,419.28,578.08,55.51,8.96;4,134.64,590.08,340.09,8.96;4,134.64,602.08,340.17,8.96;4,134.64,614.08,340.18,8.96;4,134.64,626.08,300.09,8.96"><head></head><label></label><figDesc>Binary crossentropy is used as loss function with Adam and RMSProp as optimizers. The model files are built for different runs by varying the hyper parameters of the base model. The corresponding CNN design structure is shown in Figure 4. In each layer the values are mentioned from the model summary of one run for more clarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,134.64,343.17,188.58,8.10;5,136.20,147.48,351.96,186.60"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Base design of the 2D CNN used for training</figDesc><graphic coords="5,136.20,147.48,351.96,186.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,205.48,471.09,125.34,8.10;5,139.92,494.13,61.82,8.10;5,139.92,516.69,74.86,8.10;5,139.92,527.73,21.38,8.10;5,139.92,549.69,74.22,8.10;5,139.92,560.73,17.88,8.10;5,139.92,582.69,63.60,8.10;5,139.92,605.25,60.30,8.10;5,139.92,627.81,73.82,8.10;5,139.92,660.93,37.23,8.10;5,206.16,343.17,117.06,8.10;5,134.64,373.64,137.03,10.80;5,134.64,399.28,340.05,8.96;5,165.96,411.28,308.94,8.96;5,189.60,423.28,285.42,8.96;5,134.64,435.28,301.74,8.96;5,160.32,447.28,252.78,8.96"><head>.</head><label></label><figDesc>Different runs of the CNN the 2D CNN used for training 4 Experiments and Results The CNN model is trained by varying the hyperparameters such as number of filters, and optimizers. The runs had a filter size of 64Ã—64 with batch size 32 and binary cross entropy. The difference in the accuracy is brought by changing the epoch value and the optimizers such as Adam and RMSProp runs of CNN model by varying the hyperparameters is given in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,134.64,563.85,155.76,8.10"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of 3 convolution layer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,229.92,156.21,9.06,8.10;6,293.76,156.21,9.06,8.10;6,357.60,155.97,9.06,8.10;6,418.56,155.97,9.06,8.10;6,229.92,178.05,43.70,8.10;6,229.92,188.97,27.66,8.10;6,293.76,178.05,43.70,8.10;6,293.76,188.97,27.66,8.10;6,357.60,178.05,43.70,8.10;6,357.60,188.97,27.66,8.10;6,418.56,178.05,43.70,8.10;6,418.56,188.97,27.66,8.10;6,229.92,222.21,38.96,8.10;6,293.76,222.21,23.57,8.10;6,357.60,221.97,36.06,8.10;6,418.56,221.97,36.06,8.10;6,160.80,563.85,196.14,8.10;6,146.04,586.96,328.74,8.96;6,134.64,598.96,233.85,8.96"><head></head><label></label><figDesc>layers and max pooling The intermediate visualization of convoluation layers and max pooling is shown in Figure 5, for Run1, Patient ID 181 and slice number 65.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,134.64,389.13,169.70,8.10;8,147.72,409.56,316.08,226.92"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Performance analysis -Runs vs metrics</figDesc><graphic coords="8,147.72,409.56,316.08,226.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="8,134.64,657.81,258.54,8.10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison of accuracy between training, validation and testing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,176.16,572.01,257.14,55.02"><head>Table 1 .</head><label>1</label><figDesc>Severity scoring dataset -Patient wise -Training and Test set</figDesc><table coords="2,183.48,590.61,199.38,36.42"><row><cell>Severity type</cell><cell>Training</cell><cell>Testing</cell></row><row><cell>Low</cell><cell>118</cell><cell></cell></row><row><cell>High</cell><cell>100</cell><cell>117</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,139.92,399.28,335.10,269.76"><head>Table Different</head><label>Different</label><figDesc></figDesc><table coords="5,139.92,399.28,335.10,269.76"><row><cell></cell><cell></cell><cell></cell><cell cols="2">number of filters,</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">64 with batch size 32 and</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>brought by</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">RMSProp</cell></row><row><cell></cell><cell cols="4">runs of the CNN model -Varying hyperparameters</cell></row><row><cell></cell><cell>Run 1</cell><cell>Run 2</cell><cell>Run 3</cell><cell>Run 4</cell></row><row><cell>No. of convolutional</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell>No. of filters in each</cell><cell>16Ã—32Ã—64</cell><cell>16Ã—32Ã—64</cell><cell>64Ã—32Ã—32</cell><cell>64Ã—</cell></row><row><cell></cell><cell>64Ã—64</cell><cell>64Ã—64</cell><cell>64Ã—64</cell><cell>64Ã—</cell></row><row><cell></cell><cell>max</cell><cell>max</cell><cell>max</cell><cell>max</cell></row><row><cell></cell><cell>relu , softmax</cell><cell>relu, softmax</cell><cell>relu, softmax</cell><cell>relu, softmax</cell></row><row><cell></cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,140.64,221.97,316.38,136.50"><head>Table 3 .</head><label>3</label><figDesc>Results of different runs -Training, Validation and Testing</figDesc><table coords="7,140.64,246.09,316.38,112.38"><row><cell>Run</cell><cell>Training</cell><cell>Validation</cell><cell>Training</cell><cell>Validation</cell><cell>AUC</cell><cell>Accuracy</cell></row><row><cell>No.</cell><cell>accuracy</cell><cell>accuracy</cell><cell>loss</cell><cell>loss</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>0.8314</cell><cell>0.8011</cell><cell>0.3698</cell><cell>0.4223</cell><cell>0.5446</cell><cell>0.5299</cell></row><row><cell>2</cell><cell>0.8491</cell><cell>0.8390</cell><cell>0.3378</cell><cell>0.3496</cell><cell>0.6067</cell><cell>0.5726</cell></row><row><cell>3</cell><cell>0.8840</cell><cell>0.8434</cell><cell>0.2869</cell><cell>0.3132</cell><cell>0.6264</cell><cell>0.6068</cell></row><row><cell>4</cell><cell>0.8754</cell><cell>0.8103</cell><cell>0.2979</cell><cell>0.4284</cell><cell>0.6133</cell><cell>0.5385</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,167.52,391.29,274.38,88.86"><head>Table 4 .</head><label>4</label><figDesc>Test run of Patient Id: 77 with its probability score of high severity</figDesc><table coords="7,199.56,409.89,201.06,70.26"><row><cell>Test Run</cell><cell>Probability score of high severity</cell></row><row><cell>Run 1</cell><cell>0.67741935</cell></row><row><cell>Run 2</cell><cell>0.80645161</cell></row><row><cell>Run 3</cell><cell>0.83870968</cell></row><row><cell>Run 4</cell><cell>0.86362070</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,147.84,197.97,307.14,283.62"><head>Table 5 .</head><label>5</label><figDesc>Top 10 rankings of ImageCLEF 2019 Tuberculosis -Severity scoring task</figDesc><table coords="9,147.84,222.09,301.34,259.50"><row><cell></cell><cell>Team name</cell><cell>AUC</cell><cell>Accuracy</cell><cell>No. of runs</cell></row><row><cell>Rank</cell><cell></cell><cell></cell><cell></cell><cell>submitted</cell></row><row><cell>1</cell><cell>UIIP_BioMed</cell><cell>0.788</cell><cell>0.718</cell><cell>2</cell></row><row><cell>2</cell><cell>SergeKo</cell><cell>0.775</cell><cell>0.718</cell><cell>2</cell></row><row><cell>3</cell><cell>KirillB</cell><cell>0.770</cell><cell>0.692</cell><cell>10</cell></row><row><cell>4</cell><cell>CompElecEngCU</cell><cell>0.763</cell><cell>0.658</cell><cell>2</cell></row><row><cell>5</cell><cell>agentili</cell><cell>0.721</cell><cell>0.684</cell><cell>9</cell></row><row><cell>6</cell><cell>yashindc(Organizer)</cell><cell>0.720</cell><cell>0.641</cell><cell>6</cell></row><row><cell>7</cell><cell>UniversityAlicante</cell><cell>0.701</cell><cell>0.701</cell><cell>10</cell></row><row><cell>8</cell><cell>MostaganemFSEI</cell><cell>0.651</cell><cell>0.615</cell><cell>10</cell></row><row><cell>9</cell><cell>Kavitha</cell><cell>0.626</cell><cell>0.607</cell><cell>4</cell></row><row><cell>10</cell><cell>Shopon</cell><cell>0.611</cell><cell>0.615</cell><cell>2</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,149.80,289.60,324.88,8.96;10,151.68,301.12,94.62,8.96" xml:id="b0">
	<monogr>
		<ptr target="https://www.imageclef.org/2019/medical/tuberculosis" />
		<title level="m" coord="10,157.32,289.60,92.30,8.96">ImageCLEF 2019 page</title>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.80,312.64,325.11,8.96;10,151.68,324.04,277.14,8.96" xml:id="b1">
	<monogr>
		<ptr target="https://www.crowdai.org/challenges/imageclef-2019-tuberculosis-severity-scoring/leaderboards" />
		<title level="m" coord="10,157.32,312.64,84.50,8.96">Crowd AI page</title>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.80,335.56,324.85,8.96;10,151.68,347.08,323.00,8.96;10,151.68,358.60,323.02,8.96;10,151.68,370.12,253.16,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,228.36,347.08,246.32,8.96;10,151.68,358.60,31.68,8.96">Efficient and fully automatic segmentation of the lungs in CT volumes</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oscar</forename><forename type="middle">A</forename><surname>JimÃ©nez-Del-Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,303.60,358.60,171.10,8.96;10,151.68,370.12,205.83,8.96">Proceedings of the VISCERAL Challenge at ISBI. No. 1390 in CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<meeting>the VISCERAL Challenge at ISBI. No. 1390 in CEUR Workshop Proceedings</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.80,381.64,259.45,8.96" xml:id="b3">
	<monogr>
		<ptr target="https://keras.io/" />
		<title level="m" coord="10,157.32,381.64,83.16,8.96">Keras documentation</title>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.80,416.08,324.92,8.96;10,151.68,427.60,323.23,8.96;10,151.68,439.12,323.01,8.96;10,151.68,450.64,323.13,8.96;10,151.68,462.04,190.29,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,263.64,427.60,211.27,8.96;10,151.68,439.12,318.50,8.96">Overview of ImageCLEFtuberculosis 2019 -Automatic CT-based Report Generation and Tuberculosis Severity Assessment</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dzmitri</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2380/" />
	</analytic>
	<monogr>
		<title level="m" coord="10,151.68,450.64,112.67,8.96">CLEF 2019 Working Notes</title>
		<title level="s" coord="10,272.64,450.64,174.65,8.96">CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,149.80,473.56,324.92,8.96;10,151.68,485.08,323.13,8.96;10,151.68,496.60,323.22,8.96;10,151.68,508.12,323.13,8.96;10,151.68,519.52,323.23,8.96;10,151.68,531.04,323.07,8.96;10,151.68,542.56,323.12,8.96;10,151.68,554.08,323.11,8.96;10,151.68,565.60,323.07,8.96;10,151.68,577.12,323.12,8.96;10,151.68,588.52,323.13,8.96;10,151.68,600.04,305.59,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,371.40,519.52,103.51,8.96;10,151.68,531.04,14.47,8.96;10,329.16,554.08,49.33,8.96;10,409.68,554.08,65.11,8.96;10,151.68,565.60,323.07,8.96;10,151.68,577.12,187.44,8.96">Multimedia Retrieval in Medicine, Lifelogging, Security and Nature In: Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>PÃ©teri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dzmitri</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich ; Narciso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ergina</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Roberto Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Cuevas RodrÃ­guez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantinos</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,345.60,577.12,129.20,8.96;10,151.68,588.52,229.99,8.96">Proceedings of the 10th International Conference of the CLEF Association (CLEF 2019)</title>
		<title level="s" coord="10,151.68,600.04,169.05,8.96">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF 2019)<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09-09">2019. September 9-12 2019</date>
		</imprint>
	</monogr>
	<note>Alba GarcÃ­a Seco de Herrera</note>
</biblStruct>

<biblStruct coords="10,149.80,611.56,324.99,8.96;10,151.68,623.08,323.23,8.96;10,151.68,634.60,323.13,8.96;10,151.68,646.12,54.21,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,451.56,611.56,23.23,8.96;10,151.68,623.08,323.23,8.96;10,151.68,634.60,222.59,8.96">Overview of ImageCLEFtuberculosis 2018 -Detecting multi-drug resistance, classifying tuberculosis type, and assessing severity score</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,383.28,634.60,87.59,8.96">CLEF working notes</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
