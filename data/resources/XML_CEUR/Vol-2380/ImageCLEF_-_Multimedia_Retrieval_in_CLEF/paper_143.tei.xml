<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.59,115.96,314.16,12.62;1,263.62,133.89,88.12,12.62">Using improved optical flow model to detect Tuberculosis</title>
				<funder>
					<orgName type="full">Generalitat Valenciana</orgName>
				</funder>
				<funder ref="#_zMS4P8z">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder>
					<orgName type="full">University of Alicante (Spain)</orgName>
				</funder>
				<funder ref="#_vpANdyQ #_H4zF2fn">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.88,171.56,68.73,8.74"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Carretera San Vicente del Raspeig s/n 03690 San Vicente del Raspeig</addrLine>
									<settlement>-Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.07,171.56,89.90,8.74"><forename type="first">Andrés</forename><surname>Fuster-Guilló</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Carretera San Vicente del Raspeig s/n 03690 San Vicente del Raspeig</addrLine>
									<settlement>-Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.58,171.56,83.09,8.74"><forename type="first">Jorge</forename><surname>Azorín-López</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Carretera San Vicente del Raspeig s/n 03690 San Vicente del Raspeig</addrLine>
									<settlement>-Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,424.05,171.56,51.41,8.74"><forename type="first">Irene</forename><surname>Llopis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<addrLine>Carretera San Vicente del Raspeig s/n 03690 San Vicente del Raspeig</addrLine>
									<settlement>-Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.59,115.96,314.16,12.62;1,263.62,133.89,88.12,12.62">Using improved optical flow model to detect Tuberculosis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">952667098A55EEF2804815762352B6EF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tuberculosis</term>
					<term>Optical Flow</term>
					<term>Activity Description</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In 2017, 10 million people suffered from tuberculosis and 1.3 million deaths were recorded at the national level. Nowadays, a quarter of the world's population faces this disease. Early detection of tuberculosis can save many lives. There are many methods to detect this disease but one of the cheapest and quickest is the analysis of CT images of the chest. This is one of the objectives of the ImageClef Tuberculosis 2019 task, and is the one being studied by the University of Alicante's research group in this edition. Last year we used two working approaches, one based exclusively on the use of Deep Learning techniques on a sequence of 2D images extracted from a 3D tomography and another based on the use of Optical Flow to convert the 3D tomography into a moving representation to calculate the ADV (a previous descriptor provided by the group). This descriptor can to synthesize information from a sequence into an image. This year we have tried to improve the results of the second model. This article presents the experiments carried out and the results obtained within the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tuberculosis is a disease caused by the bacterium Mycobacterium Tuberculosis or Koch's bacillus. The main organ affected are the lungs, but we can also find conditions in the kidneys, spine, and brain. It is one of the deadliest diseases in the world:</p><p>-In 2017, 10 million people were affected and 1.3 million deaths were recorded at the national level. A quarter of the world's population suffers from it -Causes more deaths than malaria and AIDS combined People who have symptoms (even if they have a negative test result) or a positive TB test result should be screened for tuberculosis. There are two types of tests to find out if a person has been infected with TB bacteria: -The tuberculin skin test : A small amount of tuberculin is injected into the lower arm and, after 48-72 hours, the patient must return for medical personnel to analyse the size of the raised, hardened, or swollen area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>-Blood Tests</head><p>In the case of a positive result, it would be to perform other tests, since with the above-mentioned tests it is not possible to confirm whether a person has a latent tuberculosis infection or tuberculosis disease. Computers can support the automatic detection of patients with tuberculosis. Along these lines, the CLEF (Conference and Labs of the Evaluation Forum) has developed several tasks within this field. This is a series of campaigns that have been carried out since 2000, focusing on the systematic evaluation of information, through various tasks. Most of the tasks are related to image classification and annotation (ImageCLEF) <ref type="bibr" coords="2,467.30,542.26,9.96,8.74" target="#b7">[8]</ref>. ImageCLEF is the name given to tasks that use image processing. They began to be proposed in 2003, and since 2004 medical tasks are added every year. In 2017 a specific task was proposed for the detection of tuberculosis called ImageCLEF Tuberculosis, with the participation of 9 groups. This year ImageClefTuberculosis <ref type="bibr" coords="2,295.50,602.04,10.52,8.74" target="#b3">[4]</ref> includes two independent subtasks.</p><p>1. Subtask 1: Severity scoring. This subtask is aimed at assessing TB severity score. The Severity score is a cumulative score of severity of TB case assigned by a medical doctor.</p><p>Originally, the score varied from 1 ("critical/very bad") to 5 ("very good").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Subtask 2: CT report.</head><p>In this subtask the participants will have to generate an automatic report based on the CT image. This report should include the following information in binary form (0 or 1): Left lung affected, right lung affected, presence of calcifications, presence of caverns, pleurisy, lung capacity decrease.</p><p>Last year we test deep learning and Optical Flow models <ref type="bibr" coords="3,400.84,190.08,9.96,8.74" target="#b8">[9]</ref>. In our second participation our objective was to improve the Optical Flow model we used last year using information from the three axes. We have tested the models developed with slight variations in the two subtasks. This document is structured as follows: in section 2 we present the architectures of the model used Optical Flow. In section 3 we present the official results of the experiments and Section 4 summarizes the document and offers a series of proposals for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our approaches to the solution</head><p>In this section we propose a combined method based on optical flow and a characterization method called ADV, to deal with the classification of chest CT scan images affected by different types of tuberculosis. The key point of this method is the interpretation of the set of cross-sectional chest images provided by CT scan, not as a volume but as a sequence of video images. We can extract movement descriptors capable of classifying tuberculosis affections by analysing deformations or movements produced in these video sequences.</p><p>The concept of optical flow refers to the estimation of displacements of intensity patterns. This concept has been extensively used in computer vision in different application domains: robot or vehicle navigation, car driving, video surveillance or facial expression <ref type="bibr" coords="3,275.00,452.34,9.96,8.74" target="#b4">[5]</ref>. In biomedical context optical flow has been used to analyse organ deformations <ref type="bibr" coords="3,299.41,464.30,11.15,8.74" target="#b6">[7,</ref><ref type="bibr" coords="3,310.56,464.30,11.15,8.74" target="#b10">11]</ref>. We can find different methods in the literature to obtain the optical flow <ref type="bibr" coords="3,315.82,476.25,9.96,8.74" target="#b2">[3]</ref>. One of the most used method to estimate motion at each pixel is Lucas Kanade <ref type="bibr" coords="3,349.67,488.21,14.61,8.74" target="#b9">[10]</ref>. In this work we will use Lucas Kanade method to extract optical flow comparing sequences of consecutive images. Nevertheless, we need not only to estimate motion but describe this motion.</p><p>To describe motion there are several methods used in different computer vision context like human behaviour recognition <ref type="bibr" coords="3,356.76,548.25,9.96,8.74" target="#b5">[6]</ref>. A successful method to describe human behaviour based on trajectory analysis is presented in <ref type="bibr" coords="3,446.61,560.21,9.96,8.74" target="#b0">[1]</ref>. The paper proposes a description vector called (ADV Activity Description Vector) tested in several contexts <ref type="bibr" coords="3,245.52,584.12,9.96,8.74" target="#b1">[2]</ref>. In summary, the ADV vector describes the activity in image sequence by counting for each region of the image the movements produced in four directions of the 2D space. A detailed description of the method can be found in <ref type="bibr" coords="3,206.17,619.98,9.96,8.74" target="#b0">[1]</ref>.</p><p>In this paper we propose the use of ADV to describe motion in the optical flow obtained from sequences of cross-sectional chest images provided by CT scan. In the first stage a transformation over the cross-sectional chest images provided by the CT scan is performed to transform image formats into three video sequences. Each video sequence corresponds to the section of the volume of the CT scan in each axis: XY axis, XZ axis and YZ axis. The second stage calculates the optical flow of the video sequences for each axis using the Lucas Kanade method. The third stage calculates the activity description vector ADV (3x3x5) independently for each optical flow extracted from the sections accumulating within each 3x3 region of the image, the displacements of the optical flow in four directions of a 2D space (right, left, up, down). The fifth component of the ADV calculates the frequencies in direction changes. In the fourth stage a normalization of the ADV vector in performed. The fifth stage uses the ADV vector normalized as the input for a generic classifier to evaluate the results. In this paper, the SVM and the LDA classifiers are used. Finally, the last stage ensembles the individual classification results for each axis into a single result. It can to combine the results using the statistical mode as the most used label or using the SVM classifier to provide a boosting based combination. On the other hand, some results about the combination of the different classification architectures have been provided as a multiclassifier (MC). This method uses a combination of the individual SVM and LDA classifiers for each axis and the combination of the ensemble layer as mode or SVM to provide a meta-classifier combining all the results together to provide a single label.</p><p>The figure summarizes the successive stages of the process for extracting the activity descriptors (optical flow+ADV) that will be the input of a classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task 1</head><p>As can be seen in the table 1 the model of learning the predictions of the ADV calculated from the sequence of slices by the SVM classifier and combining them by the mode obtains the best results. The use of the LDA as classifier produce very similar results. Finally, using a combination of the different classifiers and combinations (SVR-MC) have significant results but increasing the complexity of the prediction. In the case of the second task (see results in Table <ref type="table" coords="6,379.72,118.99,3.87,8.74" target="#tab_2">2</ref>), the best results are obtained using the SVM as classifier per axis and for combining the different predictions. Again, the MC is close to the best result but increasing the complexity of the model. Finally, the LDA classifier produce wrong results and very far from the UIIP BioMed.</p><p>To sum up, the results obtained are very promising for the task one. There are no differences between the classification methods used, but the ADV looks like a model that can offer acceptable results. However, for the second task, more resarch should be done in the ADV to be closer to the UIIP BioMed. In future editions, we will combine the use of ADVs with deep learning techniques, which we will try to use in future editions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and future work</head><p>Early detection of tuberculosis is a major social challenge, given the devastating effects of the disease. As the organizers state, "we have to work towards methods that allow a correct detection of the disease that kills thousands and thousands of people". In this paper we have proposed an approach based on Optical Flow to convert the 3D tomography into a motion representation to calculate the ADV (a previous descriptor provided by the group). This year we used the three-axis matrix and improved last year's system. The experiments carried out and the results obtained allow us to confirm the interest of this line of research and encourages us to continue making improvements to the proposed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,216.48,476.44,182.40,7.89;4,155.68,136.75,316.01,320.20"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Optical flow plus ADV process stages</figDesc><graphic coords="4,155.68,136.75,316.01,320.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,140.99,218.90,340.91,254.51"><head></head><label></label><figDesc>They use other diagnostic methods for this purpose: -Medical history. It's important to keep in mind: 1. History of exposure to tuberculosis 2. Demographic factors such as country of origin, age, race, occupation... as these may increase the risk of exposure to the disease. 3. Patient with other conditions such as HIV or diabetes -Physical exam Provides information about the patient's condition and other factors that may influence tuberculosis treatment -Diagnostic microbiology or baciloscopic Several samples from a sputum smear</figDesc><table coords="2,140.99,345.65,339.60,127.76"><row><cell>would confirm</cell></row><row><cell>the diagnosis.</cell></row><row><cell>-Anteroposterior Chest X-ray It is used to detect abnormalities in the chest,</cell></row><row><cell>lesions that can appear anywhere in the lungs, with different sizes, shapes,</cell></row><row><cell>density and cavitation, being more common the apical lesion. Although this</cell></row><row><cell>test cannot be used as a definitive diagnosis, it is used to rule out the possi-</cell></row><row><cell>bility of pulmonary tuberculosis in a person who has had a positive reaction</cell></row><row><cell>to the tuberculin skin test or blood test. Chest radiography is considered</cell></row><row><cell>fundamental in the diagnosis, so we will focus on this test later, using im-</cell></row><row><cell>ages from different x-rays, which we will process to determine if a patient</cell></row><row><cell>has tuberculosis or not, and if so, which of all types.</cell></row></table><note coords="2,151.70,333.70,328.89,8.74;2,151.70,345.65,262.11,8.74"><p>or other samples are cultured to test for the presence of acid-fast bacilli (BAAR), which must be M. tuberculosis. A positive result</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,385.00,320.92,150.85"><head>Table 1 .</head><label>1</label><figDesc>Results of University of Alicante vs better results at SubTask 1</figDesc><table coords="5,134.77,405.80,268.08,130.05"><row><cell>Run</cell><cell>AUC ACC Rank</cell></row><row><cell>UIIP BioMed</cell><cell>0.7877 0.7179 1</cell></row><row><cell cols="2">SVR-SVM-axis-mode-4.txt 0.7013 0.7009 12</cell></row><row><cell>SVR-MC</cell><cell>0.7003 0.7009 14</cell></row><row><cell cols="2">SVR-LDA-axis-mode-4.txt 0.6842 0.6838 18</cell></row><row><cell cols="2">SVR-SVM-axis-svm-4.txt 0.6761 0.6752 20</cell></row><row><cell cols="2">SVR-LDA-axis-svm-4.txt 0.6499 0.6496 23</cell></row><row><cell>3.2 Task 2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,160.83,565.76,293.70,95.21"><head>Table 2 .</head><label>2</label><figDesc>Results of University of Alicante vs better results at Subtask 2</figDesc><table coords="5,229.44,586.56,156.48,74.41"><row><cell>Run</cell><cell>AUC ACC Rank</cell></row><row><cell>UIIP BioMed</cell><cell>0.7968 0.6860 1</cell></row><row><cell cols="2">svm-axis-svm.txt 0.6190 0.5366 15</cell></row><row><cell>MC</cell><cell>0.6104 0.5250 16</cell></row><row><cell cols="2">svm-axis-mode.txt 0.6043 0.5340 18</cell></row><row><cell cols="2">lda-axis-mode.txt 0.5975 0.4860 20</cell></row><row><cell cols="2">lda-axis-svm.txt 0.5787 0.4851 22</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>Acknowledgements This research work has been partially funded by the <rs type="funder">University of Alicante (Spain)</rs>, <rs type="funder">Generalitat Valenciana</rs> and the <rs type="funder">Spanish Government</rs> through the projects (<rs type="grantNumber">PROMETEU/2018/089</rs>), <rs type="projectName">HUMANO</rs>(<rs type="grantNumber">RTI2018-094653-B-C22</rs>) and <rs type="projectName">INTEGER: Intelligent Text Generation</rs> (<rs type="grantNumber">RTI2018-094649-B-I00</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_zMS4P8z">
					<idno type="grant-number">PROMETEU/2018/089</idno>
					<orgName type="project" subtype="full">HUMANO</orgName>
				</org>
				<org type="funded-project" xml:id="_vpANdyQ">
					<idno type="grant-number">RTI2018-094653-B-C22</idno>
					<orgName type="project" subtype="full">INTEGER: Intelligent Text Generation</orgName>
				</org>
				<org type="funding" xml:id="_H4zF2fn">
					<idno type="grant-number">RTI2018-094649-B-I00</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,536.31,337.63,7.86;6,151.52,547.27,329.07,7.86;6,151.52,558.23,329.07,7.86;6,151.52,569.19,183.99,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,465.49,536.31,15.10,7.86;6,151.52,547.27,324.82,7.86">Human behaviour recognition based on trajectory analysis using neural networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Azorin-Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saval-Calvo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fuster-Guillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2013.6706724</idno>
		<ptr target="https://doi.org/10.1109/IJCNN.2013.6706724" />
	</analytic>
	<monogr>
		<title level="m" coord="6,165.58,558.23,283.79,7.86">Proceedings of the International Joint Conference on Neural Networks</title>
		<meeting>the International Joint Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,580.12,337.64,7.86;6,151.52,591.08,329.07,7.86;6,151.52,602.04,329.07,7.86;6,151.52,612.99,329.07,7.86;6,151.52,623.95,183.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,276.90,591.08,203.69,7.86;6,151.52,602.04,179.28,7.86">Group activity description and recognition based on trajectory analysis and neural networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Azorin-Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saval-Calvo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fuster-Guillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Signes-Pont</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2016.7727387</idno>
		<ptr target="https://doi.org/10.1109/IJCNN.2016.7727387" />
	</analytic>
	<monogr>
		<title level="m" coord="6,378.92,602.04,101.67,7.86;6,151.52,612.99,154.78,7.86">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page" from="1585" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,634.88,337.64,7.86;6,151.52,645.84,329.07,7.86;6,151.52,656.77,328.20,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,291.89,634.88,188.71,7.86;6,151.52,645.84,92.42,7.86">A survey of optical flow techniques for robotics navigation applications</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Napolitano</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10846-013-9923-6</idno>
		<ptr target="https://doi.org/10.1007/s10846-013-9923-6" />
	</analytic>
	<monogr>
		<title level="j" coord="6,251.45,645.84,229.15,7.86;6,151.52,656.80,50.48,7.86">Journal of Intelligent and Robotic Systems: Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="361" to="372" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,119.67,337.63,7.86;7,151.52,130.63,329.07,7.86;7,151.52,141.59,329.07,7.86;7,151.52,152.55,329.07,7.86;7,151.52,163.51,208.04,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,151.52,130.63,329.07,7.86;7,151.52,141.59,166.17,7.86">Overview of ImageCLEFtuberculosis 2019 -automatic ct-based report generation and tuberculosis severity assessment</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org/Vol-2380" />
	</analytic>
	<monogr>
		<title level="m" coord="7,340.28,141.59,140.32,7.86;7,151.52,152.55,91.40,7.86">CLEF2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12">September 9-12 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,174.47,337.63,7.86;7,151.52,185.40,329.07,7.89;7,151.52,196.39,170.81,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,327.18,174.47,153.41,7.86;7,151.52,185.43,58.42,7.86">Optical flow modeling and computation: A survey</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fortun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bouthemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cviu.2015.02.008</idno>
		<ptr target="https://doi.org/10.1016/j.cviu.2015.02.008" />
	</analytic>
	<monogr>
		<title level="j" coord="7,218.56,185.43,182.87,7.86">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,207.34,337.64,7.86;7,151.52,218.28,329.07,7.89;7,151.52,229.26,329.07,8.11;7,151.52,240.87,119.18,7.47" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,337.98,207.34,142.62,7.86;7,151.52,218.30,165.84,7.86">Automated human behavior analysis from surveillance videos: a survey</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gowsikhaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abirami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baskaran</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10462-012-9341-3</idno>
		<ptr target="https://doi.org/10.1007/s10462-012-9341-3" />
	</analytic>
	<monogr>
		<title level="j" coord="7,327.31,218.30,122.22,7.86">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="747" to="765" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,251.18,337.64,7.86;7,151.52,262.14,329.07,7.86;7,151.52,273.10,329.07,7.86;7,151.52,284.03,329.07,7.89;7,151.52,295.02,23.04,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,202.88,262.14,277.71,7.86;7,151.52,273.10,200.87,7.86">Three-dimensional optical flow method for measurement of volumetric brain deformation from intraoperative MR images</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nabavi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M L</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Jolesz</surname></persName>
		</author>
		<idno type="DOI">10.1097/00004728-200007000-00004</idno>
		<ptr target="https://doi.org/10.1097/00004728-200007000-00004" />
	</analytic>
	<monogr>
		<title level="j" coord="7,359.77,273.10,120.82,7.86;7,151.52,284.06,50.45,7.86">Journal of Computer Assisted Tomography</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="531" to="538" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,305.98,337.63,7.86;7,151.52,316.93,329.07,7.86;7,151.52,327.89,329.07,7.86;7,151.52,338.85,329.07,7.86;7,151.52,349.81,329.07,7.86;7,151.52,360.77,329.07,7.86;7,151.52,371.73,329.07,7.86;7,151.52,382.69,329.07,7.86;7,151.52,393.65,329.07,7.86;7,151.52,404.61,216.27,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,268.29,360.77,212.30,7.86;7,151.52,371.73,124.23,7.86">ImageCLEF 2019: Multimedia retrieval in medicine, lifelogging, security and nature</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,297.67,371.73,182.92,7.86;7,151.52,382.69,329.07,7.86;7,151.52,393.65,122.46,7.86">Proceedings of the 10th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="7,305.55,393.65,171.07,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09-09">2019. September 9-12 2019</date>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="7,142.96,415.56,337.64,7.86;7,151.52,426.52,329.07,7.86;7,151.52,437.48,329.07,7.86;7,151.52,448.44,322.02,8.12" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,430.29,415.56,50.30,7.86;7,151.52,426.52,248.93,7.86">Tuberculosis detection using optical flow and the activity description vector</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">L</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Rico-Juan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Guilló</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Llopis</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2125/paper_128.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="7,420.91,426.52,59.69,7.86;7,151.52,437.48,252.08,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,459.40,337.98,7.86;7,151.52,470.33,161.00,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,250.32,459.40,225.55,7.86">Optical flow measurement using Lucas Kanade method</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Saurahb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,151.52,470.36,78.20,7.86">Int J Comput Appl</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6" to="10" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,481.32,337.98,7.86;7,151.52,492.28,329.07,7.86;7,151.52,503.24,329.07,7.86;7,151.52,514.17,325.28,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,432.02,481.32,48.57,7.86;7,151.52,492.28,329.07,7.86;7,151.52,503.24,113.27,7.86">An adapted optical flow algorithm for robust quantification of cardiac wall motion from standard cine-MR examinations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lalande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Brunotte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Legrand</surname></persName>
		</author>
		<idno type="DOI">10.1109/TITB.2012.2204893</idno>
		<ptr target="https://doi.org/10.1109/TITB.2012.2204893" />
	</analytic>
	<monogr>
		<title level="j" coord="7,273.73,503.24,206.86,7.86;7,151.52,514.19,49.03,7.86">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="859" to="868" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
