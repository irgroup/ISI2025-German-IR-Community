<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.13,115.96,325.10,12.62;1,135.84,133.89,343.67,12.62;1,262.27,151.82,90.81,12.62">Attentive Multi-stage Learning for Early Risk Detection of Signs of Anorexia and Self-harm on Social Media</title>
				<funder>
					<orgName type="full">INSERM</orgName>
				</funder>
				<funder ref="#_5Tem3Tz">
					<orgName type="full">CNRS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,155.06,189.59,67.66,8.74"><forename type="first">Waleed</forename><surname>Ragheb</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">IUT de Béziers</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<settlement>Béziers</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.62,189.59,50.81,8.74"><forename type="first">Jérôme</forename><surname>Azé</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">IUT de Béziers</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<settlement>Béziers</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.32,189.59,68.00,8.74"><forename type="first">Sandra</forename><surname>Bringay</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Paul Valéry University -Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.59,189.59,48.71,8.74;1,281.23,201.55,42.09,8.74"><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Paul Valéry University -Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.13,115.96,325.10,12.62;1,135.84,133.89,343.67,12.62;1,262.27,151.82,90.81,12.62">Attentive Multi-stage Learning for Early Risk Detection of Signs of Anorexia and Self-harm on Social Media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8DA350C2429D3E0BFDDF821F4B473A22</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Classification</term>
					<term>LSTM</term>
					<term>Attention</term>
					<term>Temporal Variation</term>
					<term>Bayesian Variational Inference</term>
					<term>Anorexia</term>
					<term>Self-harm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Three tasks are proposed at CLEF eRisk-2019 for predicting mental disorder using users posts on Reddit. Two tasks (T1 and T2) focus on early risk detection of signs of anorexia and self-harm respectively. The other one (T3) focus on estimation of the severity level of depression from a thread of user submissions. In this paper, we present the participation of LIRMM (Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier) in both tasks on early detection (T1 and T2). The proposed model addresses this problem by modeling the temporal mood variation detected from user posts through multistage learning phases. The proposed architectures use only textual information without any hand-crafted features or dictionaries. The basic architecture uses two learning phases through exploration of state-of-theart deep language models. The proposed models perform comparably to other contributions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Anorexia is consider one of the most common eating disorder. It is characterized by low weight, worry of gaining weight, and a powerful need to be skinny, leading to food restriction. Many who suffer from eating disorder see themselves as overweight although they could be thin <ref type="bibr" coords="1,316.35,566.85,9.96,8.74" target="#b7">[8]</ref>. Individuals with eating disorders have also been shown to have lower employment rates, in addition to an overall loss of earnings. Eating disorder sufferers who are experiencing an overall loss in earnings associated with their illness are also magnified by the excess of healthcare costs. According to the National Eating Disorder Association (NEDA), up to 70 million people worldwide suffer from eating disorders <ref type="bibr" coords="2,396.39,118.99,9.96,8.74" target="#b0">[1]</ref>. Eating disorder symptoms are beginning earlier in both males and females. As estimated, 1.1 to 4.2 percent of women suffer from anorexia at some point in their lifetime <ref type="bibr" coords="2,467.31,142.90,9.96,8.74" target="#b5">[6]</ref>. Young people between the ages of 15 and 24 with anorexia have 10 times the risk of dying compared to their same-aged peers.</p><p>Self-harm is a very common problem, and many people are struggling to deal with it <ref type="bibr" coords="2,168.25,191.53,9.96,8.74" target="#b8">[9]</ref>. Several illnesses are associated with self-harm, including borderline personality disorder, depression, eating disorders, anxiety or emotional distress <ref type="bibr" coords="2,134.77,215.44,9.96,8.74" target="#b2">[3]</ref>. Self-harm occurs most often during the teenage and young adult begin around age 14 and carry on into their 20s, though it can also happen later in life <ref type="bibr" coords="2,467.31,227.40,9.96,8.74" target="#b8">[9]</ref>. There is also an increased risk of suicide in individuals who self-harm and it is found in 40% to 60% of suicides <ref type="bibr" coords="2,277.67,251.31,9.96,8.74" target="#b4">[5]</ref>.</p><p>Social media is becoming increasingly used not only by adults but also at different age stages. Mental disordered patients also turn to online social media and web forums for information on specific conditions and emotional support. Even though social media can be used as a very helpful tool in changing a person's life, it may cause such conflicts that can have a negative impact. This puts responsibilities for content and community management for monitoring and moderation. With the increasing number of users and their contents, these operations turn out to be extremely difficult. Many social media try to deal with this problem by reactive moderation. In reactive moderation, users report any inappropriate, negative or risky user generated contents. However it may reduce the workload or the cost of moderating, it is not enough especially for handling mental disordered user's threads or posts.</p><p>Previous researches on social media have established the relationship between an individual's psychological state and his\her linguistic and conversational patterns <ref type="bibr" coords="2,161.01,432.25,15.50,8.74" target="#b18">[19,</ref><ref type="bibr" coords="2,178.17,432.25,11.62,8.74" target="#b17">18]</ref>. This motivate the task organizers to initiate the pilot task for detecting depression from user posts on Reddit<ref type="foot" coords="2,345.38,442.64,3.97,6.12" target="#foot_0">1</ref> in eRisk-2017 <ref type="bibr" coords="2,417.74,444.21,14.61,8.74" target="#b10">[11]</ref>. In eRisk-2018 the extension of the study was planned to include detection of anorexia. In eRisk-2019, a continuation of anorexia tasks in addition to two other tasks are proposed. One task is for early detection of signs of self-harm (T2). In this task no training dataset is provided. Also, another new task for detection of severity level of depression (T3) is presented. Tasks organizers proposed new evaluation measures than what were used before.</p><p>In this paper, we present the participation of LIRMM (Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier) in both tasks for early detection of anorexia and self-harm in eRisk-2019. The originality of our approach is to perform the detection through two main learning phases. In the first learning phase. we proposed Deep Mood Evaluation Module (DMEM) that uses attention based deep learning models to construct a time series representing temporal mood variation through users posts or writings. The second phase is either to use machine learning or Bayesian inference model to obtain the proper decision. The main idea is to give a decision once the models detect clear signs of mental disorder from current and previous mood extracted from the content.</p><p>The rest of the paper is organized as follows. In Section 2, the related work is introduced. Then in Section 3, a brief tasks (T1 and T2) description of early risk detection and used datasets are presented. Section 4 presents the proposed models. The experimental setup and all model variants used are introduced in Section 5. In Section 6, the evaluation results and discussions are presented. We conclude the study and experiments in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recent psychological studies showed the correlation between person's mental status and mood variation over time <ref type="bibr" coords="3,301.76,285.25,14.60,8.74" target="#b10">[11]</ref>. It is also evident that some mental disordered may have chronic week-to-week mood instability. It is a common presenting symptom for people with a wide variety of mental disorders, with as many as 8 of 10 patients reporting some degree of mood instability during assessment. These studies suggest that clinicians should screen for temporal mood variation across most common mental health disorders.</p><p>Concerning text representation, traditional Natural Language Processing (NLP) modules start with feature extraction from text such as the count or frequency of specific words, predefined patterns, Part-of-Speech tagging, etc. These hand-crafted features should be selected carefully and sometimes with an expert view. However these features are interesting <ref type="bibr" coords="3,353.63,417.01,14.61,8.74" target="#b21">[22]</ref>, sometimes they loose the sense of generalization. Another recent trend is the use of word and documents vectorization methods. These strategies that convert either words, sentences or even overall documents into vectors take into account all the text not just parts of it. There are many ways to transform a text to high-dimensional space such as term frequency and inverse document frequency (TF-IDF), Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), etc <ref type="bibr" coords="3,379.21,488.75,14.61,8.74" target="#b13">[14]</ref>. This direction was revolutionized by Mikolov et al. <ref type="bibr" coords="3,279.29,500.70,15.50,8.74" target="#b15">[16,</ref><ref type="bibr" coords="3,296.45,500.70,12.73,8.74" target="#b16">17]</ref> who proposed the Continuous Bag Of Words (CBOW) and skip-gram models known as Word2vec. It is a probabilistic based model that makes use of a two layered neural network architecture to compute the conditional probability of a word given its context. Based on this work Le et al. <ref type="bibr" coords="3,202.79,548.52,15.50,8.74" target="#b9">[10]</ref> propose Paragraph Vector model. The algorithm which is also known as Doc2vec learns fixed-length feature representations from variablelength pieces of texts, such as sentences, paragraphs, and documents. Both word vectors and documents vectors are trained using stochastic gradient descent and back-propagation shallow neural network language models. The development of Universal Language Model Fine Tuning (ULMFiT) is considered like moving from shallow to deep contextual pre-training word representation <ref type="bibr" coords="3,444.00,620.25,9.96,8.74" target="#b6">[7]</ref>. This idea has been proved to achieve Computer Vision (CV)-like transfer learning for many NLP task. ULMFiT make use of the state-of-the art language model AWD-LSTM (Average stochastic gradient descent -Weighted Dropout LSTM) proposed by <ref type="bibr" coords="4,192.68,118.99,111.50,8.74">Merity et al. in 2017 [15]</ref>. The same 3-layer LSTM recurrent architecture with the same hyperparameters and no additions other than tuned dropout hyperparameters are used. The classifier layers above the base LM encoder is simply a pooling layer (maximum and average pool) followed by three fully-connected linear layers. The overall models signicantly outperforms the state-of-the-art on six text classication tasks including three tasks for sentiment analysis. In this paper, we will use these techniques for text representations.</p><p>Attention mechanism is considered as one of the recent trends in NLP models <ref type="bibr" coords="4,134.77,216.71,9.96,8.74" target="#b1">[2]</ref>. It can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. This can be seen as take a collection of vectors, whether it could be a sequence of vectors representing a sequence of words, or an unordered collections of vectors representing a collection of attributes and summarize them into a single vector. This summarization is done by scoring each input sequence with a probability-like scores obtained from the attention. This helps the model to pay close attention to the sequence items with higher attention scores. In this paper, we will evaluate the effect of attention mechanisms on the model.</p><p>In this paper, we will use deep attention based modification of ULMFiT classifier to construct a time series representing temporal mood variation. We the used classical machine learning and statistical models to get the final decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tasks Description</head><p>In CLEF eRisk 2019, three tasks are presented <ref type="bibr" coords="4,347.53,450.80,14.61,8.74" target="#b12">[13]</ref>. The first task (T1) is for early detection of signs of anorexia. It is a continuation of the same task in eRisk-2018. The second one (T2) is a new task in 2019 for early detection of signs of self-harm. No training data is provided for this task. Another task was proposed (T3) for measuring the severity of the signs of depression. In this section we will describe the first two tasks (T1 and T2) that we have participated on.</p><p>Both tasks are considered as a binary classification problem. The datasets are a dated textual data of user posts and comments -posts without titles-on Reddit. The training and testing datasets are provided in stream of user writings (posts and comments). The stream is ordered chronologically. A brief statistics and summary for these datasets are provided in Table <ref type="table" coords="4,383.19,572.43,3.87,8.74" target="#tab_0">1</ref>. Task organizers set up a server that iteratively gives user writings to the participating teams. The goal is not only to perform classification but also to do it as early as possible using minimum amount of writings for each user. A decision must be sent after processing each user writing to continue receiving more. This decision could be positive risk case or postponed for future writings. A detailed description of the tasks and used evaluation metrics can be found in the corresponding task description paper <ref type="bibr" coords="4,213.74,656.12,14.61,8.74" target="#b12">[13]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Models</head><p>The temporal aspects of the eRisk tasks inspired us to model the temporal mood variation through user's text content. The average number of days ranging from the first submission to the last submission is approximately 600 days. So, determining the way in which user's posts and comments vary from positive to negative and vice versa through time is worth inspecting. In the proposed models, the main idea is to process user writings for each user and determine the probability of how positive or negative it is. A detailed description of our model can be found in the working notes paper of eRisk 2018 <ref type="bibr" coords="5,400.40,347.56,14.61,8.74" target="#b19">[20]</ref>. The proposed architecture of our models comes in three main steps.</p><p>Step 1 -Text Vectorization Module: It is considered as language modeling step. The input of this step is the textual training datasets and the output is text vectorization model.</p><p>Step 2 -Mood Evaluation Module: This step is considered as the first supervised learning phase. Assign to each writing a probability like score representing how positive (risky) the submission is. The output of this step is a time series representing the mood variability over time. These time series will be the training set of the second learning phase.</p><p>Step 3 -Temporal Modeling Module: Another learning phase is to build machine learning models to learn some patterns from these time series to come up with the final classification model.</p><p>We tried to encapsulate text vectorization and mood evaluation modules and proposed Deep Mood Evaluation Module (DMEM). This module is based on ULMFiT architecture <ref type="bibr" coords="5,231.40,526.89,10.52,8.74" target="#b6">[7]</ref> and the idea of transfer learning for language modeling in addition to using attention layers for classifications. In addition, we tried Bayesian Variational Inference (BVI) <ref type="bibr" coords="5,299.81,550.80,15.50,8.74" target="#b20">[21]</ref> for the second learning phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Deep Mood Evaluation Module (DMEM)</head><p>We propose a modification of the basic architecture of the ULMFiT by adding attention to the model. The proposed architecture will help the model to focus on the important parts of the text that influence the network decision. Figure <ref type="figure" coords="5,134.77,632.21,4.98,8.74" target="#fig_0">1</ref> shows the proposed model and the separation between encoder layers (text vectorization module) and classifier layers (mood evaluation module).</p><p>The input sequence is passed to the embedding layer then the three Bi-LSTM layers to form the output of the encoder. The encoder output has the form of</p><formula xml:id="formula_0" coords="6,134.77,141.33,111.15,12.48">X i = {x i 1 , x i 2 , x i 3 , . . . , x i N }</formula><p>where N is the sequence length. The attention layer takes the encoded input sequence and computes the attention scores S i . The attention layer can be viewed as a linear layer without bias.</p><formula xml:id="formula_1" coords="6,255.46,195.82,225.13,44.44">α i = {W i .X i } S i = log[ exp(α i ) N j=1 exp(α i j ) ]<label>(1)</label></formula><p>Where W i is the weight of the attention layer of the i th sequence. The attention scores S i is used to compute the scored sequence</p><formula xml:id="formula_2" coords="6,374.11,262.70,96.76,12.20">O i = {o i 1 , o i 2 , o i 3 , . . . , o i</formula><p>N } which has the same length as the input sequence.</p><formula xml:id="formula_3" coords="6,278.18,295.51,202.42,10.81">O i = S i X i<label>(2)</label></formula><p>Since the input sequence to the attention layer (encoder output) resulted from Bi-LSTM layers, the last element in the scored output S i N can be used for representing the whole sequence. The whole sequence is represented by the weighted sum of all output sequences Ōi . For classification layers, a simple concatenation between the maximum and average pooling in addition to the scored output is inputted to a group of two different sizes fully connected linear layers. The output of the last linear layer is passed to the Softmax to form the network decision.</p><formula xml:id="formula_4" coords="6,269.87,376.19,210.72,22.58">Ōi = &lt;N &gt; S i X i<label>(3)</label></formula><p>Training the over whole models comes into three main steps proposed in <ref type="bibr" coords="7,467.31,143.69,9.96,8.74" target="#b6">[7]</ref>.</p><p>1. The LM is initialized by training the encoder on a general-domain corpus (Wikitext-103 dataset <ref type="bibr" coords="7,252.79,178.73,14.76,8.74" target="#b22">[23]</ref>). This helps to capture general features of the language. Preserve low-level representations and adapt high-level ones 2. The pre-trained LM is fine-tuned using the training datasets for both tasks. 3. The classifier and the encoder is fine-tuned on the target task using different strategies for each layer group.</p><p>The training of the architecture is done using slanted triangular learning rates (STLR), discriminative fine-tuning (Discr) and layers gradual unfreezing proposed for ULMFiT with the same hyperparameter settings <ref type="bibr" coords="7,404.74,274.33,9.96,8.74" target="#b6">[7]</ref>. We train the model on the forward language models for both the general-domain and task specific datasets. Training the attention layer uses the same learning rates and cycles used in the classification layers group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bayesian Variational Inference (BVI)</head><p>We can represent the problem of classifying users from the already classified (observed) writings as a variant of independent Bayesian classifier combination <ref type="bibr" coords="7,134.77,391.81,14.61,8.74" target="#b20">[21]</ref>. Figure <ref type="figure" coords="7,185.63,391.81,4.98,8.74" target="#fig_1">2</ref> shows the graphical model for the proposed BVI where the observed random variable W k i represents if the i th writing for the k th user if it is classified as positive or negative such that: </p><formula xml:id="formula_5" coords="8,261.82,137.56,218.77,26.67">W k i ∼ Bernoulli(π u k ) π i ∼ Beta(λ, γ)<label>(4)</label></formula><p>The hidden variable u k represents if the user will be classified as at-risk (anorexia, self-harm) or not. So we can say:</p><formula xml:id="formula_6" coords="8,269.12,221.46,211.47,23.68">u k ∼ Bernoulli(κ) κ ∼ Beta(α, β)<label>(5)</label></formula><p>The variables λ, γ, α and β are the hyper-parameters reflecting our a priori belief about the proportion of positive and negative users. We are interested in the posterior distribution of the random variable U k , that defines if the user is positive or negative, which is unfortunately intractable. We use a variational inference approach to compute an approximation such as in <ref type="bibr" coords="8,146.52,318.73,14.61,8.74" target="#b20">[21]</ref>. The approximation is obtained by solving the following equation for all variables Z i conditionned on the observed data X:</p><formula xml:id="formula_7" coords="8,218.18,353.33,262.42,9.65">log q i (Z i |X) = E j =i [log p(Z, X)] + const.<label>(6)</label></formula><p>So, we start from a number of positive and negative user writings (N d ) where d ∈ {+, -} for positives and negatives respectively. More specifically:</p><formula xml:id="formula_8" coords="8,205.93,411.58,274.66,22.21">N + = k,i 1[W k i = 1], N -= k,i 1[W k i = 0]<label>(7)</label></formula><p>Then, the expected number of positive and negative writings for positive users can be represented by N + 1 and N - 1 respectively. The same for negative users is N + 0 and N - 0 . These values are computed as:</p><formula xml:id="formula_9" coords="8,181.99,489.98,298.60,22.21">N d r = k,i E[1[uk = d]].[1[w k i = r]], d ∈ {+, -}, r ∈ {0, 1}<label>(8)</label></formula><p>We can estimate the expectation of the log of the probability to observe positive writings independently of the user category as E[ln(κ)] and for negative writings as E[ln(1 -κ)] such that:</p><formula xml:id="formula_10" coords="8,197.33,579.62,283.26,28.31">E[ln(κ)] = ψ(α + N + ) -ψ(α + β + N + + N -) E[1 -ln(κ)] = ψ(β + N -) -ψ(α + β + N + + N -) (9)</formula><p>Where ψ is the digamma function defined as the logarithmic derivative of the gamma function. In addition, we can estimate the expectation of the log probability for positive users to write positive writings as E[ln(π1)] and for negative users as E[ln(π0)] where:</p><formula xml:id="formula_11" coords="9,196.52,136.42,284.07,29.31">E[ln(πi)] = ψ(λ + N + i ) -ψ(λ + γ + N + i + N - i ) E[1 -ln(π i )] = ψ(γ + N - i ) -ψ(λ + γ + N + i + N - i )<label>(10)</label></formula><p>So, the expectation of a user to be positive or negative can be obtained as:</p><formula xml:id="formula_12" coords="9,186.89,207.30,293.70,76.78">ln(ρ k j ) = M k i W k i E[ln(πj)] + (1 -W k i ) E[ln(1 -π j )] + (α -1) E[ln(κ)] + (β -1) E[ln(1 -κ)] E[1[Uk = j]] = ρ k i j ρ k i<label>(11)</label></formula><p>Where E[1[Uk = j]] is a normalized value for the two types of users (at-risk or controlled). We can evaluate an optimal value for it iteratively by first initializing all factors, then updating each in turn using the expectations with respect to the current values of the other factors <ref type="bibr" coords="9,303.25,331.69,14.61,8.74" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>For each task, each team could participate with different five runs. We create different variants of our proposed architecture. In this section, we will present all these variants, training procedures and model hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Proposed Model Variants</head><p>All the proposed model variants for both tasks are based on two supervised learning phases (step 2 and step 3 in temporal mood variation model). For selfharm detection task (T2), as there is no training data, we train our models on the depression and anorexia datasets of eRisk-2018 <ref type="bibr" coords="9,381.01,498.16,14.61,8.74" target="#b11">[12]</ref>. We assumed that if a person with a clear signs of depression and/or anorexia could think about harm himself. We used the DMEM module as the first learning phase an all the variants and tried different machine learning and statistical methods as the second learning phase. Table <ref type="table" coords="9,266.92,545.98,4.98,8.74" target="#tab_1">2</ref> shows the used model for the second learning phase in all the runs for both tasks. MLP stands for Multi-Layer Perceptrons and RF is for Random Forest. All models that do not employ another learning phase are marked by dashes. In these runs, we used simple counting thresholds for successive positive classified writings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model Training and hyperparameters</head><p>We processed the training and testing streams of user writings by moving window concatenation of size (N ). In other words, to give a decision about the current writing at time (t), we process all user writing starting from (t -N + 1). This gives more information about the context of a writing and reduce the effect of noisy and irrelevant ones. Experiments show that (N = 5) to be a reasonable choice for the window size.</p><p>For DMEM, we use the same set of hyperparameter of AWD-LSTM proposed by <ref type="bibr" coords="10,148.08,355.35,15.50,8.74" target="#b14">[15]</ref> replacing the LSTM with Bi-LSTM and keep the same embedding size of 400 and 1150 hidden activations. We used weighted dropout of 0.2 and 0.25 as the input embedding dropout and the learning rate is 0.004. We fine-tuned the LM by eithr anorexia or depression training datasets provided. We train the LM for 14 epochs using batch size of 128 and limit the number of vocabulary to all token that appear more than twice. For classifier, we used masked self-attention layers and concatenation of maximum and average pooling. For the linear block, we used hidden linear layer of size 100 and apply dropout of 0.4. We used Adam optimizer <ref type="bibr" coords="10,232.88,450.99,10.52,8.74" target="#b3">[4]</ref> with β 1 = 0.8 and β 2 = 0.99. The base learning rate is 0.01. We used the same batch size used in training LMs. For training the classifier, we create each batch using weight random sampling to handle the problem of imbalance in the datasets. We train the classifier on training set for 30 epochs and select the best model on validation set to get the final model. For T2 training, we combine the training datasets for depression and anorexia of eRisk-2018.</p><p>In the second learning phase, the used architecture of the MLP had two hidden layers with ten neurons each. Concerning the RF classifier, ten estimators were used. These models are used to classify time series of (N ) points. For MLP, RF and BVI models in T1, positive users were reported for those with classification probability higher than 0.8. This value increases to 0.9 in T2. We set both thresholds to 0.6 in the last rounds. For some model variants (LIRMMC and LIRMMD in T1 and LIRMMA and LIRMMB in T2), we apply counting of successive positive writings and give a decision after either 5 or 10 following writings respectively.</p><p>In eRisk-2019 two different types are used for model evaluation. The first one is decision-based evaluations; where the classical classification measures -precision (P), Recall (R) and (F1) -are computed for positive (at-risk) user. In addition to these and due to the drawbacks of ERDE measure, a new latency weighted F1 measure is introduced <ref type="bibr" coords="11,248.37,186.84,14.61,8.74" target="#b12">[13]</ref>. The other complementary evaluation is rankingbased evaluation. Beside the fired decision, scores are computed and used to build a ranking of users in decreasing estimation of risk. We participated only for decision-based evaluation. Tables <ref type="table" coords="11,303.87,222.70,4.98,8.74" target="#tab_2">3</ref> and<ref type="table" coords="11,334.77,222.70,4.98,8.74" target="#tab_3">4</ref> show the evaluation results of all our proposed variants for both tasks. It is clear that using MLP for the second learning phase is the best choice for both tasks. However, the usage of high threshold in T2 make the models predict most of the positive user in late writings. Also, applying BVI gets more comparable results than the runs with simple counting of positive writings. But it needs more precise choice of threshold for early detection in both tasks. Tables <ref type="table" coords="11,181.30,572.43,4.98,8.74" target="#tab_4">5</ref> and<ref type="table" coords="11,209.51,572.43,4.98,8.74" target="#tab_5">6</ref> show some statistics of other participants runs compared to our proposed models. The ranks of the best run for each evaluation metric are also included. The statistics of the anorexia task are for 54 runs of 13 teams. The self-harm task statistics on results are for 33 runs of 8 teams. However the proposed architecture does not include any hand-crafted features, it seems to be comparable with other contributions for both tasks. Also, combining anorexia and past eRisk depression training datasets for detecting signs of self-harm is very competitive. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper we present the participation of LIRMM in the CLEF eRisk-2019 T1 and T2 tasks. Both tasks are for early detection of signs of anorexia and self-harm from users posts on Reddit respectively. We proposed five runs for each task and the results are interesting and comparable to other contributions. The proposed framework architecture used the text without any handcrafted features. It performs the classification through two phases of supervised learning using state-of-the-art deep language modeling neural network. The first learning phase builds a time series representing the mood variation using attention-based modification of the ULMFiT model. The second learning phase is another classification model that learns patterns from these time series to detect early signs of such mental disorders. In this phase, We tried set of machine learning (MLP and RF) and statistical (BVI) models.</p><p>Combining anorexia and previous eRisk depression datasets to detect early signs of self-harm (T2) is interesting and shows the correlation of such mental disorders. However, the proposed models need tuning of second learning phase classification thresholds for earlier risk detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,210.47,611.19,194.42,7.86"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Deep Mood Evaluation Module (DMEM)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,150.15,631.59,315.05,7.86;7,134.77,642.55,345.83,7.86;7,290.11,653.51,35.15,7.86"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Graphical Model for BVI: The shaded node represents observed values, circular nodes are variables with a distribution and rectangular nodes are instantiated variables</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,137.55,117.38,330.33,99.02"><head>Table 1 :</head><label>1</label><figDesc>Summary of early risk detection tasks (T1 and T2) Datasets</figDesc><table coords="5,296.22,142.09,162.09,18.87"><row><cell>T1</cell><cell></cell><cell>T2</cell></row><row><cell>Training</cell><cell>Testing</cell><cell>Testing</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,201.69,117.38,207.06,96.87"><head>Table 2 :</head><label>2</label><figDesc>Summary of the proposed model variants</figDesc><table coords="10,201.69,138.22,203.91,76.03"><row><cell></cell><cell></cell><cell cols="2">2 nd Learning Phase</cell></row><row><cell>Run ID</cell><cell>Model Name</cell><cell>T1</cell><cell>T2</cell></row><row><cell>0</cell><cell>LIRMMA</cell><cell>MLP</cell><cell>--</cell></row><row><cell>1</cell><cell>LIRMMB</cell><cell>RF</cell><cell>--</cell></row><row><cell>2</cell><cell>LIRMMC</cell><cell>--</cell><cell>MLP</cell></row><row><cell>3</cell><cell>LIRMMD</cell><cell>--</cell><cell>RF</cell></row><row><cell>4</cell><cell>LIRMME</cell><cell>BVI</cell><cell>BVI</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,174.36,325.45,261.55,88.06"><head>Table 3 :</head><label>3</label><figDesc>Results of proposed runs for anorexia task (T1)</figDesc><table coords="11,174.36,350.16,261.55,63.36"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>latency-weighted F1</cell></row><row><cell>LIRMMA</cell><cell>0.74</cell><cell>0.63</cell><cell>0.68</cell><cell>0.63</cell></row><row><cell>LIRMMB</cell><cell>0.77</cell><cell>0.60</cell><cell>0.68</cell><cell>0.62</cell></row><row><cell>LIRMMC</cell><cell>0.66</cell><cell>0.70</cell><cell>0.68</cell><cell>0.60</cell></row><row><cell>LIRMMD</cell><cell>0.74</cell><cell>0.42</cell><cell>0.54</cell><cell>0.48</cell></row><row><cell>LIRMME</cell><cell>0.57</cell><cell>0.75</cell><cell>0.65</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,174.36,458.48,261.55,88.06"><head>Table 4 :</head><label>4</label><figDesc>Results of proposed runs for self-harm task (T2)</figDesc><table coords="11,174.36,483.18,261.55,63.36"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>latency-weighted F1</cell></row><row><cell>LIRMMA</cell><cell>0.57</cell><cell>0.29</cell><cell>0.39</cell><cell>0.35</cell></row><row><cell>LIRMMB</cell><cell>0.53</cell><cell>0.22</cell><cell>0.31</cell><cell>0.29</cell></row><row><cell>LIRMMC</cell><cell>0.48</cell><cell>0.49</cell><cell>0.48</cell><cell>-</cell></row><row><cell>LIRMMD</cell><cell>0.47</cell><cell>0.44</cell><cell>0.46</cell><cell>-</cell></row><row><cell>LIRMME</cell><cell>0.52</cell><cell>0.41</cell><cell>0.46</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,154.77,117.38,300.75,88.46"><head>Table 5 :</head><label>5</label><figDesc>Statistics on 54 participating runs results and our ranks for T1</figDesc><table coords="12,154.77,142.09,300.75,63.75"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>latency-weighted F1</cell></row><row><cell>Max</cell><cell>0.77</cell><cell>0.99</cell><cell>0.71</cell><cell>0.69</cell></row><row><cell>Min</cell><cell>0.11</cell><cell>0.15</cell><cell>0.20</cell><cell>0.19</cell></row><row><cell>Average</cell><cell>0.45</cell><cell>0.63</cell><cell>0.48</cell><cell>0.46</cell></row><row><cell>Standard Deviation</cell><cell>0.17</cell><cell>0.24</cell><cell>0.17</cell><cell>0.15</cell></row><row><cell>Rank</cell><cell>1</cell><cell>14</cell><cell>5</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,154.77,224.86,300.75,88.46"><head>Table 6 :</head><label>6</label><figDesc>Statistics on 33 participating runs results and our ranks for T2</figDesc><table coords="12,154.77,249.56,300.75,63.75"><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>latency-weighted F1</cell></row><row><cell>Max</cell><cell>0.71</cell><cell>1.00</cell><cell>0.52</cell><cell>0.52</cell></row><row><cell>Min</cell><cell>0.12</cell><cell>0.22</cell><cell>0.22</cell><cell>0.17</cell></row><row><cell>Average</cell><cell>0.29</cell><cell>0.73</cell><cell>0.32</cell><cell>0.29</cell></row><row><cell>Standard Deviation</cell><cell>0.18</cell><cell>0.29</cell><cell>0.11</cell><cell>0.10</cell></row><row><cell>Rank</cell><cell>3</cell><cell>17</cell><cell>3</cell><cell>4</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,634.88,335.87,7.86;2,144.73,645.84,335.86,7.86;2,144.73,656.80,221.37,7.86"><p>Reddit is an open-source platform where community members (red-ditors) can submit content (posts, comments, or direct links), vote submissions, and the content entries are organized by areas of interests (subreddits).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to acknowledge <rs type="institution">La Région Occitanie</rs> and <rs type="institution">l'Agglomération Béziers Méditerranée</rs> which finance the thesis of <rs type="person">Waleed Ragheb</rs> as well as <rs type="funder">INSERM</rs> and <rs type="funder">CNRS</rs> for their financial support of <rs type="projectName">CONTROV</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_5Tem3Tz">
					<orgName type="project" subtype="full">CONTROV</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,139.63,337.63,7.86;13,151.52,150.59,329.07,7.86;13,151.52,161.55,60.77,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,151.53,139.63,329.06,7.86;13,151.52,150.59,62.26,7.86">The national eating disorders association (NEDA).: Envisioning a world without eating disorders</title>
	</analytic>
	<monogr>
		<title level="j" coord="13,234.61,150.59,241.92,7.86">The newsletter of the National Eating Disorders Association</title>
		<imprint>
			<biblScope unit="issue">22</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,171.92,337.63,7.86;13,151.52,182.88,329.07,7.86;13,151.52,193.84,156.20,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,296.12,171.92,184.47,7.86;13,151.52,182.88,87.28,7.86">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,260.67,182.88,219.92,7.86;13,151.52,193.84,27.64,7.86">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014-09">Sep 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,204.21,337.63,7.86;13,151.52,215.16,329.07,7.86;13,151.52,226.10,198.59,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,324.45,204.21,156.14,7.86;13,151.52,215.16,248.87,7.86">Self-harm in young people: Prevalence, associated factors, and help-seeking in school-going adolescents</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M P</forename><surname>Treacy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,406.73,215.16,73.86,7.86;13,151.52,226.12,113.99,7.86">International journal of mental health nursing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="485" to="494" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,236.49,337.64,7.86;13,151.52,247.45,108.07,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="13,261.33,236.49,215.28,7.86">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>abs/1611.01734</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,257.82,337.63,7.86;13,151.52,268.78,329.07,7.86;13,151.52,279.71,135.79,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,305.28,257.82,175.30,7.86;13,151.52,268.78,250.40,7.86">Suicide following deliberate self-harm: longterm follow-up of patients who presented to a general hospital</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hawton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weatherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,408.90,268.78,71.69,7.86;13,151.52,279.74,42.94,7.86">British Journal of Psychiatry</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">537542</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,290.10,337.64,7.86;13,151.52,301.06,149.18,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,193.79,290.10,233.48,7.86">Review of the worldwide epidemiology of eating disorders</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,449.06,290.10,31.54,7.86;13,151.52,301.06,86.75,7.86">Current Opinion in Psychiatry</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,311.43,337.64,7.86;13,151.52,322.39,329.07,7.86;13,151.52,333.35,229.92,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,243.16,311.43,233.88,7.86">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,165.46,322.39,315.14,7.86;13,151.52,333.35,43.24,7.86">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="13,142.96,343.72,337.63,7.86;13,151.52,354.68,329.07,7.86;13,151.52,365.63,158.63,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,265.31,343.72,215.28,7.86;13,151.52,354.68,192.68,7.86">The diagnostic and statistical manual of mental disorders: Fifth edition (dsm-5) model of impairment</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Joyce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sulkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,365.80,354.68,114.80,7.86;13,151.52,365.63,74.82,7.86">Assessing Impairment: From Theory to Practice</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="167" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,376.00,337.63,7.86;13,151.52,386.94,329.07,7.89;13,151.52,397.92,166.99,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,231.67,376.00,248.92,7.86;13,151.52,386.96,73.55,7.86">The functions of deliberate self-injury: A review of the evidence</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Klonsky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpr.2006.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.cpr.2006.08.002" />
	</analytic>
	<monogr>
		<title level="j" coord="13,239.52,386.96,121.21,7.86">Clinical psychology review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="226" to="239" />
			<date type="published" when="2007-04">04 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,408.29,337.97,7.86;13,151.52,419.25,329.07,7.86;13,151.52,430.21,69.77,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,248.29,408.29,227.74,7.86">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target=".org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,165.79,419.25,214.61,7.86">ICML. JMLR Workshop and Conference Proceedings</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,440.57,337.97,7.86;13,151.52,451.53,329.07,7.86;13,151.52,462.49,224.54,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,310.44,440.57,170.14,7.86;13,151.52,451.53,167.21,7.86">erisk 2017: Clef lab on early risk prediction on the internet: Experimental foundations</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,339.40,451.53,141.20,7.86;13,151.52,462.49,72.45,7.86">8th International Conference of the CLEF Association</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="346" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,472.86,337.97,7.86;13,151.52,483.82,329.07,7.86;13,151.52,494.78,329.07,7.86;13,151.52,505.74,203.11,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,317.97,472.86,162.62,7.86;13,151.52,483.82,81.07,7.86">Overview of eRisk -Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,255.27,483.82,225.33,7.86;13,151.52,494.78,329.07,7.86;13,151.52,505.74,101.08,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018)</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,516.10,337.98,7.86;13,151.52,527.06,329.07,7.86;13,151.52,538.02,329.07,7.86;13,151.52,548.98,275.83,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,315.66,516.10,164.93,7.86;13,151.52,527.06,88.92,7.86">Overview of eRisk 2019: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,260.50,527.06,220.09,7.86;13,151.52,538.02,329.07,7.86;13,151.52,548.98,16.79,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 10th International Conference of the CLEF Association, CLEF 2019</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,559.35,337.98,7.86;13,151.52,570.31,329.07,7.86;13,151.52,581.27,329.07,7.86;13,151.52,592.23,329.07,7.86;13,151.52,603.18,120.53,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,445.11,559.35,35.48,7.86;13,151.52,570.31,142.14,7.86">Learning word vectors for sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,315.39,570.31,165.21,7.86;13,151.52,581.27,329.07,7.86;13,261.93,592.23,33.78,7.86">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
	<note>HLT &apos;11</note>
</biblStruct>

<biblStruct coords="13,142.61,613.55,337.97,7.86;13,151.52,624.51,294.39,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,299.49,613.55,181.10,7.86;13,151.52,624.51,26.15,7.86">Regularizing and optimizing LSTM language models</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,199.19,624.51,218.05,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,634.88,337.97,7.86;13,151.52,645.84,329.07,7.86;13,151.52,656.80,204.75,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,407.41,634.88,73.17,7.86;13,151.52,645.84,231.41,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,403.01,645.84,77.58,7.86;13,151.52,656.80,128.10,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,119.67,337.97,7.86;14,151.52,130.63,329.07,7.86;14,151.52,141.59,329.07,7.86;14,151.52,152.55,322.43,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,294.01,119.67,186.58,7.86;14,151.52,130.63,59.42,7.86">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">W T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,234.09,130.63,246.50,7.86;14,151.52,141.59,329.07,7.86;14,151.52,152.55,115.57,7.86">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT-2013)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT-2013)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,163.51,337.97,7.86;14,151.52,174.47,329.07,7.86;14,151.52,185.43,329.07,7.86;14,151.52,196.39,98.81,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,283.98,163.51,196.61,7.86;14,151.52,174.47,127.95,7.86">Dare to care: A context-aware framework to track suicidal ideation on social media</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Moulahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Azé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bringay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="14,295.53,185.43,138.18,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Bouguettaya</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page">10570</biblScope>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>Springer</publisher>
		</imprint>
		<respStmt>
			<orgName>Web Information Systems Engineering -WISE</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,207.34,337.97,7.86;14,151.52,218.30,329.07,7.86;14,151.52,229.26,49.91,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="14,255.15,207.34,225.44,7.86;14,151.52,218.30,23.70,7.86">You are what you tweet: Analyzing twitter for public health</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<editor>Adamic, L.A., Baeza-Yates, R.A., Counts, S.</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>The AAAI Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,240.22,337.97,7.86;14,151.52,251.18,329.07,7.86;14,151.52,262.14,329.07,7.86;14,151.52,273.10,194.22,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,415.36,240.22,65.23,7.86;14,151.52,251.18,325.29,7.86">Temporal mood variation: at the CLEF erisk-2018 tasks for early risk detection on the internet</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Moulahi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Azé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bringay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,165.36,262.14,310.42,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">September 10-14, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,284.06,337.97,7.86;14,151.52,295.02,329.07,7.86;14,151.52,305.98,214.92,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,354.34,284.06,126.25,7.86;14,151.52,295.02,125.18,7.86">Dynamic bayesian combination of multiple imperfect classifiers</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Psorakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,297.75,295.02,138.23,7.86">Decision Making and Imperfection</title>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,316.93,337.97,7.86;14,151.52,327.89,329.07,7.86;14,151.52,338.85,329.07,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,310.57,316.93,170.02,7.86;14,151.52,327.89,210.69,7.86">Linguistic metadata augmented classifiers at the clef 2017 task for early detection of depression</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trotzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Friedrich</surname></persName>
		</author>
		<idno>CEUR-WS 1866</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,382.97,327.89,97.62,7.86;14,151.52,338.85,210.22,7.86">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,349.81,337.97,7.86;14,151.52,360.77,329.07,7.86;14,151.52,371.73,228.94,8.12" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,345.04,349.81,135.55,7.86;14,151.52,360.77,89.78,7.86">Identifying generalization properties in neural networks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJxOHs0cKm" />
	</analytic>
	<monogr>
		<title level="m" coord="14,262.64,360.77,217.95,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
