<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.73,115.96,317.91,12.62;1,143.16,133.89,329.04,12.62;1,252.85,151.82,109.64,12.62">UNSL at eRisk 2019: a Unified Approach for Anorexia, Self-harm and Depression Detection in Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,147.31,189.89,81.46,8.74"><forename type="first">Sergio</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
							<email>sburdisso@unsl.edu.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ejército de Los Andes 950, San Luis</addrLine>
									<postCode>5700</postCode>
									<settlement>San Lius</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)</orgName>
								<address>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.66,189.89,79.10,8.74"><forename type="first">Marcelo</forename><surname>Errecalde</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<addrLine>Ejército de Los Andes 950, San Luis</addrLine>
									<postCode>5700</postCode>
									<settlement>San Lius</settlement>
									<region>C.P</region>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.69,189.89,108.87,8.74"><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="institution" key="instit1">Instituto Nacional de Astrofísica</orgName>
								<orgName type="institution" key="instit2">Luis</orgName>
								<address>
									<addrLine>Enrique Erro No. 1, Sta. Ma. Tonantzintla</addrLine>
									<postCode>72840</postCode>
									<settlement>Puebla</settlement>
									<region>C.P</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.73,115.96,317.91,12.62;1,143.16,133.89,329.04,12.62;1,252.85,151.82,109.64,12.62">UNSL at eRisk 2019: a Unified Approach for Anorexia, Self-harm and Depression Detection in Social Media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9154E6F8E55A8421EDA60217C1993267</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>SS3</term>
					<term>Early Risk Detection</term>
					<term>Text Classification</term>
					<term>Early Classification.</term>
					<term>Text Streams Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the participation of our research group at the CLEF eRisk 2019. The eRisk goal is the early detection of atrisk people by means of machine learning techniques based on language usage. This year eRisk edition was divided into three tasks, T1, T2, and T3. The first two were focused on early detection of anorexia and self-harm on Reddit users. T3 focused on measuring users' severity of depression. To carry out this task, models had to automatically fill the standard BDI depression questionnaire based on the evidence found in the user's history of postings. We used the same classifier, SS3, to carry out these three tasks with the same hyper-parameters configuration. SS3 is a recently introduced text classifier[1] that was created with the goal to deal with early risk detection scenarios in an integrated manner: it naturally supports incremental and early classification over text streams and additionally, it has the ability to visually explain its rationale. The final results for all these three tasks show that SS3 is a very robust and efficient classifier. SS3 was the fastest method and obtained the best ERDE and overall best ranking-based measures in all the tasks. Additionally, it obtained the best P recision, F 1 and F 1 latency for task T2. Finally, in task T3, it obtained the best AHR and ACR values, and the second-best ADODL and DCHR. This was quite remarkable taking into account that the same classifier was used here to fill users' BDI questionnaires, which is a task completely different from the other two "yes or no" tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The detailed description of each task and the used performance measures, and full lists of results are given in <ref type="bibr" coords="2,272.54,155.63,9.96,8.74" target="#b3">[4]</ref>. Therefore, this paper will only focus on describing how we approached each task. All contributions we sent to the eRisk 2019 were implemented using a novel text classifier called SS3 which was recently introduced in <ref type="bibr" coords="2,195.09,191.49,9.96,8.74" target="#b0">[1]</ref>. SS3 was specially built to deal with early risk detection (ERD) tasks in an integrated manner since it naturally supports these 3 key aspects: (a) incremental training and classification; (b) early classification; and (c) having the ability to visually explain its rationale (i.e. provide the reasons for the classification). SS3 is a generalization of the classifier we used in the last year eRisk <ref type="bibr" coords="2,452.99,239.31,12.84,8.74" target="#b2">[3]</ref> for UNSLD and UNSLE runs. This year we decided not to use other models other than SS3 because of the change in the way data was released, i.e. a more realistic item-by-item release of data. The other models we used last year based on TVT <ref type="bibr" coords="2,150.95,287.13,16.19,8.74" target="#b1">[2]</ref> were no longer applicable since they were designed to work with chunks and not text streams. Additionally, this year we decided to put the robustness of SS3 into the test by using the same hyper-parameter configuration in all the 15 runs for the 3 tasks (T1, T2, and T3). Thus, the hyper-parameters values were set to λ = ρ = 1 and σ = 0.455, which were the same values used in <ref type="bibr" coords="2,467.31,334.96,9.96,8.74" target="#b0">[1]</ref>, and for which SS3 has shown to be quite robust in terms of ERDE performance measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The SS3 Text Classifier</head><p>As it is described in more details in <ref type="bibr" coords="2,290.24,416.19,9.96,8.74" target="#b0">[1]</ref>, SS3 first builds a dictionary of words for each category during the training phase, in which the frequency of each word is stored. Then, using those word frequencies, and during the classification stage, it calculates a value for each word using a function gv(w, c) to value words in relation to categories. gv takes a word w and a category c and outputs a number in the interval [0,1] representing the degree of confidence with which w is believed to exclusively belong to c, for instance, suppose categories C = {f ood, music, health, sports}, we could have: gv('sushi', f ood) = 0.85; gv('the', f ood) = 0; gv('sushi', music) = 0.09; gv('the', music) = 0; gv('sushi', health) = 0.50; gv('the', health) = 0; gv('sushi', sports) = 0.02; gv('the', sports) = 0; Additionally, a vectorial version of gv is defined as:</p><p>-→ gv(w) = (gv(w, c 0 ), gv(w, c 1 ), . . . , gv(w, c k )) where c i ∈ C (the set of all the categories). That is, -→ gv is only applied to a word and it outputs a vector in which each component is the gv of that word for each category c i . For instance, following the above example, we have: gv('sushi') = (0.85, 0.09, 0.5, 0.02); gv('the') = (0, 0, 0, 0);</p><p>The vector -→ gv(w) is called the "confidence vector of w". Note that each category c i is assigned a fixed position in -→ gv. For instance, in the example above (0.85, 0.09, 0.5, 0.02) is the confidence vector of the word "sushi" and the first position corresponds to f ood, the second to music, and so on.</p><p>It is worth mentioning that the computation of gv involves three functions, lv, sg and sn, as follows:</p><formula xml:id="formula_0" coords="3,219.27,243.19,176.81,9.65">gv(w, c) = lv σ (w, c) • sg λ (w, c) • sn ρ (w, c)</formula><p>lv σ (w, c) values a word based on the local frequency of w in c. As part of this process, the word distribution curve is smoothed by a factor controlled by the hyper-parameter σ. sg λ (w, c) captures the global significance of w in c, it decreases its value in relation to the lv value of w in the other categories; the hyper-parameter λ controls how far the local value must deviate from the median to be considered significant. sn ρ (w, c) sanctions lv in relation to how many other categories w is significant (sg λ (w, c) ≈ 1) to. That is, The more categories c i whose sg λ (w, c i ) is high, the smaller the sn ρ (w, c) value. The ρ hyper-parameter controls how sensitive this sanction is.</p><p>For those readers interested in how these functions are actually computed, we highly recommend you to read the SS3 original paper <ref type="bibr" coords="3,363.16,418.91,12.65,8.74" target="#b0">[1]</ref>, since the equations for lv, sg and sn are not given here to keep the present paper shorter and simpler. Note that using the gv function, it is quite straightforward for SS3 to visually justify its decisions if different blocks of the input are colored in relations to it, as can be seeing on an online demo available at http://tworld.io/ss3 in which users can try out SS3 for topic categorization. This is quite relevant when it comes to early detection tasks in which usually real people are involved, specialists should be able to manually analyze classified subjects and this type of visual tools could be really helpful to assist those specialists.</p><p>For all 3 tasks T1, T2 and T3 we carried out the classification of each user, incrementally as in <ref type="bibr" coords="3,221.35,552.67,9.96,8.74" target="#b0">[1]</ref>. That is, the used summary operators for all levels were the addition, .i.e ⊕ j = addition for all j, which simplified the classification process to the summation of all words' -→ gv vectors read so far, in symbols, for every subject s:</p><formula xml:id="formula_1" coords="3,267.38,605.66,213.21,26.98">- → d s = w∈W Hs -→ gv(w)<label>(1)</label></formula><p>where W H s is the subject's writing history. Note that for all the tasks -→ d s was a vector with two components, one for the positive class and the other for the   Finally, this year, models performance were also evaluated based on rankingbased measures for tasks T1 and T2. Thus, models were asked to provide an estimated score of the level of anorexia/self-harm along with the binary decision (0/1). To compute this score, SS3 performed the difference between the positive confidence value and the negative one (i.e. d[positive]-d[negative]) and returned it along with each decision. For example, in Figure <ref type="figure" coords="5,366.41,215.30,4.98,8.74" target="#fig_1">2</ref> is shown how this score changed as more writings were read, for the same user shown previously in Figure <ref type="figure" coords="5,166.20,239.21,3.87,8.74" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task 1: Early Detection of Signs of Anorexia</head><p>As mentioned earlier, we used the same classifier with the same hyper-parameters for these 5 runs, and instead, we mostly focused on changing aspects related to how we trained our models. For each one of the 5 runs, we performed the following:</p><p>-UNSL#0 : we trained the model using only the data in the "train" folder, i.e. we trained the model using the same data as for the eRisk 2018. -UNSL#1 : the same as with the previous one but this time allowing SS3 to compute the global value not only for words but also for pair of words (bigrams), i.e. SS3 learned to compute gv(w 0 , c) as well as gv(w 0 w 1 , c) for each w 0 , w 1 seen during training. -UNSL#2 : the same as run#0 but training with all available data for training this year, i.e. all the data in both "train" and "test" folders. -UNSL#3 : the same as in the previous run, but this time also taking into account bigrams of words (as in run#1). -UNSL#4 : the same as in run#2 but letting SS3 to take into account only words whose global value where greater than 0.3, i.e in Equation 1 SS3 assigned gv(w, c i ) = 0 to all w and c i such that gv(w, c i ) &lt; 0.3.</p><p>The main global results obtained in this task could be summarized as follows:</p><p>-As it is shown in Table <ref type="table" coords="5,252.18,553.64,3.87,8.74" target="#tab_0">1</ref>, UNSL#0 obtained the best ERDE 5 and UNSL#4 the best ERDE 50 . Note that most of the ERDE values are relatively close to each other, this is due to the way ERDE was computed. <ref type="foot" coords="5,409.02,575.98,3.97,6.12" target="#foot_1">5</ref> The larger and more unbalanced the dataset is, the asymptotically flatter and closer the Table <ref type="table" coords="6,162.60,388.57,3.87,8.74">2</ref>: Participating teams for Task 1: number of runs, number of user writings processed by the team, and the time taken for the whole process and for processing each writing (i.e</p><p>T otalT ime #writings×#runs ). (*) This value was originally 5, but we replaced it by the actual number of models used. ERDE values are (as it was with this task). Thus, decimals do matter a lot when it comes to ERDE measure. For instance, in this task, just a small difference of 0.009 (0.9%) in ERDE actually means that 12% of either all Table <ref type="table" coords="7,162.25,127.36,3.87,8.74">3</ref>: Ranking-based evaluation results for Task 1. Here it is shown the best results for SS3, UNSL #2 and #4, along with the other 3 best ones, LTL-INAOE and UDE #0 and #1.</p><p>1 writing 100 writing Team#run P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 UNSL#2</p><p>.8 .82</p><p>. .81 500 writing 1000 writing Team#run P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 UNSL#2 anorexic users or non-anorexic ones were not properly classified, which is a significant difference. -Regarding the new F 1 latency , we did not obtain remarkable results, being 0.13 points below the best one. This is mainly due to this new measure being introduced this year and only after the tasks ended. Therefore, SS3 could not be optimized to obtain a better F 1 latency value. As said before, we used the same hyper-parameters for the 15 runs of the 3 tasks, these hyper-parameters were selected to optimize ERDE measures, which in turns produced an SS3 model that prioritizes the recall<ref type="foot" coords="7,292.34,445.10,3.97,6.12" target="#foot_2">6</ref> and speed<ref type="foot" coords="7,344.84,445.10,3.97,6.12" target="#foot_3">7</ref> above the precision, which is not bad taking into account that we are dealing with early risk detection tasks (every positive subject not detected is a life at risk!). Despite this, our best F 1 latency value (.55) was quite above the average (0.38) and was positioned 11th out of the 50 contributions and 5th out of the 13 research groups. Additionally, we also decided to compute the F 2 latency which gives a little more of importance to recall than to precision. This improved our results, making our best F 2 latency value (.67) to be positioned 7th out of the 50 contributions and 3rd out of the 13 research groups, and only 0.07 points below the best one. -As it is shown in Table <ref type="table" coords="7,252.26,567.14,3.87,8.74">2</ref>, SS3 was the fastest method to process the writings from each server response, processing each users' writing in about 8s 8 , this contrast with other methods that obtained a better F 1 latency but required more time, such as CLaC, INAOE-CIMAT or lirmm. For instance, CLaC was 232 times slower than SS3 and took 11 days and 16h to process only 109 of the 2000 writings, whereas SS3 processed all the 2000 writings for the 5 runs in only 23h. This could suggest that some research groups possible incorporated some sort of offline (or manual) processing into their models.</p><formula xml:id="formula_2" coords="7,226.62,266.80,129.37,7.89">1 1 .83<label>1</label></formula><p>It is worth mentioning that the fact that SS3 was the fastest model was not due to the type of machine we used<ref type="foot" coords="8,330.26,201.11,3.97,6.12" target="#foot_5">9</ref> but rather due to SS3 naturally supporting incremental classification. To put this point in context, it is important to note that ERD is essentially a problem of analysis of sequential data. That is, unlike traditional supervised learning problems where learning and classification are done on "complete" objects, here classification must be done on "partial" objects which correspond to all the data sequentially read up to the present, from a (virtually infinite) data stream. Algorithms capable of naturally dealing with this scenario are said to support incremental classification. As it is described in more details in <ref type="bibr" coords="8,373.77,298.32,9.96,8.74" target="#b0">[1]</ref>, unlike most state-ofthe-art classifiers, SS3 supports incremental classification since it does not necessarily "see" the input stream as an atomic n-dimensional vector (i.e. a document vector) that must be computed entirely before making a prediction. In consequence, when working with a sequence of documents, common classifiers must re-compute the input vector each time new content is added to the sequence<ref type="foot" coords="8,221.49,368.48,7.94,6.12" target="#foot_6">10</ref> . Formally, if n is the length of the stream/sequence of items, when working with SS3, the cost of the early classification algorithm for every subject, according to the number of processed items, is equal to n (since each item needs to be processed only once). On the other hand, for classifiers not supporting incremental classification (such as SVM, LO-GREG, KNN or any type of non-recurrent Neural Networks), this cost is equal to n × (n + 1)/2 = 1 + 2 + ... + n (since the first item needs to be processed n times, the second n -1, the third n -2, and so on). Thus, we have classifiers supporting stream classifications, such as SS3, belonging to O(n) whereas the others to O(n 2 ).</p><p>-SS3 was the method that obtained the best overall performance in rankingbased evaluation since, as shown in Table <ref type="table" coords="8,330.78,505.73,3.87,8.74">3</ref>: it obtained the best ranking performance P@10 and NDCG@10 for all the 4 rankings; the best NDCG@100 for rankings made after processing 1 and 100 writings (.55 and .85 respectively); and additionally, for the ranking made after processing 500 obtained the second-best NDCG@100 (.85, first was .87) and the third-best NDCG@100 (.84, first was .88) for the ranking made after processing 1000 writings.<ref type="foot" coords="9,189.42,431.65,7.94,6.12" target="#foot_7">11</ref> Note that these results are not a minor aspect, since they are implying that both: (a) the score (confidence value) given by SS3 correctly values/ranks positive subjects, that is, the global value, gv, is correctly capturing the degree of importance of each word for the positive class 12 (see Figure <ref type="figure" coords="9,182.88,481.05,4.98,8.74" target="#fig_3">3</ref> for a top-100 word cloud selected by gv); and (b) since SS3 is valuing/ranking users correctly, it means there is much room for improving the classification performance by choosing a better policy to actually classify them -perhaps using global information across different users could lead us to better classification performance, instead of classifying them locally, simply and prematurely just when the positive value exceeds the negative one. For this task, unlike T1, the training set was not provided, and therefore we had to build our own dataset to train SS3. To achieve this, we tried out creating different datasets, for instance, collecting tweets and Reddit posts related to self-harm, or using the datasets already available for anorexia and depression, as it is described in more details below:</p><p>-UNSL#0 : we collected Reddit posts related to self-harm and stored them in a single txt file to represent the positive class. For the negative class, we used the negative documents in the "train" folder for task T1 (anorexia). This run obtained the best precision (.71) but, among the other 4 runs, the lowest recall (.41) along with UNSL#1 (.39), both using the same dataset. -UNSL#1 : this run used the same dataset as the previous one, but this time SS3 took into account also bigrams of words (as in UNSL#1 for T1). -UNSL#2 : for this run, we trained SS3 using a dataset built using the Reddit posts (the same used in the runs above) and tweets related to self-harm. We created a single file with all these tweets and posts related to self-harm (about 40MB in size) and used it to learn the positive class. For the negative class, we used the negative training documents for the eRisk 2018 depression task. Additionally, as in run#4 of T1, SS3 was configured to ignore words whose global value was less than 0.3. Among the other 4 runs, this one had the best Recall (.9) but the worst values for precision (.2) and F1 (.32). -UNSL#3 : here we trained SS3 using the training documents for T1 (anorexia) and also using the training documents for the eRisk 2018 depression task. This run had a similar performance to run#4, although its recall was a little bit worse. -UNSL#4 : SS3 was trained using the same documents as in the previous run (i.e. anorexia + depression 2018) but this time adding those of run#0. This run had the best F 2 latency (.64) and ERDE values, 8.20% and 4.93% for ERDE 5 and ERDE 50 respectively.</p><p>Since no training data was released, we did not have any validation set to check if our models were learning properly, i.e. we did not know on which data  Table <ref type="table" coords="11,162.60,384.50,3.87,8.74">5</ref>: Participating teams for Task 2: number of runs, number of user writings processed by the team, and the time taken for the whole process and for processing each writing (i.e T otalT ime #writings×#runs ). (*) This value was originally 5, but we replaced it by the actual number of models used. our models were going to be evaluated. In order to know whether the learned model made sense or not, after training, we asked SS3 to give us a list of words ordered by global value for the positive class, and checked if the list made sense to us. Fortunately, as shown in Figure <ref type="figure" coords="11,309.18,613.10,3.87,8.74" target="#fig_5">4</ref>, the generated list of words matched what we expected.</p><p>The global results obtained in this task could be summarized as follows:</p><p>Table <ref type="table" coords="12,162.25,127.36,3.87,8.74">6</ref>: Ranking-based evaluation results for Task 2. Here it is shown the best results for SS3 along with the other best one, Fazl#1.</p><p>1 writing 100 writing Team#run P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 UNSL#0</p><p>. .83 500 writing 1000 writing Team#run P@10 NDCG@10 NDCG@100 P@10 NDCG@10 NDCG@100 UNSL#0 .9 -Once again SS3 was the fastest method, processing all the writing of each response in about 5s (as shown in Table <ref type="table" coords="12,329.67,410.20,3.87,8.74">5</ref>).</p><p>-Again, SS3 was the method that obtained the best overall performance in ranking-based evaluation since, as shown in Table <ref type="table" coords="12,379.34,442.79,3.87,8.74">6</ref>: it obtained the best ranking performance P@10 and NDCG@10 for all the 4 rankings; the best NDCG@100 for rankings made after processing 1 and 100 writings (.67 and .86 respectively). Additionally, for the ranking made after processing 500 and 1000 writings, SS3 obtained the second-best NDCG@100 (.79 and .78 respectively), the first ones were obtained by Fazl#1 (.84). It is worth mentioning it took Fazl 4 days and 17h to process those 500 writings (or 9 days and 10h for the 1000 writings), whereas it took SS3 only 3h (almost 60 times faster!).</p><p>It is worth mentioning that, unlike the other runs, UNSL#3 was trained only using data from anorexia and depression and yet it obtained good results. In fact, if we had sent only this run, among all participants, SS3 would have still obtained the best ERDE values (8.78% and 5.44%), the best F 2 latency (.63) and the second best F 1 latency (.45, first would have been .46). This, added to the results obtained by the other 4 runs, shows us that SS3 is a classifier quite robust to deal with cross-domain scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Task 3: Measuring the severity of the signs of depression</head><p>This task was really difficult since it was not a single "yes or no" problem but a problem involving multiple decisions, one for each one of the 21 questions.</p><p>To make things even harder, as with Task 2, no training data was released either. Fortunately, early depression detection is a task we had some previous experience working with since we had participated in the two previous eRisk labs (2017 <ref type="bibr" coords="13,176.62,216.76,12.87,8.74" target="#b0">[1]</ref> and 2018 <ref type="bibr" coords="13,228.42,216.76,12.36,8.74" target="#b2">[3]</ref>). Therefore, we decided to train SS3 using the dataset for the eRisk 2018 depression detection task. However, the main problem was deciding how to turn this "yes or no" classifier into a classifier capable of filling BDI questionnaires. We came up with the idea of using the confidence vector, -→ d in Equation <ref type="formula" coords="13,204.74,266.13,3.87,8.74" target="#formula_1">1</ref>, to somehow infer a BDI depression level between 0 and 63.</p><p>To achieve this, first, we converted the confidence vector into a single confidence value normalized between 0 and 1, by applying the following equation:</p><formula xml:id="formula_3" coords="13,208.30,310.57,272.29,22.31">conf idence value = d[positive] -d[negative] d[positive]<label>(2)</label></formula><p>Then, after SS3 classified a subject, the obtained conf idence value was divided into 4 regions, one for each BDI depression category. This was carried out by the following equation:</p><formula xml:id="formula_4" coords="13,247.47,388.55,233.12,8.74">c = conf idence value × 4<label>(3)</label></formula><p>And finally, the subject depression level was predicted by mapping the percentage of conf idence value left inside the predicted c region to its corresponding BDI depression level range (e.g. (0.5, 0.75] -→ [19, 29] for c = 2 = "moderate depression") by computing the following:</p><formula xml:id="formula_5" coords="13,139.75,476.41,340.85,9.65">depression level = min c + (max c -min c +1)×(conf idence value×4-c) (4)</formula><p>Where min c and max c are the lower and upper bound for category c, respectively (e.g. 19 and 29 for "moderate depression" category).</p><p>In order to clarify the above process, we will illustrate it with the example shown in Figure <ref type="figure" coords="13,206.60,548.44,3.87,8.74">5</ref>. First, SS3 processed the entire writing history computing the conf idence value (given by Equation <ref type="formula" coords="13,304.24,560.40,4.43,8.74" target="#formula_3">2</ref>) and then, the final conf idence value (0.941) was used to predict the depression category, "severe depression" (c = 3), by using the Equation 3. Finally, the depression level was computed by the mapping given by Equation <ref type="formula" coords="13,258.60,596.26,3.87,8.74">4</ref>, as follows: As reader can notice, after processing all the subject's writings, the final confidence value (0.941) was mapped into its corresponding depression level (55).</p><p>At this point, we have transformed the output of SS3 from a 2-dimensional vector, d, into a BDI depression level (a value between 0 and 63). However, we have not covered yet how to actually answer the 21 questions in the BDI questionnaire using this depression level. Regardless of the method, we decided that for all those users whose depression level was less or equal to 0, all the BDI questions were answered with 0. For the other users we applied different methods, depending on the run, as described below:</p><p>-UNSLA: using the predicted depression level our model filled the questionnaires answering the expected number ( depression level</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21</head><p>) on each question. If this division had a remainder, the remainder points were randomly scattered so that the sum of all the answers always matched the predicted depression level given by SS3.</p><p>-UNSLB : this time, only the predicted category, c, was used. Our model filled the questionnaire randomly in such a way that the final depression level always matched the predicted category. Compared to the following three ones, these two models were the ones with the worst performance. -UNSLC : this model and the followings were more question-centered. Once again, as in UNSLA, our model filled the questionnaires answering the expected number derived from the predicted depression level ( depression level</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21</head><p>). But this time, answering this number only on questions for which a "textual hint" for a possible answer was found in the user's writings, and randomly and uniformly answered between 0 and depression level 21 otherwise. To find this "textual hint", our model split the user's writings into sentences and searched for the co-occurrence of the word "I" or "my" with at least one word matching a regular expression specially crafted for each question. 13  This method obtained the best AHR (41.43%) and the second-best DCHR (40%). -UNSLD: the same as the previous one, but not using the "textual hints", i.e. always answering every question randomly and uniformly between 0 and depression level 21</p><p>. This model was mainly used only with the goal of measuring the actual impact of using these "textual hints" to decide which questions should be answered with the expected answer ( depression level</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21</head><p>).</p><p>-UNSLE : the same as UNSLD, but this time not using a uniform distribution. More precisely, from the overall depression level predicted by SS3, once again the expected answer was computed ( depression level</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21</head><p>) and, depending on the value of the expected answer, actual answers were given following the probability distributions shown in Figure <ref type="figure" coords="15,355.15,622.44,3.87,8.74">6</ref>. Note that, unlike uniform 13 e.g. "(sad)|(unhappy)" for question 1, "(future)|(work out)" for question 2, "fail\w*" for question 3, "(pleasure)|(enjoy)" for question 4, etc.  distribution (used in UNSLD), when using these probability distributions the expected answer is more likely to be selected over the other ones. This model obtained the best ACR (71.27%) and the second-best AHR (40.71%) and ADODL (80.48%, best was only 0.54% above).</p><p>The obtained results are shown in Table <ref type="table" coords="16,339.30,412.28,3.87,8.74" target="#tab_8">7</ref>. As mentioned above, we obtained the best AHR (41.43%) and ACR (71.27%), and the second-best ADODL (80.48%) and DCHR (40%). However, since most of our models' answers are randomly generated, it implies that all of these measures are also stochastically generated. <ref type="foot" coords="16,179.62,458.52,7.94,6.12" target="#foot_9">14</ref> The natural question in cases like this is "How do we know these results properly represent our models' performance and we did not obtain them just by pure chance?". In order to clarify this, we run each model 1000 times and calculated the values for AHR, ACR, ADODL and DCHR each time<ref type="foot" coords="16,444.19,494.39,7.94,6.12" target="#foot_10">15</ref> . After this process finished, we ended up with a sample of 1000 values for each measure and model, which we then used to produce the results shown in Table <ref type="table" coords="16,472.84,519.87,3.87,8.74" target="#tab_9">8</ref>. Results have been replaced by intervals with 95% of confidence, which better represent our performance. One can notice that, in fact, when we participated we had a little bit of bad luck, especially for UNSLE's ADODL, because the actual value we obtained (80.84%) is almost a lower bound outlier. Another thing that we can notice, comparing UNSLC and UNSLD, is that the use of "textual hints" slightly improves the Average Hit Rate (AHR) but does not impact on the other measures. UNSLE is considerably the best method to estimate the overall depression level since it takes values within a range that is quite above the others. Additionally, another important point is that taking into account these 95% confidence intervals, the obtained values would be among the best ones even in the worst cases. Finally, since all the methods we used are based on the depression level predicted by SS3, this shows us that SS3 is correctly inferring the depression level from the textual evidence accumulated while processing the user's writings, i.e. SS3 is correctly valuing words in relation to each category (depressed and non-depressed) which is consistent with the results obtained for the ranking-based measures for task T1 and T2. Additionally, this could also imply that could really be a relationship between how subjects write (what words they use) and the actual depression level they have.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this article, we described the participation of our research group 16 at the CLEF eRisk 2019 <ref type="bibr" coords="17,210.32,291.54,12.45,8.74" target="#b3">[4]</ref>. We described how we approached each one of the three tasks using the same SS3 classifier with the same hyper-parameter configuration. We showed how we mostly focused on aspects related to how we trained this classifier to create the different runs. For example, in task T2 we described for every run what data we used to train our model with. For this task, we also highlighted the cross-domain robustness that SS3 showed by the final results, in particular for UNSL#3 that obtained quite good performance despite being trained with data from anorexia and depression. For task 3, we described how we converted SS3 into a model capable of predicting a BDI depression level (from 0 to 63) which was later used to fill the questionnaires using different methods. The final results for all these three tasks showed that SS3 is a very robust and efficient classifier. SS3 was the fastest method and obtained the best ERDE and the overall best ranking-based measures in all the tasks. Additionally, it obtained the best P recision, F 1 and F 1 latency for task T2. In task T3, it obtained the best AHR and ACR values, and the second-best ADODL and DCHR. The results obtained for this task, along with those based on ranking measures, showed us strong evidence that SS3 properly values words in relation to how relevant they are to each category and therefore, the final confidence value properly values the text created by the subjects. Finally, overall results showed us that SS3 is a robust method since it obtained a remarkable overall performance in the three tasks despite using the same hyper-parameter configuration. For future work, we plan to mainly focus on three aspects. Given the interesting nature and implications of results in task T3, we will analyze in more details the obtained results, including a more qualitative analysis in which individual subjects could be analyzed. Additionally, we will explore different variations to improve the predicted depression level. Regarding task T1, we will explore different hyper-parameter values to improve the performance in terms of the new F 1 latency measure. Finally, based on the good results obtained for ranking-based measures, we plan to design better early classification policies in the future. Current policy tends to be "too hasty" so, we hope that delaying the decision until</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,316.92,345.83,8.74;4,134.77,328.88,89.50,8.74;4,134.77,115.84,345.82,189.56"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Task 3's subject 968's positive and negative confidence value variation over time (writings).</figDesc><graphic coords="4,134.77,115.84,345.82,189.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,134.77,574.28,345.83,8.74;4,134.77,586.23,187.08,8.74;4,134.77,371.38,345.82,191.37"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Task 1's subject 968's estimated score of the level of anorexia (d[positive]d[negative]) variation over time (writings).</figDesc><graphic coords="4,134.77,371.38,345.82,191.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.77,642.61,345.82,8.74;4,134.77,656.12,17.43,8.74;4,155.13,649.20,7.75,8.74;4,155.13,649.20,9.96,8.74;4,155.39,656.12,325.20,9.65;5,134.77,119.60,207.13,8.74;5,345.55,112.69,7.75,8.74;5,345.55,112.69,9.96,8.74;5,345.81,119.60,127.55,9.65;5,473.36,118.03,3.97,6.12;5,477.82,119.60,2.77,8.74;5,134.77,131.56,345.82,8.74;5,134.77,143.51,58.14,8.74"><head></head><label></label><figDesc>negative one. The policy to classify a subject as positive was performed analyzing how -→ d s changed over time, as shown with an example in Figure 1. Subjects were classified as positive when the positive value in -→ d s exceeded the negative one 4 , for instance, the subject in the figure was classified as anorexic after reading the 42nd writing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,134.77,369.09,345.83,8.74;9,134.77,381.05,155.81,8.74;9,186.64,115.84,242.07,241.73"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Top-100 words selected by global value (gv) from the model trained for the task T1. Words are sized by gv.</figDesc><graphic coords="9,186.64,115.84,242.07,241.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,134.77,328.80,345.83,8.74;11,134.77,340.76,228.70,8.74;11,134.77,115.84,184.24,184.51"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Top-100 words and word bigrams selected by global value (gv) from the model trained for the task T2. Both are sized by gv.</figDesc><graphic coords="11,134.77,115.84,184.24,184.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="14,134.77,315.35,345.82,8.74;14,134.77,327.30,345.83,8.74;14,134.77,339.26,335.05,8.74"><head></head><label></label><figDesc>Fig. 5: Diagram of the depression level computation process for subject 2827.As reader can notice, after processing all the subject's writings, the final confidence value (0.941) was mapped into its corresponding depression level (55).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="15,146.27,438.61,322.82,8.74;15,134.77,271.96,184.26,138.19"><head>3 Fig. 6 :</head><label>36</label><figDesc>Fig. 6: Discrete probability distribution for each possible expected answer.</figDesc><graphic coords="15,134.77,271.96,184.26,138.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="14,137.60,115.83,340.16,187.99"><head></head><label></label><figDesc></figDesc><graphic coords="14,137.60,115.83,340.16,187.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,127.36,345.82,229.81"><head>Table 1 :</head><label>1</label><figDesc>Results for Task 1, decision-based evaluation. Best results are also shown for comparison.</figDesc><table coords="6,168.05,151.65,278.54,205.52"><row><cell>Team#run</cell><cell cols="4">P R F 1 ERDE5 ERDE50 F 1 latency F 2 latency</cell></row><row><cell>UDE#0</cell><cell>.51 .74 .61 8.48%</cell><cell>3.87%</cell><cell>.58</cell><cell>.64</cell></row><row><cell>lirmm#1</cell><cell>.77 .60 .68 9.09%</cell><cell>5.50%</cell><cell>.62</cell><cell>.57</cell></row><row><cell>lirmm#2</cell><cell>.66 .70 .68 9.24%</cell><cell>5.80%</cell><cell>.60</cell><cell>.60</cell></row><row><cell>Fazl#2</cell><cell cols="2">.09 1 .16 17.11% 11.22%</cell><cell>.14</cell><cell>.28</cell></row><row><cell>CLaC#0</cell><cell>.45 .74 .56 6.72%</cell><cell>3.93%</cell><cell>.54</cell><cell>.63</cell></row><row><cell>CLaC#1</cell><cell>.61 .82 .70 5.73%</cell><cell>3.12%</cell><cell>.69</cell><cell>.75</cell></row><row><cell>CLaC#2</cell><cell>.60 .81 .69 6.01%</cell><cell>3.13%</cell><cell>.68</cell><cell>.73</cell></row><row><cell>CLaC#3</cell><cell>.63 .81 .69 6.27%</cell><cell>3.54%</cell><cell>.68</cell><cell>.74</cell></row><row><cell>CLaC#4</cell><cell>.64 .79 .71 6.25%</cell><cell>3.42%</cell><cell>.69</cell><cell>.73</cell></row><row><cell>LTL-INAOE#1</cell><cell>.47 .75 .58 7.74%</cell><cell>4.19%</cell><cell>.55</cell><cell>.64</cell></row><row><cell cols="2">INAOE-CIMAT#0 .56 .78 .66 9.29%</cell><cell>3.98%</cell><cell>.62</cell><cell>.68</cell></row><row><cell cols="2">INAOE-CIMAT#3 .67 .68 .68 9.17%</cell><cell>4.75%</cell><cell>.63</cell><cell>.69</cell></row><row><cell cols="2">INAOE-CIMAT#4 .69 .63 .66 9.12%</cell><cell>5.07%</cell><cell>.61</cell><cell>.59</cell></row><row><cell>UNSL#0</cell><cell cols="2">.42 .78 .55 5.53% 3.92%</cell><cell>.55</cell><cell>.66</cell></row><row><cell>UNSL#1</cell><cell>.43 .75 .55 5.68%</cell><cell>4.10%</cell><cell>.55</cell><cell>.65</cell></row><row><cell>UNSL#2</cell><cell>.36 .86 .51 5.56%</cell><cell>3.34%</cell><cell>.50</cell><cell>.67</cell></row><row><cell>UNSL#3</cell><cell>.35 .85 .50 5.59%</cell><cell>3.48%</cell><cell>.49</cell><cell>.66</cell></row><row><cell>UNSL#4</cell><cell cols="2">.31 .92 .47 6.14% 2.96%</cell><cell>.46</cell><cell>.65</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,127.36,345.82,146.29"><head>Table 4 :</head><label>4</label><figDesc>Results for Task 2, decision-based evaluation. Best results are also shown for comparison.</figDesc><table coords="10,134.77,151.65,295.27,122.00"><row><cell cols="5">Team#run P R F 1 ERDE5 ERDE50 F 1 latency F 2 latency</cell></row><row><cell cols="2">BiTeM#0 .52 .41 .46 9.73%</cell><cell>7.62%</cell><cell>.46</cell><cell>.43</cell></row><row><cell>Fazl#2</cell><cell cols="2">.12 1 .22 22.66% 13.23%</cell><cell>.19</cell><cell>.35</cell></row><row><cell cols="2">UNSL#0 .71 .41 .52 9.00%</cell><cell>7.30%</cell><cell>.52</cell><cell>.45</cell></row><row><cell cols="2">UNSL#1 .70 .39 .50 9.02%</cell><cell>7.60%</cell><cell>.50</cell><cell>.43</cell></row><row><cell cols="2">UNSL#2 .20 .90 .32 9.19%</cell><cell>6.86%</cell><cell>.32</cell><cell>.53</cell></row><row><cell cols="2">UNSL#3 .31 .85 .45 8.78%</cell><cell>5.44%</cell><cell>.45</cell><cell>.63</cell></row><row><cell cols="3">UNSL#4 .31 .88 .46 8.20% 4.93%</cell><cell>.45</cell><cell>.64</cell></row><row><cell cols="5">4 Task 2: Early Detection of Signs of Self-harm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="16,151.56,127.36,312.25,86.35"><head>Table 7 :</head><label>7</label><figDesc>Results for Task 3. Best results are also shown for comparison.</figDesc><table coords="16,168.37,139.70,278.61,74.02"><row><cell>run</cell><cell>AHR</cell><cell>ACR ADODL DCHR</cell></row><row><cell cols="3">CAMH GPT nearest unsupervised 23.81% 57.06% 81.03% 45%</cell></row><row><cell>UNSLA</cell><cell cols="2">37.38% 67.94% 72.86% 30%</cell></row><row><cell>UNSLB</cell><cell cols="2">36.93% 70.16% 76.83% 30%</cell></row><row><cell>UNSLC</cell><cell cols="2">41.43% 69.13% 78.02% 40%</cell></row><row><cell>UNSLD</cell><cell cols="2">38.10% 67.22% 78.02% 30%</cell></row><row><cell>UNSLE</cell><cell cols="2">40.71% 71.27% 80.48% 35%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="16,134.77,239.20,349.41,87.35"><head>Table 8 :</head><label>8</label><figDesc>Results for Task 3. Now our runs results are shown using a 95% confidence interval.</figDesc><table coords="16,136.16,263.49,348.02,63.06"><row><cell>run</cell><cell>AHR</cell><cell>ACR</cell><cell>ADODL</cell><cell>DCHR</cell></row><row><cell cols="3">UNSLA 38.13% ± 2.29% 68.30% ± 0.84%</cell><cell>72.62%</cell><cell>30%</cell></row><row><cell cols="4">UNSLB 38.97% ± 2.65% 69.77% ± 1.98% 74.72% ± 2.82%</cell><cell>30%</cell></row><row><cell cols="4">UNSLC 40.19% ± 3.14% 69.26% ± 1.75% 77.53% ± 1.92%</cell><cell>29.91% ± 8.70%</cell></row><row><cell cols="5">UNSLD 39.26% ± 3.21% 68.72% ± 1.81% 77.56% ± 1.86% 30.86% ± 11.14%</cell></row><row><cell cols="5">UNSLE 38.18% ± 3.41% 69.61% ± 1.95% 82.94% ± 2.17% 38.42% ± 10.14%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="5,144.73,608.97,335.86,7.86;5,144.73,619.93,245.23,7.86"><p>Except for task T3 in which we did not perform an "early stop", and therefore every user was classified after processing the entire writing history.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="5,144.73,631.34,23.79,7.86;5,172.27,629.41,53.83,5.24;5,186.91,636.42,24.55,5.24;5,229.57,631.34,251.02,7.86;5,144.73,644.66,7.42,7.86;5,162.69,642.73,11.46,5.24;5,156.14,649.75,24.55,5.24;5,184.45,644.66,7.17,7.86;5,195.38,642.73,53.83,5.24;5,208.07,648.94,27.94,6.26"><p>cf p = #positive users #users therefore each user, misclassified as false positive, added a value of cf p #users = #positive users #users 2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="7,144.73,602.00,335.86,7.86;7,144.73,612.96,219.49,7.86"><p>This is due to the way ERDE measure is computed, the false positive cost (cf p) is really small compared to the false negative cost (cf n).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="7,144.73,623.92,266.37,7.86"><p>On average, SS3 classified users after reading the 2nd or 3rd post.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="7,144.73,634.88,335.86,7.86;7,144.73,645.84,335.87,7.86;7,144.73,656.80,100.06,7.86"><p>Note that much of this 8s were wasted waiting for network communication, since this number includes the latency of receiving and sending the response from and to the API RESTful server.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="8,144.73,602.00,335.87,7.86;8,144.73,612.96,335.87,7.86;8,144.73,623.92,335.87,7.86;8,144.73,634.88,224.82,7.86"><p>We coded our script in plain python 2.7 and only using built-in functions and data structures, no external library was used (such as numpy). Additionally, to run our script we used one of the author's personal laptop which had standard technical specifications (Intel Core i5, 8GB of DDR4 RAM, etc.).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="8,144.73,645.84,335.87,7.86;8,144.73,656.80,20.48,7.86"><p>Since the "input document" is a stream, the input is a "document" that grows over time!</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7" coords="9,144.73,602.00,335.86,7.86;9,144.73,612.96,335.87,7.86;9,144.73,623.92,14.85,7.86"><p>Those first NDCG@100 values, .87 and .88, were obtained by UDE#1. It is worth mentioning that it took UDE 1 day and 6h to process those 500 writings (or 2 days and</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8" coords="9,163.36,623.92,317.24,7.86;9,144.73,634.88,53.12,7.86;9,133.85,644.07,7.31,5.24;9,144.73,645.84,335.87,7.86;9,144.73,656.80,33.59,7.86"><p>12h for those 1000 writings) whereas it took SS3 only 5h to process them (9 times faster). 12 which, as we will see later, this is also reflected by the promising results obtained in task T3.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_9" coords="16,144.73,634.88,335.87,7.86;16,144.73,645.84,151.80,8.35"><p>Only ADODL and DCHR for UNSLA and DHR for UNSLB are deterministically determined by depression l evel and c.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_10" coords="16,144.73,656.80,217.23,7.86"><p>Just as if we had participated 1000 times in this task.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>there is "enough confidence" to correctly classify subjects along with the use of global information across all the subjects could help to improve classification performance.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="18,138.35,198.38,342.24,7.86;18,146.91,209.34,333.68,7.86;18,146.91,220.27,333.68,7.89;18,146.91,231.26,175.47,7.86;18,354.83,231.26,125.77,7.86;18,146.91,242.21,155.72,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="18,362.09,198.38,118.50,7.86;18,146.91,209.34,333.68,7.86;18,146.91,220.30,49.54,7.86">A text classification framework for simple and effective early depression detection over social media streams</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2019.05.023</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0957417419303525" />
	</analytic>
	<monogr>
		<title level="j" coord="18,208.66,220.30,152.89,7.86">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,138.35,253.17,342.24,7.86;18,146.91,264.13,333.68,7.86;18,146.91,275.09,55.09,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="18,449.87,253.17,30.72,7.86;18,146.91,264.13,248.35,7.86">Temporal variation of terms as concept space for early risk prediction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Funez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J G</forename><surname>Ucelay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Cagnina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,415.55,264.13,65.04,7.86;18,146.91,275.09,26.42,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,138.35,286.05,342.24,7.86;18,146.91,297.01,273.18,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="18,273.48,297.01,146.61,7.86">Unsls participation at erisk 2018 lab</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Funez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J G</forename><surname>Ucelay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">G</forename><surname>Burdisso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Cagnina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montesy Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Errecalde</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="18,138.35,307.97,342.24,7.86;18,146.91,318.93,333.68,7.86;18,146.91,329.89,333.68,7.86;18,146.91,340.84,251.78,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="18,307.48,307.97,173.11,7.86;18,146.91,318.93,76.83,7.86">Overview of eRisk 2019: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,243.59,318.93,237.01,7.86;18,146.91,329.89,329.48,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 10th International Conference of the CLEF Association, CLEF 2019</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
