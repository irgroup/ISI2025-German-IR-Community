<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.05,115.96,327.26,12.62;1,238.17,133.89,139.01,12.62">Early detection of anorexia using RNN-LSTM and SVM classifiers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.44,172.16,96.12,8.74"><forename type="first">Akshaya</forename><surname>Ranganathan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,365.09,172.16,105.82,8.74"><forename type="first">Chandrabose</forename><surname>Aravindan</surname></persName>
							<email>aravindanc@ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.05,115.96,327.26,12.62;1,238.17,133.89,139.01,12.62">Early detection of anorexia using RNN-LSTM and SVM classifiers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D99150CEF76BC00D2D96B45B25C7F860</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anorexia</term>
					<term>early detection</term>
					<term>natural language processing</term>
					<term>deep learning</term>
					<term>machine Learning</term>
					<term>LSTM</term>
					<term>SVM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social Media text analysis has engendered a variety of applications in the medical domain, a major example being the detection and cure of deleterious mental disorders. Anorexia is a deadly, psychiatric eating disorder with typical characteristics of alarmingly low body weight conditions and distorted body image, with an unreasonable sense of being overweight. With developments in the field of Natural Language Processing, such highly lethal disorders can be identified and mitigated in their rudimentary stages, saving the victim a lot of mental and physical abuse. The Task 1 of CLEF 2019's eRisk lab focuses mainly on the early prediction of anorexia, analysed by posts which are sourced from social media platforms. Our team, SSN-NLP has used variations of two major models for sentiment classification, a deep learning RNN-LSTM, and a traditional SGDC Classifier. User-specific data from consequent posts that were extracted from Reddit was released by CLEF eRisk, which was used in its entirety for our training, testing, evaluation and scoring process. With the help of RAKE (Automated keyword extraction), numeric scores were obtained to identify the level of anorexia/self-harm.SSN-NLP submitted 5 variant models to the server that repeatedly accepted submissions and gave user writings to the participating teams. According to the ERDE-50 and F1 scores, our 2-layer LSTM with normed-bahdanau attention, performed the best having scores of 0.07 and 0.33 respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Anorexia Nervosa is a potentially life-threatening psychiatric disorder characterized by very extreme unhappiness over one's body image and intense desire to lose weight even if it's lower than what's considered normal. In the age of Instagram celebrities showing off their perfectly toned bodies, internet culture has created harsh rules that people, especially teenagers are expected to adhere to. According to a study by National Eating Disorders Association<ref type="foot" coords="2,432.40,117.42,3.97,6.12" target="#foot_0">1</ref> , irrespective of the time, 0.3-0.4% of women and 0.1% men test positive for anorexia nervosa. DSM-5 (Diagnostic and Statistical Manual of Mental Disorders) gives definitions and diagnostic material for mental disorders. According to DSM-5, Anorexia Nervosa is characterized by the following criteria: <ref type="foot" coords="2,396.28,165.24,3.97,6.12" target="#foot_1">2</ref>1. Restriction of energy intake relative to requirements leading to significantly low body weight in the context of age, sex, developmental trajectory, and physical health. 2. Intense fear of gaining weight or becoming fat, even though underweight 3. Disturbance in the way in which oneś body weight or shape is experienced, undue influence of body weight or shape on self-evaluation, or denial of the seriousness of the current low body weight.</p><p>However, another serious type of anorexia is called Atypical Anorexia where a person maintains a healthy weight despite consistent loss in weight.Types of anorexia include:</p><p>1. Binge/purge type: A person tries to purge by over-exercising or even vomiting after eating in an attempt to compensate for the weight gained by eating. 2. Restrictive type:: A person levies harsh restrictions on the quantity of food consumed, which in most cases is barely sufficient for survival.</p><p>eRisk 2019 primarily focuses on early detection of risk on the internet. The primary goal is to use text mining solutions for early detection in various areas like detection of people with suicidal tendencies, tendency to fall prey to criminal organizations, etc <ref type="bibr" coords="2,215.69,426.66,9.96,8.74" target="#b3">[4]</ref>. The aim of Task 1 under Erisk 2019 is to detect symptoms of anorexia as early as possible. Early detection technologies using text processing can be employed in different areas, particularly those related to health and safety. A few applications of early detection include the areas of sexual predators, mental disorders and cyber-bullying. Prediction is broadly classified into two stages: -the training stage and the test stage. In the training stage eRisk released chunks of training data as well as test data of eRisk 2018. The chunks consisted of user writings posted on Reddit as well as classification results. Users are classified as Anorexic and Non-Anorexic. During the testing stage, an automatic server repeatedly accepted our submissions and released test data batch by batch. The task evaluates the earliness of predictions in addition to their correctness. The task aims to obtain a scoring system based on the level of alert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Extant methods to detect Anorexia can be categorized into two types. One method is the analysis of change in behavioral patterns by general physicians as well as friends and family of the patient through structured mental analysis.</p><p>According to a study that weighs the importance of a primary physician in detecting eating disorders, a series of questions are used to detect the presence of anorexia which is done by examining the answers to each of these questions <ref type="bibr" coords="3,462.33,154.86,14.61,8.74" target="#b15">[16]</ref>.</p><p>A few examples include What did you eat yesterday?, Do you ever binge eat (eat more than you want) or use laxatives, diuretics, or diet pills?, Do you think you are thin (too thin), etc. The second method <ref type="bibr" coords="3,337.24,190.72,10.52,8.74" target="#b8">[9]</ref> involves the use of Sentiment Analysis on Social Media posts. For example, a research work showcased that students with signs of depression use more personal pronouns like 'I' and negative valence possessing words (eg: gloomy, sad). Erisk aims at early detection of anorexic tendencies by analyzing posts of users on Reddit. One such approach involves the Bag of Words (BoW) model <ref type="bibr" coords="3,314.87,250.50,15.50,8.74" target="#b12">[13]</ref> that uses a vocabulary comprising of all the unique words in the text and performs vectorization assigning a specific weight to each word. The term weighting for the BoW model has been split into 3 components: a term frequency component, a document frequency component, and a normalization component. Yet another approach involves UMLS based MetaMap <ref type="bibr" coords="3,185.16,310.28,10.52,8.74" target="#b8">[9]</ref> assistance for keyword detection. Further, Traditional Learning algorithms were applied to the information collected by the methods mentioned above (eg. SVM, logistic regression, RF). Yet another approach involved the use of TF-IDF similar to the works mentioned before. However, this research adopted a deep learning approach using CNN-LSTM <ref type="bibr" coords="3,368.11,358.10,9.96,8.74" target="#b2">[3]</ref>. Our work involves the usage of Recurrent Neural Networks with Long short term memory (LSTM) to analyze patterns and make predictions on sequences of texts. Rapid automated keyword extraction (RAKE) was implemented to identify the most frequently occurring keywords relating to anorexia in the training data. The results were combined to devise a prediction and risk-based scoring system.</p><p>3 Dataset Analysis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset analysis -Task 1</head><p>This year's Task 1 was an extension of CLEF eRisk 2018's Task 2, the training data <ref type="bibr" coords="3,162.64,524.61,15.50,8.74" target="#b13">[14]</ref> of this years task was a combination of both the test and training data of the previous year. Reddit, much like twitter offers a python supporting API that can be used to scrape required data effectively. Twitter sentiment analysis <ref type="bibr" coords="3,173.33,560.48,10.52,8.74" target="#b1">[2]</ref> has proven to be a powerful indicator of mental illnesses like depression and PTSD. While the training data was categorized into negative and positive examples, the labels of test data had to be extracted from the file riskgolden-truth-test.txt and mapped on to the actual writings of the users. Each document had an XML tree structure comprising of the tags : INDIVIDUAL ,ID ,WRITING ,TITLE ,DATE and TEXT. For the training-examples, a total of 152 user writings were given in comparison to 320 users for the test-examples all out of which only the TEXT and TITLE attributes were separated to be fed as training data. Table <ref type="table" coords="3,237.52,656.12,4.98,8.74" target="#tab_0">1</ref> gives a summary of all heading levels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data extraction and cleaning</head><p>The data <ref type="bibr" coords="4,181.45,270.01,15.50,8.74" target="#b13">[14]</ref> given was a consolidation of the test and training data of CLEF 2018. Data were represented as positive-examples and negative-examples chunks, each containing XML files of writings done by a certain subject. Using XML ElementTree library of Python, the given TEXT elements of each file were consolidated as follows: (see Fig. <ref type="figure" coords="4,263.49,317.84,4.43,8.74" target="#fig_0">1</ref>) To flatten out the discrepancies in the data set, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data augmentation</head><p>Due to the sparse characteristics of positive examples in the training set, Data Augmentation had to be done using the mentioned mechanism: Synonym generation using POS Tagging: Using the POSTagger module 3 , various parts of speech were identified from each positive example of the text. Post identification, the NLTK WordNet<ref type="foot" coords="5,252.11,129.37,3.97,6.12" target="#foot_3">4</ref> module identified the synonyms for adjectives(JJ) and adverbs(RB) and populated the dataset with replaced text which led to a significant increase of tuples in our dataset. As shown in the figure, (Fig. <ref type="figure" coords="5,454.68,154.86,4.43,8.74">3</ref>) the POS Tagger splits each sentence into relevant parts of speech, and the wordnet (Fig. <ref type="figure" coords="5,158.87,178.77,4.43,8.74" target="#fig_1">2</ref>) generates synonyms for each word. Multiple sentences of anorexia positive users were augmented to the dataset by replacing each adverb and adjective in a sentence with their respective list of most relevant synonyms. Take an example sentence: My body is so heavy that I actively need to exercise every moment of the day. The POS Tagger identifies heavy and actively as adjective and adverb respectively. Synset identifies synonyms for heavy as weighty, hefty, big, massive and synonyms for actively as effectively, usefully, productively. Now, sentences with combinations of these synonyms are generated. Nearly 45,000 sentences were added to our dataset through the mentioned methodology. NMT is built based on the concept of an Encoder-Decoder <ref type="bibr" coords="5,442.23,566.58,14.61,8.74" target="#b14">[15]</ref>. The encoder converts the input sequence to a thought vector while the decoder maps it to a target language. In our case, the decoder maps the input sequences to two classes-positive and negative indication of anorexia. The TensorFlow code based on tutorial code released by Neural Machine Translation<ref type="foot" coords="5,439.06,612.83,3.97,6.12" target="#foot_4">5</ref>  <ref type="bibr" coords="5,447.67,614.40,10.52,8.74" target="#b6">[7]</ref> that was developed based on Seq2Seq models <ref type="bibr" coords="5,320.25,626.36,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="5,337.41,626.36,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="5,346.82,626.36,7.75,8.74" target="#b5">6]</ref> was used to implement our deep learning approach for sentiment classification. Neural Machine Translation (NMT) was implemented with LSTM. LSTM is expanded as Long Short Term memory which is used to remember only the important parts of each input sentence and is trained to forget the rest. Thus, the output is a combination of the current input sentences predictions as well as the memory of previous important parts of sentences. LSTM captures Long Term Dependencies using 3 gates -Forget Gate: Decides what part of previous cell state must be forgotten.</p><p>-Input Gate: Responsible for the addition of information to the cell state.</p><p>-Output Gate: Responsible for selecting useful information to output at current cell state</p><formula xml:id="formula_0" coords="6,242.07,242.17,238.53,14.30">i t = σ(w (i) x x + w (i) h h t-1 + b (i) )<label>(1)</label></formula><formula xml:id="formula_1" coords="6,229.99,260.06,250.60,14.30">f t = σ(w (f ) x x + w (f ) h h t-1 + b (f ) + 1)<label>(2)</label></formula><formula xml:id="formula_2" coords="6,239.70,277.94,240.89,14.30">o t = σ(w (o) x x + w (o) h h t-1 + b (o) )<label>(3)</label></formula><formula xml:id="formula_3" coords="6,233.25,295.82,247.35,14.30">c t = tanh(w (c) x x + w (c) h h t-1 + b (c) )<label>(4)</label></formula><formula xml:id="formula_4" coords="6,261.05,314.38,219.54,9.65">c t = f t • c t-1 + i t • c t<label>(5)</label></formula><formula xml:id="formula_5" coords="6,264.84,329.81,215.75,9.96">h b/f = o t • tanh(c t )<label>(6)</label></formula><p>where w s are the weight matrices, h t-1 is the hidden layer state at time t -1, i t , f t , o t are the input, forget, output gates respectively at time t, and h b/f is the hidden state of backward, forward LSTM cells. Four different NMT variations have been implemented for runs 1-4 of our submissions.</p><p>- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Traditional Learning Approach</head><p>TF-IDF is used to assign weights to words to find out important words. TF stands for term frequency. It is a measure of the number of times a word occurs in a given document <ref type="bibr" coords="6,225.79,497.27,14.61,8.74" target="#b9">[10]</ref>. It is calculated by dividing the number of occurrences of a given word by the total number of words in a document. However, words like a, the occur a lot of times and are not very significant. So, we calculate the Inverse Document Frequency.</p><formula xml:id="formula_6" coords="6,259.11,550.89,221.49,8.74">W eights = T F * IDF<label>(7)</label></formula><p>Stochastic Gradient Descent <ref type="bibr" coords="6,254.96,568.63,13.34,8.74" target="#b0">[1]</ref> is essentially Gradient Descent with a batch size of 1 and works effectively when redundant data is present. SGD Classifier of sklearn performs Stochastic Gradient Descent Optimization on SVM Classification Model. Stochastic Gradient Descent is proven to be useful especially for large datasets and has found increased usage in several text mining applications <ref type="bibr" coords="6,134.76,628.41,14.61,8.74" target="#b9">[10]</ref>. After data augmentation, the dataset was cleaned and fed to the model. The accuracy of the model while training was found to be 90%.</p><p>-Model 0: SVM Classifier with SGD optimization using TF-IDF</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Automated Keyword Extraction</head><p>The motive behind Task 1 of eRisk 2019 was to facilitate the early prediction of anorexia. This year, they added another feature to the submissions called a score of positivity or negativity. Score is a numeric estimation of the level of anorexia/self-harm. Using this score, CLEF 2019 adapts ranking based measures for the evaluation of participants. The module Rapid Automated Keyword Extraction (RAKE) <ref type="bibr" coords="7,224.12,198.97,15.50,8.74" target="#b10">[11]</ref> was used to identify the most frequently occurring keywords in our training set, and to calculate the score based on these keywords. The input parameters for RAKE comprise a list of stop words (or stoplist) usually provided by NLTK for the English language, a set of phrase delimiters, and a set of word delimiters. RAKE uses stop words and phrase delimiters to segment the chunk of text into candidate keywords. The number of times each word occurs in the document gives the frequency score, and the number of times each keyword occurs with each other keyword is found as the co-occurrence score.</p><formula xml:id="formula_7" coords="7,199.94,304.69,280.65,9.65">f inal score = co -occurrence score /f requency score<label>(8)</label></formula><p>RAKE eliminates words that occur very frequently in the document but are of trivial relevance. Using co-occurring keywords, we successfully mined out pairs like body-mass, anorexia-nervosa,purge-eating, binge-eating. The fundamental difference between RAKE and TF-IDF scores is that RAKE finds word phrases in a single document and assigns relevance scores, while TF-IDF uses multiple documents to assign a single word score. Since our work required a single but voluminous training document, RAKE outperformed its TF-IDF counterpart.</p><p>To achieve stable prediction scores, we used a function that checks the following :</p><p>-If a user classified as anorexia positive has stopped posting altogether, the score was significantly increased, causing a high level of alert. -If a user was classified positive both in the current and previous runs, the score was boosted so as to confirm the decision of positive anorexia, as early as possible. -If a user was classified positive in the previous run, but the current run is negative, the score was balanced out, waiting for further writings to make the ultimate decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Decision based evaluation</head><p>According to the task, several methods of evaluation were considered <ref type="bibr" coords="7,441.55,602.86,9.96,8.74" target="#b4">[5]</ref>. Evaluation of results was initially based on Early Risk Detection Error (ERDE). ERDE gives a measure of correctness of decision as well as delay taken to arrive at a decision. P = T P T P + F P (9) R = T P T P + F N (10)</p><formula xml:id="formula_8" coords="8,278.55,143.21,202.04,22.31">F = 2 • P • R P + R<label>(11)</label></formula><p>However, ERDE has certain drawbacks. For example, a system that detects all the true positive writings still does not get an error of zero. Alternatively, a modification ERDE o %was suggested. This method considers the percentage of writings of the users seen before making a decision as opposed to the number of user writings. However, this method has a major flaw as in real life the total number of user writings may not be known.Another method based on F latency was proposed. For a user u ∈ U , k u writings are seen before making a decision d u . g u stands for the ground truth of decisions. Delay in finding true positives are considered as</p><formula xml:id="formula_9" coords="8,210.69,286.89,269.90,9.65">latency T P = median {k u : u U, d u = g u = 1}<label>(12)</label></formula><p>Standard measures of precision, recall, F-measure are calculated as follows:</p><formula xml:id="formula_10" coords="8,254.26,326.46,226.33,23.22">P = |u U : d u = g u = 1| |u U : d u = 1|<label>(13)</label></formula><formula xml:id="formula_11" coords="8,254.33,359.60,226.26,23.22">R = |u U : d u = g u = 1| |u U : g u = 1|<label>(14)</label></formula><formula xml:id="formula_12" coords="8,278.55,388.63,202.04,22.31">F = 2 • P • R P + R<label>(15)</label></formula><p>A penalty factor is introduced. A penalty is assigned to every true positive decision taken after k u writings.</p><formula xml:id="formula_13" coords="8,226.33,446.03,254.27,22.49">penalty(k u ) = -1 + 2 1 + exp -p•(ku-1)<label>(16)</label></formula><p>Yet another factor for evaluating performance is the speed of a system. A speed of 1 indicates that the system predicted true positives in the first writing as opposed to 0 if the system predicts only after a few hundred writings.</p><formula xml:id="formula_14" coords="8,187.97,522.71,292.63,9.65">speed = (1 -median {penalty(k u : u U, d u = g u = 1)})<label>(17)</label></formula><p>Based on the speed and F1 score, latency weighted F1 score is calculated.</p><formula xml:id="formula_15" coords="8,263.69,563.83,216.90,9.65">F latency = F * speed<label>(18)</label></formula><p>The maximum precision attained by our system is 0.48, whereas the overall <ref type="bibr" coords="8,134.77,596.34,10.52,8.74" target="#b4">[5]</ref> maximum among all systems is 0.71. Maximum recall of our system is 0.26, as opposed to overall maximum of all systems which is 1. Maximum F1 score is 0.34, whereas maximum of all systems id 0.71. ERDA5 is relatively low with a value of 0.08 as opposed to least value of 0.06 amongst all systems. Least ERDA50 is 0.07 for our system, while overall least is 0.03. Speed of a system is 1 if it detects true positive in the first writing of a user. Systems speed is 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ranking based evaluation</head><p>Along with the decision, a score which is an estimate of the level of risk, was also calculated for each user. The evaluation algorithm assigns ranks to users based on decreasing level of risk. The ranks are re-calculated after each set of writings. The rankings are evaluated with P@10 and NDCG metrics. The relatively long duration between submissions of various runs can be attributed to the offline processes used by our system(6 days,22 hs) From the released evaluation results, it can be inferred that our models performed extremely well with respect to early prediction (speed ), as the true positives were correctly classified within the first few sets of user writings. Our F latency however, was not up to standards, in comparison with a few of the best functioning systems, such as CLAC, which achieved a weighted F1 score of 0.69. Model 1 : 2 Layer BLSTM with scaled luong attention and Model 4: 4 Layer BLSTM with normed bahdanau attention have shown the best performance and this could be explained by taking the concept behind these attention mechanisms. As mentioned in <ref type="bibr" coords="9,335.90,584.39,9.96,8.74" target="#b5">[6]</ref>, the luong mechanism simply uses hidden states at the top LSTM layers in both the encoder and decoder, thus explaining why for a lesser number of layers (2 layers) scaled -luong attention worked better. The reason why bahdanau attention worked for a deeper number of layers (4 layers) can be justified, as a hidden state in Bahdanau goes through a deep-output and a max-out layer before making predictions <ref type="bibr" coords="9,185.77,656.12,9.96,8.74" target="#b0">[1]</ref>.</p><p>In this paper, we have presented the participation of our team, SSN-NLP at the eRisk 2019 task of early detection of signs of anorexia. Early risk prediction on the internet is vital to the development in the field of mental health and safety. We have treated this as a classification problem and presented 4 variations of Deep learning approaches, and one Traditional learning model using Neural Machine Translation (NMT) and SVM with SGD optimizer. The future scope for our model includes complete automation, devoid of any kind of online processing and research on other algorithms that could improve our model accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,197.51,468.02,220.34,7.89;4,134.77,350.16,345.83,103.10"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. XML DOM Tree structure of the released data</figDesc><graphic coords="4,134.77,350.16,345.83,103.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,414.29,103.75,7.89;5,134.77,425.27,45.33,7.86;5,387.58,418.89,82.29,7.89;5,376.84,322.07,83.00,82.05"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Word net relating to anorexia Fig. 3. POS-tagging</figDesc><graphic coords="5,376.84,322.07,83.00,82.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,213.16,115.91,189.04,104.19"><head>Table 1 .</head><label>1</label><figDesc>Training and Test 2018 data set</figDesc><table coords="4,213.16,139.01,189.04,81.09"><row><cell>Attributes</cell><cell cols="2">2018 Train 2018 Test</cell></row><row><cell>Number of users</cell><cell>152</cell><cell>320</cell></row><row><cell>Positives/Negatives</cell><cell>20/132</cell><cell>41/279</cell></row><row><cell>Number of documents</cell><cell>84,834</cell><cell>1,68,507</cell></row><row><cell cols="2">Avg documents per user 558.26</cell><cell>526.89</cell></row><row><cell cols="2">Avg words per document 184.54</cell><cell>197.28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,145.08,115.91,325.20,82.11"><head>Table 2 .</head><label>2</label><figDesc>Decision based evaluation</figDesc><table coords="9,145.08,134.97,325.20,63.06"><row><cell>team</cell><cell cols="5">run P R F1 ERDE5 ERDE50 latencyTP speed latency-weighted F1</cell></row><row><cell cols="2">SSN-NLP 0 .32 .16 .22 .08</cell><cell>.08</cell><cell>2</cell><cell>1</cell><cell>.22</cell></row><row><cell cols="2">SSN-NLP 1 .30 .22 .25 .08</cell><cell>.07</cell><cell>1</cell><cell>1</cell><cell>.25</cell></row><row><cell cols="2">SSN-NLP 2 .47 .22 .30 .08</cell><cell>.07</cell><cell>2</cell><cell>1</cell><cell>.30</cell></row><row><cell cols="2">SSN-NLP 3 .48 .26 .34 .08</cell><cell>.07</cell><cell>2</cell><cell>1</cell><cell>.33</cell></row><row><cell cols="2">SSN-NLP 4 .32 .15 .21 .08</cell><cell>.08</cell><cell>1</cell><cell>1</cell><cell>.21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,217.75,350.23,179.86,94.81"><head>Table 3 .</head><label>3</label><figDesc>Ranking based evaluation</figDesc><table coords="9,217.75,371.03,179.86,74.02"><row><cell>Name</cell><cell>run</cell><cell cols="2">1 writing P@10 NDCG@10 NDCG@100</cell></row><row><cell cols="3">SSN-NLP 0 .6</cell><cell>.64</cell><cell>.29</cell></row><row><cell cols="3">SSN-NLP 1 .3</cell><cell>.28</cell><cell>.15</cell></row><row><cell cols="3">SSN-NLP 2 .5</cell><cell>.48</cell><cell>.29</cell></row><row><cell cols="3">SSN-NLP 3 .6</cell><cell>.64</cell><cell>.30</cell></row><row><cell cols="3">SSN-NLP 4 .3</cell><cell>.33</cell><cell>.15</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,645.84,306.27,7.86"><p>https://www.nationaleatingdisorders.org/statistics-research-eating-disorders</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,656.80,304.48,7.86"><p>https://www.nationaleatingdisorders.org/learn/by-eating-disorder/anorexia</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,656.80,118.83,7.86"><p>https://github.com/nltk/nltk</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,645.84,151.64,7.86"><p>https://github.com/wordnet/wordnet</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,656.80,143.47,7.86"><p>https://github.com/tensorflow/nmt</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.35,277.47,342.24,7.86;10,146.91,288.43,258.97,7.86" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473.2014Sep1</idno>
		<title level="m" coord="10,280.73,277.47,199.86,7.86;10,146.91,288.43,74.61,7.86">Neural machine translation by jointly learning to align and translate</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,138.35,299.04,342.24,7.86;10,146.91,310.00,333.68,7.86;10,146.91,320.96,333.68,7.86;10,146.91,331.92,287.85,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,216.26,310.00,255.90,7.86">CLPsych 2015 shared task: Depression and PTSD on Twitter</title>
		<author>
			<persName coords=""><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Craig</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kristy</forename><surname>Hollingshead</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,159.65,320.96,320.95,7.86;10,146.91,331.92,216.96,7.86">Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</title>
		<meeting>the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,342.52,332.69,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,353.67,342.52,80.16,7.86">TUA1 at eRisk 2018</title>
		<author>
			<persName coords=""><forename type="first">Ning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,353.13,342.25,7.86;10,146.91,364.09,333.68,7.86;10,146.91,375.04,321.93,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,378.56,353.13,102.04,7.86;10,146.91,364.09,122.86,7.86">Overview of eRisk: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,290.76,364.09,189.83,7.86;10,146.91,375.04,172.02,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="343" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,385.65,342.24,7.86;10,146.91,396.61,333.68,7.86;10,146.91,407.57,333.68,7.86;10,146.91,418.53,74.36,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,387.08,385.65,93.51,7.86;10,146.91,396.61,147.70,7.86">Overview of eRisk 2019: Early Risk Prediction on the Internet</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,301.05,396.61,179.55,7.86;10,146.91,407.57,329.62,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 10th International Conference of the CLEF Association</title>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,429.13,266.05,7.86;10,146.91,440.09,281.44,7.86;10,146.91,451.05,161.61,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,150.84,440.09,269.70,7.86">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName coords=""><forename type="first">Minh</forename><forename type="middle">-</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hieu</forename><surname>Thang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.04025</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,138.35,461.66,342.25,7.86;10,146.91,472.62,297.27,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,295.91,461.66,181.04,7.86">Neural machine translation (seq2seq) tutorial</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/tutorials/seq2seq(17.02" />
		<imprint>
			<date type="published" when="2017">2017. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,483.22,342.24,7.86;10,146.91,494.18,144.02,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,238.76,483.22,241.83,7.86;10,146.91,494.18,67.34,7.86">The annals of mathematical statistics</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Monro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951-09-01">1951 Sep 1</date>
			<biblScope unit="page" from="400" to="407" />
		</imprint>
	</monogr>
	<note>A stochastic approximation method</note>
</biblStruct>

<biblStruct coords="10,138.35,504.79,342.24,7.86;10,146.91,515.74,333.67,7.86;10,146.91,526.70,84.18,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="10,384.86,504.79,95.73,7.86;10,146.91,515.74,333.67,7.86;10,146.91,526.70,46.27,7.86">Early Detection of Signs of Anorexia and Depression Over Social Media using Effective Machine Learning Frameworks</title>
		<author>
			<persName coords=""><forename type="first">Sayanta</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jandhyala</forename><forename type="middle">Sree</forename><surname>Kalyani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tanmay</forename><surname>Basu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,537.31,337.97,7.86;10,146.91,548.27,333.68,7.86;10,146.91,559.23,142.12,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,316.03,537.31,164.56,7.86;10,146.91,548.27,150.54,7.86">Text Mining: Use of TF-IDF to Examine the Relevance of Words to Documents</title>
		<author>
			<persName coords=""><forename type="first">Shahzad</forename><surname>Qaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ramsha</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">181.10.5120/ijca2018917395</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,304.98,548.27,171.36,7.86">International Journal of Computer Applica</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,569.83,337.98,7.86;10,146.91,580.79,333.68,7.86;10,146.91,591.75,50.68,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,416.81,569.83,63.78,7.86;10,146.91,580.79,172.25,7.86">Automatic keyword extraction from individual documents</title>
		<author>
			<persName coords=""><forename type="first">Stuart</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dave</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wendy</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,331.24,580.79,149.35,7.86">Text mining: applications and theory</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,602.36,337.98,7.86;10,146.91,613.32,333.67,7.86;10,146.91,624.27,24.58,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,337.98,602.36,142.61,7.86;10,146.91,613.32,62.47,7.86">Sequence to sequence learning with neural networks</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,228.87,613.32,207.04,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,634.88,337.97,7.86;10,146.91,645.84,333.68,7.86;10,146.91,656.80,64.53,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="10,346.80,634.88,133.79,7.86;10,146.91,645.84,333.68,7.86;10,146.91,656.80,34.42,7.86">Word Embeddings and Linguistic Metadata at the CLEF 2018 Tasks for Early Detection of Depression and Anorexia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Trotzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,119.67,337.98,7.86;11,146.91,130.63,333.68,7.86;11,146.91,141.59,307.83,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,397.74,119.67,82.85,7.86;11,146.91,130.63,333.68,7.86;11,146.91,141.59,37.58,7.86">Utilizing neural networks and linguistic metadata for early detection of depression indications in text sequences</title>
		<author>
			<persName coords=""><forename type="first">Marcel</forename><surname>Trotzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sven</forename><surname>Koitka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,195.92,141.59,227.59,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,152.55,337.98,7.86;11,146.91,163.51,18.43,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="11,304.31,152.55,176.28,7.86;11,146.91,163.51,14.75,7.86">Literature Survey: Neural Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,174.47,337.98,7.86;11,146.91,185.43,333.68,7.86;11,146.91,196.39,28.67,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,223.13,174.47,257.47,7.86;11,146.91,185.43,115.77,7.86">Detection, evaluation, and treatment of eating disorders the role of the primary care physician</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,269.47,185.43,143.92,7.86">Journal of general internal medicine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="577" to="590" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
