<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,227.61,115.96,160.13,12.62;1,188.58,133.89,238.19,12.62;1,230.59,151.82,154.18,12.62">CENTRE@CLEF2019: Overview of the Replicability and Reproducibility Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,149.16,189.57,53.60,8.74"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<email>ferro@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.32,189.57,58.34,8.74"><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
							<email>norbert.fuhr@uni-due.de</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Duisburg-Essen</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.22,189.57,62.65,8.74"><forename type="first">Maria</forename><surname>Maistro</surname></persName>
							<email>maistro@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.76,189.57,60.39,8.74"><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
							<email>tetsuyasakai@acm.org</email>
							<affiliation key="aff3">
								<orgName type="institution">Waseda University</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,452.09,189.57,14.11,8.74;1,287.44,201.53,36.01,8.74"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
							<email>ian.soboroff@nist.gov</email>
							<affiliation key="aff4">
								<orgName type="institution">National Institute of Standards and Technology (NIST)</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,227.61,115.96,160.13,12.62;1,188.58,133.89,238.19,12.62;1,230.59,151.82,154.18,12.62">CENTRE@CLEF2019: Overview of the Replicability and Reproducibility Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F25280EA0E956ABA27C913277B95D8A6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reproducibility has become increasingly important for many research areas, among those IR is not an exception and has started to be concerned with reproducibility and its impact on research results. This paper describes our second attempt to propose a lab on reproducibility named CENTRE, held during CLEF 2019. The aim of CENTRE is to run both a replicability and reproducibility challenge across all the major IR evaluation campaigns and to provide the IR community with a venue where previous research results can be explored and discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reproducibility is becoming a primary concern in many areas of science <ref type="bibr" coords="1,450.71,519.58,15.50,8.74" target="#b15">[16,</ref><ref type="bibr" coords="1,467.86,519.58,12.73,8.74" target="#b23">24]</ref> as well as in computer science, as also witnessed by the recent ACM policy on result and artefact review and badging.</p><p>Also in Information Retrieval (IR) replicability and reproducibility of the experimental results are becoming a more and more central discussion items in the research community <ref type="bibr" coords="1,226.81,579.44,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="1,238.99,579.44,12.73,8.74" target="#b11">12,</ref><ref type="bibr" coords="1,253.38,579.44,12.73,8.74" target="#b16">17,</ref><ref type="bibr" coords="1,267.77,579.44,12.73,8.74" target="#b22">23,</ref><ref type="bibr" coords="1,282.16,579.44,11.62,8.74" target="#b27">28]</ref>. We now commonly find questions about the extent of reproducibility of the reported experiments in the review forms of all the major IR conferences, such as SIGIR, CHIIR, ICTIR and ECIR, as well as journals, such as ACM TOIS. We also witness to the raise of new activities aimed at verifying the reproducibility of the results: for example, the "Reproducibility Track" at ECIR since 2015 hosts papers which replicate, reproduce and/or generalize previous research results.</p><p>Nevertheless, it has been repeatedly shown that best TREC systems still outperform off-the-shelf open source systems <ref type="bibr" coords="2,335.20,167.29,48.15,8.74">[4-6, 22, 23]</ref>. This is due to many different factors, among which lack of tuning on a specific collection when using default configuration, but it is also caused by the lack of the specific and advanced components and resources adopted by the best systems.</p><p>It has been also shown that additivity is an issue, since adding a component on top of a weak or strong base does not produce the same level of gain <ref type="bibr" coords="2,452.91,227.54,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,465.09,227.54,11.62,8.74" target="#b21">22]</ref>. This poses a serious challenge when off-the-shelf open source systems are used as stepping stone to test a new component on top of them, because the gain might appear bigger starting from a weak baseline.</p><p>Moreover, besides the problems encountered in replicating/reproducing research, we lack any well established measure to assess and quantify the extent to which something has been replicated/reproduced. In other terms, even if a later researcher can manage to replicate or reproduce an experiment, to which extent can we claim that the experiment is successfully replicated or reproduced? For the replicability task we can compare the original measure score with the score of the replicated run, as done in <ref type="bibr" coords="2,299.78,347.56,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="2,316.93,347.56,11.62,8.74" target="#b13">14]</ref>. However, this can not be done for reproducibility, since the reproduced system is obtained on a different data set and it is not directly comparable with the original system in terms of measure scores.</p><p>Finally, both a Dagstuhl Perspectives Workshop <ref type="bibr" coords="2,363.00,395.86,15.50,8.74" target="#b10">[11]</ref> and the recent SWIRL III strategic workshop <ref type="bibr" coords="2,231.80,407.81,10.52,8.74" target="#b0">[1]</ref> have put on the IR research agenda the need to develop both better explanatory models of IR system performance and new predictive models, able to anticipate the performance of IR systems in new operational conditions.</p><p>Overall, the above considerations stress the need and urgency for a systematic approach to reproducibility and generalizability in IR. Therefore, the goal of CLEF, NTCIR, TREC REproducibility (CENTRE) at CLEF 2019 is to run a joint CLEF/NTCIR/TREC task on challenging participants:</p><p>to replicate and reproduce best results of best/most interesting systems in previous editions of CLEF/NTCIR/TREC by using standard open source IR systems; to contribute back to the community the additional components and resources developed to reproduce the results in order to improve existing open source systems; to start exploring the generalizability of our findings and the possibility of predicting IR system performance; to investigate possible measures for replicability and reproducibility in IR.</p><p>The paper is organized as follows: Section 2 introduces the setup of the lab; Section 3 discusses the participation and the experimental outcomes; and, Section 4 draws some conclusions and outlooks possible future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation Lab Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tasks</head><p>Similarly to its previous edition, CENTRE@CLEF 2019 offered the following two tasks:</p><p>-Task 1 -Replicability: the task focuses on the replicability of selected methods on the same experimental collections; -Task 2 -Reproducibility: the task focuses on the reproducibility of selected methods on different experimental collections;</p><p>For Replicability and Reproducibility we refer to the ACM Artifact Review and Badging definitions<ref type="foot" coords="3,238.18,265.36,3.97,6.12" target="#foot_0">6</ref> :</p><p>-Replicability (different team, same experimental setup): the measurement can be obtained with stated precision by a different team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same or a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using the author's own artifacts. In CENTRE@CLEF 2019 this meant to use the same collections, topics and ground-truth on which the methods and solutions have been developed and evaluated. -Reproducibility (different team, different experimental setup): The measurement can be obtained with stated precision by a different team, a different measuring system, in a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently. In CENTRE@CLEF 2019 this meant to use a different experimental collection, but in the same domain, from those used to originally develop and evaluate a solution.</p><p>For Task 1 and Task 2, CENTRE@CLEF 2019 teams up with the Open-Source IR Replicability Challenge (OSIRRC) <ref type="bibr" coords="3,330.32,500.06,15.50,8.74" target="#b9">[10]</ref> at SIGIR 2019. Therefore, participating groups could consider to submit their runs both to CENTRE@CLEF 2019 and OSIRRC 2019, where the second venue requires to submit the runs as Docker images.</p><p>Besides Task 1 and Task 2, CENTRE@CLEF 2019 offered also a new pilot task:</p><p>-Task 3 -Generalizability: the task focuses on collection performance prediction and the goal is to rank (sub-)collections on the basis of the expected performance over them.</p><p>In details, Task 3 was instatiated as follows:</p><p>-Training: participants need to run plain BM25 and, if they wish, also their own system on the test collection used for TREC 2004 Robust Track (they are allowed to use the corpus, topics and qrels). Participants need to identify features of the corpus and topics that allow them to predict the system score with respect to Average Precision (AP). old topics were used in TREC 2017 Common Core track. Participants will submit a run for each system (BM25 and their own system) and an additional file (one for each system) including the AP score predicted for each topic.</p><p>The score predicted can be a single value or a value with the corresponding confidence interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Replicability and Reproducibility Targets</head><p>For the previous edition of CENTRE@CLEF 2018 <ref type="bibr" coords="4,354.35,371.59,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="4,371.51,371.59,12.73,8.74" target="#b13">14]</ref> we selected the target runs for replicability and reproducibility among the Ad Hoc tasks in previous editions of CLEF, TREC, and NTCIR. However, even though CENTRE@CLEF 2018 had 17 enrolled teams, eventually only one team managed to submit a run. One of the main issues reported by the participating team is the lack of the external resources exploited in the original paper, which are no longer available <ref type="bibr" coords="4,462.32,431.37,14.61,8.74" target="#b18">[19]</ref>. Therefore, for CENTRE@CLEF 2019 we decided to focus on more recent papers submitted at TREC Common Core Track in 2017 and 2018.</p><p>To select the target runs from the TREC 2017 and 2018 Common Core Tracks we did not consider the impact of the proposed approaches in terms of number of citations, since both the tracks are recent and the citations received by the submitted papers are not significant. Therefore, we looked at the final ranking of runs reported in the tracks overviews <ref type="bibr" coords="4,311.17,515.06,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="4,323.36,515.06,7.75,8.74" target="#b2">3]</ref> and we chose the best performing runs which exploit open source search systems and do not make use of additional relevance assessments, which are not available to different teams.</p><p>Below we list the runs selected as targets of replicability and reproducibility among which the participants can choose. For each run, we specify the corresponding collection for replicability and for reproducibility. For more information, the list also provides references to the papers describing those runs as well as the overviews describing the overall task and collections.</p><p>-Runs: WCrobust04 and WCrobust0405 <ref type="bibr" coords="4,341.15,620.39,15.50,8.74" target="#b17">[18]</ref> • Task Type: TREC 2017 Common Core Track <ref type="bibr" coords="4,376.82,632.25,10.52,8.74" target="#b1">[2]</ref> • Replicability: New York Times Annotated Corpus, with TREC 2017 Common Core Topics Since these runs were not originally thought for being used as targets of a replicability/reproducibility exercise, we contacted the authors of the papers to inform them and ask their consent to use the runs.</p><p>The participants in CENTRE@CLEF 2019 were not provided with the corpora necessary to perform the tasks. The following collections were needed to perform the task:</p><p>-The New York Times Annotated Corpus<ref type="foot" coords="5,330.21,321.90,3.97,6.12" target="#foot_1">7</ref> contains over 1.8 million articles written and published by the New York Times between January 1, 1987 and June <ref type="bibr" coords="5,175.97,347.38,12.73,8.74" target="#b18">19,</ref><ref type="bibr" coords="5,192.35,347.38,18.15,8.74">2007</ref>. The text in this corpus is formatted in News Industry Text Format (NITF), which is an XML specification that provides a standardized representation for the content and structure of discrete news articles. The dataset is available upon payment of a fee. -The TREC Washington Post Corpus<ref type="foot" coords="5,317.94,394.64,3.97,6.12" target="#foot_2">8</ref> contains 608 180 news articles and blog posts from January 2012 through August 2017. The articles are stored in JSON format, and include title, byline, date of publication, kicker (a section header), article text broken into paragraphs, and links to embedded images and multimedia. The dataset is publicly available and free of charge. -The TREC 2004 Robust Corpus<ref type="foot" coords="5,295.49,455.42,3.97,6.12" target="#foot_3">9</ref> corresponds to the set of documents on TREC disks 4 and 5, minus the Congressional Record. This document set contains approximately 528 000 documents. The dataset is available upon payment of a fee.</p><p>Finally, Table <ref type="table" coords="5,213.82,515.82,4.98,8.74" target="#tab_2">1</ref> reports the topics used for the three tasks, with the corresponding number of documents and pool sizes. An example of topic is reported in the Figure <ref type="figure" coords="5,194.98,539.73,4.98,8.74">1</ref> for TREC 2018 Common Core Track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation Measures</head><p>Task 1 -Replicability: As done in the previous edition of CENTRE <ref type="bibr" coords="5,430.91,599.63,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="5,448.07,599.63,11.62,8.74" target="#b13">14]</ref>, the quality of the replicability runs has been evaluated from two points of view: -Effectiveness: how close are the performance scores of the replicated systems to those of the original ones. This is measured using the Root Mean Square Error (RMSE) <ref type="bibr" coords="6,218.48,364.17,15.50,8.74" target="#b20">[21]</ref> between the new and original measures scores M (•):</p><formula xml:id="formula_0" coords="6,228.03,388.33,252.56,30.32">RMSE = 1 T T i=1 M orig,i -M replica,i 2<label>(1)</label></formula><p>where T is the total number of topics, M orig,i is the measure score of the original target run on topic t i and M replica,i is the measure score of the replicated run on topic t. Equation ( <ref type="formula" coords="6,311.32,453.93,4.24,8.74" target="#formula_0">1</ref>) is instantiated with AP, Normalized Discounted Cumulated Gain (nDCG) and Expected Reciprocal Rank (ERR). -Ranked result lists: since different result lists may produce the same effectiveness score, we also measure how close are the ranked results list of the replicated systems to those of the original ones. This is measured using Kendall's τ correlation coefficient <ref type="bibr" coords="6,257.38,513.53,15.50,8.74" target="#b19">[20]</ref> among the list of retrieved documents for each topic, averaged across all the topics. The Kendall's τ correlation coefficient on a single topic is given by:</p><formula xml:id="formula_1" coords="6,211.24,556.27,269.35,66.09">τ i orig, replica = P -Q P + Q + U P + Q + V τ orig, replica = 1 T T i=1 τ i orig, replica<label>(2)</label></formula><p>where T is the total number of topics, P is the total number of concordant pairs (document pairs that are ranked in the same order in both vectors) Q the total number of discordant pairs (document pairs that are ranked in opposite order in the two vectors), U and V are the number of ties, respectively, in the first and in the second ranking.</p><p>Note that the definition of Kendall's τ in Equation ( <ref type="formula" coords="7,376.63,150.09,4.24,8.74" target="#formula_1">2</ref>) is originally proposed for permutations of the same set of items, therefore it is not applicable whenever two rankings do not contain the same set of documents. However, for real rankings of systems it is highly likely that two lists do not contain the same set of items, thus we performed some pre-processing with the runs before computing Kendall's τ in Equation <ref type="bibr" coords="7,242.00,209.87,11.62,8.74" target="#b1">(2)</ref>.</p><p>In details, consider a fixed topic t, the original ranking r t,orig and the replicated ranking r t,replica . If one of the rankings contains a document that is not retrieved by the other ranking, we define the rank position of that document as zero. For example, if for a document d, d ∈ r t,orig , but d ∈ r t,replica , then the rank position of d in r t,replica is zero. Whenever the two rankings contains the same set of documents, Equation ( <ref type="formula" coords="7,306.40,281.60,4.24,8.74" target="#formula_1">2</ref>) is not affected by this pre-processing step and the computation of Kendall's tau is performed as usual. Furthermore, if two rankings retrieves different documents and place them in the same rank positions, Kendall's tau will still be equal to 1, and the comparison is performed just with respect to the relative order of the documents retrieved by both the rankings.</p><p>Task 2 -Reproducibility: Since for the reproducibility runs we do not have an already existing run to compare against, we compare the reproduced run score with respect to a baseline run, to see whether the improvement over the baseline is comparable between the original collection C and the new collection D. In particular we compute the Effect Ratio (ER), which is also exploited in CEN-TRE@NTCIR 14 <ref type="bibr" coords="7,213.22,424.28,14.61,8.74" target="#b24">[25]</ref>.</p><p>In details, given two runs, we refer to the A-run, as the advanced run, and B-run, as the baseline run, where the A-run has been reported to outperform the B-run on the original test collection C. The intuition behind ER is to evaluate to which extent the improvement on the original collection C is reproduced on a new collection D. For any evaluation measure M , let M C i (A) and M C i (B) denote the score of the A-run and that of the B-run for the i-th topic of collection C (1 ≤ i ≤ T C ). Similarly, let M D i (A ) and M D i (B ) denote the scores for the reproduced A-run and B-run respectively, on the new collection D. Then, ER is computed as follows:</p><formula xml:id="formula_2" coords="7,188.74,550.60,291.85,32.18">ER(∆M D reproduced , ∆M C orig ) = 1 T D T D i=1 ∆M D i,reproduced 1 T C T C i=1 ∆M C i,orig<label>(3)</label></formula><p>where</p><formula xml:id="formula_3" coords="7,163.02,591.80,127.62,12.32">∆M C i,orig = M C i (A) -M C i (B)</formula><p>is the per-topic improvement of the original advanced and baseline runs for the i-th topic on C.</p><formula xml:id="formula_4" coords="7,134.77,605.12,345.83,25.88">Similarly ∆M D i,reproduced = M C i (A ) -M C i (B )</formula><p>is the per-topic improvement of the reproduced advanced and baseline runs for the i-th topic on D. Note that the per-topic improvement can be negative, for those topics where the advanced run fails to outperform the baseline run. If ER ≤ 0, that means that the replicated A-run failed to outperform the replicated B-run: the replication is a complete failure. If 0 &lt; ER &lt; 1, the replication is somewhat successful, but the effect is smaller compared to the original experiment. If ER = 1, the replication is perfect in the sense that the original effect has been recovered as is. If ER &gt; 1, the replication is successful, and the effect is actually larger compared to the original experiment.</p><p>Finally, ER in Equation ( <ref type="formula" coords="8,263.51,325.70,4.24,8.74" target="#formula_2">3</ref>) is instantiated with respect to AP, nDCG and ERR. Furthermore, as suggested in <ref type="bibr" coords="8,286.39,337.65,14.61,8.74" target="#b24">[25]</ref>, ER is computed even for the replicability task, by replacing ∆M D i,reproduced with ∆M C i,replica in Equation ( <ref type="formula" coords="8,415.59,349.61,3.87,8.74" target="#formula_2">3</ref>).</p><p>Task 3 -Generalizability: For the generalizability task we planned to compare the predicted run score with the original run score. This is measured with Mean Absolute Error and RMSE between the predicted and original measures scores, with respect to AP, nDCG and ERR. However, we did not receive any run for the generalizability task, so we did not put in practice this part of the evaluation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Participation and Outcomes</head><p>19 groups registered for participating in CENTRE@CLEF2019, but unfortunately only one group succeeded in submitting two replicability runs and two reproducibility runs. No runs were submitted for the generalizability task.</p><p>The team from the University of Applied Science TH Köln [8] replicated and reproduced the runs by Grossman and Cormack <ref type="bibr" coords="8,364.77,542.95,14.61,8.74" target="#b17">[18]</ref>, i.e. WCrobust04 and WCrobust0405. They could not replicate the runs by Benham et Al. <ref type="bibr" coords="8,445.47,554.90,10.52,8.74" target="#b6">[7]</ref> since they do not have access to the Gigaworld dataset<ref type="foot" coords="8,351.25,565.28,7.94,6.12" target="#foot_4">10</ref> , which is publicly available upon payment of a fee. The dataset is necessary to perform the external query expansion exploited by the selcted runs from <ref type="bibr" coords="8,333.41,590.77,9.96,8.74" target="#b6">[7]</ref>.</p><p>Eventually, the participating team submitted four official runs and four unofficial runs described in Table <ref type="table" coords="8,270.32,615.06,3.87,8.74" target="#tab_3">2</ref>. The runs and all the code is publicly available online 11 .</p><p>The paper by Grossman and Cormack <ref type="bibr" coords="9,315.54,118.99,15.50,8.74" target="#b17">[18]</ref> exploits the principle of automatic routing runs: first, a logistic regression model is trained with the relevance judgments from one or more collections for each topic, then the model is used to predict relevance assessments of documents from a different collection. Both the training and the prediction phases are done on a topic-wise basis.</p><p>The routing process represented a challenge for the participating team, which initially submitted a set of four official runs, where some of the topics were missing. For example, the official run irc task1 WCrobust0405 001 contains only 33 topics, while the corresponding original run WCrobust0405 contains all the 50 topics. The participating team could not understand how to derive document rankings for those topics such that no training topics were available for the logistic regression model. For example, when they were attempting to replicate WCrobust0405, they exploited as training set the intersection between the topics from TREC 2004 Robust and TREC 2005 Robust. Then, for the prediction phase, only 33 topics from TREC 2017 Common Core were contained in the training set, and no prediction could be performed for the remaining topics. Due to similar issues, the official irc task2 WCrobust04 001 and irc task2 WCrobust0405 001 contain 25 and 15 topics respectively.</p><p>Afterwards, the participating team contacted the authors of the original paper, Grossman and Cormack <ref type="bibr" coords="9,266.68,350.58,14.61,8.74" target="#b17">[18]</ref>, to understand how to derive rankings even when there are no training topics available. The authors clarified that for WC-robust0405 the training set contains both the topics from TREC 2004 Robust and TREC 2005 Robust, and when a topic is not contained in TREC 2005 Robust, they used just the TREC 2004 Robust collection as training set. Therefore, the authors submitted four additional unofficial runs, where both irc task1 WCrobust04 001 and irc task1 WCrobust0405 001 contain all the 50 topics, while the reproduced runs irc task2 WCrobust04 001 and irc task2 WCrobust04 001 contain 25 topics. Note that some of the topics are missing for the reproduced runs, since no training data is available for 25 out of the 50 topics of TREC 2018 Common Core.</p><p>In the following we report the evaluation results for the replicability and reproducibility tasks, both for the official and unofficial submissions.</p><p>Table <ref type="table" coords="9,176.99,510.44,4.98,8.74" target="#tab_4">3</ref> and Table <ref type="table" coords="9,231.70,510.44,4.98,8.74" target="#tab_5">4</ref> report AP, nDCG and ERR scores for the official replicated runs. As shown by RMSE, the replication task was fairly successful with respect to AP and nDCG, while when ERR is considered, RMSE is greater than 0.2, showing that it is harder to replicate ERR than the other evaluation measures. Indeed, it is well known that ERR is highly sensitive to the position of relevant documents at the very beginning of the ranking, thus even the misplacement of a single relevant documents may cause a significant drop in ERR score.</p><p>Furthermore, as the cut-off increases, even RMSE for AP and nDCG increases, showing that the replication is less accurate at lower cut-off levels. On the other side, RMSE for ERR is almost constant when the cut-off increases, showing once more that ERR focuses on the top rank positions rather than considering the whole ranking. Similarly, Table <ref type="table" coords="11,220.43,344.62,4.98,8.74" target="#tab_6">5</ref> reports AP, nDCG and ERR scores for the unofficial replicated run irc task1 WCrobust0405 001. Note that the official and unofficial replicated run irc task1 WCrobust04 001 are identical, therefore the evaluation scores for this unoffical run are the same reported in Table <ref type="table" coords="11,437.58,380.49,4.98,8.74" target="#tab_4">3</ref> and are omitted in the following.</p><p>Again, we can observe that the replication task is more successful for RMSE with respect to AP and nDCG than ERR. Furthermore, RMSE increases as the cut-off increases, meaning that the accuracy of the replicated run decreases as the cut-off level increases.</p><p>By comparing the official and unofficial evaluation results for irc task1-WCrobust0405 001, in Table <ref type="table" coords="11,279.25,470.48,4.98,8.74" target="#tab_5">4</ref> and Table <ref type="table" coords="11,337.46,470.48,4.98,8.74" target="#tab_6">5</ref> respectively, we can note that RMSE score are quite similar, showing that the unofficial run is fairly accurate even on the additional topics. Table <ref type="table" coords="11,177.77,509.50,4.98,8.74" target="#tab_7">6</ref> reports ER for the replication task with the official runs. We considered WCrobust0405 as advanced run and WCrobust04 as baseline run, therefore the per-topic improvement is computed as WCrobust0405 scores minus WCrobust04 scores for each topic. For the replicated official runs, we needed to select from irc task1 WCrobust04 001 the 33 topics contained in irc task1 WCrobust0405 001, otherwise we could not compute the mean per-topic improvement.</p><p>ER shows that the replication task is fairly successful for AP, while it is less successful for nDCG and ERR. Furthermore, ER &gt; 1 highlights that the difference between the advanced and the baseline run is more pronounced in the replicated runs than in the original runs. Again, it can be noted that as the cut-off increases, the accuracy of the replicability exercise decreases for AP and nDCG, while it is almost constant for ERR.   Analogously, Table <ref type="table" coords="13,238.20,364.54,4.98,8.74" target="#tab_8">7</ref> reports ER for the replication task with the unofficial runs. We considered WCrobust0405 as advanced run and WCrobust04 as baseline run, therefore the per-topic improvement is computed as in Table 6 and the first column is equal. Both the replicated unofficial runs contain the same 50 topics, therefore the per-topic improvement is computed as irc task1 WCrobust0405 001 scores minus irc task1 WCrobust04 001 scores for each topic.</p><p>When the whole set of 50 topics is considered, the replication is fairly successful with respect to all the measure, with ER ranging between 0.83 and 1.12. The only exception is represented by AP@10, where the replicated runs fails to replicate the per-topic improvements. Again, the accuracy of the replicated runs decreases as the cut-off increases.</p><p>Table <ref type="table" coords="13,177.80,510.33,4.98,8.74" target="#tab_9">8</ref> reports the Kendall's τ correlation between the original and replicated runs, both for the official and unofficial runs. We computed Kendall's τ at different cut-off levels, where we first trimmed the runs at the specified cut-off and subsequently computed Kendall's τ between the trimmed runs.</p><p>Table <ref type="table" coords="13,177.35,559.31,4.98,8.74" target="#tab_9">8</ref> shows that the replication was not successful for any of the runs in terms of Kendall's τ . This means that even if the considered replicated runs were similar to the original runs in terms of placement of relevant and non relevant documents, they actually retrieves different documents.</p><p>Figure <ref type="figure" coords="13,180.62,608.30,4.98,8.74" target="#fig_0">2</ref> and Figure <ref type="figure" coords="13,238.15,608.30,4.98,8.74" target="#fig_1">3</ref> shows the first 10 rank positions for WCrobust04 and its replicated version irc task1 WCrobust04 001, for topic 307 from TREC 2017 Common Core Track. We can observe that even if the runs retrieves a similar set of documents, the relative position of each document is different. For example, document 309412 is at rank position 1 for the original run, but at rank position 2 for the replicated run, similary document 733642 is at rank position 1 for the replicated run and at rank position 5 for the original run. Moreover, document 241240 is at rank position 3 for the replicated run, but it does not apper on the first 10 positions for the original run.</p><p>Table <ref type="table" coords="14,177.19,394.25,3.87,8.74" target="#tab_9">8</ref>, Figure <ref type="figure" coords="14,219.84,394.25,4.98,8.74" target="#fig_0">2</ref> and Figure <ref type="figure" coords="14,279.18,394.25,4.98,8.74" target="#fig_1">3</ref> highlights how hard is to replicate the exact ranking of documents. Therefore, whenever a replicability task is considered, comparing the evaluation scores with RMSE or ER might not be enough, since these approaches consider just the position of relevant and not relevant documents, and overlook the actual ranking of documents.</p><p>Finally, Table <ref type="table" coords="14,215.39,457.63,4.98,8.74" target="#tab_10">9</ref> reports the mean per-topic improvement and ER for the official runs from the reproducibility task. As done for the replicability task, we considered WCrobust0405 as advanced run and WCrobust04 as baseline run on the test collection from TREC 2017 Common Core Track. For the reproduced official runs, we needed to select from irc task2 WCrobust04 001 the 15 topics contained in irc task2 WCrobust0405 001 from TREC 2018 Common Core Track, otherwise we could not compute the per topic improvement.</p><p>Table <ref type="table" coords="14,177.49,544.92,4.98,8.74" target="#tab_10">9</ref> shows that the reproducibility task is fairly successful with respect to AP, with cut-off 100 and 1000. For nDCG, the improvement of the advanced run over the baseline run is more pronounced for the reproduced runs than for the original runs. Conversely, the improvement of the advanced run over the baseline run is more pronounced for the original runs than for the replicated runs for ERR. Again, ERR is the hardest measure in terms of reproducibility success, with the lowest ER.</p><p>Furthermore, when the cut-off increases, the accuracy of the reproducibility exercise increases for AP, while it decreases for nDCG and remains almost constant for ERR. Similarly, Table <ref type="table" coords="15,221.40,335.87,9.96,8.74" target="#tab_11">10</ref> reports the mean per-topic improvement and ER for the unofficial runs from the reproducibility task. We considered WCrobust0405 as advanced run and WCrobust04 as baseline run on TREC 2017 Common Core, therefore the per-topic improvement is computed as in Table <ref type="table" coords="15,414.67,371.73,4.98,8.74" target="#tab_10">9</ref> and the first column is equal. Both the reproduced unofficial runs contain the same 25 topics, therefore the per-topic improvement is computed as irc task2 WCrobust-0405 001 scores minus irc task2 WCrobust04 001 scores for each topic.</p><p>The best reproducibility results are obtained with respect to AP@10 and nDCG@1000, thus the effect of the advanced run over the baseline run is better reproduced at the beginning of the ranking for AP, and when the whole ranked list is considered, for nDCG. Again, ERR is the hardest measure to be reproduced, indeed it has the lowest ER score for each cut-off level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>This paper reports the results on the second edition of CENTRE@CLEF2019. A total of 19 participants enrolled in the lab, however just one group managed to submit two replicability runs and two reproducibility runs. As reported in Section 3, the participating team could not reproduce the runs from Benham et Al. <ref type="bibr" coords="15,150.97,572.31,9.96,8.74" target="#b6">[7]</ref>, due to the lack of the Gigaworld dataset, but they managed to replicate and reproduce the runs from Grossman and Cormack <ref type="bibr" coords="15,363.59,584.27,14.61,8.74" target="#b17">[18]</ref>. More details regarding the implementation are described in their paper <ref type="bibr" coords="15,347.19,596.22,9.96,8.74">[8]</ref>.</p><p>The experimental results show that the replicated runs are fairly successful with respect to AP and nDCG, while the lowest replicability results are obtained with respect to ERR. As ERR mainly focuses on the beginning of the ranking, misplacing even a single relevant document can deteriorate ERR score and have a great impact on the replicability evaluation scores.</p><p>Moreover, whenever replicability is considered, RMSE and ER are not enough to evaluate the replicated runs. Indeed, they only account for the position of relevant and not relevant documents by considering the similarity between the original scores and the replicated scores, and they overlook the actual ranking of documents. When the runs are evaluated with Kendall's τ to account for the actual position of the documents in the ranking, the experiments show that the replicability is not successful at all, with Kendall's τ values close to 0. This confirms that, even if it is possible to achieve similar scores in terms of IR evaluation measures, it is challenging to replicate the same documents ranking.</p><p>When it comes to reproducibility, there are no well-established evaluation measures to determine to which extent a system can be reproduced. Therefore, we compute ER, firstly exploited in <ref type="bibr" coords="16,295.87,250.50,14.61,8.74" target="#b24">[25]</ref>, which focuses on the reproduction of the improvement of an advanced run over a baseline run. The experiments show that reproducibility was fairly successful in terms of AP@10 and nDCG@1000, while, similarly to the replicability task, ERR is the hardest measure in terms of reproducibility success.</p><p>Finally, as reported in <ref type="bibr" coords="16,251.05,310.28,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="16,268.22,310.28,11.62,8.74" target="#b14">15]</ref>, the lack of participation is a signal that the IR community is somehow overlooking replicability and reproducibility issues. As it also emerged from a recent survey within the SIGIR community <ref type="bibr" coords="16,436.80,334.19,14.61,8.74" target="#b12">[13]</ref>, while there is a very positive attitude towards reproducibility and it is considered very important from a scientific point of view, there are many obstacles to it such as the effort required to put it into practice, the lack of rewards for achieving it, the possible barriers for new and inexperienced groups, and, last but not least, the (somehow optimistic) researcher's perception that their own research is already reproducible.</p><p>For the next edition of the lab we are planning to propose some changes in the lab organization to increase the interest and participation of the research community. First, we will target for more popular systems to be replicated and reproduced, moreover we will consider other tasks than the AdHoc, as for example the medical or other popular domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="13,161.67,297.35,124.50,7.89;13,161.67,308.34,124.50,7.86;13,161.67,319.30,124.50,7.86;13,161.67,330.26,47.40,7.86;13,161.67,205.77,124.50,76.82"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. First 10 rank positions for WCrobust04 for topic 307 form TREC 2017 Common Core Track.</figDesc><graphic coords="13,161.67,205.77,124.50,76.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="13,301.52,297.35,152.16,7.89;13,301.52,309.47,122.66,6.31;13,442.66,308.34,11.03,7.86;13,301.52,319.30,152.16,7.86;13,301.52,330.26,47.40,7.86;13,301.52,206.71,152.17,75.87"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. First 10 rank positions for irc task1 WCrobust04 001 for topic 307 form TREC 2017 Common Core Track.</figDesc><graphic coords="13,301.52,206.71,152.17,75.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,140.99,118.96,339.60,100.53"><head></head><label></label><figDesc>TREC Washington Post Corpus, with TREC 2018 Common Core Topics • Reproducibility: New York Times Annotated Corpus, with TREC 2017 Common Core Topics</figDesc><table /><note coords="5,158.68,118.96,321.91,8.77;5,168.64,130.95,94.45,8.74;5,140.99,145.90,210.68,8.77;5,158.68,160.88,228.66,8.77;5,158.68,173.85,76.22,8.77"><p><p><p><p>• Reproducibility: TREC Washington Post Corpus, with TREC 2018 Common Core Topics -Runs: RMITFDA4 and RMITEXTGIGADA5 [7]</p>• Task Type: TREC 2018 Common Core Track</p><ref type="bibr" coords="5,376.82,160.91,10.52,8.74" target="#b2">[3]</ref> </p>• Replicability:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,115.91,345.82,199.20"><head>Table 1 .</head><label>1</label><figDesc>Topics used for the first edition of CENTRE@CLEF 2019 with the number of documents in the pool.</figDesc><table coords="6,163.08,152.39,289.19,52.32"><row><cell>Evaluation Campaign</cell><cell>Track</cell><cell># Topics</cell><cell>Pool Size</cell></row><row><cell>TREC 2018</cell><cell>Common Core</cell><cell>50</cell><cell>26 233</cell></row><row><cell>TREC 2017</cell><cell>Common Core</cell><cell>50</cell><cell>30 030</cell></row><row><cell>TREC 2004</cell><cell>Robust</cell><cell>250</cell><cell>311 410</cell></row></table><note coords="6,176.52,307.22,262.31,7.89"><p>Fig. 1. Example of a topic for TREC 2018 Common Core Track.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,115.91,345.83,108.23"><head>Table 2 .</head><label>2</label><figDesc>Path to the submitted runs files in the online repository with their description and the number of assessed topics included in each run.</figDesc><table coords="8,140.34,149.75,338.42,74.39"><row><cell>Run Path</cell><cell>Description</cell><cell># Topics</cell></row><row><cell>official/task1/irc task1 WCrobust04 001</cell><cell>official run, replicating WCrobust04</cell><cell>50</cell></row><row><cell>official/task1/irc task1 WCrobust0405 001</cell><cell>official run, replicating WCrobst0405</cell><cell>33</cell></row><row><cell>official/task2/irc task2 WCrobust04 001</cell><cell>official run, reproducing WCrobust05</cell><cell>25</cell></row><row><cell>official/task2/irc task2 WCrobust0405 001</cell><cell>official run, reproducing WCrobust0405</cell><cell>15</cell></row><row><cell>unofficial/complete topics/task1/irc task1 WCrobust04 001</cell><cell>unofficial run, replicating WCrobust04</cell><cell>50</cell></row><row><cell>unofficial/complete topics/task1/irc task2 WCrobust04 001</cell><cell>unofficial run, replicating WCrobust0405</cell><cell>50</cell></row><row><cell>unofficial/complete topics/task2/irc task2 WCrobust04 001</cell><cell>unofficial run, reproducing WCrobust05</cell><cell>25</cell></row><row><cell>unofficial/complete topics/task2/irc task2 WCrobust0405 001</cell><cell>unofficial run, reproducing WCrobust0405</cell><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,153.12,345.83,190.85"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of the replicability task for the official WCrobust04 (50 topics): measures scores averaged across the topics and RMSE.</figDesc><table coords="10,150.43,189.59,314.50,154.38"><row><cell></cell><cell>Original Run</cell><cell>Replicated Run</cell><cell>RMSE</cell></row><row><cell></cell><cell>WCrobust04</cell><cell>irc task1 WCrobust04 001</cell><cell></cell></row><row><cell>AP@10</cell><cell>0.0506</cell><cell>0.0564</cell><cell>0.0224</cell></row><row><cell>AP@100</cell><cell>0.2252</cell><cell>0.1862</cell><cell>0.0868</cell></row><row><cell>AP@1000</cell><cell>0.3821</cell><cell>0.2963</cell><cell>0.1371</cell></row><row><cell>nDCG@10</cell><cell>0.1442</cell><cell>0.1503</cell><cell>0.0567</cell></row><row><cell>nDCG@100</cell><cell>0.3883</cell><cell>0.3421</cell><cell>0.1110</cell></row><row><cell>nDCG@1000</cell><cell>0.6299</cell><cell>0.5418</cell><cell>0.1374</cell></row><row><cell>ERR@10</cell><cell>0.5340</cell><cell>0.5663</cell><cell>0.2463</cell></row><row><cell>ERR@100</cell><cell>0.5341</cell><cell>0.5693</cell><cell>0.2437</cell></row><row><cell>ERR@1000</cell><cell>0.5663</cell><cell>0.5695</cell><cell>0.2436</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,430.64,345.83,190.85"><head>Table 4 .</head><label>4</label><figDesc>Evaluation of the replicability task for the official WCrobust0405 (33 topics): measures scores averaged across the topics and RMSE.</figDesc><table coords="10,139.67,467.12,336.02,154.38"><row><cell></cell><cell>Original Run</cell><cell>Replicated Run</cell><cell>RMSE</cell></row><row><cell></cell><cell>WCrobust0405</cell><cell>irc task1 WCrobust0405 001</cell><cell></cell></row><row><cell>AP@10</cell><cell>0.0473</cell><cell>0.0491</cell><cell>0.0233</cell></row><row><cell>AP@100</cell><cell>0.2541</cell><cell>0.2214</cell><cell>0.0649</cell></row><row><cell>AP@1000</cell><cell>0.4428</cell><cell>0.3751</cell><cell>0.1042</cell></row><row><cell>nDCG@10</cell><cell>0.1490</cell><cell>0.1511</cell><cell>0.0489</cell></row><row><cell>nDCG@100</cell><cell>0.4268</cell><cell>0.3944</cell><cell>0.0814</cell></row><row><cell>nDCG@1000</cell><cell>0.6883</cell><cell>0.6237</cell><cell>0.1025</cell></row><row><cell>ERR@10</cell><cell>0.6601</cell><cell>0.6756</cell><cell>0.2097</cell></row><row><cell>ERR@100</cell><cell>0.6630</cell><cell>0.6777</cell><cell>0.2074</cell></row><row><cell>ERR@1000</cell><cell>0.6630</cell><cell>0.6777</cell><cell>0.2074</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,134.77,116.41,345.83,191.35"><head>Table 5 .</head><label>5</label><figDesc>Evaluation of the replicability task for the unofficial WCrobust0405 (50 topics): measures scores averaged across the topics and RMSE.</figDesc><table coords="11,139.67,153.39,336.02,154.38"><row><cell></cell><cell>Original Run</cell><cell>Replicated Run</cell><cell>RMSE</cell></row><row><cell></cell><cell>WCrobust0405</cell><cell>irc task1 WCrobust0405 001</cell><cell></cell></row><row><cell>AP@10</cell><cell>0.0584</cell><cell>0.0604</cell><cell>0.0209</cell></row><row><cell>AP@100</cell><cell>0.2699</cell><cell>0.2244</cell><cell>0.0798</cell></row><row><cell>AP@1000</cell><cell>0.4378</cell><cell>0.3534</cell><cell>0.1227</cell></row><row><cell>nDCG@10</cell><cell>0.1675</cell><cell>0.1698</cell><cell>0.0484</cell></row><row><cell>nDCG@100</cell><cell>0.4480</cell><cell>0.3994</cell><cell>0.1024</cell></row><row><cell>nDCG@1000</cell><cell>0.6878</cell><cell>0.6064</cell><cell>0.1279</cell></row><row><cell>ERR@10</cell><cell>0.6330</cell><cell>0.6572</cell><cell>0.2106</cell></row><row><cell>ERR@100</cell><cell>0.6359</cell><cell>0.6593</cell><cell>0.2095</cell></row><row><cell>ERR@1000</cell><cell>0.6360</cell><cell>0.6593</cell><cell>0.2095</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,134.77,156.45,345.83,189.16"><head>Table 6 .</head><label>6</label><figDesc>Evaluation of the replicability task with mean per-topic improvement and Effect Ratio (ER) for the official runs (50 topics for original runs and 33 topics for replicated runs).</figDesc><table coords="12,203.44,202.62,208.47,142.99"><row><cell></cell><cell>∆M C orig</cell><cell>∆M C replica</cell><cell>ER</cell></row><row><cell>AP@10</cell><cell>0.0078</cell><cell>0.0065</cell><cell>0.8333</cell></row><row><cell>AP@100</cell><cell>0.0446</cell><cell>0.0576</cell><cell>1.2915</cell></row><row><cell>AP@1000</cell><cell>0.0556</cell><cell>0.0866</cell><cell>1.5576</cell></row><row><cell>nDCG@10</cell><cell>0.0233</cell><cell>0.0309</cell><cell>1.3262</cell></row><row><cell>nDCG@100</cell><cell>0.0597</cell><cell>0.0839</cell><cell>1.4054</cell></row><row><cell>nDCG@1000</cell><cell>0.0578</cell><cell>0.0975</cell><cell>1.6869</cell></row><row><cell>ERR@10</cell><cell>0.1042</cell><cell>0.1270</cell><cell>1.2188</cell></row><row><cell>ERR@100</cell><cell>0.1019</cell><cell>0.1255</cell><cell>1.2316</cell></row><row><cell>ERR@1000</cell><cell>0.1019</cell><cell>0.1254</cell><cell>1.2362</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,134.77,439.46,345.83,178.20"><head>Table 7 .</head><label>7</label><figDesc>Evaluation of the replicability task with mean per-topic improvement and Effect Ratio (ER) for the unofficial runs (50 topics for original and replicated runs).</figDesc><table coords="12,203.44,474.67,208.47,142.99"><row><cell></cell><cell>∆M C orig</cell><cell>∆M C replica</cell><cell>ER</cell></row><row><cell>AP@10</cell><cell>0.0078</cell><cell>0.0040</cell><cell>0.5128</cell></row><row><cell>AP@100</cell><cell>0.0446</cell><cell>0.0382</cell><cell>0.8565</cell></row><row><cell>AP@1000</cell><cell>0.0556</cell><cell>0.0571</cell><cell>1.0270</cell></row><row><cell>nDCG@10</cell><cell>0.0233</cell><cell>0.0195</cell><cell>0.8369</cell></row><row><cell>nDCG@100</cell><cell>0.0597</cell><cell>0.0573</cell><cell>0.9598</cell></row><row><cell>nDCG@1000</cell><cell>0.0578</cell><cell>0.0647</cell><cell>1.1194</cell></row><row><cell>ERR@10</cell><cell>0.1042</cell><cell>0.0908</cell><cell>0.8714</cell></row><row><cell>ERR@100</cell><cell>0.1019</cell><cell>0.0901</cell><cell>0.8842</cell></row><row><cell>ERR@1000</cell><cell>0.1019</cell><cell>0.0899</cell><cell>0.8822</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="13,142.37,115.91,335.69,71.68"><head>Table 8 .</head><label>8</label><figDesc>Kendall's τ between the original and replicated runs.</figDesc><table coords="13,142.37,140.27,335.69,47.32"><row><cell>Replicated Run</cell><cell>Original Run</cell><cell>τ @10</cell><cell>τ @100</cell><cell>τ @1000</cell></row><row><cell>irc task1 WCrobust04 001 official</cell><cell>WCrobust04</cell><cell>-0.0222</cell><cell>0.0073</cell><cell>0.0021</cell></row><row><cell>irc task1 WCrobust0405 001 official</cell><cell>WCrobust0405</cell><cell>-0.0034</cell><cell>0.0316</cell><cell>0.0046</cell></row><row><cell>irc task1 WCrobust0405 001 unofficial</cell><cell>WCrobust0405</cell><cell>-0.0107</cell><cell>0.0199</cell><cell>0.0029</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="14,134.77,115.91,345.83,189.16"><head>Table 9 .</head><label>9</label><figDesc>Evaluation of the reproducibility task with mean per-topic improvement and Effect Ratio (ER) for the official runs (50 topics for original runs and 15 topics for the reproduced runs).</figDesc><table coords="14,196.53,162.08,222.30,142.99"><row><cell></cell><cell>∆M C orig</cell><cell>∆M D reproduced</cell><cell>ER</cell></row><row><cell>AP@10</cell><cell>0.0078</cell><cell>0.0122</cell><cell>1.5641</cell></row><row><cell>AP@100</cell><cell>0.0446</cell><cell>0.0431</cell><cell>0.9664</cell></row><row><cell>AP@1000</cell><cell>0.0556</cell><cell>0.0579</cell><cell>1.0414</cell></row><row><cell>nDCG@10</cell><cell>0.0233</cell><cell>0.0298</cell><cell>1.2790</cell></row><row><cell>nDCG@100</cell><cell>0.0597</cell><cell>0.0767</cell><cell>1.2848</cell></row><row><cell>nDCG@1000</cell><cell>0.0578</cell><cell>0.0898</cell><cell>1.5536</cell></row><row><cell>ERR@10</cell><cell>0.1042</cell><cell>0.0124</cell><cell>0.1190</cell></row><row><cell>ERR@100</cell><cell>0.1019</cell><cell>0.0142</cell><cell>0.1394</cell></row><row><cell>ERR@1000</cell><cell>0.1019</cell><cell>0.0135</cell><cell>0.1325</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="15,134.77,115.91,345.83,189.16"><head>Table 10 .</head><label>10</label><figDesc>Evaluation of the reproducibility task with mean per-topic improvement and Effect Ratio (ER) for the unofficial runs (50 topics for original runs and 25 topics for the reproduced runs).</figDesc><table coords="15,196.53,162.08,222.30,142.99"><row><cell></cell><cell>∆M C orig</cell><cell>∆M D reproduced</cell><cell>ER</cell></row><row><cell>AP@10</cell><cell>0.0078</cell><cell>0.0065</cell><cell>0.8333</cell></row><row><cell>AP@100</cell><cell>0.0446</cell><cell>0.0241</cell><cell>0.5404</cell></row><row><cell>AP@1000</cell><cell>0.0556</cell><cell>0.0336</cell><cell>0.6043</cell></row><row><cell>nDCG@10</cell><cell>0.0233</cell><cell>0.0155</cell><cell>0.6652</cell></row><row><cell>nDCG@100</cell><cell>0.0597</cell><cell>0.0426</cell><cell>0.7136</cell></row><row><cell>nDCG@1000</cell><cell>0.0578</cell><cell>0.0509</cell><cell>0.8806</cell></row><row><cell>ERR@10</cell><cell>0.1042</cell><cell>0.0004</cell><cell>0.0038</cell></row><row><cell>ERR@100</cell><cell>0.1019</cell><cell>0.0033</cell><cell>0.0324</cell></row><row><cell>ERR@1000</cell><cell>0.1019</cell><cell>0.0029</cell><cell>0.0285</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0" coords="3,144.73,646.97,225.95,6.31;3,144.73,657.93,124.73,6.31"><p>https://www.acm.org/publications/policies/ artifact-review-badging</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1" coords="5,144.73,636.01,215.19,6.31"><p>https://catalog.ldc.upenn.edu/LDC2008T19</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2" coords="5,144.73,646.97,182.91,6.31"><p>https://trec.nist.gov/data/wapost/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3" coords="5,144.73,657.93,285.13,6.31"><p>https://trec.nist.gov/data/qa/T8_QAdata/disks4_5.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_4" coords="8,144.73,646.97,215.19,6.31"><p>https://catalog.ldc.upenn.edu/LDC2012T21</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="16,142.96,515.02,337.64,7.86;16,151.52,525.97,329.07,7.86;16,151.52,536.93,329.07,7.86;16,151.52,547.89,329.07,7.86;16,151.52,558.85,329.07,7.86;16,151.52,569.81,329.07,7.86;16,151.52,580.77,329.07,7.86;16,151.52,591.73,329.07,7.86;16,151.52,602.69,329.07,7.86;16,151.52,613.65,329.07,7.86;16,151.52,624.60,329.07,7.86;16,151.52,635.56,47.74,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="16,166.64,613.65,313.95,7.86;16,151.52,624.60,242.13,7.86">Research Frontiers in Information Retrieval -Report from the Third Strategic Workshop on Information Retrieval in Lorne (SWIRL 2018)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Von Billerbeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Capra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Carman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Demartini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mizzaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sitbon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,401.02,624.60,55.31,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-06">June 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.96,645.84,337.63,7.86;16,151.52,656.80,284.21,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="16,151.52,656.80,174.02,7.86">TREC 2017 Common Core Track Overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,347.16,656.80,74.75,7.86">Voorhees and Ellis</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,119.67,337.63,7.86;17,151.52,130.63,284.21,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="17,151.52,130.63,174.02,7.86">TREC 2018 Common Core Track Overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,347.16,130.63,74.75,7.86">Voorhees and Ellis</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,140.76,337.63,7.86;17,151.52,151.72,329.07,7.86;17,151.52,162.68,232.73,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="17,390.73,140.76,89.86,7.86;17,151.52,151.72,329.07,7.86;17,151.52,162.68,35.89,7.86">Report on the SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,195.61,162.68,55.12,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="2015-12">December 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,172.80,337.64,7.86;17,151.52,183.76,329.07,7.86;17,151.52,194.72,329.07,7.86;17,151.52,205.68,329.07,7.86;17,151.52,216.64,93.20,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="17,376.47,172.80,104.12,7.86;17,151.52,183.76,77.50,7.86">Has Adhoc Retrieval Improved Since 1994?</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,177.30,194.72,303.29,7.86;17,151.52,205.68,214.90,7.86">Proc. 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2009)</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting>32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2009)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="692" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,226.77,337.63,7.86;17,151.52,237.72,329.07,7.86;17,151.52,248.68,329.07,7.86;17,151.52,259.64,329.07,7.86;17,151.52,270.60,72.46,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="17,373.46,226.77,107.13,7.86;17,151.52,237.72,189.06,7.86">Improvements That Don&apos;t Add Up: Ad-Hoc Retrieval Results Since 1998</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,297.73,248.68,182.86,7.86;17,151.52,259.64,201.14,7.86">Proc. 18th International Conference on Information and Knowledge Management (CIKM 2009)</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">W L</forename><surname>Cheung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Chu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</editor>
		<meeting>18th International Conference on Information and Knowledge Management (CIKM 2009)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,280.73,337.63,7.86;17,151.52,291.69,329.07,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="17,220.98,291.69,161.07,7.86">RMIT at the 2018 TREC CORE Track</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Benham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
		<imprint>
			<publisher>Voorhees and Ellis</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,312.77,337.64,7.86;17,151.52,323.73,329.07,7.86;17,151.52,334.69,285.27,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="17,249.17,312.77,231.43,7.86;17,151.52,323.73,20.66,7.86">Replicability and Reproducibility of Automatic Routing Runs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Schaer</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="17,433.25,323.73,47.34,7.86;17,151.52,334.69,58.30,7.86">CLEF 2019 Working Notes</title>
		<title level="s" coord="17,217.12,334.69,149.88,7.86">CEUR Workshop Proceedings (CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,344.82,337.64,7.86;17,151.52,355.78,288.78,7.86" xml:id="b8">
	<monogr>
		<title level="m" coord="17,369.41,344.82,106.95,7.86;17,151.52,355.78,183.64,7.86">CEUR Workshop Proceedings (CEUR-WS.org</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CLEF 2018 Working Notes</note>
</biblStruct>

<biblStruct coords="17,142.62,365.90,337.97,7.86;17,151.52,374.59,329.07,10.13;17,151.52,387.82,329.07,7.86;17,151.52,398.78,329.07,7.86;17,151.52,409.74,122.44,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,388.93,365.90,91.66,7.86;17,151.52,376.86,199.19,7.86">The SIGIR 2019 Open-Source IR Replicability Challenge (OSIRRC 2019)</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Clancy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,387.76,387.82,92.83,7.86;17,151.52,398.78,329.07,7.86;17,151.52,409.74,93.78,7.86">Proc. 42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Chevalier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Scholer</surname></persName>
		</editor>
		<meeting>42nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,419.86,337.97,7.86;17,151.52,430.82,329.07,7.86;17,151.52,441.78,329.07,7.86;17,151.52,452.74,329.07,7.86;17,151.52,463.70,235.61,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="17,264.61,452.74,215.98,7.86;17,151.52,463.70,98.53,7.86">The Dagstuhl Perspectives Workshop on Performance Modeling and Prediction</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kuflik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lindén</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shapira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Tintarev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Willemsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,257.14,463.70,55.12,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-06">June 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,473.83,337.98,7.86;17,151.52,484.78,329.07,7.86;17,151.52,495.74,329.07,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="17,439.82,473.83,40.78,7.86;17,151.52,484.78,329.07,7.86;17,151.52,495.74,160.57,7.86">Increasing Reproducibility in IR: Findings from the Dagstuhl Seminar on &quot;Reproducibility of Data-Oriented Experiments in e-Science</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lippold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,322.89,495.74,54.92,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="82" />
			<date type="published" when="2016-06">June 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,505.87,337.98,7.86;17,151.52,516.83,168.78,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="17,239.60,505.87,241.00,7.86;17,151.52,516.83,31.25,7.86">SIGIR Initiative to Implement ACM Artifact Review and Badging</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,190.31,516.83,55.11,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-06">June 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,526.96,337.97,7.86;17,151.52,537.91,188.59,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="17,337.35,526.96,143.24,7.86;17,151.52,537.91,87.00,7.86">CENTRE@CLEF2018: Overview of the Replicability Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<editor>Cappellato et al.</editor>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,548.04,337.97,7.86;17,151.52,559.00,329.07,7.86;17,151.52,569.96,329.07,7.86;17,151.52,580.92,329.07,7.86;17,151.52,591.88,329.07,7.86;17,151.52,602.84,329.07,7.86;17,151.52,613.79,88.94,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="17,335.26,548.04,145.33,7.86;17,151.52,559.00,213.66,7.86">Overview of CENTRE@CLEF 2018: a First Tale in the Systematic Reproducibility Realm</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,176.32,580.92,304.28,7.86;17,151.52,591.88,329.07,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Nineth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="17,231.91,602.84,168.63,7.86">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Bellot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,623.92,337.98,7.86;17,151.52,634.88,329.07,7.86;17,151.52,645.84,329.07,7.86;17,151.52,656.80,25.60,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="17,309.54,623.92,171.06,7.86;17,151.52,634.88,227.77,7.86">Report from Dagstuhl Seminar 16041: Reproducibility of Data-Oriented Experiments in e-Science</title>
	</analytic>
	<monogr>
		<title level="s" coord="17,386.69,634.88,69.74,7.86">Dagstuhl Reports</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016">2016</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Schloss Dagstuhl-Leibniz-Zentrum für Informatik</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,119.67,337.98,7.86;18,151.52,130.63,218.08,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="18,194.38,119.67,286.22,7.86;18,151.52,130.63,31.13,7.86">Some Common Mistakes In IR Evaluation, And How They Can Be Avoided</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,190.18,130.63,55.12,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="41" />
			<date type="published" when="2017-12">December 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,141.59,337.97,7.86;18,151.52,152.55,304.92,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="18,288.38,141.59,192.21,7.86;18,151.52,152.55,191.39,7.86">MRG UWaterloo and WaterlooCormack Participation in the TREC 2017 Common Core Track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,364.29,152.55,74.74,7.86">Voorhees and Ellis</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,163.51,337.98,7.86;18,151.52,174.47,287.35,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="18,269.06,163.51,211.53,7.86;18,151.52,174.47,186.02,7.86">Replicating an Experiment in Cross-lingual Information Retrieval with Explicit Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jungwirth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<editor>Cappellato et al.</editor>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,185.43,310.21,7.86" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
		<title level="m" coord="18,214.81,185.43,102.65,7.86">Rank correlation methods</title>
		<meeting><address><addrLine>Oxford, England</addrLine></address></meeting>
		<imprint>
			<publisher>Griffin</publisher>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,196.39,337.98,7.86;18,151.52,207.35,199.61,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="18,270.78,196.39,150.75,7.86">Mathematics of Statistics -Part One</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Kenney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">S</forename><surname>Keeping</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1954">1954</date>
			<publisher>D. Van Nostrand Company</publisher>
			<pubPlace>Princeton, USA</pubPlace>
		</imprint>
	</monogr>
	<note>3rd edn.</note>
</biblStruct>

<biblStruct coords="18,142.62,218.30,337.98,7.86;18,151.52,229.26,329.07,7.86;18,151.52,240.22,71.81,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="18,373.08,218.30,107.52,7.86;18,151.52,229.26,61.14,7.86">Examining Additivity and Weak Baselines</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kharazmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,220.00,229.26,209.25,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2016-06">June 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,251.18,337.98,7.86;18,151.52,262.14,329.08,7.86;18,151.52,273.10,329.07,7.86;18,151.52,284.06,329.07,7.86;18,151.52,295.02,329.07,7.86;18,151.52,305.98,329.07,7.86;18,151.52,316.93,65.62,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="18,276.66,262.14,203.93,7.86;18,151.52,273.10,115.92,7.86">Toward Reproducible Baselines: The Open-Source IR Reproducibility Challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chattopadhyaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ingersoll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,393.68,284.06,86.91,7.86;18,151.52,295.02,309.23,7.86">Advances in Information Retrieval. Proc. 38th European Conference on IR Research (ECIR 2016)</title>
		<title level="s" coord="18,189.57,305.98,173.06,7.86">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Di Nunzio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Silvello</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">9626. 2016</date>
			<biblScope unit="page" from="357" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,327.89,337.97,7.86;18,151.52,338.85,329.07,7.86;18,151.52,349.81,329.08,7.86;18,151.52,360.77,61.07,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="18,151.52,349.81,146.87,7.86">A manifesto for reproducible science</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Munafò</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">A</forename><surname>Nosek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">V M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Button</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Percie Du Sert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Ware</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P A</forename><surname>Ioannidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,305.62,349.81,105.11,7.86">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2017-01-21">0021. January 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,371.73,337.98,7.86;18,151.52,382.69,329.07,7.86;18,151.52,393.65,329.07,7.86;18,151.52,404.61,273.90,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="18,416.46,371.73,64.14,7.86;18,151.52,382.69,106.77,7.86">Overview of the NTCIR-14 CENTRE Task</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,151.52,393.65,324.97,7.86">Proc. 14th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Ishita</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Kando</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>14th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="494" to="509" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Informatics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,415.56,337.97,7.86;18,151.52,426.52,329.07,7.86;18,151.52,437.48,218.02,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="18,279.44,415.56,201.15,7.86;18,151.52,426.52,33.34,7.86">The Twenty-Sixth Text REtrieval Conference Proceedings</title>
	</analytic>
	<monogr>
		<title level="m" coord="18,194.42,426.52,48.02,7.86">TREC 2017)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Special Publication</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="500" to="324" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,448.44,337.98,7.86;18,151.52,459.40,329.07,7.86;18,151.52,470.36,135.72,7.86" xml:id="b26">
	<monogr>
		<title level="m" coord="18,292.80,448.44,187.79,7.86;18,151.52,459.40,126.51,7.86">The Twenty-Seventh Text REtrieval Conference Proceedings (TREC 2018)</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,481.32,337.97,7.86;18,151.52,492.28,329.07,7.86;18,151.52,503.24,329.07,7.86;18,151.52,514.19,180.22,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="18,350.89,481.32,129.70,7.86;18,151.52,492.28,54.58,7.86">Principles for Robust Evaluation Infrastructure</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,382.75,492.28,97.84,7.86;18,151.52,503.24,324.97,7.86">Proc. Workshop on Data infrastructurEs for Supporting Information Retrieval Evaluation (DESIRE 2011)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Agosti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Thanos</surname></persName>
		</editor>
		<meeting>Workshop on Data infrastructurEs for Supporting Information Retrieval Evaluation (DESIRE 2011)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
