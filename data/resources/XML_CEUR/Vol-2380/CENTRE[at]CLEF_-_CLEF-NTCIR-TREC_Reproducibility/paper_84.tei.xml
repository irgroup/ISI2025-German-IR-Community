<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.94,115.96,235.48,12.62;1,209.14,133.89,197.07,12.62">Replicability and Reproducibility of Automatic Routing Runs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,234.99,172.15,55.81,8.74"><forename type="first">Timo</forename><surname>Breuer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln (University of Applied Sciences)</orgName>
								<address>
									<postCode>50678</postCode>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.50,172.15,63.54,8.74"><forename type="first">Philipp</forename><surname>Schaer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">TH Köln (University of Applied Sciences)</orgName>
								<address>
									<postCode>50678</postCode>
									<settlement>Cologne</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.94,115.96,235.48,12.62;1,209.14,133.89,197.07,12.62">Replicability and Reproducibility of Automatic Routing Runs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDECBD4483A16384700D86CBECD8BA0A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Relevance Transfer</term>
					<term>Replicability</term>
					<term>Reproducibility</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports our participation in CENTRE@CLEF19. We focus on reimplementing submissions by Grossman and Cormack to the TREC 2017 Common Core Track. Our contributions are twofold. Reimplementations are used to study the replicability as well as the reproducibility of WCRobust04 and WCRobust0405. Our results show that the replicability and reproducibility of transferring relevance judgments across different corpora are limited. It is not possible to replicate or reproduce the baseline. However, improvements in evaluation measures by enriching training data are achievable. Further experiments examine general relevance transfer and the augmentation of tfidf-features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Being able to reproduce the results of scientific experiments is essential for the validity of new findings. Especially in the field of computer science, it is desirable to ensure reproducible outcomes of complex systems. In 2018 the Association for Computing Machinery (ACM) introduced publication guidelines and procedures concerned with artifact review and badging 1 . According to these definitions, the terminology of repeatability, replicability, and reproducibility is coined as follows. While repeatability is limited to the reliable repetition of experiments with the same experimental setup conducted by the original researcher, replicability expands this scenario to the conduction by a different researcher. Reproducibility expands replicability by the use of another experimental setup.</p><p>In information retrieval (IR) research evaluation is a primary driver of manifesting innovation. In order to apply new IR systems to different datasets, reproducible evaluation outcomes have to be guaranteed. This requirement led to the advent of attempts like RIGOR <ref type="bibr" coords="1,305.89,589.78,9.96,8.74" target="#b0">[1]</ref>, the Open-Source IR Reproducibility Challenge <ref type="bibr" coords="1,180.84,601.74,10.52,8.74" target="#b4">[5]</ref> and most recently the CENTRE lab which has been held in 2018 at the CLEF conference for the first time <ref type="bibr" coords="2,318.34,118.99,10.52,8.74" target="#b2">[3]</ref> <ref type="foot" coords="2,328.85,117.42,3.97,6.12" target="#foot_0">2</ref> . Its second iteration CENTRE@-CLEF19 <ref type="bibr" coords="2,174.27,130.95,10.52,8.74" target="#b1">[2]</ref> is devoted to the replicability, reproducibility, and generalizibility of IR systems submitted to CLEF, NTCIR and TREC in previous years.</p><p>ACM badging and CENTRE terminologies do not entirely coincide. CEN-TRE defines replicability and reproducibility by the use of original or experimental test collections. In the following, we adhere to the definitions used in the context of CENTRE. We chose to participate in replicating and reproducing the automatic routing runs by Grossman &amp; Cormack <ref type="bibr" coords="2,349.66,203.20,9.96,8.74" target="#b3">[4]</ref>. Thus we are obliged to the following two tasks:</p><p>Task 1 -Replicability: The reimplemented system will replicate the runs WCRobust04 and WCRobust0405 by assessing the New York Times (NYT) corpus which has also been used in the original paper by Grossman &amp; Cormack.</p><p>Task 2 -Reproducibility: The reimplemented system will reproduce the runs WCRobust04 and WCRobust0405 by assessing the TREC Washington Post (WaPo) corpus.</p><p>The remainder of this paper is structured as follows. In Section 2 we outline the original runs WCRobust04 and WCRobust0405. Likewise, document collections will be introduced shortly. Section 3 will give insights into our implementation. Summaries of our results follow in Section 4. The paper ends with Section 5 which concludes our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Automatic Routing Runs &amp; Corpora</head><p>In the context of the TREC Common Core Track in 2017, Grossman and Cormack contributed the WaterlooCormack submissions. More specifically, we will focus on the runs WCRobust04 and WCRobust0405. Both run submissions follow the principle of automatic routing runs. For a given topic a logistic regression model will be trained on relevance judgments from one (or two) collection(s). Afterwards, the model predicts relevance assessments of documents from another collection. In contrast to other retrieval procedures, no explicit query is needed for ranking documents. Training and prediction are done on a topic-wise basis.</p><p>In order to train the model, text documents are transformed into a numerical representation with the help of tfidf-weights. The qrel files are based on ternary relevance judgments and will be converted to a binary scheme. In doing so, tfidf-features can be subdivided into two classes. Training is based on features of judged documents only. The likelihood of tfidf-representations being relevant will score documents. The complete corpus is ranked by score. The 10,000 highestscoring documents form the ranking for a single topic.</p><p>The tfidf-features are derived based on a union corpus which consolidates vocabulary from all corpora. Consequently, training features are augmented by the vocabulary of the corpus whose documents will be judged. Both runs assess documents from the NYT corpus. The two runs differ in the composition of the training set. While WCRobust04 is trained on features derived from documents of Robust04 only, WCRobust0405 enriches the training set by incorporating documents from Robust05. Table <ref type="table" coords="3,267.60,190.72,4.98,8.74">1</ref> gives an overview of run constellations.  <ref type="table" coords="3,163.47,392.95,4.13,7.89">1</ref>. Overview of run constellations and their respective relevance judgments and corpora. Depending on the task, a different corpus will be classified.</p><p>The corpora used in the CENTRE lab contain documents from the news domain. Relevance judgments and documents are taken from corpora of the TREC Robust Track in 2004 <ref type="bibr" coords="3,234.05,473.55,10.52,8.74" target="#b6">[7]</ref> and 2005 <ref type="bibr" coords="3,291.96,473.55,9.96,8.74" target="#b7">[8]</ref>. Relevance will be assessed for the New York Times<ref type="foot" coords="3,184.79,483.93,3.97,6.12" target="#foot_1">3</ref> and Washington Post<ref type="foot" coords="3,283.99,483.93,3.97,6.12" target="#foot_2">4</ref> corpora. The Robust04 collection consists of documents from TREC Disks 4&amp;5<ref type="foot" coords="3,282.41,495.88,3.97,6.12" target="#foot_3">5</ref> (minus Congressional Record data). Articles range from the years 1989 to 1996 and add up to approximately 500,000 single documents. AQUAINT<ref type="foot" coords="3,236.01,519.79,3.97,6.12" target="#foot_4">6</ref> is known as the test collection of Robust05. The document collection gathers articles from the years 1996 to 2000 and holds around one million single documents. TREC Disks 4&amp;5 as well as the AQUAINT corpus consist of SGML-tagged text data. The New York Times corpus covers articles from over 20 years starting in 1987 up to the year 2007. On the whole, the corpus contains 1,8 million documents. The NYT corpus is formatted in News Industry Text Format (NITF) <ref type="foot" coords="3,241.95,591.53,3.97,6.12" target="#foot_5">7</ref> . The TREC Washington Post corpus comprises news articles of a time span from January 2012 to August 2017. The initial version contains duplicate documents. After removing these, the corpus contains nearly 600,000 different articles. The Washington Post corpus is provided as JSON Lines 8 file. Both corpora served as a data basis for the TREC Common Core Tracks in 2017/18.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation</head><p>As depicted in figure <ref type="figure" coords="4,233.06,227.19,3.87,8.74" target="#fig_0">1</ref>, our interpretation of the WaterlooCormack workflow can be subdivided into three processing steps. First of all, corpora data will be prepared, resulting in single documents containing normalized text. The next step consists of deriving tfidf-features from these documents in order to perform topic-wise training and prediction. The last step will evaluate the resulting run with the help of the respective qrels and TREC evaluation measures.</p><p>For our implementation, we chose to use Python. According to the premise of CENTRE, participants are obliged to use open source tools. The Python community offers a vast variety of open and free software, thus we had no problems in finding the required components of the workflow. In the following, more detailed insights into the processing steps of the workflow will be given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data preparation</head><p>Specific characteristics have to be considered when preparing data of four different collections. There are differences both in compression data formats and text formatting. This circumstance has to be kept in mind when trying to implement the workflow as generic as possible. Extraction of compressed corpora files is realized with GNU tools tar 9 and gzip 10 . Within this context, the different extensions of compressed files from the TREC Disks 4&amp;5, AQUAINT and NYT corpora (.z, .0z, .1z, .2z, .gz, .tgz) have to be handled properly. We expect the routine to start with the extracted JSON Lines file of the Washington Post corpus. We use BeautifulSoup 11 in combination with lxml 12 for parsing raw text data from the formatted document files. Embeddings and URLs to external documents were removed. The raw text will be normalized by excluding punctuation, removing stop words, and stemming words in the respective order. For this purpose, we make use of nltk 13 . Originally, documents of two corpora have to be unified into one single corpus. However, our procedure deviates from this approach. The tfidf-weights are derived solely on the basis of the corpus, which provides tfidf-features for the training of the logistic regression model. . Elliptical shapes represent processing steps and rectangular boxes their produced results. After data preparation, the TfidfVectorizer can be derived. Originally, this has to be done with a unified corpus consisting of NYT and Robust04/05 documents. Our approach deviates from this procedure, which is indicated by the dotted arrow. We derive the TfidfVectorizer solely based on Robust04/05 documents. Training data for two classes can be acquired with the help of qrel files from Ro-bust04/05. The training step will result in a logistic regression model, which is adapted for a specific topic. Tfidf-features of the NYT corpus will be classified with this model during the prediction step. The run will be evaluated by using trec eval in combination with the NYT qrels.</p><p>That means tfidf-features will not be augmented by the vocabulary of the corpus whose documents will be ranked. We choose this approach with respect to the results reported in 4.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training &amp; Prediction</head><p>Our implementation of the training and prediction routines mainly relies on the scikit-learn package <ref type="bibr" coords="6,222.00,201.13,9.96,8.74" target="#b5">[6]</ref>. More specifically we make use of the TfidfVectorizer and the LogisticRegression classifier. As explained earlier, training and prediction will be conducted topic-wise. For both steps, a tfidf-representation of documents is required. In order to convert text documents into numerical vectors, we construct the TfidfVectorizer based on Robust04/05 documents (depending on the specific run). Yu et al. <ref type="bibr" coords="6,198.57,260.90,10.52,8.74" target="#b8">[9]</ref> pay special attention to the importance of L 2 -normalization of feature vectors. The TfidfVectorizer uses the L 2 -norm as a default setting. Training features will be stored on disk in SVMlight format to ensure compatibility with other machine learning frameworks. Depending on the corpora constellations, there are deviating numbers of topics for which the logistic regression classifier can be trained and used for classification. Only those topics, which are judged for the test collection as well, can be used for the training of a model. Using NYT in combination with Robust04, for instance, results in a subset of 50 intersecting topics which are judged for both corpora. Combining NYT with Robust05 gives a subset of 33 intersecting topics. For each intersecting topic of the test and training corpus, a ranking with 10,000 entries will be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation</head><p>The evaluation will be done by the use of trec eval. Besides the ranking from the previous step qrels of the corpus to be assessed have to be provided. Evaluation measures are reported in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Miscellanea</head><p>Our code contributions also incorporate other machine learning models. Originally WaterlooCormack runs were computed by the use of Sofia-ML<ref type="foot" coords="6,428.97,507.29,7.94,6.12" target="#foot_6">14</ref> . We tried to integrate Sofia-ML in our workflow but were not able to report any experimental results due to hardware limitations. Using the CLI of Sofia-ML, predictions are done with SVMlight formatted features. Providing the tfidf-features of the entire corpus to Sofia-ML was not possible for us, since we ran out of memory on our 16GB laptop machine. Providing tfidf-features separately as single files to the CLI prolonged the classification routine to unreasonable processing times. Likewise, the use of SVM models from the scikit-learn library resulted in longer processing times. The interfaces of the models are identical and code integration was possible with little effort. However, due to the more compute-intensive nature of SVMs the processing time of a single prediction nearly multiplied by the factor of ten.</p><p>Based on the workflow described in the previous section, we evaluate different combinations of test and training corpora in order to assess the characteristics of the procedure and underlying data. In section 4.1 we try out all corpora combinations beyond the envisaged constellations of WCRobust04 and WCRo-bust0405. In section 4.2 we investigate the necessity of augmenting training data. Section 4.3 has a special focus on the replicability and reproducibility of the WaterlooCormack runs. In this context, we have a look at the benefits of preprocessing text data before deriving tfidf-features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Relevance transfer</head><p>Having four different corpora at hand (TREC Disk 4&amp;5, AQUAINT, NYT, WaPo) we produce runs for all possible corpora combinations. Table <ref type="table" coords="7,446.03,287.12,4.98,8.74" target="#tab_1">2</ref> shows results of all simple combinations. Whereas 'simple' refers to using only one corpus for the training step and omitting the enrichment of tfidf-features by the vocabulary of the test corpus. Figure <ref type="figure" coords="7,315.00,322.99,4.98,8.74">2</ref> shows the MAP values in decreasing order. Classifying NYT documents by relevance judgments from the Robust corpora results in the two highest MAP values. However, the reported MAP values cannot be compared directly due to the deviating number of intersecting topics across different combinations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Replicability and Reproducibility of WCRobust04 &amp; WCRobust0405</head><p>Table <ref type="table" coords="9,163.14,596.34,4.98,8.74" target="#tab_3">4</ref> reports evaluation measures of the replicated and reproduced Water-looCormack runs. All reported MAP values stay below the baseline reported by Grossman and Cormack <ref type="bibr" coords="9,243.78,620.25,9.96,8.74" target="#b3">[4]</ref>. P@10 values of replicated runs stay slightly below those given by the original paper. For each run constellation results without our preprocessing pipeline are added. Especially WCRobust04 profits from our preprocessing proposal.</p><p>Grossman and Cormack retrieve better results when enriching training data by an additional corpus. As explained earlier, the union corpus consists of documents and relevance judgments from Robust04/05 corpora. The improvement of evaluation measures is also valid for both our replicated and reproduced results. Table <ref type="table" coords="10,163.52,166.81,4.98,8.74">5</ref> shows the same evaluation measures based on 15 intersecting topics across all corpora for a better comparison of both tasks. Reproduced runs yield lower measures. Figure <ref type="figure" coords="10,238.56,190.72,4.98,8.74">3</ref> and<ref type="figure" coords="10,266.77,190.72,4.98,8.74" target="#fig_1">4</ref> show bar plots for each of the 15 topics resulting from replication and reproduction, respectively. Improvements by enriching training data are more consistent across topics of replicated runs. 14 out of 15 topics profit from training data enrichment. Evaluation measures of reproduced runs are generally lower and fewer topics profit from training data enrichment (with regards to our sample of 15 topics).  Complementing WCRobust0405 Concerning WCRobust0405, Grossman and Cormack also report MAP and P@10 values based on 50 topics. Our previous setups derive rankings for WCRobust0405 based on 33 topics (replicability) and 15 topics (reproducibility). In our case, topic classifiers are trained on intersecting topics only, i.e., there are 33 intersecting topics between NYT and the Robust corpora and 15 intersecting topics between WaPo and the Robust corpora. With regard to the remaining topics, no details were given in the original paper. For this reason, we chose to investigate solely intersecting topics for WCRobust0405. After contacting Cormack, we came to know that for these topics, training data is taken where available. That means, when training data is only available from Robust04, the classifier will be trained with documents from one corpus only. The resulting rankings should be comparable to those from WCRobust04. Given this information, we retrieved more complete runs, which are shown in table 6. Further considerations Even though the workflow proposed by Grossman and Cormack is intuitive, its description is only one paragraph long in the original paper. As we were reimplementing the workflow, many details had to be considered, which were not explicitly mentioned by the authors. For instance, our text preprocessing improved evaluation measures, but no details about such a processing step are given in the original paper. So, it is possible that there are still hidden details that are not covered by our reimplementation. Furthermore, the implementations of the logistic regression classifier by Sofia-ML and scikit-learn may differ.</p><p>Reflecting on decreasing scores of reproduced runs, it is worth considering the data basis of both replicated and reproduced runs. Replicated runs rank New York Times articles which cover a period from 1987 to 2007. The Robust corpora, used for training, contain articles that fall into this period <ref type="bibr" coords="12,443.48,596.34,37.12,8.74;12,134.77,608.30,22.14,8.74">(1989 to 2000)</ref>. Opposed to this, the Washington Post collection contains more recent news articles from the years 2012 to 2017. News articles are subject to a strong time dependency, and topic coverage varies over time. This influence may affect the choice of words and consequently the vocabulary. News article collections covering the same years may be more likely to share larger amounts of the same vocabulary, which is beneficial for the reimplemented procedure based on tfidffeatures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Our participation in CENTRE@CLEF19 is motivated by replicating and reproducing automatic routing runs proposed by Grossman and Cormack <ref type="bibr" coords="13,432.85,194.33,9.96,8.74" target="#b3">[4]</ref>. For the replicability task, the New York Times corpus is used, whereas the reproducility task applies the procedures to the Washington Post corpus.</p><p>We provide a schematic overview of how we interpret the workflow description of the WaterlooCormack submissions by Grossman and Cormack. The underlying implementation is based on Python and available open source extensions.</p><p>Our experimental setups include assessments of general relevance transfer, tfidf-feature augmentation and the replicability and reproducibility of the Water-looCormack runs. Outcomes of relevance transfer vary across corpora combinations. Ranking the New York Times corpus with the help of relevance judgments and documents from Robust corpora yields the best MAP values. Augmenting tfidf-features by the vocabulary of the corpus to be ranked is originally intended for the WaterlooCormack runs. A further setup investigates the necessity of feature augmentation. Our results conform with the assumptions by Yu et al. <ref type="bibr" coords="13,467.30,349.75,9.96,8.74" target="#b8">[9]</ref>. Augmenting tfidf-features is negligible.</p><p>We were not able to fully replicate or reproduce the baseline given by Grossman and Cormack. All MAP values stay below the baseline. P@10 values of replicated runs differ only slightly from the baseline. Our replicated results are comparable to the classification only approach by Yu et al. Due to missing details in the original paper, we contacted Cormack concerning WCRobust0405 and were able to complement runs which were initially limited to rankings of intersecting topics only.</p><p>Reproduced runs generally perform worse. This might be a starting point for future investigations. General corpora characteristics could be assessed by quantitative and qualitative analysis. These findings might be related to diverging evaluation measures. Likewise, it is possible to exchange the logistic regression model by more sophisticated approaches. Our code contributions provide possibilities for using other models and frameworks. Especially Python implementations should be easily integrable. The source code is available at https://bitbucket.org/centre_eval/c2019_irc/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,538.65,345.83,7.89;5,134.77,549.64,345.83,7.86;5,134.77,560.60,345.82,7.86;5,134.77,571.56,345.82,7.86;5,134.77,582.51,345.83,7.86;5,134.77,593.47,345.83,7.86;5,134.77,604.43,345.83,7.86;5,134.77,615.39,345.82,7.86;5,134.77,626.35,345.83,7.86;5,134.77,637.31,345.82,7.86;5,134.77,648.27,81.74,7.86;5,134.77,115.84,345.84,397.09"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Exemplary visualization of the workflow for the replication of WCRobust04 and WCRobust0405. Elliptical shapes represent processing steps and rectangular boxes their produced results. After data preparation, the TfidfVectorizer can be derived. Originally, this has to be done with a unified corpus consisting of NYT and Robust04/05 documents. Our approach deviates from this procedure, which is indicated by the dotted arrow. We derive the TfidfVectorizer solely based on Robust04/05 documents. Training data for two classes can be acquired with the help of qrel files from Ro-bust04/05. The training step will result in a logistic regression model, which is adapted for a specific topic. Tfidf-features of the NYT corpus will be classified with this model during the prediction step. The run will be evaluated by using trec eval in combination with the NYT qrels.</figDesc><graphic coords="5,134.77,115.84,345.84,397.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,134.77,624.87,345.82,7.89;11,134.77,635.86,87.93,7.86"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Resulting AP values of the reproduced WaterlooCormack runs for each of the 15 intersecting topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,238.32,338.77,162.53"><head>Table</head><label></label><figDesc></figDesc><table coords="3,138.17,238.32,335.37,144.77"><row><cell>Task</cell><cell>Run name</cell><cell>Corpus to be</cell><cell>Relevance</cell><cell>Training data</cell></row><row><cell></cell><cell></cell><cell>classified</cell><cell>judgments for</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>training</cell><cell></cell></row><row><cell>Replicability</cell><cell>WCRobust04</cell><cell>New York Times</cell><cell>Robust Track 2004</cell><cell>TREC Disks 4&amp;5</cell></row><row><cell></cell><cell>WCRobust0405</cell><cell>New York</cell><cell>Robust Track</cell><cell>TREC Disks</cell></row><row><cell></cell><cell></cell><cell>Times</cell><cell>2004 &amp; 2005</cell><cell>4&amp;5 +</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>AQUAINT</cell></row><row><cell>Reproducibility</cell><cell>WCRobust04</cell><cell>Washington Post</cell><cell>Robust Track 2004</cell><cell>TREC Disks 4&amp;5</cell></row><row><cell></cell><cell>WCRobust0405</cell><cell>Washington</cell><cell>Robust Track</cell><cell>TREC Disks</cell></row><row><cell></cell><cell></cell><cell>Post</cell><cell>2004 &amp; 2005</cell><cell>4&amp;5 +</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>AQUAINT</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,406.21,345.83,258.64"><head>Table 2 .</head><label>2</label><figDesc>Transferring relevance judgments across different corpora combinations MAP values for different corpora combinations beyond the envisaged training routine of the WaterlooCormack runs. The first corpus being labeled is the test corpus, whereas the second represents the training data. Direct comparison is not advised due to diverging numbers of intersecting topics. However, it can be seen, that classifying the NYT corpora with a model trained on Robust corpora results in the highest MAP values.In their contribution to the reproducibility track of ECIR 2019 Yu et al. consider augmenting tfidf-features in this manner to be negligible, thus facilitating generalizibility<ref type="bibr" coords="9,202.37,142.90,9.96,8.74" target="#b8">[9]</ref>. Even though this assumption is reasonable, the authors do not provide evidence. The following setup compares different corpora combinations in two variants. The first variant produces runs based on training with tfidf-features derived exclusively from the training corpus. The second variant is based on training features that are augmented by the vocabulary of the corpus to be classified. Numerical representations of documents will contain more tfidf-features, and less out-of-vocabulary terms during prediction should occur. This variant complies with the procedure proposed originally for the Water-looCormack runs. Table3reports evaluation results of these runs. For none of the reported combinations there are significant differences when augmenting training data. For instance, classifying NYT with training data from Robust04 results in a MAP value of 0.2963. Augmenting the training data with the NYT vocabulary results in a MAP value of 0.2924. Due to these findings, we omit augmenting training data for our final runs.</figDesc><table coords="7,134.77,406.21,345.83,258.64"><row><cell>Test</cell><cell>Training</cell><cell>Topics</cell><cell>MAP</cell><cell>P@10</cell></row><row><cell></cell><cell>Robust04</cell><cell>50</cell><cell>0.2963</cell><cell>0.6860</cell></row><row><cell>NYT</cell><cell>Robust05</cell><cell>33</cell><cell>0.3019</cell><cell>0.7212</cell></row><row><cell></cell><cell>WaPo</cell><cell>25</cell><cell>0.1684</cell><cell>0.5120</cell></row><row><cell></cell><cell>NYT</cell><cell>50</cell><cell>0.1183</cell><cell>0.2560</cell></row><row><cell>Robust04</cell><cell>Robust05</cell><cell>50</cell><cell>0.1797</cell><cell>0.4160</cell></row><row><cell></cell><cell>WaPo</cell><cell>25</cell><cell>0.1068</cell><cell>0.3400</cell></row><row><cell></cell><cell>NYT</cell><cell>33</cell><cell>0.1629</cell><cell>0.3455</cell></row><row><cell>Robust05</cell><cell>Robust04</cell><cell>50</cell><cell>0.1913</cell><cell>0.4360</cell></row><row><cell></cell><cell>WaPo</cell><cell>15</cell><cell>0.1430</cell><cell>0.3733</cell></row><row><cell></cell><cell>NYT</cell><cell>25</cell><cell>0.1058</cell><cell>0.3000</cell></row><row><cell>WaPo</cell><cell>Robust04</cell><cell>25</cell><cell>0.1373</cell><cell>0.3200</cell></row><row><cell></cell><cell>Robust05</cell><cell>15</cell><cell>0.1789</cell><cell>0.4333</cell></row><row><cell cols="2">4.2 Feature augmentation</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Originally tfidf-features are derived from the union corpus. That implies tfidf-</cell></row><row><cell cols="5">weights will be determined by the vocabulary of the training and test corpus.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,134.77,492.41,345.83,29.81"><head>Table 3 .</head><label>3</label><figDesc>Feature augmentation for different corpora constellations. The first variant uses the training corpus only for deriving tfidf-weights. The second variant embodies the vocabulary of the test corpus for deriving tfidf-weights.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,134.77,290.99,345.83,336.89"><head>Table 4 .</head><label>4</label><figDesc>Evaluation measures of replicated and reproduced runs based on all intersecting topics for each specific corpora combination. Outcomes are compared against the baseline reported by Grossman and Cormack<ref type="bibr" coords="10,318.02,446.06,9.22,7.86" target="#b3">[4]</ref>. None of the replicated or reproduced runs can reach the baseline in terms of MAP. P@10 of WCRobust04 slightly beats the baseline. Improved measures confirm our preprocessing proposal.</figDesc><table coords="10,134.77,290.99,345.83,336.89"><row><cell>Test</cell><cell cols="2">Training Preprocessing</cell><cell>Topics</cell><cell>MAP</cell><cell>P@10</cell></row><row><cell>Baseline [4]</cell><cell>Robust04 Robust0405</cell><cell>--</cell><cell>50 33</cell><cell>0.3711 0.4307</cell><cell>0.6460 0.7788</cell></row><row><cell>NYT</cell><cell>Robust04 Robust0405</cell><cell>yes no yes no</cell><cell>50 50 33 33</cell><cell>0.2963 0.2671 0.3751 0.3784</cell><cell>0.6860 0.6380 0.7455 0.7455</cell></row><row><cell>WaPo</cell><cell>Robust04 Robust0405</cell><cell>yes no yes no</cell><cell>25 25 15 15</cell><cell>0.1373 0.1003 0.1987 0.2142</cell><cell>0.3200 0.2600 0.4333 0.4333</cell></row><row><cell>Test</cell><cell></cell><cell>Training</cell><cell>MAP</cell><cell></cell><cell>P@10</cell></row><row><cell>NYT</cell><cell cols="2">Robust04 Robust0405</cell><cell>0.2648 0.3788</cell><cell></cell><cell>0.6067 0.7133</cell></row><row><cell>WaPo</cell><cell cols="2">Robust04 Robust0405</cell><cell>0.1409 0.1987</cell><cell></cell><cell>0.2933 0.4333</cell></row><row><cell cols="6">Table 5. Evaluation measures of replicated and reproduced runs based on 15 inter-</cell></row><row><cell>secting topics</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,134.77,306.11,345.83,96.77"><head>Table 6 .</head><label>6</label><figDesc>Evaluation outcomes of WCRobust04 and WCRobust0405 with equal number of topics. Depending on the topic, training data might be derived from Robust04 documents only.</figDesc><table coords="12,138.17,306.11,320.64,57.10"><row><cell>Task</cell><cell>Run</cell><cell>Topics</cell><cell>MAP</cell><cell>P@10</cell></row><row><cell>Replicability</cell><cell>WCRobust04 WCRobust0405</cell><cell>50 50</cell><cell>0.2963 0.3534</cell><cell>0.6860 0.7340</cell></row><row><cell>Reproducibility</cell><cell>WCRobust04 WCRobust0405</cell><cell>25 25</cell><cell>0.1373 0.1708</cell><cell>0.3200 0.4000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,144.73,645.84,335.86,7.86;2,144.73,656.80,29.19,7.86"><p>Note that there have been other iterations of CENTRE at TREC in 2018 and NTCIR in 2019</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,144.73,613.61,188.29,7.47"><p>https://catalog.ldc.upenn.edu/LDC2008T19</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,144.73,624.57,160.05,7.47"><p>https://trec.nist.gov/data/wapost/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="3,144.73,635.53,249.49,7.47"><p>https://trec.nist.gov/data/qa/T8_QAdata/disks4_5.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="3,144.73,646.48,188.29,7.47"><p>https://catalog.ldc.upenn.edu/LDC2002T31</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="3,144.73,657.44,150.64,7.47"><p>https://iptc.org/standards/nitf/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_6" coords="6,144.73,657.44,202.91,7.47"><p>https://code.google.com/archive/p/sofia-ml/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,138.35,591.59,342.24,8.37;13,146.91,602.55,333.68,7.86;13,146.91,613.51,245.49,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,423.59,591.59,57.00,7.86;13,146.91,602.55,333.68,7.86;13,146.91,613.51,68.37,7.86">Report on the SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,224.50,613.51,55.76,7.86">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,623.92,342.24,8.37;13,146.91,634.88,333.67,7.86;13,146.91,645.84,333.68,7.86;13,146.91,656.80,333.68,7.86;14,146.91,119.67,333.68,7.86;14,146.91,130.63,50.68,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,457.68,623.92,22.91,7.86;13,146.91,634.88,51.58,7.86">CEN-TRE@CLEF</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,244.30,634.88,236.29,7.86;13,146.91,645.84,146.27,7.86">Advances in Information Retrieval -41st European Conference on IR Research, ECIR 2019</title>
		<title level="s" coord="14,288.93,119.67,146.53,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Mayr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<meeting><address><addrLine>Cologne, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-04-14">2019. April 14-18, 2019. 2019</date>
			<biblScope unit="volume">11438</biblScope>
			<biblScope unit="page" from="283" to="290" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct coords="14,138.35,141.59,342.24,8.37;14,146.91,152.55,333.68,7.86;14,146.91,163.51,333.68,7.86;14,146.91,174.47,333.68,7.86;14,146.91,185.43,333.68,7.86;14,146.91,196.39,333.68,7.86;14,146.91,207.34,205.53,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,403.29,141.59,77.30,7.86;14,146.91,152.55,288.91,7.86">Overview of CEN-TRE@CLEF 2018: A First Tale in the Systematic Reproducibility Realm</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maistro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,454.46,152.55,26.14,7.86;14,146.91,163.51,333.68,7.86;14,146.91,174.47,198.13,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction -9th International Conference of the CLEF Association, CLEF 2018</title>
		<title level="s" coord="14,451.65,196.39,28.95,7.86;14,146.91,207.34,108.29,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Bellot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Trabelsi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">September 10-14, 2018. 2018</date>
			<biblScope unit="volume">11018</biblScope>
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,218.30,342.24,8.37;14,146.91,229.26,333.68,7.86;14,146.91,240.22,333.68,7.86;14,146.91,251.18,333.68,7.86;14,146.91,262.14,313.07,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,333.28,218.30,147.31,7.86;14,146.91,229.26,250.77,7.86">MRG UWaterloo and WaterlooCormack Participation in the TREC 2017 Common Core Track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,422.72,229.26,57.88,7.86;14,146.91,240.22,229.44,7.86">Proceedings of The Twenty-Sixth Text REtrieval Conference, TREC 2017</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>The Twenty-Sixth Text REtrieval Conference, TREC 2017<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">November 15-17, 2017 (2017</date>
			<biblScope unit="page" from="500" to="324" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,273.10,342.24,8.37;14,146.91,284.06,333.68,8.37;14,146.91,295.02,333.68,7.86;14,146.91,305.98,333.68,7.86;14,146.91,316.93,333.68,7.86;14,146.91,327.89,333.68,7.86;14,146.91,338.85,205.53,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,373.33,284.06,107.26,7.86;14,146.91,295.02,208.72,7.86">Toward reproducible baselines: The open-source IR reproducibility challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chattopadhyaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ingersoll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,379.10,295.02,101.48,7.86;14,146.91,305.98,272.26,7.86">Advances in Information Retrieval -38th European Conference on IR Research, ECIR 2016</title>
		<title level="s" coord="14,451.65,327.89,28.95,7.86;14,146.91,338.85,108.29,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M D</forename><surname>Nunzio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Silvello</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">March 20-23, 2016. 2016</date>
			<biblScope unit="volume">9626</biblScope>
			<biblScope unit="page" from="408" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,349.81,342.25,8.37;14,146.91,362.29,333.68,6.85;14,146.91,373.24,333.68,6.85;14,146.91,382.69,333.68,8.37;14,146.91,393.65,165.65,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,219.38,382.69,169.05,7.86">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,399.98,382.69,80.61,7.86;14,146.91,393.65,73.41,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,404.61,342.24,8.37;14,146.91,415.56,333.67,7.86;14,146.91,426.52,333.68,7.86;14,146.91,437.48,313.07,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,223.14,404.61,168.16,7.86">Overview of the TREC 2004 Robust Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,409.69,404.61,70.89,7.86;14,146.91,415.56,203.52,7.86">Proceedings of the Thirteenth Text REtrieval Conference, TREC 2004</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>the Thirteenth Text REtrieval Conference, TREC 2004<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">November 16-19, 2004 (2004</date>
			<biblScope unit="page" from="500" to="261" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,448.44,342.25,8.37;14,146.91,459.40,333.68,7.86;14,146.91,470.36,333.68,7.86;14,146.91,481.32,333.68,7.86;14,146.91,492.28,80.12,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,227.40,448.44,213.95,7.86">Overview of the TREC 2005 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,462.94,448.44,17.66,7.86;14,146.91,459.40,271.55,7.86">Proceedings of the Fourteenth Text REtrieval Conference, TREC 2005</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<meeting>the Fourteenth Text REtrieval Conference, TREC 2005<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">November 15-18, 2005 (2005</date>
			<biblScope unit="page" from="500" to="266" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.35,503.24,342.24,8.37;14,146.91,514.19,333.68,7.86;14,146.91,525.15,333.68,7.86;14,146.91,536.11,333.67,7.86;14,146.91,547.07,291.79,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,277.41,503.24,203.18,7.86;14,146.91,514.19,35.84,7.86">Simple Techniques for Cross-Collection Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,202.38,514.19,278.21,7.86;14,146.91,525.15,86.18,7.86">Advances in Information Retrieval -41st European Conference on IR Research, ECIR 2019</title>
		<title level="s" coord="14,200.93,547.07,140.53,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Mayr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<meeting><address><addrLine>Cologne, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">April 14-18, 2019. 2019</date>
			<biblScope unit="volume">11437</biblScope>
			<biblScope unit="page" from="397" to="409" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
