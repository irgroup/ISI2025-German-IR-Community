<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.23,115.96,322.89,12.62;1,252.98,133.89,109.41,12.62;1,144.83,151.82,325.71,12.62">ProTestA: Identifying and Extracting Protest Events in News Notebook for ProtestNews Lab at CLEF 2019</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.15,189.50,59.41,8.74"><forename type="first">Angelo</forename><surname>Basile</surname></persName>
							<email>angelo.basile@symanto.netwww.symanto.net</email>
							<affiliation key="aff0">
								<orgName type="institution">Symanto Research GmbH &amp; Co</orgName>
								<address>
									<settlement>Nürnberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.73,189.50,74.01,8.74"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
							<email>t.caselli@rug.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">Rijksuniversiteit Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.23,115.96,322.89,12.62;1,252.98,133.89,109.41,12.62;1,144.83,151.82,325.71,12.62">ProTestA: Identifying and Extracting Protest Events in News Notebook for ProtestNews Lab at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1C36191F3D9CE0434217AF13A38661D2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>document classification</term>
					<term>sentence classification</term>
					<term>event extraction</term>
					<term>protest events</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This notebook describes our participation to the Protest-New Lab, identifying protest events in news articles in English. Systems are challenged to perform unsupervised domain adaptation against three sub-tasks: document classification, sentence classification, and event extraction. We describe the final submitted systems for all sub-tasks, as well as a series of negative results. Results indicate pretty robust performances in all tasks (average F1 of 0.705 for the document classification sub-task, average F1 of 0.592 for the sentence classification sub-task; average F1 0.528 for the event extraction sub-task), ranking in the top 4 systems, although drops in the out-of-domain test sets are not minimal.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The growth of the Web has made more and more data available, and the need for Natural Language Processing (NLP) systems that are able to generalize across data distributions has become a urgent topic. In addition to this, portability of models across data sets, even when assumed to be on the same domain, is still a big challenge in NLP. Indeed recent studies have shown that systems, even when using architectures based on Neural Networks and distributed word representations, are highly dependent on their training sets and can hardly generalise <ref type="bibr" coords="1,165.29,568.19,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="1,180.78,568.19,11.62,8.74" target="#b29">30,</ref><ref type="bibr" coords="1,192.41,568.19,7.75,8.74" target="#b4">5]</ref>.</p><p>The 2019 CLEF ProtestNews Lab 3 targets models' portability and unsupervised domain adaptation in the area of social protest events to support comparative social studies. The lab is organised along three tasks: a.) document classification (Task 1); b.) sentence classification (Task 2); and c.) event trigger and argument extraction (Task 3).</p><p>Task 1 and 2 are essentially text classification tasks. The goal is to distinguish between documents and sentences that report on or contain mentions of protest events. Task 3 is an event extraction task, where systems have to identify the correct event trigger, in this case a protest event, and its associated arguments in every sentence of a document.</p><p>As described in <ref type="bibr" coords="2,223.56,202.77,9.96,8.74" target="#b6">[7]</ref>, the creation of the data sets followed a very detailed procedure to ensure maximal agreement among the annotators as well as to avoid errors. Furthermore, the task is designed as a cascade of sub-tasks: first, identify if a document reports a protest event (Task 1), then identify which sentences are actually describing the protest event in the specific document (Task 2), and, finally, for each protest event sentence, identify the actual event mention(s) and its arguments (Task 3). However, there is no overlap among the training and test data of the three tasks.</p><p>As already mentioned, the lab's main challenge is unsupervised domain adaptation. The lab organisers made available training and development data for one domain, namely news reporting protest events in India, and asked the participants to test their models both on in-domain data and on out-of-domain ones, namely news about protest events in China. In the remainder of the notebook, we will refer to these two test distributions as India and China.</p><p>When analysing the three tasks, it seems evident that the first two tasks are very similar and can be targeted with a common architecture, and possibly features, modulo the granularity of the text message, i.e. full document vs. sentences. On the other hand, the third task requires a dedicated and radically different approach.</p><p>In the remainder of this contribution, we illustrate the systems we developed for the final submissions, and provide some data analysis that may help understand the drops in performance across the two test data. We also describe and reflect on what we tried but did not work as expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Final Systems</head><p>The three tasks have been addressed with two separate systems. In particular, for Task 1 and 2, we opted for a feature based stacked ensemble model based on a set of different basic Logistic Regression classifiers, while for Task 3, we used a Bi-LSTM architecture optimized for sequence labelling task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training Materials</head><p>The lab organisers made available training and development data for each task. Table <ref type="table" coords="2,163.09,620.25,3.87,8.74" target="#tab_0">1</ref>, summarises the distributions of the labels of the training and development data for Task 1 and 2, i.e. document and sentence classification, respectively. As the figures show, the positive class, i.e. the protest documents or sentences, is pretty much unbalanced with respect to the negative one, i.e. non-protest, ranging between 22.41% for Task 1 to 16.78% in Task 2 in training. The distribution of the classes is mirrored in the development data, with minor differences for Task 2, where the positive class is slightly bigger than the negative one (20.81% vs. 16.78%). For training our systems, we did not use any additional training material. The development data was used to identify which methods to use for the final systems rather than fine tuning the models, given the fact that at test time the models has to perform optimally for two different data distributions, in-and out-of-domain (India vs. China). Table <ref type="table" coords="3,177.57,346.88,4.98,8.74" target="#tab_1">2</ref> illustrates the distribution of the annotations for Task 3, i.e. event trigger and argument detection. The data was released in the form of tabdelimited files, with two columns only: the first with pre-tokenized tokens and the second with labels for both event triggers and arguments. Overall, seven different argument types were annotated, namely participant, organiser, target, etime (event time), place, fname (facility name), and loc (location). The role set is inspired by the Automatic Content Extraction (ACE) guidelines for events <ref type="foot" coords="3,473.36,417.04,3.97,6.12" target="#foot_0">4</ref> , and especially the event types Attack and Demonstrate, although the organisers have a finer granularity for locations, as well as for people, or entities, involved in a protest distinguishing, for instance, between organisers, targets, and actual participants. The annotation are encoded in a BIO scheme (Beginning, Inside, Outside), resulting in different alphabets for event triggers (e.g. B-trigger, Itrigger and O) and each of the arguments (e.g. O, B-organiser, I-organiser, B-etime, I-etime, etc.). The training data contains 250 documents and a total of 594 sentences, while the development set is composed by 36 documents for a total of 171 sentences.</p><p>The average amount of event trigger per sentence is 1.41 in training and 1.35 in development, indicating that multiple event triggers are available in the same sentence. As for the arguments, the average per event trigger is 2.24 in training and 1.85 in development, indicating both that arguments are shared among event triggers in the same sentences and that not all arguments are available in every sentence. Similarly to Task 1 and 2, only the available training data was used to train the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classifying Documents and Sentences (Task 1 and Task2)</head><p>The document and sentence classification tasks have been formulated as standard classification tasks. In the perspective of maximizing the system results on both test distributions, we have developed a stacked ensemble model of Logistic Regression classifiers, following a previously successful implementation that showed robust portability <ref type="bibr" coords="4,249.78,289.53,14.61,8.74" target="#b17">[18]</ref>.</p><p>We extracted three different sets of features. Each set of features was used to train a basic Logistic Regression classifier, as available in the scikit learn platform <ref type="bibr" coords="4,175.69,325.51,14.61,8.74" target="#b19">[20]</ref>, and obtain a 10-fold cross-validation prediction for each training set. This means that for each document/sentence, we have 3 basic classifiers as well as their corresponding predictions, resulting in a total of 6 meta level features (3 classifiers X 2 classes per each task) per document/sentence as input for the final meta-classifier. The meta-classifier is an additional Logistic Regression classifier. In training, we have used the default value of the C parameter and balanced class weights. Pre-processing of the data is limited to lowercase, and removal of special characters (e.g. #, * , (, . . . ) and digits.</p><p>Word embeddings features We used the pre-trained FastText embedding <ref type="bibr" coords="4,470.08,433.69,10.52,8.74" target="#b2">[3]</ref> for English with 300 dimensions and sub-word information. <ref type="foot" coords="4,405.24,444.08,3.97,6.12" target="#foot_1">5</ref> For each document/sentence, we obtain a 300 dimension representation by applying average pooling on the token embeddings, any time that a token is not present in the embedding vocabulary, we extract sub-words of length 3 or greater and check if they are present in the embeddings. This is a strategy to maximize the information in the training data as well as to reduce out of vocabulary (OOV) tokens across the different test distributions.</p><p>Most important token and character n-grams features These two sets of features have been identified as useful features to increase the robusteness and portability of the models across data sets. The features have been extracted by performing two sets of TF-IDF scores over each training data (i.e. Task 1 and Task 2) to select the most important tokens and characters n-gram per class (i.e. protest documents/sentences vs. non-protest documents/sentences). For each extracted token, the maximum and minimum cosine similarity is obtained with respect to all tokens in a document/sentence using the FastText embeddings. Similarly to the word embeddings feature, in case a token is not present in the embeddings, we checked for sub-words embeddings. The character n-grams are represented by means of Boolean features indicating whether they are present or not in the document/sentence, thus capturing and representing different information.</p><p>Table <ref type="table" coords="5,177.43,179.37,4.98,8.74" target="#tab_2">3</ref> illustrates the settings used to tune the system for each test distributions and task. The amounts of token and character n-grams varies per task as well as per test distribution. Although more experiments are needed, during the submission phase and quite not surprisingly, we observed that the higher the number of tokens and character n-grams is extracted, the better the model performs on the same test data distribution, thus loosing in portability (for instance, with 4,000 token n-grams and 1,000 characters n-grams, the F1 of Task 2 on China drops to 0.553 to 0.536). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Extracting Events and their Arguments (Task 3)</head><p>We framed the event mention and argument extraction task as a supervised sequence labelling classification problem, following a well established practice in NLP <ref type="bibr" coords="5,173.38,503.03,11.62,8.74" target="#b0">[1,</ref><ref type="bibr" coords="5,185.00,503.03,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,192.75,503.03,11.62,8.74" target="#b25">26,</ref><ref type="bibr" coords="5,204.38,503.03,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="5,212.12,503.03,11.62,8.74" target="#b18">19]</ref>. In particular, given a sentence, S, the system is asked to identify all linguistic expressions w ∈ S, where w is a mention of a protest event, ev w , as well as all linguistic expressions y ∈ S where y is a mention of an argument, arg y , associated to a specific event mention ev w .</p><p>We have implemented a two-step approach using a common sequence labelling model based on a publicly available Bi-LSTM network with a CRF classifier as last layer <ref type="bibr" coords="5,211.07,575.36,14.61,8.74" target="#b24">[25]</ref>. <ref type="foot" coords="5,231.96,573.78,3.97,6.12" target="#foot_2">6</ref> In more details, we developed two different models: first, we detect event trigger mentions, and subsequently, the event arguments (and their roles). Such an approach is inspired by SRL architectures <ref type="bibr" coords="5,412.87,599.27,14.61,8.74" target="#b26">[27]</ref>, where first predicates are identified and disambiguated, and afterwards the relevant arguments are labelled. In our case, we first identify sentences that contain relevant event triggers, and then look for event arguments in these sentences.</p><p>We did not fine-tuned the hyperparameters, but followed the suggestions in <ref type="bibr" coords="6,146.23,130.95,16.13,8.74" target="#b24">[25,</ref><ref type="bibr" coords="6,162.36,130.95,12.10,8.74" target="#b23">24]</ref> for sequence labelling tasks. In Table <ref type="table" coords="6,341.21,130.95,3.87,8.74" target="#tab_3">4</ref>, we report the shared parameters of the networks for both tasks. The "LSTM Layers" refers separately to the number of forward and backward layers. Training is stopped after 5 consecutive epochs with no improvements. Komninos and Manandhar ( <ref type="bibr" coords="6,232.09,322.80,15.50,8.74" target="#b10">[11]</ref>) pre-trained word embeddings are used to initialize the ELMo embeddings <ref type="bibr" coords="6,241.64,334.76,15.50,8.74" target="#b21">[22]</ref> and fine-tune them with respect to the training data. The ELMo embeddings are used to enhance the network generalisation capabilities for event and argument detection over both test data distributions. As for the event trigger detection sub-task, the embedding representations are further concatenated with character-level embeddings <ref type="bibr" coords="6,373.70,382.58,14.61,8.74" target="#b14">[15]</ref>, and parts-of-speech (POS) embeddings. POS tags have been obtained from the Stanford CoreNLP toolkit <ref type="bibr" coords="6,167.11,406.49,14.61,8.74" target="#b15">[16]</ref>. <ref type="foot" coords="6,188.93,404.91,3.97,6.12" target="#foot_3">7</ref> This minimal set of features is further extended with embedding representations for dependency relations and event triggers for the argument detection sub-task. At test time, the protest event triggers are obtained from the event mentions model.</p><p>Both for the event trigger and argument detection sub-tasks, we have conducted five different runs to better asses the variability of the deep learning models due to random initialisations. At test time, we selected the model that obtained the best F1 scores on the development set out of the five runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results on Test Data</head><p>In this section we illustrate the results for all three tasks<ref type="foot" coords="6,382.47,551.64,3.97,6.12" target="#foot_4">8</ref> . Notice that for Task 3 the scores are cumulative for both event trigger and participant detection. For all tasks, the ranking is based on the average F1 of the systems on the two test distributions (i.e. India and China). Table <ref type="table" coords="6,318.10,589.08,4.98,8.74" target="#tab_4">5</ref> reports the results for each task and the corresponding rankings. For ease of comparison, we also report the distance from the best ranking system for each task expressed in differences in F1 scores. Quite disappointingly, the drops against the China test data are not minimal, although with a pretty wide range. The minimal drop is on Task 2, where the system does not perform optimally on the India test data (F1 0.631). On the other hand, the largest drop is in Task 1, where the system looses 0.21 points in F1 when applied to the China data set. As for Task 3, the drop is still relevant (-0.144 points). However, we also noticed that the results for Precision and Recall on the China are pretty well balanced (P = 0.492; R = 0.425), indicating some robustness of the trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Analysis</head><p>To better understand the results of our systems for the three tasks, we have conducted an analysis of the data to highlight similarities and differences. Following recent work <ref type="bibr" coords="7,217.69,404.61,15.50,8.74" target="#b22">[23,</ref><ref type="bibr" coords="7,233.19,404.61,11.62,8.74" target="#b12">13]</ref>, we embrace the vision that corpora, even when on the same domain, are not monolithic entities but rather they are regions in a high dimensional space of latent factors, including topics, genres, writing styles, years of publication, among others, that express similarities and diversities. In particular, we have investigated to what extent the test sets of the three tasks occupy a similar (or different) portions of this space with respect to their corresponding training distributions. To do so, we used two metrics, the Jensen-Shannon (J-S) divergence and the out-of-vocabulary rate of tokens (OOV), that previous work in transfer learning <ref type="bibr" coords="7,247.68,500.25,15.50,8.74" target="#b27">[28]</ref> has shown to be particularly useful for this kind of analysis.</p><p>The J-S divergence assesses similarity between two probability distributions, q and r and is a smoothed, symmetric variant of the Kullback-Leibler divergence. On the other hand, the OOV rate can be used to assess the differences between data distributions, as it highlights the percentage of unknown tokens. All measures have been computed between the training data and the two test distributions, i.e. India and China. Results are reported on Table <ref type="table" coords="7,422.21,584.16,3.87,8.74" target="#tab_5">6</ref>.</p><p>As the figures in Table <ref type="table" coords="7,249.40,596.34,4.98,8.74" target="#tab_5">6</ref> show the test distributions, India and China, can be seen as occupying pretty different portions of this variety of spaces. Not surprisingly, the China distributions are very different from their respective training ones, although with varying degrees. This variation in similarity, however, also affects the India test distributions, where the highest similarity is observed for Task 1 (0.922) and the lowest for Task 3 (0.703). The J-S scores show that the test distributions for Task 3 and Task 2 are even more different than those for Task 1, indicating that the differences in performances of the models across the three tasks is subject to these variations in similarities. As a further support to this observation, we found that there is a positive correlation between the J-S similarity scores and the F1 values across the three tasks (ρ=0.901, p&lt;.05).</p><p>The OOV rates support the observations conducted with the J-S divergence. The OOV rates for the India test distributions are much lower then those compared to China, clearly signalling that there are strong lexical differences among the data sets. The OOV rate for India and China for Task 3 are much closer than those for Task 1 and 2, and still the differences in overall F1 scores for this task between the two test distributions is pretty large (F1 0.600 for India vs. F1 0.456 for China), suggesting that OOV is actually a less powerful predictor of differences in performance between data distributions. Indeed, we have found that there is a negative non significant correlation between OOV rates and the F1 scores across the tasks (ρ=-0.804, p&gt;.05).</p><p>Finally, a further aspect to account for the behavior of the models concerns the proportion of the predictions. In particular, for Task 1 and 2 the proportions of the predictions in the two classes (protest vs. non-protest) are the same as in the training sets for the India data (i.e. in-domain), while they drop when applied to the China tests. In Task 3, the system predicts the same proportion of event triggers in both test distributions (0.90 event per sentence on India, and 0.95 event per sentence on China, respectively), although slightly lower than that observed in training. On the other hand, the proportions of predicted arguments per event are different: on the India data, they are in line with those of the training sets (2.51 vs. 2.24 in training, respectively), while they are lower in the China data (1.94 vs. 2.24 in training, respectively). These observations further indicate that the systems for Tasks 1 and 2 are more dependent on the training set, while the system for Task 3 appears to be more resilient to out-of-domain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Alternative Methods: What Did Not Work</head><p>In this section we briefly report on alternative methods that actually resulted to be detrimental for the performance with respect to the final settings. We mainly focused on changing strategies in modelling by using different algorithms and paradigms rather than attempting to extend the training materials.</p><p>Task 1 and 2 -Inductive Transfer Learning In an attempt to build a system that better generalizes across data sets, we tried exploiting recent advancements in transfer learning. Combining a fine-tuned language model with a classifier has been shown to be a sound strategy for classifying text <ref type="bibr" coords="9,368.14,154.86,9.96,8.74" target="#b5">[6]</ref>. We thus experimented with two pre-trained contextualized embedding models, ELMo <ref type="bibr" coords="9,404.06,166.81,16.13,8.74" target="#b21">[22,</ref><ref type="bibr" coords="9,420.19,166.81,12.10,8.74" target="#b20">21]</ref> and BERT <ref type="bibr" coords="9,134.77,178.77,9.96,8.74" target="#b3">[4]</ref>. In both cases, we extracted fixed representations and used them in combination with a linear SVM with the default hyper-parameters provided by the scikit-learn implementation <ref type="bibr" coords="9,276.85,202.68,14.61,8.74" target="#b19">[20]</ref>. With BERT, we obtain fixed representations by applying average pooling to the second-to-last hidden layer using the pre-trained BERT base model. For Task 1, we represented a document as the average of the sentence embeddings obtained by using ELMo or BERT. We used spaCy for splitting the document into sentences. We experimented with frozen and fine-tuned weights. We fine-tune the inner three layers with ELMo, while we started from the pre-trained base English model and trained it for 10,000 steps on the Indian training set with BERT. In this latter case, training data was assembled by combining the document and sentence training corpora. Finally, we also experimented with an ensemble model using both word and character n-grams and BERT embedding representations.</p><p>We obtained promising results on the development set, but, surprisingly, the performances dropped when applied to the test distributions (F1 = 0.466 for ELMo, and F1 = 0.567 for BERT, respectively). The ensemble model using both dense and sparse representations outperformed the simpler model by 0.1 F1 point.</p><p>Task 1 and 2 -Convolutional Neural Networks (CNN) It has been shown that character-level convolutional neural networks perform well in document and sentence classification tasks <ref type="bibr" coords="9,260.47,429.40,15.50,8.74" target="#b30">[31]</ref> and, being character based, these models are in theory not severely harmed by OOV words, thus making portability across test distributions less prone to errors. We experimented with the architecture described in <ref type="bibr" coords="9,192.61,465.26,14.61,8.74" target="#b9">[10]</ref>, randomly initializing character embeddings, which are then passed as input to a stack of convolutional networks, with kernel sizes ranging from 3 to 7. As a regularization method, we use a 10% dropout <ref type="bibr" coords="9,419.58,489.17,14.61,8.74" target="#b28">[29]</ref>. Similarly to the use of the inductive transfer leaning approaches, good results on the development set were followed by very poor test results (F1 = 0.427). As for this approach, we hypothesize that the training data is too small for effectively using randomly initialized embeddings, although character-based.</p><p>Task 1 and 2 -FastText We experimented with Facebook's FastText system, an an off-the-shelf supervised classifier <ref type="bibr" coords="9,307.82,572.43,9.96,8.74" target="#b8">[9]</ref>. We trained two versions of the system using different token n-grams representations (i.e. bigrams and trigrams), the wiki-news-300d-1M-subword.vec FastText embeddings with subwords for English, and varying learning rates (ranging from 0.1 up to 1.0). We fine tuned the learning rate against the development data. Pre-processing of the data is the same as the one used for the final system, namely lowercase and removal of special characters (e.g. #, * , (, . . . ) and digits. When applied to the test data, the best model scored F1 0.608 We also observed that bigrams performs opti-mally for Task 1, regardless of the test distributions, while for Task 2, bigrams worked best for the in-domain test distributions, i.e. India, and trigrams for the out-of-domain one, i.e. China.</p><p>Task 3 -Multi-task Learning We investigated if a multi-task learning architecture, still based on the Bi-LSTM network, could be a viable solutions to improve the system performance and portability. Given the incompatibility of the Task 3 annotations with other existing corpora for event extraction (e.g. ACE and POLCON <ref type="bibr" coords="10,227.77,219.07,14.76,8.74" target="#b13">[14]</ref>), opted for a multi-task learning approach, as it has proven useful to address scarcity of labeled data. However, we adopted a slightly different strategy: rather than using an alternative tasks in support of our target task, e.g. semantic role labelling in support of opinion role labelling <ref type="bibr" coords="10,462.33,254.94,14.60,8.74" target="#b16">[17]</ref>, we used an alternative data set annotated with different labels but targeting the same problem. We thus extracted all sentences annotated with Attack and Demonstrate events from the ACE corpus and used them as a support task in a multi-task learning setting. In this case, we achieved an averaged F1 of 0.517 for both test distributions, lower than 0.011 points than the final submitted system. On the positive side, however, we observed that the multi-task model obtains the best Precision score on the China test data (0.541), although at a large expense of Recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>Our contribution mainly focused on two aspects: a.) assess the most viable approach for each task at stake and maximize portability with limited efforts; b.) explain the limits of the trained models in terms of similarities and differences across training and test distributions rather than just limiting to technical aspects of the systems.</p><p>Task 1 and Task 2 have shown that a simple system can obtain competitive results in an unsupervised domain adaptation setting. This aspect is actually encouraging and triggers further investigation in this direction by focusing efforts on parameter optimisation. We also believe that the lack of any material for the out-of-domain distributions is a further challenge to take into account, as no fine tuning of the models on the target domain was actually possible. As far as we can put efforts into the development of maximally "generalisable" systems, the dependance of the models on the training materials remains high, thus posing the problem if we are not just modelling data sets rather than linguistic phenomena.</p><p>Task 3 has actually highlighted the contribution of both more complex architectures, such as a Bi-LSTM-CRF network, and contextualised embedding representations, such as ELMo. In this specific case, the trained model is able to predict a comparable amount of event triggers between the two test distributions, although it suffers on the argument sub-task, where less arguments are predicted for the out-of-domain data. Unfortunately, the evaluation format does not allow to quantify the losses per sub-task and per trained models.</p><p>Finally, the similarity and diversity measures (i.e. J-S divergence and OOV) resulted in useful tools to better understand the different behaviors of the systems on both test distributions. It is worth noticing how J-S similarity scores correlates with F1 scores of the trained models, suggesting that it could be possible to quantify, or predict, a margin loss of systems before applying them to out-of-domain test distributions and, consequently, take actions to minimize the losses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,235.43,345.83,83.85"><head>Table 1 .</head><label>1</label><figDesc>Distributions of classes for training and development for Task 1 and Task 2. Numbers in parentheses indicate percentages.</figDesc><table coords="3,160.20,266.77,294.97,52.52"><row><cell>Task</cell><cell>Data set</cell><cell>Protest Not Protest</cell></row><row><cell>Task 1 (Document Classification)</cell><cell>Train Dev.</cell><cell>769 (22.41%) 2,661 (77.58%) 102 (22.31%) 355 (77.68%)</cell></row><row><cell>Task 2 (Sentence Classification )</cell><cell>Train Dev.</cell><cell>988 (16.78%) 4,897 (83.21%) 138 (20.81%) 525 (79.18%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,174.32,535.05,266.71,50.58"><head>Table 2 .</head><label>2</label><figDesc>Distribution of event triggers and arguments for Task 3.</figDesc><table coords="3,253.60,555.42,108.15,30.21"><row><cell cols="2">Annotations Train Dev</cell></row><row><cell>Event Triggers</cell><cell>844 126</cell></row><row><cell>Arguments</cell><cell>1,895 288</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,134.77,297.31,345.83,127.69"><head>Table 3 .</head><label>3</label><figDesc>Most important tokens and character n-grams features for Task 1 and Task 2 across the two test distributions, i.e. India and China.</figDesc><table coords="5,229.88,328.64,156.77,96.36"><row><cell></cell><cell cols="2">Feature Type Test Set Amount</cell></row><row><cell>task 1</cell><cell>Tokens Char. n-grams India India Tokens China Char. n-grams China</cell><cell>8,000 750 4,000 750</cell></row><row><cell>task 2</cell><cell>Tokens Char. n-grams India India Tokens China Char. n-grams China</cell><cell>4,000 1,000 2,000 500</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,215.32,187.67,184.72,94.41"><head>Table 4 .</head><label>4</label><figDesc>System details</figDesc><table coords="6,215.32,208.05,184.72,74.04"><row><cell>Parameters</cell><cell>Value</cell></row><row><cell>LSTM Layers</cell><cell>1</cell></row><row><cell>Units per layer</cell><cell>100</cell></row><row><cell>Optimizer</cell><cell>Nadam</cell></row><row><cell>Gradient Normalisation</cell><cell>τ = 1</cell></row><row><cell>Dropout</cell><cell>Variational, (0.5, 0.5)</cell></row><row><cell>Batch size</cell><cell>12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,191.65,115.91,232.05,95.21"><head>Table 5 .</head><label>5</label><figDesc>Results and ranking for Task 1, 2, and 3.</figDesc><table coords="7,191.65,136.29,232.05,74.84"><row><cell cols="6">Data set Task F1 score Avg. F1 Final Rank -1st</cell></row><row><cell>India China</cell><cell>Task 1 Task 1</cell><cell>0.807 0.597</cell><cell>0.702</cell><cell>3</cell><cell>-0.044</cell></row><row><cell>India China</cell><cell>Task 2 Task 2</cell><cell>0.631 0.553</cell><cell>0.592</cell><cell>4</cell><cell>-0.062</cell></row><row><cell>India China</cell><cell>Task 3 Task 3</cell><cell>0.600 0.456</cell><cell>0.528</cell><cell>3</cell><cell>-0.039</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,134.77,115.91,345.82,82.11"><head>Table 6 .</head><label>6</label><figDesc>Similarity, J-S, and Diversity, OVV, between train and test distributions for all tasks</figDesc><table coords="8,337.50,145.50,79.65,7.89"><row><cell>J-S</cell><cell>OOV</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,646.48,263.61,7.47;3,144.73,657.44,170.95,7.47"><p>https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/ english-events-guidelines-v5.4.3.pdf   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="4,144.73,645.84,335.86,8.12;4,144.73,657.44,191.35,7.47"><p>We used the wiki-news-300d-1M-subword.vec model, available at https:// fasttext.cc/docs/en/english-vectors.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="5,144.73,657.44,236.86,7.47"><p>https://github.com/UKPLab/emnlp2017-bilstm-cnn-crf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="6,144.73,634.88,87.16,7.86"><p>We used version 3.9.2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="6,144.73,645.84,335.86,7.86;6,144.73,656.80,332.51,8.12"><p>Results and ranking were taken from the Codalab page of the ProtestNews Lab available at https://competitions.codalab.org/competitions/22349#results .</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,243.70,337.63,7.86;11,151.52,254.66,329.07,7.86;11,151.52,265.61,106.21,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,189.67,243.70,120.62,7.86">The stages of event extraction</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,331.50,243.70,149.09,7.86;11,151.52,254.66,191.70,7.86">Proceedings of the Workshop on Annotating and Reasoning about Time and Events</title>
		<meeting>the Workshop on Annotating and Reasoning about Time and Events</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,276.30,337.64,7.86;11,151.52,287.25,329.07,7.86;11,151.52,298.21,67.58,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,206.00,276.30,233.58,7.86">ClearTK-TimeML: A minimalist approach to TempEval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,287.25,297.50,7.86">Second Joint Conference on Lexical and Computational Semantics (* SEM)</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="10" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,308.89,337.63,7.86;11,151.52,319.85,247.97,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,364.59,308.89,116.00,7.86;11,151.52,319.85,81.72,7.86">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.96,330.53,337.63,7.86;11,151.52,341.49,329.07,7.86;11,151.52,352.45,25.60,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="11,346.99,330.53,133.60,7.86;11,151.52,341.49,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.96,363.13,337.64,7.86;11,151.52,374.09,329.07,7.86;11,151.52,385.05,329.07,7.86;11,151.52,396.01,329.07,8.12;11,151.52,407.61,85.23,7.47" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,329.85,363.13,150.75,7.86;11,151.52,374.09,145.67,7.86">Breaking nli systems with sentences that require simple lexical inferences</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P18-2103" />
	</analytic>
	<monogr>
		<title level="m" coord="11,317.91,374.09,162.68,7.86;11,151.52,385.05,200.44,7.86">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="650" to="655" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="11,142.96,417.65,337.64,7.86;11,151.52,428.61,61.81,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,243.16,417.65,233.88,7.86">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,165.60,428.61,19.07,7.86">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,439.29,337.64,7.86;11,151.52,450.25,329.07,7.86;11,151.52,461.21,329.07,7.86;11,151.52,472.17,329.07,7.86;11,151.52,483.12,101.04,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,166.18,450.25,314.41,7.86;11,151.52,461.21,34.85,7.86">A task set proposal for automatic protest information collection across multiple countries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hürriyetoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yörük</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yüret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">¸</forename><surname>Yoltar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gürel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Duruşan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,190.62,472.17,138.56,7.86">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Mayr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="316" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,493.80,337.64,7.86;11,151.52,504.76,197.05,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,238.88,493.80,237.90,7.86">Refining event extraction through cross-document inference</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,504.76,117.19,7.86">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="254" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,515.44,337.63,7.86;11,151.52,526.40,215.47,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<title level="m" coord="11,360.75,515.44,119.84,7.86;11,151.52,526.40,49.79,7.86">Bag of tricks for efficient text classification</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.62,537.08,337.98,7.86;11,151.52,548.04,25.60,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,191.88,537.08,232.14,7.86">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,446.93,537.08,33.66,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,558.72,337.97,7.86;11,151.52,569.68,329.07,7.86;11,151.52,580.64,329.07,7.86;11,151.52,591.60,123.44,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,280.63,558.72,199.96,7.86;11,151.52,569.68,59.09,7.86">Dependency based embeddings for sentence classification tasks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Komninos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,233.71,569.68,246.88,7.86;11,151.52,580.64,329.07,7.86;11,151.52,591.60,30.54,7.86">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1490" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,602.28,337.97,7.86;11,151.52,613.24,329.07,7.86;11,151.52,624.20,97.80,7.86" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00350</idno>
		<title level="m" coord="11,263.10,602.28,217.49,7.86;11,151.52,613.24,260.68,7.86">Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.62,634.88,337.97,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.77,329.07,7.89;12,151.52,119.67,329.07,8.11;12,151.52,131.28,122.39,7.47" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,172.52,645.84,308.07,7.86;11,151.52,656.80,160.94,7.86">Automatic recognition of conceptualization zones in scientific articles and two life science applications</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dobnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Batchelor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/bts071</idno>
		<ptr target="http://dx.doi.org/10.1093/bioinformatics/bts071" />
	</analytic>
	<monogr>
		<title level="j" coord="11,322.52,656.80,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="991" to="1000" />
			<date type="published" when="2012-04">Apr 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,141.60,337.98,7.86;12,151.52,152.56,329.07,7.86;12,151.52,163.52,249.88,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,356.29,141.60,124.31,7.86;12,151.52,152.56,283.17,7.86">Towards a dataset of automatically coded protest events from english-language newswire documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lorenzini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kriesi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wueest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,456.89,152.56,23.69,7.86;12,151.52,163.52,221.21,7.86">Paper presented at the Amsterdam Text Analysis Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,174.49,337.98,7.86;12,151.52,185.45,159.05,7.86" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01354</idno>
		<title level="m" coord="12,229.12,174.49,247.58,7.86">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.62,196.42,337.98,7.86;12,151.52,207.37,329.07,7.86;12,151.52,218.33,329.07,7.86;12,151.52,229.29,136.69,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,464.72,196.42,15.88,7.86;12,151.52,207.37,230.82,7.86">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,404.78,207.37,75.81,7.86;12,151.52,218.33,329.07,7.86;12,151.52,229.29,61.64,7.86">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. System Demonstrations</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics. System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,240.26,337.97,7.86;12,151.52,251.22,329.07,7.86;12,151.52,262.18,329.07,7.86;12,151.52,273.14,329.07,7.86;12,151.52,284.10,329.07,7.86;12,151.52,295.06,329.07,8.12;12,151.52,306.66,85.23,7.47" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,268.39,240.26,212.20,7.86;12,151.52,251.22,199.51,7.86">SRL4ORL: Improving opinion role labeling using multi-task learning with semantic role labeling</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1054</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-1054" />
	</analytic>
	<monogr>
		<title level="m" coord="12,377.03,251.22,103.56,7.86;12,151.52,262.18,329.07,7.86;12,151.52,273.14,209.50,7.86">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">Jun 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="583" to="594" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="12,142.62,316.98,337.97,7.86;12,151.52,327.94,324.38,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,212.42,316.98,249.90,7.86">Tuwienkbs at germeval 2018: German abusive tweet detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Montani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,327.94,248.61,7.86">14th Conference on Natural Language Processing KONVENS</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,338.91,337.97,7.86;12,151.52,349.87,329.07,7.86;12,151.52,360.83,329.07,7.86;12,151.52,371.79,329.07,7.86;12,151.52,382.75,25.60,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,274.86,338.91,205.73,7.86;12,151.52,349.87,107.49,7.86">Event detection and domain adaptation with convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,282.75,349.87,197.84,7.86;12,151.52,360.83,329.07,7.86;12,151.52,371.79,148.12,7.86">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<title level="s" coord="12,347.31,371.79,49.39,7.86">Short Papers</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="365" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,393.72,337.98,7.86;12,151.52,404.67,329.07,7.86;12,151.52,415.61,329.07,7.89;12,151.52,426.59,25.60,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,411.80,404.67,68.80,7.86;12,151.52,415.63,94.62,7.86">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,253.06,415.63,145.82,7.86">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,437.56,337.97,7.86;12,151.52,448.52,290.96,7.86" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05987</idno>
		<title level="m" coord="12,299.10,437.56,181.49,7.86;12,151.52,448.52,125.02,7.86">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.62,459.49,337.98,7.86;12,151.52,470.45,328.14,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,195.45,470.45,166.59,7.86">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,383.14,470.45,67.85,7.86">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,481.42,337.97,7.86;12,151.52,492.37,329.07,7.86;12,151.52,503.33,329.07,7.86;12,151.52,514.29,149.49,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,266.16,481.42,210.45,7.86">Effective measures of domain similarity for parsing</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Van Noord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.46,492.37,315.14,7.86;12,151.52,503.33,180.30,7.86">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1566" to="1576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,525.26,337.98,7.86;12,151.52,536.19,329.07,8.14;12,151.52,547.83,47.07,7.47" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="12,263.81,525.26,216.78,7.86;12,151.52,536.22,91.18,7.86">Optimal hyperparameters for deep lstm-networks for sequence labeling tasks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno>CoRR abs/1707.06799</idno>
		<ptr target="http://arxiv.org/abs/1707.06799" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,558.15,337.98,7.86;12,151.52,569.11,329.07,7.86;12,151.52,580.07,329.07,7.86;12,151.52,591.02,329.07,7.86;12,151.52,601.98,237.29,8.12" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,262.05,558.15,218.55,7.86;12,151.52,569.11,226.21,7.86">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1035" />
	</analytic>
	<monogr>
		<title level="m" coord="12,402.54,569.11,78.05,7.86;12,151.52,580.07,287.91,7.86">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="338" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,612.95,337.97,7.86;12,151.52,623.91,329.07,7.86;12,151.52,634.87,225.59,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,307.15,612.95,169.69,7.86">Open domain event extraction from twitter</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.17,623.91,315.42,7.86;12,151.52,634.87,104.81,7.86">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1104" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,645.84,337.97,7.86;12,151.52,656.80,329.07,7.86;13,151.52,119.67,329.07,7.86;13,151.52,130.63,329.07,7.86;13,151.52,141.59,329.07,8.11;13,151.52,153.20,85.23,7.47" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,265.50,645.84,215.09,7.86;12,151.52,656.80,71.81,7.86">Neural semantic role labeling with dependency path embeddings</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1113</idno>
		<ptr target="https://www.aclweb.org/anthology/P16-1113" />
	</analytic>
	<monogr>
		<title level="m" coord="12,255.21,656.80,225.38,7.86;13,151.52,119.67,183.68,7.86">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08">Aug 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="13,142.62,163.51,337.98,7.86;13,151.52,174.47,329.07,7.86;13,151.52,185.43,329.07,7.86;13,151.52,196.39,329.07,8.12;13,151.52,207.99,38.16,7.47" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="13,241.30,163.51,239.30,7.86;13,151.52,174.47,49.15,7.86">Learning to select data for transfer learning with bayesian optimization</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1038" />
	</analytic>
	<monogr>
		<title level="m" coord="13,220.18,174.47,260.41,7.86;13,151.52,185.43,100.02,7.86">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="372" to="382" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,218.30,337.97,7.86;13,151.52,229.26,329.07,7.86;13,151.52,240.20,200.65,7.89" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,151.52,229.26,279.01,7.86">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,438.49,229.26,42.10,7.86;13,151.52,240.22,111.20,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,251.18,337.97,7.86;13,151.52,262.14,329.07,7.86;13,151.52,273.10,97.80,7.86" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.01445</idno>
		<title level="m" coord="13,363.18,251.18,117.41,7.86;13,151.52,262.14,258.59,7.86">The fine line between linguistic generalization and failure in seq2seq-attention models</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,142.62,284.06,337.98,7.86;13,151.52,295.02,120.79,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="13,290.87,284.06,189.73,7.86;13,151.52,295.02,49.79,7.86">Character-level convolutional networks for text classification</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,222.02,295.02,21.63,7.86">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
