<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,201.94,115.96,211.48,12.62;1,151.16,133.89,313.04,12.62;1,161.05,151.82,293.24,12.62">CLEF ProtestNews Lab 2019: Contextualized Word Embeddings for Event Sentence Detection and Event Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,166.63,189.49,98.57,8.74"><forename type="first">Gabriella</forename><surname>Skitalinskaya</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bremen</orgName>
								<address>
									<postCode>28359</postCode>
									<settlement>Bremen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,272.77,189.49,47.94,8.74"><forename type="first">Jonas</forename><surname>Klaff</surname></persName>
							<email>joklaff@uni-bremen.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bremen</orgName>
								<address>
									<postCode>28359</postCode>
									<settlement>Bremen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.41,189.49,101.32,8.74"><forename type="first">Maximilian</forename><surname>Splieth√∂ver</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bremen</orgName>
								<address>
									<postCode>28359</postCode>
									<settlement>Bremen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,201.94,115.96,211.48,12.62;1,151.16,133.89,313.04,12.62;1,161.05,151.82,293.24,12.62">CLEF ProtestNews Lab 2019: Contextualized Word Embeddings for Event Sentence Detection and Event Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6BBEC2C60BFD428403BD04CF04DB35A7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Contextualized String Embeddings</term>
					<term>Classification</term>
					<term>Named Entity Recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work we describe our results achieved in the Protest-News Lab at CLEF 2019. To tackle the problems of event sentence detection and event extraction we decided to use contextualized string embeddings. The models were trained on a data corpus collected from Indian news sources, but evaluated on data obtained from news sources from other countries as well, such as China. Our models have obtained competitive results and have scored 3rd in the event sentence detection task and 1st in the event extraction task based on average F1-scores for different test datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated protest news mining can play a great role in analyzing and understanding protests and their media coverage, especially on a global scale. Such research may be able to support different research domains by capturing the protest's evolution over time and identifying the origins of riots and social movements. Additionally, by analyzing news sources from a wide range of countries we can get a better understanding of the worldwide media coverage of protest events.</p><p>The CLEF-2019 ProtestNews! Lab <ref type="bibr" coords="1,305.20,532.69,15.50,8.74" target="#b17">[19]</ref> tries to tackle this problem and has introduced three shared tasks aimed at identifying and extracting event information from news articles across multiple countries. The aim of the shared tasks is the development of a generalizeable text classification and information extraction tool that could be applied to datasets from different countries without additional training.</p><p>The first task can be described as a binary classification task aimed at discriminating between news articles related to protest events and any other news articles. In the second task, the tool should be able to determine whether a sentence is an event sentence, i.e. contains an event trigger or a mention of it. Finally, the third task is a named entity recognition (NER) task focused on extracting various types of information from a given event sentence such as location, time and participants of an event. In this paper we will only cover the second and third tasks.</p><p>For every task a set of news articles from one country (India) was provided with a predefined training and development split. The resulting models were then evaluated on news articles from the same country as in the training set and on an additional set containing data from another country(China).</p><p>The rest of this paper is organized as follows. We discuss relevant literature in Section 2. Section 3 gives details on the training dataset and the description of the proposed approaches. Section 4 provides experimental evaluation, and important insights gained during our work. We conclude in Section 5, outlining our contributions and directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Various Natural Language Processing (NLP) techniques have been utilized in research to automatically analyze and extract information about events from free-form texts focusing on different types of events and pursuing different goals. We would like to give a few examples of typical approaches used to address the problems of our interest. The authors of <ref type="bibr" coords="2,317.71,392.32,10.52,8.74" target="#b5">[7]</ref> use a Conditional Random Fields (CRF) model to evaluate social media posts of a big event in order to gather information about smaller sub-events, that are collocated to the more popular one. The authors do not focus on political events, but try to find a more generalizable approach, applicable to multiple types of events.</p><p>In contrast to that, <ref type="bibr" coords="2,239.56,452.29,10.52,8.74" target="#b6">[8]</ref> focuses on the analysis of activism. Their main approach is to extract event information from natural language text and visualize it afterwards. Instead of social media posts, as in <ref type="bibr" coords="2,360.89,476.20,9.96,8.74" target="#b5">[7]</ref>, <ref type="bibr" coords="2,378.46,476.20,10.52,8.74" target="#b6">[8]</ref> utilize news articles from media outlets.</p><p>In <ref type="bibr" coords="2,162.55,500.31,10.52,8.74" target="#b6">[8]</ref> the authors use a simple count of certain linguistic features to determine if a sentence is relevant. Similarly, <ref type="bibr" coords="2,318.90,512.27,10.52,8.74" target="#b7">[9]</ref> creates simple hand-crafted rules for different NLP tags (like part-of-speech and named-entity tags) to classify sequences into protest relevant or not.</p><p>The authors of <ref type="bibr" coords="2,218.95,548.33,15.50,8.74" target="#b8">[10]</ref> present an actual use case by using the gathered information to create a protest/demonstration forecast system that is able to predict the occurrences of planned protests by analyzing "open-source documents that appear to indicate civil unrest event planning". They apply simple statistical models to do phrase filtering and Probabilistic Soft Logic to identify geographical information.</p><p>It can be seen that most of the considered approaches use simple term representations, that do not take into account the context of the term or only do so for the train set, which means that terms that never occurred in the training set will always have a zero-vector. To achieve a better approximation for such words, the authors of <ref type="bibr" coords="3,228.91,118.99,15.50,8.74" target="#b12">[14]</ref> train their model to generate representations for parts of words. The idea is to better incorporate subword information and to be able to generate encodings for out-of-vocabulary terms by combining the encoding of different parts of the word.</p><p>Distributed term representations (word embeddings) and a Bi-LSTM have often been used in recent research to solve the task of sequence tagging and classification (see for example <ref type="bibr" coords="3,269.12,190.72,15.50,8.74" target="#b11">[13,</ref><ref type="bibr" coords="3,286.28,190.72,11.62,8.74" target="#b15">17]</ref>). Due to the success of this combination and improvements to the contextualized word embeddings in the recent years, we have chosen to use the flair embeddings and their language model for all tasks in consideration. The chosen approaches will be described in more detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The provided datasets are individual for each task and consist of newspaper articles, taken from Indian and Chinese online-newspapers. The training data consists of news articles from Indian sources whereas the test data is represented by two sets, one containing Indian news sources (test) and the other Chinese news sources (test china). All datasets are in the English language.</p><p>In the case of Task 2, the provided training dataset is imbalanced, 988 sentences have been tagged as protest-related and 4897 as not. Detailed descriptive statistics for each dataset can be found in Table <ref type="table" coords="3,347.84,388.99,3.87,8.74" target="#tab_0">1</ref>.</p><p>For Task 3 the provided train dataset consists of 21623 labeled tokens. The tokens were labeled according to the BIO labeling scheme were a (B) label indicates the first token of an entity, an (I) label all following tokens and an (O) label all tokens, outside of entities. Entities of interest included: 'participant', 'trigger', 'loc', 'place', 'etime', 'fname', 'target'. Full explanations on the what is considered in each entity type can be found in <ref type="bibr" coords="3,339.92,460.72,14.61,8.74" target="#b17">[19]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approach</head><p>In the framework of the ProtestNews Labs we wanted to evaluate how well contextual string embeddings perform in sequence labeling and classifying protest-related news, and whether the models trained on data from one country can be applied to data from other countries.</p><p>Task 2. In this task the goal was to classify whether the above mentioned sentences contain an event-trigger or not. To solve this task we chose an approach using contextualized distributed term representations <ref type="bibr" coords="4,368.16,170.66,15.50,8.74" target="#b11">[13]</ref> to represent the input text. For this purpose, we stacked different traditional word embeddings such as GloVe <ref type="bibr" coords="4,178.73,194.57,15.50,8.74" target="#b10">[12]</ref> and FastText <ref type="bibr" coords="4,261.31,194.57,15.50,8.74" target="#b12">[14]</ref> together with the contextualized embeddings generated from Flair language models (LM), as suggested by <ref type="bibr" coords="4,413.25,206.52,14.61,8.74" target="#b11">[13]</ref>. Flair LMs are character-level Bi-LSTMs, pre-trained on the task of predicting the most probable next character in a sequence of characters. Therefore, they encode in their representation all previous and all following words from the given input sequence. In our work, we used the Flair-LMs pre-trained on a news corpus (news-forward-fast) and the corresponding inverted corpus(news-backward-fast). We choose the described approach for its ability to capture the context of the input, which proved to be useful for this specific task.</p><p>In the next step, we used the generated representations for every word in the given input sequence to derive a vector representation for the whole input sequence by using LSTM-based document embeddings <ref type="bibr" coords="4,373.36,329.92,9.96,8.74">[6]</ref>. In contrast to pooled document embeddings which (by default) represent the document by averaging all word representations, LSTM-based document embeddings take the word vectors as input features and are fine-tuned to the specific downstream task to extract the resulting document embedding from the last hidden state after the fine-tuning [6].</p><p>The resulting document embeddings were used to classify every input sequence as containing an event-trigger <ref type="bibr" coords="4,307.76,417.44,12.73,8.74" target="#b0">(1)</ref> or not (0). The classification itself was performed by a linear transformation, using a single linear layer with the dimension of the resulting document embeddings.</p><p>We tested both the original as well as preprocessed input sequences, where the preprocessing steps included stopword removal, removal of named entities, such as date and time and removal of short words. Since the preprocessed sequences lead to a significant performance drop, we fine-tuned the Flair-LM on the original texts.</p><p>Task 3.The aim of this task is to develop a generalized model to extract event related information, such as location, time and participants, from given sentences. The sentences are, as above mentioned, taken from online newspapers. The task is framed as a named entity recognition (NER) task and therefore a token labeling problem.</p><p>For task 3 we chose pooled contextualized embeddings <ref type="bibr" coords="4,394.80,584.39,15.50,8.74" target="#b13">[15]</ref> for their better performance compared to the non-pooled version. While the standard version of the contextualized flair embeddings does only account for the context of a token per sentence, the pooled embeddings combine the contexts of all usages of the term in the input and concatenates the resulting vector with the contextualized vector for the sequence of interest. The process of generating the embeddings is described in detail in <ref type="bibr" coords="4,229.77,656.12,14.61,8.74" target="#b13">[15]</ref>.</p><p>In both approaches models were trained using the provided train set and validated on the dev data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task 2. Event sentence detection</head><p>In the framework of the sentence event detection task we have submitted two runs experimenting with different minibatch sizes. In both runs we have used LSTMbased document embeddings built with stacked Glove and contextualized string embeddings. In our experiments, we used the hyperparameter settings proposed by the authors in <ref type="bibr" coords="5,214.77,258.38,14.61,8.74" target="#b11">[13]</ref>. The only difference between Run 1 and Run 2 is in the minibatch size, which has been set to 16 and 8 respectively.</p><p>The results obtained by our runs for each dataset as well as the best results in the track and baseline provided by the organizers are presented in Table <ref type="table" coords="5,134.77,306.46,3.87,8.74" target="#tab_1">2</ref>. According to <ref type="bibr" coords="5,207.93,306.46,14.61,8.74" target="#b17">[19]</ref>, a Linear Support Vector Classification with a stochastic gradient descent learning model was selected as a baseline model. For the official testing phase the average of F-scores obtained for each task was used as the performance measure. The second submission was used as our final submission, positioning us in third place.</p><p>When comparing the results achieved by the first and second run, a decrease in quality of classification with the increase in minibatch size can be observed. This may be explained by the following. In cases where models tend to overfit, the gradients calculated with a small batch size are much more noisy than gradients calculated with large batch size, so it is easier for the model to escape from sharp minimizers, and thus leads to a better generalization <ref type="bibr" coords="5,368.04,426.27,14.61,8.74" target="#b14">[16]</ref>.</p><p>One of the goals of the ProtestNews Labs track is to build a model able to generalize outside of the country domain used for training, making it possible to use the the same model to detect event sentences in news sources from other countries. Thus, it is interesting to see not only how well the model performs on data of the two considered countries, but also how big the difference between the achieved results is. In Table <ref type="table" coords="5,257.86,498.26,4.98,8.74" target="#tab_1">2</ref> it can be seen that in Run 2, the gap between the India test score and China test score is the lowest, which can indicate a higher cross-country generalization ability of the proposed model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task 3. Event tagging</head><p>We have submitted 2 runs experimenting with different standard word embeddings, which were stacked with pooled contextualized string embeddings, as recommended in <ref type="bibr" coords="6,194.84,163.48,14.61,8.74" target="#b13">[15]</ref>. Using these embeddings we trained our own Sequence Tagging Models. In the first run we have used FastText embeddings <ref type="bibr" coords="6,396.05,175.44,14.61,8.74" target="#b12">[14]</ref>, whereas in the second run we tried the Glove embeddings <ref type="bibr" coords="6,323.97,187.39,14.61,8.74" target="#b10">[12]</ref>. In our experiments, we use the hyperparameter settings recommended by the authors in <ref type="bibr" coords="6,388.89,199.35,15.50,8.74" target="#b13">[15]</ref> as they achieved state-of-the-art performance in other natural language processing tasks.</p><p>The results obtained by our runs for each dataset are presented in Table <ref type="table" coords="6,134.77,235.34,3.87,8.74" target="#tab_2">3</ref>. During the testing phase the average of F-scores obtained for each dataset was used as the performance measure. The second submission was used as our final submission and landed us the first place. It can be seen that there is a considerable difference in the results obtained for different countries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper we tackled the problem of event sentence detection and event tagging in protest-related news articles at the CLEF ProtestNews Lab. The proposed solutions were based on using contextualized string embeddings. We achieved the best F-score in extracting relevant information from event-related sentences, and the third-best F-score in classifying sentences from news articles. The improvement of the generalization ability of the approach will be the main focus of our future work. We will try other embeddings such as bert <ref type="bibr" coords="6,451.93,520.93,16.76,8.74" target="#b16">[18]</ref> to further investigate if an attention based incorporation of the context improves the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,171.96,491.27,270.71,95.21"><head>Table 1 .</head><label>1</label><figDesc>Dataset description per task</figDesc><table coords="3,171.96,512.05,270.71,74.44"><row><cell></cell><cell></cell><cell cols="2">Task2</cell><cell></cell><cell>Task3</cell></row><row><cell></cell><cell># of sent</cell><cell>min length</cell><cell>max length</cell><cell>average length</cell><cell># of tokens</cell></row><row><cell>train</cell><cell>5882</cell><cell>3</cell><cell>988</cell><cell>146</cell><cell>21623</cell></row><row><cell>dev</cell><cell>662</cell><cell>15</cell><cell>539</cell><cell>153</cell><cell>3188</cell></row><row><cell>test</cell><cell>1107</cell><cell>2</cell><cell>499</cell><cell>147</cell><cell>6506</cell></row><row><cell>test china</cell><cell>1235</cell><cell>6</cell><cell>664</cell><cell>141</cell><cell>4345</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,142.93,554.18,329.49,83.86"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of the results obtained by different runs on the test datasets</figDesc><table coords="5,181.17,574.96,253.02,63.08"><row><cell></cell><cell cols="3">Set 1 (China) Set 2 (India) Average F-score F-score F-score</cell></row><row><cell>Baseline</cell><cell>0.200</cell><cell>0.582</cell><cell>0.391</cell></row><row><cell>Best results</cell><cell>0.604</cell><cell>0.706</cell><cell>0.655</cell></row><row><cell>Run 1</cell><cell>0.523</cell><cell>0.617</cell><cell>0.570</cell></row><row><cell>Run 2</cell><cell>0.583</cell><cell>0.648</cell><cell>0.615</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,140.84,301.03,333.67,73.00"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of the results obtained by different runs on the test datasets</figDesc><table coords="6,140.84,321.80,333.67,52.22"><row><cell cols="3">Set 1 (China)</cell><cell cols="3">Set 2 (India)</cell><cell>Macro average</cell><cell>Macro average</cell><cell>Macro average</cell></row><row><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell cols="6">Run 1 62.72 41.00 49.59 61.44 47.98 53.88</cell><cell>62.08</cell><cell>44.49</cell><cell>51.73</cell></row><row><cell cols="6">Run 2 62.65 46.24 53.21 66.20 55.67 60.48</cell><cell>64.43</cell><cell>50.96</cell><cell>56.85</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,601.61,342.23,7.86;6,146.91,612.57,79.20,7.86" xml:id="b0">
	<monogr>
		<ptr target="https://www.crummy.com/software/BeautifulSoup/.Lastac-cessed21" />
		<title level="m" coord="6,146.91,601.61,78.33,7.86">BeautifulSoup -bs4</title>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,623.66,324.17,7.86" xml:id="b1">
	<monogr>
		<ptr target="https://www.nltk.org/" />
		<title level="m" coord="6,146.91,623.66,103.21,7.86">Natural Language Toolkit</title>
		<imprint>
			<date type="published" when="2019-05-21">21 May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,634.75,300.73,7.86" xml:id="b2">
	<monogr>
		<ptr target="https://www.spacy.io" />
		<title level="m" coord="6,146.91,634.75,84.09,7.86">Explosion AI -spaCy</title>
		<imprint>
			<date type="published" when="2019-05-21">21 May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,645.84,350.63,7.86;6,146.91,656.80,143.18,7.86" xml:id="b3">
	<monogr>
		<ptr target="https://spacy.io/api/annotation#named-entities" />
		<title level="m" coord="6,146.91,645.84,170.04,7.86">Annotation Specifications -Named Entities</title>
		<imprint>
			<date type="published" when="2019-05-21">21 May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,119.67,342.23,7.86;7,146.91,130.63,108.57,7.86" xml:id="b4">
	<monogr>
		<ptr target="https://textblob.readthedocs.io/en/dev/" />
		<title level="m" coord="7,146.91,119.67,157.46,7.86">TextBlob: Simplified Text Processing</title>
		<imprint>
			<date type="published" when="2019-05-21">21 May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,163.51,342.23,7.86;7,146.91,174.47,333.67,7.86;7,146.91,185.43,333.66,7.86;7,146.91,196.39,333.67,7.86;7,146.91,207.35,28.16,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,418.51,163.51,62.06,7.86;7,146.91,174.47,214.25,7.86">Extraction and Compilation of Events and Sub-events from Twitter</title>
		<author>
			<persName coords=""><forename type="first">Arpit</forename><surname>Khurdiya</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dey</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lipika</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Diwakar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ishan</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,384.36,174.47,96.22,7.86;7,146.91,185.43,333.66,7.86;7,146.91,196.39,118.27,7.86">Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology</title>
		<meeting>the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="504" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,218.30,342.23,7.86;7,146.91,229.26,333.67,7.86;7,146.91,240.22,333.67,7.86;7,146.91,251.18,245.95,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,314.29,229.26,166.29,7.86;7,146.91,240.22,241.38,7.86">Extractivism: Extracting Activist Events from News Articles Using Existing NLP Tools and Services</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ploeger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kruijt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">M</forename><surname>Aroyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">G A</forename><surname>De Bakker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Fokkens-Zwirello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Hoeksema</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Braake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,410.18,240.22,70.40,7.86;7,146.91,251.18,46.41,7.86">CEUR Workshop Proceedings</title>
		<title level="s" coord="7,240.55,251.18,121.09,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">3041</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,262.14,342.22,7.86;7,146.91,273.10,333.66,7.86;7,146.91,284.06,333.67,7.86;7,146.91,295.02,79.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,439.57,262.14,41.00,7.86;7,146.91,273.10,263.93,7.86">Planned Protest Modeling in News and Social Media</title>
		<author>
			<persName coords=""><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><surname>Arredondo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Mares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,432.50,273.10,48.07,7.86;7,146.91,284.06,329.41,7.86">Proceedings of the Twenty-Seventh Innovative Applications of Artificial Intelligence Conference</title>
		<meeting>the Twenty-Seventh Innovative Applications of Artificial Intelligence Conference</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Naren Ramakrishnan</note>
</biblStruct>

<biblStruct coords="7,142.61,305.98,337.96,7.86;7,146.91,316.94,333.66,7.86;7,146.91,327.89,333.66,7.86;7,146.91,338.85,333.66,7.86;7,146.91,349.81,277.36,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,305.38,316.94,175.19,7.86;7,146.91,327.89,176.40,7.86">Just the Facts with PALOMAR: Detecting Protest Events in Media Outlets and Twitter</title>
		<author>
			<persName coords=""><forename type="first">Konstantina</forename><surname>Papanikolaou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Papasarantopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Theoni</forename><surname>Stathopoulou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Papastefanatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,343.05,327.89,137.52,7.86;7,146.91,338.85,333.66,7.86;7,146.91,349.81,109.17,7.86">The Workshops of the Tenth International AAAI Conference on Web and Social Media Social Media in the Newroom: Technical Report WS-16-19</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,360.77,337.96,7.86;7,146.91,371.73,287.04,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,388.25,360.77,92.33,7.86;7,146.91,371.73,153.46,7.86">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,382.69,337.96,7.86;7,146.91,393.65,333.66,7.86;7,146.91,404.61,333.67,7.86;7,146.91,415.57,137.94,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,402.12,382.69,78.45,7.86;7,146.91,393.65,115.78,7.86">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,283.61,393.65,196.97,7.86;7,146.91,404.61,207.13,7.86">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">15321543</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,426.52,337.96,7.86;7,146.91,437.48,333.67,7.86;7,146.91,448.44,333.66,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,341.86,426.52,138.72,7.86;7,146.91,437.48,72.13,7.86">Contextual String Embeddings for Sequence Labeling</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,238.99,437.48,241.59,7.86;7,146.91,448.44,75.46,7.86">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">16381649</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,459.40,337.96,7.86;7,146.91,470.36,300.94,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="7,441.77,459.40,38.81,7.86;7,146.91,470.36,162.85,7.86">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName coords=""><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,481.32,337.96,7.86;7,146.91,492.28,194.36,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="7,368.97,481.32,111.61,7.86;7,146.91,492.28,158.94,7.86">Pooled Contextualized Embeddings for Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,503.24,337.96,7.86;7,146.91,514.20,333.66,7.86;7,146.91,525.15,100.36,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="7,423.63,503.24,56.95,7.86;7,146.91,514.20,265.88,7.86">On large-batch training for deep learning: Generalization gap and sharp minima</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04836</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,536.11,337.96,7.86;7,146.91,547.07,333.66,7.86;7,146.91,558.03,188.33,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,398.52,547.07,82.06,7.86;7,146.91,558.03,82.22,7.86">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,236.17,558.03,67.85,7.86">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,568.99,337.96,7.86;7,146.91,579.95,333.66,7.86;7,146.91,590.91,28.16,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="7,335.65,568.99,144.93,7.86;7,146.91,579.95,195.52,7.86">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.61,601.87,337.96,7.86;7,146.91,612.83,333.67,7.86;7,146.91,623.78,333.66,7.86;7,146.91,634.74,333.66,7.86;7,146.91,645.70,30.72,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="7,164.17,612.83,316.41,7.86;7,146.91,623.78,75.75,7.86">A Task Set Proposal for Automatic Protest Information Collection Across Multiple Countries</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>H√ºrriyetoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Y√∂r√ºk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Y√ºret</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">¬∏</forename><surname>Yoltar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>G√ºrel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Duru≈ü An</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-15719-7</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/978-3-030-15719-7" />
	</analytic>
	<monogr>
		<title level="m" coord="7,244.33,623.78,193.58,7.86">European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="316" to="323" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
