<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,175.80,115.90,263.75,12.90;1,224.93,133.83,165.50,12.90;1,223.43,153.83,168.50,10.75">FOI Cross-Domain Authorship Attribution for Criminal Investigations Notebook for PAN at CLEF 2019</title>
				<funder ref="#_u7tyCJw">
					<orgName type="full">Swedish Armed Forces</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,237.57,190.37,72.78,8.64"><forename type="first">Fredrik</forename><surname>Johansson</surname></persName>
							<email>fredrik.johansson@foi.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Swedish Defence Research Agency (FOI) Stockholm</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.71,190.37,48.08,8.64"><forename type="first">Tim</forename><surname>Isbister</surname></persName>
							<email>tim.isbister@foi.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Swedish Defence Research Agency (FOI) Stockholm</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,175.80,115.90,263.75,12.90;1,224.93,133.83,165.50,12.90;1,223.43,153.83,168.50,10.75">FOI Cross-Domain Authorship Attribution for Criminal Investigations Notebook for PAN at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">578F7E92D7CCB67273AAF58FA0253C26</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorship attribution techniques have existed for a long time, but they are seldom evaluated in conditions similar to the real-world scenarios in which they have to work if they should be useful tools in criminal investigations involving digital communication. We have used a SVM classifier as a base, onto which we have added two sets of hand-crafted stylometric features and evaluated it using data from the PAN-CLEF 2019 cross-domain authorship attribution task. Results outperform the baseline systems to which our classifiers have been compared.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite that the uniqueness of individuals' fingerprints has been widely known for several decades, collecting and matching fingerprints from crime scenes to the fingerprints of suspects or large databases is still a useful tool in many criminal investigations. However, an increasing amount of crimes are carried out in the digital environment rather than in the physical world. People are sending threatening e-mails to politicians. Drug sellers advertise for cheap LSD on illegal darknet marketplaces. Terrorists post violent extremism propaganda on social media. The list goes on and on. In common for many crimes in the digital arena is that they in many cases involve digital written communication of various types. Therefore, it is unsurprisingly that many researchers in recent years have considered the idea to "fingerprint" online users by extracting and, in various ways, compare stylometric features such as distribution of function words, parts of speech, and word lengths from their written texts. One well-known and promising example of this type of methods is the Writeprint technique, developed by researchers at the University of Arizona <ref type="bibr" coords="1,249.57,555.37,10.58,8.64" target="#b0">[1]</ref>. In their experiments, as well as in many other authorship attribution studies, it is often assumed that criminal investigators have access to texts written by a (usually quite small) set of candidate authors, and that the anonymous texts with unknown authorship have been written by one of these candidate authors. Different studies have shown promising results for many types of digital communication, involving everything from e-mails <ref type="bibr" coords="1,299.62,615.14,16.60,8.64" target="#b14">[15]</ref> and forum posts <ref type="bibr" coords="1,390.11,615.14,16.60,8.64" target="#b10">[11]</ref> to tweets <ref type="bibr" coords="1,450.92,615.14,11.62,8.64" target="#b8">[9]</ref> and blog posts <ref type="bibr" coords="2,179.58,119.31,15.27,8.64" target="#b9">[10]</ref>. One fundamental issue with these studies is that they tend to almost always be conducted on English texts. Far from all offenders in the digital environment communicate in English, so there is a need for more studies on how this kind of stylometric techniques work for other languages. Another issue is that criminal investigators in practice far from always are able to access training data from the same type of written communication as the anonymous texts that are supposed to be matched against the training data. However, it is quite seldom that studies evaluate how well authorship attribution algorithms perform when training on data from other medium types than they are tested on. Moreover, the available texts are seldom controlled for topic, leading to possibilities that authors may sometimes be distinguished based on topic rather than style. Given these issues it is still not obvious whether stylometric techniques are practically useful for law enforcement in real-world criminal investigations or not. For this reason, the PAN 2019 cross-domain authorship attribution task <ref type="bibr" coords="2,385.53,262.77,11.62,8.64" target="#b6">[7]</ref> is highly interesting. First of all it is cross-domain, meaning that texts of known and unknown authorship come from different domains. It is also the case that the challenge is an example of open-set attribution, meaning that the true author is not necessarily included in the list of candidate authors. Finally, it is also multilingual in the sense that it in addition to English also covers French, Italian, and Spanish texts.</p><p>The rest of this paper is structured as follows. First, we give an overview of previous work on authorship attribution in Section 2. In Section 3, we briefly describe the data available for the PAN 2019 authorship attribution task and present different ideas for how the challenge at hand can be tackled using different overall design choices. In Section 4, we describe the features we have implemented and used in our submitted systems. This is followed by Section 5, in which we give a detailed system description of how the various features have combined, scaled, and fed into two different classifiers. The obtained results are presented in Section 6. Finally, we conclude the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A systematic review of the research field is outside the scope of this paper, but it is important to note that authorship attribution overall is a quite well-studied problem. As mentioned by Juola in his review of the history of the authorship attribution research field forward to around year 2006, the idea of telling something about a person from the language he or she uses goes back at least until the days of the Old Testament <ref type="bibr" coords="2,466.48,536.89,10.58,8.64" target="#b5">[6]</ref>. As clearly stated by Juola, the underlying theory behind most authorship attribution approaches is that some kind of fingerprint of an author can be extracted as a summary statistic from a given text, and that different authors will vary, noticeably and consistently, along this summary statistic. In his survey, Juola identifies the open class version of the problem (in which the true author is not necessarily in the set of identified candidate authors) to be much harder than the closed class version, and stresses the importance and difficulty of developing accurate cross-genre techniques. <ref type="bibr" coords="2,407.70,620.57,10.58,8.64" target="#b5">[6]</ref>. Another good overview of the authorship attribution field is given in <ref type="bibr" coords="2,356.16,632.53,15.27,8.64" target="#b12">[13]</ref>. Among other things, Stamatatos mentions the importance of the open class version of the problem as well as the importance of attribution methods to be robust even given a limited amount of rather short texts <ref type="bibr" coords="3,181.08,119.31,15.27,8.64" target="#b12">[13]</ref>. He also highlights the need of finding specific stylometric features which capture only authorial information, rather than genre or topic. Much research has been undertaken since these overviews were conducted. One interesting example is the Writeprint technique introduced by Abbasi and Chen <ref type="bibr" coords="3,379.34,155.18,10.58,8.64" target="#b0">[1]</ref>. Another study worth mentioning is that by Narayanan et al. <ref type="bibr" coords="3,290.92,167.13,15.27,8.64" target="#b9">[10]</ref>, in which the authors show that authorship attribution can be conducted also on very large scale with good accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overall Design Choices</head><p>A detailed description of the PAN 2019 cross-domain authorship attribution dataset can be found in <ref type="bibr" coords="3,181.42,246.45,10.58,8.64" target="#b6">[7]</ref>, but we here provide a short explanation of the most important aspects as they have an impact on how we have approached the problem in our implementations.</p><p>Participants in the challenge have got access to a development corpus with highly similar characteristics as an unseen evaluation corpus (to which we have not got access, but on which the developed system has been evaluated by submitting it and running it on TIRA <ref type="bibr" coords="3,173.43,306.23,14.94,8.64" target="#b11">[12]</ref>). Both the development and evaluation corpora consist of a set of crossdomain authorship attribution problems in each of the following languages: English, French, Italian, and Spanish. A fundamental restriction to note is that the sets of candidate authors of the development and the evaluation corpora are not overlapping, so that it is not possible to pre-train a model for classifying the authors of interest on the development corpus and simply apply it to the evaluation corpus. This constraint made us realize that we either have to:</p><p>1. Develop a solution which dynamically builds a (supervised) model on-the-fly as it encounter new problem instances, or 2. Develop a more general solution which learns whether two texts are likely to have been written by the same author, and apply this to all authors in each new problem instance.</p><p>Since we have previous experience of developing and applying the second type of techniques to the related problem of author verification <ref type="bibr" coords="3,362.56,477.11,10.58,8.64" target="#b1">[2]</ref>, <ref type="bibr" coords="3,379.91,477.11,10.58,8.64" target="#b4">[5]</ref>, we started by applying a similarity-based supervised classifier <ref type="bibr" coords="3,309.51,489.06,11.62,8.64" target="#b1">[2]</ref> intended to classify pairs of texts as to whether they have being written by the same author or not. When dealing with such a small number of text documents for each author as were present in the development corpus, our initial impression was that a more general solution to the problem might perform better. However, our existing classifier had only been developed for English and Swedish and has been trained on forum posts, which is quite different from the data used in this challenge. Since initial experimental results were not very encouraging, we decided not to spend the time on collecting more representative data to train this kind of binary classifiers on for all the languages of interest. Instead, our intuition on this point suggested that training a more tailored supervised classifier dynamically for each new problem instance would be a more viable approach.</p><p>We got many initial ideas for what type of supervised classifiers to build, many of them involving various kinds of deep learning architectures. Everything from making use of a pre-trained language model per language which could be fine-tuned to each individual candidate author, to building Siamese networks were up on the drawing board.</p><p>However, after making a few tests on the TIRA <ref type="bibr" coords="4,328.36,119.31,16.60,8.64" target="#b11">[12]</ref> platform we realized that the virtual machines and their lack of GPUs would make this kind of dynamic model building per problem instance take forever using such advanced architectures. For this reason, we have in the end decided to go with a much more "traditional" authorship attribution approach. This approach has many similarities with the baseline-SVM implementation provided by the PAN organizers. However, it has been complemented with many handcrafted stylometric features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>This section presents the full list of hand-crafted features that have been implemented in any of our submitted solutions. Overall, stylometric features are intended to reflect stylistic characteristics of the writing of individual authors. The idea is that they should be as independent of topic as possible, and instead capture the more general writing style of an author. Below follows a high-level description of all implemented features.</p><p>Capital words: is defined as the number of uppercase word bigrams divided by number of word bigrams in total in a text.</p><p>Character n-grams: data-driven n-grams on character level (where a character n-gram is a contiguous sequence of n characters from a given sample of text).</p><p>Character upper-lower ratio: is defined as the number of upper-case characters divided by number of lower-case characters in a text.</p><p>Lexical diversity: defined as the amount of unique words divided by the total amount of words in a text.</p><p>Lix: a metric defined as:</p><formula xml:id="formula_0" coords="4,238.98,487.73,3.87,8.74">(</formula><p>no.words no.sents ) + ( no.long_words no.words )</p><p>where no.words is the number of words, no.sents is the number of sentences, and no.long_words is the number of long words, defined to be all words that are longer than six characters. It is intended to be used as an approximation of readability and has in our initial experiments performed better than more traditional measures such as Flesch-Kincaid <ref type="bibr" coords="4,198.13,560.80,10.58,8.64" target="#b7">[8]</ref>.</p><p>Masked character n-grams: work as the character n-grams, but with the difference that all characters between A and Z (uppercase as well as lowercase) are masked as a star (*). The idea is to have this feature focus on the effects of punctuation, spacing, diacritics, numbers, and other non-alphabetical symbols, as suggested in <ref type="bibr" coords="4,425.30,620.57,10.58,8.64" target="#b2">[3]</ref>.</p><p>Part-of-speech (POS) tag n-grams: work in the same way as the word n-grams, but use POS tags as tokens rather than words. The POS tagging is language dependent and relies on spaCy's<ref type="foot" coords="5,202.84,117.64,3.49,6.05" target="#foot_0">1</ref> POS tagger.</p><p>Sentence length: for all sentences in a text, the mean and standard deviation are calculated to get the average sentence length and the variation of sentence lengths.</p><p>Shannon entropy: intended to capture the entropy of texts written by an author. It is defined as</p><formula xml:id="formula_1" coords="5,263.78,201.07,87.30,30.32">H = - M i=1 P i log 2 P i</formula><p>where P i is the probability of character number i appearing in the stream of characters of the message.</p><p>Word length: for all words in a text, the mean and standard deviation are calculated to get the average word length and the variation of word lengths.</p><p>Word length distribution: a vector representing the raw counts of word lengths up to 16 characters, divided by the total amount of words in a text.</p><p>Word n-grams: data-driven n-grams on word level (where a word n-gram is a contiguous sequence of n words from a given sample of text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Submitted Systems</head><p>Our research institute FOI has contributed with two system submissions to the PAN 2019 authorship attribution challenge. These submissions are here referred to as is-bister19 and johansson19, respectively. Since the submitted solutions have much in common we describe them jointly, but in practice we have performed much of the feature selection, experimentation, etc. more or less independent of each other. This means that none of the submitted systems utilize all of the features described in last section. Instead, they use (partially overlapping) subsets of these features. A detailed description of which features that are used in which system is given in Tables <ref type="table" coords="5,398.37,503.65,4.98,8.64" target="#tab_0">1</ref> and<ref type="table" coords="5,422.71,503.65,3.74,8.64" target="#tab_1">2</ref>.</p><p>As previously described, our implemented systems build upon the baseline-SVM classifier, although it has been extended with a lot of other features. We have experimented with several other types of standard classifiers, but the linear SVM classifier performed consistently better than standard alternatives such as random forest and Ad-aBoost classifiers. However, it is important to note that the SVM classifier performed much better when using a one-vs-all regime, training as many binary classifiers as there are candidate authors. In the implemented classifier there is also a reject option, assigning an unknown document to the &lt;UNK&gt; class when the difference of the top two candidates is less than a pre-specified threshold (set to 0.1 in both systems). Initial experiments indicated that the classifiers perform better with this kind of solution rather than to assign &lt;UNK&gt; when the most likely class probability is less than some predefined threshold. However, systematic searches for good threshold settings have not been undertaken, so it is likely that classification performance can be increased by finetuning this threshold.</p><p>In case of the isbister19 submission, the whole corpus for each problem (including the texts from the unknown authors as well) were used to create the vocabulary for the data-driven n-gram representations. A small increase of performance could be gained when using the vocabulary also from the unknown authors. Grid search has been used for both submitted systems in order to find good parameters for the n-grams. In both systems we have concatenated all used features into a single feature vector. This vector has been transformed by scaling each feature by its maximum absolute value. Somewhat surprisingly, the choice of scaling method had a huge impact on the predictive performance, as other standard scaling methods performed much worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>When developing our submissions, we decided on which features to include, how to scale the data, which classifier to use, etc. by validating different configurations on the development corpus being part of the PAN 2019 cross-domain authorship attribution dataset. The results for the submitted systems, as well as two provided baselines to which we have compared our results, as reported by the PAN 2019 evaluation script are shown in the first column of Table <ref type="table" coords="7,278.62,505.86,3.74,8.64" target="#tab_2">3</ref>. These results are, however, not very reliable as various grid searches have been performed in order to find features and classifiers that perform well on this specific evaluation.</p><p>According to our preliminary analysis there was a clear difference in difficulty for different problem instances on this development corpus, but we could not see any distinct trend in that our trained classifiers performed better for some languages than others.</p><p>A more reliable estimate of how well the submitted systems can be expected to perform on unseen data is given in the two last columns of Table <ref type="table" coords="7,387.29,620.57,3.74,8.64" target="#tab_2">3</ref>. These are the results obtained when submitting the systems to TIRA and evaluating them on previously unseen data. Test-dataset 1 is the data that was used to evaluate the early bird submissions, while the Test-dataset 2 is the larger dataset used to evaluate the final submissions.</p><p>In this paper we have presented our submitted systems for the cross-domain authorship attribution task at PAN 2019. The final submitted systems can be seen as extensions of the PAN-CLEF 2019 baseline-SVM system, to which we have added a large amount of hand-crafted stylometric features. The submitted systems have achieved overall scores of approximately 0.62 macro F1 on the final TIRA test set. They have also consistently outperformed the baseline implementations to which they have been compared.</p><p>As future work, we would like to contrast this type of models with more modern pre-trained deep-learning architectures such as language models implemented as stacked Long Short-Term Memories (LSTMs) <ref type="bibr" coords="8,320.05,236.61,11.62,8.64" target="#b3">[4]</ref> or Transformers <ref type="bibr" coords="8,400.01,236.61,15.27,8.64" target="#b13">[14]</ref>, which are finetuned on the specific problem instances at hand. However, since such approaches would take a very long time to run on TIRA, given the current specifications of the virtual machines, such an evaluation would require the PAN 2019 cross-domain authorship attribution evaluation corpus (or similar datasets) to be released for such an evaluation to be feasible.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,136.16,115.83,308.03,227.15"><head>Table 1 .</head><label>1</label><figDesc>System overview -isbister19</figDesc><table coords="6,136.16,137.15,308.03,205.83"><row><cell></cell><cell>Workflow</cell></row><row><cell>Features</cell><cell>Parameters</cell></row><row><cell>Lix</cell><cell></cell></row><row><cell>CharUpperLowerRatio</cell><cell></cell></row><row><cell>CountWordCaps</cell><cell></cell></row><row><cell>avg_sen_len</cell><cell></cell></row><row><cell>std_sen_len</cell><cell></cell></row><row><cell>lex_diversity</cell><cell></cell></row><row><cell>avg_word_len</cell><cell></cell></row><row><cell>std_word_len</cell><cell></cell></row><row><cell>shannon_entropy</cell><cell></cell></row><row><cell>word_sizes</cell><cell></cell></row><row><cell>word_ngrams</cell><cell>weighting=smooth_idf, range(1, 3), min_df=2, lower=True</cell></row><row><cell>char_ngrams</cell><cell>weighting=smooth_idf, range(1, 3), min_df=25, lower=True</cell></row><row><cell>binary_char_ngrams</cell><cell>weighting=binary, range=(1, 4)</cell></row><row><cell>Transformation</cell><cell></cell></row><row><cell>MaxAbsScaler</cell><cell></cell></row><row><cell>Classifier</cell><cell></cell></row><row><cell cols="2">LinearSVM (One-vs-all) C=1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,136.16,115.83,303.55,216.19"><head>Table 2 .</head><label>2</label><figDesc>System overview -johansson19</figDesc><table coords="7,136.16,137.15,303.55,194.87"><row><cell></cell><cell>Workflow</cell></row><row><cell>Features</cell><cell>Parameters</cell></row><row><cell>Lix</cell><cell></cell></row><row><cell>CharUpperLowerRatio</cell><cell></cell></row><row><cell>CountWordCaps</cell><cell></cell></row><row><cell>avg_sen_len</cell><cell></cell></row><row><cell>std_sen_len</cell><cell></cell></row><row><cell>avg_word_len</cell><cell></cell></row><row><cell>std_word_len</cell><cell></cell></row><row><cell>word_sizes</cell><cell></cell></row><row><cell>word_ngrams</cell><cell>weighting=smooth_idf, range(1, 3), min_df=3, lower=True</cell></row><row><cell>char_ngrams</cell><cell>weighting=smooth_idf, range(1, 3), min_df=3, lower=True</cell></row><row><cell>POS_ngrams</cell><cell>weighting=smooth_idf, range(1, 2), min_df=2, lower=True</cell></row><row><cell>Masked ngrams</cell><cell>weighting=smooth_idf, range(1, 2), min_df=2, lower=True</cell></row><row><cell>Transformation</cell><cell></cell></row><row><cell>MaxAbsScaler</cell><cell></cell></row><row><cell>Classifier</cell><cell></cell></row><row><cell cols="2">LinearSVM (One-vs-all) C=2.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,181.92,364.78,251.52,72.59"><head>Table 3 .</head><label>3</label><figDesc>Evaluation results (macro F1 scores)</figDesc><table coords="7,181.92,385.02,251.52,52.36"><row><cell>Submission</cell><cell cols="3">Train-dataset 1 Test-dataset 1 Test-dataset 2</cell></row><row><cell>isbister19</cell><cell>0.641</cell><cell>0.607</cell><cell>0.622</cell></row><row><cell>johansson19</cell><cell>0.623</cell><cell>0.610</cell><cell>0.616</cell></row><row><cell>PAN2019-svm</cell><cell>0.576</cell><cell>xx</cell><cell>xx</cell></row><row><cell cols="2">PAN2019-compressor 0.556</cell><cell>xx</cell><cell>xx</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,657.08,56.33,7.77"><p>https://spacy.io/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="programName">R&amp;D programme</rs> of the <rs type="funder">Swedish Armed Forces</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_u7tyCJw">
					<orgName type="program" subtype="full">R&amp;D programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,398.02,326.51,7.77;8,150.95,408.98,320.20,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,230.89,398.02,238.23,7.77;8,150.95,408.98,134.26,7.77">Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,291.27,408.98,79.52,7.77">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2008-04">Apr 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,419.38,321.93,7.77;8,150.95,430.33,321.87,7.77;8,150.95,441.29,64.25,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,338.76,419.38,125.78,7.77;8,150.95,430.33,60.73,7.77">Multi-domain alias matching using machine learning</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ashcroft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shrestha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,249.82,430.33,205.40,7.77">Third European Network Intelligence Conference (ENIC)</title>
		<imprint>
			<date type="published" when="2016-09">2016. Sep 2016</date>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,451.69,279.82,7.77;8,150.95,462.65,311.39,7.77;8,150.95,473.61,310.64,7.77;8,150.95,484.56,225.93,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,244.22,451.69,178.22,7.77;8,150.95,462.65,167.31,7.77">EACH-USP Ensemble Cross-Domain Authorship Attribution-Notebook for PAN at CLEF 2018</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Custódio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Paraboni</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,213.35,473.61,244.53,7.77">CLEF 2018 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Soulier</surname></persName>
		</editor>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">10-14 September. Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,494.96,296.67,7.77;8,150.95,505.92,251.51,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,267.53,494.96,87.80,7.77">Long short-term memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="http://dx.doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j" coord="8,362.08,494.96,57.78,7.77">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11">Nov 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,516.31,309.72,7.77;8,150.95,527.27,305.22,7.77;8,150.95,538.23,311.66,7.77;8,150.95,549.19,44.08,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,288.21,516.31,147.89,7.77">Detecting multiple aliases in social media</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shrestha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,527.27,305.22,7.77;8,150.95,538.23,110.38,7.77;8,325.95,538.23,51.42,7.77">Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1004" to="1011" />
		</imprint>
	</monogr>
	<note>ASONAM &apos;13</note>
</biblStruct>

<biblStruct coords="8,142.61,559.58,311.30,7.77;8,150.95,570.54,137.09,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,185.34,559.58,78.72,7.77">Authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000005</idno>
		<ptr target="http://dx.doi.org/10.1561/1500000005" />
	</analytic>
	<monogr>
		<title level="j" coord="8,269.58,559.58,86.22,7.77">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="334" />
			<date type="published" when="2006-12">Dec 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,580.94,321.69,7.77;8,150.95,591.90,319.94,7.77;8,150.95,602.85,313.95,7.77;8,150.95,613.81,124.47,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,150.95,591.90,260.37,7.77">Overview of the Cross-domain Authorship Attribution Task at PAN 2019</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,305.73,602.85,117.33,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="8,429.54,602.85,35.36,7.77;8,150.95,613.81,48.03,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,624.21,307.33,7.77;8,150.95,635.17,326.64,7.77;8,150.95,646.13,321.45,7.77;8,150.95,657.08,66.24,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,344.78,624.21,105.16,7.77;8,150.95,635.17,326.64,7.77;8,150.95,646.13,63.53,7.77">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P F</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975-01">Jan 1975</date>
		</imprint>
		<respStmt>
			<orgName>Institute for Simulation and Training, University of Central Florida</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct coords="9,142.61,119.96,330.72,7.77;9,150.95,130.92,294.17,7.77;9,150.95,141.88,307.31,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,282.00,119.96,191.33,7.77;9,150.95,130.92,12.55,7.77">Authorship attribution for twitter in 140 characters or less</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dazeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,181.09,130.92,264.03,7.77;9,150.95,141.88,34.56,7.77;9,223.46,141.88,30.33,7.77">Proceedings of the 2010 Second Cybercrime and Trustworthy Computing Workshop</title>
		<meeting>the 2010 Second Cybercrime and Trustworthy Computing Workshop<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CTC &apos;10</note>
</biblStruct>

<biblStruct coords="9,142.24,152.84,330.89,7.77;9,150.95,163.80,323.27,7.77;9,150.95,174.76,167.68,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,164.40,163.80,196.17,7.77">On the feasibility of internet-scale author identification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Paskov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bethencourt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">C R</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,398.50,163.80,75.72,7.77;9,150.95,174.76,72.22,7.77">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2012-05">2012. May 2012</date>
			<biblScope unit="page" from="300" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,185.71,311.49,7.77;9,150.95,196.67,146.68,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,238.97,185.71,150.29,7.77">Authorship attribution of web forum posts</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Pillay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,427.33,185.71,26.40,7.77;9,150.95,196.67,71.83,7.77">eCrime Researchers Summit</title>
		<imprint>
			<date type="published" when="2010-10">2010. Oct 2010</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,207.63,335.40,7.77;9,150.95,218.59,309.15,7.77;9,150.95,229.55,209.02,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,333.86,207.63,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,259.53,218.59,200.58,7.77;9,150.95,229.55,144.92,7.77">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,240.51,325.81,7.77;9,150.95,251.47,253.50,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,207.24,240.51,182.01,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.v60:3</idno>
		<ptr target="https://doi.org/10.1002/asi.v60:3" />
	</analytic>
	<monogr>
		<title level="j" coord="9,395.57,240.51,72.48,7.77;9,150.95,251.47,31.00,7.77">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009-03">Mar 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,262.43,321.33,7.77;9,150.95,273.39,303.89,7.77" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/1706.03762.pdf" />
		<title level="m" coord="9,205.76,273.39,88.17,7.77">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,284.34,307.25,7.77;9,150.95,295.30,231.59,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,331.44,284.34,118.04,7.77;9,150.95,295.30,80.72,7.77">Mining e-mail content for author identification forensics</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>De Vel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Corney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mohay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,237.37,295.30,53.79,7.77">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="55" to="64" />
			<date type="published" when="2001-12">Dec 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
