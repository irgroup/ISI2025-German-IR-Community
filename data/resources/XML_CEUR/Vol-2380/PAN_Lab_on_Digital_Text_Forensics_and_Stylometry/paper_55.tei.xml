<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.33,151.12,309.13,14.66;1,203.52,170.07,189.37,12.69">UniNE at PAN-CLEF 2019: Bots and Gender Task Notebook for PAN at CLEF 2019</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,212.10,208.13,57.16,9.19"><forename type="first">Catherine</forename><surname>Ikae</surname></persName>
							<email>catherine.ikae@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.68,208.13,54.50,9.19"><forename type="first">Sukanya</forename><surname>Nath</surname></persName>
							<email>sukunya.nath@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.06,208.13,58.64,9.19"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.33,151.12,309.13,14.66;1,203.52,170.07,189.37,12.69">UniNE at PAN-CLEF 2019: Bots and Gender Task Notebook for PAN at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B722D0F617FF21D8BB867B4BF0BF3AB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When participating in the "bots and gender" subtask (both in English and Spanish), our aim is to automatically detect different text sources (sequence of tweets sent by a bot or a human). When a text is identified as being sent by humans, the system must determine the author's gender (author profiling). To solve these questions, we focus on a simple classifier (k-NN, k = 5) usually able to produce a correct answer but not in an efficient way. Thus, we apply a feature selection procedure to reduce the number of terms (around 200 to 500). We also propose to apply a Zeta model to reduce the number of decisions taken by the k-NN classifier. In this case, we focus on terms used in one category and ignored or used rarely by the second. In addition, the Type-Token Ratio of the lexical density (LD) presents some merit to discriminate between tweets sent by a bot (TTR &lt; 0.2, LD ≥ 0.8) or humans (TTR ≥ 0.2, LD &lt; 0.8).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.2" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction 1</head><p>In the last two decades, UniNE has participated in different CLEF evaluation campaigns with the objective of creating new test collections on the one hand and, on the other, to promote research in different NLP domains. This year, our team takes part in the CLEF-PAN in the subtask "bots and gender profiling" using both the English and Spanish corpus <ref type="bibr" coords="1,188.61,509.09,95.43,8.85" target="#b8">(Rangel &amp; Rosso, 2019)</ref>.</p><p>Within this track, given a set of tweets, the computer must identify whether this sequence was sent by a bot or a human. In the latter case, the author gender must be determined. This author profiling question is not new <ref type="bibr" coords="1,345.78,543.65,92.12,8.85">(Schwartz et al., 2016)</ref> and has been the subject of previous evaluation campaigns <ref type="bibr" coords="1,344.34,555.17,95.43,8.85">(Potthast et al., 2019a)</ref>. This problem presents interesting questions from a linguistics point of view because the web offers new forms of communication <ref type="bibr" coords="1,270.82,578.21,168.32,8.85">(chat, forum, e-mail, social networks, etc.)</ref>. It was recognized <ref type="bibr" coords="1,171.58,589.73,60.53,8.85" target="#b2">(Crystal, 2006)</ref> that such communication channels might be viewed as new forms between the classical oral and written usage. In addition, CLEF-PAN campaigns allow us to access large text corpora to verify stylistic assumptions and to detect new facets in our understanding of gender differences <ref type="bibr" coords="1,323.81,624.05,76.52,8.85" target="#b5">(Pennebaker, 2011)</ref>.</p><p>The rest of this paper is organized as follows. Section 2 describes the text datasets while Section 3 describes our feature selection procedure. Section 4 exposes our combined Zeta and k-NN classifier and Section 5 shows some of our evaluation results. A conclusion draws the main findings of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus</head><p>When faced with a new dataset, a first analysis is to extract an overall picture of the data, their relationships, and to detect and explore some simple patterns related to the different categories. A statistical overview of these PAN datasets is provided in Section 2.1 while Section 2.2 focuses on the emoticon distribution across the different categories. The distribution of the Type-Token ratio values is exposed in Section 2.3. Section 2.4 proposes to use the lexical density to discriminate between bots and humans. Finally, Section 2.5 exposes a brief overview of the distribution of positive and negative emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overall Statistics</head><p>To design and implement our classification system, a training corpus was available in the English and Spanish languages. As depicted in Table <ref type="table" coords="2,362.36,381.89,3.76,8.85" target="#tab_0">1</ref>, the training data contains the same number of documents (one document = a sequence of 100 tweets) in the bots and human categories. In the latter case, one can find exactly the same number of documents written by men and women (1,030 in English, 750 in Spanish).</p><p>These values are obtained by concatenating the two subsets made available by the organizers, namely the train and dev parts. To be precise, the train subset is composed of 2,880 English documents and the dev by 1,240 items (for a grand total of 4,120). For the Spanish corpus, one can count respectively 2,080 and 920 documents (total: 3,000).</p><p>As each document is not a single tweet (but usually 100), the mean number of tokens per document is around 2,097 for the English language (median: 1,920; sd: 961.4; min: 100; max: 5,277). For the Spanish language, the mean length is 1, <ref type="bibr" coords="2,385.47,510.05,85.69,8.85;2,125.28,521.57,133.51,8.85">889 (median: 1,925.5; sd: 619.2; min: 100; max: 4,933)</ref>. In this computation, the punctuation symbols and emoticons (or sequences of them) count as tokens. For example, from the expression "Paul's books!!!", our tokenizer returns {paul ' s book !!!}. As we can see, a light stemmer was applied, removing only the plural form '-s' <ref type="bibr" coords="2,353.78,555.89,61.97,8.85">(Harman, 1981)</ref>. This choice is justified to keep the word meaning as close as possible to the original one (which is not the case, for example, with Porter's stemmer reducing "organization" to "organ").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English Spanish Bots</head><p>Human M / F Bots Human M / F Nb. doc. Looking at the mean length for both genders, Table <ref type="table" coords="3,359.45,172.85,5.04,8.85" target="#tab_0">1</ref> does not corroborate the common assumption that "women are more talkative than men". For the English language, the mean is slightly higher for women (2,123 vs. 2,014) but not for the Spanish corpus <ref type="bibr" coords="3,188.61,207.41,66.58,8.85">(1,821 vs. 1,964)</ref>.</p><p>As text categorization problems are known for having a large and sparse feature set <ref type="bibr" coords="3,125.28,230.45,71.26,8.85" target="#b11">(Sebastiani, 2002)</ref>, Table <ref type="table" coords="3,228.88,230.45,5.04,8.85" target="#tab_0">1</ref> indicates the number of distinct terms per category (or the vocabulary size denoted by |Voc|) which is 101,826 for the English bots category. Moreover, and for both languages, the vocabulary size is larger for the human category than for the bots <ref type="bibr" coords="3,195.36,265.01,58.36,8.85">(English: 101,</ref><ref type="bibr" coords="3,253.72,265.01,49.08,8.85">826 vs. 162,</ref><ref type="bibr" coords="3,302.81,265.01,17.65,8.85">384;</ref><ref type="bibr" coords="3,323.52,265.01,56.12,8.85">Spanish: 119,</ref><ref type="bibr" coords="3,379.63,265.01,48.50,8.85">965 vs. 147,</ref><ref type="bibr" coords="3,428.14,265.01,17.04,8.85">109)</ref>. The texts sent by bots are certainly composed with a smaller vocabulary and the same or similar expressions are often repeated. 11:21 Of the Izharites, the Hebronites, the family of the LORD, that I am a brother to wife. 9:2 And he called for their land to Assyria unto this day have I drawn thee.</p><p>🍀🍀🍀🍀🍄🌻🍀🍄🌺 🍀🌺🍀🍀🍄🍀🍄🍀🍄  Happy 1 year with the most amazing girlfriend I could ask for❤ https://t.co/94QD5vM2KJ RT @CuntsWatching: "No idea he cut hair" 😂😂😂 https://t.co/qAgs7rRGR3</p><p>RT @Jam10Moir: When yeh forget to take the hanger aff yer jersey https://t.co/Gd5SIrS3vA @UbuntuBhoy It's a hard life. @DR_Kronenbourg I nearly fucking was 😂 Of course, the tweets produced by bots are not really generated by computers but correspond to retweets or tweets showing text excerpts extracted from a larger corpus. To illustrate this, Table <ref type="table" coords="3,224.87,651.89,9.48,8.85" target="#tab_2">2a</ref> exposes six examples of tweets generated by three bots, while Table <ref type="table" coords="3,175.26,663.41,10.04,8.85">2b</ref> and 2c present four tweets written by two women and men.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Emoticons</head><p>An interesting aspect of web communication <ref type="bibr" coords="4,316.51,168.53,60.28,8.85" target="#b2">(Crystal, 2006)</ref> is the frequent usage of emoticons to denote an author's emotions (e.g., 😱, 😊) or to shorten the message (e.g., 🙏, 👌, 💻). Table <ref type="table" coords="4,204.15,193.73,5.04,8.85" target="#tab_6">3</ref> shows the most frequent emoticons per category and language.</p><p>From this table, it is not fully clear how we can simply detect a pertinent pattern to be suitable for automatic classification. One can infer that humans employ more frequently such symbols compared to bots. On the other hand, women show a higher usage of emoticons but without showing an important difference about the emoticon types. When analyzing the sequence of emoticons, the most frequent one is "😂😂😂" follows by "😂😂".  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type-Token Ratio</head><p>As bots could be deployed to send a repetitive message (maybe with a slight modification), one can assume that the TTR value (the number of distinct word-types divided by the number of word-tokens) should be smaller than for a sequence of tweets written by a human. Of course, the text genre has a clear impact on this estimation, with a lower TTR value for an oral production compared to a written message. As a comparison basis, the TTR achieved by Trump was 0.297 vs. 0.362 for Hillary Clinton (oral form, primaries debates) <ref type="bibr" coords="4,246.39,495.65,54.68,8.85" target="#b10">(Savoy, 2018)</ref>. Over all candidates, Trump achieved the lowest value, depicting a candidate owning a reduced vocabulary and repeating the same expressions again and again. These examples indicate that values smaller than 0.25 or 0.2 represent a clear lower limit for a message.</p><p>Based on the training set (English language), the TTR values have been computed for documents sent by bots and humans. The two resulting distributions are depicted in Figure <ref type="figure" coords="4,164.97,564.53,3.76,8.85" target="#fig_0">1</ref>. In this case, one can see that messages sent by bots tend to contain the same or similar expressions resulting in a lower TTR value, even lower than 0.2 (usually producing a boring message). A similar picture can be obtained with the Spanish language (see the Appendix).</p><p>With the English training data, one can count 398 documents generated by a bot having a TTR value smaller than 0.2 (over 2,060 or 19.3%). On the other hand, only 13 documents having a TTR smaller than 0.2 have been written by humans. For the Spanish corpus, one can find 843 documents generated by bots with a TTR values smaller than 0.2 (over 1500, or 56.2%), and none by human beings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Lexical Density</head><p>The lexical density measures the percentage of content words in a text. This percentage can also be estimated by considering the number of functional words in a text and assuming that a word could be either a content word or a functional one (see Eq. 1). In our implementation, the English language has 571 functional words while for Spanish such a wordlist counts 350 entries. As shown in Figure <ref type="figure" coords="5,218.39,659.81,3.76,8.85" target="#fig_1">2</ref>, bots tend to present a higher LD value than the set of tweets sent by humans. For example, by assuming that the maximum value for a document written by a human is 0.8, the system can consider documents having a larger value as sent by bots. On the training set, one can count 322 English documents or 216 Spanish ones (sent by bots) for one single English document written by a human (and none in the Spanish corpus).</p><formula xml:id="formula_0" coords="5,159.15,433.92,300.84,18.80">LD(T) = 𝑐𝑜𝑛𝑡𝑒𝑛𝑡(𝑇) 𝑙𝑒𝑛(𝑇) * = 1 = - 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛(𝑇) 𝑙𝑒𝑛(𝑇) * (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Emotion Distribution</head><p>With the English language, we have a list of words corresponding to positive (159 entries) and negative (151 entries) emotions (extracted from the LIWC (Linguistic Inquiry and Word Count) <ref type="bibr" coords="6,227.78,238.13,123.18,8.85" target="#b13">(Tausczik &amp; Pennebaker, 2010)</ref>). According to <ref type="bibr" coords="6,417.29,238.13,53.91,8.85;6,125.28,249.65,60.64,8.85">Pennebaker's findings (2011)</ref>, one can expect a larger number of emotional words in tweets written by woman. According to the data depicted in Table <ref type="table" coords="6,335.40,260.93,3.76,8.85" target="#tab_7">4</ref>, such a difference does exist but it is rather small. Moreover, when analyzing only the emotions expressed with words, the mean is rather low (2.5%) but even smaller for bots (1.86%). One can also consider that emotions are also provided by emoticons and thus we need to take account of both the emoticons and words indicating emotions. 3 The Feature Selection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive</head><p>According to our point of view, the key function of a successful classifier is to be able to generate a good feature set. Moreover, we also want to understand the proposed attribution and be able to explain it in plain English. Therefore, one of our main objectives is to reduce the feature space into one to three orders of magnitude compared to a solution based on all possible isolated words. As shown in Table <ref type="table" coords="6,402.54,511.25,3.76,8.85" target="#tab_8">5</ref>, the vocabulary size (|Voc|) is large for all categories and languages. If text categorization can be characterized by such huge feature spaces, they are also sparse (when considering isolated words, n-grams of words or letters). Many terms occur just once (hapax legomenon) or twice (dis legomena). Ignoring those words reduces the vocabulary size by around 50%.</p><p>To reduce this feature set and based on the training data, terms (isolated words or punctuation symbols in this study) having a tweet frequency (df) smaller than a predefined threshold (fixed at 9 in our experiments) are ignored <ref type="bibr" coords="6,385.92,603.17,55.22,8.85" target="#b9">(Savoy, 2015)</ref>. With the English bots corpus (see the first two rows in Table <ref type="table" coords="6,344.30,614.69,3.62,8.85" target="#tab_8">5</ref>), this filter reduced the feature space from 101,826 to 15,478 dimensions (a reduction of 84.8%). Higher reduction rates can be achieved with the human vocabulary (English: 162,384 to 14,728 (90.9%); Spanish: 147,109 to 13,866 (90.6%)).</p><p>Using the term frequency difference, we can observe the term more employed in each category. For example, the terms "urllink" (replacing the sequence "http://aref"), "job", "developer", "and", "hiring" or "swissmade" appear more frequently in tweets sent by bots than by humans. As other examples, we can mention that men used more frequently: "the", "that" "it", "he", "a", "is" and the punctuation symbols ".", ",". Woman tweets contain more "rt" (retweets), "you", "to", "my", "your", "thank", "me", "love" and the punctuation symbols ":", "&amp;". These short examples tend to confirm part of <ref type="bibr" coords="7,160.96,196.61,86.44,8.85" target="#b5">Pennebaker's (2011)</ref>  To go further in this space reduction, one can then add a final third step by applying a feature selection procedure. For example, one can reduce the feature space to a value between 200 to 500, allowing a manageable space to explain the proposed decision. For example, previous studies indicate that odds ratio, mutual information or occurrence frequency tends to produce effective reduced term sets for different text categorization tasks <ref type="bibr" coords="7,206.92,422.93,70.98,8.85" target="#b11">(Sebastiani, 2002)</ref>, <ref type="bibr" coords="7,284.68,422.93,54.87,8.85" target="#b9">(Savoy, 2015)</ref>.</p><p>In addition, our classifier will also consider terms used infrequently in one category and ignored or used rarely by the other (Zeta model) <ref type="bibr" coords="7,331.95,445.97,63.76,8.85" target="#b0">(Burrows, 2007)</ref>, <ref type="bibr" coords="7,401.94,445.97,69.21,8.85;7,125.28,457.49,21.54,8.85" target="#b1">(Craig &amp; Kinney, 2009)</ref>. To achieve this, terms appearing only in a single category are extracted and ranked according to their term frequency (tf) or document frequency (df). Instead of considering all of them, only the top 200 most frequent ones (based on the tf and df statistics) are judged useful to discriminate between two classes. The two wordlists (each containing 200 entries) are merged to generate the final terms able to discriminate between the two categories. The size of those lists is depicted in Table <ref type="table" coords="7,405.59,515.09,5.04,8.85" target="#tab_8">5</ref> under the label "Voc Uniq" (e.g., English bots: 345, English human: 373). For example, within the bots category, one can find terms such as: "camber", "cincinnati", "cooperative" or "norwalk". The male category is characterized by terms such as: "outwildtv", "obstruction", "avalanche" or "golfer" while in tweets written by women, one can find "gown", "allergy", "👭" or "ballet".</p><p>It is also interesting to analyze the distribution of definite articles and some pronouns <ref type="bibr" coords="7,125.28,597.17,81.15,8.85" target="#b5">(Pennebaker, 2011)</ref> in both languages as depicted in Table <ref type="table" coords="7,384.17,597.17,9.48,8.85" target="#tab_9">6a</ref> (English) and 6b (Spanish). In those tables, the number of documents in each gender is the same and represents the half of those appearing in the column "Bots". Thus, looking at the frequencies, one can expect a pattern such as 2:1:1 when the term occurrence frequency is the same through the different categories.</p><p>The frequencies depicted in Table 6a confirm Pennebaker's findings. Definite articles ("the", "a") are more frequent with male writers, and personal pronouns ("i", "you", "me", etc.) are more often used by women. Exceptions can be found. The English pronoun "he" is clearly employed more often by men. Bots frequently adopt the pronouns "you" or "we" and use more infrequently "she". Is the bot style more feminine? The Spanish corpus also confirms Pennebaker's conclusions. Definite articles ("el", "un", "una", etc.) appear more frequently with men, and personal pronouns ("yo", "tu", "ella", etc.) are more associated with the woman's style. The Spanish pronoun "nosotros" (we) or "vosotros" (you, plural) are usually not present but this indication is often implicit with the verbal suffixes (e.g., "podemos" we can). (A linguist will also infer that frequencies of such pronouns will be rather small due to their spelling composed of 8 letters, not a length reflecting the less effort principle).</p><p>Finally, when analyzing the popularity of some countries (see Table <ref type="table" coords="8,408.28,659.33,7.64,8.85" target="#tab_9">6a</ref>), one can see that "france" is the most popular while "swissmade" appears only with bots. For the other names, "italy" is more associated with women, while all the others are with men (except "swiss" that is associated with bots) (due to soccer, a sport popular in Spain, Italy and Germany?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Text Classification Strategy</head><p>Our solution is based on a three-stage function. In the first, the needed variables are initialized (function preProcessing() in Figure <ref type="figure" coords="9,345.39,236.93,4.18,8.85" target="#fig_3">3</ref>) and they correspond to the unique vocabulary used in the two categories (VocUnC1, VocUnC2) and to the document representations belonging to the two categories (PtC1, PtC2).</p><p>Based on the training data, the system extracts the vocabulary (isolated terms with their frequency) appearing in both categories (function defineVoc()). From them, one can determine the terms appearing frequently in one category but absent (or occurring rarely) in the second (in our implementation, such a term can appear up to three times (min=3) in the second category). To rank them, the term frequency (tf) or the tweet frequency (df) statistics are applied. Instead of returning two wordlists, the system selects the top 200 most frequent ones in the underlying category and merges them (function topVoc()). In Steps #5 and #6, the system represents the documents belonging to Category #1 or #2 as vectors (generating the PtC1 and PtC2 variables).</p><p>After this initialization, each document belonging to the test sample can be processed (see function binaryClassifier() in Figure <ref type="figure" coords="9,332.75,392.21,3.62,8.85" target="#fig_3">3</ref>). In Step #1, the Zeta model is applied. This function counts the number of distinct terms appearing in VocUnC1 (denoted N1) and in VocUnC2 (or N2). If (N1 &gt; N2+q), the test identifies the given document as belonging to Category #1. On the other hand, if (N2 &gt; N1+q), it is assumed that the document must be labeled with the second category (e.g. Human). If the Zeta reaches a decision (e.g., dec=1 for Bot, dec=2, for Human), this value is returned. Otherwise, Zeta is unable to achieve a clear decision (dec=0). For those cases, the TTR value (Type-Token Ratio) is computed <ref type="bibr" coords="10,302.09,394.61,56.34,8.85">(Step #3 and4)</ref>. When this value is smaller than 0.2, the decision is taken as "Bot" (dec=1). In addition, we might have computed the lexical density value and returned "Bot" if this value is larger than 0.8. This step was not included in our final submission (due to time constraints).</p><p>In general, the Zeta model (together with the TTR value) cannot always propose a clear answer. In this case, the system calls the k-NN function (with the new document, and the set of points corresponding to Category #1 (PtC1) or #2 (PtC2)). In our experiment, the k value was fixed to 13 and the distance between two text surrogates is computed according to the Manhattan function <ref type="bibr" coords="10,315.22,488.21,97.08,8.85" target="#b4">(Kocher &amp; Savoy, 2017)</ref>.</p><p>When the document type is found to be sent as human, the system re-applies the binaryClassifier() function but with Category #1 corresponding to male and Category #2 to female (but ignoring the TTR computation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>Table <ref type="table" coords="10,161.89,586.85,5.04,8.85" target="#tab_12">7</ref> depicts the accuracy rate achieved with our model under different conditions and for both the type (bot vs. human) and the gender (male vs. female). These results were achieved with the English corpus using the dev test set. In the first row, all words have been used to build the document surrogates. In the second line, the vocabulary size was reduced to consider only terms having a df value larger than 9. In the next row labelled "FS", our feature selection is applied. Finally, the last five lines correspond to a feature space reduced to 100, 200, 300, 400, or 500 terms selected by the information gain function <ref type="bibr" coords="10,185.30,668.21,73.21,8.85" target="#b11">(Sebastiani, 2002)</ref>. When applying our nearest neighbor approach, Table <ref type="table" coords="10,150.54,679.73,5.04,8.85" target="#tab_12">7</ref> indicates the mean accuracy rates achieved considering k=13 or k=5 neighbors.</p><p>To compute the accuracy rates, only the train subset is used to define the needed wordlists and document surrogates (in other words, based on 2,880 English documents, and 1,240 Spanish ones). During the evaluation, only the dev subset was needed to derive the performance values (or with 2,080 English documents, and 980 Spanish ones).  The important conclusion that can be drawn from Table <ref type="table" coords="11,370.56,377.33,5.04,8.85" target="#tab_12">7</ref> is that it is possible to reduce the feature set to a few hundred words and to still have a good overall effectiveness. Considering k=13 neighbors tends to produce better results (and this solution is less prone to over-fitting).</p><p>Table <ref type="table" coords="11,161.89,423.41,5.04,8.85" target="#tab_14">8</ref> reports our official results achieved with the TIRA system <ref type="bibr" coords="11,409.58,423.41,61.57,8.85;11,125.28,434.93,28.36,8.85" target="#b7">(Potthast et al., 2019b)</ref> using the first (test set 1) or the second (test set 2). These evaluations correspond to our feature selection (FS) with the inclusion of the Zeta test and TTR filter. More information can be found in <ref type="bibr" coords="11,290.52,457.97,91.10,8.85" target="#b8">(Rangel &amp; Rosso, 2019</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Using the CLEF-PAN datasets of the "bots and gender profiling" written in English and Spanish, we were able to achieve the following main findings. First, the text genre associated with bots can be viewed as repetitive, showing a low TTR value (usually lower than 0.25). After fixing a threshold (e.g., 0.2) for this value, one can detect 9.6% to 55% tweet sequences sent by bots (see Figure <ref type="figure" coords="11,322.32,649.73,4.18,8.85" target="#fig_0">1</ref>) with a low error rate (around 3%). For a large majority however (90% for the English corpus), documents present a higher TTR value and no decision can be reached with this simple rule. Similarly, one can compute the lexical density value and one can see that values larger than 0.8 correspond very often to bot tweets.</p><p>Second, analyzing the emoticon distribution, or the most frequent ones, we can infer that humans tend to employ them more frequently than bots. In tweets sent by machines, the used emoticons indicate directions or appear to draw reader attention (see Table <ref type="table" coords="12,150.54,208.13,3.62,8.85" target="#tab_6">3</ref>). If humans have adopted the emoticons in their web communications, it is not clear whether we can easily distinguish their usage between men and women.</p><p>Third, our attribution approach is based on a cascade classifier. In a first step, the Zeta classifier is used to determine the category (bots vs. human, male vs. female) based on terms occurring infrequently in the first class and never (or very rarely) in the second. When the test sample is strongly correlated to the training set, such a strategy works well and can accurately determine close to 85% when a decision can be computed. As the main drawback, this approach fails to propose an answer when the vocabulary appearing in the new document is not associated clearly with one of the predefined wordlists. In such cases, a second classifier must be used (k-NN in our experiments, with k = 5, Manhattan distance).</p><p>Fourth, removing terms occurring rarely or in a few documents corresponds to our first step in the proposed reduction procedure. In addition, we impose that terms appearing more frequently in a given category must be selected for that class. This strategy can be further improved by applying a term filter (e.g., mutual information, odds ratio <ref type="bibr" coords="12,169.95,380.45,72.18,8.85" target="#b11">(Sebastiani, 2002)</ref>, <ref type="bibr" coords="12,250.15,380.45,55.39,8.85" target="#b9">(Savoy, 2015)</ref>). After this step, the number of terms could be limited from 200 to 500. This last step is usually accompanied with an effectiveness decrease (around 3% to 8%, depending on the collection).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,150.85,318.07,294.77,8.45"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of the TTR values for the bots vs. human (English corpus)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,132.73,636.79,331.00,8.45"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of the lexical density values for the bots vs. human (Spanish corpus)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,186.98,359.11,222.57,8.45"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The main steps of our automatic attribution system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,133.44,620.60,324.11,54.33"><head>Table 1 :</head><label>1</label><figDesc>Overall statistics about the training data in both languages</figDesc><table coords="2,133.44,620.60,324.11,54.33"><row><cell></cell><cell>2060</cell><cell>1,030 / 1,030</cell><cell>1,500</cell><cell>750 / 750</cell></row><row><cell>Nb tweets</cell><cell>205,919</cell><cell>102,842 / 102,930</cell><cell>149,968</cell><cell>75,000 / 75,000</cell></row><row><cell>Mean length</cell><cell>2,097</cell><cell>2,014 / 2,123</cell><cell>1,889</cell><cell>1,964 / 1,821</cell></row><row><cell>|Voc|</cell><cell>101,826</cell><cell>95,323 / 102,689 human: 162,384</cell><cell>119,965</cell><cell>95,590 / 89,141 human: 147,109</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,125.28,307.20,327.33,47.18"><head></head><label></label><figDesc>🚑 #JOB 🚑 #medical Anesthesiologist https://t.co/t8C84NGQuI 👈 #hiring #health 🏥 https://t.co/HlAmnmpjPZ 🏥. 🚑 #JOB 🚑 #medical Mental Health Nurse https://t.co/i9PEEOOxz2 👈 #hiring #health 🏥 https://t.co/HlAmnmpjPZ 🏥.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,125.28,417.43,329.20,88.15"><head>Table 2a :</head><label>2a</label><figDesc>Examples of two tweets sent by three distinct bots</figDesc><table /><note coords="3,125.28,441.56,319.51,8.01;3,125.28,451.88,198.10,8.01;3,125.28,462.20,157.32,8.01;3,125.28,475.64,329.20,8.01;3,125.28,485.96,132.79,8.01;3,125.28,493.92,254.52,11.66"><p>RT @EdinburghUni: The future of Scotland's international relations will be discussed at 'Global Heritage, Global Ambitions: Scotland's Inte… Indeed Murray.... https://t.co/fUZ3dqGL1U Getting ready for Easter ! Growing up in Québec my sweet memories of Easter are from la cabane à… https://t.co/OrIEL6cBSH Diner tonight ... Nettles a la crème 🍃🍃🍃🍃 https://t.co/eE4vycXV9h</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,207.46,518.23,181.54,8.45"><head>Table 2b: Examples of tweets sent by two women</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,213.47,611.83,169.53,8.45"><head>Table 2c :</head><label>2c</label><figDesc>Examples of tweets sent by two men</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="4,180.37,379.51,235.71,8.45"><head>Table 3 :</head><label>3</label><figDesc>The most frequent emoticons per category and language</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,146.88,325.01,295.02,73.75"><head>Table 4 :</head><label>4</label><figDesc>Distribution of the positive and negative emotions (English language)</figDesc><table coords="6,370.78,325.01,36.13,8.85"><row><cell>Negative</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,125.28,196.61,345.91,154.39"><head>Table 5 :</head><label>5</label><figDesc>findings, indicating that definite articles are more frequently used by men while personal pronouns and emotions tend to appear more often in female messages. Vocabulary size with different feature selection strategies</figDesc><table coords="7,130.16,237.65,306.94,96.45"><row><cell></cell><cell></cell><cell>English</cell><cell></cell><cell>Spanish</cell></row><row><cell></cell><cell>Bots</cell><cell>Humans M / F</cell><cell>Bots</cell><cell>Humans M / F</cell></row><row><cell>|Voc|</cell><cell>101,826</cell><cell>95,323 / 102,689 human: 162,384</cell><cell>119,965</cell><cell>95,590 / 89,141 human: 147,109</cell></row><row><cell>with df &gt; 9</cell><cell>15,478</cell><cell>9,122 / 9,227</cell><cell>16,725</cell><cell>11,488 / 9,848</cell></row><row><cell></cell><cell></cell><cell>human: 14,728</cell><cell></cell><cell>human: 13,866</cell></row><row><cell>with tf</cell><cell>8,699</cell><cell>5,768 / 5,417</cell><cell>8,732</cell><cell>5,415 / 4,552</cell></row><row><cell></cell><cell></cell><cell>human: 10,173</cell><cell></cell><cell>human: 9,283</cell></row><row><cell>Voc Uniq</cell><cell>345</cell><cell>373</cell><cell>391</cell><cell>364</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,156.32,191.57,268.87,355.65"><head>Table 6a :</head><label>6a</label><figDesc>Some occurrence statistics for the English corpus (tf / df)</figDesc><table coords="8,156.32,191.57,268.87,355.65"><row><cell></cell><cell>Bots tf/df</cell><cell>Male tf/df</cell><cell>Female tf/df</cell></row><row><cell>the</cell><cell>95,860 / 1,881</cell><cell>54,272 / 1,030</cell><cell>48,311 / 1,030</cell></row><row><cell>a</cell><cell>67,654 / 1,895</cell><cell>32,316 / 1,030</cell><cell>31,773 / 1,030</cell></row><row><cell>i</cell><cell>24,367 / 1,568</cell><cell>24,160 / 1,022</cell><cell>29,598 / 1,014</cell></row><row><cell>you</cell><cell>39,521 / 1,654</cell><cell>16,916 / 1,030</cell><cell>20,811 / 1,030</cell></row><row><cell>she</cell><cell>1,403 / 628</cell><cell>1,347 / 557</cell><cell>2,114 / 685</cell></row><row><cell>he</cell><cell>4,633 / 1,092</cell><cell>/ 897</cell><cell>3,165 / 765</cell></row><row><cell>we</cell><cell>13,331 / 1,463</cell><cell>6,661 / 995</cell><cell>7,483 / 985</cell></row><row><cell>swissmade</cell><cell>439 / 6</cell><cell>0 / 0</cell><cell>0 / 0</cell></row><row><cell>swiss</cell><cell>62 / 47</cell><cell>15 / 15</cell><cell>15 / 14</cell></row><row><cell>spain</cell><cell>68 / 46</cell><cell>89 / 64</cell><cell>44 / 39</cell></row><row><cell>italy</cell><cell>79 / 64</cell><cell>92 / 57</cell><cell>113 / 59</cell></row><row><cell>portugal</cell><cell>25 / 19</cell><cell>37 / 29</cell><cell>22 / 19</cell></row><row><cell>germany</cell><cell>147 / 96</cell><cell>105 / 78</cell><cell>66 / 56</cell></row><row><cell>france</cell><cell>213 / 147</cell><cell>158 / 112</cell><cell>145 / 103</cell></row><row><cell></cell><cell>Bots tf/df</cell><cell>Male tf/df</cell><cell>Female tf/df</cell></row><row><cell>el</cell><cell>56,700 / 1310</cell><cell>26,180 / 750</cell><cell>19,505 / 750</cell></row><row><cell>un</cell><cell>21,627 / 1256</cell><cell>19,233 / 749</cell><cell>8,930 / 749</cell></row><row><cell>una</cell><cell>12,070 / 1191</cell><cell>6,293 / 742</cell><cell>5,817 / 745</cell></row><row><cell>unos</cell><cell>1,155 / 367</cell><cell>355 / 263</cell><cell>276 / 211</cell></row><row><cell>unas</cell><cell>710 / 254</cell><cell>156 / 129</cell><cell>163 / 146</cell></row><row><cell>yo</cell><cell>2,174 / 552</cell><cell>1,892 / 662</cell><cell>3,073 / 662</cell></row><row><cell>tu</cell><cell>4,178 / 686</cell><cell>1,687 / 577</cell><cell>2,569 / 648</cell></row><row><cell>ella[s]</cell><cell>562 / 319</cell><cell>381 / 253</cell><cell>534 / 323</cell></row><row><cell>ello[s]</cell><cell>674 / 362</cell><cell>442 / 281</cell><cell>429 / 265</cell></row><row><cell>nosotro[s]</cell><cell>511 / 276</cell><cell>260 / 190</cell><cell>282 / 198</cell></row><row><cell>vosotro[s]</cell><cell>118 / 74</cell><cell>43 / 32</cell><cell>32 / 26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="8,176.10,555.67,244.25,8.45"><head>Table 6b :</head><label>6b</label><figDesc>Some occurrence statistics for the Spanish corpus (tf / df)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="11,148.13,354.31,300.19,8.45"><head>Table 7 :</head><label>7</label><figDesc>Evaluation of under different feature selection strategies (English corpus)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="11,125.50,457.97,340.48,62.37"><head></head><label></label><figDesc>).</figDesc><table coords="11,125.50,475.97,340.48,44.37"><row><cell></cell><cell cols="2">TIRA test set 1</cell><cell cols="2">TIRA test set 1</cell><cell cols="2">TIRA test set 2</cell></row><row><cell></cell><cell></cell><cell>k=5</cell><cell></cell><cell>k=13</cell><cell>k=13</cell><cell></cell></row><row><cell>Classifier</cell><cell>type</cell><cell>gender</cell><cell>type</cell><cell>gender</cell><cell>type</cell><cell>gender</cell></row><row><cell>FS+Zeta test+TTR</cell><cell>0.8939</cell><cell>0.7689</cell><cell cols="2">0.8939 0.7992</cell><cell>0.9125</cell><cell>0.7371</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="11,134.14,528.79,328.18,8.45"><head>Table 8 :</head><label>8</label><figDesc>Official Evaluation of under different feature selection strategies (English corpus)</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,125.28,469.40,345.90,8.32;12,136.63,479.72,172.01,8.32" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,177.72,469.40,256.71,8.32">All the way through: Testing for authorship in different frequency strata</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,441.63,469.49,29.55,8.23;12,136.63,479.81,92.06,8.23">Literary and Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,493.16,345.89,8.32;12,136.63,503.48,132.27,8.32" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Shakespeare</surname></persName>
		</author>
		<title level="m" coord="12,277.33,493.25,146.28,8.23">computers, and the mystery of authorship</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,516.92,320.24,8.32" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,169.03,517.01,94.16,8.23">Language and the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Crystal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,530.36,345.92,8.32;12,136.63,540.68,102.50,8.32" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,176.82,530.36,99.46,8.32">How effective is suffixing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,287.55,530.45,183.65,8.23;12,136.63,540.77,26.04,8.23">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,554.12,345.95,8.32;12,136.63,564.44,144.50,8.32" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,218.33,554.12,142.41,8.32">Distance measures in author profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,372.61,554.21,98.62,8.23;12,136.63,564.53,44.79,8.23">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1103" to="1119" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,577.88,307.25,8.32" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<title level="m" coord="12,192.76,577.97,94.74,8.23">The secret life of pronouns</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Bloomsbury Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,591.32,345.92,8.32;12,136.63,601.64,281.75,8.32" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,300.03,591.32,171.17,8.32;12,136.63,601.64,23.97,8.32">A decade of shared tasks in digital text forensics at PAN</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,170.13,601.73,67.31,8.23">Proceedings ECIR</title>
		<meeting>ECIR</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="volume">11437</biblScope>
			<biblScope unit="page" from="291" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,615.08,345.89,8.32;12,136.63,625.40,334.55,8.32;12,136.63,635.72,181.75,8.32" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,309.74,615.08,135.00,8.32">TIRA integrated research architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,216.20,625.40,254.98,8.32;12,136.63,635.72,81.41,8.32">Information retrieval evaluation in a changing world -Lessons Learned from 20 years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,125.28,649.16,345.94,8.32;12,136.63,659.48,334.53,8.32;12,136.63,670.04,326.99,8.32" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,221.20,649.25,250.02,8.23;12,136.63,659.57,60.80,8.23">Overview of the 7th Author Profiling Task at PAN 2019: Bots and Gender Profiling</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,408.62,659.48,62.54,8.32;12,136.63,670.04,54.17,8.32">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="12,197.35,670.04,199.72,8.32">Notebook Papers. CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,125.28,149.96,345.91,8.32;13,136.63,160.28,197.77,8.32" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,162.28,149.96,275.72,8.32">Comparative evaluation of term selection functions for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,445.63,150.05,25.56,8.23;13,136.63,160.37,107.54,8.23">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="261" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,125.28,173.96,345.91,8.32;13,136.63,184.28,197.77,8.32" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,163.66,173.96,273.12,8.32">Analysis of the style and the rhetoric of the 2016 US presidential primaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,445.63,174.05,25.56,8.23;13,136.63,184.37,107.54,8.23">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="159" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,125.28,197.72,345.88,8.32;13,136.63,208.04,70.52,8.32" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,182.64,197.72,184.74,8.32">Machine learning in automatic text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,378.15,197.81,89.18,8.23">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,125.28,221.48,345.89,8.32;13,136.63,231.80,334.56,8.32;13,136.63,242.12,220.46,8.32" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,384.07,231.80,87.12,8.32;13,136.63,242.12,125.16,8.32">Personality, gender, and age in the language of social media</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Ramones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E P</forename><surname>Seliman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,270.33,242.21,36.71,8.23">PLOS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,125.28,255.56,345.92,8.32;13,136.63,265.88,334.54,8.32;13,136.63,276.44,37.52,8.32" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,277.59,255.56,193.61,8.32;13,136.63,265.88,126.53,8.32">The psychological meaning of words: LIWC and computerized text analysis methods</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">R</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,271.50,265.97,157.43,8.23">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
