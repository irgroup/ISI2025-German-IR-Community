<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.28,115.90,306.81,12.90;1,176.81,133.83,261.73,12.90;1,223.43,153.96,168.50,10.75">Cross-Domain Authorship Attribution Combining Instance-Based and Profile-Based Features Notebook for PAN at CLEF 2019</title>
				<funder ref="#_fBRyrKb">
					<orgName type="full">MIUR</orgName>
				</funder>
				<funder>
					<orgName type="full">Department of Computer</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.94,190.63,100.99,8.64"><roleName>Massimo</roleName><forename type="first">Andrea</forename><surname>Bacciu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.43,190.63,40.12,8.64"><forename type="first">La</forename><surname>Morgia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,286.56,190.63,61.22,8.64"><forename type="first">Alessandro</forename><surname>Mei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.90,190.63,87.85,8.64"><forename type="first">Eugenio</forename><forename type="middle">Nerio</forename><surname>Nemmi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,450.64,190.63,28.77,8.64;1,262.07,202.58,16.16,8.64"><forename type="first">Valerio</forename><surname>Neri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,301.64,202.58,51.65,8.64"><forename type="first">Julinda</forename><surname>Stefa</surname></persName>
							<email>stefa@di.uniroma1.itbacciu.1747105@studenti.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department">Affiliation Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.28,115.90,306.81,12.90;1,176.81,133.83,261.73,12.90;1,223.43,153.96,168.50,10.75">Cross-Domain Authorship Attribution Combining Instance-Based and Profile-Based Features Notebook for PAN at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">47B3165DD0A709B4CA65E9FB21FD2C63</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Being able to identify the author of an unknown text is crucial. Although it is a well-studied field, it is still an open problem, since a standard approach has yet to be found. In this notebook, we propose our model for the Authorship Attribution task of PAN 2019, that focuses on cross-domain setting covering 4 different languages: French, Italian, English, and Spanish. We use ngrams of characters, words, stemmed words, and distorted text. Our model has an SVM for each feature and an ensemble architecture. Our final results outperform the baseline given by PAN in almost every problem. With this model, we reach the second place in the task with an F1-score of 68%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stylometry is the application of the study of linguistic style, and it is often used for establishing authenticity or authorship of an unknown text. It was first used to determine the author of unknown playwrights, but it soon became a powerful tool in Forensics analysis. Nowadays, it is also used in court. It is famous how Linguistic analysis helped, for example, to solve the Coleman case <ref type="bibr" coords="1,291.49,495.07,15.27,8.64" target="#b9">[12]</ref>. PAN 2019 <ref type="bibr" coords="1,355.97,495.07,11.90,8.64" target="#b3">[4,</ref><ref type="bibr" coords="1,367.87,495.07,7.93,8.64" target="#b6">9]</ref> focuses on the task of Authorship Attribution, that is the task of determining the author of a disputed document given a set of known authors. When the disputed text could be written by an author that does not belong to the known set, the task is called open-set Authorship Attribution. This task is more challenging than the closed-set, where we always know that some author in our set wrote the disputed document. The main difference is that in the closed-set we look for the most similar author, while in the open-set, we must further understand if the most similar author is also the real author. Since for each author we have more training documents, we build features using them individually and then concatenating them. We refer to the features computed on a single document as instance-based features while to those concatenated as profile-based features. We choose to combine these two methods in order to catch both the patterns that they capture. In this paper, we extract different types of features and we pre-process the texts in several ways. We use a Tokenizer, a Stemmer, and a POS tagger. Afterward, starting from the pre-processed text, we extract 6 types of different features, and we use the Tf-Idf to weight them. We train an SVM for each feature, then we ensemble their predictions with the soft-voting. Our architecture uses 4 SVMs for the French, 5 for the Spanish and the Italian, and 6 for the English. With our technique, we achieve a final overall F1-score of 70.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Typically, we can divide the approaches to solve the Authorship Attribution problem in two different categories: profile-based or instance-based approach <ref type="bibr" coords="2,402.83,261.19,15.27,8.64" target="#b16">[19]</ref>. In the profilebased approach, we concatenate together texts of the same author to extract its stylometric profile. This method relies on collecting as more information of the user as possible, in one document. It is especially suited when the texts are similar in the domain space. In the instance-based approach, instead, we analyze the texts associated with an author separately. It gives better results if the texts associated with each author are from different domains. In both these approaches, stylometric features are prevalent.</p><p>Stylometry is one of the most effective technique to distinguish the authorship of a text, and it has been used in most of the studies. Although to extract a stylometric profile there are several kinds of features, some of them have been proven to be more powerful. Several independent Authorship Attribution studies showed that character ngram are key features and they are more robust compared to the word n-gram features in cross-topic and cross-genre conditions <ref type="bibr" coords="2,299.01,404.90,16.58,8.64" target="#b10">[13,</ref><ref type="bibr" coords="2,315.59,404.90,12.43,8.64" target="#b16">19,</ref><ref type="bibr" coords="2,328.02,404.90,12.43,8.64" target="#b17">20]</ref>. This is because character n-grams can capture the use of punctuation marks, the lexical information, the use of the capital letter, and it is also tolerant of typing errors.</p><p>Despite the effectiveness of character n-gram applied on plain text, several variations have been proposed to improve it. One of the most successful variations consists in text distortion (e.g., by removing some character) <ref type="bibr" coords="2,370.16,464.91,15.27,8.64" target="#b18">[21]</ref>. There are a variety of features that can represent the stylistic profile of an author, such as Function Words, POS tagging, and word n-gram. Some studies proposed to combine these features to obtain a stronger representation of the author stylistic profile. Custodio et al. <ref type="bibr" coords="2,449.23,500.78,11.62,8.64" target="#b2">[3]</ref> proposed the most interesting approach. It consists in fitting three different SVMs with different features then combine their predictions. While the features mentioned above work differently based on configuration and language, some method does not. Compression <ref type="bibr" coords="2,171.19,548.60,10.79,8.64" target="#b4">[5,</ref><ref type="bibr" coords="2,183.76,548.60,7.47,8.64">6,</ref><ref type="bibr" coords="2,193.01,548.60,12.45,8.64" target="#b11">14,</ref><ref type="bibr" coords="2,207.24,548.60,13.28,8.64" target="#b16">19]</ref> is a particularly attractive method because it does not need any configuration, it is language independent, easy to apply, and does not require any prior knowledge of features extraction to produce a prediction. The drawback is the high cost in terms of computational expensiveness. The compression method focuses on repetitions and the ability of the compression algorithm to detect them. It uses off-the-shelf compression algorithms to compress all the texts of the same author together. The prediction is evaluated calculating the similarity between the compressed unknown text and the compression of each file of the author concatenated.</p><p>Koppel et al. <ref type="bibr" coords="2,204.54,644.48,15.27,8.64" target="#b8">[11]</ref>, introduced another innovative approach called unmasking. It is a complex meta-learning approach to Author Verification, especially suited for long texts. The idea behind this method is that most of the time, few features are the most significant. To show this, they use an SVM classifier to determine the accuracy results of the cross-validation between known versus unknown documents. Then, they compute the most significant features, remove them, and repeat the process. After some iterations, they show that if the predicted author is the same of the unknown document, the accuracy of the cross-validation decreased significantly, while if the author is not the same, the accuracy remains pretty high. Kestemont et al <ref type="bibr" coords="3,384.39,191.04,11.62,8.64" target="#b5">[8]</ref> used the unmasking method on two datasets, one intra-genre, and the other cross-genre. For the first dataset, they confirmed the effectiveness of the methodology, while for the cross-genre dataset, they show that the reliability of this approach drastically drops. Abbasi et al. <ref type="bibr" coords="3,447.72,226.91,11.62,8.64" target="#b0">[1]</ref> tried unsupervised methods to perform user Authorship Verification. They used a set of features comprising Lexical, Syntactic, Structural, Content and Idiosyncratic types over 4 different datasets with the best result reached on the eBay comments dataset with a 96% accuracy over 25 users. Kocher et al. <ref type="bibr" coords="3,303.81,274.73,16.60,8.64" target="#b7">[10]</ref> used an unsupervised method too. They use the 200 most common terms of the disputed text (isolated words and punctuation symbols) and simple distance measure and a set of impostors, to determine whether or not the disputed text was written by the proposed author. They use a dataset with texts of four different languages: English, Dutch, Spanish, and Greek. Their result was of 70% accuracy. Shrestha et al. <ref type="bibr" coords="3,257.84,334.51,16.60,8.64" target="#b15">[18]</ref> were the first to attempt to solve this task using a Convolutional Neural Network with character n-grams as input. They used three layers: A character embedding layer, a convolutional layer, and a fully connected softmax layer. With this architecture, they score an accuracy of 72% as best result, on a dataset of 50 users. Recently, Brocardo et al. <ref type="bibr" coords="3,282.52,382.33,11.62,8.64" target="#b1">[2]</ref> used Deep Belief Network to perform the task. They introduced new stylometric features and a method to merge pairs of random features. They combine two similar features by computing cosine similarity for every pair and then, they apply a linear combination to reduce two features into one. They use the Equal Error Rate (EER) as evaluation metric, reaching a value of 8.2% and 5.4% for the forgery dataset. Ruder et al. <ref type="bibr" coords="3,248.14,442.10,16.60,8.64" target="#b14">[17]</ref> perform a comparison between several Convolutional Neural Network approaches and the traditional ones. Their best model outperforms the results of three out of five datasets they tested on. Potha et al. <ref type="bibr" coords="3,384.52,466.01,16.60,8.64" target="#b12">[15]</ref> propose a variation of the Common N-Grams (CNG) approach originally proposed by Keselj et al. <ref type="bibr" coords="3,454.55,477.97,11.62,8.64">[7]</ref> for closed-set attribution and later modified by Stamatatos <ref type="bibr" coords="3,350.86,489.92,15.27,8.64" target="#b18">[21]</ref>. Following the profile-based paradigm, this method firstly concatenates all samples of known authorship into a single document and then extracts the representation vector using character n-gram. Another vector is produced from the disputed document and the two vectors are compared using a dissimilarity function. If the resulting score is above a certain threshold, the authorship of the disputed document is assigned to the author of the known documents. They tested this model on PAN 2013 dataset, with an overall F1 score of 0.78%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Background</head><p>The main idea behind the Authorship Attribution is that by extracting some stylistic or syntactic features, we can distinguish between texts written by different authors. The 2019 edition of PAN shared task, focuses on finding the author of a series of fanfictions belonging to different fandoms. Fanfiction is a work of fiction written by a fan of an-other work. The authors of the fanfictions usually maintain the original characters and the story setting or add their elements. Fandom is the domain to which the fanfiction belongs to. For example, if the fanfiction is based on the Harry Potter saga, this means it belongs to the fandom of Harry Potter. In the dataset, there are a set D of known fanfictions and a set U of unknown fanfictions. The goal is to identify for each document in U the correct author. The correct author can be one of the writers of the documents in D or none of them. The nature of the dataset rises three main problems. The authors are fandom writer, so they try to reproduce the writing style of the original work. The fandom of the known document and the fandom of the unknown documents are different. Finally, we are in an open-set problem, so there is no certainty that the unknown text is written by one of the authors in the known set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset</head><p>Before starting to address the problem, we collect some statistics about the PAN dataset, to better understand the data. PAN dataset is divided into 20 problems, 5 problems for each language: English, French, Italian, Spanish. For each problem, we have 9 known authors with 7 documents each, for a total of 63 training texts. The number of texts for which we have to predict an author is not the same for every problem. They vary with a maximum of 561 documents in the first problem and a minimum of 38 for the tenth problem. On average we have 202 of unknown fanfics. Since it is well known that in the Authorship Attribution problem, the number of words per document directly affect the performances of the classifiers, we analyze the distribution of the words in each document with known authors. We notice that inside the same problem the length of the documents can be very different. Globally, almost all the documents are in a range between 500 and 1000 words, with the shortest document of 382 words and the longest of 1523.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Authorship Attribution</head><p>In the subsections below, we firstly describe our steps to prepare the data and the tool we used. Later, we describe which features we choose to perform the classification, and finally, we describe our proposed model to solve the Authorship Attribution task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Text Pre-Processing</head><p>Pre-processing is a crucial step to prepare the data in almost every NLP problems. Text pre-processing usually consists in normalize, sanitize or alter the text to remove noise, error, or completely change the data format. We pre-process the texts using different techniques, following we briefly describe the text pre-process we apply on the data.</p><p>WordPunctTokenizer. WordPunctTokenizer of the NLTK library. It divides a text into a list of words. We chose this tokenizer because it maintains the punctuation marks and separates them from words. In this way, we can exploit the punctuation marks to generate a more accurate stylistic profile of the author.</p><p>SnowballStemmer. A stemmer is a tool that removes morphological affixes from a word, reducing it to its stem. A stem is the part of the word that contains no morphological inflections (love, loving and loved are stemmed as love). It is part of the NLTK package, and it supports all the languages that are in the PAN dataset, making it suitable for our purpose. Stemming can be very important since by removing the morphological inflectional it permits to recognize that two words are semantically identical even if they differ syntactically.</p><p>Convertion with POS tagging. A Part-Of-Speech Tagger is a tool that takes in input a text and assigns a part of speech tag to each word. Some examples of POS tags are PRP$ that identify a possessive pronoun (my, his, hers), VB, that identify a verb at the base form (take), and VBD that identify a verb at past tense (took). To create this representation, we firstly tokenize the text, then we use the POS tagger. Finally, we concatenate all the tags and the punctuation marks, adding a space between them. Table <ref type="table" coords="5,159.01,274.91,4.98,8.64" target="#tab_0">1</ref> show an example of text before and after this process. POS tagging is generally used to underline the structure of the text removing all context-based information. It is useful to identify syntactic patterns in the style of the author. We used the spaCy<ref type="foot" coords="5,455.93,297.15,3.49,6.05" target="#foot_0">1</ref> POS tagger since it handles all the languages present in the dataset, with an accuracy that vary from 95.29% to 97.23%. Text distortion. This pre-processing technique for Authorship Attribution task was firstly proposed by <ref type="bibr" coords="5,215.85,489.48,16.60,8.64" target="#b18">[21]</ref> and it was used with good results also in <ref type="bibr" coords="5,411.32,489.48,10.58,8.64" target="#b2">[3]</ref>. This method consists of masking some part of the text, replacing characters with the '*' symbol. We used this method to maintain only punctuation marks and diacritical characters as shown in Table <ref type="table" coords="5,197.64,525.35,3.74,8.64">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Features</head><p>To develop our classifier we tested different kind of features. We heavily use character n-grams due to their robustness in cross-domain settings <ref type="bibr" coords="5,360.16,588.91,15.77,8.64" target="#b10">[13,</ref><ref type="bibr" coords="5,376.96,588.91,12.45,8.64" target="#b16">19,</ref><ref type="bibr" coords="5,390.44,588.91,13.28,8.64" target="#b17">20]</ref> and word n-grams. All our features are based on the extraction of sub-sequences of words or characters called n-gram, and then weighting these sequences with the Tf-Idf, where the term frequency is logarithmically scaled. More formally, an n-gram is a contiguous sequence of n items from a given sample of text. The items can be phonemes, syllables, letters or words. Instead, the Tf-Idf, term frequency-inverse document frequency, is a measure associated to each term, in our case the n-gram sequences, that increases proportionally to the number of times it appears in a document, while it is reduced by the number of documents in the dataset that contain the term. In this way, it is possible to give more importance to features that are frequently used by only one author and less importance to widespread features such as stop-words. With the aim to capture different peculiarities of the author stylistic profile, we tried to combine the benefits of two different approaches: the profile and the instance-based.</p><p>Profile-Based Features. In the profile-based approach, we concatenate all the documents that belong to the same author and consider them as a single one. In this way, it is possible to outline the general style of the author. According to this approach, we extract the Profile feature. It is the union of Char-gram and Word-gram features computed in the following way. For the char-gram, we take into account the raw text, then we select the char-grams of length between 3 and 5, with a cut-off document frequency less than 0.12. Regarding the word-gram, we firstly tokenize and stem the text. Then we extract the word sequences of length 1 up to 3. We consider only the feature with document frequency strictly lower than 0.3. Once computed both the features we stack them together.</p><p>Instance-Based Features. In the instance-based approach, we process and extract the features from each document of an author separately. This last approach allows to extract separate style for each text sample and thus different profiles across different domains. So, for each document, we extract the following features:</p><p>-Char: from the raw text, we extract char-grams of length 3 up to 5. We select all the sequences with a document frequency of less than 0.12. -Dist: we pre-process the text with the aforementioned distortion technique, then we extract sequences of characters of length between 3 and 5. We use 0.12 as cut-off document frequency value. -Stem1&amp;2: After stemming the text, we extract word uni-grams and bi-grams and for each set of features we weight the terms with the Tf-Idf and discard terms that appear with a document frequency higher than 0.3. Finally, we stack them together. -Stem1-3: We stem the text, and then we extract word-grams of length 1 up 3. We take into account only word-grams that appear in the text with document frequency lower than 0.03.</p><p>-POS:We transform the text into its POS tagged form then we extract the sequences of tags of length 3 up to 5. We use 0.12 as cut-off document frequency value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Classifiers</head><p>As the first experiment, we stack all the features mentioned above together, and we test them on different classifiers. We evaluate the performances of the following classifiers: SVM with linear kernel, SVM with RBF kernel, K-nearest neighbors with K = 3 and Random Forest. In this experiment, we left all the hyper-parameters to the default values. In Table <ref type="table" coords="7,190.13,226.48,4.98,8.64" target="#tab_1">3</ref> are shown the results of the classifiers. As we can see, the SVM with linear kernel outperforms other classifiers in almost all the problems. Given this result, we analyze the performance of different kind of features with the linear SVM. In Table <ref type="table" coords="7,149.28,262.35,3.74,8.64" target="#tab_2">4</ref>, we report the score of each kind of feature on different problems. After evaluated these experiments, we try to improve our results with an ensemble classifier that relies on SVMs with linear kernel. The ensemble is a method to combine different classifiers predictions to build a more generally estimator. The ensemble can be based on two methods: averaging method and boosting method. The averaging method takes the output probabilities of N estimators and combines them usually using average. Instead, the boosting method uses a weak base estimator as a starting point, and then, other weak learners are trained to improve the predecessor. For our final classifier, we build an ensemble architecture based on the averaging method. We combine the predictions of several SVMs by the soft voting function. To ensemble the predictions we average for each class the probability of being the right one as predicted by our classifiers, then we pick as a final prediction the class with the highest value. We finally test different combinations of our features in order to optimize the performances and select only the best features for each language.</p><p>In Figure <ref type="figure" coords="7,189.21,429.72,3.74,8.64">1</ref>, we show our final architecture and features combinations for each language. The continuous line in figure are the features used for all the languages: the Profile, Char, Stem1-3 and the Dist. While the dashed line represents the feature used only for the English and the Italian classifier Stem1&amp;2. Finally, the dotted line depicts the feature we use only for documents written in English and Spanish POS. Table <ref type="table" coords="7,473.12,477.54,3.74,8.64" target="#tab_3">5</ref>, resume in tabular form the features used for each language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Unknown Detection</head><p>In this section, we focus on the process of determining if the author of an unknown document is in the known author set or not. To achieve this goal, we take into account the probabilities results of the first three users. Let's P 1 , P 2 and P 3 , respectively the probability of the first, the second and third most probable authors. Then we take a decision based on two conditions. The first one is that the difference between P 1 and P 2 must be less than 0.1. The second condition is that the mean of the difference between P 1 and P 2 and P 1 and P 3 must be less 0.7. If both conditions are True, we predict the text as written by an unknown author. Otherwise, we choose the author with the highest probability. The values of 0.1 and 0.7 are based on experimental observations. The idea is that if an author of the known set wrote the unknown document, the difference between his probability and the probabilities of the other users must be higher than if we do not have the author of that unknown document. The idea is that if one of the known authors has written the document, then the distance between their probabilities are high. On the other hand, if the real author is unknown, the probabilities of the known authors are close to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U nknown =</head><p>T rue, P 1 -P 2 &lt; 0.1 ∧ mean(P 1 -P 2 , P 1 -P 3 ) &lt; 0.7 F alse, otherwise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>PAN organizers chose the macro-averaged F1 score as an evaluation metric since the unknown documents to predict are not equally distributed across all the problems. PAN provides to all the participants of the Authorship Attribution task a Train and a Dev dataset as well as a Virtual Private Server (VPS) to deploy the model. The VPS is hosted on the TIRA platform <ref type="bibr" coords="10,254.82,314.25,15.27,8.64" target="#b13">[16]</ref>, Testbed for Information Retrieval Algorithms. The main function of TIRA is to create a sandbox that the organizers can use to perform the final test and verify the correctness of the result. To better reproduce a real-case scenario, the Test set is unknown to the participants, and the teams involved in the contest can evaluate their model on the Test dataset only on TIRA. We show in Table <ref type="table" coords="10,224.01,374.02,4.98,8.64" target="#tab_4">6</ref> the results on the Dev set. As we can see, the overall F1-score is 70.5%, 12.6% higher than baseline-SVM. Looking at the single problems scores, we can see how few problems, 3, 4, and 14, seem to undermine the effectiveness of our model. Problems 16 and 18 are the ones that reach the higher scores, achieving an F1-score of 88.3% and 87.8% respectively. In Figure <ref type="figure" coords="10,350.40,421.84,3.71,8.64" target="#fig_0">2</ref>(a), we plot the F1-score of the baseline-SVM, the union of all our features and the final ensemble, for each problem. As we can see, our ensemble method outperforms the baseline-SVM in all but one problem, while it constantly performs better than our classifiers without the ensemble. Looking at the Figure <ref type="figure" coords="10,225.16,469.66,3.71,8.64" target="#fig_0">2</ref>(a), it is clear that, even if the methods perform differently, they all struggle with specific problems while achieving better results in others. Further, we plot the F1-score of the two features with the highest results, Profile and Char, used for all languages and the result of our ensemble. As we can see in Figure <ref type="figure" coords="10,447.93,505.53,4.15,8.64" target="#fig_0">2</ref>(b) the Profile feature, that is the concatenation of Char and Word n-grams computed with the profile-based approach, performs better than our second best feature (Char), and worse than the ensemble. Looking at the single languages scores we note that the model performs better on the Italian (76.88%) and the Spanish (76.58%) languages, conversely the performance decrease on the English (63.74%) and the French (65.20%) languages. The final result on the Test dataset used by PAN to evaluate the performance of the proposed model, achieve an F1-score of 68%, that is the second-best score in the task, just 1% lower than the first classified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Discussion on Classifier Performances</head><p>Analyzing our results, we noticed that in the case our classifier assign an author and the author belong to the set of known authors, our classifier have a mean error of only   2.95%. On the other hand, in the case in which in the classification is involved the unknown detector we have a mean error of 26.17%. So, we further investigate about the performance of our classifier in the closed-set scenario. In other words, we run our Authorship Attribution model only on the documents that are written by known author in the Dev dataset. Then, we label as the right author, the one with highest probability score. After the execution we score an overall accuracy of 87% on a total of 2,646 documents. More in details we achieve a single accuracy of 90% on English, 82.4% on French, 84.3% on Italian and 88.5% on Spanish. To better understand the impact of the unknowns detector on the model, we repeat the experiment on a fake open-set scenario.</p><p>In this scenario, we take into account the possibility that there are unknown authors, but we use the same dataset of the previous experiment where they are not. This time we achieve as overall result an accuracy of 78.7%, that is 8.3% lower of the experiment in the closed-set scenario. This results show that in the absence of unknown author (i.e., in a closed-set scenario), our classifier achieves excellent results. However, when we move on the open-set the unknowns detector induces an error of 8.3%. This drop in performance is pretty normal, and it is well known that the Authorship Attribution in open-set scenario is more difficult then in a closed-set. Nonetheless, the results clearly indicate that although our methodology to detect the unknown authors performs slightly better than the baseline, further improvements are needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we proposed our solution for the 2019 Authorship Attribution PAN task. We present a model that relies on different classifiers fitted with a single feature rather than more features for a single classifier. We use an ensemble approach to combine all the probabilities of our single classifiers for each language and increase their result. We use different pre-processing techniques to extract features of a different meaning. We use text distortion, tokenization, stemming, and POS tagging to prepare the text for the extraction. To solve the problem of the unknown authors, we introduced a method that takes into account the three most similar author for the disputed text, instead of only the first two. With our approach, we outperform the baseline for almost every problem. Analyzing our result on different problems, we notice that our performances tend to decrease in the presence of a high number of author missing in the training data. So, we believe that improving the algorithm to detect when an author is unknown could lead to better results in this problem and hence a better result in the overall score. Looking at the baseline in Table <ref type="table" coords="12,229.30,555.70,3.74,8.64" target="#tab_4">6</ref>, we notice that some times the compression method seems to reach high results. It could be useful to understand what kind of pattern the compression identify and use it in order to improve our classifier.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,226.84,115.83,159.43,8.12;6,136.16,134.91,47.80,7.77;6,309.27,134.91,114.29,7.77;6,136.16,146.27,151.74,7.77;6,136.16,157.23,162.13,7.77;6,136.16,168.19,160.81,7.77;6,136.16,179.15,159.01,7.77;6,136.16,190.11,86.90,7.77;6,309.27,146.27,159.39,7.77;6,309.27,157.23,168.36,7.77;6,309.27,168.19,161.39,7.77;6,309.27,179.15,120.54,7.77;6,309.27,190.11,165.38,7.77;6,309.27,201.07,26.40,7.77"><head>Table 2 .</head><label>2</label><figDesc>Text conversion with text distortion Original Text Text converted with POS tagger marqué sur la couverture, avant d'avoir un temps d'arrêt. Le dossier se nommait en effet sobrement « Enterrement de vie de garçon ». Plusieurs souvenirs remontèrent. John sourit doucement en se remém *****é *** ** **********, ***** *'***** ** ***** *'***ê*. ** ******* ** ******* ** ***** ********* « *********** ** *** ** ***ç** ». ********* ********* ******è****. **** ****** ********* ** ** ***é**</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,164.17,255.18,3.30,5.63;11,194.69,255.18,3.30,5.63;11,223.57,255.18,6.60,5.63;11,254.10,255.18,6.60,5.63;11,284.62,255.18,6.60,5.63;11,149.60,229.14,8.44,5.63;11,149.60,194.22,8.44,5.63;11,149.60,159.31,8.44,5.63;11,219.04,264.17,21.77,5.57;11,140.93,182.83,5.57,24.98;11,184.96,279.45,25.34,5.57;11,225.63,279.45,8.21,5.57;11,249.17,279.45,38.19,5.57;11,134.77,292.71,168.76,7.77;11,134.77,303.67,160.52,7.77;11,341.24,255.18,3.30,5.63;11,371.77,255.18,3.30,5.63;11,400.64,255.18,6.60,5.63;11,431.17,255.18,6.60,5.63;11,461.70,255.18,6.60,5.63;11,326.67,232.49,8.44,5.63;11,326.67,209.60,8.44,5.63;11,326.67,186.71,8.44,5.63;11,326.67,163.82,8.44,5.63;11,326.67,140.93,8.44,5.63;11,396.11,264.17,21.77,5.57;11,318.00,182.83,5.57,24.98;11,370.42,279.45,25.34,5.57;11,411.09,279.45,12.49,5.57;11,438.91,279.45,17.14,5.57;11,311.84,292.71,168.76,7.77;11,311.84,303.67,102.59,7.77"><head></head><label></label><figDesc>Comparison between the ensemble, all features stacked together and the baseline-SVM Comparison between the ensemble, the Profile and the Char features</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,186.48,327.38,240.16,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Comparison between different features set and classifiers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,136.16,354.40,340.77,94.85"><head>Table 1 .</head><label>1</label><figDesc>Text conversion with POS Tagging Original Text Text converted with POS tagger Your eyes opened, scanning the room with slightly dazed wariness. You weren't home, but in a room with grey walls and a glass front. Several cameras were pointed at you. You felt panic rise within sone intro.you PRP$ NNS VBN , VBG DT NN IN RB VBN NN . PRP VBD RB NN , CC IN DT NN IN JJ NNS CC DT NN NN . JJ NNS VBD VBN IN PRP . PRP VBD JJ NN IN PRP , CC PRP VBD PRP RP IN PRP$ NN CC PRP$ NNS . " NNP , JJ NN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,162.10,128.72,294.20,509.07"><head>Table 3 .</head><label>3</label><figDesc>F1-score for the individual classifier</figDesc><table coords="8,162.10,151.40,294.20,486.40"><row><cell>Pr</cell><cell>SVM Linear</cell><cell>SVM RBF</cell><cell>K-NN</cell><cell>Random Forest</cell></row><row><cell>01</cell><cell>78.7</cell><cell>76.9</cell><cell>67.9</cell><cell>68.3</cell></row><row><cell>02</cell><cell>57.1</cell><cell>56.2</cell><cell>45.8</cell><cell>42.7</cell></row><row><cell>03</cell><cell>71.0</cell><cell>67.1</cell><cell>49.3</cell><cell>45.6</cell></row><row><cell>04</cell><cell>45.3</cell><cell>34.2</cell><cell>32.6</cell><cell>33.7</cell></row><row><cell>05</cell><cell>53.0</cell><cell>51.8</cell><cell>43.1</cell><cell>44.1</cell></row><row><cell>06</cell><cell>65.5</cell><cell>64.3</cell><cell>59.3</cell><cell>43.7</cell></row><row><cell>07</cell><cell>62.9</cell><cell>58.0</cell><cell>51.1</cell><cell>38.2</cell></row><row><cell>08</cell><cell>64.2</cell><cell>60.7</cell><cell>53.6</cell><cell>39.4</cell></row><row><cell>09</cell><cell>73.0</cell><cell>65.0</cell><cell>46.7</cell><cell>43.5</cell></row><row><cell>10</cell><cell>54.8</cell><cell>56.7</cell><cell>41.9</cell><cell>33.6</cell></row><row><cell>11</cell><cell>69.6</cell><cell>65.9</cell><cell>61.8</cell><cell>60.3</cell></row><row><cell>12</cell><cell>64.6</cell><cell>62.3</cell><cell>62.2</cell><cell>48.8</cell></row><row><cell>13</cell><cell>72.1</cell><cell>71.7</cell><cell>52.3</cell><cell>55.8</cell></row><row><cell>14</cell><cell>78.2</cell><cell>67.6</cell><cell>60.4</cell><cell>71.7</cell></row><row><cell>15</cell><cell>70.2</cell><cell>69.5</cell><cell>69.3</cell><cell>65.6</cell></row><row><cell>16</cell><cell>87.6</cell><cell>87.1</cell><cell>75.2</cell><cell>68.8</cell></row><row><cell>17</cell><cell>71.5</cell><cell>73.4</cell><cell>71.8</cell><cell>40.7</cell></row><row><cell>18</cell><cell>82.2</cell><cell>81.9</cell><cell>72.9</cell><cell>68.2</cell></row><row><cell>19</cell><cell>66.2</cell><cell>63.7</cell><cell>54.6</cell><cell>38.0</cell></row><row><cell>20</cell><cell>52.8</cell><cell>49.3</cell><cell>42.5</cell><cell>26.0</cell></row><row><cell>Overall</cell><cell>67.0</cell><cell>64.2</cell><cell>55.7</cell><cell>48.8</cell></row><row><cell></cell><cell cols="3">Figure 1. Ensemble architecture</cell><cell></cell></row><row><cell>Features</cell><cell>Classifiers</cell><cell></cell><cell>Ensemble</cell><cell></cell></row><row><cell>Profile</cell><cell>SVM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Char</cell><cell>SVM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stem1-3</cell><cell>SVM</cell><cell></cell><cell></cell><cell>Prediction</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Soft Voting</cell></row><row><cell>Dist</cell><cell>SVM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stem1&amp;2</cell><cell>SVM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pos</cell><cell>SVM</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,163.59,161.97,288.18,269.93"><head>Table 4 .</head><label>4</label><figDesc>F1-score for the individual feature and the aggregation</figDesc><table coords="9,163.59,186.48,288.18,245.42"><row><cell>Problem</cell><cell>Profile</cell><cell>Char</cell><cell>Dist</cell><cell>Stem1-3</cell><cell>Stem1&amp;2</cell><cell>POS</cell></row><row><cell>01</cell><cell>76.6</cell><cell>75.4</cell><cell>75.4</cell><cell>76.9</cell><cell>79.0</cell><cell>75.9</cell></row><row><cell>02</cell><cell>55.4</cell><cell>55.6</cell><cell>43.9</cell><cell>52.5</cell><cell>53.0</cell><cell>47.2</cell></row><row><cell>03</cell><cell>70.8</cell><cell>60.8</cell><cell>41.1</cell><cell>62.5</cell><cell>63.7</cell><cell>45.7</cell></row><row><cell>04</cell><cell>48.5</cell><cell>46.2</cell><cell>28.9</cell><cell>43.0</cell><cell>43.1</cell><cell>33.2</cell></row><row><cell>05</cell><cell>49.3</cell><cell>53.6</cell><cell>44.4</cell><cell>52.5</cell><cell>49.3</cell><cell>42.5</cell></row><row><cell>06</cell><cell>66.4</cell><cell>62.6</cell><cell>63.8</cell><cell>63.0</cell><cell>58.0</cell><cell>19.4</cell></row><row><cell>07</cell><cell>57.9</cell><cell>58.4</cell><cell>39.3</cell><cell>57.6</cell><cell>46.8</cell><cell>21.9</cell></row><row><cell>08</cell><cell>63.0</cell><cell>58.6</cell><cell>52.2</cell><cell>57.4</cell><cell>45.3</cell><cell>25.3</cell></row><row><cell>09</cell><cell>70.1</cell><cell>62.1</cell><cell>52.2</cell><cell>68.6</cell><cell>54.4</cell><cell>21.1</cell></row><row><cell>10</cell><cell>54.8</cell><cell>58.5</cell><cell>40.6</cell><cell>59.3</cell><cell>56.6</cell><cell>7.4</cell></row><row><cell>11</cell><cell>70.5</cell><cell>64.6</cell><cell>55.6</cell><cell>69.4</cell><cell>71.0</cell><cell>27.1</cell></row><row><cell>12</cell><cell>68.3</cell><cell>68.4</cell><cell>54.9</cell><cell>70.6</cell><cell>70.1</cell><cell>20.9</cell></row><row><cell>13</cell><cell>72.6</cell><cell>71.9</cell><cell>63.3</cell><cell>68.5</cell><cell>70.5</cell><cell>28.3</cell></row><row><cell>14</cell><cell>65.8</cell><cell>51.8</cell><cell>79.4</cell><cell>80.1</cell><cell>81.2</cell><cell>39.4</cell></row><row><cell>15</cell><cell>86.4</cell><cell>76.9</cell><cell>56.3</cell><cell>79.9</cell><cell>76.9</cell><cell>19.9</cell></row><row><cell>16</cell><cell>84.0</cell><cell>85.0</cell><cell>71.0</cell><cell>81.8</cell><cell>74.9</cell><cell>30.8</cell></row><row><cell>17</cell><cell>78.3</cell><cell>75.7</cell><cell>52.3</cell><cell>63.1</cell><cell>61.4</cell><cell>35.1</cell></row><row><cell>18</cell><cell>80.6</cell><cell>76.8</cell><cell>61.7</cell><cell>84.1</cell><cell>76.5</cell><cell>30.1</cell></row><row><cell>19</cell><cell>67.3</cell><cell>69.4</cell><cell>42.0</cell><cell>69.1</cell><cell>62.7</cell><cell>18.7</cell></row><row><cell>20</cell><cell>52.8</cell><cell>53.8</cell><cell>26.1</cell><cell>43.5</cell><cell>50.1</cell><cell>12.2</cell></row><row><cell>overall</cell><cell>67.0</cell><cell>64.3</cell><cell>52.2</cell><cell>65.2</cell><cell>62.2</cell><cell>30.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,164.96,533.91,285.45,81.11"><head>Table 5 .</head><label>5</label><figDesc>Table of features for each language</figDesc><table coords="9,164.96,558.41,285.45,56.61"><row><cell></cell><cell>Profile</cell><cell>Char</cell><cell>Stem1-3</cell><cell>Dist</cell><cell>POS</cell><cell>Stem1&amp;2</cell></row><row><cell>English</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>French</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>-</cell><cell>-</cell></row><row><cell>Italian</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>-</cell><cell>x</cell></row><row><cell>Spanish</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,170.70,376.54,273.96,268.09"><head>Table 6 .</head><label>6</label><figDesc>F1-score on the Dev dataset</figDesc><table coords="11,170.70,399.21,273.96,245.42"><row><cell>Problem</cell><cell>Baseline-SVM</cell><cell>Baseline-Comp</cell><cell>Ensemble</cell><cell>Delta</cell></row><row><cell>01</cell><cell>69.5</cell><cell>68.2</cell><cell>82.2</cell><cell>12.7</cell></row><row><cell>02</cell><cell>44.7</cell><cell>33.6</cell><cell>56.2</cell><cell>11.5</cell></row><row><cell>03</cell><cell>49.3</cell><cell>50.1</cell><cell>73.0</cell><cell>23.7</cell></row><row><cell>04</cell><cell>33.1</cell><cell>49.0</cell><cell>51.1</cell><cell>18.0</cell></row><row><cell>05</cell><cell>47.1</cell><cell>34.0</cell><cell>56.2</cell><cell>9.1</cell></row><row><cell>06</cell><cell>70.2</cell><cell>69.1</cell><cell>65.6</cell><cell>-4.6</cell></row><row><cell>07</cell><cell>49.9</cell><cell>54.2</cell><cell>63.8</cell><cell>13.9</cell></row><row><cell>08</cell><cell>50.6</cell><cell>49.2</cell><cell>65.6</cell><cell>15.0</cell></row><row><cell>09</cell><cell>59.9</cell><cell>60.8</cell><cell>73.8</cell><cell>13.9</cell></row><row><cell>10</cell><cell>44.2</cell><cell>50.1</cell><cell>57.3</cell><cell>13.1</cell></row><row><cell>11</cell><cell>65.1</cell><cell>59.5</cell><cell>73.7</cell><cell>8.6</cell></row><row><cell>12</cell><cell>59.4</cell><cell>50.8</cell><cell>71.0</cell><cell>11.6</cell></row><row><cell>13</cell><cell>68.7</cell><cell>73.1</cell><cell>74.3</cell><cell>5.6</cell></row><row><cell>14</cell><cell>59.8</cell><cell>78.0</cell><cell>83.3</cell><cell>23.5</cell></row><row><cell>15</cell><cell>74.5</cell><cell>71.2</cell><cell>82.1</cell><cell>7.6</cell></row><row><cell>16</cell><cell>76.8</cell><cell>70.5</cell><cell>88.3</cell><cell>11.5</cell></row><row><cell>17</cell><cell>58.4</cell><cell>62.3</cell><cell>81.7</cell><cell>23.3</cell></row><row><cell>18</cell><cell>70.3</cell><cell>65.9</cell><cell>87.8</cell><cell>17.5</cell></row><row><cell>19</cell><cell>55.6</cell><cell>40.3</cell><cell>71.0</cell><cell>15.4</cell></row><row><cell>20</cell><cell>51.3</cell><cell>22.3</cell><cell>54.1</cell><cell>2.8</cell></row><row><cell>Overall</cell><cell>57.9</cell><cell>55.6</cell><cell>70.5</cell><cell>12.6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,657.93,91.46,6.31"><p>https://spacy.io/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This work was supported in part by the <rs type="funder">MIUR</rs> under grant "<rs type="programName">Dipartimenti di eccellenza 2018</rs><rs type="grantNumber">-2022</rs>" of the <rs type="funder">Department of Computer</rs> <rs type="institution">Science of Sapienza University</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fBRyrKb">
					<idno type="grant-number">-2022</idno>
					<orgName type="program" subtype="full">Dipartimenti di eccellenza 2018</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.61,142.69,326.51,7.77;13,150.95,153.65,324.52,7.77;13,150.95,164.61,56.77,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,230.89,142.69,238.23,7.77;13,150.95,153.65,134.26,7.77">Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,291.27,153.65,184.21,7.77">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,175.53,337.98,7.77;13,150.95,186.49,315.95,7.77;13,150.95,197.45,23.90,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,356.55,175.53,124.04,7.77;13,150.95,186.49,81.00,7.77">Authorship verification using deep belief network systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Brocardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Traore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Woungang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Obaidat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,238.03,186.49,176.33,7.77">International Journal of Communication Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3259</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,208.37,311.12,7.77;13,150.95,219.33,153.55,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,251.94,208.37,198.50,7.77">Each-usp ensemble cross-domain authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Custódio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Paraboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,150.95,219.33,127.40,7.77">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,230.25,312.25,7.77;13,150.95,241.21,301.85,7.77;13,150.95,252.17,316.87,7.77;13,150.95,263.12,321.36,7.77;13,150.95,274.08,323.61,7.77;13,150.95,285.04,329.64,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,150.95,252.17,316.87,7.77;13,150.95,263.12,140.81,7.77">Overview of PAN 2019: Author Profiling, Celebrity Profiling, Cross-domain Authorship Attribution and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavancas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,407.83,274.08,66.74,7.77;13,150.95,285.04,229.80,7.77">Proceedings of the Tenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Heinatz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Tenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">2019. Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,295.96,323.03,7.77;13,139.25,306.89,310.28,7.77;13,139.25,317.81,336.58,7.77;13,150.95,328.77,296.65,7.77;13,150.95,339.72,191.67,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,238.26,295.96,227.38,7.77;13,139.25,306.89,3.36,7.77;13,238.26,306.89,211.27,7.77">Author clustering using compression-based dissimilarity scores 6</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Graner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,204.82,328.77,242.78,7.77;13,150.95,339.72,35.85,7.77">Proceedings of the conference pacific association for computational linguistics</title>
		<meeting>the conference pacific association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
	<note>Cross-domain authorship attribution based on compression. N-gram-based author profiles for authorship attribution</note>
</biblStruct>

<biblStruct coords="13,142.61,350.65,302.47,7.77;13,150.95,361.60,248.18,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,361.66,350.65,83.42,7.77;13,150.95,361.60,102.06,7.77">Cross-genre authorship verification using unmasking</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Crombez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,259.41,361.60,56.05,7.77">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="340" to="356" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,372.53,321.69,7.77;13,150.95,383.49,319.94,7.77;13,150.95,394.44,313.95,7.77;13,150.95,405.40,124.47,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,150.95,383.49,260.37,7.77">Overview of the Cross-domain Authorship Attribution Task at PAN 2019</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="13,305.73,394.44,117.33,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="13,429.54,394.44,35.36,7.77;13,150.95,405.40,48.03,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,416.32,332.89,7.77;13,150.95,427.28,296.46,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,232.18,416.32,211.01,7.77">A simple and efficient algorithm for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,448.73,416.32,26.40,7.77;13,150.95,427.28,212.78,7.77">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="269" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,438.21,311.25,7.77;13,150.95,449.16,322.35,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,310.76,438.21,142.73,7.77;13,150.95,449.16,80.96,7.77">Measuring differentiability: Unmasking pseudonymous authors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,237.74,449.16,139.44,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,460.09,331.04,7.77;13,150.95,471.04,221.87,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,313.28,460.09,160.01,7.77;13,150.95,471.04,105.75,7.77">Forensic linguistics: Applying the science of linguistics to issues of the law</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,262.57,471.04,54.97,7.77">Hofstra L. Rev</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">881</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,481.97,310.21,7.77;13,150.95,492.93,238.67,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,254.96,481.97,197.49,7.77;13,150.95,492.93,36.14,7.77">The effect of author set size and data size in authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,192.62,492.93,122.29,7.77">Literary and linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="55" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,503.85,329.08,7.77;13,150.95,514.81,244.24,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,302.46,503.85,168.86,7.77;13,150.95,514.81,36.14,7.77">Comparing compression models for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Oliveira</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Justino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,192.62,514.81,106.94,7.77">Forensic science international</title>
		<imprint>
			<biblScope unit="volume">228</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="100" to="104" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,525.73,330.59,7.77;13,150.95,536.69,242.55,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,245.35,525.73,179.35,7.77">A profile-based method for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Potha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,442.45,525.73,30.38,7.77;13,150.95,536.69,130.54,7.77">Hellenic Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,547.61,335.40,7.77;13,150.95,558.57,309.15,7.77;13,150.95,569.53,209.02,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,333.86,547.61,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,259.53,558.57,200.58,7.77;13,150.95,569.53,144.92,7.77">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,580.45,338.35,7.77;13,150.95,591.41,314.88,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="13,283.19,580.45,197.40,7.77;13,150.95,591.41,164.87,7.77">Character-level and multi-channel convolutional neural networks for large-scale authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ghaffari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Breslin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.06686</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="13,142.24,602.33,318.38,7.77;13,150.95,613.29,300.19,7.77;13,150.95,624.25,311.79,7.77;13,150.95,635.20,184.57,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,409.85,602.33,50.78,7.77;13,150.95,613.29,197.65,7.77">Convolutional neural networks for authorship attribution of short texts</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,366.22,613.29,84.92,7.77;13,150.95,624.25,308.26,7.77">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="13,189.90,635.20,43.97,7.77">Short Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="669" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,646.13,302.64,7.77;13,150.95,657.08,295.21,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,207.24,646.13,182.01,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,395.57,646.13,49.31,7.77;13,150.95,657.08,211.53,7.77">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,119.96,315.41,7.77;14,150.95,130.92,210.90,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,207.24,119.96,250.40,7.77;14,150.95,130.92,27.22,7.77">On the robustness of authorship attribution based on character n-gram features</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,183.82,130.92,94.36,7.77">Journal of Law and Policy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="421" to="439" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.24,141.88,320.23,7.77;14,150.95,152.84,311.79,7.77;14,150.95,163.80,168.31,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,207.24,141.88,152.53,7.77">Authorship attribution using text distortion</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,377.55,141.88,84.92,7.77;14,150.95,152.84,308.26,7.77">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s" coord="14,189.90,163.80,43.46,7.77">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1138" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
