<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.40,115.90,294.56,12.90">Word Distance Approach for Celebrity Profiling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.51,153.95,97.07,8.64"><forename type="first">Muhammad</forename><forename type="middle">Usman</forename><surname>Asif</surname></persName>
						</author>
						<author>
							<persName coords="1,248.00,153.95,76.23,8.64"><forename type="first">Muhammad</forename><surname>Naeem</surname></persName>
						</author>
						<author>
							<persName coords="1,331.83,153.95,65.80,8.64"><forename type="first">Zeeshan</forename><surname>Ramzan</surname></persName>
							<email>zramzan@uet.edu.pk</email>
						</author>
						<author>
							<persName coords="1,422.02,153.95,48.83,8.64"><forename type="first">Fahad</forename><surname>Najib</surname></persName>
							<email>fahad.najib@uet.edu.pk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Engineering and Technology</orgName>
								<address>
									<settlement>Lahore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">KSK</orgName>
								<address>
									<settlement>Campus</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.40,115.90,294.56,12.90">Word Distance Approach for Celebrity Profiling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">92792D45C5C73C511923B33844E68A24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Celebrity Profiling</term>
					<term>Text Classification</term>
					<term>Natural Language Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes and evaluates a model for Celebrity Profiling 2019 dataset. The training data set contain 33,836 celebrities' text with 50 different languages. The task was to create a model for this textual complex dataset which predict gender (male, female, nonbinary), fame (star, superstar, rising), occupation (sports, performer, creator, professional, manager, science, politics, religious) and birthyear  of celebrity. We use word distance features as input to different classifiers for different aspects (gender, fame, occupation and birthyear) of celebrity to create models. Results showed that word distance-based features outperformed the PAN baseline results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Celebrity profiling task <ref type="bibr" coords="1,233.08,424.65,16.60,8.64" target="#b13">[14]</ref> offerd by PAN'19 <ref type="bibr" coords="1,330.49,424.65,11.62,8.64" target="#b2">[3]</ref> is to predict the celebrity predict gender (male, female, nonbinary), degree of fame (star, superstar, rising), occupation (sports, performer, creator, professional, manager, science, politics, religious) and birthyear (1940-2011) from celebrities' tweets written in 50 different languages. This task was offered by PAN <ref type="bibr" coords="1,219.73,472.47,10.58,8.64" target="#b2">[3]</ref>. The dataset <ref type="bibr" coords="1,286.07,472.47,16.60,8.64" target="#b12">[13]</ref> for both training and testing of models was given by PAN. The complete dataset contains tweets of 48,335 celebrity users. The training dataset consists of tweets of 33,836 users, and rest of the users' tweets were included in test dataset. The prediction of properties containing many labels e.g., birthyear contain 71 label classes and occupation contain 8 label classes, makes the task more challenging.</p><p>Almost all celebrities use the twitter and tweets there. The task has importance in social media and in celebrity industry for predicting the celebrity properties like gender, birthyear, occupation, fame by using their tweets. To measure these properties of celebrities from their tweets is significant for the celebrity fans, social media and industry. Knowing users' demographics from their written text has also applications in marketing as brands could increase reach of their message to more relevant audience <ref type="bibr" coords="1,134.77,615.93,15.77,8.64" target="#b9">[10,</ref><ref type="bibr" coords="1,150.54,615.93,11.83,8.64" target="#b11">12]</ref>. The problem of celebrity traits predictions has also applications in forensic <ref type="bibr" coords="2,134.77,119.31,11.45,8.64" target="#b7">[8,</ref><ref type="bibr" coords="2,146.22,119.31,7.64,8.64" target="#b3">4]</ref> because of increasing cases of cyber crime including sexual harassment, threatening, identity theft etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The problem of predicting different personality traits from text, due to it's applications in various other problem, have gain lot attention from community. Previously doc2vec document embedding technique used to train SVM and logistic regression classifier <ref type="bibr" coords="2,134.77,222.64,10.89,8.64" target="#b1">[2,</ref><ref type="bibr" coords="2,145.66,222.64,7.26,8.64" target="#b4">5,</ref><ref type="bibr" coords="2,152.92,222.64,7.26,8.64" target="#b0">1]</ref>. RUSProfiling (Cross-Genre Gender Identification in Russian texts) used character n-grams, word n-grams and gender specific Russian grammatical features to train multinomial Naive Bayes, logistic regression, random forest, and ensemble classifier for gender identification <ref type="bibr" coords="2,232.22,258.50,10.58,8.64" target="#b6">[7]</ref>. The problem to identification of author's traits from his/her written text have been addressed by using stylistic features to train different Machine Learning classifiers e.g., J48, Logistic Regression, Random Forest and Naive Bayes <ref type="bibr" coords="2,134.77,294.37,15.27,8.64" target="#b10">[11]</ref>. Different feature representations including raw frequency, binary, normalized frequency, tf-idf and second order attributes (SOA) have been used in combination with different machine learning algorithms including multinomial naive Bayes, Support Vector Machines (SVM), logistic regression <ref type="bibr" coords="2,297.87,330.23,10.58,8.64" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus</head><p>The PAN'19 <ref type="bibr" coords="2,190.80,385.74,11.62,8.64" target="#b2">[3]</ref> Celebrity Profiling <ref type="bibr" coords="2,286.77,385.74,16.60,8.64" target="#b13">[14]</ref> Dataset <ref type="bibr" coords="2,341.51,385.74,16.60,8.64" target="#b12">[13]</ref> contains twitter data of total 48,335 User Profiles. These tweets belongs to 50 different languages. A subset of this dataset, tweets of 33,836 users, used for the purpose of training models, whereas, remaining dataset consisting of 14,499 user profiles is used for testing of trained models. The complete training datasets consists of a single ndjson file in which tweets of all 33,836 user profiles/celebrities are present.</p><p>The corpus contains tweets, grouped by user/celebrity and labeled with gender (male, female, nonbinary), degree of fame (star, superstar, rising), occupation (sports, performer, creator, professional, manager, science, politics, religious) and birthyear .</p><p>The corpus was not balanced (See Figure <ref type="figure" coords="2,324.99,505.29,3.60,8.64">1</ref>). In case of gender, more than 50% profiles are of male celebrities, whereas, only 32 users belongs to nonbinary. Similarly, huge proportion of user profiles are stars, whereas, the frequency of rising and superstars is very low. Same is the case with occupation, where, there are sufficient instances of sports, performer and creator, whereas, remaining categories are in minority. The corpus is also unbalanced in case of birthyear (See Figure <ref type="figure" coords="2,367.12,565.07,3.60,8.64">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>We use the word distance approach for training models to predict different personality traits of celebrities. We made 200 (4 * 50) models as corpus contains tweets of 50 different languages and we have to predict fours aspects of user profile for each user profile. Each model predicts the specific class / personality trait for specific language such as English gender model predicts gender of user whose tweets are in English language. Each model has been trained using different sets of features and classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pre-processing</head><p>As corpus contains tweets written in 50 different languages, we put the same language tweets in same file by using langdetect module of Python. In this way, whole corpus was divided into 50 ndjson files such as en.ndjson, ar.ndjson files for languages English and Arabic. After separation we examine that almost 93% tweets are of English language and remaining 7% are non-English so made two categories English and non-English corpus.</p><p>After separating tweets of different languages, we applied different technique for data cleaning and features extraction for training models. There were lots of emojis, tag words, stop words, punctuation words, numbers, alphanumeric words, links, URLs, short form words, repeating characters words with punctuation's marks and escape characters. First of all, we removed all links / URLs from corpus by using a regular expression. Then, we extracted words from the text by tokenizing text using word tokenizers. We used the language specific word tokenizers for the purpose of tokenizing text into words. If, we could not find any word tokenizer for any language then we tokenized the text with space delimiter. We made a set of unique tokens. After that, we excluded all punctuation marks, stop words, numbers, alphanumeric words, URLs. Then we remove all escape characters and hash tag (#), @, spaces, brackets etc., from the word string and made the words clean. That's how we get the cleaned set of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Features Selection</head><p>After data cleaning and pre-processing, we made a dictionary for each personality trait for each language, which yielded 200 (4 * 50) dictionaries. The key of each of these dictionaries is a word and value of this dictionary is a list. Length of list depends upon the number of labels in the class (gender, fame, occupation or birthyear) to predict. Let if we want to make a model to predict gender then the list's first index (0 index) give count of male users in corpus who used this word (key in the dictionary) in their tweets. Same, second index for female and third index for non-binary (See Figure <ref type="figure" coords="4,431.90,570.51,3.60,8.64" target="#fig_1">3</ref>).</p><p>n 1 : Number of males in corpus who uses this word in their tweet n 2 : Number of females in corpus who uses this word in their tweet n 3 : Number of non-binaries in corpus who uses this word in their tweet Same process was followed to create dictionaries for the fame, occupation and birthyear classes. For example, the range of birthyear is from 1940 to 2011. It contains 71 possibilities, so the list length would be 71.</p><p>The most important and tricky part of feature selection was to filter most distinguishing features from the dictionaries created in last step. For each word, we checked that which label / class (male, female, non-binary) is using this word most. If all classes are using a word with almost comparable frequency, then it is common word and we will not choose it as feature to train model. But if one label / class is using this word most and others are using it least, then we will choose this word as feature. We can say that, we will choose such words, for which, one label class has greater distance in count from other classes. For this we designed strategy to calculate how much maximum distance, a word is creating. As in total corpus we have let say 60% men, 30% women and 10% non-binary tweets so men will always dominate the women and non-binaries. For this we multiplied the count (n 1 , n 2 , n 3 ) of list with the corresponding ratio. Equations 1, 2 and 3 shows the formulas to calculate the ratio to be multiplied with the count. ratio_male = total number of tweets in all corpora total number of tweets of male users (1) ratio_f emale = total number of tweets in all corpora total number of tweets of female users</p><p>(2) ratio_nonbinary = total number of tweets in all corpora total number of tweets of non-binary users</p><p>After calculating the ratio, we multiplied the ratio number with each word's count list (n 1 , n 2 , n 3 ). New structure of key-value pair of dictionary is represented below:</p><p>W ord : [n 1 * ratio male , n 2 * ratio f emale , n 3 * ratio non-binary ] After multiplying the ratio, the problem created because of unbalanced dataset or dominating class is somehow solved. After this we calculated the difference created by the highest value of count with other counts in the list. For this we picked the highest count value in the list let say n 1 has the highest value in list, then calculated it's difference with other values in the list. At the end add the all differences. After adding we get a number which is the distance of that word. Let's say n 1 has highest value in list (n 1 , n 2 , n 3 ), the word distance would be calculated using Equation <ref type="formula" coords="5,386.23,496.13,3.74,8.64" target="#formula_1">4</ref>.</p><formula xml:id="formula_1" coords="5,218.63,523.67,261.96,9.65">W ord_Distance = (n 1 -n 2 ) + (n 1 -n 3 )<label>(4)</label></formula><p>After calculating distance of each word, the dictionary would now contain words as keys and their respective distance as value Dictionary{word 1 : word 1 _distance, word 2 : word 2 _distance} Now, we sorted this dictionary in reverse direction. The large size of dictionary made it challenging to sort dictionary. Therefore, we get the list of all values form dictionary and sorted it in reverse order and then deleted the low distance values. After sorting list, we picked top scoring values and got the corresponding words from the dictionary and selected them as features.</p><p>After extracting features, we created CSV files to pass it to the Machine Learning algorithms to train model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classifiers</head><p>The sklearn implementations of various Machine Learning algorithms were applied on CSV files created in last step. We used 80% data for training the model and 20% for testing. We applied six different algorithms (See Table <ref type="table" coords="7,356.98,293.79,4.15,8.64" target="#tab_0">1</ref>) to train models. Then tested the models with 20% testing data. We selected highest scoring algorithms for training the model using 100% available data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Measures</head><p>The performance of our proposed for Individual traits was judged by F 1 measure (See Equation <ref type="formula" coords="7,173.79,379.02,3.60,8.64">5</ref>). Whereas, overall performance of the system would be judged by a combined metric cRank, which is harmonic mean of each label's metric (See Equation <ref type="formula" coords="7,464.58,390.98,3.60,8.64" target="#formula_2">6</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head><p>The results of our proposed approach on Training dataset are presented in Table <ref type="table" coords="7,473.11,512.97,3.74,8.64" target="#tab_1">2</ref>.</p><p>Table <ref type="table" coords="7,160.22,524.93,4.98,8.64" target="#tab_1">2</ref> shows the F-measure of all traits of training dataset. The F-measure in case of occupation and fame is much higher than other two traits. The training dataset is somehow more balanced in case of occupation and fame than other two traits could be the reason for such results. Moreover, the birth year range is 1940-2011 and there are not enough user profiles for non-English to cover all these birthyears (1940-2011). These problems with the training dataset made it very challamging to correctly predict birthyear. The cRank (See Equation <ref type="formula" coords="7,282.71,596.66,4.15,8.64" target="#formula_2">6</ref>) on Training dataset, the combined score of all traits, is 0.604653. Table <ref type="table" coords="7,173.78,620.57,4.98,8.64" target="#tab_2">3</ref> presents results obtained by applying our proposed technique on test dataset using TIRA <ref type="bibr" coords="7,185.51,632.53,10.58,8.64" target="#b8">[9]</ref>. These results show that our technique could not perform well on test dataset as compared with training dataset. The features, the list of words used for training, were extracted from train dataset, which were not necessarily present in test dataset </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have explained a technique for the prediction of the celebrities' gender, fame, occupation and birthyear from their tweets. It has applications in various fields like forensics, marketing and security. We trained models on the training data provided by the PAN organizers. The results we achieved on are pretty good. In future, more performance can e achieved by making training dataset more balanced and well representative of the population. Moreover, more sophisticated features, which are not specific to training dataset, can also improve results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,177.74,309.31,259.89,8.12;3,144.67,329.63,326.01,178.74"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. Overview of PAN19 Celebrity Profiling Dataset (Source: [14])</figDesc><graphic coords="3,144.67,329.63,326.01,178.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,199.93,264.55,215.50,8.12;4,144.67,115.83,326.01,133.98"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example of dictionary used for Features Selection</figDesc><graphic coords="4,144.67,115.83,326.01,133.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,249.30,417.27,21.39,9.65;7,274.66,410.53,90.00,8.74;7,280.47,424.10,78.38,8.74;7,468.98,417.59,11.62,8.64;7,217.85,449.19,35.97,8.96;7,324.56,442.45,4.98,8.74;7,266.97,454.63,3.97,6.12;7,258.98,462.21,19.46,6.05;7,282.35,456.51,7.75,8.74;7,307.47,454.63,3.97,6.12;7,293.51,462.21,31.41,6.05;7,328.82,456.51,7.75,8.74;7,349.80,454.63,3.97,6.12;7,339.98,462.21,23.11,6.05;7,366.99,456.51,7.75,8.74;7,384.65,454.63,3.97,6.12;7,378.15,462.21,16.46,6.05"><head>1 F1,fame + 1 F1,occupation + 1 F1,gender + 1 F1</head><label>1111</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,136.16,115.83,358.12,594.24"><head>Table 1 .</head><label>1</label><figDesc>Classifiers used for creating models</figDesc><table coords="6,136.16,149.00,358.12,561.07"><row><cell cols="3">index Language Gender</cell><cell>Fame</cell><cell>Occupation</cell><cell>Birthyear</cell></row><row><cell>1</cell><cell>af</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>2</cell><cell>ar</cell><cell cols="2">Logistic Regression K Neighbors</cell><cell>Random Forest</cell><cell>Logistic Regression</cell></row><row><cell>3</cell><cell>bg</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>4</cell><cell>bn</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>5</cell><cell>ca</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>6</cell><cell>cs</cell><cell cols="2">Logistic Regression SVC</cell><cell cols="2">Logistic Regression Logistic Regression</cell></row><row><cell>7</cell><cell>cy</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>8</cell><cell>da</cell><cell>Decision Tree</cell><cell cols="3">Logistic Regression Logistic Regression Logistic Regression</cell></row><row><cell>9</cell><cell>de</cell><cell cols="2">Logistic Regression SVC</cell><cell cols="2">Logistic Regression Logistic Regression</cell></row><row><cell>10</cell><cell>en</cell><cell cols="2">Logistic Regression Random Forest</cell><cell>Random Forest</cell><cell>Logistic Regression</cell></row><row><cell>11</cell><cell>el</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>12</cell><cell>es</cell><cell cols="3">Logistic Regression Logistic Regression Random Forest</cell><cell>Logistic Regression</cell></row><row><cell>13</cell><cell>et</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>14</cell><cell>fa</cell><cell>SVC</cell><cell>Decision Tree</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>15</cell><cell>fi</cell><cell>SVC</cell><cell>Decision Tree</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>16</cell><cell>fr</cell><cell>Decision Tree</cell><cell>SVC</cell><cell>Random Forest</cell><cell>SVC</cell></row><row><cell>17</cell><cell>gu</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>18</cell><cell>he</cell><cell>Gaussian NB</cell><cell>SVC</cell><cell>Gaussian NB</cell><cell>Logistic Regression</cell></row><row><cell>19</cell><cell>hi</cell><cell cols="2">Logistic Regression Random Forest</cell><cell>K Neighbors</cell><cell>Logistic Regression</cell></row><row><cell>20</cell><cell>hr</cell><cell>Gaussian NB</cell><cell>SVC</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>21</cell><cell>hu</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>22</cell><cell>id</cell><cell>Gaussian NB</cell><cell>SVC</cell><cell>Gaussian NB</cell><cell>Logistic Regression</cell></row><row><cell>23</cell><cell>it</cell><cell>Gaussian NB</cell><cell>Decision Tree</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>24</cell><cell>ja</cell><cell>Decision Tree</cell><cell cols="2">Logistic Regression K Neighbors</cell><cell>Logistic Regression</cell></row><row><cell>25</cell><cell>kn</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>26</cell><cell>ko</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>27</cell><cell>lv</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>28</cell><cell>mk</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>29</cell><cell>mr</cell><cell>SVC</cell><cell>SVC</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>30</cell><cell>ne</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>31</cell><cell>nl</cell><cell>Decision Tree</cell><cell>SVC</cell><cell>Decision Tree</cell><cell>SVC</cell></row><row><cell>32</cell><cell>no</cell><cell cols="2">Logistic Regression Decision Tree</cell><cell cols="2">Logistic Regression Logistic Regression</cell></row><row><cell>33</cell><cell>pl</cell><cell>Random Forest</cell><cell>Gaussian NB</cell><cell cols="2">Logistic Regression Logistic Regression</cell></row><row><cell>34</cell><cell>pt</cell><cell>Decision Tree</cell><cell>SVC</cell><cell>Random Forest</cell><cell>Decision Tree</cell></row><row><cell>35</cell><cell>ro</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>36</cell><cell>ru</cell><cell cols="2">Logistic Regression K Neighbors</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>37</cell><cell>sk</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>38</cell><cell>sl</cell><cell cols="3">Logistic Regression Logistic Regression Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>39</cell><cell>so</cell><cell>Random Forest</cell><cell>Gaussian NB</cell><cell>Decision Tree</cell><cell>Logistic Regression</cell></row><row><cell>40</cell><cell>sq</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>41</cell><cell>sv</cell><cell>Decision Tree</cell><cell>Decision Tree</cell><cell cols="2">Logistic Regression Logistic Regression</cell></row><row><cell>42</cell><cell>sw</cell><cell>Random Forest</cell><cell cols="3">Logistic Regression Logistic Regression Logistic Regression</cell></row><row><cell>43</cell><cell>ta</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>44</cell><cell>te</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>45</cell><cell>th</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>46</cell><cell>tl</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>47</cell><cell>tr</cell><cell>Gaussian NB</cell><cell>Random Forest</cell><cell>K Neighbors</cell><cell>K Neighbors</cell></row><row><cell>48</cell><cell>uk</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row><row><cell>49</cell><cell>ur</cell><cell cols="4">Logistic Regression Logistic Regression Logistic Regression Logistic Regression</cell></row><row><cell>50</cell><cell>vi</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell><cell>SVC</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,241.75,115.83,131.86,94.52"><head>Table 2 .</head><label>2</label><figDesc>Results on Training Dataset</figDesc><table coords="7,265.28,139.98,84.80,70.37"><row><cell>Traits</cell><cell>F-measure</cell></row><row><cell>Gender</cell><cell>0.746</cell></row><row><cell>Fame</cell><cell>0.989</cell></row><row><cell>Occupation</cell><cell>0.995</cell></row><row><cell>Birthyear</cell><cell>0.307</cell></row><row><cell cols="2">cRank = 0.604653</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,115.83,345.82,154.49"><head>Table 3 .</head><label>3</label><figDesc>Results on Test Datasetwith comparable frequency. This limitation of this approach resulted in over-fitting by giving very promising results on training dataset but not on test dataset.</figDesc><table coords="8,265.28,138.15,84.80,70.37"><row><cell>Traits</cell><cell>F-measure</cell></row><row><cell>Gender</cell><cell>0.588</cell></row><row><cell>Fame</cell><cell>0.505</cell></row><row><cell>Occupation</cell><cell>0.427</cell></row><row><cell>Birthyear</cell><cell>0.254</cell></row><row><cell cols="2">cRank = 0.40181</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,456.32,337.98,7.77;8,150.95,467.28,207.84,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,304.16,456.32,176.43,7.77;8,150.95,467.28,79.25,7.77">Twitter author profiling using word embeddings and logistic regression</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Akhtyamova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cardiff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ignatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,248.19,467.28,84.45,7.77">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,478.82,337.98,7.77;8,150.95,489.78,159.92,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,252.88,478.82,211.66,7.77">Author profiling using svms and word embedding averages</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Bayot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gonçalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,489.78,82.96,7.77">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,501.33,337.98,7.77;8,150.95,512.28,329.64,7.77;8,150.95,523.24,329.64,7.77;8,150.95,534.20,329.64,7.77;8,150.95,545.16,329.64,7.77;8,150.95,556.12,283.16,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,435.07,512.28,45.52,7.77;8,150.95,523.24,329.64,7.77;8,150.95,534.20,85.31,7.77">Overview of PAN 2019: Author Profiling, Celebrity Profiling, Cross-domain Authorship Attribution and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavancas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,358.30,545.16,122.29,7.77;8,150.95,556.12,182.80,7.77">Proceedings of the Tenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Heinatz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Tenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">2019. Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,567.66,337.98,7.77;8,150.95,578.27,154.00,8.12" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,190.75,567.66,195.32,7.77">Quantifying evidence in forensic authorship analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,393.32,567.66,87.27,7.77;8,150.95,578.62,106.19,7.77">International Journal of Speech, Language &amp; the Law</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,590.16,337.98,7.77;8,150.95,601.12,329.64,7.77;8,150.95,612.08,242.55,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,437.82,590.16,42.77,7.77;8,150.95,601.12,231.15,7.77">Author profiling with doc2vec neural network-based document embeddings</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Posadas-Durán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,401.10,601.12,79.50,7.77;8,150.95,612.08,130.54,7.77">Mexican International Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="117" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,623.62,337.98,7.77;8,150.95,634.58,180.81,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,376.24,623.62,104.35,7.77;8,150.95,634.58,114.56,7.77">Adapting cross-genre author profiling to language and corpus</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,283.69,634.58,21.92,7.77">CLEF</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,646.13,337.98,7.77;8,150.95,657.08,268.22,7.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,367.09,646.13,113.50,7.77;8,150.95,657.08,204.16,7.77">The winning approach to crossgenre gender identification in russian at rusprofiling 2017</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>FIRE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,119.96,337.98,7.77;9,150.95,130.92,329.64,7.77;9,150.95,141.53,157.15,8.12" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,291.43,119.96,189.16,7.77;9,150.95,130.92,234.55,7.77">Bit-level n-gram based forensic authorship analysis on social media: Identifying individuals from linguistic profiles</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K R</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ashman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,392.18,130.92,88.42,7.77;9,150.95,141.88,83.93,7.77">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="171" to="182" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,152.84,337.98,7.77;9,150.95,163.80,329.64,7.77;9,150.95,174.76,209.02,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,345.61,152.84,134.98,7.77;9,150.95,163.80,12.95,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,278.99,163.80,201.61,7.77;9,150.95,174.76,144.92,7.77">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,185.71,338.35,7.77;9,150.95,196.67,248.04,7.77" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rambocas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
		<title level="m" coord="9,269.74,185.71,184.95,7.77">Marketing research: The role of sentiment analysis</title>
		<imprint>
			<publisher>Faculdade de Economia do Porto</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Universidade do Porto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct coords="9,142.24,207.63,334.76,7.77" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,226.19,207.63,187.39,7.77">Multi-lingual author profiling using stylistic features</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sittar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ameer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>FIRE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,218.59,338.35,7.77;9,150.95,229.55,212.80,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,270.32,218.59,210.27,7.77;9,150.95,229.55,110.07,7.77">Online marketing research utilizing sentiment analysis and tunable demographics analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">A</forename><surname>Pettit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,291.65,229.55,33.99,7.77">uS Patent</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">357</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,240.51,338.35,7.77;9,150.95,251.47,53.03,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,292.12,240.51,65.75,7.77">Celebrity Profiling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,375.41,240.51,93.12,7.77">Proceedings of ACL 2019</title>
		<meeting>ACL 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="9,142.24,262.43,338.35,7.77;9,150.95,273.39,329.64,7.77;9,150.95,284.34,186.98,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,299.16,262.43,181.43,7.77;9,150.95,273.39,16.14,7.77">Overview of the Celebrity Profiling Task at PAN 2019</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,380.04,273.39,100.56,7.77;9,150.95,284.34,18.89,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="9,175.86,284.34,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
