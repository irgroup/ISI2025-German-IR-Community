<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.96,115.90,291.44,12.90;1,189.61,133.83,236.14,12.90;1,223.43,153.68,168.50,10.75">Identification Of Bot Accounts In Twitter Using 2D CNNs On User-generated Contents Notebook for PAN at CLEF 2019</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.03,190.08,67.10,8.64"><forename type="first">Marco</forename><surname>Polignano</surname></persName>
							<email>marco.polignano@uniba.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bari ALDO</orgName>
								<address>
									<addrLine>MORO ; via E. Orabona 4</addrLine>
									<postCode>70125</postCode>
									<settlement>Bari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.91,190.08,100.12,8.64"><forename type="first">Marco</forename><surname>Giuseppe De Pinto</surname></persName>
							<email>marcogiuseppe.depinto@uniba.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bari ALDO</orgName>
								<address>
									<addrLine>MORO ; via E. Orabona 4</addrLine>
									<postCode>70125</postCode>
									<settlement>Bari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.44,190.08,55.69,8.64"><forename type="first">Pasquale</forename><surname>Lops</surname></persName>
							<email>pasquale.lops@uniba.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bari ALDO</orgName>
								<address>
									<addrLine>MORO ; via E. Orabona 4</addrLine>
									<postCode>70125</postCode>
									<settlement>Bari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.98,190.08,77.35,8.64"><forename type="first">Giovanni</forename><surname>Semeraro</surname></persName>
							<email>giovanni.semeraro@uniba.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bari ALDO</orgName>
								<address>
									<addrLine>MORO ; via E. Orabona 4</addrLine>
									<postCode>70125</postCode>
									<settlement>Bari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.96,115.90,291.44,12.90;1,189.61,133.83,236.14,12.90;1,223.43,153.68,168.50,10.75">Identification Of Bot Accounts In Twitter Using 2D CNNs On User-generated Contents Notebook for PAN at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">15115C9933E38CE1017677304AC10357</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The number of accounts that autonomously publish contents on the web is growing fast, and it is very common to encounter them, especially on social networks. They are mostly used to post ads, false information, and scams that a user might run into. Such an account is called bot, an abbreviation of robot (a.k.a. social bots, or sybil accounts). In order to support the end user in deciding where a social network post comes from, bot or a real user, it is essential to automatically identify these accounts accurately and notify the end user in time.</p><p>In this work, we present a model of classification of social network accounts in humans or bots starting from a set of one hundred textual contents that the account has published, in particular on Twitter platform. When an account of a real user has been identified, we performed an additional step of classification to carry out its gender. The model was realized through a combination of convolutional and dense neural networks on textual data represented by word embedding vectors. Our architecture was trained and evaluated on the data made available by the PAN Bots and Gender Profiling challenge at CLEF 2019, which provided annotated data in both English and Spanish. Considered as the evaluation metric the accuracy of the system, we obtained a score of 0.9182 for the classification Bot vs. Humans, 0.7973 for Male vs. Female on the English language. Concerning the Spanish language, similar results were obtained. A score of 0.9156 for the classification Bot vs. Humans, 0.7417 for Male vs. Female, has been earned. We consider these results encouraging, and this allows us to propose our model as a good starting point for future researches about the topic when no other descriptive details about the account are available. In order to support future development and the replicability of results, the source code of the proposed model is available on the following GitHub repository: https://github.com/marcopoli/Identification-of-Twitter-bots-using-CNN</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A bot can be considered as an automatic system capable of creating contents on the web independently, i.e., without a human being involved. They are often used as link aggre-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>gators or as repositories of copyrighted contents such as movies, songs or images. In the past, they have also been used to alter public opinion about famous people through the inclusion of highly targeted comments, especially during political elections <ref type="bibr" coords="2,433.46,143.22,10.58,8.64" target="#b5">[6]</ref>. In other cases, they have been used for manipulating the stock market or to spread fake theories. Each bot is different and it can complete different tasks. Some are more complex and produce contents very similar to those of a human being. Others simply retweet or answer simple questions. Bots that provide a legal and potentially useful service are also present on the web, but before using them, it is always necessary to be aware that you do not have a human being on the other side and that such data could be reused for other purposes. A recent analysis by the Pew Research Center <ref type="foot" coords="2,387.05,225.24,3.49,6.05" target="#foot_0">1</ref> shows that automated systems generate two-thirds of the links shared on Twitter and their usage by real users is continuously growing due to their extreme efficiency and availability. If on the one hand, these systems provide the real user with a service of content sharing, on the other hand they represent a severe risk to the privacy of the user. It is clear that any interaction with them is stored and after a sufficient number of iterations is sufficient to profile the user in order to mislead him with fake advertising, fake websites, phishing, and other malicious activities.</p><p>The identification of bots on social networks is a challenge that, in recent years, has involved many researchers in creating an accurate classification system with real-time response times. A bot detection system can, therefore, help to maintain the stability of the network and ensure the safety of users. State of the art systems have relied on the use of numerous features of the user profile of the accused person such as the number of followers, the number of tweets and retweets, the length of the name, the age and so on. In our solution, we use only a set of one hundred tweets per user without knowing any information about the account from which they come. This situation can make the task of classification much more complex and utterly different from what is already present in the literature. This choice, which could be considered as limiting, presents a broader application scenario. In this way, it is possible to identify bots even in contexts where little information is available about the account, such as in possible situations of privacy, a topic that has become increasingly important in recent years. Our solution, therefore, wants to be able to work correctly with the least amount of information possible, trying to focus on what are the particularities of the writing style of an automatic system and a real user. In this regard, it may, therefore, be interesting to learn more about any differences in the style of writing used by men and women. Consequently, we wanted to deepen the theme, trying to carry out a further step of classification male vs. female in case the system was able to classify the account as human. This task, known in the literature as author profiling, has been a factor of scientific interest for many years, demonstrating how this information can be effectively identified simply by analyzing the content produced on social media.</p><p>The rest of the article is organized as follow: we start with an overview of the state of the art techniques used to address the classification task in Sec. 2. In Sec. 3 we describe and detail the model used in the challenge PAN Bots and Gender Profiling challenge at CLEF 2019 <ref type="bibr" coords="2,196.35,622.79,15.27,8.64" target="#b18">[19]</ref>, while in Section 4, we discuss the experimental analysis carried out on the available training and validation dataset. In Sec. 5, conclusions and future developments close the article inviting to download the available code of the proposed model in order to allow everyone to continue its implementation for future studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The research area concerning authorship attribution to short texts is the one that well encloses the goal of our model: the classification of social media accounts into a bot or a human being using the user-generated textual contents. In this field of research, many classification strategies have been presented in the last years. One of the first systems of the interest of community was the one proposed by Lee <ref type="bibr" coords="3,408.51,248.59,15.27,8.64" target="#b11">[12]</ref>. It was based on the concept of honeypots defined as fake websites used as traps to identify the main characteristics of online spammers. The collected data were used at a later stage of classification through standard machine learning algorithms such as logistic regression and J48 to successfully detect them. Approaches based on the use of lexical features such as characters, words, and n-grams, part of speech (pos) tags, number of punctuations and more, have been proposed for numerous tasks of authorship attribution <ref type="bibr" coords="3,415.19,320.32,16.60,8.64" target="#b22">[23]</ref> as an example for author verification <ref type="bibr" coords="3,238.35,332.28,10.58,8.64" target="#b7">[8]</ref>, plagiarism detection <ref type="bibr" coords="3,337.86,332.28,10.58,8.64" target="#b3">[4]</ref>, author profiling or characterization <ref type="bibr" coords="3,153.16,344.23,10.58,8.64" target="#b6">[7]</ref>. However, approaches based on the manual definition of features engineering, as the previous, are often high time consuming and inaccurate. As a consequence, it has become always more common to identify approaches based on a representation of text in a vectorial space automatically learned from a neural network <ref type="bibr" coords="3,393.47,380.10,15.27,8.64" target="#b13">[14]</ref>.</p><p>In <ref type="bibr" coords="3,160.82,393.42,10.58,8.64" target="#b0">[1]</ref>, the author exposes the concept of word embedding that can be summarized as a "learned distributed feature vector to represent the similarity between words". This concept has been exploited by Mikolov <ref type="bibr" coords="3,296.40,417.33,16.60,8.64" target="#b13">[14]</ref> through word2vec, a tool for implementing work embeddings, but also by for Pennington <ref type="bibr" coords="3,344.01,429.29,16.60,8.64" target="#b15">[16]</ref> that proposed GloVe and by Bojanowski <ref type="bibr" coords="3,184.99,441.24,11.62,8.64" target="#b1">[2]</ref> who implemented its n-gram based vector space named FastText. The benefits of using these vectorial representations are about the property that every vector has in this space. In particular, two words that are semantically related as an example "sport" and "football" results very similarly in that space. This property supports the encoding of a sentence in a new structure able to preserve semantic relations among words. Approaches based on neural networks that use word embeddings as representations of sentences have proved to be very promising and effective for text classification tasks even in domains close to the authorship attribution <ref type="bibr" coords="3,368.84,524.93,15.27,8.64" target="#b9">[10]</ref>. In 2017 Shrestha <ref type="bibr" coords="3,463.99,524.93,16.60,8.64" target="#b21">[22]</ref> presents an authorship attribution model for short texts using convolutional neural networks (CNNs) <ref type="bibr" coords="3,189.85,548.84,18.41,8.64" target="#b10">[11]</ref>. The architecture uses n-grams as input, suitably transformed into semantic embeddings through a vector space of size 300 learned directly from the training data using the word2vec approach. The results described by Shrestha in her work show the good predictive ability of deep neural models, especially when a very large amount of data is available for the training phase. Strategies based on the use of recurrent neural networks (RNNs) <ref type="bibr" coords="3,262.56,608.62,19.26,8.64" target="#b20">[21]</ref> were used also by <ref type="bibr" coords="3,361.08,608.62,58.87,8.64">Kudugunta [9]</ref> for the task of tweet-level bot detection. The authors use GloVe for the encoding of the words constituting the Tweets so that an RNN followed by more dense networks enriched by a context vector could be applied to the data. Account-level Twitter bots account detection is, instead, performed by more classical machine learning strategies such as Logistic Re-gression and Random Forest Classifiers. The excellent results obtained by the authors confirm again the usefulness of deep learning approaches for dealing with the task.</p><p>It is not difficult to find in literature examples of approaches that use neural networks even for the task of identifying the gender of the author of short texts, such as those published on social media. The overview about the multimodal gender identification challenge at PAN 2018 <ref type="bibr" coords="4,248.51,179.35,15.27,8.64" target="#b19">[20]</ref>, well describe how the close totality of the submitted approaches are based on CNNs, RNNs and, more in general, a combination of neural networks. Following the wave of positive results obtained by such approaches based on neural networks, in this work, we combined the contribution of word embeddings with that of CNNs and Dense neural networks. In particular, unlike the works analyzed, we decided to use word embeddings pre-trained on English and Spanish and 2D CNNs able to work on the tensorial representation of content generated by each account. The particularity of our model lies in the idea to work with one single model directly on all the contents generated by the user considering them as a single learning example of our net. Moreover, we were able to use the same network architecture for both the two different classification tasks (bot vs. human, male vs. female) by varying only the training data obtaining by the way good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Model</head><p>The model of classification of Twitter accounts in bot or human and later in male or female proposed in this work is based on a neural architecture that through convolutional layers and dense layers is able to capture distant relationships among words. In particular it focus not only on word relations in the same short text but also it is able to detect relations among word in different pieces of text. The key idea behind the proposed approach is that in order to exploit the stylistic information contained in a set of contents produced by a user, it is necessary to work on them at the same time. It is immediately clear that you can imagine the account of a user u ∈ U as a set of contents C = c u1 , c u2 , c u3 , ..., c un aggregated in the form of a matrix. It is possible to place each sentence as a row of the matrix and to tokenize them into words for creating the grid structure. This allows us to draw a structured representation of the profile of the user and to work on them with approaches, as CNNs, that are more commonly used for data in a grid-like topology (i.e. images).</p><p>Fig. <ref type="figure" coords="4,167.78,524.93,4.98,8.64" target="#fig_0">1</ref> describes very generally the architecture of the model designed for facing the bot identification task at user-level. In order to feed the network, we started with the encoding of each user-generated content in a list of word embedding vectors. Starting from a word embedding matrix S ∈ IR e×|V | , where e is the size of the word embedding vectors and |V | the cardinality of the dictionary pre-trained, we encoded each of the first 50 words w jk that composed the j-th user tweet t uj ∈ T u as word embedding vector. Tweets with a number of words higher than 50 have been truncated. Words not found in the vector space are transformed into word embeddings through a random vector selected from the entire dictionary, as proposed by Zhang <ref type="bibr" coords="4,364.04,620.57,15.27,8.64" target="#b23">[24]</ref>. We obtained a matrix of encoded user tweets E u ∈ IR m×50×e where m is the number of tweets considered for the user, 50 is the fixed number of word of each tweet we decided to consider during the encoding, e is the size of the word embedding vectors. We used E u as input of our  The first three layers of our net are composed by 2D convolutional networks mediated by three max-pooling 2 x 2 operations. These max-pooling operations have the purpose of allowing the network to focus on low-level feature blocks and to map them in a higher-level feature space, more descriptive than the previous, through the convolutional operations. In this way, CNNs allow us to efficiently detect local relations shared among words closed in positions in user's tweets.</p><p>The details about the number of parameters for each layer and its shape are reported in Fig. <ref type="figure" coords="6,192.72,131.27,3.74,8.64" target="#fig_1">2</ref>. The figure allows us to observe the configuration of parameters used in particular for the first three CNNs and max-pooling operations. Starting from a word embedding matrix of size 100 x 50 x 300, we performed the first 2D CNN with a 5 x 5 kernel using a ReLu activation function <ref type="bibr" coords="6,303.93,167.13,15.27,8.64" target="#b14">[15]</ref>. The rectified linear unit (ReLu) can be formalized as g(z) = max{0, z} and it allows to obtain a large value in case of activation by applying this function as a good choice to represent hidden units. As commonly performed, after a CNN able to perform convolutional operations on data, we applied a max-pooling operation of size 2 x 2 transforming each squared portion of our previous output as their max value. Pooling can, in this case, help the model to focus only on principal characteristics of every portion of data making them invariant by their position. We have run the process described twice more by simply changing the kernel size to 5 x 4 and finally to 3 x 3. Following we have flatten the output to make it compatible with the next layers.</p><p>We applied three Dense layers (fully connected layers) with a tanh activation function, varying the output size from 800 elements to 400, 200, and finally 100. This step allows the network to put in relations all the intermediate results obtained by the previous layers on the different sections of the input, discovering hidden correlations that can contribute to the prediction. The tanh function defined as g(z) = 2σ(2z) -1 has an S-Shape and produces values among -1 and 1 making layer output more center to the 0. Moreover, it produces a gradient larger than sigmoid function helping to speed up the convergence <ref type="bibr" coords="6,213.48,370.97,10.58,8.64" target="#b4">[5]</ref>. Finally, another dense layer with a soft-max activation function has been applied for estimating the probability distribution of each of the classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model Evaluation</head><p>The evaluation of the proposed model has been carried out in order to be able to answer two different research questions. First, we want to investigate whether the model produces results of accuracy that are good enough to identify Twitter bot accounts and to detect the gender of the user in case of human being. Secondly, we want to understand if the choice of word embedding vector space influences the final performance of the model. Such a result may produce interesting considerations to be used in future work on the subject by providing a detailed starting point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets, Baselines and Metrics</head><p>The dataset used for the training and validation phase of the model is the one provided by the PAN Bots and Gender Profiling challenge at CLEF 2019 <ref type="bibr" coords="6,415.57,584.11,15.27,8.64" target="#b18">[19]</ref>. It has been provided in two languages English and Spanish and it is composed by tweets labeled with a bot or to a male/female human class. The detailed statistics about the dataset are available in Tab. 1 . The test dataset has been not released yet.</p><p>We used as validation metric the Accuracy, the same used in the PAN challenge. In particular, for each language, individual accuracies are calculated. Firstly, we calculated the accuracy of identifying bots vs. human. Then, in case of humans, we calculated the accuracy of identifying males vs. females. Finally, the average of the accuracy values per language are used for obtain the final score.</p><p>The baseline considered for our task is the majority vote classifier that, as consequence of the homogeneous classes distribution in the dataset has an accuracy score equal to 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tweets Preprocessing and Data Enrichment</head><p>The tweets available in the dataset were supplied without any cleaning or pre-processing. In this regard, it was decided to keep as much information as possible within the model. Each sentence is divided into tokens through the TweetTokenizer class of the NLTK library. After that, we used Ekphrasis preprocessor library to annotate mentions, URL, email, numbers, dates, amount of money, and make word spelling correction and hashtag unpacking if necessary. As an example "14/01/2018" is translated into the word "date" and the hashtag "#lovefootball" is translated into "love football". This process allows to correctly apply the translation of words in word embedding without excluding the previously mentioned elements.</p><p>In order to obtain a more general and accurate model, we have decided to enrich the reference dataset with further data regarding the contents produced by men or women. We followed the strategy used in the GitHub project Gender-Classificationusing-Twitter-Feeds<ref type="foot" coords="7,218.35,470.15,3.49,6.05" target="#foot_1">2</ref> based on the work of Liu <ref type="bibr" coords="7,336.18,471.82,15.27,8.64" target="#b12">[13]</ref>. For the English language, we developed a module able to collect tweets localized in the USA through official Twitter API. Messages collected between the 15/03/2019 to the 30/04/2019 have been filtered on the base of the official first name written in the account description. In particular, if the name was one of them reported by the USA census<ref type="foot" coords="7,369.09,517.97,3.49,6.05" target="#foot_2">3</ref> as used for a male subject we labeled it as a consequence. Similarly, we labeled female tweets <ref type="foot" coords="7,402.65,529.92,3.49,6.05" target="#foot_3">4</ref> . As far as Spanish is concerned, the strategy was symmetrical. First of all, we collected the geolocalized tweets in Spain, then we filtered and categorized them following a list of male and female names available on the web <ref type="foot" coords="7,274.03,565.79,3.49,6.05" target="#foot_4">5</ref> .</p><p>The previously filtered tweets were then aggregated into groups of 100, randomly selecting them from the corresponding reference class. We obtained 1000 additional examples of annotated accounts for each of the classes and for each of the two languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Word Embedding Pre-trained Vectors</head><p>Word embeddings could be trained directly on "training data" of the domain of application, but this strategy can lack generalization. When a new sentence to classify is provided as input many words in it could be not possible to be translated making impossible the correct classification. For this reason, we decided to use a common practice of transfer learning in NLP tasks i.e. the use of vector spaces word embeddings already pre-calculated on different domains. This allows us to cover an extensive variety of terms by reducing the computational cost of the model and including information about terms that are independent of their domain of use. We decided to compare the results of the model obtained varying three different pre-trained word embeddings:</p><p>-Google word embeddings (GoogleEmb) <ref type="foot" coords="8,320.54,249.09,3.49,6.05" target="#foot_5">6</ref> : 300 dimensionality word2vec vectors, case sensitive, composed by a vocabulary of 3 million words and phrases that are obtained from roughly 100 billion of tokens extracted by a huge dataset of Google News; -GloVe (GloVeEmb)<ref type="foot" coords="8,234.46,296.31,3.49,6.05" target="#foot_6">7</ref> : 300 dimensionality vectors, composed by a vocabulary of 2.2 million words case sensitive obtained from 840 billion of tokens and trained on data crawled from generic Internet web pages; -FastText (FastTextEmb)<ref type="foot" coords="8,254.02,331.57,3.49,6.05" target="#foot_7">8</ref> : 300 dimensionality vectors, composed by a vocabulary of 2 million words and n-grams of the words, case sensitive and obtained from 600 billion of tokens trained on data crawled from generic Internet web pages by Common Crawl nonprofit organization;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Runs And Results</head><p>The model has been trained using the categorical cross entropy loss function <ref type="bibr" coords="8,451.30,414.09,11.62,8.64" target="#b4">[5]</ref> and Adam optimizer for 20 epochs and best models have been used for the classification phase. The number of batches is set as 64 for optimization reason.</p><p>In order to evaluate the influence that the different pre-trained word embeddings have on the final performances of the model, we have performed the training phase keeping constant all the parameters except the word embedding matrix used to encode the user's tweets. The portion of the dataset used for the evaluation is equal to 20% of the training set using 42 as a random seed. As a consequence of the not availability of GoogleEmb and GloVe pre-trained vectors for the Spanish language, we evaluate the model performances only on English data.</p><p>The results in Tab. 2 showed quite better performances obtained by FastText word embedding vector space. The differences among results are not statistically significant but this allow us to decide to use FastText in our final model. Moreover, its availability in both the languages of the interest of the PAN Bots and Gender Profiling challenge at CLEF 2019 <ref type="bibr" coords="8,184.03,581.46,16.60,8.64" target="#b18">[19]</ref> (English and Spanish) has emphasized and confirmed our choice.</p><p>The final model trained four times (Eng -Bot vs. Human, Eng -Male vs. Female, Esp -Bot vs. Human, Esp -Male vs. Female) has been deployed on Tira.io<ref type="foot" coords="8,456.15,603.70,3.49,6.05" target="#foot_8">9</ref>  <ref type="bibr" coords="8,463.99,605.37,16.60,8.64" target="#b16">[17]</ref>  for participating to the PAN 2019 Bots and Gender Profiling challenge. The first run on a preliminary released test set showed an accuracy score of 0.9470 and 0.8181 respectively for the Bot vs. Human and Male vs. Female tasks in English language. In Spanish language we obtained 0.9611 and 0.7778 respectively for the Bot vs. Human and Male vs. Female tasks. Finally we run the model also on the final test set earning an accuracy score of 0.9182 and 0.7973 respectively for the Bot vs. Human and Male vs. Female tasks in English language. In Spanish language we obtained 0.9156 and 0.7417 respectively for the Bot vs. Human and Male vs. Female tasks.</p><p>A comparison with the baselines proposed by the challenge authors after the end of the competition <ref type="bibr" coords="9,213.22,450.62,16.60,8.64" target="#b18">[19]</ref> is showed in Fig. <ref type="figure" coords="9,307.49,450.62,3.74,8.64">3</ref>. In particular, it is interesting to observe that our model is better than all the proposed baselines for the Spanish language. For English, a simple strategy based on n-grams and Random Forest can overcome our results. Probably this anomaly has been obtained as a consequence of the ability of ngrams to capture words misspelled or unknown in a standard vocabulary like the one used in FastText embedding space. In any case, it is performed more better than the LDSE baseline <ref type="bibr" coords="9,197.23,522.35,15.27,8.64" target="#b17">[18]</ref>. A possible future work can try to overcome these limits using one of the newest language models, as BERT <ref type="bibr" coords="9,300.49,534.31,10.58,8.64" target="#b2">[3]</ref>, as a base for our proposed network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we presented an architecture based on deep neural networks for the classification of Twitter accounts in a bot or human, carrying out, where possible, a further refinement in man or woman. The model is based on the representation of the user account as a list of 100 tweets appropriately transformed into tensorial form through the encoding of words in the equivalent word embedding FastText form. Unlike state of the art, no additional information about the Twitter account has been used allowing our approach to be used even when this information is not available. On these representations of input data, we learned a deep neural network that uses 2D CNNs, max-pooling operations, and Dense Layers to estimate the probability of distribution of annotation classes correctly. The approach was tested on the data provided by the PAN Bots and Gender Profiling challenge at CLEF 2019, which provided appropriately annotated data in both English and Spanish. As a preliminary step, the model was validated by varying the pre-trained word embedding space used in the training phase. The embeddings provided by Google and trained on News, GloVe trained on Tweets and FastText trained on web pages collected on the web were tested. The final choice fell on FastText following the good results obtained and its effectiveness in the tasks of classification of the text demonstrated in the literature. The final model learned was submitted to the competition and obtained a of accuracy equal to: 0.9182 and 0.797 respectively for the Bot vs. Human and Male vs. Female tasks in English language, 0.9156 and 0.7417 for Spanish data.</p><p>The good results obtained suggest that such approaches based on deep neural networks are an excellent basis for solving the task. In particular, they are general enough to work in a real application context correctly. Since the result obtained can only be considered a starting point for further extensions, modifications, and improvements of the proposed approach, we have decided to make the product code available to the whole reference community with the hope that it will be useful for future work in the field. The code that implements the presented model can be found at the following GitHub repository: https://github.com/marcopoli/Identification-of-Twitter-bots-using-CNN</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>This work is partially funded by project "Electronic Shopping &amp; Home delivery of Edible goods with Low environmental Footprint" (ESHELF), under the Apulian IN-NONETWORK programme, Italy. Moreover, it is partially funded by project "DECi-SION" codice raggruppamento: BQS5153, under the Apulian INNONETWORK programme, Italy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,135.61,277.71,344.14,8.12;5,134.77,115.84,345.83,147.14"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of the Proposed Classification Model based on 2D CNNs and Dense Layers</figDesc><graphic coords="5,134.77,115.84,345.83,147.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,173.79,529.74,267.78,8.12;5,186.64,306.52,242.07,208.48"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Detailed description of the architecture of the proposed classifier</figDesc><graphic coords="5,186.64,306.52,242.07,208.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,202.03,115.83,211.29,85.08"><head>Table 1 .</head><label>1</label><figDesc>PAN 2019 -Bot and Gender Profiling task dataset</figDesc><table coords="7,207.13,136.42,198.85,64.49"><row><cell></cell><cell cols="2">English</cell><cell cols="2">Spanish</cell></row><row><cell></cell><cell cols="4">#Accounts #Tweets #Accounts #Tweets</cell></row><row><cell>Bot</cell><cell>2060</cell><cell>206000</cell><cell>1500</cell><cell>150000</cell></row><row><cell>Human</cell><cell>2060</cell><cell>206000</cell><cell>1500</cell><cell>150000</cell></row><row><cell>Male</cell><cell>1030</cell><cell>103000</cell><cell>750</cell><cell>75000</cell></row><row><cell>Female</cell><cell>1030</cell><cell>103000</cell><cell>750</cell><cell>75000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,147.10,115.83,321.16,85.02"><head>Table 2 .</head><label>2</label><figDesc>Results of the model on the validation set varying the word embedding encoding</figDesc><table coords="9,225.32,136.75,162.48,64.10"><row><cell></cell><cell>English</cell><cell></cell></row><row><cell></cell><cell cols="2">Bot vs. Human Male vs. Female</cell></row><row><cell>Baseline</cell><cell>0.5000</cell><cell>0.5000</cell></row><row><cell>GoogleEmb</cell><cell>0.9547</cell><cell>0.8173</cell></row><row><cell>GloVe</cell><cell>0.9611</cell><cell>0.8264</cell></row><row><cell>FastText</cell><cell>0.9733</cell><cell>0.8479</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,162.93,215.92,287.26,97.24"><head>Table 3 .</head><label>3</label><figDesc>Results obtained on the test set considering organizers baselines</figDesc><table coords="9,162.93,237.24,287.26,75.92"><row><cell></cell><cell>English</cell><cell></cell><cell>Spanish</cell><cell></cell></row><row><cell></cell><cell cols="4">Bot vs. Human Male vs. Female Bot vs. Human Male vs. Female</cell></row><row><cell>Our Model</cell><cell>0.9182</cell><cell>0.7973</cell><cell>0.9156</cell><cell>0.7417</cell></row><row><cell>char nGrams</cell><cell>0.9360</cell><cell>0.7920</cell><cell>0.8972</cell><cell>0.7289</cell></row><row><cell>word nGrams</cell><cell>0.9356</cell><cell>0.7989</cell><cell>0.8833</cell><cell>0.7244</cell></row><row><cell>W2V</cell><cell>0.9030</cell><cell>0.7879</cell><cell>0.8444</cell><cell>0.7156</cell></row><row><cell>LDSE</cell><cell>0.9054</cell><cell>0.7800</cell><cell>0.8372</cell><cell>0.6900</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.08,239.12,7.77"><p>https://www.pewinternet.org/2018/04/09/bots-in-the-twittersphere/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="7,144.73,623.64,253.85,7.77"><p>https://github.com/vjonnala/Gender-Classification-using-Twitter-Feeds</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,144.73,634.79,255.90,7.77"><p>http://www2.census.gov/topics/genealogy/1990surnames/dist.male.first</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,144.73,645.94,262.87,7.77"><p>http://www2.census.gov/topics/genealogy/1990surnames/dist.female.first</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="7,144.73,657.08,203.39,7.77"><p>http://www.20000-names.com/male_spanish_names.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="8,144.73,623.80,80.46,7.77"><p>https://goo.gl/zQFRx3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="8,144.73,634.79,138.71,7.77"><p>https://nlp.stanford.edu/projects/glove/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="8,144.73,645.94,167.01,7.77"><p>https://fasttext.cc/docs/en/english-vectors.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="8,144.73,657.08,67.17,7.77"><p>https://www.tira.io</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.61,535.40,328.91,7.77;10,150.95,546.36,229.58,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,331.81,535.40,135.60,7.77">A neural probabilistic language model</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,150.95,546.36,132.46,7.77">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003-02">Feb. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,557.60,325.55,7.77;10,150.95,568.56,203.79,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,333.00,557.60,135.16,7.77;10,150.95,568.56,40.87,7.77">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,197.78,568.56,88.23,7.77">Transactions of the ACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,579.80,325.47,7.77;10,150.95,590.76,294.64,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,328.63,579.80,139.45,7.77;10,150.95,590.76,144.12,7.77">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.61,602.01,337.98,7.77;10,150.95,612.96,328.22,7.77;10,150.95,623.92,314.51,7.77;10,150.95,634.88,168.21,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,286.55,602.01,178.46,7.77">Plagiarism detection without reference collections</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Eissen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kulig</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-70981-7_40</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-70981-7_40" />
	</analytic>
	<monogr>
		<title level="m" coord="10,150.95,612.96,328.22,7.77;10,150.95,623.92,77.57,7.77">Proceedings of the 30th Annual Conference of the Gesellschaft für Klassifikation e.V</title>
		<meeting>the 30th Annual Conference of the Gesellschaft für Klassifikation e.V</meeting>
		<imprint>
			<date type="published" when="2006">March 8-10, 2006. 2006</date>
			<biblScope unit="page" from="359" to="366" />
		</imprint>
		<respStmt>
			<orgName>Freie Universität Berlin</orgName>
		</respStmt>
	</monogr>
	<note>Advances in Data Analysis</note>
</biblStruct>

<biblStruct coords="10,142.61,646.13,318.08,7.77;10,150.95,657.08,65.99,7.77" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m" coord="10,343.83,646.13,49.27,7.77">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,119.96,330.63,7.77;11,150.95,130.92,326.59,7.77;11,150.95,141.88,291.64,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,283.45,119.96,189.79,7.77;11,150.95,130.92,326.59,7.77;11,150.95,141.88,50.45,7.77">Algorithms, bots, and political communication in the us 2016 election: The challenge of automated political communication for election law and administration</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Calo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,207.25,141.88,160.64,7.77">Journal of information technology &amp; politics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,152.33,315.64,7.77;11,150.95,163.28,257.51,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,302.62,152.33,155.63,7.77;11,150.95,163.28,47.56,7.77">Automatically categorizing written texts by author gender</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Shimoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,204.49,163.28,120.29,7.77">Literary and linguistic computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="412" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,173.73,36.67,7.77;11,196.22,173.73,267.96,7.77;11,150.95,184.69,323.87,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,233.71,173.73,214.25,7.77">Authorship verification as a one-class classification problem</title>
		<author>
			<persName coords=""><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,184.69,249.48,7.77">Proc. of the twenty-first international conference on Machine learning</title>
		<meeting>of the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">62</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,195.14,328.10,7.77;11,150.95,206.10,75.46,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,249.68,195.14,138.83,7.77">Deep neural networks for bot detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kudugunta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,394.26,195.14,76.45,7.77">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="312" to="322" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,216.54,296.02,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,277.15,216.54,49.27,7.77">Deep learning</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,332.18,216.54,22.41,7.77">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,226.99,300.94,7.77;11,150.95,237.95,113.69,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,214.05,226.99,160.11,7.77">Generalization and network design strategies</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,379.66,226.99,63.52,7.77;11,150.95,237.95,40.47,7.77">Connectionism in perspective</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="143" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,248.40,329.34,7.77;11,150.95,259.36,329.64,7.77;11,150.95,270.32,231.44,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,265.46,248.40,206.12,7.77;11,150.95,259.36,28.11,7.77">Uncovering social spammers: social honeypots+ machine learning</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,196.95,259.36,283.64,7.77;11,150.95,270.32,130.50,7.77">Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 33rd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,280.76,332.86,7.77;11,150.95,291.72,203.73,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,221.11,280.76,253.98,7.77;11,150.95,291.72,22.01,7.77">What&apos;s in a name? using first names as features for gender inference in twitter</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ruths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,190.56,291.72,137.98,7.77">2013 AAAI Spring Symposium Series</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,302.17,334.74,7.77;11,150.95,313.13,292.21,7.77;11,150.95,324.09,153.41,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,370.57,302.17,106.40,7.77;11,150.95,313.13,160.55,7.77">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,329.59,313.13,113.58,7.77;11,150.95,324.09,67.40,7.77">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="3111" to="3119" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,334.53,324.20,7.77;11,150.95,345.49,307.78,7.77;11,150.95,356.45,57.53,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,233.61,334.53,216.62,7.77">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,345.49,290.07,7.77">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,366.90,335.35,7.77;11,150.95,377.86,319.98,7.77;11,150.95,388.82,120.79,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,298.04,366.90,163.80,7.77">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,377.86,319.98,7.77;11,150.95,388.82,33.78,7.77">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,399.26,335.40,7.77;11,150.95,410.22,309.15,7.77;11,150.95,421.18,209.02,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,333.86,399.26,140.16,7.77">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,259.53,410.22,200.58,7.77;11,150.95,421.18,144.92,7.77">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,431.63,308.54,7.77;11,150.95,442.59,324.24,7.77;11,150.95,453.55,221.42,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,307.56,431.63,143.22,7.77;11,150.95,442.59,107.79,7.77">A low dimensionality representation for language variety identification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franco-Salvador</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,276.49,442.59,198.70,7.77;11,150.95,453.55,109.32,7.77">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="156" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,464.00,338.35,7.77;11,150.95,474.95,320.27,7.77;11,150.95,485.91,304.34,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,228.63,464.00,251.96,7.77;11,150.95,474.95,29.82,7.77">Overview of the 7th author profiling task at pan 2019: Bots and gender profiling</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,394.27,474.95,76.96,7.77;11,150.95,485.91,38.13,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="11,195.56,485.91,198.98,7.77">Notebook Papers. CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mãijller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,496.36,323.95,7.77;11,150.95,507.32,309.12,7.77;11,150.95,518.28,120.15,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,394.58,496.36,71.61,7.77;11,150.95,507.32,272.57,7.77">Overview of the 6th author profiling task at pan 2018: multimodal gender identification in twitter</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,428.91,507.32,31.16,7.77;11,150.95,518.28,94.00,7.77">Working Notes Papers of the CLEF</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,528.73,327.37,7.77;11,150.95,539.68,309.90,7.77;11,150.95,550.64,23.90,7.77" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="11,320.21,528.73,149.40,7.77;11,150.95,539.68,41.28,7.77">Learning internal representations by error propagation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>California Univ San Diego La Jolla Inst for Cognitive Science</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct coords="11,142.24,561.09,318.38,7.77;11,150.95,572.05,300.19,7.77;11,150.95,583.01,311.79,7.77;11,150.95,593.97,159.84,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,409.85,561.09,50.78,7.77;11,150.95,572.05,197.65,7.77">Convolutional neural networks for authorship attribution of short texts</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,366.22,572.05,84.92,7.77;11,150.95,583.01,308.26,7.77">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="669" to="674" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="11,142.24,604.41,302.64,7.77;11,150.95,615.37,295.21,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,207.24,604.41,182.01,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,395.57,604.41,49.31,7.77;11,150.95,615.37,211.53,7.77">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,625.82,283.16,7.77;11,150.95,636.78,319.62,7.77;11,150.95,647.74,92.89,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,281.96,625.82,143.44,7.77;11,150.95,636.78,153.55,7.77">Detecting hate speech on twitter using a convolution-gru based deep neural network</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,322.89,636.78,130.28,7.77">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="745" to="760" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
