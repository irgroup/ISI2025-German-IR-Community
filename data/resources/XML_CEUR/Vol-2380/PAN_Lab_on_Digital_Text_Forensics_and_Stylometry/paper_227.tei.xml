<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.59,115.90,332.19,12.90;1,281.06,133.83,53.24,12.90;1,223.43,153.95,168.50,10.75">Identifying Twitter Bots Using a Convolutional Neural Network Notebook for PAN at CLEF 2019</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.65,190.61,61.14,8.64"><forename type="first">Michael</forename><surname>Färber</surname></persName>
							<email>michael.faerber@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,272.75,190.61,57.27,8.64"><surname>Agon Qurdina</surname></persName>
							<email>agon.qurdina@studentet.uni-pr.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Prishtina</orgName>
								<address>
									<country>Kosovo</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.87,190.61,52.85,8.64"><forename type="first">Lule</forename><surname>Ahmedi</surname></persName>
							<email>lule.ahmedi@uni-pr.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Prishtina</orgName>
								<address>
									<country>Kosovo</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.59,115.90,332.19,12.90;1,281.06,133.83,53.24,12.90;1,223.43,153.95,168.50,10.75">Identifying Twitter Bots Using a Convolutional Neural Network Notebook for PAN at CLEF 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">858DADA1D59EF982EF07F1BC4F13FE7D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present an approach for identifying Twitter bots based on their written tweets using a convolutional neural network. We experiment with various embedding methods (pretrained and trained on the training dataset) and convolutional neural network architectures and compare their performance. When evaluating our best performing approach on the actual test data set of the CLEF 2019 Bots Profiling Subtask (English language), we obtain an accuracy of 90.34%. We therefore see convolutional neural networks as a promising machine learning technique for Twitter bot detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With over 1 billion active users, Twitter is among the most frequently used social media platforms. It has taken an important role as a medium disseminating information and opinions. However, due to its potential to influence the reader's opinion, bot nets are considered to be a threat to society and democracy. For instance, it has been reported that botnets have been identified in the context of public voting, such as the Brexit voting <ref type="bibr" coords="1,162.78,494.85,11.62,8.64" target="#b8">[9]</ref> and the federal elections of the United States in 2016 <ref type="bibr" coords="1,393.29,494.85,10.58,8.64" target="#b5">[6]</ref>. Botnets have also been used for making the ideologies of terrorism attractive <ref type="bibr" coords="1,367.58,506.81,10.58,8.64" target="#b4">[5]</ref>. It is estimated that about 15% of all active accounts on Twitter (i.e., 48 million) are bot accounts <ref type="bibr" coords="1,413.45,518.76,15.27,8.64" target="#b13">[14]</ref>. Developing approaches to detect Twitter bots automatically is therefore important.</p><p>In this paper, we consider the following task proposed as a shared task at CLEF 2019: "Given a Twitter feed, determine whether its author is a bot or a human." <ref type="bibr" coords="1,456.52,554.89,12.03,8.64" target="#b3">[4,</ref><ref type="bibr" coords="1,468.55,554.89,12.03,8.64" target="#b12">13]</ref> In the past, several approaches to Twitter bot identification have been proposed (see Section 2). However, most of them do not use the content of the tweets, but instead the metadata of the tweets and their implications (such as the publication frequency over time). We present an approach based on convolutional neural networks where all tweets of a user are used as input. This paper is structured as follows. In Section 2, we present related works on bot identification. In Section 3, we describe our approach for Twitter bot identification. In Section 4, we present the evaluation setup, the evaluation data set, and the evaluation results. We conclude in Section 5 with a summary and an outlook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Given that millions of user accounts on social media platforms are bots, classifying user accounts in social media has already been approached in various regards. In 2016, Adewole et al. <ref type="bibr" coords="2,177.76,237.41,11.62,8.64" target="#b0">[1]</ref> listed 65 articles about malicious account detection approaches for social networks, including social tagging and other social network variations. We differentiate between approaches that are non-content based and content-based.</p><p>Non-content based approaches to bot identification. Non-content-based approaches use patterns in the behaviour of the Twitter accounts. Chavosi et al. <ref type="bibr" coords="2,394.78,298.45,10.58,8.64" target="#b2">[3]</ref>, for instance, perform correlation analysis, exploiting the fact that highly synchronous cross-user activities indicate whether an account is a bot or not. In <ref type="bibr" coords="2,345.20,322.36,10.58,8.64" target="#b1">[2]</ref>, Beskow and Carley state that measured differences between bot and human conversation networks can be used to increase the accuracy in bot detection. Mazza et al. <ref type="bibr" coords="2,331.78,346.27,15.27,8.64" target="#b11">[12]</ref>, one of the most recent works on bot detection, use patterns of the retweeting activity, with the specific goal of detecting malicious retweeting bots. Recently, Lundberg et al. <ref type="bibr" coords="2,346.70,370.18,16.60,8.64" target="#b10">[11]</ref> use only tweets' metadata in order to provide a language-independent approach to bot detection.</p><p>Content-based approaches to bot identification. Content-based approaches target the classification of Twitter accounts based on the account's tweets. In <ref type="bibr" coords="2,412.86,419.26,15.27,8.64" target="#b9">[10]</ref>, the authors use content-based features and pattern contrast features for bot detection. They obtain classification results over 0.90 of AUC with this approach.</p><p>Hybrid approaches to bot identification. In their paper <ref type="bibr" coords="2,367.51,468.35,10.58,8.64" target="#b7">[8]</ref>, Kudugunta and Ferrara propose a hybrid approach that exploits both tweet content and metadata (e.g., retweet and reply count, or number of hashtags) to detect whether a given tweet was posted by a human or a bot. The framework uses a deep neural network based on a contextual long short-term memory (LSTM) architecture and exhibits promising performance of over 0.96 of AUC to bot detection at the tweet-level.</p><p>Note that in this paper, we obtain an AUC score of 0.86 based solely on the content of the tweets. To the best of our knowledge, we are the first ones approaching such a task using a convolutional neural network model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>In this section, we present our approach for twitter bot identification. The source code of our implementation is available online at https://github.com/agon-qurdina/ author-profiling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>Normally, the input for our model would be the set of tweets for a given user. But we decided to have the entire user's feed of tweets as a single input to the model. Thus, we merged all of the author's tweets together into a single block of text which we called "article." Next, given a set of "articles" as input, we preprocessed them along the following steps:</p><p>Text Cleaning. New lines were replaced by spaces. We also expanded contractions and removed stop words, HTML tags, and special characters from the articles' content.</p><p>Texts to Sequences. The articles' content was tokenized and a word dictionary (size: 155,227 unique words) was generated.</p><p>Sequence Padding. We applied a post-padding with a fixed sequence length l. Due to the way we concatenated the tweets to a single "article," we were left with a limited number of training samples. Thus, in order to keep as much information as possible, we set l = 11000. By choosing this high value for the sequence length, only a small percentage (284 from 2873) of the sequences were truncated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic Model Architecture</head><p>Our basic architecture is shown in the Figure <ref type="figure" coords="3,326.31,584.71,3.74,8.64" target="#fig_0">1</ref>. We use a CNN architecture that is based on Kim et al.'s approach for sentence classification <ref type="bibr" coords="3,371.56,596.66,10.58,8.64" target="#b6">[7]</ref>. His proposed architecture has been widely applied for various tasks in the past. The CNN consists of two one-dimensional convolutional neural networks layers, followed by MaxPooling layers, with a dense neural networks layer processing the output of the second CNN layer. The model is completed by a final output layer that uses the sigmoid activation function to return a binary output (namely, the classification into human or bot).</p><p>In the following, we describe the architecture in more detail: Input layer. Considering the article's words were embedded into d-dimensional vectors, the final matrix used as input to the model can be written as I = l × d where l is the chosen sequence length (i.e., the length of the articles). Recall that l = 11000 in our setting.</p><p>First convolutional layer. The first transformation this embedded input goes through is a convolutional layer with f 1-dimensional filters of length k. Thus, the layer weights can be considered a matrix of shape W c ∈ R f ×k .</p><p>We used a filter size f of 64 and a filter length k of 4. In our context, having 1dimensional filters means that for each word in an article, its three adjacent words are considered as the context of the word. The output of the convolutional layer then is C = conv(I, W c) where conv is the convolutional operation applied to input I using the weights matrix W c. This operation includes applying the ReLu activation function to complete weights calculations. Also, a dropout function is used to prevent overfitting. We used a dropout rate of 0.5, which means 50% of the weights (randomly chosen) during each training epoch are set to 0.</p><p>First max pooling layer. The above output C is then considered the input to a 1dimensional Max Pooling layer. The purpose of the layer is to extract only the most important features of the convolution outputs. This is done by keeping only the max value from a pool size p. As we chose p = 4, the output of this layer can be written as M = max pool(C, p). This operation reduces the number of weights by four times.</p><p>Second convolutional layer and max pooling layer. The output M of the max pooling layer is the input of the second convolutional layer, and the whole process described above is applied to this input, to get a final output M 2 .</p><p>Fully connected layer. Given the two-dimensional matrix of weights from the last step, the next layer in the network is a fully connected one with a size of 256 hidden neurons. But in order for the convolutional output to serve as an input to this layer, its dimensionality needs to be reduced. This was done using the flatten method, which keeps all of the values but flatten them in a long vector. A ReLU activation function and a dropout layer with a rate of 0.5 were used here.</p><p>Output layer. The last layer is a fully connected layer with one neuron. The sigmoid activation function is used to provide a binary output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Architecture Variations</head><p>We developed and evaluated the following architecture variations:</p><p>1. The first variation uses 1-dimensional MaxPooling layers of size 2 after each of the Convolutional layers. That means the resulting number of features, after passing from the convolutional layer to the MaxPooling layer and then out of it, will be halved. Considering we start with a sequence length of 11,000, the fully-connected layer contains more than 11 million weights to train. We will call this variation Large Model in the remaining part of this paper. 2. The second variation uses 1-dimensional MaxPooling layers of size 4 after each of the Convolutional layers, which reduces the number of features generated by the Convolutional layers by a factor of 4. It does that by only keeping the max value </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set</head><p>The actual CLEF 2019 Bots and Gender Profiling Task test data set is hidden and only used for official system submissions. Thus, we used the training and validation data set of the CLEF 2019 Bots and Gender Profiling Task data set for training and testing our models before the CLEF submissions. In Table <ref type="table" coords="5,321.77,518.89,3.74,8.64" target="#tab_0">1</ref>, we outline noteworthy statistics about the used data set. Note that the data set provided by CLEF is balanced, i.e., the number of bot profiles and human profiles is the same. For the official system submissions, the performance of any system is evaluated based on the accuracy. We therefore also use this evaluation metric for our own experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Settings</head><p>We developed our models using Keras v2.1.2 with a Tensorflow v1.0.0 backend. Training the model was performed on a machine with 64GB memory and a GeForce GTX 1080 Ti GPU. We implemented and evaluated our basic model using a word-based embedding method, where an embedding vector is generated for each unique word in the text corpus. The embedding formed the first layer of our model and was trained alongside the model itself. The texts are truncated to a length of 11,000 characters and we use a 300dimensional embedding. Thus, this layer on its own adds a further 46 million parameters to be trained in the model's training process. By training the embedding as part of the model it allows the generated sequences of word indices to be the input to our model. The first layer of the network will be responsible for generating the word vectors for each of the words from the inputs.</p><p>We fine-tuned the hyperparameters of our basic model using the dedicated validation data set. In the end, we used the parameters as shown in Table <ref type="table" coords="6,409.31,388.56,3.74,8.64" target="#tab_1">2</ref>. Note that these optimal hyperparameters performed best on both the architecture variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Results</head><p>Evaluating Embeddings on the Basic Architecture Table <ref type="table" coords="6,380.64,448.26,4.98,8.64" target="#tab_2">3</ref> presents the evaluation results for all the used embedding dimensions. The embedding dimensions gave similar results, with some slight differences in the model accuracy in favor of the model generating 300-dimensional vectors for each word. Thus, we decided to go with that embedding in the final model for the CLEF test runs.</p><p>Evaluating the Architecture Variations We trained the extended models with the same hyperparameters as our basic model and used word2vec as the method of generating the word embeddings, with a dimension size of 300 based on our results from Table <ref type="table" coords="6,159.09,560.80,3.74,8.64" target="#tab_2">3</ref>. The evaluation results for the two architecture variations are shown in Table <ref type="table" coords="6,473.11,560.80,3.74,8.64" target="#tab_3">4</ref>.</p><p>Although the training accuracies were similar, the validation accuracies were very different. Even though the Large Model is a deeper model (having more trainable weights and predicting power), the big difference between its training and validation accuracies, led us to believe that it was overfitting on the training data. One possible reason for this might be that the model is too complex for the limited number of training samples (articles) in our task. The table also shows that the Simple Model performs better in all the other metrics as well. Thus, the model chosen for the CLEF submission was the Simple Model.</p><p>Evaluating on CLEF's Test Data Set Applying our basic model -using our simpler architecture variation, a word2vec embedding layer generating 300-dimensional vectors and the hyperparameters shown in Table <ref type="table" coords="7,317.47,143.22,4.98,8.64" target="#tab_1">2</ref> -on the official CLEF test data set via official approach submissions, we obtained an accuracy of 90.34%. Based on the accuracy alone, our model performed even better on the test data than in our experiments with the validation data. Comparing our approach to the approaches of other teams at CLEF 2019 with respect to bot identification on the English language -ignoring the other tasks proposed within the CLEF 2019 Bots and Gender Profiling Task -, our team ranked in the top half of all participating teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we presented a convolutional neural network architecture for determining whether a Twitter feed is written by a bot or a human. In our experiments, we found that a convolutional neural network, using the flatten transition function and a 300dimensional word2vec embedding method performs best among our methods. In the official CLEF 2019 Bots and Gender Profiling Task test runs, we obtained a relatively high accuracy of 90.34%. In the future, besides evaluating a deeper convolutional neural network, we plan to develop further approaches based on LSTMs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,186.24,328.58,242.88,8.12;3,134.77,115.84,345.81,198.00"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Architecture of our system used for classifying sentences.</figDesc><graphic coords="3,134.77,115.84,345.81,198.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,208.70,115.83,197.95,57.38"><head>Table 1 .</head><label>1</label><figDesc>Characteristics of the used evaluation data set.</figDesc><table coords="5,239.77,138.52,133.57,34.69"><row><cell>Dataset</cell><cell>Number of articles In %</cell></row><row><cell>Train</cell><cell>2873 69.85</cell></row><row><cell>Validation</cell><cell>1240 30.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,151.70,190.86,328.90,211.28"><head>Table 2 .</head><label>2</label><figDesc>Hyperparameters.</figDesc><table coords="5,208.57,215.37,198.22,122.36"><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Conv. filter size</cell><cell>64</cell></row><row><cell>Conv. kernel size</cell><cell>4</cell></row><row><cell cols="2">MaxPooling1D pool size 4</cell></row><row><cell>Dropout rate</cell><cell>0.5</cell></row><row><cell>Dense layer units</cell><cell>256</cell></row><row><cell cols="2">Layers Activation function ReLu</cell></row><row><cell>Optimizer</cell><cell>Adam</cell></row><row><cell>Learning Rate</cell><cell>Adaptive (0.001→0.00001)</cell></row><row><cell>Loss function</cell><cell>Binary crossentropy</cell></row><row><cell>Batch Size</cell><cell>32</cell></row></table><note coords="5,151.70,369.59,328.90,8.64;5,151.70,381.55,328.89,8.64;5,151.70,393.50,68.71,8.64"><p>from 4 adjacent features. If the same input size is used, this makes for a significant lower number of weights in the fully-connected layer (around 16,000) compared to the Large Model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,205.22,599.86,204.92,59.20"><head>Table 3 .</head><label>3</label><figDesc>Results for the different embedding dimensions.</figDesc><table coords="5,256.80,624.36,99.52,34.69"><row><cell>Embedding</cell><cell>Accuracy</cell></row><row><cell cols="2">100-dimensional 84.03%</cell></row><row><cell cols="2">300-dimensional 85.65%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,136.32,115.83,342.72,68.44"><head>Table 4 .</head><label>4</label><figDesc>Results for the architecture variations.</figDesc><table coords="6,136.32,138.52,342.72,45.75"><row><cell>Architecture</cell><cell># Trainable Weights</cell><cell>Train Accuracy</cell><cell>Validation Acc.</cell><cell>Precision</cell><cell>Recall F1 Score</cell><cell>AUC Score</cell></row><row><cell cols="2">Large Model 11,000,000</cell><cell>95.58%</cell><cell cols="4">79.68% 72.94% 94.35% 82.28% 79.68%</cell></row><row><cell>Simple Model</cell><cell>16,000</cell><cell>97.67%</cell><cell cols="4">85.65% 97.02% 73.55% 83.67% 85.65%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.61,395.19,336.63,7.77;7,150.95,406.15,308.37,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,407.27,395.19,71.97,7.77;7,150.95,406.15,97.37,7.77">Malicious accounts: Dark of the social networks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Adewole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Anuar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kamsin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">D</forename><surname>Varathan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Razak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,254.45,406.15,140.62,7.77">J. Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="41" to="67" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,416.95,337.98,7.77;7,150.95,427.91,295.77,7.77;7,150.95,438.87,289.81,7.77;7,150.95,449.83,76.64,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,258.16,416.95,222.43,7.77;7,150.95,427.91,98.65,7.77">Bot Conversations are Different: Leveraging Network Metrics for Bot Detection in Twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Beskow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,267.54,427.91,179.19,7.77;7,150.95,438.87,236.40,7.77">Proceedings of the IEEE/ACM 2018 International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the IEEE/ACM 2018 International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="825" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,460.63,302.65,7.77;7,150.95,471.59,329.64,7.77;7,150.95,482.54,97.37,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,296.03,460.63,149.23,7.77;7,150.95,471.59,39.49,7.77">DeBot: Twitter Bot Detection via Warped Correlation</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Chavoshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hamooni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,208.35,471.59,254.77,7.77;7,186.82,482.54,35.36,7.77">Proceedings of the IEEE 16th International Conference on Data Mining</title>
		<meeting>the IEEE 16th International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="817" to="822" />
		</imprint>
	</monogr>
	<note>ICDM&apos;16</note>
</biblStruct>

<biblStruct coords="7,142.61,493.34,312.25,7.77;7,150.95,504.30,301.85,7.77;7,150.95,515.26,316.87,7.77;7,150.95,526.22,321.36,7.77;7,150.95,537.18,323.61,7.77;7,150.95,548.14,315.39,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,150.95,515.26,316.87,7.77;7,150.95,526.22,140.81,7.77">Overview of PAN 2019: Author Profiling, Celebrity Profiling, Cross-domain Authorship Attribution and Style Change Detection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Manjavancas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tschuggnall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Zangerle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,407.83,537.18,66.74,7.77;7,150.95,548.14,230.72,7.77">Proceedings of the Tenth International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Heinatz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Tenth International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,558.94,334.09,7.77;7,150.95,569.89,188.79,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,316.08,558.94,160.62,7.77;7,150.95,569.89,28.55,7.77">An empirical comparison of botnet detection methods</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stiborek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zunino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,185.82,569.89,80.70,7.77">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="100" to="123" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,580.69,330.63,7.77;7,150.95,591.65,329.64,7.77;7,150.95,602.61,291.64,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,283.45,580.69,189.79,7.77;7,150.95,591.65,329.64,7.77;7,150.95,602.61,50.45,7.77">Algorithms, bots, and political communication in the US 2016 election: The challenge of automated political communication for election law and administration</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Calo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,207.25,602.61,160.64,7.77">Journal of information technology &amp; politics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,613.41,337.28,7.77;7,150.95,624.37,321.50,7.77;7,150.95,635.33,68.48,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,183.68,613.41,211.63,7.77">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,413.15,613.41,66.74,7.77;7,150.95,624.37,259.48,7.77;7,150.95,635.33,42.34,7.77">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
	<note>EMNLP&apos;14</note>
</biblStruct>

<biblStruct coords="7,142.61,646.13,328.10,7.77;7,150.95,657.08,79.94,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,249.68,646.13,138.83,7.77">Deep neural networks for bot detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kudugunta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,394.26,646.13,76.45,7.77">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="312" to="322" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,119.96,333.99,7.77;8,150.95,130.92,212.58,7.77" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,322.13,119.96,154.47,7.77;8,150.95,130.92,98.55,7.77">For Whom the Bell Trolls: Troll Behaviour in the Twitter Brexit Debate</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Llewellyn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Favero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
		<idno>CoRR abs/1801.08754</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,141.88,324.25,7.77;8,150.95,152.84,288.38,7.77;8,150.95,163.80,75.46,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,150.95,152.84,226.97,7.77">Contrast pattern-based classification for bot detection on twitter</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Loyola-González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-Cuevas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">I</forename><surname>Mata-Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,383.31,152.84,47.06,7.77">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="45800" to="45817" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,174.76,316.85,7.77;8,150.95,185.71,321.27,7.77;8,150.95,196.67,57.52,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,300.22,174.76,158.87,7.77;8,150.95,185.71,27.66,7.77">Towards a language independent Twitter bot detector</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nordqvist</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Laitinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.52,185.71,222.67,7.77">Proceedings of the Digital Humanities in the Nordic Countries</title>
		<meeting>the Digital Humanities in the Nordic Countries</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="308" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,207.63,327.81,7.77;8,150.95,218.59,283.67,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,404.21,207.63,65.84,7.77;8,150.95,218.59,170.43,7.77">Rtbust: Exploiting temporal patterns for botnet detection on twitter</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mazza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cresci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Avvenuti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Quattrociocchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<idno>CoRR abs/1902.04506</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,229.55,323.41,7.77;8,150.95,240.51,316.91,7.77;8,150.95,251.47,241.55,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,229.20,229.55,236.44,7.77;8,150.95,240.51,58.90,7.77">Overview of the 7th Author Profiling Task at PAN 2019: Bots and Gender Profiling</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,425.77,240.51,42.10,7.77;8,150.95,251.47,72.99,7.77">CLEF 2019 Labs and Workshops</title>
		<title level="s" coord="8,230.42,251.47,85.63,7.77">Notebook Papers. CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,262.43,303.31,7.77;8,150.95,273.39,321.38,7.77;8,150.95,284.34,306.33,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,376.56,262.43,68.99,7.77;8,150.95,273.39,202.82,7.77">Online Human-Bot Interactions: Detection, Estimation, and Characterization</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flammini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,371.84,273.39,100.49,7.77;8,150.95,284.34,182.09,7.77">Proceedings of the Eleventh International Conference on Web and Social Media</title>
		<meeting>the Eleventh International Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="280" to="289" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
