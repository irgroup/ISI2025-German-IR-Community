<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.30,115.96,334.75,12.62;1,209.08,133.89,197.20,12.62">TOBB-ETU at CLEF 2019: Prioritizing Claims Based on Check-Worthiness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,231.35,171.79,63.26,8.74"><forename type="first">Bahadir</forename><surname>Altun</surname></persName>
							<email>ialtun@etu.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">TOBB University of Economics and Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.31,171.79,66.69,8.74"><forename type="first">Mucahid</forename><surname>Kutlu</surname></persName>
							<email>m.kutlu@etu.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">TOBB University of Economics and Technology</orgName>
								<address>
									<settlement>Ankara</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.30,115.96,334.75,12.62;1,209.08,133.89,197.20,12.62">TOBB-ETU at CLEF 2019: Prioritizing Claims Based on Check-Worthiness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">087FB670C00EE0E9244695453D1D4CAE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fact-Checking</term>
					<term>Check-Worthiness</term>
					<term>Learning-to-Rank</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, we witnessed an incredible amount of misinformation spread over the Internet. However, it is extremely time consuming to analyze the veracity of every claim made on the Internet. Thus, we urgently need automated systems that can prioritize claims based on their check-worthiness, helping fact-checkers to focus on important claims. In this paper, we present our hybrid approach which combines rule-based and supervised methods for CLEF-2019 Check That! Lab's Check-Worthiness task. Our primary model ranked 9 th based on MAP, and 6 th based on R-P, P@5, and P@20 metrics in the official evaluation of primary submissions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the fast developing information retrieval (IR) technologies and social media platforms such as Twitter and Facebook, it is very easy to reach any kind of information we are looking for and share it with other people. Therefore, any information can be popular worldwide by the incredible sharing behavior of the Internet users. As a worrisome finding, a recent study <ref type="bibr" coords="1,369.05,483.70,10.52,8.74" target="#b6">[7]</ref> reports that false news spread eight times faster than true news.</p><p>Obviously, false news can have many undesired consequences and be very harmful for our daily life. Many researchers and journalists are trying to minimize the spread of misinformation and its negative impacts. For example, factchecking websites, such as Snopes 1 , investigate the veracity of claims spread on the Internet and publish their findings. However, these valuable efforts are not enough to effectively combat the false news because fact-checking is a very time-consuming task, taking around one day for a single claim <ref type="bibr" coords="1,410.34,579.58,9.96,8.74" target="#b5">[6]</ref>.</p><p>Considering the vast amount of claims spread on the Internet on a daily basis and high cost of fact-checking, there is an urgent need to develop systems that Algorithm 1 Claim Ranking Algorithm In this paper, we present our method for CLEF-2019 Check That Lab!'s[3] Check Worthiness task <ref type="bibr" coords="2,231.24,279.64,11.75,8.74" target="#b0">[1]</ref>. We use a hybrid approach in which claims are ranked using a supervised method and then reranked based on hand-crafted rules. In particular, we use MART <ref type="bibr" coords="2,255.68,303.55,10.52,8.74" target="#b4">[5]</ref> learning-to-rank algorithm to rank the claims. Features we investigate include topical category of claims, named entities, partof-speech tags, bigrams, and speakers of the claims. We also develop rules to detect the statements that are not likely to be a claim, and put those statements at the very end of our ranked lists. Our primary model ranked 9 th based on MAP, and 6 th based on R-P, P@5, and P@20 metrics in the official evaluation of primary submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Approach</head><p>We propose a hybrid approach which uses both rule-based and supervised methods to rank claims based on their check-worthiness. Now we explain our approach in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hybrid Approach</head><p>We first rank claims using a supervised method and then rerank the claims using a rule-based method. Algorithm 1 shows the steps in our proposed hybrid approach. For the supervised ranking phase, we investigated logistic regression (LR) and various learning-to-rank (L2R) algorithms including MART <ref type="bibr" coords="2,438.05,536.57,9.96,8.74" target="#b4">[5]</ref>, Rank-Boost <ref type="bibr" coords="2,163.01,548.52,9.96,8.74" target="#b3">[4]</ref>, and RankNet <ref type="bibr" coords="2,231.82,548.52,14.23,8.74" target="#b1">[2]</ref>. In our not-reported initial experiments, we observed that MART outperforms other L2R methods. Thus, we focus on only MART and LR in developing our primary and contrastive systems.</p><p>In the training dataset, we observed that many sentences contain phrases that are not likely to be a part of a check-worthy claim such as thanks. In addition, speaker of many statements are defined as system and these statements contain non-claim phrases such as applause indicating the actions of the audience during the debate. Thus, in rule-based reranking phase, inspired from <ref type="bibr" coords="2,411.70,632.21,9.96,8.74" target="#b8">[9]</ref>, we set score of a sentence to the minimum score if it contains any of the thanks, thank you, welcome, and goodbye phrases, or 2) its speaker is system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>The features we use can be categorized into five categories: 1) Named entities, 2) part-of-speech tags, 3) topical category, 4) bigrams, and 5) speakers. Now we explain our features used in our supervised methods.</p><p>Named Entities: Claims about people and institutions are likely to be check-worthy because people and institutions can be negatively affected by those claims. In addition, a check-worthy claim should be also verifiable. The location information, numerical values in claims are easy to verify because they provide unambiguous information. Therefore, detecting whether a statement is about a person or an institution, and existence of numerical values, location, and date information might be good indicators for check-worthy claims. Thus, we identify the named entities using Stanford Named Entity Tagger<ref type="foot" coords="3,388.31,273.68,3.97,6.12" target="#foot_0">2</ref> which tags entities such as person, location, organization, money, date, time and percentage. We use a binary vector of size 7 representing the presence of each named entity type separately.</p><p>Part-of-speech (POS) Tags: Sentences without informative words are less likely to be check-worthy. POS tags of words might help us to detect the amount of information in a sentence. For instance, a sentence without any noun such as "That is great!" does not contain any information that can be fact-checked. Thus, we detect POS tags in the statements using Stanford POS toolkit <ref type="foot" coords="3,455.00,382.08,3.97,6.12" target="#foot_1">3</ref> . For this set of features, we again use a binary feature vector of size 36 in which each feature represents existence or absence of a particular POS tag in the corresponding statement.</p><p>Topical Category: Topic of a claim might be an effective indicator for check-worthy claims <ref type="bibr" coords="3,227.77,456.19,9.96,8.74" target="#b7">[8]</ref>. For instance, a claim about celebrities might be less check-worthy than a claim about economics or wars. Therefore, we detect categories of statements using IBM-Watson's Natural Language Understanding Tool<ref type="foot" coords="3,154.14,490.48,3.97,6.12" target="#foot_2">4</ref> . This categorization classifies every statement into topics such as finance, law, government, and politics, where each topic could be branched up to two levels of subtopics. We only use the main topic and their immediate subtopics, yielding 298 features in total. The topics are represented as binary features as we do for named entities and POS tags.</p><p>Bigram: Instead of using a large list of bigrams, we use a limited but powerful set of bigrams. In this set of features, we use bigrams that appear at least N times only in check-worthy or only in not check-worthy claims in the training set. We set N to 50 empirically based on our initial (not-reported) experiments, yielding 47 features. Some of these bigrams are "All right", "I know", and "go ahead". Speaker List: A claim's check worthiness may depend on the person who makes it. Claims of influential people are more important than claims of random people. In addition, some people might make check-worthy claims more frequently than others. For instance, in the training dataset, we found that 3.8% of Donald Trump's statements and 2.6% of Hilary Clinton's statements are labeled as check-worthy, showing that Donald Trump is more likely to make check-worthy claims than Hilary Clinton. Therefore, we use the 33 speakers appearing in the training data as binary features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>In this section, we present experimental results on both training and test data using different sets of features and machine learning algorithms.</p><p>The training and test datasets contain 19 and 7 files at varying lengths, respectively, where each file corresponds to transcription of a debate for the US 2016 presidential election. We perform 19-fold cross validation on the training data where each fold is a separate debate, and calculate mean average precision (MAP). We use Ranklib<ref type="foot" coords="4,238.28,365.39,3.97,6.12" target="#foot_3">5</ref> library in our L2R approach and Scikit toolkit<ref type="foot" coords="4,442.73,365.39,3.97,6.12" target="#foot_4">6</ref> for LR. We set the number of trees and the number of leaves parameters of MART to 50, and 2, respectively based on our initial experiments with different parameter configurations. We use default parameters for LR.</p><p>We first investigate the impact of each feature group using LR and MART. In particular, for each feature group we use all other features to build the model and observe how the performance would change without the corresponding feature group. Table <ref type="table" coords="4,196.99,450.69,5.73,8.77" target="#tab_0">1</ref> shows MAP scores for various feature sets. From the results in Table <ref type="table" coords="4,264.36,614.33,3.87,8.74" target="#tab_0">1</ref>, we can see that features have different impacts on the performance of MART and LR. Not using named entities and topical category features cause around 2.96%, and 2.28% decrease in the performance of MART, respectively. However, for LR, POS tags seem the most effective features while named entities and topical categories have very small impact on the performance. Nevertheless, we achieve the best results when we use LR with all features (0.2198) while LR with All-{Named Entities}, MART with All-{Speaker List}, and MART with all features have also similar results.</p><p>For our primary submission, we selected MART algorithm with all features except speaker list. This is because its performance is very close to our best performing model and it does not use any speaker list which makes it more debate-independent model. For our contrastive-1 and contrastive-2 submissions, we elected MART and LR using all features.</p><p>For the evaluation on test data, we train our selected models with all training data. Table <ref type="table" coords="5,191.85,262.43,5.73,8.77">2</ref> presents official performance scores of all our submissions based on various evaluation metrics. 12 groups submitted 25 runs in total. Our primary submission ranked 9 th among primary models based on MAP which is the official evaluation metric of the task. Our primary submission is also ranked 6 th based on R-P, P@5, and P@20 metrics, among primary models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Official Results for our Submitted Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>MAP RR R-P P@1 P@3 P@5 P@10 P@20 P@50 MART w/ All-{Speaker List} (Primary)</p><p>. <ref type="bibr" coords="5,225.38,382.37,16.79,7.86">0884</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Qualitative Analysis</head><p>In this section, we take a deeper look into our results and conduct a qualitative analysis. We manually investigate the top 10 claims in our primary system's output in each test file. Table <ref type="table" coords="5,270.11,560.45,5.73,8.77" target="#tab_2">3</ref> shows a sample of claims with their labels and ranks in our system's output.</p><p>Comparing Row 1 and 2, while both of the statements are about the change in unemployment, one of them is labeled as check-worthy while the other one is not. We also observe a similar issue in statements shown in Row 3 and 4 where both statements are about the amount of trade and use similar words with similar sentence structure but their labels are different. This might be due to many reasons. First, check-worthy claims can be subjective, making the task even more challenging. Second, we might need background information about the claims because a claim which has been already discussed among people is more check-worthy than the one which is not discussed by anyone. The requirement of background information suggests that context the claim made and external resources such as web pages, social media posts about the claim can be useful to detect check-worthiness of claims.</p><p>Regarding the claims in Row 5 and 6, the statements contain verifiable claims and their topic is about economics which can be considered as an important topic. In addition, the statement in Row 5 has also an explicit accusation regarding to an administration. However, they are both labeled as not check-worthy. These samples provide further evidence that detecting check-worthiness of a claim requires utilizing external resources and its context instead of just using the claim itself.</p><p>Regarding the claims in Row 7, 8, and 9, we can see that all three claims are about trade but only claim in Row 9 is labeled as check-worthy. This might be because the amount of money mentioned in Row 7 and 8 are not exact numbers, making them hard to verify. On the other hand, the claim in Row 9 mentions an exact number about the trade deficit. While our features take account whether a claim has a numerical value or not, this suggest that we have to handle special cases where numbers are not exact.</p><p>In this paper, we described our methods for CLEF-2019 Check That! Lab's Check-Worthiness task and discuss results conducting a qualitative analysis. We proposed a hybrid approach which combines rule-based and supervised methods together. We first rank claims using MART algorithm, and then change the scores of some statements based on our hand-crafted rules. We investigated various features including topical category, POS tags, named entities, bigrams, and speakers of claims. Our primary model ranked 9 th based on MAP, and 6 th based on R-P, P@5, and P@20 metrics, among primary models. In our qualitative analysis we discussed that detecting check-worthiness is a subjective task and linguistic analysis of claims are not enough, requiring utilization of other resources to capture the background information about claims.</p><p>In the future, we plan to investigate linguistic features to capture the contextual information about the claims, and develop more effective hand-crafted rules.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,138.66,131.87,120.65,7.89;2,138.66,142.82,100.95,7.89;2,138.66,153.81,140.70,8.28;2,138.66,164.77,132.44,8.28;2,138.66,175.73,132.63,8.28;2,138.66,186.69,152.61,8.28;2,138.66,197.65,234.96,7.86;2,138.66,208.58,104.02,7.89;2,134.77,243.77,345.83,8.74;2,134.77,255.73,172.16,8.74"><head>1 :</head><label>1</label><figDesc>Input: Training Data TrD 2: Input: Test Data TD 3: FT rD = extract f eatures(T rD) 4: model = train M ART (FT rD ) 5: FT D = extract f eatures(T D) 6: ranked claims = test(model, FT D ) 7: ranked claims = apply rules(ranked claims, RU LES) 8: return ranked claims assist fact-checkers to focus on the important claims instead of spending their precious time for less important claims.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,165.01,482.37,285.33,94.42"><head>Table 1 .</head><label>1</label><figDesc>MAP Scores using k-Fold Cross Validation on Training Data</figDesc><table coords="4,220.92,502.74,173.53,74.04"><row><cell>Features</cell><cell>MART</cell><cell>LR</cell></row><row><cell>All</cell><cell cols="2">0.2193 0.2198</cell></row><row><cell>All -{Named Entities}</cell><cell cols="2">0.1897 0.2197</cell></row><row><cell>All -{POS tags}</cell><cell cols="2">0.2132 0.1967</cell></row><row><cell cols="3">All -{Topical Category} 0.1965 0.2116</cell></row><row><cell>All -{Bigrams}</cell><cell cols="2">0.2193 0.2083</cell></row><row><cell>All -{Speaker List}</cell><cell cols="2">0.2196 0.2094</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,136.16,382.35,341.57,74.44"><head></head><label></label><figDesc>.2028 .1150 .0000 .0952 .1429 .1286 .1357 .0829</figDesc><table coords="5,136.16,415.62,341.57,41.17"><row><cell>MART w/ All</cell><cell>.0898 .2013 .1150 .0000 .1429 .1143 .1286 .1429 .0829</cell></row><row><cell>(Contr. -1)</cell><cell></cell></row><row><cell>LR w/ All</cell><cell>.0913 .3427 .1007 .1429 .1429 .1143 .0714 .1214 .0829</cell></row><row><cell>(Contr. -2)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,136.16,115.91,348.76,259.05"><head>Table 3 .</head><label>3</label><figDesc>A sample of statements and their ranks in our primary system's output</figDesc><table coords="6,136.16,145.90,348.76,229.06"><row><cell cols="3">Row Speaker Statement</cell><cell cols="2">Label Rank Debate</cell></row><row><cell>1</cell><cell>Trump</cell><cell>And Hispanic American unem-ployment has also reached the</cell><cell>1</cell><cell>2 20180131 state union</cell></row><row><cell></cell><cell></cell><cell>lowest levels in history.</cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>Trump</cell><cell>Unemployment claims have hit</cell><cell>0</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell>a 45-year low.</cell><cell></cell><cell></cell></row><row><cell>3 4</cell><cell>Trump Trump</cell><cell>They do $531 billion with us. We do $100 billion with them.</cell><cell>1 0</cell><cell>9 20181015 60 min 10</cell></row><row><cell>5</cell><cell>Christie</cell><cell>He's lost $4,000 in the last seven</cell><cell>0</cell><cell>3 20160129 7 gop</cell></row><row><cell></cell><cell></cell><cell>years in his income because of</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>this administration.</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell>Trump</cell><cell>But they had to pay over a bil-lion dollars.</cell><cell>0</cell><cell>1 trump emergency</cell></row><row><cell>7</cell><cell>Trump</cell><cell>I mean, were taking in billions</cell><cell>0</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>and billions of dollars in tariffs</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>from China.</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>Rubio</cell><cell>But you still have hundreds of billions of dollars of deficit that</cell><cell>0</cell><cell>9 20160311 12 gop</cell></row><row><cell></cell><cell></cell><cell>you're going to have to make up.</cell><cell></cell><cell></cell></row><row><cell>9</cell><cell>Trump</cell><cell>And we have a $505 billion trade</cell><cell>1</cell><cell>10</cell></row><row><cell></cell><cell></cell><cell>deficit right now.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="3,144.73,634.88,203.96,7.86"><p>https://nlp.stanford.edu/software/CRF-NER.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,144.73,645.84,186.58,7.86"><p>https://nlp.stanford.edu/software/tagger.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="3,144.73,656.80,294.46,7.86"><p>https://www.ibm.com/watson/services/natural-language-understanding/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="4,144.73,645.84,195.23,7.86"><p>https://sourceforge.net/p/lemur/wiki/RankLib/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="4,144.73,656.80,96.91,7.86"><p>https://scikit-learn.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,353.80,342.25,7.86;7,146.91,364.75,333.68,7.86;7,146.91,375.71,333.68,7.86;7,146.91,386.67,139.04,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,146.91,364.75,333.68,7.86;7,146.91,375.71,162.02,7.86">Overview of the clef-2019 checkthat! lab on automatic identification and verification of claims. task 1: Check-worthiness</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martino</forename></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,319.37,375.71,120.85,7.86">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,397.63,342.24,7.86;7,146.91,408.59,333.68,7.86;7,146.91,419.55,314.35,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,195.64,408.59,164.22,7.86">Learning to rank using gradient descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">N</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,383.34,408.59,97.25,7.86;7,146.91,419.55,231.77,7.86">Proceedings of the 22nd International Conference on Machine learning (ICML-05)</title>
		<meeting>the 22nd International Conference on Machine learning (ICML-05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,430.51,342.25,7.86;7,146.91,441.47,333.67,7.86;7,146.91,452.43,333.68,7.86;7,146.91,463.38,298.37,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,262.50,441.47,218.08,7.86;7,146.91,452.43,137.22,7.86">Overview of the clef-2019 checkthat!: Automatic identification and verification of claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,302.72,452.43,177.87,7.86;7,146.91,463.38,106.54,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,474.34,342.24,7.86;7,146.91,485.30,333.68,7.86;7,146.91,496.26,20.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,354.73,474.34,125.86,7.86;7,146.91,485.30,102.32,7.86">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,258.56,485.30,149.37,7.86">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="933" to="969" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,507.22,342.25,7.86;7,146.91,518.18,164.02,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,213.84,507.22,243.45,7.86">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,465.52,507.22,15.08,7.86;7,146.91,518.18,64.30,7.86">Annals of statistics</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1189" to="1232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,529.14,342.24,7.86;7,146.91,540.10,333.68,7.86;7,146.91,551.06,288.68,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,310.89,529.14,169.70,7.86;7,146.91,540.10,77.95,7.86">Detecting check-worthy factual claims in presidential debates</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,243.91,540.10,236.68,7.86;7,146.91,551.06,160.16,7.86">Proceedings of the 24th acm international on conference on information and knowledge management</title>
		<meeting>the 24th acm international on conference on information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,562.02,342.24,7.86;7,146.91,572.97,110.07,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,282.46,562.02,158.84,7.86">The spread of true and false news online</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,448.39,562.02,28.17,7.86">Science</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">6380</biblScope>
			<biblScope unit="page" from="1146" to="1151" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,583.93,342.25,7.86;7,146.91,594.89,267.40,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,302.38,583.93,178.22,7.86;7,146.91,594.89,125.65,7.86">bigir at clef 2018: Detection and verification of check-worthy political claims</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,292.12,594.89,94.00,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,605.85,342.24,7.86;7,146.91,616.81,333.67,7.86;7,146.91,627.77,333.68,7.86;7,146.91,638.73,208.19,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,320.12,605.85,160.47,7.86;7,146.91,616.81,224.29,7.86">A hybrid recognition system for checkworthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">I</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,394.55,616.81,86.04,7.86;7,146.91,627.77,328.86,7.86">CLEF 2018 Working Notes. Working Notes of CLEF 2018-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<publisher>CEUR-WS. org</publisher>
			<date type="published" when="2018">8995. 2018</date>
			<biblScope unit="page" from="171" to="175" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
