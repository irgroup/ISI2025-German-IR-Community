<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,196.10,115.96,223.16,12.62;1,145.29,133.89,324.76,12.62;1,201.29,151.82,212.77,12.62">Neural Weakly Supervised Fact Check-Worthiness Detection with Contrastive Sampling-Based Ranking Loss</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.29,189.49,63.27,8.74"><forename type="first">Casper</forename><surname>Hansen</surname></persName>
							<email>c.hansen@di.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.83,189.49,73.50,8.74"><forename type="first">Christian</forename><surname>Hansen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.60,189.49,92.84,8.74"><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
							<email>simonsen@di.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,408.99,189.49,71.07,8.74"><forename type="first">Christina</forename><surname>Lioma</surname></persName>
							<email>c.lioma@di.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,196.10,115.96,223.16,12.62;1,145.29,133.89,324.76,12.62;1,201.29,151.82,212.77,12.62">Neural Weakly Supervised Fact Check-Worthiness Detection with Contrastive Sampling-Based Ranking Loss</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F9B621901E91AEE1A826F42CE78BC306</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fact check-worthiness</term>
					<term>neural networks</term>
					<term>contrastive ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the winning approach used by the Copenhagen team in the CLEF-2019 CheckThat! lab. Given a political debate or speech, the aim is to predict which sentences should be prioritized for fact-checking by creating a ranked list of sentences. While many approaches for check-worthiness exist, we are the first to directly optimize the sentence ranking as all previous work has solely used standard classification based loss functions. We present a recurrent neural network model that learns a sentence encoding, from which a check-worthiness score is predicted. The model is trained by jointly optimizing a binary cross entropy loss, as well as a ranking based pairwise hinge loss. We obtain sentence pairs for training through contrastive sampling, where for each sentence we find the k most semantically similar sentences with opposite label. To increase the generalizability of the model, we utilize weak supervision by using an existing check-worthiness approach to weakly label a large unlabeled dataset. We experimentally show that both weak supervision and the ranking component improve the results individually (MAP increases of 25% and 9% respectively), while when used together improve the results even more (39% increase). Through a comparison to existing state-of-the-art check-worthiness methods, we find that our approach improves the MAP score by 11%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Tasks performed</head><p>The Copenhagen team participated in Task 1 <ref type="bibr" coords="1,329.19,556.29,10.52,8.74" target="#b0">[1]</ref> of the CLEF 2019 Fact Checking Lab (CheckThat!) on automatic identification and Verification of claims <ref type="bibr" coords="1,445.32,568.25,9.96,8.74" target="#b3">[4]</ref>. This report details our approach and results.</p><p>The aim of Task 1 is to identify sentences in a political debate that should be prioritized for fact-checking: given a debate, the goal is to produce a ranked list of all sentences based on their worthiness for fact checking.</p><p>Examples of check-worthy sentences are shown in Table <ref type="table" coords="2,402.94,118.99,3.87,8.74" target="#tab_0">1</ref>. In the first example Hillary Clinton mentions Bill Clinton's work in the 1990s, followed by a claim made by Donald Trump stating that president Clinton approved the North American Free Trade Agreement (NAFTA). In the second example Hillary Clinton mentions Donald Trump's beliefs about climate change. While this may be more difficult to fact-check, it is still considered an interesting claim and thus check-worthy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Main objectives of experiments</head><p>The task of check-worthiness can be considered part of the fact-checking pipeline, which traditionally consists of three steps:</p><p>1. Detect sentences that are interesting to fact-check.</p><p>2. Gather evidence and background knowledge for each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Manually or automatically estimate veracity.</head><p>Sentences detected in step 1 for further processing are described as being checkworthy. This detection can be considered a filtering step in order to limit the computational processing needed in total for the later steps. In practice, sentences are ranked according to their check-worthiness such that they can be processed in order of importance. Thus, the ability to correctly rank check-worthy sentences above non-check-worthy is essential for automatic check-worthiness methods to be useful in practice. However, existing check-worthiness methods <ref type="bibr" coords="2,134.77,578.95,16.20,8.74" target="#b9">[10,</ref><ref type="bibr" coords="2,150.96,578.95,12.15,8.74" target="#b15">16,</ref><ref type="bibr" coords="2,163.11,578.95,12.15,8.74" target="#b10">11,</ref><ref type="bibr" coords="2,175.26,578.95,8.10,8.74" target="#b4">5,</ref><ref type="bibr" coords="2,183.36,578.95,8.10,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,191.45,578.95,8.10,8.74" target="#b8">9,</ref><ref type="bibr" coords="2,199.55,578.95,12.15,8.74" target="#b18">19]</ref> do not directly model this aspect, as they are all based on traditional classification based training objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>Most existing check-worthiness methods are based on feature engineering to extract meaningful features. Given a sentence, ClaimBuster <ref type="bibr" coords="2,397.35,656.12,15.50,8.74" target="#b9">[10]</ref> predicts check-worthiness by extracting a set of features (sentiment, statement length, Part-of-Speech (POS) tags, named entities, and tf-idf weighted bag-of-words), and uses a SVM classifier for the prediction. Patwari et al. <ref type="bibr" coords="3,361.07,142.90,15.50,8.74" target="#b15">[16]</ref> presented an approach based on similar features, as well as contextual features based on sentences immediately preceding and succeeding the one being assessed, as well as certain hand-crafted POS patterns. The prediction is made by a multi-classifier system based on a dynamic clustering of the data. Gencheva et al. <ref type="bibr" coords="3,399.28,190.72,10.52,8.74" target="#b4">[5]</ref> also extend the features used by ClaimBuster to include more context, such as the sentence's position in the debate segment, segment sizes, similarities between segments, and whether the debate opponent was mentioned. In the CLEF 2018 competition on check-worthiness detection <ref type="bibr" coords="3,285.68,238.55,14.61,8.74" target="#b14">[15]</ref>, Hansen et al. <ref type="bibr" coords="3,365.38,238.55,10.52,8.74" target="#b8">[9]</ref> showed that a recurrent neural network with multiple word representations (word embeddings, part-ofspeech tagging, and syntactic dependencies) could obtain state-of-the-art results for check-worthiness prediction. Hansen et al. <ref type="bibr" coords="3,337.29,274.41,10.52,8.74" target="#b5">[6]</ref> later extended this work with weak supervision based on a large collection of unlabeled political speeches and showed significant improvements compared to existing state-of-the-art methods. This paper directly improves the work done by Hansen et al. by integrating a ranking component into the model trained via contrastive sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Neural Check-Worthiness Model</head><p>Our Neural Check-Worthiness Model (NCWM) uses a dual sentence representation, where each word is represented by both a word embedding and its syntactic dependencies within the sentence. The word embedding is a traditional word2vec model <ref type="bibr" coords="3,164.62,412.28,15.49,8.74" target="#b13">[14]</ref> that aims at capturing the semantics of the sentence. The syntactic dependencies of a word aim to capture the role of that word in modifying the semantics of other words in the sentence <ref type="bibr" coords="3,319.58,436.19,14.61,8.74" target="#b12">[13]</ref>. We use a syntactic dependency parser <ref type="bibr" coords="3,165.31,448.15,10.52,8.74" target="#b1">[2]</ref> to map each word to its dependency (as a tag) within the sentence, which is then converted to a one-hot encoding. This combination of capturing both semantics and syntactic structure has been shown to work well for the check-worthiness task <ref type="bibr" coords="3,233.55,484.01,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="3,244.07,484.01,7.01,8.74" target="#b8">9]</ref>. For each word in a sentence, the word embedding and one-hot encoding are concatenated and fed to a recurrent neural network with Long Short-Term Memory Units (LSTM) as memory cells (See Figure <ref type="figure" coords="3,468.97,507.92,3.87,8.74" target="#fig_0">1</ref>). The output of the LSTM cells are aggregated using an attention weighted sum, where each weight is computed as:</p><formula xml:id="formula_0" coords="3,254.77,551.20,225.82,24.72">α t = exp (score (h t )) i exp (score (h i ))<label>(1)</label></formula><p>where h t is the output of the LSTM cell at time t, and score(•) is a learned function that returns a scalar. Finally, the attention weighted sum is transformed to the check-worthiness score by a sigmoid transformation, such that the score lies between 0 and 1.</p><p>Loss functions. The model is jointly trained using both a classification and ranking loss function. For the classification loss, we use the standard binary cross entropy loss. For the ranking loss, we use a hinge loss based on the computed check-worthiness score of sentence pairs with opposite labels. To obtain these pairs we use contrastive sampling, such that for each sentence we sample the k most semantically similar sentences with the opposite label, i.e., for check-worthy sentences we sample k non-check-worthy sentences. In order to estimate the semantic similarity we compute an average word embedding vector of all words in a sentence, and then use the cosine similarity to find the k most semantically similar sentences with the opposite label. The purpose of this contrastive sampling is to enable the model to better learn the small differences between check-worthy and non-check-worthy sentences. The combination of both the classification and ranking loss enables the model to learn accurate classifications while ensuring the predicted scores are sensible for ranking. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Resources employed</head><p>Our approach is summarized in Figure <ref type="figure" coords="4,311.45,554.92,3.87,8.74" target="#fig_0">1</ref>, and in the following the underlined values were found to perform the best during validation. The cross validation consisted of a fold for each training speech and debate. The LSTM has {50, 100, 150, 200} hidden units, a dropout of {0, 0.1, 0.3, 0.5} was applied to the attention weighted sum, and we used a batch size of {40, 80, 120, 160, 200}.</p><p>For the contrastive sampling we found the 5 most semantically similar sentences with the opposite label. For the syntactic dependency parsing we use spaCy<ref type="foot" coords="4,473.36,625.08,3.97,6.12" target="#foot_0">1</ref> , and for the neural network implementation TensorFlow.</p><p>To train a more generalizable model we employ weak supervision <ref type="bibr" coords="5,441.85,118.99,11.62,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,453.47,118.99,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="5,461.22,118.99,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,468.97,118.99,7.75,8.74" target="#b17">18</ref>] by using an existing check-worthiness approach, ClaimBuster<ref type="foot" coords="5,406.87,129.37,3.97,6.12" target="#foot_1">2</ref> [10], to weakly label a large collection of unlabeled political speeches and debates. We obtain 271 political speeches and debates by Hillary Clinton and Donald Trump from the American Presidency Project<ref type="foot" coords="5,279.59,165.24,3.97,6.12" target="#foot_2">3</ref> . This weakly labeled dataset is used for pretraining our model. To create a pretrained word embedding, we crawl documents related to all U.S. elections available through the American Presidency Project, e.g., press releases, statements, speeches, and public fundraisers, resulting in 15,059 documents. This domain specific pretraining was also done by Hansen et al. <ref type="bibr" coords="5,149.31,226.59,9.96,8.74" target="#b5">[6]</ref>, and was shown to perform significantly better than a word embedding pretrained on a large general corpus like Google News<ref type="foot" coords="5,370.31,236.97,3.97,6.12" target="#foot_3">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>For evaluation we use the official test dataset of the competition, while choosing the hyper parameters based on a 19-fold cross validation (1 fold for each training speech and debate). Following the competition guidelines, we report the MAP and P@k metrics for the full test data, only the 3 debates, and only the 4 speeches. This splitting choice was done to investigate how the performance varies depending on the setting.</p><p>Overall, our Neural Check-Worthiness Model (NCWM) obtained the first place in the competition with a MAP of 0.1660 (primary run). To investigate the effect of the ranking component and the weak supervision (See Table <ref type="table" coords="5,454.47,389.57,3.87,8.74" target="#tab_1">2</ref>), we also report the results when these are not part of NCWM. The model without the ranking component is similar to the state-of-the-art work by Hansen et al. <ref type="bibr" coords="5,134.77,425.44,10.52,8.74" target="#b5">[6]</ref> (contrastive-1 run), and the model without either the ranking component or weak supervision is similar to earlier work by Hansen et al. <ref type="bibr" coords="5,414.18,437.39,9.96,8.74" target="#b8">[9]</ref>. The results show that the ranking component and weak supervision lead to notable improvements, both individually and when combined. The inclusion of weak supervision leads to the largest individual MAP improvement (25% increase), while the individual improvement of the ranking component is smaller (9% increase). We observe that the ranking component's improvement is marginally larger when weak supervision is included (11% increase with weak supervision compared to 9% without), thus showing that even a weakly labeled signal is also beneficial for learning the correct ranking. Combining both the ranking component and weak supervision leads to a MAP increase of 39% compared to a model without either of them, which highlights the immense benefit of using both for the task of check-worthiness as the combination provides an improvement larger than the individual parts.</p><p>To investigate the performance on speeches and debates individually, we split the test data and report the performance metrics on each of the sets. In both of MAP P@1 P@5 P@20 P@50 NCWM 0.0538 0.0000 0.1333 0.0500 0.0467 NCWM (w/o. ranking) <ref type="bibr" coords="6,241.31,312.55,9.73,7.86" target="#b5">[6]</ref> 0.0482 0.0000 0.0667 0.0333 0.0267 NCWM (w/o. WS) 0.0462 0.0000 0.0000 0.0667 0.0667 NCWM (w/o. ranking and w/o. WS) <ref type="bibr" coords="6,298.39,334.47,9.73,7.86" target="#b8">[9]</ref> 0.0329 0.0000 0.0000 0.0167 0.0533 them we observe a similar trend as for the full dataset, i.e., that both the ranking component and weak supervision lead to improvements individually and when combined. However, the MAP on the debates is significantly lower than for the speeches (0.0538 and 0.2502 respectively). We believe the reason for this difference is related to two issues: i) All speeches are by Donald Trump and 15 out of 19 training speeches and debates have Donald Trump as a participant, thus the model is better trained to predict sentences by Donald Trump. ii) Debates are often more varied in content compared to a single speech, and contain participants who are not well represented in the training data. Issue (i) can be alleviated by obtaining larger quantities and more varied training data, while issue (ii) may simply be due to debates being inherently more difficult to predict. Models better equipped to handle the dynamics of debates could be a possible direction to solve this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and future work</head><p>We presented a recurrent neural model that directly models the ranking of checkworthy sentences, which no previous work has done. This was done through a hinge loss based on contrastive sampling, where the most semantically similar sentences with opposite labels were sampled for each sentence. Additionally, we utilize weak supervision through an existing check-worthiness method to label a large unlabeled dataset of political speeches and debates. We experimentally verified that both the sentence ranking and weak supervision lead to notable performance MAP improvements (increases of 9% and 25% respectively) compared to a model without either of them, while using both lead to an improvement greater than the individual parts (39% increase). In comparison to a state-ofthe-art check-worthiness model <ref type="bibr" coords="7,270.67,142.90,9.96,8.74" target="#b5">[6]</ref>, we found our approach to perform 11% better on the MAP metric, while also achieving the first place in the competition.</p><p>In future work we plan to investigate approaches for better modelling checkworthiness in debates, as this is important for real-world applications of checkworthiness systems. Specifically, we plan to (1) investigate how context <ref type="bibr" coords="7,446.97,190.78,15.50,8.74" target="#b16">[17]</ref> can be included to better model the dynamics of a debate compared to a speech;</p><p>(2) the use of speed reading for sentence filtering <ref type="bibr" coords="7,363.64,214.69,9.96,8.74" target="#b6">[7]</ref>; and (3) extending the evaluation of this task beyond MAP and P@k, for instance using evaluation measures of both relevance and credibility <ref type="bibr" coords="7,321.76,238.60,14.61,8.74" target="#b11">[12]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,471.69,345.83,7.89;4,134.77,482.67,306.52,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Architecture of our Neural Check-Worthiness Model (NCWM). The checkworthiness score is used for minimizing the classification and ranking losses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.77,222.08,386.15,130.32"><head>Table 1 .</head><label>1</label><figDesc>Example of check-worthy sentences (red highlight)</figDesc><table coords="2,134.77,246.57,269.52,23.82"><row><cell>Speaker</cell><cell>Sentence</cell></row><row><cell cols="2">CLINTON I think my husband did a pretty good job in the 1990s.</cell></row></table><note coords="2,134.77,273.49,331.90,7.86;2,134.77,284.42,180.03,7.89;2,134.77,300.71,118.40,7.86;2,134.77,311.67,357.74,7.86;2,134.77,322.60,386.15,7.89;2,134.77,333.58,109.73,7.86;2,134.77,344.54,84.32,7.86"><p>CLINTON I think a lot about what worked and how we can make it work again... TRUMP Well, he approved NAFTA... CLINTON Take clean energy CLINTON Some country is going to be the clean-energy superpower of the 21st century. CLINTON Donald thinks that climate change is a hoax perpetrated by the Chinese. CLINTON I think it's real. TRUMP I did not.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,116.41,345.82,177.09"><head>Table 2 .</head><label>2</label><figDesc>Test results for our full Neural Check-Worthiness Model (NCWM) and when excluding the ranking and weak supervision (WS) components.</figDesc><table coords="6,142.76,151.85,326.66,141.65"><row><cell>Test (Speeches and Debates)</cell><cell>MAP P@1</cell><cell>P@5</cell><cell>P@20 P@50</cell></row><row><cell>NCWM</cell><cell cols="3">0.1660 0.2857 0.2571 0.1571 0.1229</cell></row><row><cell>NCWM (w/o. ranking) [6]</cell><cell cols="3">0.1496 0.1429 0.2000 0.1429 0.1143</cell></row><row><cell>NCWM (w/o. WS)</cell><cell cols="3">0.1305 0.1429 0.1714 0.1429 0.1200</cell></row><row><cell cols="4">NCWM (w/o. ranking and w/o. WS) [9] 0.1195 0.1429 0.1429 0.1143 0.1057</cell></row><row><cell>Test (Speeches)</cell><cell>MAP P@1</cell><cell>P@5</cell><cell>P@20 P@50</cell></row><row><cell>NCWM</cell><cell cols="3">0.2502 0.5000 0.3500 0.2375 0.1800</cell></row><row><cell>NCWM (w/o. ranking) [6]</cell><cell cols="3">0.2256 0.2500 0.3000 0.2250 0.1800</cell></row><row><cell>NCWM (w/o. WS)</cell><cell cols="3">0.1937 0.2500 0.3000 0.2000 0.1600</cell></row><row><cell cols="4">NCWM (w/o. ranking and w/o. WS) [9] 0.1845 0.2500 0.2500 0.1875 0.1450</cell></row><row><cell>Test (Debates)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,657.44,80.03,7.47"><p>https://spacy.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,624.57,155.34,7.47"><p>https://idir.uta.edu/claimbuster/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,144.73,635.53,329.52,7.47;5,144.73,646.48,18.83,7.47"><p>https://web.archive.org/web/20170606011755/http://www.presidency.ucsb. edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,657.44,202.42,7.47"><p>https://code.google.com/archive/p/word2vec/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,294.64,337.64,7.86;7,151.52,305.60,329.07,7.86;7,151.52,316.56,329.07,7.86;7,151.52,327.52,174.49,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,151.52,305.60,329.07,7.86;7,151.52,316.56,74.76,7.86">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martino</forename></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,235.18,316.56,241.20,7.86">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Task 1: Check-Worthiness</note>
</biblStruct>

<biblStruct coords="7,142.96,338.54,337.63,7.86;7,151.52,349.49,329.07,7.86;7,151.52,360.45,195.39,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,315.33,338.54,165.26,7.86;7,151.52,349.49,153.03,7.86">It depends: Dependency parser comparison using a web-based evaluation tool</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,325.08,349.49,155.51,7.86;7,151.52,360.45,104.48,7.86">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,371.47,337.63,7.86;7,151.52,382.43,329.07,7.86;7,151.52,393.39,233.61,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,429.05,371.47,51.54,7.86;7,151.52,382.43,136.54,7.86">Neural ranking models with weak supervision</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,310.00,382.43,170.59,7.86;7,151.52,393.39,151.90,7.86">ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,404.40,337.64,7.86;7,151.52,415.36,329.07,7.86;7,151.52,426.32,329.07,7.86;7,151.52,437.28,313.92,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,267.90,415.36,212.69,7.86;7,151.52,426.32,156.51,7.86">Overview of the CLEF-2019 CheckThat!: Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,325.78,426.32,154.81,7.86;7,151.52,437.28,122.09,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,448.30,337.63,7.86;7,151.52,459.25,329.07,7.86;7,151.52,470.21,329.07,7.86;7,151.52,481.17,20.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,438.61,448.30,41.98,7.86;7,151.52,459.25,278.86,7.86">A contextaware approach for detecting worth-checking claims in political debates</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,447.52,459.25,33.07,7.86;7,151.52,470.21,263.71,7.86">International Conference Recent Advances in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,492.19,337.64,7.86;7,151.52,503.15,329.07,7.86;7,151.52,514.11,290.62,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,426.27,492.19,54.32,7.86;7,151.52,503.15,312.73,7.86">Neural checkworthiness ranking with weak supervision: Finding sentences for fact-checking</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alstrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,151.52,514.11,262.29,7.86">Companion Proceedings of the 2019 World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,525.12,337.64,7.86;7,151.52,536.08,193.52,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alstrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<title level="m" coord="7,427.88,525.12,52.71,7.86;7,151.52,536.08,136.08,7.86">Neural speed reading with structural-jump-lstm</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,547.10,337.64,7.86;7,151.52,558.05,329.07,7.86;7,151.52,569.01,179.80,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,426.45,547.10,54.14,7.86;7,151.52,558.05,140.07,7.86">Unsupervised neural generative semantic hashing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Alstrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,311.99,558.05,168.60,7.86;7,151.52,569.01,151.90,7.86">ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,580.03,337.63,7.86;7,151.52,590.99,329.07,7.86;7,151.52,601.95,329.07,7.86;7,151.52,612.91,170.03,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,389.38,580.03,91.20,7.86;7,151.52,590.99,329.07,7.86;7,151.52,601.95,329.07,7.86;7,151.52,612.91,11.14,7.86">The copenhagen team participation in the check-worthiness task of the competition of automatic identification and verification of claims in political debates of the clef-2018 fact checking lab</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,181.97,612.91,111.31,7.86">CLEF-2018 CheckThat! Lab</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,623.92,337.98,7.86;7,151.52,634.88,329.07,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.80,20.99,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,346.66,623.92,133.93,7.86;7,151.52,634.88,217.42,7.86">Toward automated fact-checking: Detecting check-worthy factual claims by claimbuster</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,391.31,634.88,89.27,7.86;7,151.52,645.84,252.36,7.86">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,119.67,337.98,7.86;8,151.52,130.63,329.07,7.86;8,151.52,141.59,329.07,7.86;8,151.52,152.55,20.99,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,435.77,119.67,44.82,7.86;8,151.52,130.63,210.61,7.86">Claimrank: Detecting check-worthy claims in arabic and english</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,382.78,130.63,97.81,7.86;8,151.52,141.59,271.54,7.86">Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,163.51,337.97,7.86;8,151.52,174.47,329.07,7.86;8,151.52,185.43,329.07,7.86;8,151.52,196.39,329.07,7.86;8,151.52,207.34,179.68,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,339.48,163.51,141.10,7.86;8,151.52,174.47,119.33,7.86">Evaluation measures for relevance and credibility in ranked lists</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,249.37,185.43,231.22,7.86;8,151.52,196.39,143.42,7.86">Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<meeting>the ACM SIGIR International Conference on Theory of Information Retrieval<address><addrLine>ICTIR; Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-10-01">2017. October 1-4, 2017. 2017</date>
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,218.30,337.98,7.86;8,151.52,229.26,329.07,7.86;8,151.52,240.22,201.21,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,317.17,218.30,163.42,7.86;8,151.52,229.26,32.07,7.86">Part of speech n-grams and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J K</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,191.90,229.26,288.69,7.86;8,151.52,240.22,94.48,7.86">French Review of Applied Linguistics, Special issue on Information Extraction and Linguistics</title>
		<imprint>
			<biblScope unit="volume">XIII</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="22" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,251.18,337.98,7.86;8,151.52,262.14,329.07,7.86;8,151.52,273.10,223.53,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,408.18,251.18,72.41,7.86;8,151.52,262.14,233.92,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,404.58,262.14,76.02,7.86;8,151.52,273.10,123.09,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,284.06,337.98,7.86;8,151.52,295.02,329.07,7.86;8,151.52,305.98,241.81,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,397.36,284.06,83.24,7.86;8,151.52,295.02,325.12,7.86">Overview of the clef-2018 checkthat! lab on automatic identification and verification of political claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,163.04,305.98,202.16,7.86">International Conference of the CLEF Association</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,316.93,337.98,7.86;8,151.52,327.89,329.07,7.86;8,151.52,338.85,265.58,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,331.84,316.93,148.75,7.86;8,151.52,327.89,215.67,7.86">Tathya: A multi-classifier system for detecting check-worthy statements in political debates</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Patwari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bagchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,386.05,327.89,94.54,7.86;8,151.52,338.85,164.38,7.86">ACM on Conference on Information and Knowledge Management</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2259" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,349.81,337.97,7.86;8,151.52,360.77,329.07,7.86;8,151.52,371.73,329.07,7.86;8,151.52,382.69,329.07,7.86;8,151.52,393.65,329.07,7.86;8,151.52,404.61,48.38,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,412.58,349.81,68.01,7.86;8,151.52,360.77,309.90,7.86">Contextual compositionality detection with external knowledge bases and word embeddings</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,286.81,382.69,193.78,7.86;8,151.52,393.65,81.51,7.86">Companion of The 2019 World Wide Web Conference, WWW 2019</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Amer-Yahia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Mahdian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Goel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Houben</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Zia</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">May 13-17, 2019. 2019</date>
			<biblScope unit="page" from="317" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,415.56,337.97,7.86;8,151.52,426.52,329.07,7.86;8,151.52,437.48,329.07,7.86;8,151.52,448.44,20.99,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,343.94,415.56,136.65,7.86;8,151.52,426.52,200.51,7.86">Neural query performance prediction using weak supervision from multiple signals</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,373.05,426.52,107.55,7.86;8,151.52,437.48,263.81,7.86">International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,459.40,337.98,7.86;8,151.52,470.36,329.07,7.86;8,151.52,481.32,20.99,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,300.77,459.40,179.83,7.86;8,151.52,470.36,190.53,7.86">A hybrid recognition system for check-worthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,363.96,470.36,112.43,7.86">CLEF-2018 CheckThat! Lab</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
