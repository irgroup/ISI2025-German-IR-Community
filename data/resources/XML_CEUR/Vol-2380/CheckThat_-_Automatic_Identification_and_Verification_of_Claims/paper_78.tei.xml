<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,168.37,116.98,278.62,12.60;1,161.93,134.92,291.50,12.60;1,250.51,152.85,114.35,12.60">The IPIPAN Team Participation in the Check-Worthiness Task of the CLEF2019 CheckThat! Lab</title>
				<funder ref="#_T3gQX8B">
					<orgName type="full">Polish National Agency for Academic Exchange</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,234.85,190.62,58.13,8.80"><forename type="first">Jakub</forename><surname>Gąsior</surname></persName>
							<email>j.gasior@ipipan.waw.plp.przybyla@ipipan.waw.pl</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Polish Academy of Sciences</orgName>
								<address>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.67,190.62,64.84,8.80"><forename type="first">Piotr</forename><surname>Przybyła</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Polish Academy of Sciences</orgName>
								<address>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,168.37,116.98,278.62,12.60;1,161.93,134.92,291.50,12.60;1,250.51,152.85,114.35,12.60">The IPIPAN Team Participation in the Check-Worthiness Task of the CLEF2019 CheckThat! Lab</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">65993B3A001F3B4098F7526E98EE2DDC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>Fact-checking</term>
					<term>Logistic regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the IPIPAN team at the CLEF-2019 CheckThat! Lab focused on automatic identification and verification of claims. We participated in Task 1 oriented on assessing the check-worthiness of claims in political debate by identifying and ranking, which sentences should be prioritized for fact-checking. We proposed a logistic regression-based classifier using features such as vector representation of sentences, Part-of-Speech (POS) tags, named entities, and sentiment scores. In the official evaluation, our best performing run was ranked 3 rd out of 12 teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent spread of misinformation in political debates and media has stimulated further research in fact-checking: the task of assessing the truthfulness of a claim.</p><p>The CLEF-2019 CheckThat! Lab <ref type="bibr" coords="1,304.09,490.54,10.52,8.80" target="#b5">[6]</ref> aims at streamlining a typical factchecking pipeline consisting of the following steps:</p><p>-Identifying check-worthy text fragments (Task 1) <ref type="bibr" coords="1,369.11,523.19,9.96,8.80" target="#b3">[4]</ref>; -Retrieving and supporting evidence for the selected claims (Task 2A) <ref type="bibr" coords="1,457.39,535.33,9.96,8.80" target="#b6">[7]</ref>; -Determining whether the claim is likely true or likely false by comparing a claim against the retrieved evidence (Task 2B) <ref type="bibr" coords="1,358.45,559.43,9.96,8.80" target="#b6">[7]</ref>.</p><p>This report details our proposed methods and results for Task 1, where we focused on the English part <ref type="bibr" coords="1,264.69,591.89,9.96,8.80" target="#b3">[4]</ref>. The overall aim of this task was to identify check-worthy claims and rank them according to perceived worthiness for factchecking.</p><p>The remainder of this paper is organized as follows: In Section 2, we present the works related to the task of identifying check-worthy claims and fact-checking itself. In Section 3, we provide a detailed description of the task, discuss the datasets and performance metrics. Section 4 details the proposed approach and the evaluation results. Finally, Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">State of the Art</head><p>Automating the process of fact-checking has been first discussed in the context of computational journalism <ref type="bibr" coords="2,261.68,237.73,9.96,8.80" target="#b4">[5]</ref>, where authors outline a vision for a system to support mass collaboration of investigative journalists and concerned citizens. They discuss several features of the system to highlight a few important database research challenges such as privacy, trust, authority, data mining and information retrieval.</p><p>Thorne and Vlachos <ref type="bibr" coords="2,240.75,297.73,15.50,8.80" target="#b15">[16]</ref> survey automated fact-checking research stemming from natural language processing and related disciplines, unifying the task formulations and methodologies across papers and authors. Similar work in the area of political debate was introduced in <ref type="bibr" coords="2,320.96,333.59,14.61,8.80" target="#b17">[18]</ref>. Authors detail the construction of a publicly available dataset using statements fact-checked by journalists available online and discuss baseline approaches for the challenges that need to be addressed. Similar datasets were later released <ref type="bibr" coords="2,342.70,369.46,15.50,8.80" target="#b12">[13,</ref><ref type="bibr" coords="2,361.92,369.46,11.62,8.80" target="#b18">19]</ref>, where authors collated labeled claims from Politifact. Wang created a dataset of almost 13 thousand claims with additional meta-data such as the speaker affiliation and the context in which the claim appears <ref type="bibr" coords="2,254.68,405.33,14.61,8.80" target="#b18">[19]</ref>. Rashkin and Choi later supplemented the Politifact dataset with numerous news articles deemed as hoax according to a US News &amp; World report in order to build a prediction model <ref type="bibr" coords="2,392.63,429.24,14.61,8.80" target="#b12">[13]</ref>.</p><p>One of the biggest datasets of this kind was released in <ref type="bibr" coords="2,396.86,441.41,14.61,8.80" target="#b16">[17]</ref>, where authors presented a dataset containing over 185 thousand claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. These claims were later classified as Supported, Refuted or NotEnoughInfo by annotators achieving 31.87% accuracy on labeling a claim accompanied by the correct evidence and 50.91% accuracy, while ignoring the evidence.</p><p>Similar work was introduced by Redi and Fetahu <ref type="bibr" coords="2,359.36,525.32,14.61,8.80" target="#b13">[14]</ref>, where authors provided an algorithmic assessment of Wikipedia's verifiability. They provided algorithmic models to determine if a statement requires a citation, and to predict the citation reason based on custom taxonomy. Authors provided a complete evaluation of the robustness of proposed models across different classes of Wikipedia articles of varying quality, as well as on an additional dataset of claims annotated for fact-checking. Unfortunately, the model could not reliably detect check-worthy claims in the datasets, labeling most of them as negatives.</p><p>One of the first complete tools in the area of assessing check-worthiness was provided in <ref type="bibr" coords="2,190.48,633.14,10.52,8.80" target="#b7">[8,</ref><ref type="bibr" coords="2,205.86,633.14,7.01,8.80" target="#b8">9]</ref>, where authors proposed the ClaimBuster: a fact-checking platform, using natural language processing and supervised learning to detect important factual claims in political discourses. ClaimBuster uses a sentiment, sentence length, Part-of-Speech (POS) tags and entity types as features in order to rank claims from the least to the most check-worthy. Authors claim average accuracy for sentences fact-checked by CNN of 0.433 and 0.438 for sentences fact-checked by PolitiFact.</p><p>A similar tool was introduced in <ref type="bibr" coords="3,298.93,167.75,14.61,8.80" target="#b9">[10]</ref>, where authors presented the Claim-Rank: a multilingual automatic system to detect check-worthy claims in a given text. A model is trained on annotations from nine reputable fact-checking organizations (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post), and thus it can mimic the optimal claim selection strategies. Authors achieved the Mean Average Precision score of 0.323 for English and 0.302 for Arabic.</p><p>Finally, in <ref type="bibr" coords="3,195.04,251.44,15.50,8.80" target="#b10">[11]</ref> authors present an approach based on universal sentence representations created in collaboration with Full Fact, an independent fact-checking charity. Authors claim an F1 score of 0.83, with 5% relative improvement over the state-of-the-art methods ClaimBuster and ClaimRank, discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Description</head><p>The objective of the task was to identify check-worthy claims in order to facilitate manual fact-checking efforts by prioritizing the claims that fact-checkers should consider first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>The task organizers provided two datasets: a training set comprised of 19 political debates and speeches (a total 16421 sentences) and a testing set comprised of 7 files (a total of 7080 sentences). Each file was annotated by its speaker and check-worthiness factor (0 or 1) as determined by experts.</p><p>The training set contained 440 annotated check-worthy sentences (2.68% of total), while the final testing set contained only 136 check-worthy sentences (1.92% of total).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation metrics</head><p>The task was evaluated according to the following metrics:</p><p>-Average Precision -Precision at N , estimated for N check-worthy sentences and then averaged over the total number of check-worthy sentences; -Reciprocal Rank -The reciprocal of the rank of the first check-worthy sentence in the list of predictions sorted by score (in descending order); -Precision@N -Precision estimated for the first N sentences in the provided ranked list; -R-Precision -Precision at R, where R is the number of relevant sentences for the evaluated set.</p><p>The official measure ranking the submission of teams was the Mean Average Precision (MAP), calculated over multiple provided debates (each with its own separate prediction file).</p><p>In this section, we describe the details of our approach and present the evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Design and Selection</head><p>The features we extracted for each sentence in the database can be divided into the following categories:</p><p>-Bag-of-Words N-Gram Representation of Sentences: The first step was vocabulary-based vectorization. We employed term frequency-inverse document frequency (TF-IDF) transformation and extracted and built the n-gram model (up to 3) of the dataset. After pruning the most common terms, we ended up with 1006 unigram features, 1177 bigram features, and 1186 trigram features. -Vector Representation of Sentences: We employed word2vec tool to a text corpus as input and produced the word vectors as output. We used a model pretrained on Google News archive <ref type="bibr" coords="4,351.24,364.53,9.96,8.80" target="#b0">[1]</ref>. To represent sentences in the provided dataset, we first create 300-dimensional vectors components for each term in the sentence and then select 300 minimal, 300 maximal, and 300 averaged values resulting in a features vector of 900 elements. -Types of Named Entities Detected: The process of recognizing named entities is one the first step towards information extraction that seeks to locate and classify entities in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages. We employ the NLTK library <ref type="bibr" coords="4,416.05,461.57,10.52,8.80" target="#b1">[2]</ref> to extract a subset of 18 NER tags for each sentence. -Part-of-Speech (POS) Tags: We employ the NLTK's library POS tagger <ref type="bibr" coords="4,151.70,498.84,10.52,8.80" target="#b1">[2]</ref> to mark up individual words in a sentence as corresponding to a particular Penn Treebank Constituent Tag, based on both its definition and relationship with adjacent and related words in a sentence. It results in a 36-dimensional feature vector. -Sentiment Scores: To determine the sentiment of each sentence we use BING, AFINN and NRC Lexicons <ref type="bibr" coords="4,303.87,560.01,10.52,8.80" target="#b2">[3]</ref> to extract the sentiment score of each term in the sentence, as well as an averaged sentiment score of the whole sentence. It results in a feature vector consisting of 15 elements (11 tags from NRC indicating feelings or emotions, i.e., anger, fear, joy; 2 tags from BING and AFINN; and an overall averaged sentiment of the whole sentence.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>-Statistical Analysis of Sentences:</head><p>We also calculate basic metrics of each sentence after tokenization, such as word count, character count, average word density, punctuation count, upper case count, and title word count. It results in a feature vector consisting of 6 elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Classifier</head><p>As our classifier, we selected a L1-regularized logistic regression model (LASSO) or so-called sparse logistic regression model, where the weight vector of the classifier has a small number of nonzero values. By adding the penalty on the weights w:</p><formula xml:id="formula_0" coords="5,249.27,195.97,227.08,16.13">argmin w,v l avg (w, v) + λ||w|| 1 , (<label>1</label></formula><formula xml:id="formula_1" coords="5,476.35,195.97,4.24,8.80">)</formula><p>where λ is a regularization parameter, it is possible to achieve attractive properties such as feature selection and robustness to noise <ref type="bibr" coords="5,395.73,229.34,15.50,8.80" target="#b11">[12,</ref><ref type="bibr" coords="5,414.55,229.34,12.73,8.80" target="#b14">15,</ref><ref type="bibr" coords="5,430.60,229.34,11.62,8.80" target="#b19">20]</ref>.</p><p>We carried out multiple evaluating runs with different subsets of features discussed in Section 4.1 in order to select the best combination of dependent variables. In order to select the best model to employ in the testing phase, we performed a Leave-One-Out (LOO) cross validation on the whole set of N = 19 training debates for various combinations of selected features -training the model on the set of N -1 debates and testing it on the last one. This process was repeated N times.</p><p>Table <ref type="table" coords="5,176.30,324.99,4.98,8.80" target="#tab_0">1</ref> shows the results of Mean Average Precision, Reciprocal Rank and R-Precision metrics achieved during the training phase. As can be seen, none of the analyzed models achieved maximum scores in all measured performance metrics. As a result, top scoring models for each performance metric were selected for the final submission, i. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Final Results</head><p>Twelve teams submitted a total of 25 runs to this task. Table <ref type="table" coords="5,417.87,453.82,4.98,8.80" target="#tab_1">2</ref> presents the results of our three submission runs as well as the top-ranked submission from the Copenhagen team.</p><p>Overall, our primary submission has been ranked third according to the official measure (Mean Average Precision), sixth according to Reciprocal Rank, and second according to R-Precision score. These results allow us to conclude, that the proposed model was better at finding the most check-worthy claims, than at a task of finding all the check-worthy claims in the provided texts. The precise reasons for such behavior will require further analysis.</p><p>Surprisingly, our best performing model was one of the contrastive runs, employing text vectors and POS tags as the only selection features. Our primary submission used also NER tags and sentiment scores, which had a negative impact on Mean Average Precision and Reciprocal Rank scores.</p><p>We can conclude that this result is caused by a lower representation of NER features in the final testing set. Also, further analysis of the testing set revealed that most of the check-worthy claims had significantly more positive sentiment scores than the claims in the training dataset (see, Table <ref type="table" coords="5,383.77,645.10,3.87,8.80" target="#tab_2">3</ref>). This also impacted the overall performance of the submitted primary model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we present our solution to Task 1 of the CLEF-2019 Check-That! Lab. For the task of detecting check-worthy claims, we employed an L1regularized logistic regression (LASSO) classifier. We selected features such as vector representation, named entities, POS tags, as well as averaged sentiment values achieving 3 rd place on the English dataset. This work opens up several possible avenues for future research. First, we intend to employ syntactic parsing and sentence dependency mapping in order to extract additional information regarding the stance of claims, as well as contradicting or confirming sentences during debates. Secondly, we plan to extend the vector representation of sentences to larger segments of text in order to capture additional nuances of longer debates or speeches. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,233.56,372.81,9.30,8.80;5,140.99,389.14,302.57,8.90;5,140.99,400.18,272.19,8.90;5,140.99,411.22,319.86,8.90"><head></head><label></label><figDesc>e.: -Text2vec + NER + POS + Sentiment -Primary submission; -Text2vec + N-Gram (2) -Contrastive submission No. 1; -N-Gram (1) + NER + Sentiment -Contrastive submission No. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,136.16,128.20,351.53,336.11"><head>Table 1 :</head><label>1</label><figDesc>Mean Average Precision, Reciprocal Rank and R-Precision scores for each model across the provided training datasets. The best results are marked in a bold font.</figDesc><table coords="6,308.06,165.30,179.63,20.85"><row><cell>Mean Average</cell><cell>Reciprocal</cell><cell>R-</cell></row><row><cell>Precision</cell><cell>Rank</cell><cell>Precision</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,136.16,128.20,347.92,136.06"><head>Table 2 :</head><label>2</label><figDesc>Mean Average Precision, Reciprocal Rank and R-Precision scores for each model across the provided testing datasets. The best results are marked in a bold font, while the best results from our submissions are underlined.</figDesc><table coords="7,136.16,177.26,347.92,87.00"><row><cell></cell><cell>Mean Average</cell><cell>Reciprocal</cell><cell>R-</cell></row><row><cell></cell><cell>Precision</cell><cell>Rank</cell><cell>Precision</cell></row><row><cell>Text2vec + NER + POS +</cell><cell>.1332</cell><cell>.2864</cell><cell>.1481</cell></row><row><cell>Sentiment (primary)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Text2vec + N-Gram (2)</cell><cell>.1365</cell><cell>.3079</cell><cell>.1490</cell></row><row><cell>N-Gram (1) + NER + Sentiment</cell><cell>.1013</cell><cell>.2791</cell><cell>.1002</cell></row><row><cell>Copenhagen (primary)</cell><cell>.1660</cell><cell>.4176</cell><cell>.1387</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,136.16,290.80,324.31,97.01"><head>Table 3 :</head><label>3</label><figDesc>Average sentiment scores (negative, positive and overall) calculated for check-worthy sentences in training and testing datasets, respectively.</figDesc><table coords="7,136.16,327.90,324.31,59.90"><row><cell></cell><cell>Negative</cell><cell>Overall</cell><cell>Positive</cell></row><row><cell></cell><cell>Sentiment</cell><cell>Sentiment</cell><cell>Sentiment</cell></row><row><cell>Training</cell><cell>-2.06676</cell><cell>0.017379</cell><cell>1.23742</cell></row><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Testing Dataset</cell><cell>-0.97227</cell><cell>0.045449</cell><cell>1.04570</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This work was supported by the <rs type="funder">Polish National Agency for Academic Exchange</rs> through a <rs type="grantName">Polish Return</rs> grant number <rs type="grantNumber">PPN/PPO/2018/1/00006</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_T3gQX8B">
					<idno type="grant-number">PPN/PPO/2018/1/00006</idno>
					<orgName type="grant-name">Polish Return</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,154.09,557.50,326.51,8.17;7,154.08,567.36,45.57,7.92" xml:id="b0">
	<monogr>
		<ptr target="https://code.google.com/archive/p/word2vec/" />
		<title level="m" coord="7,154.09,557.50,70.56,7.92">Word2vec Project</title>
		<imprint>
			<date type="published" when="2019-05-24">2019-05-24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,154.09,577.63,303.36,8.17" xml:id="b1">
	<monogr>
		<ptr target="https://www.nltk.org/" />
		<title level="m" coord="7,154.09,577.63,103.21,7.92">Natural Language Toolkit</title>
		<imprint>
			<date type="published" when="2019-05-24">2019-05-24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,154.09,587.89,186.76,7.92;7,362.91,588.69,117.68,7.37;7,154.08,597.76,244.90,8.17" xml:id="b2">
	<monogr>
		<ptr target="https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm" />
		<title level="m" coord="7,154.09,587.89,182.55,7.92">NRC Word-Emotion Association Lexicon</title>
		<imprint>
			<date type="published" when="2019-05-24">2019-05-24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,154.09,608.02,326.51,7.92;7,154.08,617.89,326.51,7.92;7,154.08,627.75,274.42,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,246.53,617.89,234.06,7.92;7,154.08,627.75,159.84,7.92">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgi</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">San</forename><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,321.31,627.75,19.00,7.92">Task</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Check-Worthiness</note>
</biblStruct>

<biblStruct coords="7,154.09,638.02,326.51,7.92;7,154.08,647.88,326.51,7.92;7,154.08,657.74,240.17,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,370.31,638.02,110.29,7.92;7,154.08,647.88,167.70,7.92">Computational Journalism: A Call to Arms to Database Researchers</title>
		<author>
			<persName coords=""><forename type="first">Sarah</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,344.78,647.88,135.81,7.92;7,154.08,657.74,136.62,7.92">Proceedings of the Conference on Innovative Data Systems Research</title>
		<meeting>the Conference on Innovative Data Systems Research</meeting>
		<imprint>
			<date type="published" when="2011-04">04 2011</date>
			<biblScope unit="page" from="148" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.09,120.62,326.50,7.92;8,154.08,130.48,326.51,7.92;8,154.08,140.34,326.51,7.92;8,154.08,150.21,326.51,7.92;8,154.08,160.07,119.34,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,387.80,130.48,92.79,7.92;8,154.08,140.34,278.18,7.92">Overview of the CLEF-2019 CheckThat!: Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.63,140.34,28.96,7.92;8,154.08,150.21,257.02,7.92">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.09,169.49,326.51,7.92;8,154.08,179.35,326.51,7.92;8,154.08,189.21,281.71,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,218.00,179.35,262.60,7.92;8,154.08,189.21,142.43,7.92">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reem</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,303.91,189.21,128.04,7.92">Task 2: Evidence and Factuality</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.09,198.63,326.51,7.92;8,154.08,208.49,326.51,7.92;8,154.08,218.36,326.51,7.92;8,154.08,228.22,326.51,7.92;8,154.08,238.08,326.51,8.17;8,154.08,248.74,35.51,7.37" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,381.81,198.63,98.79,7.92;8,154.08,208.49,161.45,7.92">Detecting Check-worthy Factual Claims in Presidential Debates</title>
		<author>
			<persName coords=""><forename type="first">Naeemul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Tremayne</surname></persName>
		</author>
		<idno type="DOI">10.1145/2806416.2806652</idno>
		<ptr target="http://doi.acm.org/10.1145/2806416.2806652" />
	</analytic>
	<monogr>
		<title level="m" coord="8,341.44,208.49,139.15,7.92;8,154.08,218.36,326.51,7.92;8,154.08,228.22,10.75,7.92">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.09,257.36,326.51,7.92;8,154.08,267.23,326.51,7.92;8,154.08,277.09,326.51,7.92;8,154.08,286.95,326.51,7.92;8,154.08,296.82,326.51,7.92;8,154.08,307.48,200.27,7.37" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,432.52,257.36,48.08,7.92;8,154.08,267.23,322.08,7.92">Toward Automated Fact-Checking: Detecting Check-worthy Factual Claims by ClaimBuster</title>
		<author>
			<persName coords=""><forename type="first">Naeemul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fatma</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Tremayne</surname></persName>
		</author>
		<idno type="DOI">10.1145/3097983.3098131</idno>
		<ptr target="http://doi.acm.org/10.1145/3097983.3098131" />
	</analytic>
	<monogr>
		<title level="m" coord="8,166.56,277.09,314.03,7.92;8,154.08,286.95,179.31,7.92">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,316.10,326.51,7.92;8,154.08,325.96,326.51,7.92;8,154.08,335.82,326.51,7.92;8,154.08,345.69,326.51,7.92;8,154.08,355.55,326.51,7.92;8,154.08,365.41,316.85,8.17" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,220.09,325.96,260.50,7.92;8,154.08,335.82,17.54,7.92">ClaimRank: Detecting Check-Worthy Claims in Arabic and English</title>
		<author>
			<persName coords=""><forename type="first">Israa</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-5006</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-5006" />
	</analytic>
	<monogr>
		<title level="m" coord="8,193.08,335.82,287.51,7.92;8,154.08,345.69,249.35,7.92">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<title level="s" coord="8,284.18,355.55,171.24,7.92">Association for Computational Linguistics</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,374.83,326.52,7.92;8,154.08,384.69,326.51,7.92;8,154.08,394.56,326.51,7.92;8,154.08,404.42,171.01,8.17" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,467.02,374.83,13.57,7.92;8,154.08,384.69,326.51,7.92;8,154.08,394.56,197.57,7.92">Towards Automated Factchecking: Developing an Annotation Schema and Benchmark for Consistent Automated Claim Detection</title>
		<author>
			<persName coords=""><forename type="first">Lev</forename><surname>Konstantinovskiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oliver</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mevan</forename><surname>Babakar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno>CoRR, abs/1809.08193</idno>
		<ptr target="http://arxiv.org/abs/1809.08193" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,413.84,326.51,7.92;8,154.08,423.70,326.51,7.92;8,154.08,433.56,326.51,7.92;8,154.08,443.43,326.51,8.17;8,154.08,454.09,96.71,7.37" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,221.68,413.84,258.92,7.92;8,154.08,423.70,31.65,7.92">Feature Selection, L1 vs. L2 Regularization, and Rotational Invariance</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1145/1015330.1015435</idno>
		<ptr target="http://doi.acm.org/10.1145/1015330.1015435" />
	</analytic>
	<monogr>
		<title level="m" coord="8,211.01,423.70,269.58,7.92;8,154.08,433.56,104.88,7.92">Proceedings of the Twenty-first International Conference on Machine Learning, ICML &apos;04</title>
		<meeting>the Twenty-first International Conference on Machine Learning, ICML &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">78</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,462.71,326.51,7.92;8,154.08,472.57,326.51,7.92;8,154.08,482.43,326.51,7.92;8,154.08,492.30,326.51,7.92;8,154.08,502.16,326.51,7.92;8,154.08,512.82,196.06,7.37" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,154.08,472.57,326.51,7.92;8,154.08,482.43,32.54,7.92">Truth of varying shades: Analyzing language in fake news and political factchecking</title>
		<author>
			<persName coords=""><forename type="first">Eunsol</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jin</forename><forename type="middle">Yea</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Svitlana</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yejin</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1317</idno>
		<ptr target="https://www.aclweb.org/anthology/D17-1317" />
	</analytic>
	<monogr>
		<title level="m" coord="8,205.43,482.43,275.16,7.92;8,154.08,492.30,81.26,7.92">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<title level="s" coord="8,154.08,502.16,173.03,7.92">Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="2931" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,521.44,326.51,7.92;8,154.08,531.30,326.51,7.92;8,154.08,541.17,294.07,8.17" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="8,447.32,521.44,33.28,7.92;8,154.08,531.30,322.96,7.92">Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia&apos;s Verifiability</title>
		<author>
			<persName coords=""><forename type="first">Miriam</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Besnik</forename><surname>Fetahu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dario</forename><surname>Taraborelli</surname></persName>
		</author>
		<idno>CoRR, abs/1902.11116</idno>
		<ptr target="http://arxiv.org/abs/1902.11116" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,550.58,326.50,7.92;8,154.08,560.45,326.51,7.92;8,154.08,570.31,326.51,8.17;8,154.08,580.97,73.17,7.37" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,379.66,550.58,100.92,7.92;8,154.08,560.45,200.56,7.92">A Fast Hybrid Algorithm for Large-Scale L1-Regularized Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">Jianing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wotao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stanley</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Sajda</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1756006.1756029" />
	</analytic>
	<monogr>
		<title level="j" coord="8,361.92,560.45,82.03,7.92">J. Mach. Learn. Res</title>
		<idno type="ISSN">1532-4435</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="713" to="741" />
			<date type="published" when="2010-03">March 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,589.59,326.51,7.92;8,154.08,599.45,326.51,7.92;8,154.08,610.11,148.49,7.37" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="8,315.39,589.59,165.20,7.92;8,154.08,599.45,160.45,7.92">Automated Fact Checking: Task formulations, methods and future directions</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<idno>CoRR, abs/1806.07687</idno>
		<ptr target="http://arxiv.org/abs/1806.07687" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,618.73,326.51,7.92;8,154.08,628.60,326.51,7.92;8,154.08,638.46,263.72,8.17" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="8,171.88,628.60,272.73,7.92">FEVER: a large-scale dataset for Fact Extraction and VERification</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
		<idno>CoRR, abs/1803.05355</idno>
		<ptr target="http://arxiv.org/abs/1803.05355" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,154.08,647.88,326.51,7.92;8,154.08,657.74,326.51,7.92;9,154.08,120.62,326.51,7.92;9,154.08,130.48,326.51,7.92;9,154.08,141.14,196.06,7.37" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,311.36,647.88,169.23,7.92;8,154.08,657.74,48.27,7.92">Fact Checking: Task definition and dataset construction</title>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-2508</idno>
		<ptr target="https://www.aclweb.org/anthology/W14-2508" />
	</analytic>
	<monogr>
		<title level="m" coord="8,223.35,657.74,257.24,7.92;9,154.08,120.62,154.25,7.92">Proceedings of the ACL 2014 Workshop on Language Technolo-gies and Computational Social Science</title>
		<title level="s" coord="9,177.19,130.48,165.96,7.92">Association for Computational Linguistics</title>
		<meeting>the ACL 2014 Workshop on Language Technolo-gies and Computational Social Science<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.08,150.21,326.52,7.92;9,154.08,160.07,326.51,8.17;9,154.08,170.73,68.46,7.37" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,247.75,150.21,232.85,7.92;9,154.08,160.07,84.94,7.92">Liar, Liar Pants on Fire&quot;: A New Benchmark Dataset for Fake News Detection</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wang</forename></persName>
		</author>
		<idno>CoRR, abs/1705.00648</idno>
		<ptr target="http://arxiv.org/abs/1705.00648" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.08,179.79,326.52,7.92;9,154.08,189.66,326.51,8.17;9,154.08,200.32,148.49,7.37" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,249.14,179.79,161.09,7.92">On Model Selection Consistency of Lasso</title>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Yu</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1248547.1248637" />
	</analytic>
	<monogr>
		<title level="j" coord="9,417.29,179.79,63.30,7.92;9,154.08,189.66,15.70,7.92">J. Mach. Learn. Res</title>
		<idno type="ISSN">1532-4435</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2541" to="2563" />
			<date type="published" when="2006-12">December 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
