<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,175.29,115.96,264.77,12.62;1,176.38,133.89,262.59,12.62;1,214.68,151.82,186.00,12.62;1,146.70,171.87,321.96,10.52;1,243.88,185.82,127.59,10.52">Using External Knowledge Bases and Coreference Resolution for Detecting Check-Worthy Statements CLEF-2019 Shared Task: Automatic Identification and Verification of Claims</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.52,222.06,57.31,8.74"><forename type="first">Salar</forename><surname>Mohtaj</surname></persName>
							<email>salar.mohtaj@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Quality and Usability Lab</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.39,222.06,79.21,8.74"><forename type="first">Tilo</forename><surname>Himmelsbach</surname></persName>
							<email>tilo.himmelsbach@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Quality and Usability Lab</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.97,234.01,79.81,8.74"><forename type="first">Vinicius</forename><surname>Woloszyn</surname></persName>
							<email>woloszyn@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Quality and Usability Lab</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.72,234.01,72.86,8.74"><forename type="first">Sebastian</forename><surname>Möller</surname></persName>
							<email>sebastian.moeller@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Quality and Usability Lab</orgName>
								<orgName type="institution">Technische Universität Berlin</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">DFKI Projektbüro Berlin Berlin</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,175.29,115.96,264.77,12.62;1,176.38,133.89,262.59,12.62;1,214.68,151.82,186.00,12.62;1,146.70,171.87,321.96,10.52;1,243.88,185.82,127.59,10.52">Using External Knowledge Bases and Coreference Resolution for Detecting Check-Worthy Statements CLEF-2019 Shared Task: Automatic Identification and Verification of Claims</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">77173F1CD0D5DA58E7CDC097203C9790</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fact-checking</term>
					<term>check-worthiness</term>
					<term>fake news</term>
					<term>coreference resolution</term>
					<term>political debates</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the proliferation of online information sources, it has become more and more difficult to judge the trustworthiness of a statement on the Web. Nevertheless, recent advances in natural language processing allow us to analyze information more objectively according to certain criteria -e.g. whether a proposition is factual or opinative, or even the authority or credibility of an author in a certain topic. In this paper, we formulated a ranking schema that can be employed in textual claims for speeding up the human fact-checking process. Our experiments have shown that our proposed method statistically outperformed the baseline. Additionally, this work describes a multilingual data set of claims collected from several fact-check websites, which was used to fine-tuning our model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The 2016 American presidential elections were a source of growing public awareness of what has since been denominated as "fake news". The term started to be used in different positions within the social space as a means of discrediting, attacking and delegitimizing political opponents. However, the task of assessing the credibility of a claim is time-consuming for the user. For example, Kumar's work <ref type="bibr" coords="1,158.61,614.24,15.50,8.74" target="#b12">[12]</ref> reports that even humans are not able to always distinguish hoax from authentic claims and that quite a few people could differentiate satirical articles from true news.</p><p>With the increasing number of false claims and rumors, fact-checking websites like snopes.com, politifact.com, fullfact.org, have become popular. These websites compile articles written by experts who manually investigate controversial claims to determine their veracity, providing shreds of evidence for the verdict (e.g. true or false). However, with the quick proliferation of such false statements, especially in the context of a political debate, it becomes very difficult for a single person to assess the validity of all claims made.</p><p>In this paper, our team " É Proibido Cochilar"(" É Proibido Cochilar" is the title of a Brazilian song and means "it is forbidden to take a nap") have put forward a new supervised worthiness-rank of the checking of a claim. Additionally to the Presidential debates in the 2016 US campaign <ref type="bibr" coords="2,402.53,262.90,13.70,8.74" target="#b3">[3]</ref>, we have also created a large multilingual data set of statements extracted from several different fact-checking websites. The experiments have shown that our proposed method statistically outperformed the baseline in terms of imitating the human experts judging about the Worthiness of checking a claim.</p><p>The remainder of this paper is organized as follows. Section 2 discusses previous works on fake News detection. Section 3 presents details of our approach. Section 4 and 5 describe the design of our experiments and the results. Section 6 summarizes our conclusions and presents future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Several studies have addressed the task of assessing the credibility of a claim. For instance, Popat et al. <ref type="bibr" coords="2,229.14,428.75,15.50,8.74" target="#b16">[16]</ref> proposed a new approach to identify the credibility of a claim in a text. For a certain claim, it retrieves the corresponding articles from News and/or social media and feeds those into a distantly supervised classifier for assessing their credibility. Experiments with claims from the website snopes.com and from popular cases of Wikipedia hoaxes demonstrate the viability of Popat et al proposed methods. Another example is TrustRank <ref type="bibr" coords="2,381.40,488.52,9.96,8.74" target="#b9">[9]</ref>. This work presents a semi-supervised approach to separate reputable good pages from spam. To discover good pages it relies on an observation that good pages seldom point to bad ones, i.e. people creating good pages have little reason to point to bad pages. Finally, it employs a biased PageRank using this empirical observation to discover other pages that are likely to be good.</p><p>Controversial subjects can also be indicative of dispute or debate involving different opinions about the same subject. Detect and alert users when they are reading a controversial web-page is one way to make users aware of the information quality they are consuming. One example of controversy detection is <ref type="bibr" coords="2,134.77,608.30,10.52,8.74" target="#b6">[6]</ref> which relies on supervised k-nearest-neighbor classification that maps a webpage into a set of neighboring controversial articles extracted from Wikipedia. In this approach, a page adjacent to controversial pages is likely to be controversial itself. Another work in this sense is <ref type="bibr" coords="2,288.70,644.16,15.50,8.74" target="#b13">[13]</ref> which aims to generate contrastive summaries of different viewpoints in opinionated texts. It proposes a comparative LexRank, that relies on random walk formulation to give a score to a sentence based on their difference to other sentences.</p><p>Factuality Assessment is another way to asses the information quality. Yu et al.'s work <ref type="bibr" coords="3,189.49,160.62,15.50,8.74" target="#b21">[21]</ref> aims to separate opinions from facts, at both the document and sentence level. It uses a Bayesian classifier for discriminating between documents with a preponderance of opinions, such as editorials from regular news stories. The main goal of this approach is to classify a document/sentence in factual or opinionated text from the perspective of the author. The evaluation of the proposed system reported promising results in both document and sentence levels. Other work on the same line is <ref type="bibr" coords="3,290.80,232.35,14.61,8.74" target="#b17">[17]</ref>, which proposes a two-stage framework to extract opinionated sentences from news articles. In the first stage, a supervised learning model gives a score to each sentence based on the probability of the sentence to be opinionated. In the second stage, it uses these probabilities within the HITS schema to treat the opinionated sentences as Hubs, and the facts around these opinions are treated as the Authorities. The proposed method extracts opinions, grouping them with supporting facts as well as other supporting opinions.</p><p>There are also some works that analyze how a piece of information flows over the internet. For instance, <ref type="bibr" coords="3,276.93,345.71,10.52,8.74" target="#b7">[7]</ref> presents an interesting analysis about how Twitter bots can send spam tweets, manipulate public opinion and use them for online fraud. It reports the discovery of the 'Star Wars' botnet on Twitter, which consists of more than 350,000 bots tweeting random quotations exclusively from Star Wars novels. It analyzes and reveals rich details on how the botnet is designed and gives insights on how to detect virality in Twitter.</p><p>Other works analyze the writing style in order to detect a false claim. <ref type="bibr" coords="3,450.62,423.21,15.50,8.74" target="#b10">[10]</ref> reports that fake news in most cases are more similar to satire than to real news, leading us to conclude that persuasion in the fake news is achieved through heuristics rather than the strength of arguments. It shows that the overall title structure and the use of proper nouns in titles are very significant in differentiating fake from real. It gives an idea that fake news is targeted for audiences who are not likely to read beyond titles and that they aim at creating mental associations between entities and claims. Decrease the readability of texts is also another way to overshadow false claims on the internet. Many automatic methods to evaluate the readability of texts have been proposed. For instance, Coh-Metrix <ref type="bibr" coords="3,187.82,542.76,9.96,8.74" target="#b8">[8]</ref>, which is a computational tool that measures cohesion, discourse, and text difficulty.</p><p>Most of the works just cited rely on supervised learning strategies addressed to assess News articles using few different aspects, such as credibility, controversy, factuality and virality of information. Nonetheless, a common drawback of supervised learning approaches is that the quality of the results is heavily influenced by the availability of a large, domain-dependent annotated corpus to train the model. Unsupervised and semi-supervised learning techniques, on the other hand, are attractive because they do not imply the cost of corpus annotation. In short, our method uses a semi-supervised strategy where only a small set of unreliable News websites is used to spot another bad News websites using a biased PageRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head><p>In order to rank statements according to their estimated check-worthiness, we relied on an important empirical observation: there is a significant number of claims with pronouns referring back to nouns mentioned in previous statements. For example, "I beat her, and I beat her badly. She's raising your taxes really high"; the pronouns her and she refer to the same person, namely Hillary Clinton. More examples are given in table <ref type="table" coords="4,321.13,248.12,3.87,8.74" target="#tab_0">1</ref>. Sentences that contain pronouns are normally an issue for statistical models and can significantly decrease the quality of prediction. To overcome this issue, a coreference resolution technique is applied to replace pronouns with their original references. We used a feed-forward neural-network to compute the coreference score for each pair of potential mentions <ref type="bibr" coords="4,345.16,451.62,9.96,8.74" target="#b1">[1]</ref>, e.g. Hillary Clinton ← she. We have considered the last 30 sentences (slide-window) to compute the coreferences. Table <ref type="table" coords="4,199.26,475.53,4.98,8.74">2</ref> illustrates the coreference resolution of the examples presented in Table <ref type="table" coords="4,173.84,487.48,3.87,8.74" target="#tab_0">1</ref>. To resolve coreferences leads to more clear-cut statements, which in our experiments improved the performance of our predictions.</p><p>Table <ref type="table" coords="4,168.99,531.25,4.13,7.89">2</ref>. The result of applying coreference resolution on the sentences in Table <ref type="table" coords="4,468.11,531.28,3.58,7.86" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speaker Sentence</head><p>Label SANDERS Millions of Americans are working longer hours for low wages. Additionally, we have performed a normalization of the corpus using standard techniques: lowercasing, lemmatization, number removal, white-space removal, stop-word removal, and tokenization. In addition to preparing the data set to the training phase, we used some external fact-checking collection to tackle some issues in the provided data set. Firstly, since the provided data is highly imbalanced (less than 3% of data are labeled as 1), we provide external data to make the data more balanced. Moreover, it can lead to an improved generalization of the classification model if the training data is more diverse. To add the external data-set to the training data same pre-processing steps includes in coreference resolution, are applied on the data.</p><p>For this purpose, we have created a tool -called Fake News Extractor[2] -to automatically extract claims from Fact-Checking websites and then consolidate a large data set for machine learning purposes. It extracts claims in three different languages: English, Portuguese and German. Table <ref type="table" coords="5,426.07,250.57,4.98,8.74">3</ref> gives some statistics about the data set created by our tool.</p><p>We have used Support Vector Machine Regression (SVM) <ref type="bibr" coords="5,416.58,481.73,15.50,8.74" target="#b18">[18]</ref> and Term Frequency-Inverse Document Frequency (TF-IDF). Additionally, we have used Scikit-Learn <ref type="bibr" coords="5,191.33,505.64,15.50,8.74" target="#b14">[14]</ref> library for feature extracting, for example uni-gram, bi-grams and tri-grams. In a nutshell, the main contributions to tackle the challenge are as follows:</p><p>the use of using coreference resolution in political debates creation of an external collection of claims extracted from fact-check websites employed as a training set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Design</head><p>For the validation of our experiments, we used 5-fold cross validation in the document level. In other words, we have splited the training data into 5 categories, where each fold of the whole document is considered as belonging to either the training or testing set. The reason for splitting the data into training and testing folds in the document level is to preserve the sequence of sentences of each debate.</p><p>We have created three different models, as follow:</p><p>Resolving coreference (ReCo): we have tested the performance of our model using the normalization of the corpus -previously described in Section 3.</p><p>Resolving coreference + further pre-processing (ReCo+pre): as described in the previous Section, in this experiment the coreference resolution technique is used to replace pronouns by the right references. We also employed in this model the normalization of the corpus.</p><p>Using external fact-checking data-set (ExtDat): in this model we used an external data set of claims described previously. Additionally, all mentioned text normalization techniques were used in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section, we present the results and discuss the evaluation of our proposed approach for Worthiness-Rank of Claims Checking.</p><p>Figure <ref type="figure" coords="6,182.31,346.63,4.98,8.74" target="#fig_1">1</ref> shows that our models yield better results in comparison to the baseline. The differences range from 4.02 to 8.86 percentage points (pp) when compared to the runner-up method, namely ExtDat. Using a Wilcoxon statistical test <ref type="bibr" coords="6,153.31,382.50,15.50,8.74" target="#b19">[19]</ref> with a significance level of 0.05, we verified that the results of our models are statistically superior to the baseline. Regarding the final submission, we used the 2-top best models, namely ReCo+pre and ExtDat models as our contrastive and primary submissions, respectively. Table 4 presents our results on the test data in different evaluation measures. Table <ref type="table" coords="7,210.07,115.91,4.13,7.89">4</ref>. Our primary and contrastive results on the test data Submission MAP RR R-P P@1 P@3 P@5 P@10 P@20 P@50 Primary</p><p>. The performance of a machine learning model trained in a supervised manner is mostly determined by the amount and quality of the training data. The paradigm of transfer-learning can be a remedy to the problem of having only small amounts of human-labeled data <ref type="bibr" coords="7,298.17,252.70,14.61,8.74" target="#b11">[11]</ref>. Language models that are trained unsupervised on a large but unlabeled corpus from a similar domain tend to learn abstract/high-level features that can benefit supervised training <ref type="bibr" coords="7,412.09,276.61,14.61,8.74" target="#b15">[15]</ref>. We assume that the basic understanding of a language that is learning by Language Models like ELMo <ref type="bibr" coords="7,184.78,300.52,14.61,8.74" target="#b15">[15]</ref>, XLNet <ref type="bibr" coords="7,240.47,300.52,14.61,8.74" target="#b20">[20]</ref>, and BERT <ref type="bibr" coords="7,314.25,300.52,10.52,8.74" target="#b5">[5]</ref> can be of particular use for teaching the machine the concept of check-worthiness. Furthermore, check-worthiness could be interpreted as more than a pure language understanding problem. The overall goal of reducing the human workload of checking claims could be further approached by a Fact-Checking system based on the ideas of question answering over knowledge-bases <ref type="bibr" coords="7,230.02,360.30,9.96,8.74" target="#b4">[4]</ref>. This way obvious true or false claims could be filtered out. Factual claims like "Homicides last year increased by 17 percent in America's fifty largest cities." are relatively easy to verify compared to "[...] NAFTA [is] one of the worst economic deals ever made by our country.".</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,455.59,563.41,4.61,7.86;4,144.70,574.37,273.27,7.86;4,455.59,574.37,4.61,7.86;4,144.70,585.78,277.51,7.86;4,455.59,585.78,4.61,7.86;4,144.70,596.73,194.32,7.86;4,455.59,596.73,4.61,7.86;4,144.70,607.69,236.87,7.86;4,455.59,607.69,4.61,7.86"><head></head><label></label><figDesc>1 TRUMP I beat Hillary Clinton, and I beat Hillary Clinton badly. 1 CLINTON Russia is interested in keeping Bashar al-Assad in power. 0 SANDERS Listen to what I told YouTube then. 0 TRUMP Hillary Clinton's raising your taxes really high. 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,149.70,597.83,315.97,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The obtained results in each experiment in addition to baseline results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,279.93,345.82,95.71"><head>Table 1 .</head><label>1</label><figDesc>Sample sentences from the training data that contain pronouns referring back to nouns mentioned in previous statements.</figDesc><table coords="4,177.77,311.66,259.82,63.98"><row><cell>Speaker Sentence</cell><cell>Label</cell></row><row><cell>SANDERS They are working longer hours for low wages.</cell><cell>1</cell></row><row><cell>TRUMP I beat her, and I beat her badly.</cell><cell>1</cell></row><row><cell cols="2">CLINTON They're interested in keeping Assad in power. 0</cell></row><row><cell>SANDERS Listen to what I told them then.</cell><cell>0</cell></row><row><cell>TRUMP She's raising your taxes really high.</cell><cell>1</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,252.01,294.14,140.23,7.89;5,192.04,313.20,19.45,7.86;5,353.00,313.20,38.53,7.86;5,407.96,313.20,7.68,7.86;5,192.04,324.56,72.46,7.86;5,353.00,324.56,29.87,7.86;5,400.28,346.47,23.04,7.86;5,192.04,335.52,96.87,7.86;5,353.00,335.52,29.87,7.86;5,192.04,346.47,106.75,7.86;5,353.00,346.47,29.87,7.86;5,192.04,357.43,110.50,7.86;5,353.00,357.43,29.87,7.86;5,192.04,368.39,102.68,7.86;5,353.00,368.39,29.87,7.86;5,192.04,379.75,142.86,7.86;5,353.00,379.75,44.49,7.86;5,402.58,401.67,18.43,7.86;5,192.04,390.71,205.45,7.86;5,192.04,401.67,125.46,7.86;5,353.00,401.67,44.49,7.86;5,192.04,412.63,132.10,7.86;5,353.00,412.63,44.49,7.86;5,192.04,423.59,105.08,7.86;5,353.00,423.59,44.49,7.86;5,192.04,434.94,108.54,7.86;5,353.00,434.94,32.34,7.86;5,402.58,440.42,18.43,7.86;5,192.04,445.90,84.03,7.86;5,353.00,445.90,32.34,7.86;7,134.77,425.77,62.94,10.52" xml:id="b0">
	<monogr>
		<ptr target="http://correctiv.org/GermanReferences" />
		<title level="m" coord="5,263.34,294.17,124.43,7.86">Claims used to train our model</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,449.67,337.63,7.86;7,151.52,460.63,306.95,7.86" xml:id="b1">
	<monogr>
		<ptr target="https://github.com/huggingface/neuralcoref" />
		<title level="m" coord="7,151.53,449.67,329.06,7.86;7,151.52,460.63,33.97,7.86">Github -huggingface/neuralcoref: Fast coreference resolution in spacy with neural networks</title>
		<imprint>
			<date type="published" when="2019-06-30">2019-06-30</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,471.37,337.64,7.86;7,151.52,482.33,329.07,7.86;7,151.52,493.29,329.07,7.86;7,151.52,504.25,329.07,7.86;7,151.52,515.21,82.02,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,448.79,471.37,31.80,7.86;7,151.52,482.33,329.07,7.86;7,151.52,493.29,152.23,7.86">to automatically extract claims from fact-checking websites and then consolidate a large data set for machine learning purposes</title>
		<ptr target="https://github.com/vwoloszyn/fakenewsextractor" />
		<imprint>
			<date type="published" when="2019-06-25">2019-06-25</date>
		</imprint>
	</monogr>
	<note>Github -vwoloszyn/fake news extractor: This project is a collective effort. currently, these claims are available for english, portuguese and german</note>
</biblStruct>

<biblStruct coords="7,142.96,525.95,337.63,7.86;7,151.52,536.91,329.07,7.86;7,151.52,547.86,183.77,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,151.52,536.91,329.07,7.86;7,151.52,547.86,71.76,7.86">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">Check-Worthiness</note>
</biblStruct>

<biblStruct coords="7,142.96,558.60,337.63,7.86;7,151.52,569.56,329.07,7.86;7,151.52,580.52,329.07,7.86;7,151.52,591.48,200.98,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,336.34,558.60,144.24,7.86;7,151.52,569.56,85.30,7.86">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,257.05,569.56,223.54,7.86;7,151.52,580.52,140.11,7.86">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10">Oct 2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,602.22,337.63,7.86;7,151.52,613.18,329.07,7.86;7,151.52,624.14,25.60,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,346.99,602.22,133.60,7.86;7,151.52,613.18,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.96,634.88,337.64,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.80,169.98,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,266.57,634.88,133.51,7.86">Detecting controversy on the web</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dori-Hacohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,421.94,634.88,58.66,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.80,48.64,7.86">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1845" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,119.67,337.64,7.86;8,151.52,130.63,329.07,7.86;8,151.52,141.59,315.34,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,251.58,119.67,229.02,7.86;8,151.52,130.63,37.80,7.86">Discovery, retrieval, and analysis of the&apos;star wars&apos; botnet in twitter</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Echeverria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,211.85,130.63,268.74,7.86;8,151.52,141.59,202.45,7.86">Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,151.78,337.63,7.86;8,151.52,162.71,329.07,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,362.80,151.78,117.79,7.86;8,151.52,162.74,141.02,7.86">Coh-metrix: Providing multilevel analyses of text characteristics</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Kulikowich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,298.87,162.74,91.16,7.86">Educational researcher</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,172.92,337.64,7.86;8,151.52,183.88,329.07,7.86;8,151.52,194.84,207.60,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,332.53,172.92,144.04,7.86">Combating web spam with trustrank</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.23,183.88,311.33,7.86">Proceedings of the Thirtieth international conference on Very large data bases</title>
		<meeting>the Thirtieth international conference on Very large data bases</meeting>
		<imprint>
			<publisher>VLDB Endowment</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="576" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,205.03,337.98,7.86;8,151.52,215.99,329.07,7.86;8,151.52,226.94,97.80,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Horne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Adali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09398</idno>
		<title level="m" coord="8,248.89,205.03,231.70,7.86;8,151.52,215.99,265.34,7.86">This just in: fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.62,237.13,337.98,7.86;8,151.52,248.09,329.07,7.86;8,151.52,259.05,329.07,7.86;8,151.52,270.01,178.87,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,243.16,237.13,233.88,7.86">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.46,248.09,315.14,7.86;8,151.52,259.05,43.24,7.86">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="8,142.62,280.19,337.97,7.86;8,151.52,291.15,329.07,7.86;8,151.52,302.11,329.07,7.86;8,151.52,313.07,160.10,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,293.16,280.19,187.43,7.86;8,151.52,291.15,159.06,7.86">Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,331.24,291.15,149.35,7.86;8,151.52,302.11,133.28,7.86">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>International World Wide Web Conferences Steering Committee</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="591" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,323.26,337.98,7.86;8,151.52,334.21,329.07,7.86;8,151.52,345.17,329.07,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,276.36,323.26,204.24,7.86;8,151.52,334.21,14.95,7.86">Summarizing contrastive viewpoints in opinionated text</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,189.58,334.21,291.01,7.86;8,151.52,345.17,82.06,7.86">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="66" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,355.36,337.98,7.86;8,151.52,366.32,329.07,7.86;8,151.52,377.25,329.07,7.89;8,151.52,388.24,25.60,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,411.80,366.32,68.80,7.86;8,151.52,377.28,94.62,7.86">Scikit-learn: Machine learning in python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,253.06,377.28,145.82,7.86">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,398.42,337.98,7.86;8,151.52,409.38,329.07,7.86;8,151.52,420.34,329.07,7.86;8,151.52,431.30,329.07,7.86;8,151.52,442.26,318.15,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,165.31,409.38,166.11,7.86">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,352.22,409.38,128.37,7.86;8,151.52,420.34,329.07,7.86;8,151.52,431.30,158.41,7.86">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">Jun 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="8,142.62,452.44,337.98,7.86;8,151.52,463.40,329.07,7.86;8,151.52,474.36,319.50,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,362.59,452.44,118.00,7.86;8,151.52,463.40,88.38,7.86">Credibility assessment of textual claims on the web</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,261.05,463.40,219.54,7.86;8,151.52,474.36,198.10,7.86">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2173" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,484.55,337.97,7.86;8,151.52,495.51,329.07,7.86;8,151.52,506.46,329.07,7.86;8,151.52,517.42,100.96,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,371.51,484.55,109.08,7.86;8,151.52,495.51,247.84,7.86">A novel two-stage framework for extracting opinionated sentences from news articles</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.34,495.51,59.25,7.86;8,151.52,506.46,329.07,7.86;8,151.52,517.42,26.52,7.86">Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing</title>
		<meeting>TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,527.61,337.98,7.86;8,151.52,538.57,329.07,7.86;8,151.52,549.53,176.44,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="8,204.97,527.61,222.52,7.86">The Support Vector Method of Function Estimation</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4615-5703-63</idno>
		<ptr target="https://doi.org/10.1007/978-1-4615-5703-63" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer US</publisher>
			<biblScope unit="page" from="55" to="85" />
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,559.71,337.97,7.86;8,151.52,570.67,329.07,7.86;8,151.52,581.61,168.27,7.89" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,313.81,559.71,166.77,7.86;8,151.52,570.67,251.23,7.86">Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,409.67,570.67,70.92,7.86;8,151.52,581.63,93.33,7.86">Selected tables in mathematical statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="171" to="259" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,591.82,337.98,7.86;8,151.52,602.78,329.07,7.86;8,151.52,613.74,97.80,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="8,455.76,591.82,24.83,7.86;8,151.52,602.78,264.15,7.86">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.62,623.92,337.97,7.86;8,151.52,634.88,329.07,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,236.63,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,265.20,623.92,215.39,7.86;8,151.52,634.88,249.94,7.86">Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,422.21,634.88,58.38,7.86;8,151.52,645.84,307.85,7.86">Proceedings of the 2003 conference on Empirical methods in natural language processing</title>
		<meeting>the 2003 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
