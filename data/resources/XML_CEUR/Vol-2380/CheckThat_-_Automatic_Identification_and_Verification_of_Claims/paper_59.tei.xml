<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,222.48,152.52,150.12,12.61">CheckThat! 2019 UAICS</title>
				<funder ref="#_7dVYXHT #_3HYhqTx">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.72,190.17,88.61,10.48"><forename type="first">Lucia-Georgiana</forename><surname>Coca</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.48,190.17,107.00,10.48"><forename type="first">Ciprian-Gabriel</forename><surname>Cusmuliuc</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.72,190.17,53.50,10.48"><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,156.84,212.09,56.34,9.47"><forename type="first">Alexandru</forename><surname>Ioan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<settlement>Iasi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,222.48,152.52,150.12,12.61">CheckThat! 2019 UAICS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2474C1B3CB736BA3AAEF66238DE0FB7A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CheckThat!</term>
					<term>SVM</term>
					<term>Naive Bayes</term>
					<term>Linear Regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Investigative journalists or detectives lose a lot of time to prove a certain claim, searching for the source or evidence to support this assertion often by hand. In this context, in order to address this problem, the 2019 CLEF Check-That! comes with two tasks: (1) Check-Worthiness and (2) Evidence &amp; Factuality. Our group participated to the first task whose aim is to evaluate the check worthiness of a political claim in a debate. The method to achieve the goal of the task was to represent each claim by a feature vector and feed it to a machine learning classification algorithms in order to classify if the claim is check-worthy or not. We submitter 3 runs, one primary and two contrastive, the primary being a Naive Bayes, the first contrastive Linear Regression and the second one SVM. The best result we achieved using the official measure MAP was with the Naive Bayes, the second best was the SVM and the third was the Linear Regression. This paper presents the details of our approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The popularity of social networks has increased significantly in recent years, and reading news on these social networks has become a natural activity for all users. The news is instantly transmitted to these networks, which are read quickly, marked with opinions (see Facebook1), retransmitted (retweet on Twitter2, share on Facebook) without having to check many times whether they are true or false news. This problem has also affected the political environment; growing political unrest in many countries has made politicians exchange accusations in diverse political debates, some that are more accurate than others are. The challenge is thus presented to us to first check the need to verify a political claim and then to verify if it is factually true. The first task consists of classifying claims from a presidential political debate, each candidate can make a claim and the others have a short time to issue a response, each of them has the right to make accusations in order to convince the audience about their political wittiness <ref type="bibr" coords="2,197.88,160.65,94.17,10.48" target="#b0">(Atanasova et al., 2019)</ref>.</p><p>In order to investigate the check-worthiness of a claim we have been provided with multiple presidential transcripts from the last elections in the United States. The goal is to provide a score for each line in the transcript, score that would signify the priority for fact checking and would be an input for task 2 <ref type="bibr" coords="2,326.52,208.65,83.49,10.48" target="#b5">(Elsayed et al., 2019)</ref>.</p><p>This paper describes the participation of team UAICS, from the Faculty of Computer Science, Alexandru Ioan Cuza University of Iasi, in Task 1 at CLEF 2019.</p><p>The remaining of this paper was organized as follows: Section 2 gives a description of the task. Section 3 details the model we developed and the submitted runs and then Section 4 details the results we obtained, finally Section 5 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Task Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Objectives</head><p>The objective is to provide a score for each line of a presidential debate <ref type="foot" coords="2,422.40,345.12,3.24,6.82" target="#foot_0">3</ref> , this score signifying the worthiness of the line to continue for fact checking<ref type="foot" coords="2,395.04,357.12,3.24,6.82" target="#foot_1">4</ref> (which is task 2) thus the objective is to create a filtering layer for the second task.</p><p>Given the fact that in a political debate things evolve quickly a manual checking would, be very cumbersome and slow, thus the need arises for automated checking in order to make the public more informed about the discussion and discourage fake information</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dataset</head><p>There were two datasets available, one to train the model and one for testing the model. They were both political debates transcripts from the last United States presidential elections.</p><p>The dataset was consisting of the following columns: line no, speaker, text and label; the test file did not have the label available. The label was a binary one, zero signifying that the sentence should not be fact checked and one to be fact checked. A concrete example with label 1 would be from Trump: "So Ford is leaving" and one with label 0 would be from BLITZER: "Let's begin with Senator Sanders".</p><p>The training had 19 files and the test had seven files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation metric</head><p>The task has been evaluated according to the official organizer's measures. The official measure is MAP <ref type="bibr" coords="2,194.76,625.65,82.99,10.48" target="#b1">(Beitzel et al., 2009)</ref> which calculates the usual mean of the average precision. Other measures used are the Mean Reciprocal Rank <ref type="bibr" coords="2,376.20,637.65,67.39,10.48" target="#b2">(Craswell, 2009)</ref> which allows obtaining reciprocals of rank of the first relevant document, as well as Mean Precision at k, which performs the average of k best candidates. Details on the measures used can be found in the task overview. Evaluations are carried out on primary and contrastive runs, the resulting metrics are as described above. Each participant has the right to three models, one primary and two secondary (contrastive).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods and runs</head><p>Right from the start, we decide we only want to use the training data provided and no other external information for our models, thus only the presidential debates were available.</p><p>We selected multiple machine-learning algorithms in order to test which one would be best for our problem. We started with the classical ones, Decision Trees <ref type="bibr" coords="3,439.68,301.65,30.93,10.48;3,124.68,313.65,23.35,10.48" target="#b4">(Dobra, 2009)</ref> and Naive Bayes <ref type="bibr" coords="3,223.80,313.65,59.13,10.48" target="#b12">(Rennie, 2003)</ref>, and then we moved to more advanced algorithms such as SVM <ref type="bibr" coords="3,213.96,325.65,45.29,10.48" target="#b11">(Liu, 2009)</ref>, Random Forest <ref type="bibr" coords="3,333.84,325.65,43.73,10.48" target="#b6">(Ho, 1995)</ref>, Logistic Regressions <ref type="bibr" coords="3,124.68,337.65,63.67,10.48" target="#b7">(Hosmer, 2000)</ref> and finally we tested a neural network, a Multilayer Perceptron Classifier. We use machine-learning algorithms in previous editions of CLEF <ref type="bibr" coords="3,419.40,349.65,51.09,10.48;3,124.68,361.65,21.57,10.48" target="#b10">(Iftene et al., 2009)</ref>, <ref type="bibr" coords="3,153.12,361.65,75.09,10.48" target="#b8">(Iftene et al., 2012)</ref>, <ref type="bibr" coords="3,234.96,361.65,75.19,10.48" target="#b9">(Iftene et al., 2013)</ref>, and <ref type="bibr" coords="3,333.84,361.65,80.13,10.48" target="#b3">(Cristea et al., 2016)</ref>.</p><p>In order to verify our algorithms, given we had no validation data; it was decided to split the training data 70-30, 70% would be used for training and 30 for measuring the performance.</p><p>To ease our implementation we used PySpark, combined with the PySpark MLlib that contains prebuild, ready to use machine-learning algorithms, we decided to use this tool in order to benefit from the parallel processing power of PySpark to scale the application in order to process large amounts of data.</p><p>Our metrics were based on sklearn's metrics so in the end we would have the Precision, Recall and F1 of the classifiers but also the confusion matrix. In addition to our metrics, in order to comply with the organizers requirements, we also used their provided metrics that are the following: R-Precision, Average Precision, Reciprocal Rank and Precision@k so in the end we would have a multitude of metrics that would help us better measure our classification efforts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training and test data</head><p>The data provided contained presidential elections debates from the United States in 2016. The data was of two main categories, training and test. The training had 19 files while the test had seven files. The main difference of the test and training was that the test has a missing label column that is the classification category of the phrase.</p><p>One training example with the available columns would be the following: From the training data we made several decisions: the speaker is not relevant for the algorithms and it would make it more biased to certain decisions (which we do not want, so we excluded it), we would not exclude the speaker "SYSTEM" with phrases such as "(APPLAUSE)" as they are all very similar and the label 0 would be enough to make the algorithms realize that it has to predict with 0 and that besides tokenization we can run feature extraction algorithms without much pre-processing at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing and feature extraction</head><p>Before feeding the data to the machine learning algorithms, we had to preprocess the text and extract features. This section describes in detail this process in order to fully understand the training data fed to the algorithms. As said in the previous section, we did not take into consideration the speaker column in the classification process, on the "text" column and the "label". For preprocessing, we only applied a "Tokenizer" for each line, taking text (such as a sentence) and breaking it into individual terms (words). After the tokenization process we removed the stop words with the "StopWordsRemover" class, given the fact that the texts are in English we only removed stop words from this language.</p><p>We did not take into account irony or sentiment analysis in the preprocessing part as we believed feature extraction could represent this indirectly however we were aware this could affect certain edge cases of the classification.</p><p>After we preprocessed the text it was necessary to extract features from the text, we did this using a multitude of methods trying to find the perfect fit for every algorithm. The best results were obtained with two main methods: TF-IDF and CountVectorizer (Convert a collection of text documents to a matrix of token counts).</p><p>For the first method, TF-IDF, we used it with Logistic Regression and Multilayer Perceptron, the implementations in Pyspark are HashingTF and then next in pipeline would be IDF. The TF-IDF would create a feature model where the term frequency would yield informational value to classification algorithms. We decided to use Hash-ingTF in order to make the implementation faster as this would create a feature map where a raw feature is mapped into an index (term) by applying a hash function, after which the IDF would take the generated term frequency vectors to fit which scales each feature and down-weighs features that appear frequently in the corpus.</p><p>As for settings, we had to fine-tune the preprocessing methods and the final form of them is that for Logistic Regression the number of features of HashingTF was 262,144 and for Multilayer Perceptron was 5,000 (as this would force us to create the same number of input layers for the neural network, we had to scale it down to this value).</p><p>The settings for IDF for both algorithms are the same, the minimum number of documents in which a term should appear for filtering is 0.</p><p>For the second model, CountVectorizer, we used it with Naive Bayes and SVM, the implementation is with the same name, after the CountVectorizer we applied IDF. The CountVectorizer is very similar to HashingTF, the main difference being that the first one is reversible (because of not doing hashing), is more computationally intensive however it does not reduce the dimension, having lower informational loss. We also tried HashingTF on these models however we obtained worse results that is the logic behind switching the feature extraction algorithm. The settings of the CountVectorizer are the following: minimum term frequency is 1 and so is the minimum definition frequency, the maximum definition frequency is 2^63-1 and the vocabulary size is 2^18.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Models</head><p>After we preprocessed the data and extracted the feature with the methods described in the previous sections, in this section we will talk about the algorithms used to fit the extracted features.</p><p>Our approach was to use a few diverse algorithms and select the best three -one primary and two contrastive. We started investigating these models by looking into what participants of CLEF CheckThat 2018 did, the most notable algorithms being Multilayer Perceptron and SVM but also Random Forests.</p><p>We started with the classical ones, Decision Trees and Naive Bayes, and then we moved to more advanced algorithms such as SVM, Random Forest, Logistic Regressions and finally we tested a neural network, the Multilayer Perceptron Classifier. As stated in the beginning of this section the algorithms had the implementation based in PySpark <ref type="foot" coords="5,158.52,450.12,3.24,6.82" target="#foot_2">5</ref> . After we trained and measured the performance using the aforementioned metrics, from these initial six algorithm only four were left: Logistic Regression, Naive Bayes, SVM and Multilayer Perceptron, these had the best results and we could further improve them.</p><p>The Naive Bayes was right from the start one of the top performers of our tests, so naturally it received the most attention. The settings used for this algorithm were rather slim, the smoothing was set to 1 and the model was multinomial (given how we are classifying on word counts from the text).</p><p>The next algorithm that caught our eye was the SVM that had very interesting results, granted not as good as Bayes but very notable, we used this SVM's hyperplane to classify the multidimensional feature matrix. As for settings the SVM is using a linear kernel, the maximum iterations are set to 100 and the regression parameter is set to zero.</p><p>The third best algorithm was the Logistic Regression. Having good results close to SVM, with the settings being: the maximum iterations are set to 100, the regression parameter is set to 0 and the label distribution was set to automatically be identified (binomial or multinomial).</p><p>In contrast to the three algorithms that performed well we had one that yielded less than satisfactory results, even though it had long training times. The Multilayer Perceptron had very low accuracy that is why we chose not to include it in the sent result. The Multilayer Perceptron had the maximum iterations set to 1,500 and no matter how long the training iterations were set the accuracy remained low. The network had 5,000 input neurons (similar to the number of features) and it had two hidden layers with 1,000 and 2,000 neurons while the output layers were reducing to two neurons corresponding to the labels. Probably the unsatisfactory results were much related to the low number of features extracted, but long training times and the fact that the other algorithms had very fast results with high accuracy made us leave this one last.</p><p>To conclude this section, for the submission we chose as primary the Naive Bayes, as contrastive one, we chose Linear Regression and finally for contrastive 2 we chose SVM. We only made two submissions, UAICS-1 and UAICS-2, the latter being the final version of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, the results of the three submissions will be discussed. The official results of our submissions (of team UAICS), ranking fifth out of 12 for the primary MAP metric, are:</p><p>Table <ref type="table" coords="6,291.84,410.89,3.40,8.08">3</ref>. Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>submission</head><p>MAP RR R-P P@1 P@3 P@5 P@10 P@20 P@50 primary . To detail our results, we got the following places:</p><p>• MAP (Mean Average Precision) -5th place;</p><p>• RR (Reciprocal Rank) -1st place;</p><p>• R-P (R-Precision) -3rd place;</p><p>• P@1 (Precision@1) -1st place;</p><p>• P@3 (Precision@3) -1st place;</p><p>• P@5 (Precision@5) -2nd place;</p><p>• P@10 (Precision@10) -1st place;</p><p>• P@20 (Precision@20) -4th place;</p><p>• P@50 (Precision@50) -6th place.</p><p>With the official labeled test files (7,080 lines of test), we can inspect further metrics such as Precision, Recall, F1: If we analyze the performance of each system the findings are that the Primary -Naive Bayes has the overall best performance having very high detection rate of phrases which are not worthy of checking and also the best rate of detecting cases which are worthy of fact checking. The confusion matrix also confirm that Naive Bayes is a very performant algorithm, from 7000+ lines only 354 were wrongly labeled.</p><p>The next contestant to the place of the best algorithm is the Contrastive-1-Logistic Regression, which seems to have a good capability of predicting non-priority fact checking cases but it is much worse than Naive Bayes at predicting the cases that actually have to be fact checked, thus this would be a close second. The confusion matrix goes hand in hand with the above-mentioned metrics, as the algorithm has wrongly classified 317 lines from the test data.</p><p>The final contestant to the place of the best algorithm is the Contrastive-2-Support Vector Machine with the highest detection rate of non-priority cases but unfortunately very low performance in detecting priority cases.</p><p>Comparing the Precision, Recall, F1 and Confusion Matrix with the official results it can clearly be seen that the best algorithm is still the primary-Naive Bayes, however the second best is contrastive-2 followed by contrastive-1, this may be because contrastive-1 and contrastive-2 were very close to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and future work</head><p>In this paper, we proposed three models to solve the CLEF2019 CheckThat challenge (task 1 Check Worthiness) which deals with the evaluation of the check-worthiness of statements in political debates. We used Naive Bayes, SVM and Logistic Regression to train the models on the extracted features from TF-IDF and CounVectorizer. We got good results with these three models, ranking 5th out of 12. We are currently trying to further improve the feature extraction methods and also insert more data into the algorithms, so we would have even better results, also very important for us is to improve our algorithms and also find new ones, we would like to improve on the Multilayer Perceptron and test everything with a Convolutional Neural Network, so that in the future we would get even better results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,143.28,639.69,289.21,37.84"><head>Table 1 .</head><label>1</label><figDesc>Training example.</figDesc><table coords="3,143.28,653.13,289.21,24.40"><row><cell>Line no.</cell><cell>Speaker</cell><cell>Text</cell><cell>Label</cell></row><row><cell>1</cell><cell>Trump</cell><cell>So Ford is leaving.</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,179.64,172.61,237.09,42.92"><head>Table 2 .</head><label>2</label><figDesc>Test example.</figDesc><table coords="4,179.64,191.13,237.09,24.40"><row><cell>Line no.</cell><cell>Speaker</cell><cell>Text</cell></row><row><cell>1</cell><cell>Sanders</cell><cell>They went to the DNC quietly.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,136.08,196.61,312.07,148.52"><head>Table 4 .</head><label>4</label><figDesc>Precision, Recall and F1 results primary</figDesc><table coords="7,136.08,221.35,312.07,123.78"><row><cell>Primary</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>support</cell></row><row><cell>0</cell><cell>0.98</cell><cell>0.96</cell><cell>0.97</cell><cell>6944</cell></row><row><cell>1</cell><cell>0.11</cell><cell>0.24</cell><cell>0.15</cell><cell>136</cell></row><row><cell>Micro avg</cell><cell>0.95</cell><cell>0.95</cell><cell>0.95</cell><cell>7080</cell></row><row><cell>Macro avg</cell><cell>0.55</cell><cell>0.60</cell><cell>0.56</cell><cell>7080</cell></row><row><cell>Weighted avg</cell><cell>0.97</cell><cell>0.95</cell><cell>0.96</cell><cell>7080</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,127.68,376.61,328.87,145.40"><head>Table 5 .</head><label>5</label><figDesc>Precision, Recall and F1 contrastive 1</figDesc><table coords="7,127.68,400.75,328.87,121.26"><row><cell>Contr.-1</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>support</cell></row><row><cell>0</cell><cell>0.98</cell><cell>0.97</cell><cell>0.98</cell><cell>6944</cell></row><row><cell>1</cell><cell>0.06</cell><cell>0.09</cell><cell>0.07</cell><cell>136</cell></row><row><cell>Micro avg</cell><cell>0.96</cell><cell>0.96</cell><cell>0.96</cell><cell>7080</cell></row><row><cell>Macro avg</cell><cell>0.52</cell><cell>0.53</cell><cell>0.52</cell><cell>7080</cell></row><row><cell>Weighted avg</cell><cell>0.96</cell><cell>0.96</cell><cell>0.96</cell><cell>7080</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,141.00,553.13,307.03,124.88"><head>Table 6 .</head><label>6</label><figDesc>. Precision, Recall and F1 results contrastive 2</figDesc><table coords="7,141.00,577.27,307.03,100.74"><row><cell>Contr.-2</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell><cell>support</cell></row><row><cell>0</cell><cell>0.98</cell><cell>0.99</cell><cell>0.99</cell><cell>6944</cell></row><row><cell>1</cell><cell>0.10</cell><cell>0.06</cell><cell>0.08</cell><cell>136</cell></row><row><cell>Micro avg</cell><cell>0.97</cell><cell>0.97</cell><cell>0.97</cell><cell>7080</cell></row><row><cell>Macro avg</cell><cell>0.54</cell><cell>0.52</cell><cell>0.53</cell><cell>7080</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,163.08,207.65,260.43,79.52"><head>Table 7 .</head><label>7</label><figDesc>Confusion Matrix for primary</figDesc><table coords="8,163.08,232.39,260.43,54.78"><row><cell>Primary</cell><cell>Predicted No</cell><cell>Predicted Yes</cell></row><row><cell>Actual No</cell><cell>6694</cell><cell>250</cell></row><row><cell>Actual Yes</cell><cell>104</cell><cell>32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,169.08,318.65,244.23,82.64"><head>Table 8 .</head><label>8</label><figDesc>Confusion Matrix for contrastive 1</figDesc><table coords="8,169.08,343.39,244.23,57.90"><row><cell>contr.-1</cell><cell>Predicted No</cell><cell>Predicted Yes</cell></row><row><cell>Actual No</cell><cell>6751</cell><cell>193</cell></row><row><cell>Actual Yes</cell><cell>124</cell><cell>12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="8,152.16,434.81,276.75,79.88"><head>Table 9 .</head><label>9</label><figDesc>Confusion Matrix for contrastive 2</figDesc><table coords="8,152.16,459.55,276.75,55.14"><row><cell>contr.-2</cell><cell>Predicted No</cell><cell>Predicted Yes</cell></row><row><cell>Actual No</cell><cell>6875</cell><cell>69</cell></row><row><cell>Actual Yes</cell><cell>128</cell><cell>8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,129.96,673.73,267.50,9.47"><p>https://sites.google.com/view/clef2019-checkthat/task-1-check-worthiness</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,129.96,684.77,273.42,9.47"><p>https://sites.google.com/view/clef2019-checkthat/task-2-evidence-factuality</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="5,129.96,684.77,184.66,9.47"><p>https://www.tutorialspoint.com/pyspark/index.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is partially supported by <rs type="grantNumber">POC-A1-A1.2.3-G-2015</rs> program, as part of the <rs type="projectName">PrivateSky</rs> project (<rs type="grantNumber">P 40 371/13/01.09.2016</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_7dVYXHT">
					<idno type="grant-number">POC-A1-A1.2.3-G-2015</idno>
					<orgName type="project" subtype="full">PrivateSky</orgName>
				</org>
				<org type="funding" xml:id="_3HYhqTx">
					<idno type="grant-number">P 40 371/13/01.09.2016</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,132.64,478.61,337.99,9.47;9,141.72,489.65,328.86,9.47;9,141.72,500.69,244.53,9.47" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,141.72,489.65,328.86,9.47;9,141.72,500.69,33.45,9.47">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,181.44,500.69,94.18,9.47">Task 1: Check-Worthiness</title>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="9,132.64,511.61,337.87,9.47;9,141.72,522.65,181.33,9.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,304.92,511.61,16.36,9.47">MAP</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Beitzel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">C</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,438.00,511.61,32.52,9.47;9,141.72,522.65,94.83,9.47">Encyclopedia of Database Systems</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.64,533.69,338.11,9.47;9,141.72,544.61,149.89,9.47" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,214.08,533.69,81.29,9.47">Mean Reciprocal Rank</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,411.60,533.69,59.16,9.47;9,141.72,544.61,63.38,9.47">Encyclopedia of Database Systems</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.64,555.65,337.96,9.47;9,141.72,566.69,328.95,9.47;9,141.72,577.61,328.74,9.47;9,141.72,588.65,316.89,9.47" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,179.40,566.69,291.27,9.47;9,141.72,577.61,135.68,9.47">Using Machine Learning Techniques, Textual and Visual Processing in Scalable Concept Image Annotation Challenge</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Cristea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Savoaia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Martac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">C</forename><surname>Pătraș</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">O</forename><surname>Scutaru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Covrig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,294.12,577.61,176.34,9.47;9,141.72,588.65,173.77,9.47">Working Notes of CLEF 2016 -Conference and Labs of the Evaluation forum -ImageCLEF2016</title>
		<meeting><address><addrLine>Evora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-08">2016. 5-8 September 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.64,599.69,338.03,9.47;9,141.72,610.61,159.61,9.47" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,204.60,599.69,101.63,9.47">Decision Tree Classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dobra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,421.68,599.69,48.99,9.47;9,141.72,610.61,73.10,9.47">Encyclopedia of Database Systems</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.64,621.65,337.97,9.47;9,141.72,632.69,328.86,9.47;9,141.72,643.61,328.74,9.47;9,141.72,654.65,249.21,9.47" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,231.48,632.69,239.10,9.47;9,141.72,643.61,95.51,9.47">Overview of the CLEF-2019 CheckThat!: Automatic Identification and Verification of Claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,254.04,643.61,216.42,9.47;9,141.72,654.65,37.92,9.47">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">2019. September, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.64,148.61,337.98,9.47;10,141.72,159.65,328.89,9.47;10,141.72,170.69,309.09,9.47" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,219.84,148.61,115.59,9.47">Random Decision Forests (PDF)</title>
		<author>
			<persName coords=""><forename type="first">Tin</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,341.64,148.61,128.98,9.47;10,141.72,159.65,184.04,9.47">Proceedings of the 3rd International Conference on Document Analysis and Recognition</title>
		<meeting>the 3rd International Conference on Document Analysis and Recognition<address><addrLine>Montreal, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-08-16">1995. 14-16 August 1995. 17 April 2016. 5 June 2016</date>
			<biblScope unit="page" from="278" to="282" />
		</imprint>
	</monogr>
	<note>Archived from the original</note>
</biblStruct>

<biblStruct coords="10,132.64,181.61,337.96,9.47;10,141.72,192.65,24.09,9.47" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">W</forename><surname>Hosmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stanley</forename><surname>Lemeshow</surname></persName>
		</author>
		<title level="m" coord="10,324.96,181.61,105.66,9.47">Applied Logistic Regression</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct coords="10,132.64,203.69,337.99,9.47;10,141.72,214.61,328.89,9.47;10,141.72,225.65,328.77,9.47;10,141.72,236.69,18.57,9.47" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,440.64,203.69,30.00,9.47;10,141.72,214.61,325.15,9.47">Enhancing a Question Answering system with Textual Entailment for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Gînscă</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moruz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trandabăț</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Husarciuc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boroș</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,141.72,225.65,231.61,9.47">Notebook Paper for the CLEF 2012 LABs Workshop -QA4MRE</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 17-20 September</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.38,247.61,338.20,9.47;10,141.72,258.65,328.80,9.47;10,141.72,269.69,191.49,9.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,280.32,247.61,190.26,9.47;10,141.72,258.65,143.94,9.47">Using Anaphora resolution in a Question Answering system for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moruz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ignat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,291.84,258.65,178.68,9.47;10,141.72,269.69,58.21,9.47">Notebook Paper for the CLEF 2013 LABs Workshop -QA4MRE</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013. 23-26 September</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.38,280.61,338.26,9.47;10,141.72,291.65,329.04,9.47;10,141.72,302.69,328.89,9.47;10,141.72,313.61,328.67,9.47;10,141.72,324.65,160.05,9.47" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,431.64,280.61,39.00,9.47;10,141.72,291.65,104.23,9.47">UAIC Participation at QA@CLEF2008</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trandabăț</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Pistol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moruz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Husarciuc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cristea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,264.00,291.65,206.76,9.47;10,141.72,302.69,324.84,9.47">Evaluating Systems for Multilingual and Multimodal Information Access, 9th Workshop of the Cross-Language Evaluation Forum, CLEF 2008</title>
		<title level="s" coord="10,388.80,313.61,81.59,9.47;10,141.72,324.65,47.31,9.47">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2009. September 17-19, 2008. 2009</date>
			<biblScope unit="volume">5706</biblScope>
			<biblScope unit="page" from="448" to="451" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="10,132.38,335.69,338.23,9.47;10,141.72,346.61,14.53,9.47;10,124.80,357.65,11.37,9.47" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,238.92,335.69,160.94,9.47">SVM. In Encyclopedia of Database Systems</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">13</biblScope>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,141.72,357.65,328.83,9.47;10,141.72,368.69,89.37,9.47" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,326.40,357.65,144.15,9.47;10,141.72,368.69,59.18,9.47">Tackling the poor assumptions of Naive Bayes classifiers</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,206.40,368.69,19.75,9.47">ICML</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
