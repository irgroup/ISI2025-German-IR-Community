<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.90,115.96,271.56,12.62;1,176.07,133.89,263.21,12.62;1,247.62,151.82,120.12,12.62">Entity Detection for Check-worthiness Prediction: Glasgow Terrier at CLEF CheckThat! 2019</title>
				<funder>
					<orgName type="full">China Scholarship Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.01,189.66,34.87,8.74"><forename type="first">Ting</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.43,189.66,75.03,8.74"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.40,189.66,48.48,8.74"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<settlement>Glasgow</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.90,115.96,271.56,12.62;1,176.07,133.89,263.21,12.62;1,247.62,151.82,120.12,12.62">Entity Detection for Check-worthiness Prediction: Glasgow Terrier at CLEF CheckThat! 2019</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13E4535B1386F9AA355A076B8D4D5E46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fact checking</term>
					<term>Entity relationships</term>
					<term>Check-worthiness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Since information can be created and shared online by anyone, a lot of time and effort are required to manually fact-check all the information encountered by users everyday. Hence, an automatic factchecking process is needed to effectively fact-check the vast information available online. However, gathering information related to every single claim can also be redundant, as not all sentences or articles are checkworthy. In this paper, we propose an effective approach for retrieving check-worthy sentences within American political debates, which relates to the first task of the CLEF CheckThat! 2019 Lab. To rank sentences based on their check-worthiness, we propose to represent each sentence using their mentioned entities using a TF-IDF representation. We use a SVM classifier to predict the check-worthiness of each sentence. Our approach ranked 4th out of 12 submissions. Our experiments show that the pronouns and coreference resolution pre-processing procedure we use as part of our approach does improve the effectiveness of sentence checkworthiness prediction. Furthermore, our results show that entity analysis features provide valuable evidence for this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, information is easily accessible online, from articles by reliable news agencies, to reports from independent reporters, to extreme views published by unknown individuals. Such amount of information may create difficulties for information consumers as they try to distinguish fake news from genuine news. Indeed, users may not be necessarily aware that the information they encounter is false, and may not have the time and effort to fact-check all the claims and information they come across online. Moreover, social media outlets are becoming increasingly important in everyday life, where users can obtain the latest news Hillary Clinton: I think my husband did a pretty good job in the 1990s. Hillary Clinton: I think a lot about what worked and how we can make it work again... Donald Trump: Well, he approved NAFTA.. Hillary Clinton: Take clean energy. Hillary Clinton: Donald thinks that climate change is a hoax perpetrated by china Hillary Clinton: I think it's real. Donald Trump: I did not. and updates, share links to news and information they want to spread, and post comments with their own opinions. With the amount of information that is created daily, it is not feasible for journalists and users to manually fact-check every news article, sentence or tweet online. Therefore, an automatic fact-checking system that extracts the most check-worthy claims from articles and debates could allow journalists to focus on manually checking suspicious but worthy claims, thereby reducing the workload required for the task.</p><p>The task of predicting the check-worthiness of each sentence in the text is the objective of Task 1 of the CLEF CheckThat! 2019 Lab <ref type="bibr" coords="2,386.92,399.55,9.96,8.74" target="#b0">[1]</ref>. In particular, participants are asked to retrieve the most check-worthy sentences from transcripts obtained from American political debates. The task is defined as follows. Given a debate (D) that contains a set of ordered sentences (D = (s 1 , s 2 , ..., s 3 )), where each sentence has a line number, a speaker's name, and the content of the sentence (s n =&lt; l n , p n , c n &gt;)), a system should return a list of sentences, ordered based on their estimated check-worthiness. For example, Table <ref type="table" coords="2,416.83,471.28,4.98,8.74" target="#tab_0">1</ref> presents two examples of excerpts from such debates, where the sentences labelled with are considered to be check-worthy.</p><p>The focus of this paper is to effectively address Task 1 of the CLEF Check-That! 2019 Lab. To do so, we build upon recent developments to improve a chatbot's understanding in a conversation (a debate is form of conversation <ref type="bibr" coords="2,463.43,536.57,10.30,8.74" target="#b2">[3]</ref>), namely techniques for coreference resolution, in order to process the pronouns present within the text. Moreover, we observe that several entities tend to be present in sentences that are worth checking. For example, the bold text in Table 1 refers to entities. Therefore, we hypothesise that an entity resolution and analysis using knowledge graphs (KG) can help distinguish between sentences that are worth checking and sentences that are not. The contributions of this paper are two-fold: we develop a useful automatic pre-processing procedure to process the text before analysis; Secondly, we show that entity resolution and analysis can indeed enhance the effectiveness of our approach at identifying check-worthy sentences.</p><p>The rest of the paper is organised as follows. We briefly introduce related work in Section 2. Section 3 describes our proposed approach. We provide the experimental setup in Section 4, followed by the results and analysis in Section 5. Finally, we draw the main conclusions from this paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous studies that focused on the task of predicting the check-worthiness of a sentence are limited. ClaimBuster <ref type="bibr" coords="3,315.13,220.18,10.52,8.74" target="#b5">[6]</ref> used an SVM classifier with TF-IDF, part-of-speech (POS) tags, and named entity recognition as features, to classify a sentence into factual, unimportant-factual, and check-worthy factual. Gencheva et al., <ref type="bibr" coords="3,206.37,256.05,10.52,8.74" target="#b3">[4]</ref> improved the work of ClaimBuster by using additional sentiment, tense, and paragraph structure features, to predict if a sentence should be fact-checked. This work was further improved, and resulted in ClaimRank <ref type="bibr" coords="3,467.31,279.96,9.96,8.74" target="#b7">[8]</ref>, which can provide journalists with check-worthy sentences for manual checking. Moreover, Patwari et al., <ref type="bibr" coords="3,247.33,303.87,15.50,8.74" target="#b9">[10]</ref> used an SVM classifier to classify if a sentence is check-worthy or not. In particular, they analysed the topic a sentence is talking about using an LDA topic modelling approach. They also used POS with TF-IDF representation features, and achieved a 0.214 F1 score.</p><p>In last year's CLEF CheckThat! Lab, aside from the above mentioned methods, team Prise de Fer <ref type="bibr" coords="3,237.63,363.65,15.50,8.74" target="#b13">[14]</ref> manually normalised names and pronouns that appeared in the debate as a pre-processing procedure. They also used clauses and phrases as well as rule-based heuristics on the length of the sentence within a multilayer perceptron. Team Copenhagen <ref type="bibr" coords="3,321.96,399.51,10.52,8.74" target="#b4">[5]</ref> used word2vec embedding and a recurrent neural network model, and achieved 0.182 in mean average precision in a check-worthy sentence retrieval task. In addition, syntactic dependencies were used by both teams <ref type="bibr" coords="3,223.71,435.38,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="3,235.89,435.38,11.62,8.74" target="#b13">14]</ref>.</p><p>However, the above mentioned approaches did not pay much attention to automatic pre-processing, in order to unify the pronouns and references. Moreover, although these approaches used named entities as features, none of these approaches used external resources to analyse the entities mentioned in the text. Our work focuses on these two parts of analysing sentences, to predict their check-worthiness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Entity Detection Approach</head><p>The aim of the check-worthiness task is to rank the sentences, such that those sentences estimated most likely to be check-worthy are ranked first. In addressing this task, we use a classifier based on several groups of features to estimate the check-worthiness of each sentence. Sentences are then ranked based on the classifier's confidence about the check-worthiness of each sentence. Our classification approach makes use of a pre-processing of the text that addresses pronouns and coreference resolution (described in detail in Section 3.1 below), as well as several groups of features, including some that consider the presence of entities within the sentences (Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Debate D First person Pronouns Resolution</head><p>Coreference Resolution</p><p>Pre-processed sentences Fig. <ref type="figure" coords="4,154.40,179.33,4.13,7.89">1</ref>. The pre-processing procedure. A parallelogram represents input and/or output; a rectangle represents a process; an arrow represents the relationship flow between two components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing Procedure</head><p>American political debates usually consist of two or more participants, and one or more moderators, where each debate has different participants. In this case, it is not explicitly apparent to the system which participants are referenced by which pronouns. Similarly, implicit pronouns can also be used to identify a specific person or a particular thing previously mentioned or known, leading to a possible confusion. To combat the above mentioned challenges in implicit references, we propose a two-step procedure to resolve the implicit references found in the debates, namely, first-person pronouns resolution, and coreference resolution, as illustrated in Figure <ref type="figure" coords="4,284.13,346.92,3.87,8.74">1</ref>. Detailed examples can be found in Table <ref type="table" coords="4,472.85,346.92,3.87,8.74" target="#tab_3">5</ref>.</p><p>1. First-person pronouns resolution: In this step, we simply change all the first-person pronouns in each sentence s n into the current speaker's name p n .</p><p>2. Coreference resolution: Coreference resolution is the task of finding the entity expression that a pronoun refers to within a piece of text. In our proposed procedure, we use coreference resolution to replace implicit mentions to one of the previously stated real-world entities. Specifically, we use Lee et al. <ref type="bibr" coords="4,445.49,418.65,10.32,8.74" target="#b8">[9]</ref>'s implementation of a higher order coreference resolution method, applies on pairs of sentences. Therefore, the span of possible references for a pronoun is from either the current sentence, or the antecedent of the sentence, regardless of any change in speaker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Check-worthiness Estimation</head><p>After the pre-processing procedure, we obtain an ordered (based on the order of the debate) list of sentences for each debate, where most pronouns are replaced with the person's name and/or entities. Note that the coreference resolution method cannot achieve a perfect accuracy, as only a subset of the actual pronouns are resolved.</p><p>Next, to obtain a ranking of sentences, we extract features from each sentence, and use these features as input to a classifier that is trained to estimate the check-worthiness of each sentence. Figure <ref type="figure" coords="4,316.25,596.34,4.98,8.74">2</ref> shows the overall architecture of our proposed approach. Below, we describe two sources of features that we use to assist the check-worthiness estimation, namely TF-IDF sentence representation and entities analysis. training set. In particular, we use Sklearn's TfidfVectorizer<ref type="foot" coords="5,392.11,257.29,3.97,6.12" target="#foot_0">1</ref> to extract features for each sentence. We do not discard any terms from the dictionary. 2. Entity analysis: Our second group of features concerns the entities that appear in each sentence, obtained through entity linking occurrences in each sentence to a knowledge graph (KG), namely Wikipedia. In particular, Wikipedia is a large-scale online encyclopedia, where users can create articles related to specific entities, and can edit existing articles. The crowd-sourcing nature of Wikipedia allows the entities' information to be updated quickly, which means that the information is kept up-to-date. Wikipedia also contains structure relationships where one or more entities are linked together through hyperlinks, such as Polysemy (disambiguation pages), Synonymy (redirect pages) and Associative relationships (hyperlinks between Wikipedia articles). Ciampaglia et al. <ref type="bibr" coords="5,470.08,391.47,10.52,8.74" target="#b1">[2]</ref> showed that the distance between two entities within a KG could be used to improve fake news detection accuracy when applying an entity linking method on news articles. In this paper, instead of using the explicit distance between entities, we use the structured relationships constructed by Wikipedia links to analyse the entities within a given sentence using three different methods. Details of these methods are listed below: 2(a). Similarity of entities: We follow the method described by Zhu and Iglesias <ref type="bibr" coords="5,169.16,488.21,14.61,8.74" target="#b11">[12]</ref>. First, we compute the similarity between two entities using the top 5 concepts with the highest graph-based information content, which are selected and combined into a concept list. The concepts of the Wikipedia KG contain axioms describing concept hierarchies that are usually referred to as ontology classes (type: box), while axioms about entity instances are usually referred as ontology instances (object: a box). Then, we compute the semantic similarity of two entities by calculating the semantic cosine similarity of two concept lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2(b). Relatedness of entities:</head><p>We extract the relatedness between two entities using the method described by Witten et. al., <ref type="bibr" coords="5,371.85,584.95,15.50,8.74" target="#b10">[11]</ref>   where a and b are two entities, and A and B are the sets of all the concepts that are linked to a and b. W is the whole set of concepts that appear in all of Wikipedia. |x| is the number of concepts that a given set x contains. 2(c). Count of entities: Finally, we also count the non-repeated entities that appear in each sentence, and use the number of the entities as a feature.</p><p>As some sentences contain more than two entities, we need to aggregate the similarity and relatedness of each pair of entities into sentence-level features. Therefore, we calculate the mean and max of the similarity and relatedness scores for the pairs of entities within each sentence. Overall, in addition to TF-IDF term features, we therefore have additional 5 features for each sentence, as shown in Table <ref type="table" coords="6,204.01,362.66,3.87,8.74" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we describe the used dataset, the settings of each component our approach, as well as the evaluation metrics.</p><p>Dataset: We use the training and test data provided by the CLEF Check-That! 2019 lab as the training and test datasets, respectively. In the following, we describe in detail the experimental setup we used for the components of our approach:</p><p>First-person pronouns resolution and coreference resolution: As mentioned in Section 3, we simply change all the first-person pronouns (i.e., I, we, us, etc) to the current speaker's name. We use Lee et al.'s coreference resolution package<ref type="foot" coords="6,215.78,528.69,3.97,6.12" target="#foot_1">2</ref> to find the entity that a pronoun is referring to. All the parameters are set to their recommended settings <ref type="bibr" coords="6,354.31,542.22,9.96,8.74" target="#b8">[9]</ref>.</p><p>Tokenisation and TF-IDF: We use the Sklearn's TfidfVectorizer<ref type="foot" coords="6,447.32,552.96,3.97,6.12" target="#foot_2">3</ref> to tokenise and calculate the TF-IDF features. All the parameters remain at their default settings.</p><p>Entities extraction: In our experiments, we use DBpedia Spotlight<ref type="foot" coords="6,462.58,589.17,3.97,6.12" target="#foot_3">4</ref> to extract entities from each sentence, with the confidence set to 0.3 following <ref type="bibr" coords="6,465.69,602.70,9.96,8.74" target="#b6">[7]</ref>.</p><p>Table <ref type="table" coords="7,166.37,115.91,4.13,7.89">3</ref>. Performances of the top 5 ranked participating groups at the Checkworthiness prediction task.</p><p>Team Name submission MAP RR P@1 P@3 P@5 P@10 P@20 P@50 Copenhagen primary 0.1660 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entities analysis:</head><p>In our experiments, we use the Sematch [13]<ref type="foot" coords="7,434.94,306.83,3.97,6.12" target="#foot_4">5</ref> 's KG semantic similarity and relatedness algorithms to calculate the similarity and relatedness of every pair of entities appearing in each sentence. We then calculate the average and maximum similarity scores as well as the relatedness score of a sentence, and use these 4 scores as features. We also count the unique number of entities appearing in each sentence.</p><p>Classifier: We tune the SVM classifier's hyperparameters on the training set. In particular, we use the RBF kernel, a C penalty of 10, and a γ of 0.1 in our tuned SVM classifier. Sentences are ranked in descending order by their distance from the classifier's hyperplane.</p><p>Evaluation metrics: To evaluate the effectiveness of our approach at highly ranking check-worthy sentences, we use the evaluation metrics suggested by the CheckThat! lab organisers, namely Mean Average Precision (MAP), reciprocal rank (RR), and precision at k (P@k, k={1,3,5,10,20,50}).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>In this section, we address the usefulness of including the pre-processing procedure, as well as the effectiveness of our classification model. In particular, we report and discuss the results of our sentence check-worthiness prediction experiments. Table <ref type="table" coords="7,222.63,554.18,4.98,8.74">3</ref> shows the effectiveness of the top 5 ranked groups that participated in the Lab. Out of a total of 12 groups, our classifier was placed fourth group (ranked by MAP).</p><p>Next, to answer whether the pre-processing of data benefits the check-worthiness prediction task, we conduct an ablation study, whereby we remove some of the components of our approach and assessed their resulting performance. Table <ref type="table" coords="7,161.45,625.91,4.98,8.74">4</ref> presents the results using three different variants of our approach: simple TF-IDF model with an SVM classifier, using the pre-processing procedure to Table <ref type="table" coords="8,165.97,115.91,4.13,7.89">4</ref>. Performances of our classifier ranking approach with and without preprocessing and entity-based features.</p><p>Pre-processing TFIDF Entities MAP RR P@1 P@3 P@5 P@10 P@20 P@50 0.0826 0.2000 0.0000 0.0000 0.2000 0.2000 0.3500 0.1571 0.0956 0.2000 0.1667 0.1875 0.1471 0.1587 0.0985 0.0874 0.1263 0.3254 0.2857 0.2381 0.2000 0.2000 0.1287 0.0915 process the debate before using the TF-IDF features and the SVM classifier, and our full approach. The results show that the pre-processing procedure to address pronouns and perform coreference resolution improves MAP performance by 16% (0.0826 → 0.0956). Furthermore, adding the entities features enhances MAP by a further 32% (0.0956 → 0.1263). Thus, we conclude that the pre-processing procedure, as well as our entity-based features are promising and do improve the performance of our approach. However, as the coreference resolution method cannot achieve a perfect accuracy, the results of our pre-processing procedure are not completely satisfactory. Table <ref type="table" coords="8,161.75,328.53,4.98,8.74" target="#tab_3">5</ref> shows a clip of one debate, where some sentences' pronouns and coreference resolutions are correct, some are missing, and some are incorrect. Moreover, we do not consider the types of entities in our entity analysis. Such type information may actually be informative, as the entity "the United States" may be less informative than "immigration" in an American political debate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we addressed a task that can be seen as the first step towards factchecking internet content effectively, as defined by the CLEF CheckThat! 2019 Lab. In particular, we designed a pre-processing procedure, as well as a checkworthiness prediction model, to predict the check-worthiness of each sentence in a given debate. Our experiments showed that the pre-processing procedure, with pronouns resolution and coreference resolution, does improve the performance of the prediction system. Moreover, when using entities extracted and analysed using existing knowledge base tools, the performance of our prediction approach improved further. These findings suggest that pre-processing can be beneficial when analysing text for check-worthiness prediction. They also show that entities analysis might be beneficial in the general fake news detection tasks. In the future, we propose to compare more machine learning methods, and enrich the language processing choices. He calls the two of you plan amnesty.</p><p>Missing resolution</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,201.02,345.83,7.89;5,134.77,212.01,345.83,7.86;5,134.77,222.96,122.42,7.86"><head>1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 2. The check-worthiness estimation approach. A parallelogram represents input and/or output; a rectangle represents a process; an arrow represents the relationship flow between two components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,203.43,614.81,59.39,8.74;5,266.23,608.07,144.50,8.74;5,276.84,621.64,123.28,8.74"><head></head><label></label><figDesc>sr(a, b) = 1 -log(max(|A|, |B|)) -log(|A ∩ B|) log(|W |) -log(min(|A|, |B|)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,177.07,115.91,261.23,7.89"><head>Table 1 .</head><label>1</label><figDesc>Examples of sentences to check. Bold denotes entities.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,115.91,345.82,98.00"><head>Table 2 .</head><label>2</label><figDesc>Examples of the entity features of each sentence we obtain through entity analysis.</figDesc><table coords="6,219.94,147.67,175.48,66.24"><row><cell>Method name</cell><cell cols="2">Aggregation # of features</cell></row><row><cell>Similarity</cell><cell>mean</cell><cell>1</cell></row><row><cell>of entities</cell><cell>max</cell><cell>1</cell></row><row><cell>Relatedness</cell><cell>mean</cell><cell>1</cell></row><row><cell>of entities</cell><cell>max</cell><cell>1</cell></row><row><cell>Count of entities</cell><cell>-</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,134.77,115.91,345.83,437.06"><head>Table 5 .</head><label>5</label><figDesc>An example of the results of the pre-processing procedure. Bold denotes the pronouns that should have been changed to the entity it refers to. Italic denotes the changed results of the pre-processing procedure. Underline denotes the word is referring to an entity.</figDesc><table coords="9,139.59,169.57,327.91,383.40"><row><cell cols="2">Speaker's name Original text</cell><cell>after pre-processing</cell><cell>type of results</cell></row><row><cell>BLITZER</cell><cell>When nearly half of</cell><cell>When nearly half of</cell><cell>No entities to be</cell></row><row><cell></cell><cell>the delegates ..., and</cell><cell>the delegates ..., and</cell><cell>resolved</cell></row><row><cell></cell><cell>the biggest prize of</cell><cell>the biggest prize of</cell><cell></cell></row><row><cell></cell><cell>the night is Texas.</cell><cell>the night is Texas .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>Immigration is a key</cell><cell>Immigration is a key</cell><cell>Correct resolution</cell></row><row><cell></cell><cell>issue in this state,</cell><cell>issue in Texas , for all</cell><cell></cell></row><row><cell></cell><cell>for all voters</cell><cell>voters nationwide...</cell><cell></cell></row><row><cell></cell><cell>nationwide...</cell><cell></cell><cell></cell></row><row><cell>BLITZER</cell><cell>So, that's where we</cell><cell>So , Immigration 's</cell><cell>Correct resolution</cell></row><row><cell></cell><cell>begin.</cell><cell>where we begin .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>Mr. Trump, you've</cell><cell>Mr. Trump, you've</cell><cell>No entities to be</cell></row><row><cell></cell><cell>called for a</cell><cell>called for a</cell><cell>resolved</cell></row><row><cell></cell><cell>deportation force to</cell><cell>deportation force to</cell><cell></cell></row><row><cell></cell><cell>remove the 11 million</cell><cell>remove the 11 million</cell><cell></cell></row><row><cell></cell><cell>undocumented</cell><cell>undocumented</cell><cell></cell></row><row><cell></cell><cell>immigrants from</cell><cell>immigrants from</cell><cell></cell></row><row><cell></cell><cell>the United States.</cell><cell>the United States...</cell><cell></cell></row><row><cell>BLITZER</cell><cell>You've also promised</cell><cell>You 've also promised</cell><cell>No entities to be</cell></row><row><cell></cell><cell>to let what you call,</cell><cell>to let what you call ,</cell><cell>resolved</cell></row><row><cell></cell><cell>"the good ones",</cell><cell>" the good ones " ,</cell><cell></cell></row><row><cell></cell><cell>come back in.</cell><cell>come back in .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>Your words, "the</cell><cell>Your words , " the</cell><cell>No entities to be</cell></row><row><cell></cell><cell>good ones", after</cell><cell>good ones " , after</cell><cell>resolved</cell></row><row><cell></cell><cell>they've been</cell><cell>they 've been</cell><cell></cell></row><row><cell></cell><cell>deported.</cell><cell>deported .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>Senator Cruz would</cell><cell>Senator Cruz would</cell><cell>Incorrect resolution</cell></row><row><cell></cell><cell>not allow them to</cell><cell>not allow they to</cell><cell></cell></row><row><cell></cell><cell>come back in.</cell><cell>come back in .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>He says that's the</cell><cell>Senator Cruz says</cell><cell>Correct resolution</cell></row><row><cell></cell><cell>biggest difference</cell><cell>that 's the biggest</cell><cell></cell></row><row><cell></cell><cell>between the two of</cell><cell>difference between the</cell><cell></cell></row><row><cell></cell><cell>you.</cell><cell>two of you .</cell><cell></cell></row><row><cell>BLITZER</cell><cell>He calls your plan</cell><cell></cell><cell></cell></row><row><cell></cell><cell>amnesty.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,645.84,330.63,7.86;5,144.73,656.80,81.45,7.86"><p>https://scikit-learn.org/stable/modules/generated/sklearn.feature extraction.text. TfidfVectorizer.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.73,623.92,151.11,7.86"><p>https://github.com/kentonl/e2e-coref</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,144.73,634.88,330.63,7.86;6,144.73,645.84,81.45,7.86"><p>https://scikit-learn.org/stable/modules/generated/sklearn.feature extraction.text. TfidfVectorizer.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,144.73,656.80,254.87,7.86"><p>https://github.com/dbpedia-spotlight/dbpedia-spotlight-model</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="7,144.73,656.80,150.93,7.86"><p>https://github.com/gsi-upm/sematch</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The first authors acknowledges the support of the <rs type="funder">China Scholarship Council</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.35,602.26,342.24,7.86;9,146.91,613.22,333.68,7.86;9,146.91,624.18,333.68,7.86;9,146.91,635.14,142.09,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,281.07,613.22,199.52,7.86;9,146.91,624.18,317.54,7.86">Overview of the CLEF-2019 CheckThat! Lab on Automatic Identification and Verification of Claims. Task 1: Check-Worthiness</title>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgi</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Da San</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,146.91,635.14,109.22,7.86">Proc. of CLEF-CEUR 2019</title>
		<meeting>of CLEF-CEUR 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,645.84,342.25,7.86;9,146.91,656.80,333.68,7.86;9,146.91,667.76,263.38,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,374.31,656.80,106.29,7.86;9,146.91,667.76,115.66,7.86">Computational fact checking from knowledge networks</title>
		<author>
			<persName coords=""><forename type="first">Giovanni</forename><surname>Ciampaglia</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Luca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prashant</forename><surname>Shiralkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><forename type="middle">M</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johan</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alessandro</forename><surname>Flammini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,269.89,667.76,33.92,7.86">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">128193</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,119.67,342.24,7.86;10,146.91,130.63,333.68,7.86;10,146.91,141.59,25.60,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,226.44,119.67,254.15,7.86;10,146.91,130.63,80.46,7.86">Forms of conversation and problem structuring methods: a conceptual development</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Alberto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,234.48,130.63,169.43,7.86">Journal of the operational research society</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="813" to="821" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,152.55,342.24,7.86;10,146.91,163.51,333.68,7.86;10,146.91,174.47,296.04,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,254.54,163.51,226.05,7.86;10,146.91,174.47,103.26,7.86">A context-aware approach for detecting worth-checking claims in political debates</title>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,268.87,174.47,87.46,7.86">Proc. of RANLP 2017</title>
		<meeting>of RANLP 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,185.43,342.24,7.86;10,146.91,196.39,333.68,7.86;10,146.91,207.34,333.68,7.86;10,146.91,218.30,302.08,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,464.72,185.43,15.88,7.86;10,146.91,196.39,333.68,7.86;10,146.91,207.34,333.68,7.86;10,146.91,218.30,87.94,7.86">The Copenhagen team participation in the check-worthiness task of the competition of automatic identification and verification of claims in political debates of the CLEF-2018 fact checking lab</title>
		<author>
			<persName coords=""><forename type="first">Casper</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,253.15,218.30,89.35,7.86">Proc. of CLEF-CEUR</title>
		<meeting>of CLEF-CEUR</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="171" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,229.26,342.24,7.86;10,146.91,240.22,333.68,7.86;10,146.91,251.18,333.68,7.86;10,146.91,262.14,333.68,7.86;10,146.91,273.10,47.11,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,429.06,251.18,51.53,7.86;10,146.91,262.14,180.79,7.86">Claimbuster: The first-ever end-to-end fact-checking system</title>
		<author>
			<persName coords=""><forename type="first">Naeemul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gensheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fatma</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josue</forename><surname>Caraballo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Damian</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siddhant</forename><surname>Gawsane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shohedul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minumol</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aaditya</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anil</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Other</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,334.12,262.14,76.11,7.86">VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1945" to="1948" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,284.06,342.24,7.86;10,146.91,295.02,333.68,7.86;10,146.91,305.98,160.37,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,429.04,284.06,51.55,7.86;10,146.91,295.02,271.06,7.86">Mendes: Improving Efficiency and Accuracy in Multilingual Entity Extraction</title>
		<author>
			<persName coords=""><forename type="first">Joachim</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pablo</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,437.97,295.02,42.63,7.86;10,146.91,305.98,75.27,7.86">Proc. of I-SEMANTICS 2013</title>
		<meeting>of I-SEMANTICS 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="121" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,316.93,342.24,7.86;10,146.91,327.89,333.68,7.86;10,146.91,338.85,183.16,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Israa</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07587</idno>
		<title level="m" coord="10,233.03,327.89,247.57,7.86;10,146.91,338.85,17.54,7.86">Claimrank: Detecting check-worthy claims in arabic and english</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,138.35,349.81,342.24,7.86;10,146.91,360.77,311.47,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.05392</idno>
		<title level="m" coord="10,364.38,349.81,116.21,7.86;10,146.91,360.77,142.97,7.86">Higher-order coreference resolution with coarse-to-fine inference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.62,371.73,337.98,7.86;10,146.91,382.69,333.68,7.86;10,146.91,393.65,151.80,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,400.74,371.73,79.86,7.86;10,146.91,382.69,294.65,7.86">TATHYA: A multiclassifier system for detecting check-worthy statements in political debates</title>
		<author>
			<persName coords=""><forename type="first">Ayush</forename><surname>Patwari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saurabh</forename><surname>Bagchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,459.20,382.69,21.39,7.86;10,146.91,393.65,55.95,7.86">Proc. of CIKM 2017</title>
		<meeting>of CIKM 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2259" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,404.61,337.98,7.86;10,146.91,415.56,333.68,7.86;10,146.91,426.52,67.58,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,293.70,404.61,186.89,7.86;10,146.91,415.56,160.30,7.86">An effective, low-cost measure of semantic relatedness obtained from Wikipedia links</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,324.87,415.56,151.52,7.86">Proc. of WAI workshop at AAAI 2008</title>
		<meeting>of WAI workshop at AAAI 2008</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,437.48,337.97,7.86;10,146.91,448.44,333.68,7.86;10,146.91,459.40,94.21,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,324.10,437.48,156.49,7.86;10,146.91,448.44,102.44,7.86">Computing semantic similarity of concepts in knowledge graphs</title>
		<author>
			<persName coords=""><forename type="first">Ganggao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Angel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,256.09,448.44,224.51,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="85" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,470.36,337.97,7.86;10,146.91,481.32,262.26,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,376.36,470.36,104.23,7.86;10,146.91,481.32,115.65,7.86">Sematch: semantic entity search from knowledge graph</title>
		<author>
			<persName coords=""><forename type="first">Ganggao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iglesias</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Angel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,269.91,481.32,68.92,7.86">Telecomunicacion</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,492.28,337.97,7.86;10,146.91,503.24,333.68,7.86;10,146.91,514.19,171.38,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,365.65,492.28,114.93,7.86;10,146.91,503.24,292.66,7.86">Ritwik: A hybrid recognition system for check-worthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">Chaoyuan</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ayla</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ida</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,459.19,503.24,21.40,7.86;10,146.91,514.19,64.89,7.86">Proc. of CLEF-CEUR</title>
		<meeting>of CLEF-CEUR</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="171" to="175" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
