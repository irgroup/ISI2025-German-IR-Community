<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,128.64,152.52,338.21,12.61;1,252.00,170.52,91.55,12.61">Location-Based Species Recommendation GeoLifeCLEF 2019 Challenge</title>
				<funder ref="#_jbmwjpF #_5D8npxv">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,218.88,209.63,97.60,9.02"><forename type="first">Costel-Sergiu</forename><surname>Atodiresei</surname></persName>
							<email>sergiu.atodiresei@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">UAIC</orgName>
								<orgName type="department" key="dep2">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.04,209.63,53.50,9.02"><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">UAIC</orgName>
								<orgName type="department" key="dep2">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,128.64,152.52,338.21,12.61;1,252.00,170.52,91.55,12.61">Location-Based Species Recommendation GeoLifeCLEF 2019 Challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE2A065C4D354E8D5568FF7DBF1C2AF0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GeoLifeCLEF</term>
					<term>Random Forest</term>
					<term>K-Nearest Neighbors</term>
					<term>Artificial Neural Networks</term>
					<term>XGBoost</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, it is presented a system built with the aim to predict plant species given their location in the context of the GeoLifeCLEF 2019 challenge. There are developed several prediction models on the basis of a representation in the environmental space (a feature vector composed of climatic variables and other variables such as soil type, land cover, distance to water) and using the spatial occurrences of species (latitude and longitude): Random Forest, K-Nearest Neighbors, Artificial Neural Networks and XGBoost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatically predicting the list of species that are the most likely to be observed at a given location is useful for many scenarios in biodiversity informatics. First of all, it could improve species identification processes and tools by reducing the list of candidate species that are observable at a given location (be they automated, semiautomated or based on classical field guides or flora). More generally, it could facilitate biodiversity inventories through the development of location-based recommendation services (typically on mobile phones) as well as the involvement of non-expert nature observers. Last but not least, it might serve educational purposes thanks to biodiversity discovery applications providing functionalities such as contextualized educational pathways <ref type="bibr" coords="1,165.00,546.59,10.69,9.02" target="#b0">[1]</ref>. The aim of the challenge is to predict the list of species that are the most likely to be observed at a given location. In the previous edition, in the context of the GeoLifeCLEF 2018 challenge 1 , several approaches for plant predictions given their location were used. The winners of the challenge 2018 have developed three kinds of prediction models, one convolutional neural network on environmental data (CNN), one neural network on co-occurrences data and two other models only based on the spatial occurrences of species. Results show the effectiveness of the CNN which obtained the best prediction score of the whole GeoLifeCLEF challenge. The fusion of this model with the spatial ones only provides slight improvements suggesting that the CNN already captured most of the spatial information in addition to the environmental preferences of the plants <ref type="bibr" coords="2,224.64,198.11,10.69,9.02" target="#b1">[2]</ref>. Location-based species prediction is very similar with the problem Species distribution modelling (SDM), also known as environmental (or ecological) niche modelling (ENM), habitat modelling, or predictive habitat distribution modelling, which uses computer algorithms to predict the distribution of a species across geographic space and time using environmental data. The environmental data are most often climate data (e.g. temperature, precipitation), but can include other variables such as soil type, water depth, and land cover. SDMs are used in several research areas in conservation biology, ecology and evolution. Predictions of current and/or future habitat suitability can be useful for management applications (e.g. reintroduction or translocation of vulnerable species, reserve placement in anticipation of climate change) <ref type="bibr" coords="2,201.60,318.11,10.69,9.02" target="#b2">[3]</ref>.</p><p>In this paper are presented 4 machine learning models for predicting plant species in the context of the GeoLifeCLEF 2019 challenge <ref type="bibr" coords="2,332.64,342.11,10.90,9.02" target="#b3">[4]</ref>: (1) K-Nearest Neighbors: (i) Based on the environmental data (like temperature, precipitation, soil type, water depth, land cover etc.); (ii) Based on the spatial occurrences of species (a spatial model), (2) Random Forest: (i) Based on the environmental data; (ii) Based on the spatial occurrences of species, (3) Artificial Neural Networks based on the environmental data, (4) XGBoost: (i) Based on the environmental data; (ii) Based on the spatial occurrences of species. After splitting the train dataset in 90% (for training) and 10% (for testing), Random Forest and K-NN captured most of the environmental information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Evaluation Methodology</head><p>GeoLifeCLEF provides a large training set of species occurrences, each occurrence being associated to a multi-channel image characterizing the local environment. Indeed, it is usually not possible to learn a species distribution model directly from spatial positions because of the limited number of occurrences and the sampling bias. The train dataset includes 280,945 train and test georeferenced occurrences of plant species from last year (file GLC_2018.csv). Plus, 2,367,145 plant species occurrences with uncertain identifications are added (file PL_complete.csv). They come from automatic species identification of pictures produced in 2017-2018 by the smartphone application Pl@ntNet, where users are mainly amateur botanists <ref type="bibr" coords="2,410.52,579.11,10.69,9.02" target="#b4">[5]</ref>. A trusted extraction of this dataset is also provided (file PL_trusted.csv), insuring a reasonable level of identification certainty. Finally, 10,618,839 species occurrences from other kingdoms (as mammals, birds, amphibians, insects, fungi's etc.) were selected from the GBIF database (file noPlant.csv). 33 environmental raster's (constructed from various open datasets) covering the French territory are made available, so that each occurrence may be linked to an environmental tensor via a participant customizable Python code <ref type="bibr" coords="2,124.80,663.11,10.69,9.02" target="#b5">[6]</ref>. The test occurrences data come from independents datasets of the French National Botanical Conservatories. This TestSet includes 844 plant species. It is a subset of those found in the train set. The main evaluation criteria will be the accuracy based on the 30 first answers, also called Top 30. It is the mean of the function scoring 1 when the good species is in the 30 first answers, and 0 otherwise, over all test set occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>Proposed Solution</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General Architecture of the System</head><p>The general architecture of the system is presented in Fig. <ref type="figure" coords="3,369.36,257.11,3.76,8.94" target="#fig_0">1</ref>. There is a Processing Training Data Module, which extracts and augments (with climatic variables and other variables such as soil type, land cover, distance to water, etc.) plant species occurrences with certain and uncertain identifications. The output of this module consists of 2 .csv files. The first one is made of spatial occurrences of species (latitude and longitude) and the second one is composed of 29 environmental variables. This files are the input for the Machine Learning Module where our 4 machine learning models are used to predict 25,000 plant species occurences from the test data. Finally, the Predictions Collector Module generates 20 run files based on the output (32 .csv files) from the previous module, each run file containing the prediction of a particular model, or mixed predictions from several/all models. These runs has been submitted to be evaluated within the GeoLifeCLEF 2019 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>The system is based of 3 modules, developed in Python and using several libraries like Pandas (providing high-performance, easy-to-use data structures and data analysis tools) <ref type="bibr" coords="4,153.12,320.15,10.69,9.02" target="#b6">[7]</ref>, NumPy (for scientific computing) [8], Scikit-learn (contains machine learning algorithms including K-Nearest Neighbors, Random Forest and also preprocessing) <ref type="bibr" coords="4,187.20,344.15,11.71,9.02" target="#b7">[9]</ref> similar to work from <ref type="bibr" coords="4,292.20,344.15,15.93,9.02" target="#b8">[10,</ref><ref type="bibr" coords="4,311.76,344.15,11.95,9.02" target="#b9">11]</ref>, Keras (high-level neural networks API) <ref type="bibr" coords="4,148.68,356.15,15.43,9.02" target="#b10">[12]</ref>, XGBoost (implements machine learning algorithms under the Gradient Boosting framework) <ref type="bibr" coords="4,213.00,368.15,15.43,9.02" target="#b11">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Main Modules</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Processing Training Data Module</head><p>This module processes 2 datasets: (1) PL_complete.csv with 2,367,145 plant species occurrences with uncertain identifications, (2) PL_trusted.csv -a trusted extraction of the complete dataset (approx. 10%) insuring a reasonable level of identification certainty.</p><p>The output consists in 4 files: (1, 2) PL_complete_core.csv, PL_trusted_core.csvbased on the spatial occurrences of species and have 3 columns containing in this order: latitude, longitude, glc19SpId. The values of latitude and longitude are rounded to 4 decimals to avoid overfitting as much as possible in the machine learning models, <ref type="bibr" coords="4,459.96,513.59,10.89,9.02" target="#b2">(3,</ref><ref type="bibr" coords="4,124.80,525.59,8.35,9.02" target="#b3">4)</ref> PL_complete_env.csv, PL_trusted_env.core -based on the environmental variables and have 30 columns. Each plant occurrence was linked to environmental tensors via a customizable Python code provided in the context of the challenge and 29 climatic variables and other variables were extracted: chbio_1, chbio_3, chbio_4, chbio_5, chbio_6, chbio_7, chbio_8, chbio_9, chbio_10, chbio_11, chbio_12, chbio_13, chbio_14, chbio_15, chbio_16, chbio_17, chbio_18, chbio_19, etp, alti, awc_top, bs_top, cec_top, crusting, dgh, dimp, erodi, oc_top, pd_top. More variables were available, but those didn't provide a clear added value. Each occurrence ID in the submitted run must exist in the testSet file (glc19TestOccId). Each predicted plant species (glc19SpId) must be one of the species marked as TRUE in the column "test" of the Table of species Ids and names and identification of test set species <ref type="bibr" coords="4,429.84,645.59,15.43,9.02" target="#b12">[14]</ref>. As a consequence, to predict the test dataset, the .csv files are filtered and contain only the occurrences of species marked as TRUE in the test set species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Machine Learning Module</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. K-Nearest Neighbors Classifier</head><p>One of the machine learning models used is K-Nearest Neighbors Classifier, where the output is the class membership (e.g. plant species id -glc19SpId) most common among its k nearest neighbors <ref type="bibr" coords="5,220.92,197.15,15.43,9.02" target="#b13">[15]</ref>. The distance between neighbors is determined with the Euclidean metric.</p><p>Multiple K-NN models were developed with 1, 3, and 5 neighbors. No more than 5 neighbors were used because, as can be seen in the section 4, the accuracy decreases as many trees are used. Finally, the predictions from several/all models were merged, as stated in section 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Random Forest Classifier</head><p>Another machine learning algorithm used is Random Forest Classifier that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode (the value that appears most often) of the classes <ref type="bibr" coords="5,367.92,458.51,15.43,9.02" target="#b14">[16]</ref>. First, feature scaling is applied to the train and test data by removing the mean and scaling to unit variance. Then the Random Forest Classifier is fitted to the training set. The number of trees in the forest is 10 and the function to measure the quality of a split is "entropy" criteria for the information gain.</p><p>This classifier generates 12 different predictions (.csv files), depending to random state (the seed used by the random number generator), if the training dataset has certain and uncertain identifications and based on the spatial occurrences of species or based on the environmental data. Considering that, the K-NN model predicts the following lists of species: A Random Forest Classifier with 8 number or trees was developed, but as stated in the section 4, the accuracy was smaller than the model with 10 trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Artificial Neural Networks</head><p>An artificial neural network is an interconnected group of nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it <ref type="bibr" coords="6,300.60,209.63,15.43,9.02" target="#b15">[17]</ref>. First, label binarizer is applied to the output variable (glc19SpId) to convert multi-class labels to binary labels (belong or does not belong to the class). Then feature scaling is applied to the train and test data.</p><p>A Neural Network model is based on the Sequential model which is a linear stack of layers. The model needs to know what input shape it should expect. In consequence, the input layer in a Sequential model (and only the first, because following layers can do automatic shape inference) is a Dense layer where the input shape is specified via the argument input_dim. In our case the input shape is equal to a feature vector shape (composed of 29 climatic variables and other variables such as soil type, land cover, distance to water) used to train this machine learning model. The Rectified Linear Unit function (relu) is passed to the input and hidden layers as the activation argument. For the output layer, the Softmax activation function is used. The system makes use of 3 Sequential models with a different number of hidden layers based on the geometric pyramid rule (the Masters rule): a) for one hidden layer the number of neurons in the hidden layer is equal to: = ×</p><p>where nrHidden -the number of neurons in the hidden layer; nrInput -the number of neurons in the input layer; nrOutput -the number of neurons in the output layer. b) for two hidden layers:</p><formula xml:id="formula_0" coords="6,188.76,460.09,116.56,36.72">= × 3 1 = × r 2 = ×</formula><p>where nrHidden1 -the number of neurons in the first hidden layer; nrHidden2 -the number of neurons in the second hidden layer. c) for three hidden layers:</p><formula xml:id="formula_1" coords="6,191.40,555.61,116.08,48.60">= × 4 1 = × r 2 = × r 3 = ×</formula><p>where nrHidden1 -the number of neurons in the first hidden layer; nrHidden2 -the number of neurons in the second hidden layer; nrHidden3 -the number of neurons in the third hidden layer.</p><p>In our case, we consider 3 models: (1) the first model -trained with observations from the trusted dataset has 29 neurons in the input layer, one for each environmental and climatic feature, 197 neurons in the hidden layer, and 1348 neurons in the output layer, one for each plant species id, then trained with observations from the complete dataset has 29 neurons in the input layer, one for each environmental and climatic feature, 336 neurons in the hidden layer, and 3096 neurons in the output layer, one for each plant species id, (2) the second modeltrained with observations from the trusted dataset has 29 neurons in the input layer, 1089 neurons in the first hidden layer, 33 neurons in the second hidden layer, and 1348 neurons in the output layer, and then trained with observations from the complete dataset has 29 neurons in the input layer, 2304 neurons in the first hidden layer, 48 neurons in the second hidden layer, and 3096 neurons in the output layer, and (3) the third model -trained with observations from the trusted dataset has 29 neurons in the input layer, 2744 neurons in the first hidden layer, 196 neurons in the second hidden layer, 14 neurons in the third hidden layer, and 1348 neurons in the output layer, and then trained with observations from the complete dataset has 29 neurons in the input layer, 5832 neurons in the first hidden layer, 324 neurons in the second hidden layer, 18 neurons in the third hidden layer, and 3096 neurons in the output layer.</p><p>This classifier generates 6 different predictions (.csv files), depending to the model used and if the training dataset has certain and uncertain identification. Considering that, the ANN predicts the following lists of species: (1) ann_[1|2|3]_complete_env.csv -the 1st/2nd/3rd model is used and is trained with the complete dataset; (2) ann_[1|2|3]_trusted_env.csv -the 1st/2nd/3rd model is used and is trained with the trusted dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. XGBoost</head><p>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework <ref type="bibr" coords="7,247.32,449.15,15.43,9.02" target="#b16">[18]</ref>.</p><p>First, feature scaling is applied to the train and test data by removing the mean and scaling to unit variance. Then the XGBClassifer (implementation of the scikit-learn API for XGBoost classification.) is fitted to the training set. The number of trees to fit is 100.</p><p>This classifier generates 2 different predictions (.csv files), based on the spatial occurrences of species or based on the environmental data:</p><p>• xgboost_env_trusted.csv -the trusted training dataset is used and is based on the environmental data; • xgboost_spatial_trusted.csv -the trusted training dataset is used and is based on the spatial occurrences of species (longitude, latitude);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Predictions Collector Module</head><p>All the predictions lists (.csv files) are collected and processed to generate 20 run files, each run file containing the predictions of a particular model, or mixed predictions from several/all models. A run is a .csv file with 4 columns separated by ";" and containing in this order: glc19TestOccId ; glc19SpId ; Rank ; Probability. The models who predict the same plant species (glc19SpId) are combined in a single prediction (row in the .csv) with the probability being equal with the sum of probabilities associated with each model. These runs (including the algorithms who produced the predictions list) has been submitted to be evaluated within the GeoLifeCLEF 2019 challenge: 1) run_1 (Visual retrieval type): K-Nearest Neighbors algorithm (1-NN) -Based on the environmental data (trusted dataset). 2) run_2 (Visual retrieval type): K-Nearest Neighbors algorithm (1-NN) -Based on the environmental data (complete dataset). 3) run_3 (Visual retrieval type): K-Nearest Neighbors algorithm (3-NN and 5-NN) -Based on the environmental data (trusted and complete datasets). 4) run_4 (Textual retrieval type): K-Nearest Neighbors algorithm (1-NN) -Based on the spatial occurrences of species (trusted dataset). 5) run_5 (Textual retrieval type): K-Nearest Neighbors algorithm (1-NN) -Based on the spatial occurrences of species (complete dataset). 6) run_6 (Textual retrieval type): K-Nearest Neighbors algorithm (3-NN and 5-NN) -Based on the spatial occurrences of species (trusted and complete datasets). The probabilities associated with each model are the same as for run_3. 7) run_7 (Mixed retrieval type): K-Nearest Neighbors algorithm (1-NN) -Based on the spatial occurrences of species and the environmental data (trusted and complete datasets). 8) run_8 (Visual retrieval type): Random Forest algorithm -Based on the environmental data (trusted dataset). 9) run_9 (Visual retrieval type): Random Forest algorithm -Based on the environmental data (complete dataset). 10) run_10 (Visual retrieval type): Random Forest algorithm -Based on the environmental data (trusted and complete datasets). 11) run_11 (Textual retrieval type): Random Forest algorithm -Based on the spatial occurrences of species (trusted dataset). 12) run_12 (Textual retrieval type): Random Forest algorithm -Based on the spatial occurrences of species (complete dataset). 13) run_13 (Textual retrieval type): Random Forest algorithm -Based on the spatial occurrences of species (trusted and complete datasets). The probabilities associated with each model are the same as for run_10. 14) run_14 (Mixed retrieval type): Random Forest algorithm -Based on the spatial occurrences of species and the environmental data (trusted and complete datasets). 15) run_15 (Mixed retrieval type): K-Nearest Neighbors algorithm (1-NN) and Random Forest algorithm -Based on the spatial occurrences of species and the environmental data (trusted dataset). The probability associated with each model is 0.5. 16) run_16 (Mixed retrieval type): K-Nearest Neighbors algorithm (1-NN) and Random Forest algorithm -Based on the spatial occurrences of species and the environmental data (complete dataset). The probability associated with each model is 0.5. 17 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Experiments and evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental results</head><p>To estimate the skill of a machine learning model the k-Fold Cross-Validation is used. Cross-validation is a statistical method used to evaluate machine learning models. It has a single parameter called k that indicates the number of groups that a given data sample is going to be split. Because of that, the method is called k-Fold Cross-Validation. The KFold() scikit-learn class <ref type="bibr" coords="9,295.92,361.19,16.75,9.02" target="#b17">[19]</ref> is used to split a given dataset into 10 consecutive folds (k=10). The cross_val_score scikit-learn function <ref type="bibr" coords="9,403.68,373.19,16.75,9.02" target="#b18">[20]</ref> is called on the classifier and the fold. The results of a k-fold cross-validation run are summarized with the mean of the model skill scores and the standard deviation obtained from the cross_val_score function <ref type="bibr" coords="9,228.00,409.19,15.43,9.02" target="#b19">[21]</ref>.</p><p>For the K-Nearest Neighbors models the following results were obtained: The best model is that with 1 nearest neighbor representing run_4. The differences between the model based on the environmental data and the one based on the spatial occurrences are quite significant. If the test set contains occurrences in areas without unnoticed species, the first model (trained with a feature vector composed of climatic variables and other variables such as soil type, distance to water) will do a better job in predicting the actual plant species. The complete dataset has three times more plant species than the trusted dataset so differences between the models trained with these datasets is normal considering that some species are present more often than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>For the Random Forest models the following results were obtained: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Challenge Results</head><p>This year two criteria's where used to evaluate the runs:</p><p>• The accuracy based on the 30 first answers, also called Top30. It is the mean of the function scoring 1 when the good species is in the 30 first answers, and 0 otherwise, over all test set occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenge Results Analysis</head><p>We cannot rely solely on the spatial appearances because of environmental differences (e.g. two species at 10 km can live in different environments, plain vs. sea coast). Another issue is that some species are present more often than others (e.g. plants that have been observed several times, others thousands of times), so we do not have uniform observations, especially in the complete training dataset as can be seen in the previous section (4). Last difficulty is that an occurrence means a punctual presence of that species, and if it is missing, it does not mean that the species does not exist.</p><p>Unfortunately this leads to uncertainty in areas with unnoticed species. An improvement would be to use more than 10 trees for the Random Forest algorithm to provide a prediction list of 30 species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper details the system developed with the aim to predict plant species given their location for the 2019 edition of GeoLifeCLEF's challenge. We presented and compared four kinds of prediction models trained with the spatial occurrences of species and with the environmental data: Random Forest, K-Nearest Neighbors, Artificial Neural Networks and XGBoost. The results obtained using the Ranking metric and the Mean Reciprocal Rank show that the fusion of mixed predictions from several Random Forest models has the best prediction score of our 20 submitted runs, followed closely by mixed predictions from several K-Nearest Neighbors models. The Random Forest models captured most of the environmental information. For further development of the system the noPlant.csv dataset can be used to extract interesting correlations between plants and animals. This could lead to a more accurate prediction of plant species because some animals live only where certain plants are present.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,249.12,670.93,97.23,8.19;3,159.12,302.16,276.96,360.48"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System architecture</figDesc><graphic coords="3,159.12,302.16,276.96,360.48" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,187.32,564.59,283.29,9.02;5,124.80,576.59,345.99,9.02;5,124.80,588.59,345.81,9.02;5,124.80,600.59,345.91,9.02;5,124.80,612.59,346.02,9.02;5,124.80,624.59,345.85,9.02;5,124.80,636.59,345.78,9.02;5,124.80,648.59,251.85,9.02"><head></head><label></label><figDesc>(1) random_forest_spatial_[1|2|3]_complete.csv -random state = 1/2/3, the complete training dataset is used and is based on the spatial occurrences of species (longitude, latitude); (2) random_forest_spatial_[1|2|3]_trusted.csv -random state = 1/2/3, the trusted training dataset is used and is based on the spatial occurrences of species (longitude, latitude); (3) random_forest_env_[1|2|3]_complete.csv -random state = 1/2/3, the complete training dataset is used and is based on the environmental data; (4) random_forest_env_[1|2|3]_trusted.csv -random state = 1/2/3, the trusted training dataset is used and is based on the environmental data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,133.73,622.07,336.85,9.02;8,138.96,633.47,331.66,9.02;8,138.96,644.99,206.01,9.02;8,124.80,656.51,345.94,9.02;8,138.96,668.03,331.86,9.02;8,138.96,679.55,331.66,9.02;9,138.96,149.51,331.62,9.02;9,138.96,161.03,56.01,9.02;9,124.80,172.55,345.91,9.02;9,138.96,184.07,331.74,9.02;9,138.96,195.59,72.45,9.02;9,124.80,206.99,346.02,9.02;9,138.96,218.51,331.81,9.02;9,138.96,230.03,85.77,9.02"><head></head><label></label><figDesc>) run_17 (Mixed retrieval type): K-Nearest Neighbors algorithm (1-NN) and Random Forest algorithm -Based on the spatial occurrences of species and the environmental data (trusted and complete datasets). 18) run_18 (Visual retrieval type): Artificial neural networks (ANN) -Based on the environmental data (trusted and complete datasets). The ANN model with 1 and 2 hidden layers trained with complete dataset aren't used in this run because the accuracy obtained in the validation experiments is lower than the model with 3 hidden layers. 19) run_19 (Mixed retrieval type): XGBoost -Based on the spatial occurrences of species and the environmental data (trusted dataset). The probability associated with each model is 0.5. 20) run_20 (Visual retrieval type): K-Nearest Neighbors algorithm (1-NN), Random Forest, Artificial neural networks (ANN), XGBoost -Based on the environmental data (trusted dataset).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,124.80,257.15,345.91,153.02"><head></head><label></label><figDesc>3.III. This classifier generates 12 different predictions (.csv files), depending to the number of the nearest neighbors, if the training dataset has certain and uncertain identifications and based on the spatial occurrences of species or based on the environmental data. Considering that, the K-NN predicts the following lists of species: (1) knn_spatial_[1|3|5]nn_complete.csv -1/3/5 nearest neighbor(s), the complete training dataset is used and is based on the spatial occurrences of species (longitude, latitude); (2) knn_spatial_[1|3|5]nn_trusted.csv -1/3/5 nearest neighbor(s), the trusted training dataset is used and is based on the spatial occurrences of species (longitude, latitude); (3) knn_env_[1|3|5]nn_complete.csv -1/3/5 nearest neighbor(s), the complete training dataset is used and is based on the environmental data; (4) knn_env_[1|3|5]nn_trusted.csv -1/3/5 nearest neighbor(s), the trusted training dataset is used and is based on the environmental data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,124.80,197.23,345.92,398.82"><head></head><label></label><figDesc>The conclusion is the same as for the K-NN model. The differences between the model based on the environmental data and the one based on the spatial occurrences are quite considerable.For the Artificial Neural Network models the following results were obtained:</figDesc><table coords="10,124.80,197.23,345.91,398.82"><row><cell></cell><cell></cell><cell></cell><cell>Mean</cell><cell>Standard deviation</cell></row><row><cell cols="3">Based on the spatial occurrences of species (trusted dataset)</cell><cell>36.88%</cell><cell>0.26%</cell></row><row><cell cols="3">Based on the spatial occurrences of species (complete dataset)</cell><cell>25.22%</cell><cell>0.08%</cell></row><row><cell cols="2">Based on the environmental data (trusted dataset)</cell><cell></cell><cell>30.20%</cell><cell>0.29%</cell></row><row><cell cols="3">Based on the environmental data (complete dataset)</cell><cell>13.89%</cell><cell>0.06%</cell></row><row><cell cols="5">The best model is based on the spatial occurrences of species (trusted dataset)</cell></row><row><cell>representing run_11. Dataset</cell><cell cols="2">Number of</cell><cell>Mean</cell><cell>Standard</cell></row><row><cell></cell><cell cols="2">hidden layers</cell><cell></cell><cell>deviation</cell></row><row><cell>Based on the environmental</cell><cell>1</cell><cell></cell><cell>6.46%</cell><cell>0.22%</cell></row><row><cell>data (trusted dataset)</cell><cell>2</cell><cell></cell><cell>6.59%</cell><cell>0.27%</cell></row><row><cell></cell><cell>3</cell><cell></cell><cell>6.71%</cell><cell>0.24%</cell></row><row><cell>Based on the environmental</cell><cell>1</cell><cell></cell><cell>6.28%</cell><cell>0.05%</cell></row><row><cell>data (complete dataset)</cell><cell>2</cell><cell></cell><cell>6.41%</cell><cell>0.03%</cell></row><row><cell></cell><cell>3</cell><cell></cell><cell>6.65%</cell><cell>0.05%</cell></row><row><cell cols="5">The differences between models are negligible. The models built with 3 hidden</cell></row><row><cell cols="3">layers have achieved slightly better results (run_18).</cell><cell></cell></row><row><cell cols="5">For the XGBoost models (run_19) the following results were obtained:</cell></row><row><cell>Dataset</cell><cell></cell><cell>Mean</cell><cell></cell><cell>Standard deviation</cell></row><row><cell cols="2">Based on the spatial occurrences of species (trusted dataset)</cell><cell>9.38%</cell><cell></cell><cell>0.28%</cell></row><row><cell cols="2">Based on the environmental data (trusted dataset)</cell><cell>8.24%</cell><cell></cell><cell>0.06%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is partially supported by <rs type="grantNumber">POC-A1-A1.2.3-G-2015</rs> program, as part of the <rs type="projectName">PrivateSky</rs> project (<rs type="grantNumber">P 40 371/13/01.09.2016</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_jbmwjpF">
					<idno type="grant-number">POC-A1-A1.2.3-G-2015</idno>
					<orgName type="project" subtype="full">PrivateSky</orgName>
				</org>
				<org type="funding" xml:id="_5D8npxv">
					<idno type="grant-number">P 40 371/13/01.09.2016</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The final results presented by the organizers show that the run_14, which is a list predicted by a Random Forest model based on the spatial occurrences of species and the environmental data (trusted and complete datasets), has achieved the best accuracy of our 20 submitted runs. The next one is the run_10, also a list predicted by a Random Forest model, this time trained with environmental data (trusted and complete datasets). The third one is the run_7, generated by the 1-NN model based on the spatial occurrences of species and the environmental data (trusted and complete datasets).</p><p>On the opposite side, the last places are occupied by run_1, run_12 and run_2. These are produced by 1-NN model (based on the environmental data -trusted dataset), Random Forest model (based on the spatial occurrences of species -complete dataset), and again 1-NN model based on the environmental data, but this time using the complete dataset. The predicted plant species from run_18 (ANN) and run_19 (XGBoost) have approximately half and one third, respectively, of the accuracy of the predicted list from run_14.</p><p>It appears that Random Forest and 1-Neareast Neighbors predict the plant species with the best accuracy, like in experimental results, only if a run contains a mixed predictions from several models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,132.76,566.57,174.66,8.15;12,141.84,577.61,293.01,8.15" xml:id="b0">
	<monogr>
		<ptr target="https://www.imageclef.org/GeoLifeCLEF2019" />
		<title level="m" coord="12,141.84,566.57,51.92,8.15">GeoLifeCLEF</title>
		<imprint>
			<date type="published" when="2019-04">2019. April, 2019</date>
		</imprint>
	</monogr>
	<note>Usage scenario section</note>
</biblStruct>

<biblStruct coords="12,132.76,588.05,327.25,8.15;12,141.84,599.93,258.10,8.15;12,141.84,611.81,285.90,8.15;12,141.84,623.69,327.51,8.15;12,141.84,635.57,121.77,8.15" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<ptr target="https://www.researchgate.net/publication/327542744_Location-based_species_recommendation_using_co" />
		<title level="m" coord="12,313.56,588.05,146.46,8.15;12,141.84,599.93,254.42,8.15">Location-based species recommendation using co-occurrences and environment -GeoLifeCLEF 2018 challenge</title>
		<imprint>
			<date type="published" when="2019-04">April, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.76,648.05,338.05,8.15;12,141.84,659.09,328.98,8.15;12,141.84,670.13,163.68,8.15" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,250.80,648.05,220.02,8.15;12,141.84,659.09,134.83,8.15">Species Distribution Models: Ecological Explanation and Prediction Across Space and Time</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Elith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Leathwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,299.28,659.09,171.54,8.15;12,141.84,670.13,41.33,8.15">Annual Review of Ecology, Evolution, and Systematics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="677" to="697" />
			<date type="published" when="1009">1009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.76,149.33,324.90,8.15;13,141.84,161.33,311.18,8.15;13,141.84,173.21,46.56,8.15" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,315.00,149.33,142.66,8.15;13,141.84,161.33,219.88,8.15">Overview of GeoLifeCLEF 2019: plant species prediction using environment and animal occurrences</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,377.52,161.33,75.50,8.15;13,141.84,173.21,16.29,8.15">CLEF working notes 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.76,185.09,338.11,8.15;13,141.84,196.97,328.98,8.15;13,141.84,208.85,116.16,8.15" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,375.00,185.09,95.87,8.15;13,141.84,196.97,49.85,8.15">Pl@ntnet app in the era of deep learning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,199.92,196.97,270.90,8.15;13,141.84,208.85,56.11,8.15">ICLR 2017-Workshop Track-5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.76,220.73,282.30,8.15;13,141.84,232.73,316.89,8.15" xml:id="b5">
	<monogr>
		<ptr target="https://www.crowdai.org/challenges/lifeclef-2019-geo" />
		<title level="m" coord="13,141.84,220.73,266.31,8.15">LifeCLEF 2019 Geo (Challenge description, Data and Evaluation sections</title>
		<imprint>
			<date type="published" when="2019-05">May, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.76,244.61,333.76,8.15" xml:id="b6">
	<monogr>
		<ptr target="https://pandas.pydata.org" />
		<title level="m" coord="13,141.84,244.61,106.47,8.15">Pandas Data Analysis Library</title>
		<imprint>
			<date type="published" when="2019-05">May, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.76,268.13,337.93,8.15;13,141.84,279.05,41.37,8.15" xml:id="b7">
	<monogr>
		<ptr target="https://scikit-learn.org/" />
		<title level="m" coord="13,141.84,268.13,139.59,8.15">Scikit-learn Machine Learning Library</title>
		<imprint>
			<date type="published" when="2019-05">May, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,290.09,338.29,8.15;13,141.84,301.13,328.98,8.15;13,141.84,312.05,328.86,8.15;13,141.84,323.09,244.20,8.15" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,298.92,290.09,171.87,8.15;13,141.84,301.13,204.49,8.15">Identifying Fake News on Twitter using Naive Bayes, SVM and Random Forest Distributed Algorithms</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Cușmaliuc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Coca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,352.80,301.13,118.02,8.15;13,141.84,312.05,328.86,8.15;13,141.84,323.09,35.43,8.15">Proceedings of The 13th Edition of the International Conference on Linguistic Resources and Tools for Processing Romanian Language</title>
		<meeting>The 13th Edition of the International Conference on Linguistic Resources and Tools for Processing Romanian Language<address><addrLine>ConsILR-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="177" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,334.13,338.32,8.23;13,141.84,345.05,328.86,8.15;13,141.84,356.09,329.02,8.15;13,141.84,367.13,202.68,8.15" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,430.32,334.13,40.50,8.15;13,141.84,345.05,328.86,8.15">Combining image retrieval, metadata processing and naive Bayes classification at Plant Identification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Șerban</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sirițeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gheorghiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Alboaie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Breabăn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,167.52,356.09,303.34,8.15;13,141.84,367.13,47.46,8.15">Notebook Paper for the CLEF 2013 LABs Workshop -ImageCLEF -Plant Identification</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">2013. September. 2013</date>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,378.05,295.15,8.15" xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Keras</forename><surname>Deep</surname></persName>
		</author>
		<ptr target="https://keras" />
		<imprint>
			<date type="published" when="2019-05">May, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,389.09,335.11,8.15" xml:id="b11">
	<monogr>
		<ptr target="https://keras" />
		<title level="m" coord="13,141.84,389.09,144.28,8.15">XGBoost Gradient Boosting Framework</title>
		<imprint>
			<date type="published" when="2019-05">May, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,400.13,338.14,8.15;13,141.84,411.05,155.61,8.15" xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName coords=""><surname>Lifeclef</surname></persName>
		</author>
		<ptr target="https://www.crowdai.org/challenges/lifeclef-2019-geo" />
	</analytic>
	<monogr>
		<title level="j" coord="13,205.56,400.13,14.82,8.15">Geo</title>
		<imprint>
			<date type="published" when="2019-05">2019. May, 2019</date>
		</imprint>
	</monogr>
	<note>Submission section</note>
</biblStruct>

<biblStruct coords="13,132.50,422.09,338.20,8.15;13,141.84,433.13,214.32,8.15" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,196.44,422.09,260.99,8.15">An introduction to kernel and nearest-neighbor nonparametric regression</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,141.84,433.13,93.07,8.15">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,444.05,338.20,8.15;13,141.84,455.09,329.01,8.15;13,141.84,466.13,24.12,8.15" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,180.60,444.05,91.25,8.15">Random Decision Forests</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,287.16,444.05,183.54,8.15;13,141.84,455.09,135.55,8.15">Proceedings of the 3rd International Conference on Document Analysis and Recognition</title>
		<meeting>the 3rd International Conference on Document Analysis and Recognition<address><addrLine>Montreal, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-08-16">14-16 August 1995. 1995</date>
			<biblScope unit="page" from="278" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,477.05,338.36,8.15;13,141.84,488.09,328.78,8.15;13,141.84,499.13,145.32,8.15" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,285.72,477.05,185.14,8.15;13,141.84,488.09,135.79,8.15">Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,295.92,488.09,174.70,8.15;13,141.84,499.13,69.30,8.15">20th International Conference Artificial Neural Networks (ICANN)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,510.05,338.11,8.15;13,141.84,521.09,328.85,8.15;13,141.84,532.13,328.95,8.15;13,141.84,543.05,328.98,8.15;13,141.84,554.09,42.12,8.15" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,232.08,510.05,165.68,8.15">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,167.64,532.13,303.15,8.15;13,141.84,543.05,97.62,8.15">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<editor>
			<persName><forename type="first">Balaji</forename><forename type="middle">;</forename><surname>Krishnapuram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohak</forename><forename type="middle">;</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Charu</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dou</forename><forename type="middle">;</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajeev</forename><surname>Rastogi</surname></persName>
		</editor>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">August 13-17, 2016. 2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,565.13,338.23,8.15;13,141.84,576.05,50.64,8.15" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="13,308.52,565.13,158.76,8.15">Analyzing microarray gene expression data</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ambroise</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,587.09,338.24,8.15;13,141.84,598.13,328.78,8.15;13,141.84,609.05,304.08,8.15" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,187.56,587.09,283.18,8.15;13,141.84,598.13,30.86,8.15">A study of cross-validation and bootstrap for accuracy estimation and model selection</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,191.28,598.13,279.34,8.15;13,141.84,609.05,41.29,8.15">Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Fourteenth International Joint Conference on Artificial Intelligence<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1137" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.50,620.09,338.23,8.15;13,141.84,631.13,329.03,8.15;13,141.84,642.05,328.94,8.15;13,141.84,653.09,80.63,8.15" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,302.04,631.13,168.84,8.15;13,141.84,642.05,268.55,8.15">Overview of LifeCLEF 2019: Identification of Amazonian Plants, South \&amp; North American Birds, and Niche Prediction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,426.72,642.05,44.06,8.15;13,141.84,653.09,50.25,8.15">Proceedings of CLEF 2019</title>
		<meeting>CLEF 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
