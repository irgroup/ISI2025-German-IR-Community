<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.75,115.96,289.86,12.62;1,277.30,133.89,54.53,12.62">Non-local DenseNet for PlantCLEF 2019 Contest</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.24,172.09,52.72,8.74"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,266.15,172.09,67.67,8.74"><forename type="first">Georges</forename><surname>Quénot</surname></persName>
							<email>georges.quenot@imag.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.50,172.09,78.61,8.74"><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
							<email>lorraine.goeuriot@imag.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<orgName type="institution" key="instit4">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.75,115.96,289.86,12.62;1,277.30,133.89,54.53,12.62">Non-local DenseNet for PlantCLEF 2019 Contest</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">263F3696FFB0701744F1D654E672D5E0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>DenseNet</term>
					<term>Non-local block</term>
					<term>Plant Identification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image-based plant identification is a promising tool constituting the automation of agriculture and environmental conservation as stated in. As an attempt to tackle the data deficient challenge in Plant-CLEF 2019, the DenseNet architecture with competitive performance and relatively low number of parameters is augmented with a non-local block. A variety of data sampling schemes are also evaluated as a part of the work. The evaluation of the model and the methods is detailed in the content of the paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Various types of plants grow all around us, yet, little amongs us are plant experts. Indeed, knowing what plant available and where they are will be extremely helpful in pharmacy, from productional and academical perspective, environment protection. The rising of machine learning with artificial neural networks and convolutional neural networks which, are able to performs at near-human capability in image processing task, the popular use case of such technologies are for the automation of the task which human already excels: face recognition, image classification, etc. Still, it is would be highly beneficial if we can leverage these technologies in the task that human are yet to excel at in mass: Plant Identification.</p><p>The image-based plant identification can be formulated as a plant classification problem, where the input is an image containing the plant and the output is the id of the plant pre-defined by user. Formulating the problem of PlantCLEF contest as an image-classification task, the task itself in general has observed drastic improvement with the deep learning based methods, in the summarization of PlantCLEF 2017 <ref type="bibr" coords="1,237.05,590.58,12.45,8.74" target="#b1">[2]</ref>, it is shown that the best competitors have got over 90% accuracy using the aforementioned method. Notably, in the LifeCLEF 2018 contest <ref type="bibr" coords="2,162.80,118.99,12.01,8.74" target="#b2">[3]</ref>, the are quite a number of software that achieved comparable accuracy to that of the top experts.</p><p>In this work, we present our proposed methods for the PlantCLEF 2019 <ref type="bibr" coords="2,134.77,154.86,10.52,8.74" target="#b3">[4]</ref> which is part of the LifeCLEF 2019 <ref type="bibr" coords="2,311.35,154.86,10.52,8.74" target="#b0">[1]</ref> which focus on 10,000 species from data deficient regions. The rest of this paper is structured as follows: Section 2 gives an overview of related works on automatic plant-identification in deep learning from previous contests, section 3 describe the proposed architecture for prediction, section 4 provides additional information on data augmentation and data sampling schemes and finally we conclude our works in section 5.</p><p>The source code and trained models are made available under the github link: https://github.com/datvo06/PlantCLEF2019MRIM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Ever since AlexNet <ref type="bibr" coords="2,213.63,290.80,13.86,8.74" target="#b8">[9]</ref> won the competition of ImageNet classification 2012, Convolutional Neural Networks(CNNs) has always been at the center of image classification. Following AlexNet, there have been three lines of research focusing on the CNNs: modifying the operations in the CNNs, dividing the networks into several sub-modules and make improvement on each of them, and finally, altering the information flow by adding connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-tuning modules and adding auxiliary loss</head><p>The inception model <ref type="bibr" coords="2,439.63,372.73,16.38,8.74" target="#b11">[12,</ref><ref type="bibr" coords="2,456.02,372.73,12.29,8.74" target="#b12">13,</ref><ref type="bibr" coords="2,468.30,372.73,12.29,8.74" target="#b10">11]</ref> follows the principle of repeating many carefully designed block of filter stacked horizontally (receive the same input and the output feature map are concatenated). Each time with new version of Inception Net, the authors often optimizing one of these blocks so that the number of computations, memory consumption, number of parameters can be optimized. The Inception-v1 is used for the baseline of PlantCLEF 2017, achieving the Top 1 accuracy of 0.513 Adding Residual connections One of the problem with original deep neural networks is that the more layers added, there more model prone to gradient vanishing. Various works have been proposed to amend this problem, (i.e LSTM [7] for sequenced input, highway network [7] which introduce a gated mechanism for ANNs), for convolutional neural network, residual additive connection proposed by <ref type="bibr" coords="2,148.70,526.38,10.52,8.74" target="#b4">[5]</ref> is one of them, the author later analyzed carefully the effect of the order of each Residual Block, resulting in <ref type="bibr" coords="2,295.17,538.33,9.96,8.74" target="#b5">[6]</ref>, a modified version of the ResNet used in PlantCLEF 2017 <ref type="bibr" coords="2,223.75,550.29,9.96,8.74" target="#b1">[2]</ref>, achieved the best score among non-ensemble runs with top 1 accuracy of 0.853.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combining Inception and ResNet</head><p>The inception design and the ResNet design has merged together, first in the Inception-ResNet design <ref type="bibr" coords="2,400.75,596.34,14.61,8.74" target="#b10">[11]</ref>. The network architecture still bases on the original principle of carefully designed block, the authors did this by adding the residual connection in a few variant of inception blocks. Inception-ResNet v2 achieved similar score to ResNet modified in the PlantCLEF 2017 <ref type="bibr" coords="2,211.08,644.16,10.52,8.74" target="#b1">[2]</ref> with MRR 0.847, Top 1 0.794, Top 5 0.913 and are used by the majority participants in PlantCLEF 2018.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensemble prediction</head><p>The top performer of PlantCLEF 2017 <ref type="bibr" coords="3,397.00,118.99,15.50,8.74" target="#b9">[10]</ref> utilized ensemble prediction of multiple predictions with bagged averaging, the models used are ResNet, ResNeXt <ref type="bibr" coords="3,231.21,142.90,15.50,8.74" target="#b9">[10]</ref> and Inception-v1.</p><p>DenseNet As the residual connections has been proven to allow better gradient flow and performance boost to the convolutional neural networks, the DenseNets author <ref type="bibr" coords="3,209.78,188.36,13.11,8.74" target="#b7">[8]</ref> has tested the idea of densely connected layers. The model capable of achieving state-of-the-arts accuracy in classifying tasks with a relatively low number of parameters, making it a potentially good baseline for the data-deficient context. For this reason we choose the DenseNet as the baseline for the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Sampling Schemes</head><p>To the best of our knowledge on data-sampling for training, there are little overlapping works with the strategies proposed.</p><p>3 Model Architecture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Non-local Networks</head><p>The non-local neural network <ref type="bibr" coords="3,266.34,338.30,15.50,8.74" target="#b13">[14]</ref> was proposed to solve the problem of limited information propagation from CNN and LSTM. The idea is to performs interpixels correlations from different position in the feature maps, leading to generate more power pixel-wise representation. The non-local operation, according to <ref type="bibr" coords="3,465.09,374.17,15.50,8.74" target="#b13">[14]</ref> is defined as:</p><formula xml:id="formula_0" coords="3,241.82,393.54,234.53,26.88">y i = 1 C (x) ∀j d (x i , x j ) h (x j ) (<label>1</label></formula><formula xml:id="formula_1" coords="3,476.35,400.28,4.24,8.74">)</formula><p>Where i is the index on the output feature maps (in space, time, or spacetime in the original case of video classification, annotation), j is the index on the input feature maps x and d computes the scalar representing the pairwise relationship between the entities in the items reside in these locations. We shall see on the next section where the non-local block is added to the DenseNet baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adding Non-local operation to the DenseNet</head><p>The non-local operation is added between the output of the third dense block and the 1 × 1 channel-squashing convolution. The non-local block was added after the third dense block for several reason:</p><p>-First, in the original introduction of the non-local block <ref type="bibr" coords="3,400.19,573.02,14.61,8.74" target="#b13">[14]</ref>, multiple nonlocal position has been tested, of which, the best position is after the third Residual Convolution Block -We have known based on the mechanism of self-attention, the non-local block performs pairwise dot product between two transformation of every pair of pixels on the grid. That why it is necessary to place a few convolution blocks before the non-local block so that the operation may potentially leverage informations from local neighbors.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ensemble prediction</head><p>When applied into the final predictions, each instance of observation has multiple samples, so that there either has to be some middle layer to aggregate prediction in order to combine the prediction of multiple models on multiple instance. For this, a two-level pooling is leveraged:</p><p>The first level of pooling is used for ensembling the predictions of multiple different trained prediction instances and the second is used for aggregation of predictions from multiple observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Augmentation</head><p>Several data augmentation strategies have been applied:</p><p>-Randomly resizing image -Randomly crop -Random Horizontal Flip -Random alternating the brightness and contrast </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Sampling</head><p>Notation:</p><p>-N : total number of samples n i : number of samples for i th class o i : oversampling factor for i th class w i : sampling weight for i th class m: the median number of samples µ: the mean number of samples per classes.</p><p>Minimum Threshold Resampling This strategy only focus on augmenting the classes having less number of samples than the average number of samples per classes. Here, for each class with number of samples n i , the oversampling factor o i will be assigned the value of µ/n i . The oversampling might make some samples in the classes appears too many times compared to the others, making the model prone to overfit and also, so on each epoch, the classes samples are reshuffled and resampled. Another problem is that the training times will be prolonged due to the increase in number of samples. For this, another strategy is also applied which is described below.</p><p>Smoothed Re-sampling This strategy partly oversampling small classes while also performs subsampling on classes with large number of samples. All of the aforementioned parameters are constant during training. The number of total samples which will be used throughout the training session is the sample: N . On each epoch however, each of the classes will be under-sampled or oversampled based on the weight w i , total weight on one epoch will be normalized so that the number of total samples will always be equal to N : i w i o i n i . We will now turn to how to choose the o i and w i factors. With the m = 10 for examples, all the classes will initially applied the oversampling factor o i . The oversampling ensures a minimal number and diversity via data augmentation.</p><p>o i = 1 for n i &gt; m (no oversampling beyond median).</p><p>-</p><formula xml:id="formula_2" coords="6,151.70,366.87,79.92,9.65">o i = (1 + m/n i )/2</formula><p>for n i ≤ m (oversampling for linear importance between m/2 and m).</p><p>Oversampling reduces the imbalance from about 1000:1 to about 100:1.</p><p>Weighting further ensures a better balancing using a power law.</p><formula xml:id="formula_3" coords="6,134.77,419.82,67.00,11.23">w i = (o i n i ) γ-1 .</formula><p>-With γ = 1.0, no weighting, original case (except the oversampling effect).</p><p>-With γ = 0.5, weighting further reduces the imbalance from about 100:1 to about 10:1. -With γ = 0.25, weighting further reduces the imbalance from about 100:1 to about 3:1. -With γ = 0.15, weighting further reduces the imbalance from about 100:1 to about 2:1.</p><p>In all cases, re-normalize (divide each w i by the same value so that Σ i (w i o i n i ) = N ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment Results on the PlantCLEF 2017</head><p>All the candidate models have been trained on the PlantCLEF 2017 for preliminary testing before being used on the PlantCLEF 2019. The models are trained on the EOL set and tested on Web dataset with the data augmentation strategies mentioned in the subsection 4.1. The result is shown in the table <ref type="table" coords="6,421.22,620.25,3.87,8.74" target="#tab_0">1</ref>.</p><p>It is can be easily seen that the Non-local addition added an increase of accuracy in both the DenseNet-121 and DenseNet-201 and the DenseNet slightly out performs the ResNet. performance drop. The further inspection of the dataset shows some challenging properties:</p><p>1. The classes are imbalanced 2. Repeated samples across the classes makes the learning harder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Noisy Samples</head><p>Experiment Results on the Class-Filtered PlantCLEF 2019 We first test the effects of following strategies:</p><p>-Temporary removing all the classes with less than 5 samples -Further remove noisy/incorrect formatted images.</p><p>The result is a 8500-classes dataset with still over 400,000 samples. The evaluation of the model is shown is Table <ref type="table" coords="7,286.15,555.49,3.87,8.74" target="#tab_2">3</ref>. The result does not show much differences.</p><p>Experiment Results on the Repetition-Filtered PlantCLEF 2019 Further experiments are performed on the dataset with different thresholds for repetition, the following training/validation split strategy is applied: for each class, at least n samples /5 is taken as part of the validation set, if the class has only one samples, the training set for that class would be empty. Here, the minimum threshold sampling is applied. The evaluation result is shown in table <ref type="table" coords="7,472.84,656.12,3.87,8.74" target="#tab_3">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Results on conditional repetition filtered PlantCLEF 2019</head><p>On the final try of filtering the dataset involves filtering out all repeated samples unless it creates empty class. The statistics of the resulting dataset is stated in Table <ref type="table" coords="8,162.16,392.98,3.87,8.74" target="#tab_4">5</ref>. With all the repeated samples trimmed, the distribution is still pretty imbalanced, Figure <ref type="figure" coords="8,209.88,584.39,4.98,8.74" target="#fig_4">5</ref> shows the distributions with Smoothed Resampling strategy. Since this is the final try, the whole dataset has to be used for training, for this, other external datasets has to be used for testing. More inspections on the PlantCLEF 2017 dataset reveals that there are 551 common categories betweens the PlantCLEF 2017 and PlantCLEF 2019 dataset. The samples are sorted by sizes and filtered to avoid having them in the training set. The statistic of the dataset is shown in table 6.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,264.87,345.83,7.89;4,134.77,275.85,130.47,7.86;4,134.77,115.83,345.83,134.26"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Non-local block, f (x), g(x), h(x) are three 1 × 1 convolutions, where f (x), g(x) are channel-squashing functions.</figDesc><graphic coords="4,134.77,115.83,345.83,134.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,207.95,427.90,199.45,7.89;4,134.77,295.29,345.83,117.84"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Placing Non-local block within DenseNet.</figDesc><graphic coords="4,134.77,295.29,345.83,117.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,202.34,266.71,210.67,7.89;5,134.77,115.83,345.83,136.11"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Ensemble prediction using two-level pooling.</figDesc><graphic coords="5,134.77,115.83,345.83,136.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,221.87,465.02,171.62,7.89;5,165.95,362.70,283.47,87.56"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustration of data-augmentations.</figDesc><graphic coords="5,165.95,362.70,283.47,87.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,251.60,266.75,112.16,7.89;9,147.45,120.82,155.62,116.72"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Effect of different γ.</figDesc><graphic coords="9,147.45,120.82,155.62,116.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,134.77,337.02,345.82,7.89;11,134.77,348.01,345.83,7.86;11,134.77,358.97,327.93,7.86;11,134.77,145.35,345.82,176.90"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Top 1 On Test Set, the best automatic solution performed at 0.316, while best experts have the accuracy of 0.675. Despite obtaining the accuracy of only 4.3%, the team is in top 3, the top performing model on the top 1 accuracy is the first run.</figDesc><graphic coords="11,134.77,145.35,345.82,176.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,253.52,625.51,108.33,7.89;11,134.77,433.84,345.82,176.90"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Top 3 On Test Set.</figDesc><graphic coords="11,134.77,433.84,345.82,176.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="12,253.52,307.51,108.33,7.89;12,134.77,115.84,345.82,176.90"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Top 5 On Test Set.</figDesc><graphic coords="12,134.77,115.84,345.82,176.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,134.77,115.91,345.83,172.83"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of trained models on PlantCLEF 2017 Web. The model are further tested on the PlantCLEF 2019 dataset. The initial result is shown in Table 2. Thus, we can easily observe a drastic</figDesc><table coords="7,134.77,134.97,253.12,141.82"><row><cell>Model</cell><cell>Top 1 Accuracy</cell></row><row><cell>ResNet-18</cell><cell>0.5111</cell></row><row><cell>ResNet-152</cell><cell>0.7888</cell></row><row><cell>ShuffleNet</cell><cell>0.7222</cell></row><row><cell>DenseNet-121</cell><cell>0.8126</cell></row><row><cell>Non-local DenseNet-121</cell><cell>0.8618</cell></row><row><cell>DenseNet-201</cell><cell>0.8515</cell></row><row><cell>Non-local DenseNet-201</cell><cell>0.8744</cell></row><row><cell cols="2">4.4 Experiment results on PlantCLEF 2019</cell></row><row><cell>Initial result</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,174.85,311.00,265.67,60.99"><head>Table 2 .</head><label>2</label><figDesc>Model Performance on PlantCLEF 2019 Validation Set.</figDesc><table coords="7,224.39,330.05,163.49,41.94"><row><cell>Model</cell><cell>Top 1 Accuracy</cell></row><row><cell>DenseNet-121</cell><cell>0.2510</cell></row><row><cell>DenseNet-201</cell><cell>0.3503</cell></row><row><cell>Non-local DenseNet-201</cell><cell>0.4525</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,151.84,115.91,308.60,72.35"><head>Table 3 .</head><label>3</label><figDesc>Model evaluation from small-class-filtered dataset.</figDesc><table coords="8,151.84,134.97,308.60,53.29"><row><cell>Model</cell><cell>Top 1 Accuracy</cell><cell>Additional Condition</cell></row><row><cell>DenseNet-121</cell><cell>0.3020</cell><cell>None</cell></row><row><cell>DenseNet-201</cell><cell>0.4220</cell><cell>None</cell></row><row><cell>DenseNet-201</cell><cell>0.4890</cell><cell>Balanced Sampling</cell></row><row><cell>Non-local DenseNet-201</cell><cell>0.5215</cell><cell>Oversampling data-deficient classes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,202.54,345.83,132.68"><head>Table 4 .</head><label>4</label><figDesc>Filtering out inter-class repeated samples makes training and validating set different.It can easily be seen that removing the all repetitions from duplication creates empty classes, which would heavily differentiates the training and validating set, making it hard to validate the model.</figDesc><table coords="8,161.64,232.55,289.01,41.94"><row><cell cols="4">Max repetitions Number of empty classes Top 1 Training Top 1 Testing</cell></row><row><cell>1</cell><cell>1539</cell><cell>0.8425</cell><cell>0.1925</cell></row><row><cell>2</cell><cell>1040</cell><cell>0.6530</cell><cell>0.1512</cell></row><row><cell>3</cell><cell>778</cell><cell>0.6930</cell><cell>0.1451</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,187.08,422.84,241.20,119.52"><head>Table 5 .</head><label>5</label><figDesc>Conditional Repetition Filtered PlantCLEF 2019.</figDesc><table coords="8,195.43,443.63,221.42,98.72"><row><cell>Attributes of Dataset</cell><cell>Attribute Value</cell></row><row><cell>Number of classes</cell><cell>10,000</cell></row><row><cell>Number of samples</cell><cell>279,832</cell></row><row><cell>Mean number of samples</cell><cell>27.98</cell></row><row><cell>Minimum number of samples per class</cell><cell>1</cell></row><row><cell>Median number of samples</cell><cell>5</cell></row><row><cell>Max number of samples per class</cell><cell>1202</cell></row><row><cell>Number of unique samples</cell><cell>278,906</cell></row><row><cell>Number of samples duplicated</cell><cell>158</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,134.77,287.14,345.83,230.00"><head>Table 6 .</head><label>6</label><figDesc>Validation Dataset Statistics.The final obtained results before submission testing on these dataset are described in the table 7:</figDesc><table coords="9,137.03,306.19,341.29,210.95"><row><cell>Dataset</cell><cell cols="6">PlantCLEF 2017 EOL Common PlantCLEF 2017 Web Common</cell></row><row><cell cols="2">Number of classes</cell><cell></cell><cell>551</cell><cell></cell><cell></cell><cell>551</cell></row><row><cell cols="2">Number of samples</cell><cell></cell><cell>10,803</cell><cell></cell><cell></cell><cell>63,242</cell></row><row><cell cols="7">Training Set γ No. instances Pooling 2017 EOL 2017 Web 2017 EOL + Web</cell></row><row><cell cols="2">Conditional 0.25</cell><cell>4</cell><cell>Mean</cell><cell>0.9171</cell><cell>0.6635</cell><cell>0.6983</cell></row><row><cell>Filtered</cell><cell></cell><cell></cell><cell>Max</cell><cell>0.9169</cell><cell>0.6637</cell><cell>0.6984</cell></row><row><cell cols="2">PlantCLEF 0.5</cell><cell>4</cell><cell>Mean</cell><cell>0.9455</cell><cell>0.6970</cell><cell>0.7311</cell></row><row><cell>2019</cell><cell></cell><cell></cell><cell>Max</cell><cell>0.9413</cell><cell>0.6941</cell><cell>0.7280</cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>Mean</cell><cell>0.9138</cell><cell>0.6476</cell><cell>0.6842</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Max</cell><cell>0.9011</cell><cell>0.6338</cell><cell>0.6705</cell></row><row><cell></cell><cell>Mixed</cell><cell>10</cell><cell cols="2">Mean 0.9478</cell><cell>0.6957</cell><cell>0.7303</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Max</cell><cell>0.9371</cell><cell>0.6812</cell><cell>0.7163</cell></row><row><cell>All Data</cell><cell>No</cell><cell>1</cell><cell>No</cell><cell>0.7852</cell><cell>0.5497</cell><cell>0.5821</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,134.77,520.16,345.83,18.85"><head>Table 7 .</head><label>7</label><figDesc>Non-local DenseNet 201 Evaluation on PlantCLEF 2017 Common Categories.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We can see that with the same model, trained on the same number of epochs, the filtering strategies shows the differences: The ensemble of 4 model trained with γ = 0.5 gives of the best performance, the model which trained with all data from PlantCLEF 2019 is also evaluated and compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final Test Results</head><p>The final results are given by the top 1 accuracy on the test dataset and the hand-picked subset by experts. The detail of each run is given in table 8. The best accuracy of top 1 on the expert-chosen samples set is achieved with the mean of 4 instances trained with γ = 0.25 with 2 means pooling, and best accuracy of top 1 on all samples is chosen with γ = 0.5 and two max pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run γ</head><p>No.</p><p>Pooling </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Plant Identification is an important step in medical, agricultural and environment resource planning. However, the problem is currently still a challenging to both human and computer vision-based technologies even with the development of deep learning. With data-deficient challenge, the problem is even harder to conquer. The work aims to provide a decent-performing model proven with extensive experiments along with a variety of data-handling strategies, yet it still cannot solve the whole problem. The remaining problems are avoiding of bias between classes belonging to the same genus, this perhaps can be performed by adding hierarchical classification where the system first identifies the genus and then the species. The data-deficient challenge still need to be tackled, either by leveraging unsupervised or semi-supervised learning methods. On the model designing perspective, the authors believe that the model can potentially be improved by adding inter-channel correlations in the non-local block.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,602.29,337.64,7.86;10,151.52,613.25,329.07,7.86;10,151.52,624.21,238.42,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,442.93,602.29,37.66,7.86;10,151.52,613.25,329.07,7.86;10,151.52,624.21,80.84,7.86">Overview of lifeclef 2019: Identification of amazonian plants, south &amp; north american birds, and niche prediction</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Herv</forename><surname>Goau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B S K M S H G P B W P V R P F R S H M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,253.43,624.21,107.84,7.86">Proceedings of CLEF 2019</title>
		<meeting>CLEF 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,634.88,337.63,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.77,148.13,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,290.82,634.88,189.77,7.86;10,151.52,645.84,225.25,7.86">Plant identification based on noisy web data: The amazing performance of deep learning (LifeCLEF</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,409.59,645.84,71.00,7.86;10,151.52,656.80,48.07,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<publisher>LifeCLEF</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,343.52,337.63,7.86;12,151.52,354.48,329.07,7.86;12,151.52,365.41,86.30,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,284.82,343.52,195.76,7.86;12,151.52,354.48,230.35,7.86">Overview of ExpertLifeCLEF 2018: How far automated identification systems are from the best experts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,389.43,354.48,91.16,7.86;12,151.52,365.41,57.63,7.89">CEUR Workshop Proceedings 2125</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,377.20,337.63,7.86;12,151.52,388.16,327.70,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,281.81,377.20,198.78,7.86;12,151.52,388.16,172.86,7.86">Overview of lifeclef plant identification task 2019: diving into data deficient tropical countries</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,345.40,388.16,105.15,7.86">CLEF working notes 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,399.92,337.63,7.86;12,151.52,410.88,329.08,7.86;12,151.52,421.84,329.07,8.12;12,151.52,433.45,174.17,7.47" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,292.70,399.92,183.70,7.86">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
		<ptr target="http://ieeexplore.ieee.org/document/7780459/" />
	</analytic>
	<monogr>
		<title level="m" coord="12,165.33,410.88,310.07,7.86">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,444.56,337.64,7.86;12,151.52,455.52,329.08,7.86;12,151.52,466.45,329.07,7.89;12,151.52,477.44,171.84,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,298.94,444.56,177.41,7.86">Identity mappings in deep residual networks</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46493-0_38</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46493-0" />
	</analytic>
	<monogr>
		<title level="j" coord="12,382.14,466.45,24.62,7.89">LNCS</title>
		<imprint>
			<biblScope unit="page" from="630" to="645" />
			<date type="published" when="2016">9908. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,489.20,337.63,7.86;12,151.52,500.13,329.07,8.14;12,151.52,511.77,258.90,7.47" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,284.82,489.20,103.85,7.86">Long Short-Term Memory</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j" coord="12,397.12,489.20,83.47,7.86">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11">nov 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,522.88,337.63,7.86;12,151.52,533.84,329.07,7.86;12,151.52,544.80,329.08,7.86;12,151.52,555.76,163.64,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,449.17,522.88,31.42,7.86;12,151.52,533.84,143.72,7.86">Densely connected convolutional networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.243</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.243" />
	</analytic>
	<monogr>
		<title level="m" coord="12,326.80,533.84,153.79,7.86;12,151.52,544.80,229.31,7.86">Proceedings -30th IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>-30th IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,567.52,337.64,7.86;12,151.52,578.48,329.07,7.86;12,151.52,589.41,329.07,7.89;12,151.52,600.40,329.07,8.12;12,151.52,612.00,164.76,7.47" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,355.58,567.52,125.01,7.86;12,151.52,578.48,161.73,7.86">ImageNet Classification with Deep Convolutional Neural Network</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1061/(ASCE)GT.1943-5606.0001284</idno>
		<ptr target="http://dl.acm.org/citation.cfm?id=2999134.2999257" />
	</analytic>
	<monogr>
		<title level="m" coord="12,326.65,578.48,153.94,7.86;12,151.52,589.44,260.72,7.86">Proceedings of the 25th International Conference on Neural Information Processing Systems</title>
		<meeting>the 25th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,623.12,337.97,7.86;12,151.52,634.05,230.98,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,202.57,623.12,278.02,7.86;12,151.52,634.08,49.40,7.86">Image-based plant species identification with deep Convolutional Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,208.44,634.08,121.10,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,645.84,337.98,7.86;12,151.52,656.80,329.07,7.86;13,151.52,119.67,181.84,7.86;13,358.20,120.32,122.39,7.47;13,151.52,131.28,23.54,7.47" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2014.01.008</idno>
		<ptr target="http://arxiv.org/abs/1602.07261" />
		<title level="m" coord="12,380.09,645.84,100.51,7.86;12,151.52,656.80,292.09,7.86">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,141.59,337.98,7.86;13,151.52,152.55,329.07,7.86;13,151.52,163.51,168.87,8.12" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.4842" />
		<title level="m" coord="13,285.34,152.55,135.23,7.86">Going Deeper with Convolutions</title>
		<imprint>
			<date type="published" when="2014-09">sep 2014</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,174.47,337.98,7.86;13,151.52,185.43,329.07,8.12;13,151.52,197.03,23.54,7.47" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="13,392.60,174.47,87.99,7.86;13,151.52,185.43,155.68,7.86">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.00567" />
		<imprint>
			<date type="published" when="2015-12">dec 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,207.34,337.98,7.86;13,151.52,218.30,25.60,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="13,326.64,207.34,106.74,7.86">Non-local Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
