<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,166.08,115.96,283.20,12.62;1,143.60,133.89,328.16,12.62;1,235.67,151.82,144.01,12.62">Classifying German Animal Experiment Summaries with Multi-lingual BERT at CLEF eHealth 2019 Task 1</title>
				<funder>
					<orgName type="full">Titan X Pascal GPU</orgName>
				</funder>
				<funder>
					<orgName type="full">NVIDIA Corporation</orgName>
				</funder>
				<funder>
					<orgName type="full">Helmholtz Einstein International Berlin Research School in Data Science (HEIBRiDS)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.11,189.68,58.44,8.74"><forename type="first">Mario</forename><surname>Sänger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Knowledge management in Bioinformatics</orgName>
								<orgName type="institution">Humboldt Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.69,189.68,52.47,8.74"><forename type="first">Leon</forename><surname>Weber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Knowledge management in Bioinformatics</orgName>
								<orgName type="institution">Humboldt Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.30,189.68,79.46,8.74"><forename type="first">Madeleine</forename><surname>Kittner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Knowledge management in Bioinformatics</orgName>
								<orgName type="institution">Humboldt Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,413.27,189.68,39.52,8.74"><forename type="first">Ulf</forename><surname>Leser</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Knowledge management in Bioinformatics</orgName>
								<orgName type="institution">Humboldt Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,166.08,115.96,283.20,12.62;1,143.60,133.89,328.16,12.62;1,235.67,151.82,144.01,12.62">Classifying German Animal Experiment Summaries with Multi-lingual BERT at CLEF eHealth 2019 Task 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C49682A2C8A61E847BC8E32FABD5E5D4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ICD-10 Classification</term>
					<term>German Animal Experiments</term>
					<term>Multilabel Classification</term>
					<term>Multi-lingual BERT Encodings</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present our contribution to the CLEF eHealth challenge 2019, Task 1. The task involves the automatic annotation of German non-technical summaries of animal experiments with ICD-10 codes. We approach the task as multi-label classification problem and leverage the multi-lingual version of the BERT text encoding model <ref type="bibr" coords="1,442.52,319.29,9.73,7.86" target="#b5">[6]</ref> to represent the summaries. The model is extended by a single output layer to produce probabilities for individual ICD-10 codes. In addition, we make use of extra training data from the German Clinical Trials Register and ensemble several model instances to improve the overall performance of our approach. We compare our model with five baseline systems including a dictionary matching approach and single-label SVM and BERT classification models. Experiments on the development set highlight the advantage of our approach compared to the baselines with an improvement of 3.6%. Our model achieves the overall best performance in the challenge reaching an F1 score of 0.80 in the final evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Biomedical natural language processing (NLP) aims to support biomedical researchers, health professionals in their daily clinical routine as well as patients and the public searching for disease-related information. A large part of Biomedical NLP focuses on extraction of biomedical concepts from scientific publications or classification of such documents to biomedical concepts. In the past biomedical NLP has strongly advanced for biomedical or clinical documents in English <ref type="bibr" coords="1,134.77,603.37,9.96,8.74" target="#b6">[7]</ref>. Non-English biomedical NLP lags behind since the availability of annotated corpora and other resources (e.g. dictionaries and ontologies for biomedical concepts) in non-English languages is limited.</p><p>Since 2015 the CLEF eHealth community addresses this issue by organising shared tasks on non-English or multilingual information extraction. The subject of CLEF eHealth shared tasks since 2016 <ref type="bibr" coords="2,324.89,171.30,13.05,8.74" target="#b11">[13]</ref><ref type="bibr" coords="2,337.94,171.30,4.35,8.74" target="#b12">[14]</ref><ref type="bibr" coords="2,342.29,171.30,13.05,8.74" target="#b13">[15]</ref> include the classification of clinical documents according to the International Classification of Diseases and Related Health Problems (ICD-10) <ref type="bibr" coords="2,292.83,195.21,14.61,8.74" target="#b15">[17]</ref>. More precisely, the task has been the assignment of ICD-10 codes to death certificates in Frensh, English, Hungarian and Italian. Among the best performing teams in 2018, the task has been treated as a multi-label classification problem or as sequence-to-sequence prediction leveraging neural networks <ref type="bibr" coords="2,276.64,243.03,9.96,8.74" target="#b1">[2]</ref>. Other well performing systems were based on a supervised learning system using multi-layer perceptrons and an One-vs-Rest (OVR) strategy supplemented with IR methods <ref type="bibr" coords="2,371.13,266.94,10.52,8.74" target="#b0">[1]</ref> or an ensemble model for ICD 10 coding prediction utilising word embeddings created on the training data as well as on language-specific Wikipedia articles <ref type="bibr" coords="2,374.39,290.85,9.96,8.74" target="#b8">[9]</ref>.</p><p>In 2019, the CLEF eHealth Evaluation Task 1 focuses on the assignment of ICD-10 codes to health-related, non-technical summaries of animal experiments in German <ref type="bibr" coords="2,216.23,331.20,15.50,8.74">[10,</ref><ref type="bibr" coords="2,233.38,331.20,11.62,8.74" target="#b14">16]</ref>. According to the laws of the European Union each member state has to publish a comprehensible, nontechnical summary (NTS) of each authorised research project involving laboratory animals to provide greater transparency and increase the protection of animal welfare. In Germany the webbased database AnimalTestInfo<ref type="foot" coords="2,273.28,377.44,3.97,6.12" target="#foot_0">1</ref> houses and publishes planned animal studies to inform researchers and the public. To improve analysis of the database, summaries submitted in 2014 and 2015 (roughly 5.300) were labelled by human experts according to the German version of the ICD-10 classification system<ref type="foot" coords="2,476.12,413.31,3.97,6.12" target="#foot_1">2</ref> in <ref type="bibr" coords="2,146.48,426.84,9.96,8.74" target="#b3">[4]</ref>. Based on this pilot study further documents added to the database have been labelled and used to conduct this year's CLEF eHealth challenge. The task is to explore the automatic assignment of ICD-10 codes to the animal experiments, i.e. given the non-technical summary predicting the ICD-10 codes that are investigated in the study.</p><p>We treat the task as a multi-label classification problem and apply the multilingual BERT model <ref type="bibr" coords="2,226.00,503.05,10.52,8.74" target="#b5">[6]</ref> which recently achieved state-of-the-art results in eleven different NLP tasks <ref type="bibr" coords="2,227.31,515.01,14.61,8.74" target="#b10">[12]</ref>. The model is extended by a single output layer to produce probabilities for individual ICD-10 codes. Since training data in this task is sparse, we also use summaries of clinical trails conducted in Germany published by the German Clinical Trials Register (GCTR). We compare our model with five baseline systems including a dictionary matching approach and single-label SVM and BERT classification models. The implementation of our models is available as open source software at github<ref type="foot" coords="2,365.35,585.16,3.97,6.12" target="#foot_2">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Here we describe the corpora, used terminologies and classification models we use in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpora and Terminologies</head><p>The lab organisers provided a corpus of 8,385 German non-technical summaries of animal experiments (NTS) originating from the AnimalTestInfo database. For each experiment a short title is given followed by a description of expected benefits as well as pressures and damages of the animals. Furthermore, strategies to prevent unnecessary harm to the animals and to improve animal welfare are described. Each summary was labeled by experts using the German version of the ICD-10 classification system. Depending on the level of detail of the summary different levels (e.g. chapter, group) of the ICD-10 ontology are used to annotated the experiment. About two-thirds of the experiments are labeled with exactly one disease and 10% with multiple diseases; the remainder have no annotated disease. For each disease the complete path in the ICD-10 ontology, i.e. up to two parent groups and the chapter of the annotated disease, is given. About two third of the summaries are annotated with 2-level paths (e.g. I | B50-B64 ), 20 % with 3-or 4-level paths (eg.</p><formula xml:id="formula_0" coords="3,134.77,370.92,345.83,20.69">IV | E70-E90 | E10-E14 or II | C00-C97 | C00-C75 | C15-C26</formula><p>) and less than 1 % of the summaries are only annotated with chapters (e.g. VI ). The data set is divided into a stratified train and development split (7,543 / 842) at document level. For the final evaluation an hold-out set of 407 experiments are used by the organisers.</p><p>In addition to the provided data set, we use information from the German Clinical Trials Register (GCTR) <ref type="foot" coords="3,275.08,441.80,3.97,6.12" target="#foot_3">4</ref> . The GCTR provides access to basic information (e.g. trial title, short description, studied health condition, inclusion and exclusion criteria) of clinical trials conducted in Germany and is also annotated with ICD-10 codes. We downloaded all trials available through the GCTR website. For each trial we make use of the title as well as the scientific and lay language summary. We use the chapter and all (sub-) groups up to the third level of the ontology of the given ICD-10 codes describing the studied health condition as labels for the trial, similar to ICD-10 coding in the NTS data set. In this way we are able to extend the training set by 7,615 documents having 18,263 ICD-10 codes. ICD-codes of each study in the GCTR data set relate to the ICD-10 version valid at publication of a study. We did not adjust for any differences (e.g. any potentially missing ICD-10 codes) to version 2016 used for the NTS corpus. The two data sets almost fully overlap with regard to the considered health problems. Of the 233 distinct ICD-10 codes occurring in the complete NTS corpus, 226 (97%) are mentioned in GCTR too. Moreover, 27 other ICD-10 codes will be introduced through the additional data set. Table <ref type="table" coords="3,475.61,622.70,4.98,8.74" target="#tab_0">1</ref> summarises the used corpora. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">BERT for multi-label classification</head><p>Our approach for the task is based on BERT language model <ref type="bibr" coords="4,415.43,277.43,9.96,8.74" target="#b5">[6]</ref>. BERT is a text encoding model that recently achieved state-of-the-art results in many different NLP tasks <ref type="bibr" coords="4,211.92,301.34,14.61,8.74" target="#b10">[12]</ref>. It is a neural network based on the transformer architecture of [19], which was pretrained using two different language modelling tasks: masked language modeling and next sentence prediction. Specifically, we use the multilingual version of BERT-Base<ref type="foot" coords="4,302.40,335.64,3.97,6.12" target="#foot_4">5</ref> that has been pre-trained on Wikipedia dumps of 104 different languages including German. Given a sequence of tokens t 1 , . . . , t L , BERT first subdivides the tokens into subword-tokens, yielding a new (usually, longer) sequence s 1 , . . . , s N using WordPiece <ref type="bibr" coords="4,184.06,385.52,14.61,8.74" target="#b18">[21]</ref>. Then, it produces vector representations for each subword-token e 1 , . . . , e N ∈ R 768 and one vector c ∈ R 768 which is not tied to a specific token. BERT supports sequence lengths up to 512 sub-word tokens. We represent each animal experiment by taking as much as possible sub-word tokens from the title and the description of expected benefits and pressures of the summary text as model input. Following <ref type="bibr" coords="4,238.14,445.30,9.96,8.74" target="#b5">[6]</ref>, we employ c as a representation for the whole token sequence.</p><p>We treat the assignment of ICD-10 codes as a one-versus-rest multi-label classification problem <ref type="bibr" coords="4,216.50,481.66,9.96,8.74" target="#b4">[5]</ref>, i.e. as |Y| independent binary classification tasks, where Y is the set of all ICD-10 codes occurring in the training set. Each example is used as a positive example if it has the respective label, while all other examples are used as negative examples. The only connection between the individual classification tasks is the BERT encoder which is shared between all tasks and which receives parameter updates from all of them. We use a single output layer W ∈ R 768×|Y| to compute the output probabilities per class with σ(c • W ), where σ is the element-wise sigmoid function, and use binary cross-entropy as a loss.</p><p>We implement our model in PyTorch <ref type="bibr" coords="4,308.48,577.79,15.50,8.74" target="#b16">[18]</ref> using the pytorch-pretrained-BERT<ref type="foot" coords="4,478.04,576.22,3.97,6.12" target="#foot_5">6</ref> implementation of BERT and use the included modified version of Adam <ref type="bibr" coords="4,450.46,589.75,15.50,8.74" target="#b9">[11]</ref> for optimization. We train our model for 60 epochs on a single Nvidia V100 GPU, which takes about nine hours. In principle, it would also be possible to train and evaluate the model using only CPUs but that would take considerably more time.</p><p>We train multiple model instances using different random seeds and ensemble their predictions. Ensembling of multiple neural network models has shown to be beneficial in several NLP taks <ref type="bibr" coords="5,282.63,168.33,9.96,8.74" target="#b5">[6]</ref>. We ensemble the models in two ways: <ref type="bibr" coords="5,467.86,168.33,12.73,8.74" target="#b0">(1)</ref> by averaging the predictions of the different model instances and (2) learning a logistic regression classifier based on the model outputs on the development set. We denote the two ensembling model variants as BERT multi-label Avg and BERT multi-label LogReg. Note, that because BERT multi-label LogReg is trained on the development set, the resulting scores on this data are no longer a reliable estimate for out-of-sample performance and can only be fairly compared to the other approaches on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Baselines</head><p>To gain better insights about the performance level of our approach we compare it with five different baseline methods. First, we implement a dictionarymatching approach. For this we took the concept descriptions of all codes listed in the ICD-10 ontology as well as all given synonyms and search for occurrences of these terms in the title and goals (line 1 and 2) of an animal trial summary. Dictionary matching is performed by indexing all ICD-10 concepts using Apache Solr 7.5.0<ref type="foot" coords="5,237.56,387.19,3.97,6.12" target="#foot_6">7</ref> and applying exact and fuzzy matching. Each ICD-10 concept is linked to its related path up to the chapter-level which is used for annotation. All concepts matched by the dictionary are reported as results. We do not perform any further post-processing like sorting out overlapping ICD-10 paths. For the other baselines we transform the task into (1) a group-level or (2) a sub-group-level classification problem, i.e. we use the label on the second level of the ICD-10 hierarchy (e.g. for I | C00-C97 | C00-C75 we use C00-C97 ) resp. the deepest label (e.g. for I | C00-C97 | C00-C75 we use C00-C75 ) for a given trial summary as gold standard. In both cases, for instances with multiple codes originating from different branches of the ICD-10 ontology we use the first label as gold standard. Moreover, we add a special no-class label to support documents without any annotated ICD-10 code.</p><p>We investigate two different classification methods for the tasks, Support Vector Machines (SVM) and BERT sequence classification model <ref type="bibr" coords="5,395.19,545.70,13.19,8.74" target="#b5">[6]</ref>. For the former, we build TF-IDF vectors as input representation for the trial summaries. For the latter, the model architecture is equivalent to our multi-label model except that the final linear layer calculates a soft-max over the classes of the classification task and hence applies a (single-class) cross-entropy loss for training.</p><p>For the both classification baselines, we augment the predictions of the models according to the ICD-10 hierarchy, e.g. if a group-level model predicts C00-C97 we automatically add the parent chapter (in this case I ) to the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results &amp; Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental setup</head><p>We use the training split of the provided corpus as well as the documents from the GCTR data set to train our multi-label as well as all baseline models. For the BERT multi-label and the SVM classification models we perform hyperparameter optimisation and select the best model of each approach based on the development set performance. Regarding the SVM models, we follow <ref type="bibr" coords="6,432.52,211.17,10.52,8.74" target="#b7">[8]</ref> and test {2 -5 , 2 -3 , . . . , 2 15 } as values for the C parameter. The best scores are reached with C = 2 / C = 0.5 for group level / sub-group-level classification. In case of our BERT multi-label approach we only tune the learning rate parameter. We evaluate the sequence {5e -5, 4e -5, 3e -5, 2e -5, 1e -5} and found that 4e -5 achieves the highest scores. We omit hyperparameter tuning for the BERT classification models due to time constraints. Therefore, we use the default parameter settings of the model, i.e. learning rate of 5e -5.</p><p>As described in Section 2.2 we learn eight model instances of our approach using different random seeds and ensemble them. The two ensemble variants are built (a) by averaging of the two best model instances and (b) learning a logistic regression classifier based on the output of the three models with the highest scores. The latter is trained on the output of the individual model instances on the development set. We opt for this settings based on preliminary experiments on the training and development set.</p><p>To gain insights about the effectiveness of the additional data, we evaluate each model (except for the ensemble models) in two data configuration settings: with and without the additional texts from the GCTR data set (see Section 2.1). We use the provided evaluation script and report precision, recall and F1 scores as evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Development results</head><p>Table <ref type="table" coords="6,162.52,488.75,4.98,8.74" target="#tab_1">2</ref> highlights the results of all evaluated models on the provided development set, both with and without the additional data from GCTR as training data. The best single model performance is reached by the BERT subgroup baseline model. In this setting the model achieves an F 1 score of 0.778. Almost the same performance can be reached by our BERT multi-label approach (0.776). However, the latter offers a clearly better performance if the provided training set is extended by the GCTR samples (0.81 vs. 0.782). This represents an improvement of 0.028 (+3.6%) in terms of F 1 . For both baseline classification methods the sub-group models outperform the group-based variants, as to be expected. In case of the SVM, the performance increases from 0.655 to 0.717 (+ 9.5%) if considering sub-group labels instead group labels. With the BERT model the performance increases by 10.4% from 0.705 to 0.778. Interestingly, the BERT group level model performs nearly on par with the sub-group level SVM model. This is especially noteworthy as we do not perform hyperparameter optimisation for BERT group / sub-group but for the corresponding SVM models. This highlights the effectiveness and suitability of the BERT model for this task, since in general SVMs offer competitive performance for document classification problems <ref type="bibr" coords="7,177.46,142.90,14.61,8.74" target="#b17">[20]</ref>.</p><p>The dictionary matching can't compete with the machine learning based solutions. Even through the matching of the concept terms with the trail summaries provides the highest recall (0.894) of all evaluated approaches, the precision of the approach is very low (0.416) due to many false positives. In particular, the approach often predicts incorrect chapter annotations, for instance the chapter XXI 681 times. This is because of the broad and general topic of the chapters respectively their descriptions, e.g. XXI is about "Factors influencing health status and contact with health services".</p><p>Comparing the configurations with and without the GCTR documents, it can be seen that the performance increases (at least slightly) for all considered models. Improvements range from 0.5% (SVM Sub-group) to 1.9% (BERT group) for the baseline systems with respect to their variants without the additional data. In contrast, the multi-label model can benefit more greatly from the extended training set (+3.2%).</p><p>The overall best performance is achieved by ensembling the best BERT multilabel models. In both ensembling variants the model reaches an F 1 score of 0.815. This represents an increase of 0.6% over the single model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Development predictions</head><p>We further analysed the predictions made by the different approaches. Figure <ref type="figure" coords="7,475.61,644.16,4.98,8.74" target="#fig_0">1</ref> (left) compares the true positives of our BERT multi-label model as well as the SVM and BERT sub-group baseline (all with the GCTR corpus as additional training data). We exclude the dictionary matching baseline for this investigation, since the approach predicts too optimistically and thereby distorts the picture.</p><p>First of all it can be noted that, in total 1,422 of the 1,682 gold standard ICD-10 codes are identified by at least one of the three methods. This corresponds to 84.5% of the complete development data set. The intersection of all three methods consists of 1,001 true positives. This represents 70.4% of all correctly identified codes. Additionally, 1,240 (87.2%) labels are predicted by two of the three methods. Furthermore, it can be seen that 110 true positives are exclusively identified by our multi-label approach. This constitutes 7.7% of all correctly found codes. In contrast, 98 codes (6.9%) were predicted by (at least) one of the two classification baseline and not detected by our BERT multi-label approach. We tried to investigate the differences between the multi-label and the classification models but can't come up with a clear (error) pattern.</p><p>We also perform the investigation using the best ensembled version of our approach (BERT multi-label LogReg). Figure <ref type="figure" coords="8,337.48,310.71,4.98,8.74" target="#fig_0">1</ref> (right) highlights the results of this comparison. Through the ensembling we are able to additionally identify 20 labels correctly. Moreover, 38 ICD-10 codes that were exclusively predicted by the classification baselines previously are now detected by the multi-label approach too. However, when interpreting the figures one has to keep in mind that the logistic regression model that ensembles the predictions of the individual model instances is trained on the development set and hence may tend to represent an over-optimistic picture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Test results</head><p>Table <ref type="table" coords="9,162.66,146.25,4.98,8.74">3</ref> shows the results of the final evaluation performed by the task organisers. Every team was allowed to submit up to 3 runs of their approaches. We submitted three different runs: the best single model instance (according to the development results) of BERT multi-label (WBI-run1 ) as well as the Avg-and LogReg-ensemble (WBI-run2 /WBI-run3 ). All models are trained on the GCTRextended data.</p><p>Table <ref type="table" coords="9,163.24,238.52,4.13,7.89">3</ref>. Results of the final evaluation performed by the task organisers. They report precision, recall and F1 scores. We submitted three runs: BERT multi-label (WBI-run1 ), Avg-(WBI-run2 ) and LogReg-ensemble (WBI-run3 ). Our models achieve the best performance in the challenge. Bold figures highlight the highest value per column. The overall best performance is accomplished by the single BERT multilabel model. In this setting the model achieves an F 1 score of 0.80. The model shows a slightly better precision (0.83) than recall (0.77). Comparing the model with both ensembling variants it can be seen that all models perform almost on par and just leverage slightly different precision-recall trade-offs. The Avgensemble of the best models (run2 ) predicts more conservatively reaching the highest precision (0.84) of all evaluated models, but offers lower recall scores. In contrast, the LogReg-ensemble provides well-balanced precision and recall scores. Moreover, it has to be noted that the final evaluation scores are virtually the same as the development scores. However, no positive effects can be observed through ensembling of multiple models (at least in the considered way).</p><p>Comparing our method with the other submissions, it can be seen that our model outperforms the other team's approaches by a large extend. The second best team (MLT-DFKI) reaches a higher recall (0.86) than our multi-label model (0.77). However, their approach has a lower precision compared to our model (0.64/0.83). This allows our model to achieve a 9.6% higher F 1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper presents our contribution to Task 1 of the CLEF eHealth competition 2019. The task challenges the automatic assignment of ICD-10 codes to German non-technical summaries of animal experiments.</p><p>We approach the task as multi-label classification problem and leverage the multi-lingual version of BERT <ref type="bibr" coords="10,273.07,227.59,10.52,8.74" target="#b4">[5]</ref> to represent the summaries. We extend the model with a single output layer to predict probabilities for each ICD-10 code. Furthermore, we utilise additional data from the German Clinical Trails Register to built an extended training data set and hereby improve the overall performance of the approach. Evaluation results highlight the advantage of our proposed approach. Our model achieves the highest performance figures of all submission with an F 1 score of 0.80. Moreover, experiments on the development set illustrate that the model outperforms several strong classification baselines by a large extend.</p><p>There are several research questions worth to investigate following this work. Due to the multi-lingual nature of the used BERT encoding model it would be interesting to evaluate our approach in an cross-lingual setup, e.g. apply the learned model to non-German clinical documents or animal trail summaries. For this purpose we want to use the data from the previous editions of the CLEF eHealth challenges, i.e. Italian, English, French and Hungarian death certificates. This is especially interesting, because of the different text format of the certificates. They are much shorter than the animal experiment summaries and contain a lot of abbreviations of medical terms. It is an open question how well our trained model can be transferred to this type of texts. Furthermore, we also plan to inspect other approaches to the task, e.g. modelling the task as question-answering problem. Recently, versions of BERT trained on English biomedical literature have been published <ref type="bibr" coords="10,320.51,478.65,15.50,8.74" target="#b10">[12,</ref><ref type="bibr" coords="10,337.67,478.65,7.01,8.74" target="#b2">3]</ref>. It would be worthwhile to investigate whether an extension of such models to multi-lingual biomedical texts would improve results further.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,134.77,587.80,345.83,7.89;8,134.77,598.79,345.83,7.86;8,134.77,609.74,345.82,7.86;8,134.77,620.70,345.83,7.86;8,134.77,631.66,36.61,7.86;8,134.93,426.74,152.36,144.85"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison of the predicted true positive ICD-10 codes of the evaluated models. On the left the best (single) instance of our BERT multi-label model is contrasted with the best SVM and BERT classification baseline. The diagram on the right shows the changes when using the best ensemble model of our approach (BERT multi-label LogReg).</figDesc><graphic coords="8,134.93,426.74,152.36,144.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,115.91,345.83,108.25"><head>Table 1 .</head><label>1</label><figDesc>Overview about the used data sets. The non-technical animal experiment summaries (NTS) are provided by the task organisers. Furthermore, we build a second data set based on the German Clinical Trails Register (GCTR).</figDesc><table coords="4,152.93,162.29,302.76,61.88"><row><cell></cell><cell>#Documents</cell><cell>#ICD-10 codes</cell><cell>#ICD-10 codes (distinct)</cell></row><row><cell>NTS Train</cell><cell>7453</cell><cell>15251</cell><cell>230</cell></row><row><cell>Dev</cell><cell>842</cell><cell>1682</cell><cell>156</cell></row><row><cell>GCTR</cell><cell>7615</cell><cell>18263</cell><cell>253</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,377.72,345.83,200.73"><head>Table 2 .</head><label>2</label><figDesc>Evaluation results of our model (last three rows) and the five baseline approaches (first five rows) on the provided development set. We report precision, recall and F1 scores in two data scenarios: (left) using only the provided training data and (right) using documents from German Clinical Trail Register as additional training instances.</figDesc><table coords="7,147.88,456.47,316.81,121.97"><row><cell>Model</cell><cell>P</cell><cell>NTS data R</cell><cell>F1</cell><cell cols="2">NTS + GCTR data P R F1</cell></row><row><cell>Dictionary matching</cell><cell cols="3">0.416 0.894 0.568</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SVM group</cell><cell cols="5">0.778 0.565 0.655 0.813 0.554 0.659</cell></row><row><cell>SVM sub-group</cell><cell cols="5">0.804 0.646 0.717 0.815 0.653 0.725</cell></row><row><cell>BERT group</cell><cell cols="5">0.810 0.624 0.705 0.820 0.640 0.719</cell></row><row><cell>BERT sub-group</cell><cell cols="5">0.811 0.748 0.778 0.833 0.737 0.782</cell></row><row><cell>BERT multi-label</cell><cell cols="5">0.901 0.747 0.776 0.834 0.788 0.810</cell></row><row><cell>BERT multi-label Avg</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">0.850 0.782 0.815</cell></row><row><cell>BERT multi-label LogReg</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">0.808* 0.822* 0.815*</cell></row></table><note coords="7,134.77,432.54,171.78,7.86"><p>*: Ensembling trained on development set.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,624.57,141.22,7.47"><p>https://www.animaltestinfo.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,635.53,292.85,7.47;2,144.73,646.48,104.06,7.47"><p>https://www.dimdi.de/static/de/klassifikationen/icd/icd-10-gm/ kode-suche/htmlgm2016/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,657.44,202.91,7.47"><p>https://github.com/mariosaenger/wbi-clef19x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,144.73,657.44,207.12,7.47"><p>https://www.drks.de/drks_web/setLocale_EN.do</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,635.53,334.72,7.47;4,144.73,646.48,66.90,7.47"><p>https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_ H-768_A-12.zip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,144.73,657.44,255.19,7.47"><p>https://github.com/huggingface/pytorch-pretrained-BERT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,144.73,657.44,145.93,7.47"><p>https://lucene.apache.org/solr/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p><rs type="person">Leon Weber</rs> acknowledges the support of the <rs type="funder">Helmholtz Einstein International Berlin Research School in Data Science (HEIBRiDS)</rs>. We gratefully acknowledge the support of <rs type="funder">NVIDIA Corporation</rs> with the donation of the <rs type="funder">Titan X Pascal GPU</rs> used for this research.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,634.88,337.63,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,176.03,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,397.04,634.88,83.55,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,176.03,7.86">Mamtra-med at clef ehealth 2018: A combination of information retrieval techniques and neural networks for icd-10 coding of death certificates</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Almagro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Montalvo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">D</forename><surname>De Ilarraza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pérez</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,119.67,337.64,7.86;11,151.52,130.63,329.07,7.86;11,151.52,141.59,266.23,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Atutxa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Casillas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ezeiza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Fresno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gojenola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Oronoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Perez-De Vinaspre</surname></persName>
		</author>
		<title level="m" coord="11,338.19,130.63,142.40,7.86;11,151.52,141.59,205.44,7.86">Ixamed at clef ehealth 2018 task 1: Icd10 coding with a sequence-to-sequence approach</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>CLEF</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,151.78,337.64,7.86;11,151.52,162.74,218.49,7.86" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10676</idno>
		<title level="m" coord="11,277.94,151.78,202.66,7.86;11,151.52,162.74,52.64,7.86">Scibert: Pretrained contextualized embeddings for scientific text</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.96,172.92,337.63,7.86;11,151.52,183.88,329.07,7.86;11,151.52,194.84,329.07,7.86;11,151.52,205.77,129.77,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,315.10,183.88,165.49,7.86;11,151.52,194.84,299.48,7.86">Rethinking 3r strategies: Digging deeper into animaltestinfo promotes transparency in in vivo biomedical research</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dörendahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Leich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vietze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steinfath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chmielewska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hensel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Schönfelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,458.83,194.84,21.76,7.86;11,151.52,205.80,28.93,7.86">PLoS biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">2003217</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,215.99,301.88,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="11,210.58,215.99,166.30,7.86">Pattern recognition and machine learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,226.17,337.63,7.86;11,151.52,237.13,329.07,7.86;11,151.52,248.09,25.60,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="11,346.99,226.17,133.60,7.86;11,151.52,237.13,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.96,258.27,337.63,7.86;11,151.52,269.23,329.07,7.86;11,151.52,280.17,89.45,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,403.59,258.27,77.00,7.86;11,151.52,269.23,262.60,7.86">Deep learning with word embeddings improves biomedical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Habibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Wiegandt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,422.02,269.23,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,290.38,337.63,7.86;11,151.52,301.34,79.45,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,332.25,290.38,148.34,7.86;11,151.52,301.34,50.79,7.86">A practical guide to support vector classification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,311.52,337.63,7.86;11,151.52,322.48,329.07,7.86;11,151.52,333.44,264.71,7.86;11,134.77,343.63,345.83,7.86;11,151.52,354.59,329.07,7.86;11,151.52,365.54,329.07,7.86;11,151.52,376.50,329.07,7.86;11,151.52,387.46,329.07,7.86;11,151.52,398.42,259.66,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,217.88,322.48,262.71,7.86;11,151.52,333.44,264.71,7.86;11,134.77,343.63,7.85,7.86;11,357.65,354.59,122.95,7.86;11,151.52,365.54,75.06,7.86">Toronto cl at clef 2018 ehealth task 1: Multi-lingual icd-10 coding using an ensemble of recurrent and convolutional neural networks 10</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jeblee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Budhkar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Milic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Pou-Prom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Vishnubhotla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rudzicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Scells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,426.42,365.54,54.17,7.86;11,151.52,376.50,329.07,7.86;11,151.52,387.46,232.55,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Tenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="11,414.18,387.46,66.41,7.86;11,151.52,398.42,71.32,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">N L D E</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>Overview of the CLEF eHealth evaluation lab 2019</note>
</biblStruct>

<biblStruct coords="11,142.62,408.61,337.97,7.86;11,151.52,419.57,93.19,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,239.72,408.61,176.61,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.62,429.75,337.97,7.86;11,151.52,440.71,329.07,7.86;11,151.52,451.67,159.05,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="11,428.04,429.75,52.55,7.86;11,151.52,440.71,324.76,7.86">Biobert: pretrained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08746</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.62,461.86,337.98,7.86;11,151.52,472.82,329.07,7.86;11,151.52,483.77,329.07,7.86;11,151.52,494.73,306.33,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,329.01,472.82,151.58,7.86;11,151.52,483.77,107.08,7.86">Clinical information extraction at the clef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,301.42,483.77,179.17,7.86;11,151.52,494.73,151.81,7.86">Proceedings of CLEF 2016 Evaluation Labs and Workshop: Online Working Notes</title>
		<meeting>CLEF 2016 Evaluation Labs and Workshop: Online Working Notes</meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2016-09">2016. September 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,504.92,337.97,7.86;11,151.52,515.88,329.07,7.86;11,151.52,526.84,329.07,7.86;11,151.52,537.80,137.66,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,310.17,515.88,170.42,7.86;11,151.52,526.84,325.19,7.86">Clef ehealth 2017 multilingual information extraction task overview: Icd10 coding of death certificates in english and french</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,165.60,537.80,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,547.98,337.97,7.86;11,151.52,558.94,329.07,7.86;11,151.52,569.90,329.07,7.86;11,151.52,580.86,329.07,7.86;11,151.52,591.82,25.60,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,270.57,558.94,210.03,7.86;11,151.52,569.90,325.55,7.86">Clef ehealth 2018 multilingual information extraction task overview: Icd10 coding of death certificates in french, hungarian and italian</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Grippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Morgand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pelikán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,164.97,580.86,264.67,7.86">CLEF 2018 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,602.00,337.97,7.86;11,151.52,612.96,329.07,7.86;11,151.52,623.92,329.07,7.86;11,151.52,634.88,329.07,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.80,296.32,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,197.02,612.96,283.57,7.86;11,151.52,623.92,14.75,7.86">Overview of the CLEF eHealth 2019 Multilingual Information Extraction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Butzke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dörendahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Leich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Schönfelder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,433.85,623.92,46.75,7.86;11,151.52,634.88,329.07,7.86;11,151.52,645.84,290.76,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Tenth International Conference of the CLEF Association (CLEF 2019)</title>
		<title level="s" coord="11,450.23,645.84,30.36,7.86;11,151.52,656.80,107.98,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,119.67,337.98,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,80.91,7.86" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Organization</surname></persName>
		</author>
		<title level="m" coord="12,265.45,119.67,215.14,7.86;12,151.52,130.63,229.07,7.86">The ICD-10 classification of mental and behavioural disorders: clinical descriptions and diagnostic guidelines</title>
		<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<publisher>World Health Organization</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,152.55,337.98,7.86;12,151.52,163.51,327.47,7.86;12,134.77,174.47,345.82,7.86;12,151.52,185.43,329.07,7.86;12,151.52,196.39,167.19,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,303.85,163.51,146.46,7.86">Automatic differentiation in pytorch</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,351.88,185.43,128.71,7.86;12,151.52,196.39,73.89,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct coords="12,142.62,207.34,337.97,7.86;12,151.52,218.30,329.07,7.86;12,151.52,229.26,119.16,7.86;12,300.41,229.26,180.18,7.86;12,151.52,240.22,135.39,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,264.75,207.34,215.84,7.86;12,151.52,218.30,73.01,7.86">Baselines and bigrams: Simple, good sentiment and topic classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,245.61,218.30,234.99,7.86;12,151.52,229.26,115.61,7.86">Proceedings of the 50th annual meeting of the association for computational linguistics</title>
		<meeting>the 50th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="90" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,251.18,337.97,7.86;12,151.52,262.14,329.07,7.86;12,151.52,273.10,329.07,7.86;12,151.52,284.06,97.80,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="12,333.42,262.14,147.17,7.86;12,151.52,273.10,264.49,7.86">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
