<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.54,150.87,325.84,12.64;1,131.30,166.95,332.35,12.64">DEMIR at CLEF eHealth 2019: Information Retrieval based Classification of Animal Experiments Summaries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,195.05,206.22,54.00,8.96"><forename type="first">Nizar</forename><surname>Ahmed</surname></persName>
							<email>nizar.ahmed@ceng.deu.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">Dokuz Eylul University</orgName>
								<address>
									<settlement>Izmir</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.61,206.12,56.73,9.05"><forename type="first">Alirıza</forename><surname>Arıbaş</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dokuz Eylul University</orgName>
								<address>
									<settlement>Izmir</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.85,206.22,59.05,8.96"><forename type="first">Adil</forename><surname>Alpkoçak</surname></persName>
							<email>alpkocak@ceng.deu.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">Dokuz Eylul University</orgName>
								<address>
									<settlement>Izmir</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.54,150.87,325.84,12.64;1,131.30,166.95,332.35,12.64">DEMIR at CLEF eHealth 2019: Information Retrieval based Classification of Animal Experiments Summaries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6BC6DC4EE252F895E98B3995B6D5CE90</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Elasticsearch</term>
					<term>k-Nearest Neighbor k-NN</term>
					<term>Threshold -Nearest Neighbor t-NN</term>
					<term>Multi-label classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Information retrieval searching systems recently become powerful for retrieving full text results according to a particular query (or else a document query). Elastic search is an open source information retrieval searching system that is built on Apache Lucene, and works as a distributed search and analytics engine at the same time. Therefore, this engine can also be used as one of machine learnings' approaches to solve some challenges such as document classification problem. This study is published as working-notes paper 1 for CLEF eHealth 2019 Task 1 on Multilingual Information Extraction and it proposes a k-nearest neighbor (k-NN) and Threshold (t-NN) approaches to classify animal experiment summaries into its correct ICD-10 codes. After that, another two methods are proposed to control and adjust the retrieved labels of the documents results to assign ICD-10 codes for the issued query document. These approaches register high precision, recall and f-measure after we experiment it with the development dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Information retrieval systems proved its efficacy during time by improving the correctness of the retrieved search results and minimizing the retrieval time <ref type="bibr" coords="1,456.03,492.11,10.66,8.96" target="#b0">[1]</ref>.</p><p>Elasticsearch is an open source information retrieval searching system that is built on Apache Lucene, and works as a distributed search and analytics engine. This system showed its power since released in 2010 and become the most popular search model for full-text searching, log analytics, security intelligence and business analytics <ref type="bibr" coords="1,446.97,538.07,10.67,8.96" target="#b1">[2]</ref>. Using Elasticsearch is not limited only on information retrieval searching purposes but also it deals with machine learning applications. Accordingly, machine learning now becomes a core and natural extension to the search and some analytical capabilities of Elasticsearch <ref type="bibr" coords="1,180.23,584.18,10.66,8.96" target="#b2">[3]</ref>. Many researches employed Elastic search in their machine learning models but for statistical purposes (using Kabana statistical tool) such as M. Bajer <ref type="bibr" coords="1,459.10,595.70,11.69,8.96" target="#b3">[4]</ref> and J. Bai <ref type="bibr" coords="1,167.06,607.10,10.58,8.96" target="#b2">[3]</ref>. Our research is maintained according to CLEF 2019 eHealth Task 1 challenge <ref type="bibr" coords="1,438.56,618.62,10.66,8.96" target="#b4">[5]</ref>. The main requirements in their tasks is to discover the semantic indexing of NTPs using codes from the German version of the International Classification of Diseases (ICD-10). In our point of view, this task considered a multi-label classification problem since each text document is assigned/classified to at least one label of the ICD-10 codes. This paper suggests accumulating Elasticsearch with a machine learning model to classify the text documents into one of ICD-10 codes. Our approach first suggests the work with k-nearest neighbor k-NN and a threshold approach t-NN for retrieving the document result set of Elastic search step. After that it proposes the work with two other approaches to predict the ICD-10 codes for the query document (such as calculating the raw or similarity frequency of the retrieved label set). To the best of our knowledge, this method considered the first to apply with a multi-label problem and well thoughtout more challenging. The rest of this paper is organized as follows: section two provides all the details about our methodology. Then, section three shows experimental set up. After that, section four contains our results with its discussion. Finally, section five gives the conclusion of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>In this work, we propose an IR (Information Retrieval) mechanism for classifying the animal test information with ICD-10 codes. Animal test information is written in German language that is a non-technical summaries (NTPs) of animal experiments. This problem considered a multi-label machine learning task since each text document is assigned/classified to at least one label of the ICD-10 codes. Our methodology passes through two main phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The First Phase: Approaches responsible for controlling the results of the Elasticsearch IR system:</head><p>We use Elasticsearch platform to retrieve documents (from the training data) that are similar to a particular query document. The retrieved (resultant) documents may share the same class/es as the query document (for example one of the test/development files). We propose two main approaches to identify the result set of documents as a consequence of a particular query file: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>k-NN Method: (k nearest neighbor of the result set)</head><p>In this method we control the retrieved result set of the Elasticsearch by considering the top k documents which would be the nearest neighbors of the query document. We believe that changing k parameter will be responsible for controlling precision and recall scores. For example, imagine that we have Q1 as query document and after issuing this query in the Elasticsearch the following training data results are retrieved as follows:</p><p>Accordingly, if we set k=5, only the top 5 ranked documents will be considered and their label set will be taken into account while we calculate the predicted label set in the second phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t-NN Method: (Threshold based method)</head><p>After issuing the query document on the Elasticsearch system, the result set is retrieved with a ranking that depends on the similarity score of each document. t-NN method depends on controlling the retrieved result set of the Elasticsearch according to the similarity score parameter. Hence, we tune a specific similarity score (t: threshold value) so that any result set equal or greater than this value will be taken into account. For example, if we have t=30, it means that any resultant document with a similarity score equal or greater than 30 will be considered in the solution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Second Phase: Approaches responsible for predicting the class/es of the query document:</head><p>After producing the result set (i.e. retrieving the resultant documents in response to the query document), we should now calculate the majority label set of the results. We believe that these labels could be used as the predicted label of the query in hand. Moreover, taking into account the proper value of k or t in the first phase which plays an important role in label prediction process. There are two approaches in this phase:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw frequency of the label set:</head><p>In this approach, we calculate the frequency (normal count) of each label produced in the result set. After that we consider the top N labels with highest frequency (for example top 10 or 5 … etc.). Selecting the prober N value of the top labels controls the degree of precision and recall as well. For example, selecting N = 10 will produce a high range of predicted labels, therefore the recall score will be higher than that if we select N= 5. And vice versa for the precision score. Furthermore, another method is considered using the adaptive way (rather than the fixed one) to control the label set by averaging the sum of the label raw frequency N and use it as a cut-off value (i.e. top N will be considered). Fig. <ref type="figure" coords="5,195.33,149.94,3.76,8.96">3</ref>. The raw frequency method with its two sub-approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity frequency of the label set:</head><p>Instead of counting the raw frequency of each label of the result set, we consider the similarity score of the resultant document to be the factor of each label. For example, if the result document (Doc.1) of the Elasticsearch has a similarity score of 20 and this document is related with the label A, B, C, then each label in Doc.1 will be related to this score 20A,20B and 20C as you can see from figure <ref type="figure" coords="5,347.00,230.46,4.98,8.96" target="#fig_3">4</ref> A. So that when we calculate the frequency of each label from the total result set, see figure <ref type="figure" coords="5,371.75,242.01,4.98,8.96" target="#fig_3">4</ref> B, we will consider the similarity score not the normal count of the labels. In addition, we explore the adaptive way to control the label set by averaging the sum of the label similarity frequency M and use it as a cut-off value (i.e. top M will be considered). As a result to the great difference between the values of the labels' frequencies, the adaptive way will not be effective unless we divide the average by a particular factor (several values used as parameters and taken into consideration in our case). For example, the average from the table B of figure <ref type="figure" coords="5,379.03,529.91,4.98,8.96" target="#fig_3">4</ref> is calculated as: 390+345+200+195+50+30+30=1240/7=177.14. So, considering the top 177 labels will be exhaustive to predict the label of a particular query document. As a result, we divide the average by several values let's say 30 (a value more than 10) then: 177/30=5.9 so that only the top 6 labels will be considered as the predicted label. This approach is maintained only by experiments and it seems that it affects the progress of recall and precision very well as we will see in the result section.</p><p>In general, all the approaches mentioned in this section were preserved, explored and proved in an experimental environment. Eventually, they seem satisfying after we see the recall and precision scores getting higher with each parameter taken into consideration. Our experiments started by preparing the training documents to represent the collection of corpora that will be retrieved as the search results of a query document. And the development/test sets are used as the query documents that we need to predict their ICD-10 labels. Therefore, the experiments begin from phase one by issuing a query document as an input to the Elasticsearch platform. Then a result set returned consequently with their related labels and some other information such as similarity scores for each document. We used Elasticsearch default settings for similarity, analyzer, stemmer and stopwords in German. Elasticsearch weighting schemas consist of term frequency, inverse document frequency and field-length norm for calculating similarity score <ref type="bibr" coords="6,189.19,348.33,10.66,8.96" target="#b7">[8]</ref>. The following points describe all the experiments that held by our system and each considers one approach of phase one with another in phase two in sequence (like described previously in methodology section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiments representing k-NN method from phase one and both methods of the second phase:</head><p>Experiment 1: k-NN with top N of the fixed raw frequency approach to predict the label set.</p><p>In this test we explore seven values of k (k= 15, 20, 50, 100, 200, 500 and 1000) to consider only the top k resulted documents. Those values are used to tune k parameter and record precision and recall scores to see which value will be the most suitable one. After retrieving the resulting documents , we conduct the raw frequency method of phase two to predict the label set. We explored several values to consider the top N labels as the predicted class: N = 10 to 2 (9 values).</p><p>Experiment 2: k-NN with top N of the adaptive raw frequency approach to predict the label set.</p><p>In this experiment we try thirteen values of k (k=5,6,7,8,9,10,15, 20, 50, 100, 200, 500 and 1000) to consider only the top k resulted documents. Then we work with the adaptive approach that will choose the proper value of the top raw label frequency as described in the methodology section.</p><p>Experiment 3: k-NN with top M fixed similarity frequency of the label set. In this test we try eight values of k (k=5,6,7,8,9,15, 20 and 50) to consider only the top k resulted documents. After retrieving the resulting documents, we conduct the similarity frequency method of phase two to predict the label set. We explored several values to consider the top M labels as the predicted class: M = 10 to 2 (9 values).</p><p>Experiment 4: k-NN with top M of the adaptive similarity frequency approach to predict the label set.</p><p>In this experiment we try nine values of k (k= 5,6,7,8,9,10,15, 20 and 50) to consider only the top k resulted documents. Then we work with the adaptive approach that will choose the proper value of the top raw label frequency as described in the methodology section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments represent t-NN method from phase one and both methods of the second phase:</head><p>Experiment 5: t-NN with top N of the fixed raw frequency approach to predict the label set.</p><p>In this approach we choose to work with three threshold values of t (t= 10, 20 and 30) to take the top resultant documents which its similarity is greater or equal to t. After that we apply the raw frequency method of phase two to predict the label set. We test several values to select the top N labels as the predicted class: N = 10 to 2 (9 values).</p><p>Experiment 6: t-NN with top N of the adaptive raw frequency approach to predict the label set.</p><p>Likewise, we select four values of the threshold t (t=10,20,25 and 30). Then we work with the adaptive approach that will choose the proper value of the top raw label frequency.</p><p>Experiment 7: t-NN with top M fixed similarity frequency of the label set. Similar to experiment 5, we select three threshold values (t=10,20 and 30) for phase one and the similarity frequency method of phase two to predict the label set (top N labels as the predicted class: N = 10 to 2).</p><p>Experiment 8: t-NN with top M of the adaptive similarity frequency approach to predict the label set.</p><p>Finally, we choose eight threshold values (T= 10,20,30,40,50,60,70 and 80) in phase one, and the adaptive approach that will select the proper value of the top similarity label frequency in phase two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>For evaluating our approach, we depend on three state of art evaluation metrics: precision, recall and F-measure <ref type="bibr" coords="7,254.06,592.82,11.69,8.96" target="#b5">[6]</ref>  <ref type="bibr" coords="7,268.54,592.82,10.58,8.96" target="#b6">[7]</ref>. The following tables summarize the results of all the experiments applied on the development dataset within the two main phases (i.e. k-NN and t-NN), with each point of phase two that explains each method for predicting the labels. These tables hold only the best values of precision, recall and F-measure scores in each experiment mentioned in the last section. We noticed that working with similarity frequency for predicting the label set outperforms considering the raw frequency with both k-NN and t-NN main approaches. More specifically, as you can see from experiment 8 of table 2 (i.e. t-NN and adaptive similarity frequency for label prediction techniques), a highest precision, recall and Fmeasure has been recorded. Furthermore, this score demonstrates that setting t = 80 and working with the adaptive way for predicting the labels using similarity frequency will guarantee that the query will neither be more specific nor more exhaustive. Else, at t=80, precision, recall and f-measure are meeting at this point so that they are more moderate and stable. See figure <ref type="figure" coords="8,252.84,615.98,3.76,8.96" target="#fig_5">5</ref>. Finally, we choose three methods to apply them on the testing data: Exp3, Exp7 and Exp8. We got these results with the best evaluation scores in the development set amongst the others (As you can see from the bold text in Table <ref type="table" coords="9,388.76,416.15,4.98,8.96" target="#tab_0">1</ref> and Table <ref type="table" coords="9,440.65,416.15,3.62,8.96" target="#tab_1">2</ref>). The following Table <ref type="table" coords="9,192.79,427.67,4.98,8.96" target="#tab_2">3</ref> shows the precision, recall and F-measure scores after we run our system on the test data. As a result, we compared our results with development and test set. Our system works better with larger set, since development includes more documents than test set. The more number of the retrieved result set, the more ICD-10 codes return. Some query returns too much, some too few. The parameters, t and k, controls the size of result set. We run the test set queries using parameters shown in Table <ref type="table" coords="10,369.03,195.80,3.76,9.05" target="#tab_2">3</ref>. But this settings didn't work well in some conditions. For example, when threshold t = 80, more than 40% of test set documents retrieved no results. When we decrease the value of t from 80 to 10 and then 30, it returns document with lower similarity score and hence it may lead to misclassification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>CLEF 2019 eHealth Task 1 announced a challenge that is concerned with discovering the semantic indexing of NTPs using codes from the German version of the International Classification of Diseases (ICD-10). This task considered a multi-label classification problem since each text document is assigned/classified to at least one label of the ICD-10 codes. This paper proposes an information retrieval paradigm that depends on Elasticsearch result set to classify unseen (query documents) to its correct ICD-10 code. There are two main phases proposed in this study: the first one responsible for controlling the results of the Elasticsearch IR system (depending on k-NN and t-NN approaches) and the second responsible for predicting the class/es of the query document (depending on fixed or adaptive raw frequency as well as similarity frequency). Our results show that working with t-NN approach in phase one and the adaptive similarity frequency in phase two records the highest precision, recall and fmeasure</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,197.81,291.45,199.38,8.96;3,114.65,147.40,369.60,141.50"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. k-NN method on the Elastic search results.</figDesc><graphic coords="3,114.65,147.40,369.60,141.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,204.77,696.14,157.32,8.96;3,204.77,707.66,143.41,8.96;3,121.80,541.88,346.10,139.00"><head>Fig.</head><label></label><figDesc>Fig. SEQ Figure \* ARABIC 2. TNN method on the Elastic search results</figDesc><graphic coords="3,121.80,541.88,346.10,139.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,204.29,149.94,197.81,8.96"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. t-NN method on the Elastic search results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,139.10,449.39,328.07,8.96;5,251.09,460.91,92.87,8.96;5,114.65,285.39,393.65,161.40"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Calculating label frequency according to similarity and considering the top 5 labels (fixed method)</figDesc><graphic coords="5,114.65,285.39,393.65,161.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,136.10,175.74,334.47,8.96;6,124.70,187.26,345.43,8.96;6,124.70,198.78,345.67,8.96;6,124.70,210.20,345.96,9.06;6,124.70,221.70,345.52,8.96;6,124.70,233.25,63.18,8.96"><head>A</head><label></label><figDesc>total Number of 8793 German text documents are used in the experiments: 7543 training, 842 development set and 403 as testing set. All of the training and development set are annotated by either one of the ICD-10 codes or without label. On the other hand, we don't reward or penalizing for unannotated NTSs. Moreover, all the test set document released in CLEF 2019 eHealth Task 1 challenge without providing their gold-truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,136.70,335.73,333.24,8.96;9,257.21,347.13,80.74,8.96;9,125.25,149.65,345.00,160.45"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. meeting point of precision, recall and F-measure at t=80 with t-NN adaptive similarity frequency</figDesc><graphic coords="9,125.25,149.65,345.00,160.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,143.30,661.82,320.01,20.48"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of all k-NN experiments with raw and similarity frequency label prediction techniques using development set.</figDesc><table coords="8,124.70,150.42,345.62,149.51"><row><cell>Experiment</cell><cell>Exp. 1: k-NN</cell><cell>Exp. 2: k-NN</cell><cell>Exp. 3: k-NN</cell><cell>Exp. 4: k-NN</cell></row><row><cell>No and</cell><cell>with fixed raw</cell><cell>with adaptive</cell><cell>with fixed</cell><cell>with of the</cell></row><row><cell>Description</cell><cell>frequency</cell><cell>raw frequency</cell><cell>similarity</cell><cell>adaptive</cell></row><row><cell></cell><cell></cell><cell></cell><cell>frequency</cell><cell>similarity</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>frequency</cell></row><row><cell>k and top</cell><cell>k=15, N=2</cell><cell>k=8,</cell><cell>k=5, M=2</cell><cell>k=5,</cell></row><row><cell>N/M labels</cell><cell></cell><cell>N=adaptive</cell><cell></cell><cell>M=adaptive</cell></row><row><cell>values</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.562</cell><cell>0.549</cell><cell>0.808</cell><cell>0.672</cell></row><row><cell>Recall</cell><cell>0.503</cell><cell>0.545</cell><cell>0.707</cell><cell>0.817</cell></row><row><cell>F-measure</cell><cell>0.531</cell><cell>0.547</cell><cell>0.754</cell><cell>0.738</cell></row><row><cell cols="5">*k: stands for k nearest neighbors of Elasticsearch result set. *N: Top N raw frequency.</cell></row><row><cell cols="2">*M top M similarity frequency.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,124.70,314.01,345.43,195.94"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of all t-NN experiments with raw and similarity frequency label prediction techniques using development set.</figDesc><table coords="8,124.70,348.93,345.43,161.02"><row><cell>Experiment</cell><cell>Exp. 5: t-NN</cell><cell>Exp. 6: t-NN</cell><cell>Exp. 7: t-NN</cell><cell>Exp. 8: t-NN</cell></row><row><cell>No and</cell><cell>with fixed raw</cell><cell>with adaptive</cell><cell>with fixed</cell><cell>with of the</cell></row><row><cell>Description</cell><cell>frequency</cell><cell>raw frequency</cell><cell>similarity</cell><cell>adaptive</cell></row><row><cell></cell><cell></cell><cell></cell><cell>frequency</cell><cell>similarity</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>frequency</cell></row><row><cell>t and top</cell><cell>t= 20, N = 2</cell><cell>t= 25, N =</cell><cell>t= 30, M = 3</cell><cell>t= 80, M =</cell></row><row><cell>N/M labels</cell><cell></cell><cell>adaptive</cell><cell></cell><cell>adaptive</cell></row><row><cell>values</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.558</cell><cell>0.541</cell><cell>0.722</cell><cell>0.843</cell></row><row><cell>Recall</cell><cell>0.479</cell><cell>0.420</cell><cell>0.816</cell><cell>0.838</cell></row><row><cell>F-measure</cell><cell>0.516</cell><cell>0.473</cell><cell>0.767</cell><cell>0.841</cell></row><row><cell cols="5">*t: stands for the threshold value according to similarity score value of the retrieved</cell></row><row><cell>result set.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,135.62,531.23,333.20,149.39"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of raw and similarity (weighted) frequency label prediction techniques using test set.</figDesc><table coords="9,135.62,566.18,333.20,114.44"><row><cell>Experiment No and</cell><cell>Exp. 3:</cell><cell>Exp. 7:</cell><cell>Exp. 8:</cell></row><row><cell>Description</cell><cell>k-NN with fixed</cell><cell>t-NN with fixed</cell><cell>t-NN with of the</cell></row><row><cell></cell><cell>similarity</cell><cell>similarity</cell><cell>adaptive</cell></row><row><cell></cell><cell>frequency</cell><cell>frequency</cell><cell>similarity</cell></row><row><cell></cell><cell></cell><cell></cell><cell>frequency</cell></row><row><cell>k, t and top N/M</cell><cell>k=5, N=3</cell><cell>t=10, M=3</cell><cell>t=30, M=adaptive</cell></row><row><cell>labels values</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.46</cell><cell>0.49</cell><cell>0.46</cell></row><row><cell>Recall</cell><cell>0.50</cell><cell>0.44</cell><cell>0.49</cell></row><row><cell>F-measure</cell><cell>0.48</cell><cell>0.46</cell><cell>0.48</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,163.70,514.31,305.99,8.96;10,152.30,525.83,317.63,8.96;10,152.30,537.35,192.87,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,288.09,514.31,181.60,8.96;10,152.30,525.83,143.28,8.96">ElasticSearch: An advanced and quick search technique to handle voluminous data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Divya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,308.93,525.83,161.00,8.96;10,152.30,537.35,133.46,8.96">COMPUSOFT, An international journal of advanced computer technology</title>
		<imprint>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,163.70,550.31,306.20,8.96;10,152.30,561.86,264.88,8.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,270.22,550.31,199.68,8.96;10,152.30,561.86,145.10,8.96">Elasticsearch: The definitive guide: A distributed real-time search and analytics engine</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,163.70,574.82,305.85,8.96;10,152.30,586.34,317.51,8.96;10,152.30,597.86,110.10,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,196.54,574.82,273.01,8.96;10,152.30,586.34,68.82,8.96">Feasibility analysis of big log data real time search based on hbase and elasticsearch</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,265.61,586.34,204.20,8.96;10,152.30,597.86,80.32,8.96">2013 ninth international conference on natural computation (ICNC)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,163.70,610.82,305.85,8.96;10,152.30,622.34,317.31,8.96;10,152.30,633.86,167.34,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,214.05,610.82,255.50,8.96;10,152.30,622.34,25.25,8.96">Building an IoT data hub with Elasticsearch, Logstash and Kibana</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bajer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,213.98,622.34,255.63,8.96;10,152.30,633.86,137.56,8.96">2017 5th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,163.70,646.82,305.65,8.96;10,152.30,658.34,317.05,8.96;10,152.30,669.86,317.51,8.96;10,152.30,681.38,317.33,8.96;11,152.30,150.66,317.73,8.96;11,152.30,162.18,114.08,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,404.44,658.34,64.90,8.96;10,152.30,669.86,177.59,8.96">Overview of the {CLEF eHealth} Evaluation Lab 2019</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">.</forename><forename type="middle">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">.</forename><forename type="middle">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Scells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,364.75,669.86,105.06,8.96;10,152.30,681.38,317.33,8.96;11,152.30,150.66,278.75,8.96">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Tenth International Conference of the CLEF Association (CLEF 2019)</title>
		<meeting><address><addrLine>Berlin Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,163.70,175.26,306.15,8.96;11,152.30,186.66,317.46,8.96;11,152.30,198.18,55.36,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,342.57,175.26,127.28,8.96;11,152.30,186.66,102.72,8.96">Multi-label classification using ensembles of pruned sets</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Geoffrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,292.81,186.66,176.95,8.96;11,152.30,198.18,26.00,8.96">8th IEEE international conference on data mining</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,163.70,211.26,306.18,8.96;11,152.30,222.66,271.39,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,281.16,211.26,188.72,8.96;11,152.30,222.66,95.00,8.96">Labelling strategies for hierarchical multi-label classification techniques</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Triguero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Celine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,262.01,222.66,79.02,8.96">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="170" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,163.70,247.29,306.09,8.96;11,152.30,258.69,293.40,8.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,310.18,247.29,159.61,8.96;11,152.30,258.69,191.66,8.96">Elasticsearch: The definitive guide: A distributed real-time search and analytics engine</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
