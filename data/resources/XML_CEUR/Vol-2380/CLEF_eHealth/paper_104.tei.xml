<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.20,115.96,266.96,12.62;1,226.85,133.89,161.67,12.62;1,178.37,151.82,258.62,12.62">Classification of Animal Experiments: A Reproducible Study. IMS Unipd at CLEF eHealth Task 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,247.76,189.49,74.99,8.74"><forename type="first">Giorgio</forename><forename type="middle">Maria</forename><surname>Di</surname></persName>
							<email>giorgiomaria.dinunzio@unipd.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.20,115.96,266.96,12.62;1,226.85,133.89,161.67,12.62;1,178.37,151.82,258.62,12.62">Classification of Animal Experiments: A Reproducible Study. IMS Unipd at CLEF eHealth Task 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CBCD4E2E8AB92B402761823CC3EE357A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the third participation of the Information Management Systems (IMS) group at CLEF eHealth 2019 Task 1. In this task, participants are required to label with ICD-10 codes health-related documents with the focus on the German language and on non-technical summaries (NTPs) of animal experiments. We tackled this task by focusing on reproducibility aspects, as we did the previous years. This time, we tried three different probabilistic Naïve Bayes classifiers that use different hypothesis on the distribution of terms in the documents and the collection. The experimental evaluation showed a significantly different behavior of the classifiers during the training phase and the test phase. We are currently investigating possible sources of biases introduced in the training phase as well as out-of-vocabulary issues and change in the terminology from the training set to the test set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we report the experimental results of the participation of the IMS group to the CLEF eHealth Lab <ref type="bibr" coords="1,276.44,476.02,9.96,8.74" target="#b2">[3]</ref>, in particular to Task 1: "Multilingual Information Extraction -Semantic Indexing of animal experiments summaries" <ref type="bibr" coords="1,467.30,487.98,9.96,8.74" target="#b0">[1]</ref>. This task consists in automatically labelling with ICD-10 codes health-related documents with the focus on the German language and on non-technical summaries (NTPs) of animal experiments with the German Classification Diseases (ICD10) codes.</p><p>The main goal of our participation to the task this year was to test the effectiveness of three simple Naïve Bayes (NB) classifiers and provide the source code (as we did in the previous years) to promote failure analysis and comparison of results. 3  The contribution of our experiments to this task can be summarized as follows:</p><p>-A study of a reproducibility framework to explain each step of the pipeline from raw data to cleaned data; -An evaluation of three simple classifiers that use an optimization approach based on the two-dimensional representation of probabilistic models <ref type="bibr" coords="2,451.22,154.79,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,463.40,154.79,7.01,8.74">5]</ref>.</p><p>We submitted 3 official runs, one for each classifier, and we will prepare a number of additional non-official runs that we will evaluate and compare in order to study the change in performance when adding more information in the pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we summarize the pipeline we used in [6] that has been reproduced in this work for each run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pipeline for Data Cleaning</head><p>In order to produce a clean dataset, we followed the same pipeline for data ingestion and preparation for all the experiments. We used the tidytext [7] and SnowballC<ref type="foot" coords="2,181.02,349.05,3.97,6.12" target="#foot_0">4</ref> packages in R to read and stem words. The following code summarizes these steps: u n n e s t t o k e n s ( term , t e x t , token = " words " , s t r i p n u m e r i c = TRUE) %&gt;% mutate ( term = wordStem ( term , l a n g u a g e = " de " ) ) %&gt;% f i l t e r ( ! ( term %i n% c ( stopwords german , " t i e r " ) ) )</p><p>The %&gt;% symbol represents the usual "pipe" symbol (the output of a function step is the input of the next function). We used the "unnest tokens" function to split each text into words; then we stemmed each word with the German Snowball stemmer and filter out the list of stopwords provided by Jaques Savoy. <ref type="foot" coords="2,476.12,480.27,3.97,6.12" target="#foot_1">5</ref>We added the word "tier" ("animal" in German) to the list of stopwords since it is the most frequent word in the collection. We did not perform any acronym expansion/reduction, as we did in the previous years, and we did not perform any word decompounding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>We used three NB classifiers for the classification of documents. In particular, the three classifiers differ in the model (the mathematical description) of the distribution of documents and terms. We followed our previous work on the visualization of classifiers for hyper-parameters optimization <ref type="bibr" coords="2,389.48,614.77,9.96,8.74" target="#b1">[2]</ref>. The three models are: Multivariate Bernoulli model, Multinomial model, and Poisson model.</p><p>In the multivariate Bernoulli model, an object is a binary vector over the space of features:</p><formula xml:id="formula_0" coords="3,269.10,142.90,211.49,10.63">f k ∼ Bern(θ f k |c ) .<label>(1)</label></formula><p>where θ f k |c is the parameter of the Bernoulli variable of the k-th feature in the c class.</p><p>In the multinomial model we have one multinomial random variable which can take values over the set of features:</p><formula xml:id="formula_1" coords="3,213.50,218.00,262.85,9.96">o j ≡ (N 1,j , ..., N m,j ) ∼ M ultinomial(θ f |c ) . (<label>2</label></formula><formula xml:id="formula_2" coords="3,476.35,218.00,4.24,8.74">)</formula><p>where N k,j indicates the number of times feature f k appears in the object o j .</p><p>In the Poisson model, an object o j is generated by a multivariate Poisson random variable:</p><formula xml:id="formula_3" coords="3,267.26,275.40,213.33,9.96">N i,j ∼ Pois(θ fi|c ) .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>We submitted three official runs, one for each model. The goal of these experiments is to compare the effectiveness of the three classifiers and study the difference among them in a failure analysis (post experiments).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The dataset contains 8,793 documents: 7,544 documents for training, 842 for development, and 407 for testing. After we processed the training and development set, the number of features (words) after stemming and stopwords removal is 74,002. There are a total of 233 categories in the German Classification Diseases (ICD10) codes database. The training set contains 230 categories (categories H65-H75, R10-R19, and R20-R23 are missing), the development set contains 156 categories, while the test set 119 categories. Therefore, there are 112 categories that are in the training set but not in the test set and, surprisingly, one category, R10-R19, which is in the test set but not in the training set. Given this distribution of categories, we merged the training and the development set into one dataset that we used to train the classifiers with a k-fold cross validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Measures</head><p>In order to optimize the three models, we used the F1 measure for each binary classifier (one for each category). In this paper, we report the three measures used by the organizers, Recall, Precision and F1, both the macro-averaged measures (values averaged across all the categories) and the micro-averaged measures (as the sum of all the confusion matrices produced by each classifier). In the tables of the results, we use capital letters to indicate macro-averages (for example Recall) and small letters for micro-averages (for example recall). We report two macro-averaged F1 measures: one computed on the values of the macro-averaged Precision and Recall, the other (indicated with a '*' at superscript) computed as the average of the F1 measures. For those categories without positive documents (in the development or test set), by default we assign a recall of 1 and a precision of either 0 (when there is at least one false positive) or 1 (when no false positive is found for that category).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Official Runs</head><p>We used a k-fold cross validation approach to train the models and optimize the hyper-parameters of the two-dimensional approach (more details in the final version). We used all the training and development documents for the cross validation with k = 10, and we trained a binary classifier for each class in the corpus. Nine out of the ten folds have 838 documents while the latter has 844 documents; consequently, we have on average about 7,540 training documents and 840 validation documents. The average results across the 233 classes on the ten validation folds are the ones shown in Table <ref type="table" coords="4,226.20,548.19,3.87,8.74" target="#tab_0">1</ref>.</p><p>In Table <ref type="table" coords="4,189.74,560.48,3.87,8.74" target="#tab_1">2</ref>, we show the results of the classifiers that use the training set to estimate the probabilities and the development set for the evaluation (with or without the optimization of the decision line). We can see that these results are in line with the one reported during the k-fold cross validation approach with a slightly difference in the micro-averaged performance when the non-optimized version is used compared to the optimized one. This may indicate that there is some overfitting for those categories with too few training documents; in fact, even with just one positive training documents the algorithm tries to find the best fitting line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3. Test Macro-and micro-averaged results</head><p>Pre Rec Fscore Fscore * pre rec f1 bernoulli 0.530 0.578 0.553 0.226 0.010 0.001 0.001 multinomial 0.492 0.815 0.418 0.614 0.503 0.009 0.017 poisson 0.800 0.566 0.662 0.550 0.039 0.038 0.032</p><p>In Table <ref type="table" coords="5,190.37,217.10,3.87,8.74">3</ref>, we report the results on the test set. Surprisingly, the behavior of the classifier is completely different from the one we observed during the training/development phase. Macro-averaged measures are still satisfactory, but we have to remind that we introduced a correction in the computation of the recall for those categories without positive documents that may have affected (positively) the averages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Aftermath</head><p>We are currently analyzing possible sources of error in the test phase. One thing that seems evident from the analysis is that the distribution of probabilities of terms has changed from the development to the test set. We can observe this from a comparison of Figures <ref type="figure" coords="5,267.32,376.08,4.98,8.74">1</ref> and<ref type="figure" coords="5,295.53,376.08,3.87,8.74">2</ref>. These figures show the two-dimensional distribution ([5]) of positive and negative documents of the Poisson model for development set of category "II". The blue line indicates the decision taken by the classifier: below the line a document is assigned to category II, above the line the document is rejected. The red dots represent the positive documents. We can see that, in this case, the classifier performs well on the development set (a recall of 0.96 and a precision of 0.86) since almost all the positive documents are below the line. On the other hand, the same classifier performs very poorly on the test set (recall and precision both are zero). This is somewhat surprising since in both cases the development and test set contain unseen documents.</p><p>We are also studying whether this significant change in the position of the cloud of documents (corresponding to the probability of documents) is related to a different distribution of words in the test set or to a change in the vocabulary of terms in the test set.</p><p>There is also a chance in some bug in the source code that we were not able to find until now.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, we presented our participation to the CLEF eHealth Task 1 on the classification of medical documents. We presented the evaluation of three probabilistic classifiers based on different assumptions on the distribution of words, namely binary, multinomial and Poisson. We described a method to process the </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,134.77,349.79,345.82,7.89;6,134.77,360.77,264.60,7.86"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Poisson model development set. Distribution of positive (red) and negative (black) documents for the category II. The blue line indicates the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,170.94,115.91,273.49,62.34"><head>Table 1 .</head><label>1</label><figDesc>K-fold cross validation Macro-and micro-averaged results</figDesc><table coords="4,200.26,134.54,214.85,43.70"><row><cell>Pre Rec F1 F1  *  pre rec</cell><cell>f1</cell></row><row><cell cols="2">bernoulli 0.247 0.786 0.375 0.271 0.135 0.628 0.223</cell></row><row><cell cols="2">multinomial 0.204 0.618 0.307 0.204 0.171 0.642 0.270</cell></row><row><cell cols="2">poisson 0.727 0.542 0.621 0.468 0.393 0.726 0.510</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,145.84,202.96,323.68,110.26"><head>Table 2 .</head><label>2</label><figDesc>Development Macro-and micro-averaged results (w/out optimization)</figDesc><table coords="4,195.78,222.09,223.81,91.12"><row><cell>optimized</cell><cell>Pre Rec F1 F1  *  pre rec</cell><cell>f1</cell></row><row><cell>bernoulli</cell><cell cols="2">0.275 0.666 0.389 0.281 0.111 0.496 0.181</cell></row><row><cell cols="3">multinomial 0.200 0.546 0.293 0.206 0.125 0.520 0.202</cell></row><row><cell>poisson</cell><cell cols="2">0.764 0.609 0.678 0.543 0.408 0.815 0.418</cell></row><row><cell>non-optimized</cell><cell></cell><cell></cell></row><row><cell>bernoulli</cell><cell cols="2">0.220 0.723 0.337 0.258 0.777 0.201 0.320</cell></row><row><cell cols="3">multinomial 0.191 0.454 0.269 0.175 0.480 0.365 0.415</cell></row><row><cell>poisson</cell><cell cols="2">0.764 0.609 0.678 0.543 0.408 0.815 0.418</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,646.48,282.93,7.47"><p>https://cran.r-project.org/web/packages/SnowballC/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="2,144.73,657.44,202.42,7.47"><p>http://members.unine.ch/jacques.savoy/clef/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,515.43,342.24,7.86;6,146.91,526.39,333.67,7.86;6,146.91,537.35,333.68,7.86;6,146.91,548.31,227.76,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,226.25,526.39,254.33,7.86;6,146.91,537.35,127.47,7.86">Clef ehealth 2019 multilingual information extraction -semantic indexing of animal experiments</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Butzke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antje</forename><surname>Dötendahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nora</forename><surname>Leich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Grune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilber</forename><surname>Schönfelder</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,298.05,537.35,182.54,7.86;6,146.91,548.31,88.62,7.86">CLEF 2019 Evaluation Labs and Workshop: Online Working Notes</title>
		<imprint>
			<date type="published" when="2019-09">September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,558.90,342.24,7.86;6,146.91,569.86,333.68,7.86;6,146.91,580.82,329.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,360.96,558.90,119.63,7.86;6,146.91,569.86,245.19,7.86">Picturing bayesian classifiers: A visual data mining approach to parameters optimization</title>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,235.77,580.82,131.83,7.86">Data Mining Applications with R</title>
		<editor>
			<persName><forename type="first">Yanchang</forename><surname>Zhao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yonghua</forename><surname>Cen</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>chapter 2</note>
</biblStruct>

<biblStruct coords="6,138.35,591.41,342.24,7.86;6,146.91,602.37,333.68,7.86;6,146.91,613.33,333.67,7.86;6,146.91,624.29,333.67,7.86;6,146.91,635.25,175.56,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,215.27,613.33,189.43,7.86">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rene</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jimmy</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joao</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,433.55,613.33,47.03,7.86;6,146.91,624.29,213.49,7.86">CLEF 2019 -10th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="6,368.73,624.29,111.86,7.86;6,146.91,635.25,56.67,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">2019. September 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,645.84,342.25,7.86;6,146.91,656.80,219.57,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,260.90,645.84,219.69,7.86;6,146.91,656.80,36.77,7.86">A new decision to take for cost-sensitive naïve bayes classifiers</title>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Di</forename><surname>Nunzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,191.11,656.80,85.29,7.86">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="653" to="674" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
