<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.70,115.96,257.97,12.62;1,179.66,133.89,256.03,12.62">Overview of the CLEF eHealth 2019 Multilingual Information Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,148.28,171.59,64.84,8.74"><forename type="first">Mariana</forename><surname>Neves</surname></persName>
							<email>mariana.lara-neves@bfr.bund.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.90,171.59,61.72,8.74"><forename type="first">Daniel</forename><surname>Butzke</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,150.16,183.55,72.67,8.74"><forename type="first">Antje</forename><surname>Dörendahl</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,233.39,183.55,47.77,8.74"><forename type="first">Nora</forename><surname>Leich</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.71,183.55,79.01,8.74"><forename type="first">Benedikt</forename><surname>Hummel</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.11,195.50,84.53,8.74"><forename type="first">Gilbert</forename><surname>Schönfelder</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Clinical Pharmacology and Toxicology</orgName>
								<orgName type="institution">Charité -Universitätsmedizin Berlin</orgName>
								<address>
									<addrLine>Charitéplatz 1</addrLine>
									<postCode>10117</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.91,195.50,65.88,8.74"><forename type="first">Barbara</forename><surname>Grune</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Centre for the Protection of Laboratory Animals (Bf3R)</orgName>
								<orgName type="institution">German Federal Institute for Risk Assessment (BfR)</orgName>
								<address>
									<addrLine>Diedersdorfer Weg 1</addrLine>
									<postCode>12277</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.70,115.96,257.97,12.62;1,179.66,133.89,256.03,12.62">Overview of the CLEF eHealth 2019 Multilingual Information Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B251326195586454E182211E30A5094</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Document indexing</term>
					<term>ICD-10 codes</term>
					<term>summaries of animal experiments</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Non-technical summaries (NTSs) of animal experimentation can be valuable resources to foster more transparency of research made with animals and to better inform the community about this topic. The NTSs of planned animal experiments in Germany are publicly available and have been manually assigned to ICD-10 codes. We used this data in the scope of organizing the Multilingual Information Extraction Task (Task 1) in the CLEF eHealth challenge. For the development phase, we released a training dataset containing more than 8,000 NTSs and their corresponding codes (if any assigned). For the test phase, we released 407 unseen NTSs for which the participants should submit the predictions made by their systems. The best performing system obtained a P, R, and FM of 0.83, 0.77, and 0.80, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Non-technical summaries (NTSs) are short descriptions of the planned animal experiments to be carried out in a country and are stipulated when requesting permission for the experiment. The European Union (EU) requires the member states to collect these summaries and to make them available to the community in order to foster more transparency in animal research <ref type="bibr" coords="1,368.35,582.55,14.61,8.74" target="#b11">[12]</ref>. The German Federal Institute for Risk Assessment (BfR, in its acronym in German) publishes the German NTSs online in the AnimalTestInfo database 3 . These NTSs are regularly manually annotated with ICD-10 codes for the identification of the diseases that are the focus of the planned experiments. Indexing the NTSs using terms from standard teminologies provides additional information on the research goals of the animal experiments and supports a detailed analysis of the data. <ref type="bibr" coords="2,263.83,166.81,9.96,8.74" target="#b2">[3]</ref>.</p><p>We utilized our annotated NTSs in the scope of a shared task in the CLEF eHealh challenge. Our shared task aimed to evaluate systems for the automatic detection of the ICD-10 codes in German NTSs <ref type="foot" coords="2,334.96,201.76,3.97,6.12" target="#foot_0">4</ref> . For this purpose, we utilized the manually annotated data for building training, development, and test datasets, which were to be used by the participants in the shared task. Previous editions of CLEF eHealth addressed similar tasks, such as the extraction of ICD-10 codes in death certificates for English and French <ref type="bibr" coords="2,321.25,251.16,9.96,8.74" target="#b7">[8]</ref>, and the following year for French, Italian, and Hungarian <ref type="bibr" coords="2,237.74,263.11,9.96,8.74" target="#b8">[9]</ref>.</p><p>The remainder of the paper is structured as follows: we describe details of the shared task in Section 2 and the participating teams and systems in Section 3. We presented the baselines that we developed in Section 4 and the results obtained by participants and baselines in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Details of the Shared Task</head><p>In this section we describe details of the challenge, including the schedule of the event, the data that we released, and the evaluation that we carried out.</p><p>Schedule. We released the training data, which is split into a training and development datasets, to the participants on February 1st, 2019. During three months, the participants could utilize this data for training, tuning, and evaluating their system. We released the official test set on May 6th, 2019. The participants had one week to process the test data and prepare the submissions files, that had to be uploaded in to the submission system until May 13th, 2019. Each team was allowed to submit up to three runs for their systems, i.e., different configurations or approaches that they experimented during the development period. Manual (human-annotated) approaches were not allowed in the shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data.</head><p>Our training data consisted of a set of 8,386 manually annotated NTSs which was split into two datasets: 7,544 NTSs for the training dataset and 842 NTSs for the development dataset. For the test set, we released a collection of 407 unseen NTSs, i.e., which were not included in the training data. Each NTS is divided in six sections, namely, title, objectives, benefits, harms, replacement, reduction and refinement.</p><p>Evaluation. We evaluated the predictions returned by the participating systems based on an automatic and a manual approach. We automatically evaluated the submissions based on the standard metrics of precision (P), recall (R) and fmeasure (FM). We utilized the Python script that we released to the participants during the shared task. <ref type="foot" coords="3,261.80,141.33,3.97,6.12" target="#foot_1">5</ref> For the manual validation, one of our annotators manually checked a total of 100 NTSs originated from false positives (FPs) and false negatives (FNs) returned by the best runs. We randomly selected 25 FPs and FNs from the best run of the two best-scoring teams, thus a total of 100 NTSs. During the manual validation, our expert checked whether the wrong predictions (FP or FN) were indeed false.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Teams and systems</head><p>We received 14 submissions from six teams originated from a total of six countries, as summarized in Table <ref type="table" coords="3,266.75,278.25,3.87,8.74" target="#tab_0">1</ref>. We present a summary of each team and their systems below. DEMIR <ref type="bibr" coords="3,172.54,462.57,10.69,8.74" target="#b0">[1]</ref>. The DEMIR team developed an approach based on two phases. In the first phase, they utilized the Elasticsearch tool to perform k-Nearest Neighbor (kNN) and threshold-Nearest Neighbor (tNN). In the second phase, the codes were selected from the top ones using two majority voting approaches based on either the pre-defined top M codes or on the similarity scores of the corresponding NTSs. The team submitted three runs, namely, k-NN based on k=5 and M=2 (run1), tNN based on T=30 and M=3 (run2), and tNN based on T=80 and adaptive M.</p><p>IMS-UNIPD <ref type="bibr" coords="3,194.20,574.08,10.69,8.74" target="#b4">[5]</ref>. The IMS-UNIPD team experimented with three probabilistic Naïve Bayes (NB) classifiers, following the same approach that they used in previous editions of the Multilingual Information Extraction Task in CLEF eHealth. All models were based on a two-dimensional representation of probabilities. They submitted three runs based on the three NB classifiers, namely, Bernoulli (run1), Multinomial (run2) and Poisson (run3).</p><p>MLT-DFKI <ref type="bibr" coords="4,189.89,118.99,10.69,8.74" target="#b1">[2]</ref>. The MLT-DFKI team tried a variety of approaches, such as Conditional Neural Networks (CNN) and Attention models, which that usually used for Neural Machine Translation (NMT), among others. They obtained the best results when relying on Bidirectional Encoder Representations from Transformers (BERT) and, more specifically, on BioBERT which was trained on biomedical documents <ref type="bibr" coords="4,247.81,178.77,9.96,8.74" target="#b6">[7]</ref>. For using this approach, which is available for the English language, the team had to first automatically translate the NTSs using the Google Translate API. The team only submitted one run.</p><p>SSN-NLP <ref type="bibr" coords="4,181.81,226.32,10.69,8.74" target="#b5">[6]</ref>. The SSN-NLP team developed a multi-layer Recurrent Neural Network (RNN) with a Long Short Term Memory (LSTM) as recurrent unit.</p><p>They experimented with two attention mechanisms, namely Normed Bahdanau (NB) and Scaled Luong (SL), and with the requirement of a minimum number of occurrences of a code as generated by the model. They submitted three runs, namely, NB attention and minimum two occurrences (run1), SL attention and minimum of two occurrences (run2), and SL attention, minimum 2 occurrences and all codes if no code is repeated more than once (run3).</p><p>TALP UPC. The TALP-UPC team developed a simple semi-supervised system based on Machine Translation and Named Entity Recognition (NER). In a first step, the "Benefits" section was translated into English using the Amazon Translate API <ref type="foot" coords="4,197.22,367.93,3.97,6.12" target="#foot_2">6</ref> . For NER, they used MetaMap<ref type="foot" coords="4,343.15,367.93,3.97,6.12" target="#foot_3">7</ref> (online batch submission system) and considered only the ICD-10 vocabulary source. After the identification of the entities (codes), their parents in the ICD-10 hierarchy were also selected to the prediction list.</p><p>WBI <ref type="bibr" coords="4,159.82,429.01,15.48,8.74" target="#b10">[11]</ref>. The WBI team utilized a multilingual BERT text encoding model <ref type="bibr" coords="4,134.77,440.96,10.52,8.74" target="#b3">[4]</ref> and additional training data of German clinical trials<ref type="foot" coords="4,384.93,439.39,3.97,6.12" target="#foot_4">8</ref> also annotated with ICD-10 codes. They also experimented with training various instances of the models and ensembling the predictions based on their average or on a logistic regression classifier. The team submitted three runs, namely, BERT multi-label (run1), ensemble based on the average (run2), and an ensemble based on logistic regression (run3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline Approaches</head><p>We developed some baselines systems to compare the results from the participants to a simple text classification approach. The automatic classification of NTSs according to the ICD-10 codes consists of a multi-class and multi-label problem. It is multi-class because the ICD-10-GM-2016 ontology contains a total of 270 (until level4) that could potentially be assigned to an NTS, while it is multi-label because more than one code can be assigned to a each NTS.</p><p>We considered only supervised learning approach based on our training data, i.e. codes that do not appear in the training data cannot be identified by our baseline approaches. Given it is a multi-label problem, during the training phase and for the training dataset, one classifier is trained for each of the 270 codes (if training data is available). During the test phase, for the development and test datasets, and for each NTS, each of the above classifier is used for deciding regarding the assignment of the corresponding code to the summary. All documents were pre-processed using the standard tokenization and TF-IDF functionality available in the Python scikitlearn library <ref type="foot" coords="5,360.03,213.06,3.97,6.12" target="#foot_5">9</ref> . We considered two types of experiments, one using all sections of the summaries, and one using only only the title and the benefits sections.</p><p>We followed the approaches based on Support Vector Machine (SVM) that was previously utilized for the MIMIC II dataset <ref type="bibr" coords="5,360.02,263.55,14.61,8.74" target="#b9">[10]</ref>. The authors proposed flat and hierarchical SVMs in which the hierarchical structure of the ICD-10 terminology is considered in the latter. Both SVM algorithms were based on the SVM implementation available in the Python scikitlearn library and the differences between the two approaches are described below.</p><p>Flat This approach does not make use of the hierarchical structure of the terminology neither when building the classifiers nor when classifying the NTSs from the test set. For the flat SVM approach, we built one classifier for each code based on the totality of the summaries in the training dataset, i.e. for each code, the positive training examples were the NTSs that contained the particular code, while the negative examples were all NTSs that did not contain the code. Therefore, the classifiers were trained on a very unbalanced data for those codes that occur very seldom in our training data.</p><p>Hierarchical In this approach, we consider the four levels of the hierarchy of the ICD-10 ontology, as considered in our manual annotations of the NTSs. The classifiers related to codes on level 1 were trained on the whole training data, in which the positive examples were the ones that contained the particular code and the negative examples were the one that did not contain the code. Therefore, the classifier for level 1 are not different from the ones built in the flat approach for these same codes. As for next levels, the classifier for a particular code was only trained on the NTSs which belonged to the corresponding parent code. For instance, the classifier for code C00-C97 (level 2) was trained on all NTSs that were assigned to chapter II. The positive examples were the one assigned to code C00-C97, while the negative examples were the all the others assigned to chapter II but not to C00-C97, for instance, those that belong to the other codes in this chapter, such as D00-D09, D10-D36 or D37-D48. Therefore, each classifier has a different number of training examples, but a more balanced one with regard to the proportion of positive and negative examples, in comparison to the flat approach.</p><p>Table <ref type="table" coords="6,163.34,115.91,4.13,7.89">2</ref>. List of the results for baselines and submitted runs. All results are presented in descending order of the scores for f-measure, precision and recall. We highlight in bold the highest values for f-measure, precision and recall. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team and Runs TPs FPs FNs Precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section we present the results obtained by the runs submitted by the participating teams and by our baseline systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Evaluation</head><p>Table <ref type="table" coords="6,162.99,476.79,4.98,8.74">2</ref> summarizes the results for all runs and baselines. Details for all runs are described in Section 1. Regarding the baselines systems, we evaluated both approaches (flat and hierarchical) and using the whole text of the NTS (All) or just the title and benefits (TB) sections.</p><p>The results for all metrics varied considerably, ranging from null to up to more than 0.80. The best scores were the following, 0.8 of f.measure from the WBI (run1) team, 0.86 of recall for the MLT-DFKI team, and 0.98 of precision of two of our baselines. Excepted for our baseline systems, results for precision, recall and f-measure were quite balanced for all runs. In contrast to these, our baselines obtained a much higher precision (above 0.9) over the recall (around 0.2-0.3).</p><p>As expected, the current state-of-the-art approach for many natural language processing (NLP) tasks, i.e. BERT, obtained the best performance in the runs submitted by teams WBI and MLT-DFKI. However, other machine learning approaches, e.g. kNN and tNN from team DEMIR, could outperform the deep learning approaches proposed by team SSN NLP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Manual Evaluation</head><p>As described in Section 2, one expert manually validated a random sample of 100 FPs and FNs from the best runs from the two best-scoring teams, namely, run1 from WBI and the only run submitted by team MLT-DFKI. The FNs and FPs were automatically detected by our evaluation script (cf. Section 2) with regards to our gold standard test set. We provide a discussion below about the errors in our gold standards that we found.</p><p>FNs. From the 25 NTSs from run1 of the WBI team, our expert found seven NTSs in which a total of 14 FNs codes were wrong (cf. Table <ref type="table" coords="7,415.51,374.59,3.87,8.74" target="#tab_2">3</ref>). These were not codes missed by the run, but rather codes that were mistakenly assigned to the NTSs in our gold standard. The same seven NTSs also contained 12 wrong FNs codes detected for the run from team MLT-DFKI. Curiously, even though we randomly selected the FNs codes, both runs had practically the same FNs codes from the same seven NTSs.</p><p>FPs. From the 25 NTSs from run1 of the WBI team, our expert found 12 NTSs in which a total of 22 FPs codes were wrong (cf. Table <ref type="table" coords="7,387.55,469.76,3.87,8.74" target="#tab_3">4</ref>). These were codes that the expert judged as correct but that were not originally included in our gold standard. For the run from team MLT-DFKI, our expert judged as correct predictions just nine codes from four NTSs, from the total of 25 NTSs that were manually evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We presented the first corpus of non-technical summaries (NTS) of animal experiments for the German language. We annotated the NTS with the ICD-10 codes and utilized the data in the scope of a shared task in the CLEF eHealth challenge. Runs from two of the participants obtained results above 0.80 of fmeasure and outperformed our baseline systems. The results obtained by the participants show that automatizing this task is indeed feasible, for instance, for the development of a semi-automatic system to support the experts in the manual annotation of the NTSs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,136.16,323.27,341.19,94.81"><head>Table 1 .</head><label>1</label><figDesc>List of participating teams.</figDesc><table coords="3,136.16,344.07,96.26,7.86"><row><cell>Team</cell><cell>Institution</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,115.91,345.82,116.73"><head>Table 3 .</head><label>3</label><figDesc>List of the identified FNs which were validated as incorrect, i.e., they have not been missed by the systems.</figDesc><table coords="7,183.78,147.64,247.80,85.00"><row><cell cols="2">NTS identifier WBI run1</cell><cell>MLT-DFKI</cell></row><row><cell>19568</cell><cell>H55-H59</cell><cell>H55-H59</cell></row><row><cell>19663</cell><cell>J40-J47, J80-J84</cell><cell>J40-J47</cell></row><row><cell>19776</cell><cell>R10-R19, XVIII</cell><cell>R10-R19</cell></row><row><cell>21184</cell><cell cols="2">C76-C80, C00-C97, II C76-C80, C00-C97, II</cell></row><row><cell>21802</cell><cell>P05-P08, XVI</cell><cell>P05-P08, XVI</cell></row><row><cell>21953</cell><cell>X, J09-J18</cell><cell>X, J09-J18</cell></row><row><cell>21969</cell><cell>T80-T88, XIX</cell><cell>T80-T88, XIX</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,115.91,345.83,182.48"><head>Table 4 .</head><label>4</label><figDesc>List of the identified FPs which were validated as incorrect, i.e., they are indeed correct predictions from the systems.</figDesc><table coords="8,143.33,147.64,328.69,150.75"><row><cell cols="2">NTS identifier WBI run1</cell><cell>MLT-DFKI</cell></row><row><cell>18805</cell><cell>F10-F19, V</cell><cell></cell></row><row><cell>19776</cell><cell>N80-N98, XIV</cell><cell>N80-N98, XIV</cell></row><row><cell>21969</cell><cell cols="2">C00-C75, C00-C97, C50-C50, II C00-C75, C00-C97, C50-C50, II</cell></row><row><cell>20906</cell><cell>XXI, Z80-Z99</cell><cell></cell></row><row><cell>16241</cell><cell>C76-C80</cell><cell></cell></row><row><cell>21953</cell><cell>N17-N19, XIV</cell><cell>N17-N19, XIV</cell></row><row><cell>19599</cell><cell>XIX</cell><cell></cell></row><row><cell>20619</cell><cell>C00-C75, C15-C26</cell><cell></cell></row><row><cell>17716</cell><cell>C76-C80</cell><cell></cell></row><row><cell>17108</cell><cell>D80-D90, III</cell><cell></cell></row><row><cell>18865</cell><cell>I10-I15</cell><cell></cell></row><row><cell>22344</cell><cell>C00-C75, C60-C63</cell><cell></cell></row><row><cell>18318</cell><cell></cell><cell>C76-C80</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,656.80,215.89,8.12"><p>Task 1: https://clefehealth.imag.fr/?page_id=26</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,657.44,240.57,7.47"><p>https://github.com/mariananeves/clef19ehealth-task1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,144.73,635.53,155.34,7.47"><p>https://aws.amazon.com/translate/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="4,144.73,646.48,131.81,7.47"><p>https://metamap.nlm.nih.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="4,144.73,656.80,158.29,8.12"><p>from https://www.drks.de/drks_web/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="5,144.73,657.44,151.13,7.47"><p>https://scikit-learn.org/stable/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>We would like to thank all participants for their interest in our task, and <rs type="person">Felipe Soares</rs> for providing a description of his team's system. We would like to acknowledge the <rs type="institution">Australian National University</rs> for supporting the submission Web site in EasyChair.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,430.51,337.64,7.86;8,151.52,441.47,329.07,7.86;8,151.52,452.43,95.81,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,310.51,430.51,106.85,7.86">DEMIR at CLEF eHealth</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arıbaş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alpkocak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,445.76,430.51,34.83,7.86;8,151.52,441.47,280.96,7.86;8,455.89,441.47,24.70,7.86;8,151.52,452.43,67.14,7.86">Information Retrieval based Classification of Animal Experiment Summaries</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF (Working Notes)</note>
</biblStruct>

<biblStruct coords="8,142.96,462.75,337.64,7.86;8,151.52,473.71,329.07,7.86;8,151.52,484.67,189.75,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,151.52,473.71,329.07,7.86;8,151.52,484.67,43.41,7.86">MLT-DFKI at CLEF eHealth 2019: Multi-label Classification of ICD-10 Codes with BERT</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dunfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vechkaeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wixted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,217.69,484.67,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,494.98,337.63,7.86;8,151.52,505.94,329.07,7.86;8,151.52,516.90,329.07,7.86;8,151.52,527.83,329.07,7.89;8,151.52,539.46,207.12,7.47" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,315.10,505.94,165.49,7.86;8,151.52,516.90,297.80,7.86">Rethinking 3r strategies: Digging deeper into AnimalTestInfo promotes transparency in in vivo biomedical research</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dörendahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Leich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vietze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steinfath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chmielewska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hensel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Schönfelder</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pbio.2003217</idno>
		<ptr target="https://doi.org/10.1371/journal.pbio.2003217" />
	</analytic>
	<monogr>
		<title level="j" coord="8,456.28,516.90,24.32,7.86;8,151.52,527.86,30.33,7.86">PLOS Biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2017">12 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,549.14,337.63,7.86;8,151.52,560.07,329.07,7.89;8,151.52,571.70,145.93,7.47" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,338.64,549.14,141.95,7.86;8,151.52,560.09,189.90,7.86">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR abs/1810.04805</idno>
		<ptr target="http://arxiv.org/abs/1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,581.37,337.64,7.86;8,151.52,592.33,291.94,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,227.48,581.37,248.85,7.86">Classification of Animal Experiments: A Reproducible Study</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M</forename><surname>Di Nunzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,592.33,147.63,7.86;8,319.88,592.33,94.91,7.86">IMS Unipd at CLEF eHealth Task 1</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>CLEF (Working Notes)</note>
</biblStruct>

<biblStruct coords="8,142.96,602.65,337.64,7.86;8,151.52,613.60,329.07,7.86;8,151.52,624.56,95.81,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,336.34,602.65,144.26,7.86;8,151.52,613.60,281.68,7.86">Deep Learning Approach for Semantic Indexing of Animal Experiments Summaries in German Language</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kayalvizhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Thenmozhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Aravindan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,455.89,613.60,24.70,7.86;8,151.52,624.56,67.14,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,634.88,337.63,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.77,279.37,8.14" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,438.58,634.88,42.01,7.86;8,151.52,645.84,324.76,7.86">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno>CoRR abs/1901.08746</idno>
		<ptr target="http://arxiv.org/abs/1901.08746" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,119.67,337.64,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.59,329.07,7.86;9,151.52,152.55,308.54,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,278.61,130.63,201.98,7.86;9,151.52,141.59,324.85,7.86">CLEF eHealth 2017 multilingual information extraction task overview: ICD10 coding of death certificates in English and French</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">N</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,165.60,152.55,151.82,7.86">Proc of CLEF eHealth Evaluation lab</title>
		<meeting>of CLEF eHealth Evaluation lab<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,163.51,337.64,7.86;9,151.52,174.47,329.07,7.86;9,151.52,185.43,329.07,7.86;9,151.52,196.39,329.07,7.86;9,151.52,207.34,22.02,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,277.75,174.47,202.84,7.86;9,151.52,185.43,329.07,7.86;9,151.52,196.39,42.42,7.86">CLEF eHealth 2018 Multilingual Information Extraction Task Overview: ICD10 Coding of Death Certificates in French, Hungarian and Italian</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Grippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Morgand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pelikan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,213.09,196.39,147.78,7.86">Proc of CLEF eHealth Evaluation lab</title>
		<meeting>of CLEF eHealth Evaluation lab<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">September 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,218.30,337.97,7.86;9,151.52,229.26,329.07,7.86;9,151.52,240.20,329.07,7.89;9,151.52,251.18,329.07,8.12;9,151.52,262.79,113.97,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,208.32,229.26,268.29,7.86">Diagnosis code assignment: models and evaluation metrics</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Perotte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pivovarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
		<idno type="DOI">10.1136/amiajnl-2013-002159</idno>
		<ptr target="http://dx.doi.org/10.1136/amiajnl-2013-002159" />
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,240.22,257.04,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="237" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,273.10,337.98,7.86;9,151.52,284.06,329.07,7.86;9,151.52,295.02,123.58,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,348.65,273.10,131.94,7.86;9,151.52,284.06,311.48,7.86">Classifying German Animal Experiment Summaries with Multi-lingual BERT at CLEF eHealth 2019 Task 1</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sänger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kittner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,295.02,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,305.98,337.98,7.86;9,151.52,316.93,329.07,7.86;9,151.52,327.87,329.07,7.89;9,151.52,339.50,249.49,7.47" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,297.13,305.98,183.46,7.86;9,151.52,316.93,173.19,7.86">Recommendations to improve the EU nontechnical summaries of animal experiments</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.14573/altex.1708111</idno>
		<ptr target="https://www.altex.org/index.php/altex/article/view/90" />
	</analytic>
	<monogr>
		<title level="j" coord="9,332.38,316.93,148.22,7.86;9,151.52,327.89,56.35,7.86">ALTEX -Alternatives to animal experimentation</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="210" />
			<date type="published" when="2018-04">Apr 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
