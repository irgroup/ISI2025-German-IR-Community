<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.67,116.95,340.01,12.62">Query Expansion using Wikipedia and DBpedia</title>
				<funder ref="#_2jhKVPh">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_tkd6zyW">
					<orgName type="full">Science Foundation Ireland</orgName>
				</funder>
				<funder ref="#_6CrUt4E">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,229.31,154.86,70.66,8.74"><forename type="first">Nitish</forename><surname>Aggarwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Digital Enterprise Research Institute</orgName>
								<orgName type="laboratory">Unit for Natural Language Processing</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.65,154.86,63.41,8.74"><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Digital Enterprise Research Institute</orgName>
								<orgName type="laboratory">Unit for Natural Language Processing</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.67,116.95,340.01,12.62">Query Expansion using Wikipedia and DBpedia</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2561A74818E8D80765B7C58C0B1C74B7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Query Expansion</term>
					<term>Explicit Semantic Analysis</term>
					<term>ESA ranking</term>
					<term>Wikipedia and DBpedia</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our query expansion approach submitted for the Semantic Enrichment task in Cultural Heritage in CLEF (CHiC) 2012. Our approach makes use of an external knowledge base such as Wikipedia and DBpedia. It consists of two major steps, concept candidates generation from knowledge bases and the selection of K-best related concepts. For selecting the K-best concepts, we ranked them according to their semantic relatedness with the query. We used Wikipedia-based Explicit Semantic Analysis to calculate the semantic relatedness scores. We evaluate our approach on 25 queries from the CHiC Semantic Enrichment dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the enormous amount of information emerging on the Web, the gap between vocabularies used in indexed documents and user queries has been increased. To fill this gap, many query expansion methods such as dictionary-based query expansion <ref type="bibr" coords="1,208.88,477.79,9.96,8.74" target="#b3">[4]</ref>, and knowledge-based <ref type="bibr" coords="1,320.96,477.79,10.52,8.74" target="#b1">[2]</ref> query expansion, have been studied. The query expansion task can be defined by semantic enrichment of a query with its semantically related concepts. With these complementary concepts, additional relevant documents, which may not contain the keywords provided in that query, can be retrieved. For instance, a given query "Hiroshima"can retrieve documents where the keyword Hiroshima directly appears but not the documents, that only contain related concepts such as atomic bomb, Nagasaki or Etajima.</p><p>One possible semantic enrichment of a query can be achieved by using the Wikipedia or DBpedia. Wikipedia is a freely available large knowledge resource built by a collaborative effort of voluntary contributors. DBpedia <ref type="bibr" coords="1,430.18,609.29,10.52,8.74" target="#b2">[3]</ref> contains a large ontology describing more than 3.5 millions instances extracted from the Wikipedia info-boxes. Also, it is connected to several other linked data repositories on the Semantic Web. Therefore, our approach uses Wikipedia to retrieve the K-best related concepts to the query. We use Wikipedia and DBpedia to generate the concept candidates, and then rank them according to the semantic relatedness score given by the Wikipedia-based Explicit Semantic Analysis (ESA) <ref type="bibr" coords="2,166.20,143.90,9.96,8.74" target="#b5">[6]</ref>. ESA is an approach that calculates the semantic relatedness scores between words or phrases, and uses them to augment ranking functions. Egozi et. al. <ref type="bibr" coords="2,163.04,167.81,10.52,8.74" target="#b4">[5]</ref> used the ESA to rank the documents. Our approach takes inspiration from the same to rank all concept candidates.</p><p>In this work, we present an approach for semantic enrichment of queries using Wikipedia, DBpedia, and ESA based ranking. The rest of this paper is organized as follows: Section 2 describes our approach in detail; Section 3 explains our four different submitted runs for the semantic enrichment task; Section 4 shows the results; and finally we conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>Our approach consists of two major steps; concept candidates generation from Wikipedia and DBpedia, and selection of K-best concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Concept candidate generation</head><p>The concept candidates are the titles of Wikipedia articles, which are relevant to the given query. To retrieve these concept candidates, we search all of the Wikipedia articles with the given query, and sort them according to their TFIDF scores. Among the retrieved articles the N best articles are selected as concept candidates. Then, we find all the directly connected Wikipedia articles to the top ranked article from the N selected candidates, in the DBpedia graph. For example, for a given query "Hiroshima", we retrieve 260 different Wikipedia articles, such as "Atomic bombings of Hiroshima and Nagasaki", "Mazda Stadium", and "Nagasaki". With the intuition that the concepts containing similar strings may not provide the additional relevant documents, we exclude those concept candidates, which have a low edit distance to the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">ESA ranking</head><p>ESA attempts to represent the semantics of the given term in the high distributional semantic space. These semantics are obtained by use of a high dimensional vector, where each dimension reflects a unique Wikipedia concept. This high dimensional vector is created by taking the TF-IDF weight of a given term in the corresponding Wikipedia articles. Semantic relatedness of two given terms can be obtained by calculating the correlation between two high dimensional vectors generated by ESA. We used the ESA implementation described in <ref type="bibr" coords="2,426.89,609.29,9.96,8.74" target="#b0">[1]</ref>.</p><p>We calculate the ESA relatedness score between the query, and each of the concept candidates. Then we select the K-best concepts according to their ESA scores.</p><p>We submitted four different runs in the semantic enrichment task at CHiC. All of these runs are based on the approach described in Section 2. They use different threshold of edit distance to eliminate the concept candidates. The values of N and K are taken as 20 and 10 respectively. Run1 excludes those concept candidates, that contain the query string as a substring. For example, for a given query "Hiroshima", we eliminate all the concept candidates such as "Hiroshima Prefecture", "Hiroshima Station", and "Hiroshima University", as they contain "Hiroshima" as a substring. Run2 and run3 exclude those concept candidates, that have token distance greater than 0.5, and 0.0 respectively. Run4 is the baseline, and does not perform the elimination step. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>All of these runs are evaluated in two different phases: manually, and by using a query expansion experiment with a standard IR system. All of the suggested concepts are assessed manually for use in an interactive query expansion environment to check if these suggestions make sense with respect to the original query. These manual relevance assessment measures are on a three point scale: definitely relevant, maybe relevant, and not relevant. Table <ref type="table" coords="3,399.53,621.25,4.98,8.74" target="#tab_0">1</ref> shows the scores of weak precision and strong precision. Strong precision is the average precision over 25 queries of the "definitely relevant" suggestions, and weak precision is the average precision of the "definitely relevant", and "maybe relevant", over all In order to evaluate the approach in a query expansion environment, all of the suggestions are used as additional terms to the query. With these enriched queries, the results are assessed according to the ad-hoc retrieval standards. Then, the average precision and recall are calculated. In Table <ref type="table" coords="4,410.68,465.70,3.87,8.74" target="#tab_1">2</ref>, we report the Mean Average Precision (MAP) of all the runs. Run1 performs the best, suggesting that concepts may not improve the results over the original query if they contain the query as a substring. For instance, for a given query "Hiroshima", the suggestion "Hiroshima University" may not help to find the relevant documents, that cannot be found by the query "Hiroshima". Figure <ref type="figure" coords="4,427.99,525.47,4.98,8.74">2</ref> shows the mean interpolated precision scores against different recall values, and Figure <ref type="figure" coords="4,475.61,537.43,4.98,8.74" target="#fig_0">1</ref> shows the retrieved documents vs. mean precision, for all of the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We presented our approach for query expansion, which includes concept candidates generation from Wikipedia and DBpedia, and the selection of K-best concepts according to the ESA scores. The approach reached high precision according to the manual relevance assessment evaluation, meaning that most of the suggestions make sense in query expansion. Also, it raises the future direction of Fig. <ref type="figure" coords="5,179.72,371.38,4.13,7.89">2</ref>. Standard recall vs. mean interpolated precision for all of the runs query expansion by using Wikipedia and DBpedia. Therefore, we are planning to investigate this approach with different ranking methods, and by taking more Wikipedia features, such as Wikipedia link and category structure, into account.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,174.35,371.37,266.65,7.89;4,138.15,120.22,340.15,226.76"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Retrieved documents vs. mean precision for all of the runs</figDesc><graphic coords="4,138.15,120.22,340.15,226.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="5,138.15,120.22,340.16,226.77"><head></head><label></label><figDesc></figDesc><graphic coords="5,138.15,120.22,340.16,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,165.52,285.87,284.32,172.99"><head>Table 1 .</head><label>1</label><figDesc>Weak and strong precision of manual relevance assessment</figDesc><table coords="3,165.52,285.87,284.32,172.99"><row><cell>Run Type</cell><cell cols="3">Weak Precision Strong Precision</cell></row><row><cell>DERI SE1 CLEF-se(Run1)</cell><cell cols="2">0.8000</cell><cell>0.6800</cell></row><row><cell>DERI SE2 CLEF-se(Run2)</cell><cell cols="2">0.7720</cell><cell>0.5860</cell></row><row><cell>DERI SE3 CLEF-se(Run3)</cell><cell cols="2">0.7720</cell><cell>0.6560</cell></row><row><cell>DERI SE4 CLEF-se(Run4)</cell><cell cols="2">0.7720</cell><cell>0.6560</cell></row><row><cell cols="2">Run Type</cell><cell cols="2">Avg. Precision</cell></row><row><cell cols="2">DERI SE1 CLEF-se(Run1)</cell><cell>0.3023</cell></row><row><cell cols="2">DERI SE2 CLEF-se(Run2)</cell><cell>0.2395</cell></row><row><cell cols="2">DERI SE3 CLEF-se(Run3)</cell><cell>0.2008</cell></row><row><cell cols="2">DERI SE4 CLEF-se(Run4)</cell><cell>0.1504</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,172.73,471.44,269.89,7.89"><head>Table 2 .</head><label>2</label><figDesc>Average Mean Precision in Ad-hoc retrieval environment</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported in part by the <rs type="funder">European Union</rs> under Grant No. <rs type="grantNumber">248458</rs> for the <rs type="projectName">Monnet</rs> project and by the <rs type="funder">Science Foundation Ireland</rs> under Grant No. <rs type="grantNumber">SFI/08/CE/I1380</rs> (<rs type="grantNumber">Lion-2</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_2jhKVPh">
					<idno type="grant-number">248458</idno>
					<orgName type="project" subtype="full">Monnet</orgName>
				</org>
				<org type="funding" xml:id="_tkd6zyW">
					<idno type="grant-number">SFI/08/CE/I1380</idno>
				</org>
				<org type="funding" xml:id="_6CrUt4E">
					<idno type="grant-number">Lion-2</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,482.93,342.24,7.86;5,146.91,493.89,333.68,7.86;5,146.91,504.85,333.68,7.86;5,146.91,515.81,147.59,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,310.92,482.93,169.68,7.86;5,146.91,493.89,206.56,7.86">DERI&amp;UPM: Pushing corpus based relatedness to similarity: Shared task system description</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Asooja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,374.21,493.89,106.38,7.86;5,146.91,504.85,333.68,7.86;5,146.91,515.81,29.54,7.86">SemEval-2012, SEM, First Joint Conference on Lexical and Computational Semantics, and co-located with NAACL</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">6 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,526.65,342.24,7.86;5,146.91,537.61,333.68,7.86;5,146.91,548.56,178.44,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,343.60,526.65,136.99,7.86;5,146.91,537.61,72.09,7.86">A review of ontology based query expansion</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bhogal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Macfarlane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2006.09.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ipm.2006.09.003" />
	</analytic>
	<monogr>
		<title level="j" coord="5,234.71,537.61,103.59,7.86">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="866" to="886" />
			<date type="published" when="2007-07">Jul 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,559.40,342.24,7.86;5,146.91,570.36,333.68,7.86;5,146.91,581.32,242.83,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,343.77,559.40,136.82,7.86;5,146.91,570.36,60.30,7.86">Dbpedia.org -querying Wikipedia like a Database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,229.08,570.36,251.51,7.86;5,146.91,581.32,81.91,7.86">Developers track at 16th International World Wide Web Conference (WWW2007)</title>
		<meeting><address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-05">May 2007. May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,592.16,342.24,7.86;5,146.91,603.12,333.68,7.86;5,146.91,614.08,333.68,7.86;5,146.91,625.04,176.03,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,266.70,592.16,213.89,7.86;5,146.91,603.12,123.07,7.86">A WordNet-based query expansion method for geographical information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename></persName>
		</author>
		<ptr target="http://www.clef-campaign.org/2005/workingnotes/CLEF2005WN-Contents1.htm" />
	</analytic>
	<monogr>
		<title level="m" coord="5,291.81,603.12,109.24,7.86">CLEF 2005 Working Notes</title>
		<meeting><address><addrLine>Vienna, Austria C. Peters</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09-23">21-23 September. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,635.88,342.24,7.86;5,146.91,646.84,333.68,7.86;5,146.91,657.79,182.03,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,320.82,635.88,159.77,7.86;5,146.91,646.84,118.61,7.86">Concept-based information retrieval using explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Egozi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<idno type="DOI">10.1145/1961209.1961211</idno>
		<ptr target="http://doi.acm.org/10.1145/1961209.1961211" />
	</analytic>
	<monogr>
		<title level="j" coord="5,273.12,646.84,92.16,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011-04">Apr 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,120.67,342.24,7.86;6,146.91,131.63,333.68,7.86;6,146.91,142.59,236.07,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,278.29,120.67,202.30,7.86;6,146.91,131.63,126.81,7.86">Computing semantic relatedness using Wikipediabased explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,306.27,131.63,174.32,7.86;6,146.91,142.59,143.29,7.86">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
