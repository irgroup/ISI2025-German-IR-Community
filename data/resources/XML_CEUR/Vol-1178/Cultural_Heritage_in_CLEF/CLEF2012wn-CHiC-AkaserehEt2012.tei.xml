<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,233.21,152.67,128.81,12.64">UniNE at CLEF 2012</title>
				<funder ref="#_rKyuFzU">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,211.61,192.18,60.39,8.96"><forename type="first">Mitra</forename><surname>Akasereh</surname></persName>
							<email>mitra.akasereh@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<addrLine>Rue Emile Argand 11</addrLine>
									<postCode>2000</postCode>
									<settlement>Neuchatel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.99,192.18,39.44,8.96"><forename type="first">Nada</forename><surname>Naji</surname></persName>
							<email>nada.naji@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<addrLine>Rue Emile Argand 11</addrLine>
									<postCode>2000</postCode>
									<settlement>Neuchatel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.92,192.18,58.58,8.96"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<addrLine>Rue Emile Argand 11</addrLine>
									<postCode>2000</postCode>
									<settlement>Neuchatel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,233.21,152.67,128.81,12.64">UniNE at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AEB1603DEFA42CFFE5F91C6F86EC8623</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Probabilistic IR Models</term>
					<term>Stemmer</term>
					<term>Data Fusion</term>
					<term>Cultural Heritage</term>
					<term>bilingual IR</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As participants in this CLEF evaluation campaign, our first objective is to propose and evaluate various indexing and search strategies for the CHiC corpus, in order to compare the retrieval effectiveness across different IR models. Our second objective is to measure the relative merit of various stemming strategies when used for the French and English monolingual task in the CH context. Our third objective is to assess the effectiveness of query translation methods in a bilingual retrieval. To do so we evaluated the CHiC testcollections using Okapi, various IR models derived from the Divergence from Randomness (DFR) paradigm together with the dtu-dtn vector-space model. We also evaluated different pseudo-relevance feedback approaches. In the bilingual task, we conducted our search on the English corpus using the French and German topics with two different translations for each of them. For both English and French languages, we find that word-based indexing with our light stemming procedure results in better retrieval effectiveness than with other strategies. When ignoring stemming, the performance variations were relatively small yet for the French corpus better than applying a light stemmer. In bilingual level results show that using a combination of translation resources gives better results than a single source.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cultural heritage can be defined as any handmade substance or intangible feature remained from previous societies. It can refer to any artefacts, built or natural environments, traditions and languages, etc. The developing use of digital information challenges the cultural heritage organizations to provide cultural heritage collections in electronic format. The data may come from different sources (libraries, archives, museums, audiovisual archives, books, journals, etc.), in various languages and formats. These digital libraries should not only be created but also properly managed and assessed in order to bring the maximum utility to their users. As yet no proper evaluation approaches are available and there is work to be done in this area. The goal of Cultural Heritage in CLEF (CHiC) evaluation lab is thus providing a systematic and large-scale evaluation of cultural heritage digital libraries.</p><p>The IR group of university of Neuch√¢tel focuses, as one of its main tasks, on design, implementation and evaluation of various indexing and search strategies for a set of different natural languages. Up to this point we achieved to provide a groundwork for evaluation and comparison of different tools for monolingual IR, in different languages, using generic test-collections (e.g., newspaper articles). Our second goal is to evaluate different tools considering only a specific field of knowledge in order to integrate domain specific search into our system. The aim here is to be able to evaluate the impact of document structure and query formulation on retrieval effectiveness in order to study the possibilities to improve the search quality in a domain specific search. As a third objective we also want to integrate translation into the search process and adapting our system for bilingual and multilingual IR. Accordingly reaching these objectives has been our main motive to participate in CHiC evaluation lab at CLEF 2012.</p><p>The rest of this report is organized as follows: section 2 presents an introduction to our experiment setup. Section 3 describes the results obtained during the experiment and the related analysis. Section 4 shows our official runs and finally section 5 concludes the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Experiment Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview of the Task</head><p>In our participation in CHiC we worked on the ad-hoc retrieval task. This task is a standard retrieval task in which retrieval effectiveness for individual queries is assessed. At this level the only authorized user/system interaction would be blind-query expansion technics. The expected output is a ranked list of retrieved documents for each query. The task is covering monolingual, bilingual and multilingual subtasks in English, French and German. In our experiment we worked on monolingual English and French retrieval as well as bilingual retrieval in which we worked with French and German topics to be searched on the English corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Overview of the Test-collection</head><p>The corpus used For the ad-hoc task there are 50 very short topics. These topics are mostly named entities (people, places and works) and they mainly extracted from Europeana queries logs. Thus they convey the real user"s information needs in a cultural heritage search context. Among the 50 French topics, 11 have no relevant documents in the collection. This number grows to 14 for the English topics. One topic from each language is shown in Figure <ref type="figure" coords="4,194.59,411.83,3.76,8.96">3</ref>. As shown in the sample below each topic consists of a title and, sometimes, a description of the content. Even though, the only field that should be used for retrieval is the title.</p><p>-&lt;topic lang="en"&gt; &lt;identifier&gt;CHIC-006&lt;/identifier&gt; &lt;title&gt;esperanto&lt;/title&gt; &lt;description&gt;Constructed international auxiliary language&lt;/description&gt; &lt;/topic&gt; -&lt;topic lang="fr"&gt; &lt;identifier&gt;CHIC-004&lt;/identifier&gt; &lt;title&gt;film muet&lt;/title&gt; &lt;description /&gt; &lt;/topic&gt; -&lt;topic lang="de"&gt; &lt;identifier&gt;CHIC-025&lt;/identifier&gt; &lt;title&gt; amerikanische sklaverei &lt;/title&gt; &lt; description /&gt; &lt;/topic&gt; Fig. <ref type="figure" coords="4,218.57,648.67,3.41,8.10">3</ref>. Sample of English, French and German topics</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Indexing Strategies</head><p>In our experiment we applied a stopword removal along with a light stemmer for both English and French corpora. Our stopword list for English contains 571 terms while the French one has 464 terms. These tools are freely available at members.unine.ch/jacques.savoy/clef/. These lists are composed of terms having a high frequency such as determinants, prepositions, conjunctions, pronouns, and some verbal forms which convey no important meaning. The light stemmer that we used for English removes only the plural "-s" and is called S-stemmer <ref type="bibr" coords="5,383.23,242.25,10.69,8.96" target="#b0">[1]</ref>. The stemmer for French removes the inflectional suffixes from plural and feminine forms of the words <ref type="bibr" coords="5,124.70,266.25,10.66,8.96" target="#b1">[2]</ref>. Our choice of these light stemmers is based on previous experiments which show that light stemmers tend to be as effective as stemmers based on morphological analysis <ref type="bibr" coords="5,137.90,302.25,10.69,8.96" target="#b0">[1]</ref>, <ref type="bibr" coords="5,154.92,302.25,10.66,8.96" target="#b2">[3]</ref>, <ref type="bibr" coords="5,171.98,302.25,10.69,8.96" target="#b3">[4]</ref>. Moreover applying stemming would not be a good manner to achieve high precision which is the aim in this experiment <ref type="bibr" coords="5,327.07,314.25,10.69,8.96" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">IR Models</head><p>In our experiments we tried different weighting schemes in order to compare them and define the most effective ones in terms of achieving a high precision. First we picked the dtu-dtn model <ref type="bibr" coords="5,228.65,388.29,11.69,8.96" target="#b5">[6]</ref> as an effective vector-space model. Second, as probabilistic models, we used the Okapi (BM25) <ref type="bibr" coords="5,293.57,400.31,10.60,8.96" target="#b6">[7]</ref>. Then we tried three other probabilistic models extracted from the Divergence from Randomness (DFR) family <ref type="bibr" coords="5,423.24,412.31,10.66,8.96" target="#b7">[8]</ref>, namely DFR-PL2, DFR-I(n e )C2, and DFR-I(n e )B2. The indexing weight (weight of term t j in document d i ) in these models is computed as shown in Table <ref type="table" coords="5,370.15,436.31,3.77,8.96">1</ref>.</p><p>Table <ref type="table" coords="5,188.66,460.12,3.42,8.10">1</ref>. Formulas used in different models for assigning indexing weight</p><formula xml:id="formula_0" coords="5,124.70,478.84,334.57,29.60">Okapi ) ) ) [ ) ]</formula><p>l i is the length of document d i and avdl is the average document length.</p><p>dtu-dtn Indexing weight for document terms (dtu):</p><p>))) )</p><p>Indexing weight for query terms (dtn):</p><formula xml:id="formula_1" coords="5,285.77,623.55,12.41,9.96">))) DFR )) ( Prob 1 ( )) ( Prob ( log 2 1 2 2 1 ij ij ij ij ij ij ij tf tf Inf Inf w ÔÄ≠ ÔÉó ÔÄ≠ ÔÄΩ ÔÉó ÔÄΩ DFR-I(n e )C2: ÔÉ∫ ÔÉª ÔÉπ ÔÉ™ ÔÉ´ ÔÉ© ÔÄ´ ÔÄ´ ÔÉó ÔÄΩ 5 . 0 1 log 1 e ij ij n n tfn Inf ) 1 ( 1 1 Prob 2 ÔÄ´ ÔÉó ÔÄ´ ÔÄ≠ ÔÄΩ ij j j ij tfn df tc DFR-I(n e )B2: [ ) ‚ÅÑ )] [ ) ‚ÅÑ ))]</formula><p>DFR-PL2: </p><formula xml:id="formula_2" coords="6,178.91,317.34,228.20,24.77">! Pr 1 ij tfn j ij tfn e ob ij j ÔÅ¨ ÔÅ¨ ÔÉó ÔÄΩ ÔÄ≠ 1 Pr 2 ÔÄ´ ÔÄΩ ij ij ij tfn tfn ob</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation</head><p>For evaluating the retrieval performance we chose the MAP (mean average precision) measure. This is computed with the TREC_EVAL program where MAP value is computed based on, maximum, 1000 retrieved items per query. It is important to mention that when computing the MAP, the topics with no relevant items are not taken into account (14 topics among the English topics and 11 French ones).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Pseudo-Relevance Feedback</head><p>In order to enhance the retrieval effectiveness we also applied a blind-query expansion to our test. Our previous experiments on other corpora show that pseudorelevance feedback (PRF or blind-query expansion) tends to improve the retrieval effectiveness <ref type="bibr" coords="6,180.26,660.26,10.71,8.96" target="#b8">[9]</ref>. As a first approach we tried the Rocchio's approach <ref type="bibr" coords="6,414.86,660.26,16.93,8.96" target="#b9">[10]</ref> with Œ± = 0.75, Œ≤ = 0.75. In this method the system expands the query by adding m terms selected from the k best ranked documents retrieved for the original query. As a second approach we tried an idf-based query expansion model <ref type="bibr" coords="7,358.09,150.18,15.47,8.96" target="#b10">[11]</ref>. The reason for trying both approaches is that in some cases adding frequently occurring terms produces noise and consequently Rocchio's approach does not give good results <ref type="bibr" coords="7,407.92,174.18,15.55,8.96" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Data Fusion</head><p>In our experiment we tried to see whether combining different indexing schemes and IR models improves the retrieval effectiveness, as it is supposed to, or not <ref type="bibr" coords="7,432.43,236.22,15.35,8.96" target="#b12">[13]</ref>. It is probable that different strategies retrieve the same relevant items in their top ranks rather than the same non-relevant ones. Therefore we consider that by combining different ranked lists, resulting from different IR models, we will gain a list with relevant documents in higher ranks and the non-relevant items in lower ones <ref type="bibr" coords="7,435.19,284.25,15.46,8.96" target="#b13">[14]</ref>. In order to produce this combination of ranked lists, different fusion operators can be used. In our study we chose the Z-score scheme which tends to perform the best <ref type="bibr" coords="7,451.42,308.25,15.43,8.96" target="#b13">[14]</ref>, <ref type="bibr" coords="7,124.70,320.25,15.43,8.96" target="#b14">[15]</ref>. More details about the Z-score can be found in <ref type="bibr" coords="7,370.15,320.25,15.43,8.96" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results &amp; Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Monolingual Retrieval</head><p>At monolingual ad-hoc task, we test our system the English and French corpora. Tables <ref type="table" coords="7,155.06,409.31,4.98,8.96" target="#tab_3">2</ref> and<ref type="table" coords="7,181.65,409.31,4.98,8.96" target="#tab_4">3</ref> show the Mean Average Precision (MAP) for, respectively, English and French corpora. For both languages, we tried different IR models while applying a light stemmer (Section 2.3) and compared these results with the ones obtained when stemming is ignored. In using the Okapi model the avdl (average document length) is set to 181 for English corpus and 169 for the French one, the constant k 1 to 1.2, for both languages, and we tried three different values for the constant b: 0.5, 0.7 &amp; 0.9.  As the results show, for English the corpus with DFR-I(n e )B2 model we achieve the highest MAP while the best performing model for French is Okapi model (with b=0.5). The results show that applying the light stemmer for the English language improves the effectiveness of the search which is not the case for the French collection. As can be seen in Table <ref type="table" coords="8,243.13,198.18,4.98,8.96" target="#tab_4">3</ref> we achieved higher MAP while ignoring the stemming phase for the French language. By making a query-by-query analysis on the results we can find some examples where stemming misleads the retrieval. In Topic #21 the title "chanrdonne" (Jacques Chardonne, Writer (F.) Or place in Switzerland) is indexed as "chardon" (after applying the light stemmer) which leads the system to retrieve in its top ranks non-relevant documents (in which "chardon" refers to a flower) such as: ‚îÄ Etude de feuilles de echirops, de sphoerophalus, chardon cultiv√©, de chardon sauvage de la mer, de fleur lilas, de chardon sauvage ‚îÄ Sujet ou d√©cor : repr√©sentation v√©g√©tale (fleur, chardon) ; chardon bleu ; Etude de chardon fleuri ‚îÄ Chardons sur la c√¥te rocheuse</p><p>As another example we can mention Topic #9 for which the title "√Æles malouines" changes to "malouin" after stemming and results in the retrieval of non-relevant documents (where "Malouin" is a proper name) such as follows in the top ranks: ‚îÄ L'Avare, com√©die de Moli√®re en 5 actes, mise en vers, par A. Malouin ‚îÄ villas de la Malouine Table <ref type="table" coords="8,163.32,438.23,4.98,8.96" target="#tab_5">4</ref> contains the MAP obtained when applying pseudo-relevance feedback. These results reveal that in this experiment the PRF technic did not help to enhance the retrieval performance. The reason should be due to the fact that in this experiment we are dealing with relatively short documents (having the average number of distinct indexing terms per document at ~54 for English and ~56 for French). In Table <ref type="table" coords="9,173.25,602.06,4.98,8.96" target="#tab_6">5</ref> we can see the results for our data fusion approach for the English corpus. We can see that the MAP obtained by combining different result lists enhances, in some cases, slightly the performance. However the difference between the MAP obtained for each model separately and the combined one is rather small. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bilingual retrieval</head><p>In our bilingual retrieval we used the German and French topics to search the English corpus. Our approach was based on query translation (QT). Thus we produced the English translations for German and French topics and then we launched the search on English corpus. To translate the queries we first used two different strategies. First we used Google translation which seems to give reasonable results when dealing with very short query formulation <ref type="bibr" coords="10,244.18,572.30,15.39,8.96" target="#b16">[17]</ref>. As a second approach we used the combination of Wikipedia and Google considering that a combination of translation strategies slightly improves the retrieval performance <ref type="bibr" coords="10,274.83,596.30,15.54,8.96" target="#b15">[16]</ref>. The results for the bilingual retrieval are shown in Tables <ref type="table" coords="10,193.97,608.30,4.98,8.96">6</ref> and<ref type="table" coords="10,219.17,608.30,3.77,8.96">7</ref>. We can see that using the combination of Google and Wikipedia results a better performance even though the difference is not remarkable. The topics used in this collection are mostly name entities and only the title is used for the search which makes the translation less critical and easier. As a result there are not many differences between translations produced with the two strategies. However, by inspecting the results in details we can find some cases for which a better translation led to better retrievals. In translating Topic #5 ("briefmarke"), from German to Conclusion</p><p>The results obtained in CLEF 2012 CHiC lab, state that the models derived from the Divergence from Randomness (DFR) family, yield the best retrieval effectiveness regardless the underlying language and test-collection. Applying DFR-I(n e )B2 and DFR-PL2 for both the French and English corpora produced a high MAP compared to other tested models. Our results reveal that the Okapi model (with b=0.5) tends also to be an effective model. The resulting question is to define the best values for the underlying constants.</p><p>Our experiment shows that applying a light stemmer (removing only the plural "-s") for English, helps to achieve better results than when the stemming phase is skipped. On the contrary, when using our light stemmer for French (removing plural and feminine suffixes) does not seem to enhance the retrieval performance. A simpler stemmer for the French language may produce a better effectiveness than the applied light stemmer.</p><p>Considering the results, we can also conclude that when dealing with relatively short documents, blind-query expansion is not a useful expansion method in order to improve the retrieval effectiveness. In such cases, it seems difficult to select the most appropriate terms to be included in the expanded query.</p><p>Finally, our results from the bilingual search confirm the effectiveness of DFR-I(n e )B2 model and the S-stemmer (used for English). Furthermore, they show that a combined translation strategy leads to perform better results than a single one. Even though in our experiment, having very short topics (and mostly name entities), the difference between the various translation methods is not remarkable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,165.62,362.57,6.37,8.18;6,187.03,369.88,2.97,1.00;6,180.89,368.88,5.75,1.00;6,194.57,362.66,120.84,8.10;6,165.62,383.69,6.37,8.18;6,203.83,397.65,5.20,1.00;6,200.33,383.63,10.48,2.01;6,185.68,390.90,1.74,1.00;6,191.37,382.93,5.71,9.13;6,178.79,382.52,5.71,9.66;6,219.89,383.78,3.00,8.10;6,232.97,390.98,1.67,1.00;6,224.54,389.98,7.46,1.00;6,239.45,383.78,130.12,8.10;6,378.43,390.98,1.79,1.00;6,373.75,389.98,2.98,1.00;6,385.51,383.78,73.91,8.10;6,463.55,389.65,4.95,1.00;6,177.02,403.60,93.74,8.10;6,165.62,421.09,7.05,9.05;6,260.53,421.09,3.45,9.02;6,248.54,421.09,3.45,9.02;6,243.28,414.83,5.18,9.02;6,225.05,421.09,3.45,9.02;6,211.46,421.09,5.18,9.02;6,208.93,421.09,3.45,9.02;6,257.41,424.95,1.15,1.00;6,252.29,424.36,4.78,1.00;6,183.91,428.92,2.76,1.00;6,236.02,435.68,5.18,1.00;6,229.68,421.68,5.18,1.00;6,198.35,427.93,5.18,1.00;6,178.94,427.93,5.18,1.00;6,236.80,414.73,5.68,9.11;6,217.62,420.99,5.68,9.11;6,204.98,420.99,2.59,9.11;6,190.26,420.99,5.68,9.11;6,165.62,447.01,7.05,9.05;6,304.96,447.11,3.40,9.01;6,289.02,440.86,5.11,9.01;6,240.98,447.11,5.11,9.01;6,238.50,447.11,3.40,9.01;6,220.87,447.11,16.46,9.01;6,279.67,462.73,1.70,1.00;6,210.41,454.94,3.70,1.00;6,189.06,454.94,3.70,1.00;6,276.83,461.74,2.84,1.00;6,295.59,447.70,7.82,1.00;6,266.20,447.70,21.00,1.00;6,255.79,447.70,4.54,1.00;6,204.31,453.95,5.82,1.00;6,178.57,453.95,11.07,1.00;6,262.02,440.76,2.56,9.10;6,247.18,447.01,5.61,9.10;6,216.86,447.01,2.56,9.10;6,196.47,447.01,5.61,9.10;6,315.77,447.76,3.00,8.10;6,270.39,493.82,10.06,10.98;6,320.27,444.52,25.22,11.34;6,382.77,453.98,7.90,1.00;6,352.89,453.98,21.22,1.00;6,376.03,447.12,5.22,9.03;6,398.71,447.76,72.05,8.10;6,177.02,468.52,25.54,8.10"><head></head><label></label><figDesc>number of occurrence of term j t in the collection and n is the size of the elite set.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,124.70,553.31,346.00,128.99"><head>tion d'organismes abonn√©s au Grove Music Online.&lt;/dc:description&gt; &lt;dc:description&gt;Biographie de Lejla Agolli&lt;/dc:description&gt; &lt;dc:subject&gt;Agolli, Lejla (compositeur) :&lt;/dc:subject&gt; &lt;dc</head><label></label><figDesc></figDesc><table coords="2,124.70,553.31,346.00,128.99"><row><cell>:source&gt;http://www.musiquecontemporaine.fr/record/oai:ircam.fr:grove:41112&lt;/</cell></row><row><cell>dc:source&gt;</cell></row><row><cell>&lt;europeana:isShownAt&gt;</cell></row><row><cell>http:/</cell></row><row><cell>in CHiC test-collection is extracted from Europeana</cell></row><row><cell>(www.europeana.eu) and is offered in 3 major European languages, namely English</cell></row><row><cell>(EN), French (FR) and German (DE). Europeana is a digitized collection of Europe"s</cell></row><row><cell>cultural and scientific heritage. It provides access over 23 million objects such as</cell></row><row><cell>books, paintings, films, museum objects, etc. collected from more than 2200 institu-</cell></row><row><cell>tions in 33 countries. Europeana collection is cross-domain and in multiple languages.</cell></row><row><cell>The documents metadata is mapped to a single data model. Each document consists of</cell></row><row><cell>elements providing brief descriptions of the objects (title, keywords, description, date,</cell></row><row><cell>provider, etc.). It is worth-mentioning that some documents contain less of these tags</cell></row><row><cell>than other ones which sometimes leaves them with very poor content. As far as our</cell></row><row><cell>experiment is concerned, only human-readable informative texts are of use.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,144.02,212.27,292.65,59.61"><head>/www.grovemusic.com/shared/views/article.html?section=music.41112</head><label></label><figDesc></figDesc><table coords="4,144.02,222.35,266.85,49.53"><row><cell>&lt;/europeana:isShownAt&gt;</cell></row><row><cell>&lt;dc:rights&gt;internet&lt;/dc:rights&gt;</cell></row><row><cell>&lt;dcterms:provenance&gt;Ircam -Centre Pompidou&lt;/dcterms:provenance&gt;</cell></row><row><cell>&lt;europeana:country&gt;france&lt;/europeana:country&gt;</cell></row><row><cell>&lt;europeana:provider&gt;IRCAM-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,136.34,263.78,267.71,73.02"><head>Institut de Recherche et Coordination Acoustique/Musique&lt;/europeana:provider&gt; &lt;europeana</head><label></label><figDesc></figDesc><table coords="4,136.34,284.54,230.67,52.26"><row><cell>:language&gt;fr&lt;/europeana:language&gt;</cell></row><row><cell>&lt;/ims:fields&gt;</cell></row><row><cell>&lt;/ims:metadata&gt;</cell></row><row><cell>Fig. 2. Example of a French document</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,124.70,493.12,342.49,83.64"><head>Table 2 .</head><label>2</label><figDesc>MAP of different IR models, English corpus</figDesc><table coords="7,124.70,512.50,342.49,64.27"><row><cell></cell><cell>DFR</cell><cell>DFR</cell><cell>DFR</cell><cell>Okapi</cell><cell>Okapi</cell><cell>Okapi</cell><cell>dtu-dtn</cell><cell>Avg.</cell></row><row><cell></cell><cell>I(ne)C2</cell><cell>I(ne)B2</cell><cell>PL2</cell><cell>(b=0.5)</cell><cell>(b=0.7)</cell><cell>(b=0.9)</cell><cell></cell><cell></cell></row><row><cell>NoStem.</cell><cell>0.4244</cell><cell>0.4524</cell><cell>0.4354</cell><cell>0.4289</cell><cell>0.4207</cell><cell>0.4032</cell><cell>0.4320</cell><cell>0.4281</cell></row><row><cell>SStem.</cell><cell>0.4487</cell><cell>0.4752</cell><cell>0.4628</cell><cell>0.4560</cell><cell>0.4429</cell><cell>0.4229</cell><cell>0.4484</cell><cell>0.4510</cell></row><row><cell>% Change</cell><cell>+5.7%</cell><cell>+5.0%</cell><cell>+6.3%</cell><cell>+6.3%</cell><cell>+5.3%</cell><cell>+4.9%</cell><cell>+3.8%</cell><cell>+5.3%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,124.70,592.03,342.49,85.65"><head>Table 3 .</head><label>3</label><figDesc>MAP of different IR models, French corpus</figDesc><table coords="7,124.70,611.53,342.49,66.16"><row><cell></cell><cell>DFR</cell><cell>DFR</cell><cell>DFR</cell><cell>Okapi</cell><cell>Okapi</cell><cell>Okapi</cell><cell>dtu-dtn</cell><cell>Avg.</cell></row><row><cell></cell><cell>I(ne)C2</cell><cell>I(ne)B2</cell><cell>PL2</cell><cell>(b=0.5)</cell><cell>(b=0.7)</cell><cell>(b=0.9)</cell><cell></cell><cell></cell></row><row><cell>NoStem.</cell><cell>0.3520</cell><cell>0.3582</cell><cell>0.3623</cell><cell>0.3627</cell><cell>0.3602</cell><cell>0.3497</cell><cell>0.3413</cell><cell>0.3552</cell></row><row><cell>LStem.</cell><cell>0.3290</cell><cell>0.3360</cell><cell>0.3392</cell><cell>0.3402</cell><cell>0.3348</cell><cell>0.3253</cell><cell>0.3197</cell><cell>0.3320</cell></row><row><cell>% Change</cell><cell>-6.6%</cell><cell>-6.2%</cell><cell>-6.4%</cell><cell>-6.2%</cell><cell>-7.1%</cell><cell>-7.0%</cell><cell>-6.3%</cell><cell>-6.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,155.78,173.99,283.46,411.05"><head>Table 4 .</head><label>4</label><figDesc>MAP of idf-based blind-query expansion, English and French queries</figDesc><table coords="9,173.42,193.49,236.38,391.56"><row><cell></cell><cell></cell><cell cols="2">Mean Average Precision</cell></row><row><cell></cell><cell></cell><cell>English</cell><cell>French</cell></row><row><cell></cell><cell></cell><cell>DFR_I(ne)B2 SStemmer</cell><cell>Okapi NoStem</cell></row><row><cell></cell><cell></cell><cell>0.4752</cell><cell>0.3627</cell></row><row><cell>5 documents</cell><cell>5 terms</cell><cell>0.4382</cell><cell>0.3488</cell></row><row><cell></cell><cell>10 terms</cell><cell>0.4315</cell><cell>0.3483</cell></row><row><cell></cell><cell>30 terms</cell><cell>0.3864</cell><cell>0.3428</cell></row><row><cell></cell><cell>50 terms</cell><cell>0.3656</cell><cell>0.3241</cell></row><row><cell></cell><cell>70 terms</cell><cell>0.3606</cell><cell>0.3110</cell></row><row><cell>10 documents</cell><cell>5 terms</cell><cell>0.4557</cell><cell>0.3432</cell></row><row><cell></cell><cell>10 terms</cell><cell>0.4250</cell><cell>0.3472</cell></row><row><cell></cell><cell>30 terms</cell><cell>0.3923</cell><cell>0.3300</cell></row><row><cell></cell><cell>50 terms</cell><cell>0.3875</cell><cell>0.3283</cell></row><row><cell></cell><cell>70 terms</cell><cell>0.3913</cell><cell>0.3272</cell></row><row><cell>15 documents</cell><cell>5 terms</cell><cell>0.4545</cell><cell>0.3329</cell></row><row><cell></cell><cell>10 terms</cell><cell>0.4432</cell><cell>0.3166</cell></row><row><cell></cell><cell>30 terms</cell><cell>0.3981</cell><cell>0.2971</cell></row><row><cell></cell><cell>50 terms</cell><cell>0.3878</cell><cell>0.2947</cell></row><row><cell></cell><cell>70 terms</cell><cell>0.3764</cell><cell>0.2916</cell></row><row><cell>20 documents</cell><cell>5 terms</cell><cell>0.4519</cell><cell>0.3404</cell></row><row><cell></cell><cell>10 terms</cell><cell>0.4338</cell><cell>0.3181</cell></row><row><cell></cell><cell>30 terms</cell><cell>0.3962</cell><cell>0.2900</cell></row><row><cell></cell><cell>50 terms</cell><cell>0.3850</cell><cell>0.2864</cell></row><row><cell></cell><cell>70 terms</cell><cell>0.3798</cell><cell>0.2876</cell></row><row><cell>25 documents</cell><cell>5 terms</cell><cell>0.4456</cell><cell>0.3439</cell></row><row><cell></cell><cell>10 terms</cell><cell>0.4346</cell><cell>0.3231</cell></row><row><cell></cell><cell>30 terms</cell><cell>0.3901</cell><cell>0.3031</cell></row><row><cell></cell><cell>50 terms</cell><cell>0.3789</cell><cell>0.2641</cell></row><row><cell></cell><cell>70 terms</cell><cell>0.3723</cell><cell>0.2608</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="10,154.46,173.99,282.54,296.78"><head>Table 5 .</head><label>5</label><figDesc>MAP of different combinations of IR models, English corpus</figDesc><table coords="10,154.46,193.49,282.54,277.29"><row><cell></cell><cell cols="2">English / SStemmer</cell><cell></cell></row><row><cell>Model</cell><cell>Query Expansion</cell><cell>Single MAP</cell><cell>Combined MAP</cell></row><row><cell></cell><cell>(idf-based)</cell><cell></cell><cell>Z-Score</cell></row><row><cell>DFR-I(ne)B2</cell><cell></cell><cell>0.4752</cell><cell>0.4715</cell></row><row><cell>DFR-PL2</cell><cell></cell><cell>0.4628</cell><cell></cell></row><row><cell>DFR-I(ne)B2</cell><cell></cell><cell>0.4752</cell><cell>0.4611</cell></row><row><cell>DFR-I(ne)C2</cell><cell>5 documents /10 terms</cell><cell>0.3918</cell><cell></cell></row><row><cell>DFR-I(ne)B2</cell><cell></cell><cell>0.4752</cell><cell>0.4758</cell></row><row><cell>dtu-dtn</cell><cell></cell><cell>0.4484</cell><cell></cell></row><row><cell>dtu-dtn</cell><cell></cell><cell>0.4484</cell><cell>0.4667</cell></row><row><cell>DFR-PL2</cell><cell></cell><cell>0.4628</cell><cell></cell></row><row><cell>DFR-I(ne)C2</cell><cell></cell><cell>0.4487</cell><cell>0.4518</cell></row><row><cell>dtu-dtn</cell><cell></cell><cell>0.4484</cell><cell></cell></row><row><cell>DFR-I(ne)B2</cell><cell>20 documents /10terms</cell><cell>0.4338</cell><cell>0.4378</cell></row><row><cell>Okapi(b=0.9)</cell><cell></cell><cell>0.4229</cell><cell></cell></row><row><cell>dtu-dtn</cell><cell></cell><cell>0.4484</cell><cell>0.4301</cell></row><row><cell>DFR-PL2</cell><cell>5 documents /10terms</cell><cell>0.3834</cell><cell></cell></row><row><cell>DFR-I(ne)C2</cell><cell>20 documents /10terms</cell><cell>0.4074</cell><cell>0.4238</cell></row><row><cell>dtu-dtn</cell><cell>10 documents /10terms</cell><cell>0.3677</cell><cell></cell></row><row><cell>Okapi(b=0.9)</cell><cell></cell><cell>0.4229</cell><cell></cell></row><row><cell>DFR-I(ne)C2</cell><cell>20 documents /10terms</cell><cell>0.4074</cell><cell>0.4171</cell></row><row><cell>dtu-dtn</cell><cell>10 documents /30terms</cell><cell>0.3376</cell><cell></cell></row><row><cell>Okapi(b=0.9)</cell><cell></cell><cell>0.4229</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported in part by the <rs type="funder">Swiss National Science Foundation</rs> under Grant #<rs type="grantNumber">200020-129535/1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rKyuFzU">
					<idno type="grant-number">200020-129535/1</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The English corpus consists of 1,106,426 documents while the French one has 3,635,388 ones. A sample of both French and English documents is shown in Figures <ref type="figure" coords="3,124.70,174.18,4.98,8.96">1</ref> and<ref type="figure" coords="3,149.14,174.18,3.78,8.96">2</ref>. &lt;ims:metadata ims:identifier="http://www.europeana.eu/resolve/record/10105/662DC5085397837 C8C8891836EA6431C4A477CB2"ims:namespace="http://www.europeana.eu/" ims:language="eng"&gt; &lt;ims:fields&gt; &lt;dc:identifier&gt;Orn.0446&lt;/dc:identifier&gt; &lt;dc:subject&gt;Australian Pelican&lt;/dc:subject&gt; &lt;dc:title&gt;Australian Pelican (Orn.0446)&lt;/dc:title&gt; &lt;dc:type&gt;mounted specimen&lt;/dc:type&gt; &lt;europeana:country&gt;malta&lt;/europeana:country&gt; &lt;europeana:dataProvider&gt;Heritage Malta&lt;/europeana:dataProvider&gt; &lt;europeana:isShownAt&gt;http://www.heritagemalta.org/sterna/orn.php?id=0446 &lt;/europeana:isShownAt&gt; &lt;europeana:language&gt;en&lt;/europeana:language&gt; &lt;europeana:provider&gt;STERNA&lt;/europeana:provider&gt; &lt;europeana:type&gt;IMAGE&lt;/europeana:type&gt; &lt;europeana:uri&gt; http://www.europeana.eu/resolve/record/10105/662DC5085397837C8C8891 836EA6431C4A477CB2&lt;/europeana:uri&gt; &lt;/ims:fields&gt; &lt;/ims:metadata&gt; Fig. 1. Example of an English document &lt;ims:metadata ims:identifier="http://www.europeana.eu/resolve/record/91401/6BA09455082 C5E65E39C59DC30A0A966C235FBAE"ims:namespace="http://www.europeana.eu/"ims :language="fre"&gt; &lt;ims:fields&gt; &lt;dc:identifier&gt;oai:ircam.fr:grove:41112&lt;/dc:identifier&gt; &lt;dc:identifier&gt;http://www.grovemusic.com/shared/views/article.html?section=music. 41112 &lt;/dc:identifier&gt; &lt;europeana:uri&gt; http://www.europeana.eu/resolve/record/91401/6BA09455082C5E65E39C59DC30A0 A966C235FBAE&lt;/europeana:uri&gt; &lt;dc:title&gt;Biography. Lejla Agolli&lt;/dc:title&gt; &lt;dc:contributor&gt;Macy, Laura (√©diteur)&lt;/dc:contributor&gt; &lt;dc:type&gt;text&lt;/dc:type&gt; &lt;dc:type&gt;biography&lt;/dc:type&gt; &lt;dc:type&gt;biographie&lt;/dc:type&gt; &lt;dc:type&gt;document num√©rique&lt;/dc:type&gt; &lt;europeana:type&gt;TEXT&lt;/europeana:type&gt; &lt;dc:publisher&gt;Grove Music Online&lt;/dc:publisher&gt; &lt;dc:language&gt;English&lt;/dc:language&gt; &lt;dc:language&gt;eng&lt;/dc:language&gt; &lt;dc:description&gt;Cette biographie n'est accessible qu'√† partir de postes de consulta-</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>English, Google gives us the word "stamp" versus "postage stamp" which resulted from the Google and Wikipedia combination. As a result the system returns 9 relevant documents among its first 10 ranks when searching "postage stamp" while by searching "stamp" the first relevant document only appears at rank 82. Using the French topics for the same topic ("timbre poste"), Google gives us "stamp post" versus "postage stamp" using the combination method. Here again the system retrieves 9 relevant documents among its first 10 ranks using "postage stamp" while by searching "stamp post" it retrieves 5 relevant documents among its first 10 having the first relevant at rank 5.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Official Results</head><p>Table <ref type="table" coords="11,162.02,514.67,4.98,8.96">8</ref> summarizes our twelve official runs. We have submitted four runs for the English monolingual ad-hoc task and four French monolingual ad-hoc runs. For bilingual ad-hoc we submitted two runs using French topics to retrieve English documents and two runs using German topics again on the English corpus. In each run we used our different selected models while applying our light stemmers or alternatively skipping the stemming phase. In some cases we applied a pseudo-relevance feedback strategy <ref type="bibr" coords="11,160.34,586.70,16.72,8.96" target="#b10">[11]</ref> to evaluate its impact on the system"s performance. We also tried to merge different models into a single ranked list using the Z-score scheme <ref type="bibr" coords="11,428.23,598.70,16.72,8.96" target="#b15">[16]</ref> in order to improve the retrieval effectiveness. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,132.67,311.54,259.65,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,197.49,311.54,98.13,8.10">How effective is suffixing?</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,297.89,311.54,21.09,8.10">JASIS</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,322.58,338.04,8.10;13,141.74,333.50,56.35,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,179.73,322.58,245.63,8.10">A stemming procedure and stopword list for general French corpora</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,431.83,322.58,25.20,8.10">JASIS</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="944" to="952" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,344.54,337.93,8.10;13,141.74,355.58,265.22,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,179.24,344.54,291.36,8.10;13,141.74,355.58,37.02,8.10">Light Stemming Approaches for the French, Portuguese, German and Hungarian Languages</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,185.15,355.58,84.04,8.10">Proceedings ACM-SAC</title>
		<meeting>ACM-SAC</meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1031" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,366.50,327.84,8.10;13,141.74,377.54,111.86,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,219.89,366.50,236.86,8.10">Algorithmic Stemmers or Morphological Analysis: An Evaluation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fautsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,141.74,377.54,30.69,8.10">JASIST</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1616" to="1624" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.30,388.29,338.55,8.96;13,141.74,399.86,328.88,8.10;13,141.74,410.92,190.37,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,225.53,388.94,245.33,8.10;13,141.74,399.86,83.98,8.10">Report on the TREC 11 Experiment: Arabic, Named Page and Topic Distillation Searches</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rasolofo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,246.05,399.86,224.57,8.10;13,141.74,410.92,16.28,8.10">Proceedings of the eleventh text retrieval conference TREC-2002</title>
		<meeting>the eleventh text retrieval conference TREC-2002</meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,421.84,337.79,8.10;13,141.74,432.88,194.48,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,190.64,421.84,75.17,8.10">AT &amp; T at TREC-6</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,274.46,421.84,195.99,8.10;13,141.74,432.88,76.91,8.10">ACM Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM/SIGIR</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,443.92,337.61,8.10;13,141.74,454.84,247.69,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,310.95,443.92,159.33,8.10;13,141.74,456.24,16.01,6.26">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,166.30,454.84,140.32,8.10">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,465.88,337.80,8.10;13,141.74,476.92,328.51,8.10;13,141.74,487.84,80.41,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,272.45,465.88,198.02,8.10;13,141.74,476.92,157.39,8.10">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,308.76,476.92,157.47,8.10">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.67,498.88,338.22,8.10;13,141.74,509.92,158.50,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,232.95,498.88,149.05,8.10">Ad Hoc Retrieval with Marathi Language</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Akasereh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,388.73,498.88,82.15,8.10;13,141.74,509.92,132.20,8.10">Working notes, Forum for Information Retrieval Evaluation</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,520.84,337.80,8.10;13,141.74,531.88,324.40,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,339.55,520.84,130.65,8.10;13,141.74,531.88,27.56,8.10">New Retrieval Approaches Using SMART</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<idno>#500-236</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,177.10,531.88,74.54,8.10">Proceedings TREC-4</title>
		<meeting>TREC-4<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,542.92,338.46,8.10;13,141.74,553.84,291.82,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,221.45,542.92,249.41,8.10;13,141.74,553.84,64.32,8.10">Searching in Medline: Stemming, Query Expansion, and Manual Indexing Evaluation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,211.99,553.84,140.32,8.10">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="781" to="789" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,564.91,338.15,8.10;13,141.74,575.95,220.65,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,223.83,564.91,246.73,8.10;13,141.74,575.95,112.39,8.10">The Limitations of Term Co-Occurrence Data for Query Expansion in Document Retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Peat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,260.45,575.95,25.29,8.10">JASIS</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="378" to="383" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,586.87,338.22,8.10;13,141.74,597.91,56.35,8.10" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,253.19,586.87,150.52,8.10">Fusion via a linear combination of scores</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,410.11,586.87,36.99,8.10">IR Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="173" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,608.95,338.20,8.10;13,141.74,619.87,238.39,8.10" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,178.94,608.95,262.98,8.10">Data Fusion for Effective European Monolingual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,448.70,608.95,21.91,8.10;13,141.74,619.87,42.76,8.10">CLEF 2004. LNCS</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,630.91,337.95,8.10;13,141.74,641.95,238.39,8.10" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,276.97,630.91,60.89,8.10;13,365.35,630.91,75.99,8.10">TEL, and Persian IR</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dolamic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fautsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,448.54,630.91,21.81,8.10;13,141.74,641.95,16.28,8.10">CLEF 2008</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008. 2009</date>
			<biblScope unit="volume">5706</biblScope>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
	<note>UniNE at CLEF</note>
</biblStruct>

<biblStruct coords="13,132.40,652.87,338.06,8.10;13,141.74,663.91,253.60,8.10" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,229.36,652.87,237.34,8.10">Selection and Merging Strategies for Multilingual Information</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,141.74,663.91,66.98,8.10">CLEF 2004. LNCS</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="27" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,132.40,674.95,337.93,8.10;13,141.74,685.87,94.90,8.10" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,227.20,674.95,204.46,8.10">How effective is Google&apos;s translation service in search?</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dolamic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,434.50,674.95,35.83,8.10;13,141.74,685.87,22.65,8.10">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="139" to="143" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
