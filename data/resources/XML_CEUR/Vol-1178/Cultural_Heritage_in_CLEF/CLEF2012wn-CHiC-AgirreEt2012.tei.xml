<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.61,116.95,332.13,12.62;1,159.42,134.89,296.53,12.62;1,174.09,152.82,267.17,12.62">The Sheffield and Basque Country Universities Entry to CHiC: using Random Walks and Similarity to access Cultural Heritage</title>
				<funder ref="#_kNF9SkZ">
					<orgName type="full">European Community</orgName>
				</funder>
				<funder ref="#_pE9h4w9 #_HDQSmQz">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.86,190.54,57.47,8.74"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
							<email>e.agirre@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">UPV/EHU</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.89,190.54,54.11,8.74"><forename type="first">Paul</forename><surname>Clough</surname></persName>
							<email>p.clough@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<addrLine>Western Bank</addrLine>
									<postCode>S10 2TN</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.55,190.54,75.16,8.74"><forename type="first">Samuel</forename><surname>Fernando</surname></persName>
							<email>s.fernando@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<addrLine>Western Bank</addrLine>
									<postCode>S10 2TN</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.27,190.54,44.59,8.74"><forename type="first">Mark</forename><surname>Hall</surname></persName>
							<email>m.mhall@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<addrLine>Western Bank</addrLine>
									<postCode>S10 2TN</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,409.41,190.54,62.85,8.74"><forename type="first">Arantxa</forename><surname>Otegi</surname></persName>
							<email>arantza.otegi@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of the Basque Country</orgName>
								<orgName type="institution" key="instit2">UPV/EHU</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.22,202.49,69.83,8.74"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
							<email>m.stevenson@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<addrLine>Western Bank</addrLine>
									<postCode>S10 2TN</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.61,116.95,332.13,12.62;1,159.42,134.89,296.53,12.62;1,174.09,152.82,267.17,12.62">The Sheffield and Basque Country Universities Entry to CHiC: using Random Walks and Similarity to access Cultural Heritage</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">42C630DDF167DCEE3CF150A740507876</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Personalised PageRank</term>
					<term>Random Walks</term>
					<term>Information Retrieval</term>
					<term>Wikipedia</term>
					<term>WordNet</term>
					<term>Knowledge Bases</term>
					<term>Clustering</term>
					<term>Maximal Marginal Relevance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Cultural Heritage in CLEF 2012 (CHiC) pilot evaluation included these tasks: ad-hoc retrieval, semantic enrichment and variability tasks. At CHiC 2012, the University of Sheffield and the University of the Basque Country submitted a joint entry, attempting the three English monolingual tasks. For the ad-hoc task, the baseline approach used the Indri Search engine. Query expansion approaches used random walks using Personalised Page Rank over graphs constructed from Wikipedia and WordNet, and also by finding similar articles within Wikipedia. For the semantic enrichment task, random walks using Personalised Page Rank were again used. Additionally links to Wikipedia were added and further approaches used this information to find enrichment terms. Finally for the variability task, TF-IDF scores were calculated from text and meta-data fields. The final results were selected using MMR (Maximal Marginal Relevance) and cosine similarity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Cultural Heritage in CLEF 2012 (CHiC) pilot evaluation proposed these tasks: ad-hoc retrieval, semantic enrichment and variability tasks.</p><p>The University of Sheffield and the University of the Basque Country submitted a joint entry, attempting the three English monolingual tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Ad-hoc Retrieval Task</head><p>This task is a standard ad-hoc retrieval task, which measures information retrieval effectiveness with respect to user input in the form of queries. The topics are based on real Europeana<ref type="foot" coords="2,258.93,118.42,3.97,6.12" target="#foot_0">3</ref> query logs and the documents to be retrieved are metadata records of Europeana objects.</p><p>We participated in the English monolingual subtask and submitted 4 different runs: one baseline run, and other 3 runs applying query expansion.</p><p>For all our approaches, we used Indri search engine <ref type="bibr" coords="2,372.83,167.81,9.96,8.74" target="#b0">[1]</ref>, which is a part of the open-source Lemur toolkit <ref type="foot" coords="2,249.25,178.19,3.97,6.12" target="#foot_1">4</ref> . We indexed the title, subject and description fields of the Europeana objects. The Porter stemmer was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Baseline Approach</head><p>Our baseline approach is the default query likelihood language modeling method implemented in the Indri search engine. We chose the Dirichlet smoothing method, with the parameter µ set to the value 100. We refer to this approach as NOEXP run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion Approaches</head><p>Our query expansion retrieval model runs queries which contain the original terms of the query and the expansion terms. Documents are ranked by their probability of generating the whole expanded query (Q RQE ), which is given by:</p><formula xml:id="formula_0" coords="2,205.97,370.64,274.62,11.72">P RQE (Q RQE | Θ D ) = P (Q | Θ D ) w P (Q | Θ D ) 1-w<label>(1)</label></formula><p>where w is the weight given to the original query and Q is the expansion of query Q. The query likelihood probability (P (Q | Θ D )) is the one used for the baseline approach. Details about the probability of generating the expansion terms (P (Q | Θ D )) are omitted here, please, refer to <ref type="bibr" coords="2,368.37,430.42,9.96,8.74" target="#b4">[5]</ref>.</p><p>As we did not have training data, we fixed the parameters to the optimum values in other previous experiments (w = 0.7).</p><p>We use two different approaches to obtain the expansion terms.</p><p>Using Random Walks. The query expansion algorithm based on random walks over the graph representation of concepts and relations in a knowledge base to obtain concepts related to the queries. We have use this approach for two different runs. The difference between these two runs is the knowledge-base used. We have used Wikipedia for one run (EXP UKB WIKI10 is the identifier for this run), and WordNet <ref type="bibr" coords="2,453.19,555.88,10.52,8.74" target="#b1">[2]</ref> for the other one (EXP UKB WN100). In order to obtain the graph structure of Wikipedia, we simply treat the articles as vertices, and the links between articles as the edges. We represent WordNet as a graph as follows: graph nodes represent WordNet concepts (synsets) and dictionary words; relations among synsets are represented by undirected edges; and dictionary words are linked to the synsets associated to them by directed edges. We used WordNet version 3.0, with all relations provided, including the gloss relations. This was the setting obtaining the best results in a word similarity dataset as reported by <ref type="bibr" coords="3,395.10,131.95,9.96,8.74" target="#b2">[3]</ref>.</p><p>Given a query and the graph-based representation of Wikipedia or WordNet, we obtain a ranked list of related concepts as follows:</p><p>1. We first pre-process the query to obtain the lemmas and parts of speech of the open category words. 2. We then assign a uniform probability distribution to the terms found in the query. The rest of nodes are initialized to zero. 3. We compute personalized PageRank <ref type="bibr" coords="3,315.11,221.33,10.52,8.74" target="#b3">[4]</ref> over the graph, using the previous distribution as the reset distribution, and producing a probability distribution over WordNet concepts The higher the probability for a concept, the more related it is to the given document.</p><p>Basically, personalized PageRank is computed by modifying the random jump distribution vector in the traditional PageRank equation. In our case, we concentrate all probability mass in the concepts corresponding to the words in the query.</p><p>Let G be a graph with N vertices v 1 , . . . , v N and d i be the outdegree of node i; let M be a N × N transition probability matrix, where M ji = 1 di if a link from i to j exists, and zero otherwise. Then, the calculation of the PageRank vector Pr over G is equivalent to resolving Equation <ref type="bibr" coords="3,337.55,359.50,11.62,8.74" target="#b1">(2)</ref>.</p><formula xml:id="formula_1" coords="3,256.88,379.76,223.71,8.77">Pr = cM Pr + (1 -c)v<label>(2)</label></formula><p>In the equation, v is a N × 1 vector and c is the so called damping factor, a scalar value between 0 and 1. The first term of the sum on the equation models the voting scheme described in the beginning of the section. The second term represents, loosely speaking, the probability of a surfer randomly jumping to any node, e.g. without following any paths on the graph. The damping factor, usually set in the [0.85..0.95] range, models the way in which these two terms are combined at each step.</p><p>The second term on Eq. ( <ref type="formula" coords="3,268.50,483.77,4.24,8.74" target="#formula_1">2</ref>) can also be seen as a smoothing factor that makes any graph fulfill the property of being aperiodic and irreducible, and thus guarantees that PageRank calculation converges to a unique stationary distribution.</p><p>In the traditional PageRank formulation the vector v is a stochastic normalized vector whose element values are all 1  N , thus assigning equal probabilities to all nodes in the graph in case of random jumps. In the case of personalized PageRank as used here, v is initialized with uniform probabilities for the terms in the document, and 0 for the rest of terms.</p><p>PageRank is actually calculated by applying an iterative algorithm which computes Eq. ( <ref type="formula" coords="3,200.72,603.32,4.24,8.74" target="#formula_1">2</ref>) successively until a fixed number of iterations are executed. In our case, we used a publicly available implementation <ref type="foot" coords="3,368.75,613.71,3.97,6.12" target="#foot_2">5</ref> .</p><p>In order to select the expansion terms, we choose the top N highest scoring concepts. When using Wikipedia, the first 10 concepts are used as expansion terms. In the case of WordNet, we get all the words that lexicalize the first 100 concepts.</p><p>For instance, given a query like "Esperanto", this method based on Wikipedia suggests related terms or phrases like L. L. Zamenhof, interlingua, international auxiliary language and constructed language.</p><p>Using Wikipedia Similarities. For the second query expansion approach, we use the 10 concepts obtained by the WIKISIM approach for the Semantic Enrichment task (see Sec. 4). We refer to this query expansion approach as the EXP SE WIKISIM run. The approaches from our submission give the best results overall in comparison to the other submissions. The baseline NOEXP approach provides strong results. However the query expansion approaches give little improvement, or even slightly degrade performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Variability Task</head><p>The goal of this task is to present a list of 12 items that give a good overview <ref type="bibr" coords="4,134.77,528.93,10.52,8.74" target="#b6">[7]</ref> over what types of items are available for the given query. To achieve this we have investigated two methods for selecting the 12 items to display and two sources for the meta-data that the selection algorithms work on.</p><p>Indexing and searching of the collection was performed using Apache Solr <ref type="foot" coords="4,473.36,563.62,3.97,6.12" target="#foot_3">6</ref> . By default only the dc:title, dc:description, and dc:subject fields were searched and all words in the query were required to appear in those fields. Basic fully automatic query expansion was used to achieve higher recall. For singular nouns the plural form was added as a search keyword, vice-versa for plural nouns the singular form was added. If a word looked like a year, then the enrich:period label and europeana:year fields were also searched for that year. Additionally we used a very small gazetteer of place-names to identify candidate toponyms which were then searched for in the enrich:place label field.</p><p>For each of the query result documents we then calculated two TFIDF scores, one based on the textual description of the items (labelled TEXT, using dc:title, dc:description, and dc:subject fields), the other based on what we termed the meta-data facets (labelled FACET, using dc:subject, europeana:dataProvider, enrich:place label, europeana:year, europeana:type, and dcterms:medium fields). For the textual descriptions the dc:title and dc:description were sentence and word tokenised, and then stop-worded using NLTK <ref type="foot" coords="5,338.60,214.06,3.97,6.12" target="#foot_4">7</ref> . For all other fields the whole field content was used as a single token. Using the TFIDF scores the final 12 documents were then selected using either Maximal-Marginal-Relevance (MMR) <ref type="bibr" coords="5,134.77,251.50,10.52,8.74" target="#b8">[9]</ref> or cosine-similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approaches</head><p>Maximal-Marginal-Relevance The selection using MMR starts by clustering the documents using k-means. The number of clusters k is selected automatically <ref type="bibr" coords="5,159.67,320.25,9.96,8.74" target="#b5">[6]</ref>. The MMR algorithm then iterates over the resulting clusters, each time selecting a document from the cluster that is most dissimilar (using cosine similarity) to the documents that have already been selected. Additionally if a document's title is the same as a title in the list of previously selected documents, it is skipped, unless that would reduce the final number of documents to less than 12.</p><p>Cosine Similarity In the cosine similarity method we randomly select a document to be the first document. The remaining documents are then sorted by decreasing cosine similarity to the first document. From this ranking we then sample the final 12 documents at regular intervals. The results from our submission give the best results overall when compared to the other submissions. As the variability judgements have not yet been released, the quality of the results is hard to judge. However the results seem to imply that the cosine similarity produces better results if there are about 12 topics in the results and the topics have roughly the same number of items each, whereas the MMR method works better if this condition does not hold. The most likely reason for this is that the regular sampling used in the cosine similarity method breaks if the topic distribution is heavily skewed, or there are only a few topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Semantic Enrichment Task</head><p>The goal of this task is to present a ranked list of at most 10 concepts (words or phrases) for each query. These concepts should semantically enrich the query and/or guess the information need or query intent of the user. The concepts can be extracted from the Europeana data that has been provided (internal) or make use of other resources such as the Web or Wikipedia (external).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Approaches</head><p>Random walks The concepts from the UKBWIKI and UKBWN runs are obtained using Wikipedia and WordNet, respectively, following the expansion strategy based on random walks explained in Section 2.2.</p><p>Wikipedia links Two approaches attempted to find useful terms by finding inline Wikipedia links within each of the items in the collection. So for example given the text:</p><p>Hiroshima peace lanterns at Leith 1985. Leith; Ceremonies; Peace demonstrations; Eighties; War in Japan; World War II keywords Links might be added to the terms Hiroshima, Leith and World War II. The motivation behind this approach is that these added links will suggest useful keywords which co-occur with the query term and so could be used as semantic enrichments for the term.</p><p>The Wikipedia Miner software <ref type="bibr" coords="6,282.16,525.61,10.52,8.74" target="#b7">[8]</ref> was used to find the links. This software has been trained on a Wikipedia snapshot from 6th Jan 2011. The software attempts to learn from the way Wikipedia itself links to other articles. The main training features used are commonness and relatedness of anchor terms. The commonness feature measures how often a certain anchor text links to a particular article in the text (so for example 'tree' will link more often to the plant than to the more obscure computer science definition of tree). The relatedness computes how closely related the term is to others in the text that is being linked, and thus takes into account the context of the text.</p><p>The first approach used an IR engine to find items that contained the query term. The IR engine used was Apache Solr (as described in Section 3). All returned items were then run through Wikipedia Miner to markup Wikipedia links. A confidence threshold of 0.2 was used to eliminate low confidence links. The links that most often co-occurred within the items were then returned as the semantic enrichments. So for example World War II occurred frequently as a link in items containing 'Hiroshima', and so was returned as a enrichment term. This method is referred to as QUERYLINKS.</p><p>The second approach used a slightly different method. Here a previously processed version of Europeana was used which had already been run through Wikipedia Miner to find links for all items. Then instead of searching for items containing the query term using the IR engine, items that contained a link to the query term were used instead. So for example instead of searching for 'hiroshima', only items that contained a link to 'Hiroshima' were used. As with the first approach the most frequently co-occuring links were returned as the enrichment terms. One problem with this method is that sometimes very few or no items were found which contained a link to the query term. So as a fallback, a different method was used which made reference only to Wikipedia. The method found articles that were most similar to the query term, by examining the in and outlinks to and from the article and returning the article titles which contained the highest proportion of these in/outlinks. This method is referred to as WIKISIM. The UKBWIKI was the strongest run from our submission, showing the effectiveness of the random walk approach. The difference between the UKBWIKI and UKBWN results shows that the richness of Wikipedia provides a substantial benefit over WordNet. The WIKISIM and QUERYLINKS approach come around the middle of the table, with WIKISIM faring substantially better. This would seem to show that returning similar articles based on links seems to be quite effective for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>For the ad-hoc retrieval task, a strong baseline approach achieved better results than all the other submissions. The query expansion approaches presented here did not improve substantially on this performance.</p><p>Our submission for the variability task achieved the best results overall using text and facet similarity calculations to select the items to return. The MMR clustering approach proved slightly more effective than the cosine similarity measure.</p><p>For the semantic enrichment task the random walk approach proved effective, giving the 3rd and 6th overall highest precisions. The richer graph produced from Wikipedia proved to give substantially better results than using WordNet. The Wikipedia link approach gave results about midway in the table. Finding similar articles (in the WIKISIM run) proved to be slightly more effective than using the links alone (QUERYLINKS).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,184.05,309.71,247.26,72.97"><head>Table 1 .</head><label>1</label><figDesc>Mean average precision for all Ad-hoc experiments.</figDesc><table coords="4,255.87,309.71,103.61,52.10"><row><cell></cell><cell>MAP</cell></row><row><cell cols="2">EXP UKB WN100 51.61</cell></row><row><cell>NOEXP</cell><cell>51.48</cell></row><row><cell cols="2">EXP SE WIKISIM 50.96</cell></row><row><cell cols="2">EXP UKB WIKI10 50.64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,177.38,506.35,260.60,72.97"><head>Table 2 .</head><label>2</label><figDesc>Mean average precision for all Variability experiments.</figDesc><table coords="5,255.22,506.35,104.92,52.10"><row><cell></cell><cell>MAP</cell></row><row><cell cols="2">CLUSTERFACETS 23.93</cell></row><row><cell>CLUSTERTEXT</cell><cell>23.13</cell></row><row><cell>SIMFACETS</cell><cell>22.59</cell></row><row><cell>SIMTEXT</cell><cell>21.85</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,155.43,399.69,304.51,72.97"><head>Table 3 .</head><label>3</label><figDesc>Mean average precision for all Semantic Enrichment experiments.</figDesc><table coords="7,264.69,399.69,85.97,52.10"><row><cell></cell><cell>MAP</cell></row><row><cell>UKBWIKI</cell><cell>29.05</cell></row><row><cell>UKBWN</cell><cell>20.70</cell></row><row><cell>WIKISIM</cell><cell>19.29</cell></row><row><cell cols="2">QUERYLINKS 16.61</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,647.48,108.27,7.47"><p>http://www.europeana.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,658.44,127.10,7.47"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,658.44,122.39,7.47"><p>http://ixa2.si.ehu.es/ukb/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,144.73,658.44,141.22,7.47"><p>http://lucene.apache.org/solr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="5,144.73,658.44,75.32,7.47"><p>http://nltk.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The research leading to these results was carried out as part of the <rs type="projectName">PATHS</rs> project (http://paths-project.eu) funded by the <rs type="funder">European Community</rs>'s <rs type="programName">Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013</rs>) under grant agreement no. <rs type="grantNumber">270082</rs> and <rs type="projectName">KNOW2</rs> project (<rs type="grantNumber">TIN2009-14715-C04-01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_kNF9SkZ">
					<idno type="grant-number">FP7/2007-2013</idno>
					<orgName type="project" subtype="full">PATHS</orgName>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
				<org type="funded-project" xml:id="_pE9h4w9">
					<idno type="grant-number">270082</idno>
					<orgName type="project" subtype="full">KNOW2</orgName>
				</org>
				<org type="funding" xml:id="_HDQSmQz">
					<idno type="grant-number">TIN2009-14715-C04-01</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,374.72,342.24,7.86;8,146.91,385.68,333.67,7.86;8,146.91,396.64,192.63,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,358.69,374.72,121.90,7.86;8,146.91,385.68,134.01,7.86">Indri: a language-model based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,370.47,385.68,110.12,7.86;8,146.91,396.64,163.97,7.86">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="8,138.35,407.59,342.24,7.86;8,146.91,418.55,202.91,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,236.64,407.59,243.94,7.86;8,146.91,418.55,48.96,7.86">WordNet: An Electronic Lexical Database and Some of its Applications</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,429.51,342.24,7.86;8,146.91,440.47,333.68,7.86;8,146.91,451.43,169.88,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,434.23,429.51,46.36,7.86;8,146.91,440.47,329.20,7.86">A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kravalova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,158.44,451.43,64.50,7.86">Proc. of NAACL</title>
		<meeting>of NAACL<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,462.39,342.24,7.86;8,146.91,473.35,69.62,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,210.13,462.39,98.03,7.86">Topic-sensitive pagerank</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,328.89,462.39,40.22,7.86">WWW 02</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">517526</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,484.31,342.24,7.86;8,146.91,495.27,333.68,7.86;8,146.91,506.22,143.40,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,284.02,484.31,196.56,7.86;8,146.91,495.27,45.74,7.86">Query Expansion for IR using Knowledge-Based Relatedness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Otegi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Arregi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,198.91,495.27,281.69,7.86;8,146.91,506.22,40.95,7.86">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1467" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,517.18,342.24,7.86;8,146.91,528.14,285.91,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,269.92,517.18,173.91,7.86">Finding the Number of Clusters in a Dataset</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Sugar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.24,517.18,30.35,7.86;8,146.91,528.14,157.86,7.86">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">463</biblScope>
			<biblScope unit="page" from="750" to="763" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,539.10,342.24,7.86;8,146.91,550.06,308.50,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,275.46,539.10,201.35,7.86">The notion of overview in information visualization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hertzum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,146.91,550.06,204.52,7.86">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="509" to="525" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,561.02,342.24,7.86;8,146.91,571.98,333.68,7.86;8,146.91,582.94,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,253.07,561.02,132.84,7.86">Learning to Link with Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,405.52,561.02,75.08,7.86;8,146.91,571.98,268.27,7.86">Proceedings of the 17th ACM conference on Information and Knowledge Management</title>
		<meeting>the 17th ACM conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="509" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,593.90,342.24,7.86;8,146.91,604.85,333.68,7.86;8,146.91,615.81,333.68,7.86;8,146.91,626.77,266.63,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,283.20,593.90,197.39,7.86;8,146.91,604.85,190.60,7.86">The use of MMR, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,355.88,604.85,124.71,7.86;8,146.91,615.81,333.68,7.86;8,146.91,626.77,81.49,7.86">Proceedings of the 21st Annual international ACM SIGIR Conference on Research and Development in information Retrieval. SIGIR &apos;98</title>
		<meeting>the 21st Annual international ACM SIGIR Conference on Research and Development in information Retrieval. SIGIR &apos;98<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
