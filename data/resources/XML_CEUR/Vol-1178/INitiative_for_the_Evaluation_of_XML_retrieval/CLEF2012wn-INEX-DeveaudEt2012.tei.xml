<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,179.06,117.75,257.24,12.62;1,224.37,135.68,166.60,12.62">LIA/LINA at the INEX 2012 Tweet Contextualization track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.42,174.65,74.72,8.74"><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
							<email>romain.deveaud@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">LIA -University of Avignon</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.30,174.65,66.17,8.74"><forename type="first">Florian</forename><surname>Boudin</surname></persName>
							<email>florian.boudin@univ-nantes.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">LINA -University of Nantes</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,179.06,117.75,257.24,12.62;1,224.37,135.68,166.60,12.62">LIA/LINA at the INEX 2012 Tweet Contextualization track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CBC0C325AE4FB308B6C7A35FA04DDB95</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our participation in the INEX 2012 Tweet Contextualization track and present our contributions. We combined Information Retrieval, Automatic Summarization and Topic Modeling techniques to provide the context of each tweet. We first formulate a specific query using hashtags and important words in the Tweets to retrieve the most relevant Wikipedia articles. Then, we segment the articles into sentences and compute several measures for each sentence, in order to estimate their contextual relevance to the topics expressed by the Tweets. Finally, the best scored sentences are used to form the context. Official results suggest that our methods performed very well compared to other participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The INEX Tweet Contextualization tracks aims at providing a small bunch of text (less than 500 words) that gives insights or additional information about a given tweet. For example, when reading a tweet about Whitney Houston's funerals, the user might want to know who is this person, why is she famous and so on... One of the strict constraint was to extract this context from a Wikipedia collection provided by the organizers, so there were several challenges to tackle.</p><p>First, it was very important to retrieve relevant and important Wikipedia articles that were related to the Tweets, and that were likely to provide some useful context. Second, considering the word limit of the contexts, only very little parts of these articles had to be kept. For this purpose we segmented the top-ranked articles into sentences and used several measures to score them. These measures range from classic word overlap or cosine similarity to conceptual similarity using topic models.</p><p>The rest of the paper is organized as follows. Section 2 describes the process we followed to extract candidate sentences, which includes Tweet formatting and document retrieval on Wikipedia. Then, we describe in Section 3 the various sentence scoring methods we used in this work.</p><p>Considering that the task is to provide context from Wikipedia text, one crucial step was to retrieve Wikipedia articles that are highly relevant to the Tweet. Hopefully, relevant articles contain important sentences that give lots of contextual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">#HashtagSplitting and Tweet formatting</head><p>Hashtags in Tweets are very important pieces of information, since they are tags that were generated by the user. Making a parallel with TREC-like topics, we can view the hashtags as the title while the Tweet itself is the description.</p><p>However the main problem with hashtags is that they often are composed of several words concatenated together (e.g. #WhitneyHouston). We used an algorithm based on Peter Novig's chapter on "Natural Language Corpus Data" in <ref type="bibr" coords="2,146.64,290.04,10.52,8.74" target="#b4">[5]</ref> to split the hashtags. For each Tweet, all the hashtags we converted into a short keyword query.</p><p>We also removed all the retweet mentions (RT), user mentions (@somebody) and stopwords (based on the standard INQUERY stoplist) from the Tweets. The final output of this Tweet formatting process is a clean Tweet without stopwords or useless mentions, as well as a very short and user-generated representation of this Tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieving Wikipedia articles</head><p>Retrieving relevant Wikipedia articles is the first crucial part for finding contextually relevant sentences. For this purpose we use the well-known Markov Random Field model <ref type="bibr" coords="2,229.42,427.98,10.52,8.74" target="#b2">[3]</ref> to represent dependencies between query words. It has indeed performed consistently well on several variety of ad-hoc search tasks across the years.</p><p>Given an initial Tweet T , the output of the method described in the previous section is a set of hashtags H T and a set of terms Q T . We then score Wikipedia articles D according to the following function:</p><formula xml:id="formula_0" coords="2,160.91,516.94,293.54,9.65">s(H T , Q T , D) = λ × score M RF (H T , D) + (1 -λ)score M RF (Q T , D)</formula><p>where λ is a free smoothing parameter which was empirically set to 0.8 for all our experiments. We used the Sequential Dependance Model instantiation of MRF, which is defined as follows:</p><formula xml:id="formula_1" coords="2,214.86,575.29,185.64,93.97">score M RF (Q, D) = λ T q∈Q f T (q, D) + λ O |Q|-1 i=1 f O (q i , q i+1 , D) + λ U |Q|-1 i=1 f U (q i , q i+1 , D)</formula><p>where the features weights are set according to the author's recommendation (λ T = 0.85, λ O = 0.1, λ U = 0.05). f T , f O and f U are the log maximum likelihood estimates of query terms in document D, computed over the target collection with a Dirichlet smoothing (µ = 2500).</p><p>From the ranked list of Wikipedia articles, we only consider the 5 top articles as relevant. The underlying assumption is that a Tweet may discuss only a very limited amount of topics, due to the 140 characters limit. Since encyclopedic topics are very well delimited between Wikipedia articles, we thought 5 articles would treat roughly 4-5 to 10 different topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sentence scoring</head><p>After selecting the 5 best ranked Wikipedia articles with respect to a Tweet T , the next step is sentence segmentation. Each article is split into sentences which are the context candidates. We describe in this section the various scoring methods we used to estimate their importance with respect to the Tweet context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Automatic summarization</head><p>First, we used some NLP scores that are widely used in the field of automatic summarization. For each candidate sentence S we computed:</p><p>the word overlap between S and Q T , and between S and H T , the cosine similarity between S and Q T , and between S and H T , the TextRank <ref type="bibr" coords="3,213.19,411.15,10.52,8.74" target="#b3">[4]</ref> score of S in the context of the article from which it belongs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Conceptual similarity</head><p>We the conceptual similarity measure, we wanted to estimate at which point a candidate sentence is close to a thematic or a topic that may be related to the Tweet. We used two sources from which we extracted the concepts: Wikipedia and the Web.</p><p>The Wikipedia source is a dump from July 2011 of the online encyclopedia that contains 3,214,014 documents<ref type="foot" coords="3,305.43,518.56,3.97,6.12" target="#foot_0">1</ref> . For the Web source, we removed the spammed documents from the category B of the ClueWeb09 according to a standard list of spams for this collection<ref type="foot" coords="3,290.00,542.47,3.97,6.12" target="#foot_1">2</ref> . We followed authors recommendations <ref type="bibr" coords="3,470.08,544.05,10.52,8.74" target="#b1">[2]</ref> and set the "spamminess" threshold parameter to 70. The resulting corpus is composed of 29,038,220 web pages.</p><p>We model the concepts using Latent Dirichlet Allocation <ref type="bibr" coords="3,409.38,579.91,9.96,8.74" target="#b0">[1]</ref>, a generative probabilistic topic model. We want to model topics that are highly related to the Tweet, hence we perform LDA on the top-ranked Wikipedia or Web documents originally retrieved using the scoring function defined in 2.2. The documents of the collection are modeled as mixtures over K topics each of which is a multinomial distribution over the vocabulary W . Each topic multinomial distribution φ k is generated by a conjugate Dirichlet prior with parameter β, while each document multinomial distribution θ d is generated by a conjugate Dirichlet prior with parameter α. Thus, the topic proportions for document d are θ d , and the word distributions for topic k are φ k . In other words, θ d,k is the probability of topic k occurring in document d (i.e. P (k|d)). Respectively, φ k,w is the probability of word w belonging to topic k (i.e. P (w|k)).</p><p>In our sense, a concept is a topic generated by LDA from these top-ranked and supposedly highly relevant documents. Given a sentence S, a Tweet T and the learned topics K T , the conceptual score of S is given by:</p><formula xml:id="formula_2" coords="4,177.64,253.12,250.30,27.49">σ(S) = 1 |K T | k∈K T d P (k|d)P (d|T ) w∈W p(w|k) log N df w</formula><p>where N is the total number of documents in the collection, and df w is the document frequency of w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Tweeted URLs as context</head><p>A large part of the Tweets of the collection come along with an URL. This URL is the most important piece of context available, however the organizers judged to label as "manual" all the runs that used this information. We were not aware of this limitation and computed measures that are similar to the automatic summarization ones. When a URL is present in the Tweet, we download the page and extract its title as well as the content of the body. For each candidate sentence S we computed:</p><p>the word overlap between S and the title of the web page, and between S and the body content of the web page, the cosine similarity between S and the title of the web page, and between S and the body content of the web page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Forming context</head><p>Our three runs follow the three types of measures we described above. After every sentence have been attributed a score, they are ordered and the top-ranked sentences are selected to form context (within the limit of 500 words).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper we presented our contributions to the INEX 2012 Tweet Contextualization Track. We used various techniques involving automatic summarization and topic modeling algorithms to score the candidate sentences.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,647.48,202.42,7.47"><p>http://dumps.wikimedia.org/enwiki/20110722/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,658.44,225.95,9.21"><p>http://plg.uwaterloo.ca/ ~gvcormac/clueweb09spam/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,143.58,342.25,7.86;5,146.91,154.54,189.94,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,372.62,143.58,104.18,7.86">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,146.91,154.54,83.60,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,165.50,342.24,7.86;5,146.91,176.46,305.24,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,369.83,165.50,110.76,7.86;5,146.91,176.46,183.41,7.86">Efficient and effective spam filtering and re-ranking for large web datasets</title>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,338.35,176.46,85.91,7.86">Information Retrieval</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,187.42,342.24,7.86;5,146.91,198.38,333.68,7.86;5,146.91,209.34,333.67,7.86;5,146.91,220.30,117.25,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,296.92,187.42,183.67,7.86;5,146.91,198.38,27.38,7.86">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,193.01,198.38,287.58,7.86;5,146.91,209.34,247.12,7.86">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,231.26,342.24,7.86;5,146.91,242.21,333.68,7.86;5,146.91,253.17,101.43,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,274.37,231.26,133.75,7.86">Textrank: Bringing order into text</title>
		<author>
			<persName coords=""><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,424.82,231.26,55.78,7.86;5,146.91,242.21,333.68,7.86;5,146.91,253.17,10.75,7.86">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;04</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,264.13,342.25,7.86;5,146.91,275.09,153.73,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="5,306.39,264.13,174.21,7.86;5,146.91,275.09,58.04,7.86">Beautiful Data: The Stories Behind Elegant Data Solutions</title>
		<author>
			<persName coords=""><forename type="first">Toby</forename><surname>Segaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeff</forename><surname>Hammerbacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
