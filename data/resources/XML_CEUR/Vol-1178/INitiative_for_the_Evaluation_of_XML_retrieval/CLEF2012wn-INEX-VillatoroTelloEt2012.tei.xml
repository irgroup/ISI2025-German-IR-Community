<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.24,115.72,338.92,12.93;1,190.80,133.72,233.74,12.93;1,232.32,151.60,144.39,12.93;1,376.68,151.47,5.73,7.50">UAM at INEX 2012 Relevance Feedback Track: Using a Probabilistic Method for Ranking Refinement ⋆</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.00,189.19,86.59,9.62"><forename type="first">Esaú</forename><surname>Villatoro-Tello</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technologies Dept</orgName>
								<orgName type="laboratory">Language and Reasoning Group</orgName>
								<orgName type="institution" key="instit1">Universidad Autónoma Metropolitana (UAM)</orgName>
								<orgName type="institution" key="instit2">Unidad Cuajimalpa</orgName>
								<address>
									<settlement>City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.84,189.19,114.56,9.62"><forename type="first">Christian</forename><surname>Sánchez-Sánchez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technologies Dept</orgName>
								<orgName type="laboratory">Language and Reasoning Group</orgName>
								<orgName type="institution" key="instit1">Universidad Autónoma Metropolitana (UAM)</orgName>
								<orgName type="institution" key="instit2">Unidad Cuajimalpa</orgName>
								<address>
									<settlement>City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.24,189.19,100.92,9.62"><forename type="first">Héctor</forename><surname>Jiménez-Salazar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technologies Dept</orgName>
								<orgName type="laboratory">Language and Reasoning Group</orgName>
								<orgName type="institution" key="instit1">Universidad Autónoma Metropolitana (UAM)</orgName>
								<orgName type="institution" key="instit2">Unidad Cuajimalpa</orgName>
								<address>
									<settlement>City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,177.12,201.07,116.81,9.62"><forename type="first">Wulfrano</forename><forename type="middle">A</forename><surname>Luna-Ramírez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technologies Dept</orgName>
								<orgName type="laboratory">Language and Reasoning Group</orgName>
								<orgName type="institution" key="instit1">Universidad Autónoma Metropolitana (UAM)</orgName>
								<orgName type="institution" key="instit2">Unidad Cuajimalpa</orgName>
								<address>
									<settlement>City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.36,201.07,117.30,9.62"><forename type="first">Carlos</forename><surname>Rodríguez-Lucatero</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Technologies Dept</orgName>
								<orgName type="laboratory">Language and Reasoning Group</orgName>
								<orgName type="institution" key="instit1">Universidad Autónoma Metropolitana (UAM)</orgName>
								<orgName type="institution" key="instit2">Unidad Cuajimalpa</orgName>
								<address>
									<settlement>City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.24,115.72,338.92,12.93;1,190.80,133.72,233.74,12.93;1,232.32,151.60,144.39,12.93;1,376.68,151.47,5.73,7.50">UAM at INEX 2012 Relevance Feedback Track: Using a Probabilistic Method for Ranking Refinement ⋆</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC1345E3E2B4990999587405817C4A42</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the system developed by the Language and Reasoning Group of UAM for the Relevance Feedback track of INEX 2012. The presented system focuses on the problem of ranking documents in accordance to their relevance. It is mainly based on the following hypotheses: (i) current IR machines are able to retrieve relevant documents for most of general queries, but they can not generate a pertinent ranking; and (ii) focused relevance feedback could provide more and better elements for the ranking process than isolated query terms. Based on these hypotheses, our participation at INEX 2012 aimed to demonstrate that using some query-related relevance feedback it is possible to improve the final ranking of the retrieved documents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information Retrieval (IR) deals with the representation, storage, organization, and access to information items 1 <ref type="bibr" coords="1,283.56,461.59,9.99,9.62" target="#b0">[1]</ref>. Given some query, formulated in natural language by a user, the IR system is suppose to retrieve and sort according to their relevance degree documents satisfying user's information needs <ref type="bibr" coords="1,435.72,485.47,9.99,9.62" target="#b3">[4]</ref>.</p><p>The word relevant means that retrieved documents should be semantically related to the user information need. Hence, one main problem of IR is determining which documents are, and which are not relevant. In practice this problem is usually regarded as a ranking problem, whose goal is to define an ordered list of documents such that documents similar to the query occur at the very first positions.</p><p>Over the past years, IR Models, such as: Boolean, Vectorial, Probabilistic and Language models have represented a document as a set of representative keywords (i.e., index terms) and defined a ranking function (or retrieval function) to associate a relevance degree for each document with its respective query <ref type="bibr" coords="2,470.04,118.63,10.56,9.62" target="#b0">[1,</ref><ref type="bibr" coords="2,134.76,130.63,7.04,9.62" target="#b3">4]</ref>. In general, these models have shown to be quite effective over several tasks in different evaluation forums (CLEF<ref type="foot" coords="2,286.92,140.81,3.97,6.97" target="#foot_1">2</ref> and TREC <ref type="foot" coords="2,343.44,140.81,3.97,6.97" target="#foot_2">3</ref> ). Nevertheless, these retrieval systems still fail at retrieving most of the relevant documents to a given query in the first positions. The latter is due to the fact that modelling user intentions from queries is, in general, a highly subjective and difficult task, hence, postprocessing and ranking refinement strategies have been adopted <ref type="bibr" coords="2,416.52,190.39,12.55,9.62" target="#b11">[12]</ref><ref type="bibr" coords="2,429.07,190.39,4.18,9.62" target="#b12">[13]</ref><ref type="bibr" coords="2,429.07,190.39,4.18,9.62" target="#b13">[14]</ref><ref type="bibr" coords="2,433.26,190.39,12.55,9.62" target="#b14">[15]</ref>.</p><p>Post-retrieval techniques aim at refining retrieval results by means of feature re-weighting, query modification, document re-ranking and relevance feedback. The common idea is to interact with the user in order to learn or to improve a model of the underlying user's information need. Acceptable results have been obtained with such methods, however, they still have several limitations, including: i) the need of extensive user interaction <ref type="foot" coords="2,326.52,260.45,3.97,6.97" target="#foot_3">4</ref> ; ii) multiple execution of retrieval models; iii) the on-line construction of classification methods; iv) the lack of contextual information in the post-retrieval processing, which may be helpful for better modelling users' information needs; and v) the computational cost that involves processing the entire collection of documents each feedback iteration.</p><p>Document re-ranking or ranking refinement in information retrieval has been a widely research topic during the last fifthteen years. There are two main approaches for this task: i) indirect re-ranking via some query expansion strategy, and ii) direct re-ranking on initial retrieved documents <ref type="bibr" coords="2,386.76,369.67,14.69,9.62" target="#b14">[15]</ref>. Normally, query expansion strategies assume that top ranked documents are more likely to be relevant, the terms contained within these documents can be used to augment the original query and then a better ranking can be expected via a second retrieval process. In contrast, direct re-ranking strategies try to improve the ranking of the initial set of retrieved documents by directly adjusting their positions without the need of performing a second retrieval process, normally, this type of strategy use the information contained within the retrieved documents (e.g., inter-document similarities) to generate a better ranking of them. The generated output (i.e., a list of ranked documents) by any of this two strategies would be of obvious benefit to users, for example, direct ranking refinement can be used to improve automatic query expansion since a better ranking in the top retrieved documents can be expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Our approach</head><p>Our participation at the INEX 2012 Relevance feedback track proposes using an alternative post-retrieval technique that aims at improving the results provided by a document retrieval system and that overcomes some of the limitations of current post-retrieval methods. Our work classifies as a direct document ranking refinement strategy. In particular we face the problem of re-ranking<ref type="foot" coords="3,437.52,140.81,3.97,6.97" target="#foot_4">5</ref> a list of documents retrieved by some information retrieval system. This problem is motivated by the availability of retrieval systems that present high-recall and lowprecision performance, which evidences that the corresponding retrieval system is in fact able to retrieve many relevant documents but has severe difficulties to generate a pertinent ranking of them. Hence, given a list of ranked documents, the problem we approach consists of moving relevant documents to the first positions and displacing irrelevant ones to the final positions in the list.</p><p>We propose a solution to the ranking refinement problem based on a Markov Random Field (MRF) <ref type="bibr" coords="3,233.64,252.55,10.56,9.62" target="#b4">[5,</ref><ref type="bibr" coords="3,245.76,252.55,7.80,9.62" target="#b8">9,</ref><ref type="bibr" coords="3,255.24,252.55,7.80,9.62" target="#b5">6,</ref><ref type="bibr" coords="3,264.60,252.55,8.56,9.62" target="#b15">16</ref>] that aims at classifying the ranked documents as relevant or irrelevant. Each document in the retrieved list is associated to a binary random variable in the MRF (i.e., a node), the value of each random variable indicates whether a document is considered relevant (when its value is 1) or not (when its value is 0). The MRF considers several aspects: 1) the information provided by the base information retrieval system, 2) similarities among retrieved documents in the list, and 3) information obtained through a relevance feedback process. Accordingly, we reduce the problem of ranking refinement to that of minimizing an energy function that represents a tradeoff between document relevance and inter-document similarity. The information provided by the information retrieval system is the base of our method, which is further enriched with contextual and relevance feedback information.</p><p>Our motivation for considering context information is that relevant documents to a query will be similar to each other and to its respective query, to some extent; whereas irrelevant documents will be different among them and not as similar to the query as the relevant documents <ref type="foot" coords="3,370.56,432.65,3.97,6.97" target="#foot_5">6</ref> . Relevance feedback information has two main purposes: i) to work as a seed generation mechanism for propagating the relevancy/irrelevancy status of nodes (documents) in the MRF, and ii) to denote the users' search intention by working as example texts.</p><p>At this point it is important to mention that, traditionally a relevance feedback process takes as input a set of n documents (tentatively relevant) and generates as output a set of k isolated terms (tentatively relevant to the query) which are further employed for a query expansion process. For our purposes we will employ all the information contained in the feedback (called example texts) since by doing this we have showed <ref type="bibr" coords="3,288.12,544.39,13.17,9.62" target="#b11">[12]</ref><ref type="bibr" coords="3,301.28,544.39,4.39,9.62" target="#b12">[13]</ref><ref type="bibr" coords="3,305.67,544.39,13.17,9.62" target="#b13">[14]</ref> that it is possible to make a more accurate approximation of the users' search intention (i.e., to become into a more explicit representation the implicit information contained in the query).</p><p>The proposed MRF does not require of multiple executions of IR models, nor training classification methods, and it can work without user intervention; therefore, our MRF overcomes the main limitations of current post-processing techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Structure of the paper</head><p>The rest of the paper is organized as follows. Section 2 introduces the proposed Markov Random Field for ranking refinement in document retrieval. Section 3 describes the experimental platform used to evaluate and compare our ranking strategy. Section 4 presents the experimental results. Finally, section 5 depicts our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>A general outline of the proposed method is given in Figure <ref type="figure" coords="4,404.64,275.23,3.90,9.62" target="#fig_0">1</ref>. Given a query, the IR system retrieves from a given collection of documents a list of files sorted according to a relevance criteria. From this list, some relevant documents are selected based on a relevance feedback approach <ref type="foot" coords="4,352.56,309.41,3.97,6.97" target="#foot_6">7</ref> . For each document in the list, the textual features are extracted. The text contained in each document in the list, the query given by the user, and a subset of information selected via relevance feedback, are combined to produce a re-ordered list. This re-ranking is obtained based on a Markov random field (MRF) model that separates the relevant documents from irrelevant ones, generating a new list by positioning the relevant documents first, and the others after. Next we give a brief review of MRFs, and then we describe in detail each component of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Markov Random Fields</head><p>Markov Random Fields (MRF) are a type of undirected probabilistic graphical models that aim at modelling dependencies among variables of the problem in turn <ref type="bibr" coords="4,155.88,464.11,10.56,9.62" target="#b4">[5,</ref><ref type="bibr" coords="4,168.12,464.11,7.80,9.62" target="#b8">9,</ref><ref type="bibr" coords="4,177.48,464.11,7.80,9.62" target="#b5">6,</ref><ref type="bibr" coords="4,186.96,464.11,11.70,9.62" target="#b15">16]</ref>. MRFs have a long history within image processing and computer vision <ref type="bibr" coords="4,163.56,476.11,9.99,9.62" target="#b6">[7]</ref>. They were first proposed for denoising digital images <ref type="bibr" coords="4,417.24,476.11,10.56,9.62" target="#b4">[5,</ref><ref type="bibr" coords="4,429.36,476.11,7.80,9.62" target="#b8">9,</ref><ref type="bibr" coords="4,438.83,476.11,7.80,9.62" target="#b5">6,</ref><ref type="bibr" coords="4,448.20,476.11,12.84,9.62" target="#b15">16]</ref> and since then a large number of applications and extensions have been proposed.</p><p>MRF modelling has appealing features for problems that involve the optimization of a configuration of variables that have interdependencies among them. Accordingly, MRFs allow the incorporation of contextual information in a principled way. MRFs rely on a strict probabilistic modelling, yet they allow the incorporation of prior knowledge by means of potential functions. For those reasons, in this paper we adopted an MRF model for refining the initial ranking of a set of documents retrieved by some IR system. The rest of this sections summarizes the formalism of MRFs.</p><p>An MRF is a set of random variables F = {f 1 , ..., f N } indexed by sites or nodes where the following conditions hold: </p><formula xml:id="formula_0" coords="4,267.60,626.24,213.03,10.58">P (f i ) ≥ 0, ∀f i ∈ F<label>(1)</label></formula><formula xml:id="formula_1" coords="5,247.80,347.96,232.83,10.94">P (f i |f S-{i} ) = P (f i |N (f i ))<label>(2)</label></formula><p>where N (f i ) is the set of neighbours of f i according to the neighbouring system N . Formula 1 is the so called positivity condition and avoids negative probability values, whereas expression 2 states that the value of a random variable depends only on the set of neighbours of that variable. It has been shown that an MRF follows a Gibbs distribution <ref type="bibr" coords="5,428.28,412.03,9.99,9.62" target="#b2">[3]</ref>, where a Gibbs distribution of the possible configurations of F with respect to N has the following form:</p><formula xml:id="formula_2" coords="5,255.48,444.88,225.14,12.65">P (F ) = Z -1 × e -1 T E(F )<label>(3)</label></formula><p>where Z is a normalization constant and the T is the so called temperature parameter (a common choice is T = 1) and E(F ) is an energy function of the following form:</p><formula xml:id="formula_3" coords="5,180.84,507.07,299.79,21.24">E(F ) = c∈C V c (f ) = {i}∈C1 V 1 (f i ) + {i,j}∈C2 V 2 (f i , f j ) + . . .<label>(4)</label></formula><p>where ". . . " denotes possible potentials V c defined over higher order neighbourhoods C 3 , C 4 . . . . , C K ; each C i defines a neighbourhood system of order i between the nodes of the MRF. Often the set F is considered the union of two subsets of random variables X ∪ Y ; where X is the set of observed variables and Y is the set of output variables, which state we would like to predict. Potentials V c are problem dependent and commonly learned from data. One of the main problems in MRFs is that of selecting the most probable configuration of F (i.e., an assignment of values to each variable f i of the field). Such configuration is determined by the configuration of F that minimizes expression 4, for which a diversity of optimization techniques have been adopted <ref type="bibr" coords="5,134.76,655.75,10.56,9.62" target="#b4">[5,</ref><ref type="bibr" coords="5,147.00,655.75,7.80,9.62" target="#b8">9,</ref><ref type="bibr" coords="5,156.36,655.75,7.80,9.62" target="#b5">6,</ref><ref type="bibr" coords="5,165.72,655.75,11.70,9.62" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Proposed Model</head><p>In our case we consider a MRF in which each node corresponds to a document in the list. Each document is represented as a random variable with 2 possible values: relevant and irrelevant. We consider a fully connected graph, such that each node (document) is connected to all other nodes in the field; that is, we defined a neighbourhood scheme in which each variable is adjacent to all the others. Given that the number of documents in the list is relatively low (100, 300 and 1000 in the experiments), to consider a complete graph is not a problem computationally, and allows us to consider the relations between all documents in the list.</p><p>For representing the documents, and evaluating the internal and external similarities, we consider all the words contained in each document (except stopwords), it is worth mentioning that we did applied a stemming process to all documents. To describe the documents we used a binary bag of words (BOW) representation, in which each vector element represents a word from the collection vocabulary; and the example texts are represented in the same manner. The internal and external similarities are considered via the energy function described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Energy Function</head><p>The energy function of the MRF combines two factors: the similarity between the documents in the list (internal similarity); and external information obtained from the original order and the similarity of each document with the provided feedback (external similarity). The internal similarities correspond to the interaction potentials and the external similarities to the observation potentials. The proposed energy function takes into account both aspects and is defined as follows:</p><formula xml:id="formula_4" coords="6,240.96,483.80,239.66,10.58">E(F ) = λV c (f ) + (1 -λ)V a (f )<label>(5)</label></formula><p>Where V c is the interaction potential and it considers the similarity between random variable f and its neighbours, representing the support that neighboring variables give to f . V a is the observation potential and represents the influence of external information on variable f . The weight factor λ favours V c (λ &gt; 0), V a (λ = 0), or both (λ = 0.5).</p><p>V c is defined as:</p><formula xml:id="formula_5" coords="6,216.36,584.95,264.26,24.02">V c (f ) = Ȳ + (1 -X) if f = irrelevant X + (1 -Ȳ ) if f = relevant<label>(6)</label></formula><p>Where Ȳ represents the average distance between variable f and its neighbours with irrelevant value. X represents the average distance between variable f and its neighbors with relevant value. The distance metric used to measure the similarity between variables is defined as: 1dice(f, g), where dice(f, g) represents the Dice coefficient <ref type="bibr" coords="7,271.20,118.75,9.99,9.62" target="#b7">[8]</ref>, and is defined as: dice(f, g) = 2|f ∩g| |f ∪g| . V a is defined as follows:</p><formula xml:id="formula_6" coords="7,178.08,151.52,302.55,35.17">V a (f ) =    (1 -dist(f, e)) × g(posinv(f )) if f = irrelevant dist(f, e) × g(pos(f )) if f = relevant<label>(7)</label></formula><p>The V a potential is obtained by combining two factors. The first indicates how similar, dist(f, e), or different, 1dist(f, e) is the f variable with the example texts (e) (i.e., the information provided by the feedback). Where dist(f, e) is defined as: 1dice(f, e). The second is a function that converts the position in the list given by a base IR machine to a real value. The function used g(x) = exp(x/100)/exp <ref type="bibr" coords="7,234.68,253.99,14.47,9.62" target="#b4">(5)</ref> [2]<ref type="foot" coords="7,262.92,252.29,3.97,6.97" target="#foot_7">8</ref> . The function pos(f ) returns the position of the document f in the original list, posinv(f ) returns the inverse position of the f variable in this list.</p><p>Having described each potential, the proposed energy function is defined as:</p><formula xml:id="formula_7" coords="7,134.76,317.95,356.40,48.14">E(F ) =    λ Ȳ + (1 -X) + (1 -λ)[1 -dist(f, e)) × g(posinv(f )] if f = irrelevant λ X + (1 -Ȳ ) + (1 -λ)dist(f, e) × g(pos(f )) if f = relevant<label>(8)</label></formula><p>The initial configuration of the MRF is obtained by relevance feedback. That is, the subset of documents that contain relevant passages selected via relevance feedback are initialized as relevant, and all other documents as irrelevant. Then, the MRF configuration of minimum energy (MAP) is obtained via stochastic simulation using the ICM algorithm. At the end of this optimization process, each variable (document) has a value of relevant or irrelevant. Based on these values, a new re-ordered list is produced, by positioning first the relevant documents according to the MRF, and then the not-relevant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In this section we describe the experimental setup that we employed for the proposed method during the INEX 2012 competition. A brief description of the base IR system used is given as well as its configuration. Besides this, we describe an additional ranking refinement strategy employed in our submitted runs, as well as the documents collection and the evaluation measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Base IR System</head><p>As we have mentioned before, our ranking refinement strategy does not depend on any particular IR system. However, in order to perform our experiments we employed as base IR system the well known information retrieval system LEMUR-INDRI. This system is part of the Lemur Project<ref type="foot" coords="8,392.52,128.93,3.97,6.97" target="#foot_8">9</ref> started in 2000 by the Center for Intelligent Information Retrieval (CIIR) at the University of Massachusetts, Amherst, and the Language Technologies Institute (LTI) at Carnegie Mellon University. Particularly the LEMUR-INDRI toolkit is a search engine that provides state-of-the-art text search facilities, a rich structured query language for different text collections, and is considered as a robust system capable of producing comparable results to new IR schemes.</p><p>For all our experiments, the collections were indexed by this tool using a probabilistic language model. For this purpose, collections were preprocessed by applying stop word elimination as well as a stemming process. For our experiments we employed a list of 571 stop words available in the CLEF site <ref type="foot" coords="8,469.44,248.93,7.93,6.97" target="#foot_9">10</ref> . Additionally, for the stemming process we employed the well known Porter algorithm <ref type="bibr" coords="8,172.44,274.51,14.69,9.62" target="#b9">[10]</ref>.</p><p>As baseline results we considered the performance obtained under this configuration employing the LEMUR-INDRI search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Expansion via Relevance Feedback</head><p>A query expansion via relevance feedback process is a controlled technique which main goal is to reformulate a query. In other words, a relevance feedback strategy is normally a previous step for a query expansion (QE) process. The basic idea is to select a set of k words which are related to a set of documents that have been previously retrieved and tagged as relevant by some user. Further, this words are added to the original query <ref type="bibr" coords="8,282.36,412.87,14.69,9.62" target="#b10">[11]</ref>. In order to apply a relevance feedback process it is necessary to perform a first search (i.e., a first retrieval process) which generates an ordered list of documents. Afterwards, the user selects from the first positioned documents those that he considers as relevant (i.e., the user establishes the documents' relevance). This relevance judgements that the user just gave to the documents are employed to compute a new set of values that indicate in a more accurate form the impact of each word in the original query <ref type="foot" coords="8,469.44,482.93,7.93,6.97" target="#foot_10">11</ref> .</p><p>As an alternative solution, we performed some experiments applying a QE process. For this, every time some feedback was given, we selected the k most frequent/less frequent words for its addition to the original query in order to perform a new retrieval process. Among the disadvantages of QE is the computational cost implied, since it is necessary to perform a second retrieval process. Besides this, relevance feedback strategies have shown to be sensitive to the quality of the added words, since adding an irrelevant word could be very harmful for the IR system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data set</head><p>In the framework of the INEX 2012 Relevance Feedback track we were provided with the Wikipedia XML Corpus as the test collection. This collection was created from the October 8, 2008 dump of the English Wikipedia articles, and contains 2,666,190 articles, which represent more that than 50 GiB of disk space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation</head><p>The evaluation of results was carried out using a measure that has demonstrated its pertinence to compare IR systems, namely, the Mean Average Precision (MAP ). MAP is defined as follows:</p><formula xml:id="formula_8" coords="9,218.04,275.33,170.55,31.73">M AP = 1 |Q| |Q| i=1 m r=1 P i (r) × rel i (r)<label>n</label></formula><p>Where P i (r) is the precision at the first r documents, rel i (r) is a binary function which indicates if document at position r is relevant or not for the query i; n is the total number of relevant documents for the query i, m is the number of relevant documents retrieved and Q is the set of all queries. Intuitively, this measure indicates how well the system puts into the first positions relevant documents. It is worth pointing out that since our IR system was configured to retrieve 1000 documents per query, MAP values are measured at 1000 documents.</p><p>On the other hand, P@N is defined as the percentage of retrieved relevant items at the first N positions of the result list. Finally R -P rec is defined as the precision at R-th position in the ranking of results for a query that has R relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Experiments definition</head><p>The use-case of the INEX 2012 relevance feedback track is as follows: assume a single user searching with a particular query in an information retrieval system that supports relevance feedback. The user highlights relevant passages of text in returned documents (if any) and provides this feedback to the information retrieval system. The IR system re-ranks the remainder of the unseen results list in order to provide more relevant results to the user.</p><p>Accordingly, we conducted a series of experiments with the following objectives: i) to test the results of the proposed method compared with the traditional re-ranking strategies, ii) to evaluate the sensitivity of the method to the model parameters.</p><p>We defined 10 different configurations, which are described below:</p><p>-BASE-IND: represents the experiment performed using just the INDRI IR machine. For this experiment, if some feedback is provided, the feedback is ignored and the next retrieved document is showed.</p><p>-BASE-IND-QE20tMF: this experiment was performed using a QE strategy as re-ranking method. Once an initial documents list is provided by INDRI, the system keep delivering documents until some feedback is provided. If some feedback occurs, our systems reformulates the original query adding the 20 most frequent terms contained in the feedback passages and applies a new retrieval process. The new retrieved documents list is then showed to the user. This procedure is repeated every time some feedback occurs. -BASE-IND-QE20tLF: this configuration works in a similar form to the previous experiment, although the only difference is that we reformulate the original query by adding the 20 less frequent terms. -BASE-IND-QE20tMFandLF: this configuration works in a similar form to the previous experiment, although the only difference is that we reformulate the original query by adding the 20 most frequent and the 20 less frequent terms.</p><p>-RRMRF-xxxD-Lxx: these experiments represent the runs that employed our proposed markov random field as re-ranking strategy. The first three x's represent the number of documents that were used to construct the field, whereas the second x's represent the lambda (λ) parameter value. This configuration works as follows: once we have retrieved an initial list of documents using INDRI, our system keeps delivering documents until some feedback is provided. If some feedback occurs, our proposed method constructs a virtual example text (e) employing all the information contained in the feedback and marks as relevant those documents that provided the feedback. After the iteration process we show to the user the next relevant document. This process repeats every time some feedback is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="10,161.16,464.11,4.98,9.62" target="#tab_0">1</ref> shows the evaluation results from all the submitted runs by our team. It is important to mention that the INEX 2012 Relevance Feedback track employed a new methodology for submitting results. During this campaign, participant teams were provided with an Evaluation Platform (EP) that worked as an online tool for providing the queries as well as for providing the feedback (if any) for every document showed to the EP. A total of 50 queries were processed, hence, Table <ref type="table" coords="10,162.12,535.87,4.98,9.62" target="#tab_0">1</ref> shows the average results obtained across the 50 queries. Notice that even when the baseline configuration does not obtained a very high performance, obtained results are among the best performances. Remember that the baseline method means that we are using only the output produced by the INDRI IR machine. Therefore, obtained results indicate that INDRI was not able to retrieve a significant number of relevant documents, resulting in low recall levels.</p><p>A preliminary analysis indicate us that the configuration of our IR machine was not the most adequate for the type of queries that we processed. Most of the queries consisted on a set of general terms that do not necessarily represent a query formulated in natural language. We believe that using a boolean or a As can be observed, results obtained by the configurations that employed a query expansion strategy as re-ranking mechanism obtained the worst set of results. This indicate that terms considered during the query reformulation were somehow irrelevant even when they were provided by an user.</p><p>Finally, notice that our proposed method it is able to provide a better ranking when using 300 documents and lambda 0.5, since it provides better results at the first five positions of the final list (P @5). In general, we can observe that using few documents and a high value of lambda our method is able to produce acceptable results (almost similar to those obtained when using 1000 documents). however, the main limitation of our system was the INDRI initial bad performance (low recall values). It is important to mention, as established in <ref type="bibr" coords="11,146.28,456.55,14.69,9.62" target="#b13">[14]</ref>, the proposed Markov random field depends on having high recall levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper proposed a method for improving the ranking of a list of retrieved documents by a IR system. Based on a relevance feedback approach, the proposed method integrates the similarity between the documents in the list (internal similarity); and external information obtained from the original order, the query and the provided feedback (external similarty), via a MRF to separate the relevant and irrelevant documents in the original list.</p><p>Experiments were conducted in the framework of the INEX 2012 Relevance Feedback track. For our experiments we avoid using any specialized external resources, since we were interested in evaluating the pertinence of the method employing only textual (document's words) features. Results showed that considering few documents and providing more importance to the internal similarities among documents, the proposed method is able to reach an acceptable performance. An initial analysis indicates that for this collection, it is necessary to employ as IR method a traditional boolean or vectorial model in order to improve the recall levels of the IR machine, which is an important condition for the proposed method to work properly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.76,308.70,345.86,8.66;5,134.76,319.62,44.80,8.66"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block diagram of the proposed ranking refinement method employed in the INEX 2012</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="11,134.76,117.68,345.85,205.09"><head>Table 1 .</head><label>1</label><figDesc>Official Evaluation results obtained in the framework of the INEX 2012 Relevance Feedback track vectorial model instead of a probabilistic one could provide better results in terms of the recall measure.</figDesc><table coords="11,180.48,117.68,254.36,118.44"><row><cell>Experiment</cell><cell>MAP R-Prec P@5 Recall</cell></row><row><cell>BASE-IND</cell><cell>0.1015 18.28% 45.60% 25.93%</cell></row><row><cell>BASE-IND-QE20tMF</cell><cell>0.0775 13.96% 39.60% 21.25%</cell></row><row><cell>BASE-IND-QE20tLF</cell><cell>0.0395 7.18% 30.80% 5.61%</cell></row><row><cell cols="2">BASE-IND-QE20tMFandLF 0.0728 13.64% 39.20% 20.03%</cell></row><row><cell>RRMRF-100D-L0.3</cell><cell>0.0940 16.12% 44.80% 16.40%</cell></row><row><cell>RRMRF-100D-L0.5</cell><cell>0.0946 15.95% 45.20% 16.40%</cell></row><row><cell>RRMRF-300D-L0.3</cell><cell>0.1002 17.69% 45.20% 22.76%</cell></row><row><cell>RRMRF-300D-L0.5</cell><cell>0.1004 18.05% 46.00% 22.76%</cell></row><row><cell>RRMRF-1000D-L0.3</cell><cell>0.1015 18.24% 45.60% 25.93%</cell></row><row><cell>RRMRF-1000D-L0.5</cell><cell>0.1015 18.24% 45.60% 25.93%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,137.28,612.30,3.81,4.44;1,144.72,612.66,335.83,8.66;1,144.72,623.58,335.76,8.66;1,144.72,634.62,64.00,8.66;1,137.52,644.08,3.65,4.17;1,144.72,645.54,335.92,8.66;1,144.72,656.46,41.32,8.66"><p>⋆ This work was done under partial support of CONACyT (project grant 153315) and SEP-PROMEP (project grant 48510294(UAM-C-CA-31)). We also thank UAM for their assistance.<ref type="bibr" coords="1,137.52,644.08,3.65,4.17" target="#b0">1</ref> Depending on the context, items may refer to text documents, images, audio or video sequences.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.72,590.70,278.20,8.66"><p>Cross Language Evaluation Forum (http://www.clef-campaign.org/).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.72,601.74,200.56,8.66"><p>Text Retrieval Conference (http://trec.nist.gov/).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,144.72,612.66,335.83,8.66;2,144.72,623.58,335.95,8.66;2,144.72,634.62,335.82,8.66;2,144.72,645.54,335.83,8.66;2,144.72,656.46,148.24,8.66"><p>It is worth mentioning that if available, user interaction should be included in postretrieval techniques as it is evident that information provided by the user is much more reliable than that obtained by a fully automatic process. Hence, the goal of post-processing techniques should be minimizing users' interaction instead of completely eliminate it from the process.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,144.72,623.58,206.79,8.66"><p>Also known as the problem of Ranking Refinement.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="3,144.72,634.62,335.78,8.66;3,144.72,645.54,335.86,8.66;3,144.72,656.46,22.96,8.66"><p>Keep in mind that irrelevant documents will be similar to the query in some degree since such documents were obtained by an IR system through that query in the first place.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="4,144.72,645.54,335.82,8.66;4,144.72,656.46,308.08,8.66"><p>In the context of the Relevance Feedback track from INEX, we were given as feedback relevant passages instead of full documents though the Evaluation Platform.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="7,144.72,634.62,335.90,8.66;7,144.72,645.54,335.70,8.66;7,144.72,656.46,239.43,8.66"><p>The intuitive idea of this function is such that it first increases slowly so that the top documents have a small potential, and then it increases exponentially to amplify the potential for those documents in the bottom of the list.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="8,144.72,601.74,117.64,8.66"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="8,144.72,612.66,278.20,8.66"><p>Cross Language Evaluation Forum (http://www.clef-campaign.org/).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="8,144.72,623.58,335.71,8.66;8,144.72,634.62,335.90,8.66;8,144.72,645.54,335.91,8.66;8,144.72,656.46,215.20,8.66"><p>When the relevant documents are identified by some automatic process, it is assumed that documents placed at the top positions of the list are in fact relevant, and the new set of words that will be added to the query are automatically selected; this type of feedback is known as blind relevance feedback.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.88,193.86,337.67,8.66;12,151.56,204.78,29.80,8.66" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m" coord="12,327.24,193.86,114.09,8.65">Modern Information Retrival</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,215.34,337.67,8.66;12,151.56,226.26,329.05,8.66;12,151.56,237.30,173.32,8.66" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,349.32,215.34,131.23,8.66;12,151.56,226.26,255.35,8.66">Image Re-ranking based on Relevance Feedback Combining Internal and External Similarities</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chávez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,426.96,226.26,53.65,8.65;12,151.56,237.30,42.47,8.65">The FLAIRS Conference</title>
		<meeting><address><addrLine>Daytona Beach, Florida, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,247.74,337.67,8.66;12,151.56,258.66,328.97,8.66;12,151.56,269.70,185.32,8.66" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,289.80,247.74,190.75,8.66;12,151.56,258.66,137.77,8.66">Stochastic Relaxation, Gibbs Distribution, and the Bayesian Restoration of Images</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geman</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,306.84,258.66,173.69,8.65;12,151.56,269.70,128.53,8.65">Readings in Computer Vision: Issues, Problems, Principles, and Paradigms</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="564" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,280.14,337.62,8.66;12,151.56,291.06,130.72,8.66" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="12,322.20,280.14,158.30,8.65;12,151.56,291.06,39.11,8.65">Information Retrieval, Algorithms and Heuristics</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct coords="12,142.88,301.62,337.77,8.66;12,151.56,312.54,163.47,8.66" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kemeny</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W</forename><surname>Kanpp</surname></persName>
		</author>
		<title level="m" coord="12,340.80,301.62,114.89,8.66">Denumerable Markov Chains</title>
		<meeting><address><addrLine>New York-Heidelberg-Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,323.10,337.76,8.66" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,244.80,323.10,68.79,8.66">Graphical Models</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,333.54,337.64,8.66;12,151.56,344.46,36.40,8.66" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="12,214.32,333.54,205.87,8.66">Markov Random Field Modeling in Image Analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>2nd. Edition</note>
</biblStruct>

<biblStruct coords="12,142.88,355.02,337.76,8.66" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,218.52,355.02,104.83,8.66">Automatic Summarization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,342.84,355.02,114.36,8.65">Natural Language Processing</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.88,376.38,337.64,8.66;12,151.56,387.42,62.44,8.66" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="12,214.92,376.38,184.15,8.66">Probabilistic Reasoning in Intelligent Systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan Kaufman</publisher>
			<pubPlace>San Mateo CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,397.86,337.97,8.66;12,151.56,408.90,67.00,8.66" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,231.12,397.86,129.03,8.66">An Algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Morgan Kaufman Publishers Inc</publisher>
			<biblScope unit="page" from="313" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,419.34,338.07,8.66;12,151.56,430.26,329.08,8.66;12,151.56,441.30,30.52,8.66" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,290.28,419.34,190.34,8.66;12,151.56,430.26,35.23,8.66">Improving Retrieval Performance by Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,205.80,430.26,228.11,8.65">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,451.74,338.12,8.66;12,151.56,462.66,329.11,8.66;12,151.56,473.70,328.88,8.65;12,151.56,484.62,328.95,8.66;12,151.56,495.54,65.08,8.66" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,446.64,451.74,34.03,8.66;12,151.56,462.66,313.08,8.66">A Ranking Approach based on Example Texts for Geographic Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,249.36,473.70,231.08,8.65;12,151.56,484.62,24.61,8.65">9th Workshop of the Cross Language Evaluation Forum CLEF</title>
		<title level="s" coord="12,302.52,484.62,143.43,8.66">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2009. 2008</date>
			<biblScope unit="volume">5822</biblScope>
			<biblScope unit="page" from="239" to="250" />
		</imprint>
	</monogr>
	<note>Post-proceedings of the</note>
</biblStruct>

<biblStruct coords="12,142.55,506.10,338.10,8.66;12,151.56,517.02,329.09,8.66;12,151.56,527.94,329.08,8.66;12,151.56,538.98,280.00,8.66" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,446.88,506.10,33.76,8.66;12,151.56,517.02,288.60,8.66">Ranking Refinement via Relevance Feedback in Geographic Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,457.80,517.02,22.85,8.65;12,151.56,527.94,247.26,8.65">Mexican International Conference on Artificial Intelligence MICAI</title>
		<title level="s" coord="12,187.92,538.98,141.39,8.66">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="volume">5845</biblScope>
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,549.42,337.97,8.66;12,151.56,560.34,329.04,8.66;12,151.56,571.38,329.07,8.66;12,151.56,582.30,30.52,8.66" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,248.28,560.34,232.32,8.66;12,151.56,571.38,45.85,8.66">Document Ranking Refinement Using a Markov Random Field Model</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Juárez-González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Sucar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,215.88,571.38,165.03,8.65">Journal of Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="155" to="185" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,592.86,338.10,8.66;12,151.56,603.78,329.13,8.66;12,151.56,614.70,328.87,8.66;12,151.56,625.74,16.24,8.66" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,365.88,592.86,114.76,8.66;12,151.56,603.78,165.53,8.66">Document Re-ranking Using Cluster Validation and Label Propagation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,335.28,603.78,145.41,8.65;12,151.56,614.70,286.27,8.65">Proceedings of the 2006 ACM CIKM International Conference on Information and Knowledge Management</title>
		<meeting>the 2006 ACM CIKM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="690" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.54,636.18,337.86,8.66;12,151.56,647.10,289.96,8.66" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,226.20,636.18,254.20,8.66;12,151.56,647.10,32.69,8.66">Image Analysis, Random Fields and Markov Chain Monte Carlo Methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,192.00,647.10,190.46,8.65">Springer Series on Applications of Mathematics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
