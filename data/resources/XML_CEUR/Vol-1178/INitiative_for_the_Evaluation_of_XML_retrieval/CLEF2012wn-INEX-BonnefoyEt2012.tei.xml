<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.40,116.95,296.56,12.62">Do Social Information Help Book Search?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.02,154.62,78.32,8.74"><forename type="first">Ludovic</forename><surname>Bonnefoy</surname></persName>
							<email>ludovic.bonnefoy@etd.univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">LIA -University of Avignon</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.90,154.62,74.72,8.74"><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
							<email>romain.deveaud@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">LIA -University of Avignon</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,370.78,154.62,60.08,8.74"><forename type="first">Patrice</forename><surname>Bellot</surname></persName>
							<email>patrice.bellot@lsis.org</email>
							<affiliation key="aff1">
								<orgName type="institution">LSIS -Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.40,116.95,296.56,12.62">Do Social Information Help Book Search?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">117325F7BDBF06B1B076D5BA4E330D2C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our participation in the INEX 2012 Book Track. The collection enters its second year of age and is composed of Amazon and LibraryThing entries for real books, and their associated user reviews, ratings and tags. Like in 2011, we tried a simple yet effective approach of reranking books using a social component that takes into account both popularity and ratings. We did experiments using tags as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Previous editions of the INEX Book Track focused on the retrieval of real outof-copyright books <ref type="bibr" coords="1,219.04,399.50,9.96,8.74" target="#b0">[1]</ref>. These books were written almost a century ago and the collection consisted of the OCR content of over 50, 000 books. It was a hard track because of vocabulary and writing style mismatches between the topics and the books themselves. Information Retrieval systems had difficulties to found relevant information, and assessors had difficulties judging the documents.</p><p>In 2011, for the books search task, the document collection changed and is now composed of the Amazon pages of real books. IR systems must now search through editorial data and user reviews and ratings for each book, instead of searching through the whole content of the book. The topics were extracted from the LibraryThing<ref type="foot" coords="1,234.06,505.53,3.97,6.12" target="#foot_0">1</ref> forums and represent real requests from real users.</p><p>Like we already did last year, we used a Language Modeling approach to retrieval. For our recommendation runs, we used the reviews and the ratings attributed to books by Amazon users. We computed a "social score" for each book, considering the amount of reviews and the ratings. This score is then used to modify the initial ranking obtained by a Markov Random Field baseline that proved to be highly effective last year. We also used tags to build a profile for both a query and the books of the collection which we compared to rank the books.</p><p>The rest of the paper is organized as follows. The following Section gives an insight into the document collection whereas Section 2 describes the our retrieval framework. Finally, we describe our runs in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sequential Dependence Model</head><p>We used a language modeling approach to retrieval <ref type="bibr" coords="2,372.04,163.59,9.96,8.74" target="#b1">[2]</ref>. We use Metzler and Croft's Markov Random Field (MRF) model <ref type="bibr" coords="2,326.62,175.55,10.52,8.74" target="#b2">[3]</ref> to integrate multiword phrases in the query. Specifically, we use the Sequential Dependance Model (SDM), which is a special case of the MRF. In this model three features are considered: single term features (standard unigram language model features, f T ), exact phrase features (words appearing in sequence, f O ) and unordered window features (require words to be close together, but not necessarily in an exact sequence order, f U ).</p><p>Finally, documents are ranked according to the following scoring function:</p><formula xml:id="formula_0" coords="2,214.94,270.49,185.48,93.97">score SDM (Q, D) = λ T q∈Q f T (q, D) + λ O |Q|-1 i=1 f O (q i , q i+1 , D) + λ U |Q|-1 i=1 f U (q i , q i+1 , D)</formula><p>where the features weights are set according to the author's recommendation (λ T = 0.85, λ O = 0.1, λ U = 0.05). f T , f O and f U are the log maximum likelihood estimates of query terms in document D, computed over the target collection with a Dirichlet smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modeling book likeliness</head><p>The basic idea behind this likeliness is that if a book has a lot of reviews and if its ratings are generally good, then it must be a very good book.</p><formula xml:id="formula_1" coords="2,212.56,492.85,189.05,23.45">L(D) = log(#reviews(D)) × r∈R D r #reviews(D)</formula><p>where R D is the set of all ratings given by the users for the book D, and #reviews(D) is the number of reviews.</p><p>We further rerank the books by weighting the previously computed SDM with the likeliness score. The scoring function of a book D given a query Q is thus defined as follows:</p><formula xml:id="formula_2" coords="2,230.43,595.58,154.50,9.65">s(Q, D) = L(D) × score SDM (Q, D)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modeling book thematic relatedness</head><p>We want to represent each query Q by a thematic profile and rank books according to their relatedness to it. For this first attempt at using thematic (or topic) relatedness we choosed to rely exclusively on user tags associated with the books in the collection. We consider as a thematic profile a set of tags weighted according to their significance for Q and we call it a tag profile (TP). As a preprocessing step, a tag profile is associated to each book in the collection. Tags are weighted according to a classic tf.idf measure (where the tf is the number of users who associated the tag to the book).</p><p>The main issue is to estimate a tag profile for a query. To construct it, inspired by the pseudo relevance feedback method, we summed the profile of the x top ranked books retrieved by mean of a information retrieval model (more details in runs section). Once the query's tag profile is build, we can compare book's tag profile to it with a vector similarity measure like the cosinus.</p><p>Finally, books of the collection are ranked according to the similarity of their profile to the query's one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Runs</head><p>We submitted 4 runs for the Social Search for Best Books task. We used Indri<ref type="foot" coords="3,461.88,312.07,3.97,6.12" target="#foot_1">2</ref> for indexing and searching. We did not remove any stopword and used the standard Krovetz stemmer.</p><p>mrf-booklike This run is the implementation of the SDM model described in Section 2.1 with the likeliness score.</p><p>IOT30 and IT30 Those two runs are based on the tag profile approach presented in Section 2.3. In this approach four parameters have to be fixed : The number x of top ranked books used to build the query's tag profile, the weight given to each tag in query's profile, the information retrieval model used to retrieved books and the similarity measure to compare profiles. For both runs, x is fixed to 30, Indri's language modeling approach is used and the similarity measure is the cosinus angle between vectors.</p><p>The last parameter is the weight given to each tag of the query profile. For the IOT30 run, the t i tag's weight is compute as the sum of its tf.idf weight in each of the top x books returned by Indri:</p><formula xml:id="formula_3" coords="3,251.59,531.15,112.17,20.14">w(t i ) = b∈T opx tf.idf (t i , b)</formula><p>where b is one the T op x books retrieved.</p><p>However, we had the intution that all selected books can not contribute equally to the weight of a tag. So, for the IT30 run, we combine the tf.idf of a tag in a book with the relevance of this book according to the retrieval model used in order to penalize contribution of less relevant books:</p><formula xml:id="formula_4" coords="3,221.73,627.54,171.90,20.14">w(t i ) = b∈T opx tf.idf (t i , b) × score(b, Q)</formula><p>where score(b, Q) is the measure of relevance of the book b according to Indri. deduce B IT30 30 For the last run we wanted to take advantage of both particularities of mrf-booklike run and a tag profile based one. We combine the mrf-booklike run to the IT30 run by mean of a logistic regression. We trained a model with two classes (relevant or not) and the book scores predicted by both runs as features. Training instances were the 30 top ranked books returned by each run along with their relevance judgment deduce from 2011 qrels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="4,162.65,297.44,4.98,8.74" target="#tab_0">1</ref> shows 2012 official results and 2011 non official results for our 4 runs. The combination of mrf-booklike and IT30 improves the results as expected on 2012 qrels while it increase them dramatically for 2011 qrels. In 2012 our second run is mrf-booklike but it is the worse when evaluated with 2011 qrels which is surprising. So, according to both officials results in 2012 and non official results based on 2011 qrels we can not answer to our question : "Do Social Information Help Book Search?". It seems to vary a lot depending on evaluation corpus used. In order to explain those big differences we will need to make further experiments and more fine-grained analysis. In this paper we presented our contributions for the INEX 2012 Book Track. We proposed a simple method for reranking books based on their likeliness and an effective way to take into account user tags. Finally a combination of both methods with a logistic regression approach gives the best results. Results does not allow us to answer on the usefulness of social information for book search despite quite good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,445.41,345.83,184.61"><head>Table 1 .</head><label>1</label><figDesc>Comparison of our official results at INEX 2012 and non official results for 2011. The runs are ranked according to nDCG@10.</figDesc><table coords="4,137.87,445.41,330.77,151.24"><row><cell></cell><cell>nDCG@10</cell><cell>P@10</cell><cell>Recip rank</cell><cell>Recall@10</cell></row><row><cell>2012 Qrels -Officials</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Best Run 2012</cell><cell>0.1492</cell><cell>0.1198</cell><cell>0.3069</cell><cell>0.1527</cell></row><row><cell>B IT30 30</cell><cell>0.1339</cell><cell>0.1260</cell><cell>0.3410</cell><cell>0.1659</cell></row><row><cell>mrf-booklike</cell><cell>0.1295</cell><cell>0.1250</cell><cell>0.3584</cell><cell>0.1514</cell></row><row><cell>IOT30</cell><cell>0.1141</cell><cell>0.1240</cell><cell>0.2933</cell><cell>0.1503</cell></row><row><cell>IT30</cell><cell>0.1082</cell><cell>0.1187</cell><cell>0.2999</cell><cell>0.1426</cell></row><row><cell>2011 Qrels -Non officials</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>B IT30 30</cell><cell>0.3408</cell><cell>0.2282</cell><cell>0.5398</cell><cell></cell></row><row><cell>Best Run 2011</cell><cell>0.3101</cell><cell>0.2071</cell><cell>0.4811</cell><cell></cell></row><row><cell>IT30</cell><cell>0.2995</cell><cell>0.2105</cell><cell>0.4626</cell><cell></cell></row><row><cell>IOT30</cell><cell>0.2927</cell><cell>0.2081</cell><cell>0.4524</cell><cell></cell></row><row><cell>mrf-booklike</cell><cell>0.2786</cell><cell>0.1890</cell><cell>0.4337</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,658.44,131.81,7.47"><p>http://www.librarything.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,658.44,127.10,7.47"><p>http://www.lemurproject.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,259.15,342.24,7.86;5,146.91,270.11,333.68,7.86;5,146.91,281.07,333.68,7.86;5,146.91,292.03,286.66,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,442.93,259.15,37.66,7.86;5,146.91,270.11,256.16,7.86">Overview of the INEX 2010 Book Track: At the Mercy of Crowdsourcing</title>
		<author>
			<persName coords=""><forename type="first">Gabriella</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marijn</forename><surname>Koolen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Monica</forename><surname>Landoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,384.64,281.07,95.96,7.86;5,146.91,292.03,79.55,7.86">Comparative Evaluation of Focused Retrieval</title>
		<editor>
			<persName><forename type="first">Shlomo</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ralf</forename><surname>Schenkel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrew</forename><surname>Trotman</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="98" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,302.99,342.24,7.86;5,146.91,313.95,307.61,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,264.78,302.99,215.81,7.86;5,146.91,313.95,90.76,7.86">Combining the language model and inference network approaches to retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,245.32,313.95,85.29,7.86">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="735" to="750" />
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,324.90,342.24,7.86;5,146.91,335.86,333.68,7.86;5,146.91,346.82,333.67,7.86;5,146.91,357.78,117.25,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,296.92,324.90,183.67,7.86;5,146.91,335.86,27.38,7.86">A markov random field model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,193.01,335.86,287.58,7.86;5,146.91,346.82,247.12,7.86">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
