<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,198.61,115.90,218.13,12.90;1,227.77,133.83,159.82,12.90">Running SPARQL-Fulltext Queries Inside a Relational DBMS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.13,172.11,60.39,8.64"><forename type="first">Arunav</forename><surname>Mishra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.97,172.11,67.23,8.64"><forename type="first">Sairam</forename><surname>Gurajada</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,353.52,172.11,67.24,8.64"><forename type="first">Martin</forename><surname>Theobald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Informatics</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,198.61,115.90,218.13,12.90;1,227.77,133.83,159.82,12.90">Running SPARQL-Fulltext Queries Inside a Relational DBMS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">82E17EB0046C6FEFEE1A1A07E585A537</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Entity IDX (Entity ID</term>
					<term>Term</term>
					<term>Score) Keywords Term IDX (Term</term>
					<term>Entity ID</term>
					<term>Score)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the indexing, ranking, and query processing techniques we implemented in order to process a new kind of SPARQL-fulltext queries that were provided in the context of the INEX 2012 Jeopardy task.</p><p>1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The INEX 2012 Linked Data track provides a new data collection that aims to combine the benefits of both text-oriented and structured retrievals settings in one unified data collection. For the rapid development of a new query engine that could handle this particular combination of XML markup and RDF-style resource/property-pairs, we decided to opt for a relational database system as storage back-end, which allows us to index the collection and to retrieve both the SPARQL-and keyword-related conditions of the Jeopardy queries under one common application layer. To process the 90 queries of the benchmark, we keep two main index structures, one of which is based on a recent dump of DBpedia core triples, and another one, which is based on keywords extracted from the INEX Wikipedia-LOD collection. Additionally, our engine comes with a rewriting layer that translates the SPARQL-based query patterns into SQL queries, thus formulating joins over both the DBpedia triples and the keywords extracted from the XML articles.</p><p>2 Document Collection and Queries</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Collection</head><p>Each XML document in the Wikipedia-LOD collection combines structured and unstructured information about a Wikipedia entity (or so-called "resource") in one common XML format. The structured part ("properties") of the document represents factual knowledge, which was obtained from querying DBpedia and YAGO for facts containing this entity as either their subject or object together with the property itself, while the semistructured part (WikiText) is XML-ified content that was obtained from the Wikipedia article describing the entity. Specifically, the main components of each XML document in the collection can be divided into the following blocks:</p><p>Query1: What is a famous Indian Cuisine dish that mainly contains rice, dhal, vegetables, roti and papad SELECT ?s WHERE { ?s ?p &lt;http://dbpedia.org/ resource/Category:Indian cuisine&gt; . FILTER FTContains (?s, "rice dhal vegetables roti papad") . } http:// dbpedia.org/ resource/Thali Query2: Which mountain range is bordered by another mountain range and is a popular sightseeing and sports destination? SELECT ?p WHERE { ?m &lt;http://dbpedia.org/ ontology/border&gt; ?p . ?p &lt;http://www.w3.org/ 1999/02/22-rdf-syntax-ns#type&gt; &lt;http:// dbpedia.org/ontology/MountainRange&gt; . FILTER FTContains(?p, "popular sightseeing and sports destination") . } http:// dbpedia.org/ resource/Alps Table <ref type="table" coords="2,213.86,283.22,3.36,8.06">1</ref>. Example benchmark queries in SPARQL-fulltext format 2. WikiText: This portion of the document includes text from the Wikipedia article in well-formed XML syntax. The Wikipedia were translated from the common Medi-aWiki <ref type="bibr" coords="2,177.55,341.77,11.62,8.64" target="#b0">[1]</ref> format. Additionally XML tags for all infobox attributes (and corresponding values) were included to replace all Wiki markup by proper XML tags. The inter-Wiki links which point to the other Wikipedia entities are extended to include the links to both the YAGO and DBpedia resources of the Wikipedia target pages. Each link has three sub-links: wiki-link, yago-link, and dbpedia-link.</p><p>The wiki-link attribute is a regular hyperlink to the target Wikipedia article, while the yago-link and dbpedia-link attributes contain pointers to the respective sources in the RDF collections of DBpedia and YAGO2. 3. Properties: Finally, each document at the end includes a list of all the properties from the DBpedia and YAGO facts about the entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Benchmark Queries</head><p>The translated queries are syntactically conforming to the SPARQL standard, with an additional FTContains operator that provides the flexibility to add keyword constraints to the query. The new FTContains operator takes two parameters, namely the variable name in the SPARQL component and a set of associated keywords. Table <ref type="table" coords="2,150.73,584.71,4.98,8.64">1</ref> shows two such natural-language queries and their SPARQL translations containing FTContains operators for the keyword components. For instance, in the SPARQL translation of Query 1, we have the original SPARQL component as ?s ?p &lt;http://dbpedia.org/resource/Category:Indian cuisine&gt; and the keyword component as {rice dhal vegetables roti papad}. In addition, the subject "?s" is bound by the keyword component as specified in the FTContains function. 3 Document Parsing and Index Creation</p><p>We employed a regular SAX parser to parse the 3.1 Million XML articles whose general XML structure is still based on that of the original articles. That is, these articles contain a metadata header with information about the ID, authors, creation date and others, usually also an infobox with additional semistructured information consisting of attribute-value pairs that describe the entity, and of course rich text contents consisting of unstructured information and more XML markup about the entity that is captured by such an article. Our keyword indexer uses the basic functionality of TopX 2.0 <ref type="bibr" coords="3,461.50,434.69,15.27,8.64" target="#b10">[11]</ref>, which includes Porter stemming, stopword removal and BM25 ranking, but stores the resulting inverted lists for keywords into a relational database instead of TopX's proprietary index structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Model for the Document Collection</head><p>In this section we describe the storage backend for both the structured and unstructured data parts of our document collection. Our query engine employs two relational tables to import the core tables of DBpedia and the keywords extracted from the Wikipedia LOD collection <ref type="bibr" coords="3,201.13,566.48,11.62,8.64" target="#b1">[2]</ref> in one unified database schema. Thus, the SPARQL queries with fulltext filter conditions of the above form can directly be rewritten to SQL queries with various join conditions over these two tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Storing RDF Data in a Single Relational Table</head><p>An RDF data collection can be defined as a collection of triples (a subject or resource, a predicate or property, and an object or value). In this paper, we refer to the RDF data As our storage back-end, we use a relational database (in our case Oracle 11g), to store the RDF data we imported from the core dump of DBpedia v3.7 (see http://downloads.dbpedia.org/3.7/en/).A SPARQL query then conceptually is transformed into a sub-graph matching problem over this large RDF graph. The RDF data model (a collection of triples) can be viewed as a directed, labeled multi-graph (RDF graph) where every vertex corresponds to a subject or object, and each directed edge from a subject to an object corresponds to a predicate. There may be multiple edges directed from a subject towards an object. Thus an RDF graph becomes a multi-graph.</p><p>In our query engine, RDF data is treated as a large list of triples and stored in a relational database. Figure <ref type="figure" coords="4,245.36,368.26,4.15,8.64" target="#fig_0">1</ref>(b) shows a fragment of an RDF graph constructed over Wikipedia, and Figure <ref type="figure" coords="4,225.94,380.21,4.01,8.64" target="#fig_0">1</ref>(a) shows a corresponding relational table representation in the database. Keeping this in mind, and maintaining the simplicity of the model, we use one relational table to store all SPO triples. In our system, we refer to this table as the DBpediaCore table, and its schema is described in Table <ref type="table" coords="4,382.52,416.08,3.74,8.64" target="#tab_0">2</ref>. This route is pursued similarly by many so-called triplet-stores like Jena <ref type="bibr" coords="4,347.78,428.03,15.27,8.64" target="#b11">[12]</ref>, Sesame <ref type="bibr" coords="4,404.95,428.03,11.62,8.64" target="#b3">[4]</ref> and Oracle <ref type="bibr" coords="4,468.97,428.03,11.62,8.64" target="#b5">[6]</ref> and RDF-3X <ref type="bibr" coords="4,189.08,439.99,10.58,8.64" target="#b7">[8]</ref>. Though there are other advanced and more complex approaches, like vertical partitioning or the exploitation of property tables, our goal was satisfied by this relatively simple idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Indices on the RDF Table</head><p>Representing RDF data as a relational table opens up for us all kinds of optimization techniques used by the database community. One such technique is to build indices over the DBpediaCore table to improve the data retrieval operations on it. Since we translate a SPARQL query with fulltext conditions into conjunctive SQL queries (described in the following section), we employ a large amount of self joins over this table. These self joins could occur on any of the three columns described in Table <ref type="table" coords="4,473.11,596.66,3.74,8.64" target="#tab_0">2</ref>. Thus we build three multi-attribute indices, using each of the SPO columns of the table as key and the remaining two attributes as depending data values, to accelerate the lookup times over this table for the case when each of the attributes is provided as a constant by the SPARQL query. Table <ref type="table" coords="4,296.18,644.48,4.98,8.64" target="#tab_1">3</ref> describes these three indices built over the DBpediaCore table. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Storing Keywords in a Single Relational Table</head><p>As per traditional IR, a fulltext search allows for identifying documents that satisfy a keyword query, and optionally sorting the matching documents by their relevance to the query. The most common approaches use fairly simple TF/IDF counts or Boolean retrieval to measure the content similarity of a fulltext keyword query to the documents in the data collection. In our engine, we store the unstructured text contents of all the documents in the collection as another table in the relational database. This table essentially contains three columns, relating a keyword (or term) with the documents in which it occurs and the similarity scores calculated for this particular term and document based on the underlying scoring model.</p><p>We define a term as a sequence of characters that occur grouped together in some document and thus yield a useful semantic unit for processing. To obtain this set of terms from the fulltext content of a Wikipedia article, we use a variant of the TopX indexer <ref type="bibr" coords="5,168.27,385.03,15.27,8.64" target="#b10">[11]</ref>, which applies a standard white-space tokenizer, Porter stemming, and stopword removal to the unstructured text inputs. For this purpose, we treat all CDATA sections and attribute values of the Wikipedia-LOD articles as one flat collection of text; that is we treat the XML collection as an unstructured set of Wikipedia text documents. We use a default BM25 scoring model (using k = 2.0 and b = 0.75) to calculate the relevance score of a term in a document. In our approach, we create a Keywords table to store all the terms occurring in the unstructured Wikipedia fulltext collection. The schema of this table is shown in Table <ref type="table" coords="5,353.66,468.72,3.74,8.64">4</ref>. The Entity ID column essentially stores the Uniform Resource Identifier (URI) of the DBpedia entities. It may be noted that every document in our collection also corresponds to a DBpedia entity. So we prefer to use the RDF prefix defined by DBpedia to represent an entity, which is htttp://dbpedia.org/resource/entity . To obtain a mapping from a DBpedia entity to the Entity ID's from a Wikipedia page, we maintain a hashmap that maps every Wikipedia page to its corresponding DBpedia entity URI. Thus every statement of the Keywords table represents a term that is mapped to an entity in DBpedia together with its content similarity score to the entity's Wikipedia page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Indices on the Keywords Table</head><p>We can easily imagine that the Keywords table would be very large (containing more than a billion entires), considering the number of terms extracted from almost the entire Wikipedia encyclopedia. The Keywords table basically maps every term occurring in Wikipedia to a DBpedia entity. Taking the size of this table into consideration, data retrieval operations on the table becomes costly and inefficient. Also processing conjunctive queries over multiple self joins becomes infeasible unless correct indices are built over the table. So we build two more multi-attribute indices over this table as shown in Table <ref type="table" coords="6,197.64,155.18,3.74,8.64" target="#tab_2">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Scoring</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Keywords Scoring and retrieval</head><p>We use the TopX 2.0 indexer to create per-term inverted lists from the plain (unstructured) text content of the Wikipedia documents, which each corresponds to an entity in DBpedia. The exact BM25 variant we used for ranking an entity e by a string of keywords S in an FTContains operator is given by the following formula:</p><p>score(e, FTContains(e, S))</p><formula xml:id="formula_0" coords="6,184.91,283.43,283.95,61.82">= ti∈S (k 1 + 1) tf (e, t i ) K + tf (e, t i ) • log N -df (t i ) + 0.5 df (t i ) + 0.5 with K = k 1 (1 -b) + b len(e) avg{len(e ) | e</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>in collection}</head><p>Where:</p><p>1) N is the number of XML articles in Wikipedia LOD collection.</p><p>2) tf (e, t) is the term frequency of term t in the Wikipedia LOD article associated with entity e. 3) df (t) is the document frequency of term t in the Wikipedia LOD collection. 4) len(e) is the length (sum of tf values) of the Wikipedia LOD article associated with entity e.</p><p>We used the values of k 1 = 2.0 and b = 0.75 as the BM25-specific tuning parameters (see also <ref type="bibr" coords="6,171.84,464.96,11.62,8.64" target="#b6">[7]</ref> for tuning BM25 on earlier INEX settings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Translating the Keyword-Scores to SPO Triples</head><p>Recently there has been a lot of work on identifying appropriate entity scoring and ranking models. Many techniques use language models <ref type="bibr" coords="6,344.08,524.93,15.77,8.64" target="#b12">[13,</ref><ref type="bibr" coords="6,361.51,524.93,7.47,8.64" target="#b8">9,</ref><ref type="bibr" coords="6,370.64,524.93,13.28,8.64" target="#b9">10]</ref> while other approaches try to adopt more complex measures form IR. Ranking for structured queries have been intensively investigated for XML <ref type="bibr" coords="6,268.96,548.84,10.58,8.64" target="#b2">[3]</ref>, and, to a small extent, also for restricted forms of SQL queries <ref type="bibr" coords="6,188.08,560.80,10.58,8.64" target="#b4">[5]</ref>. While some of these approaches carry over to large RDF collections and expressive SPARQL queries as discussed earlier, the LOD track makes a significant simplifying assumption: since every DBpedia or YAGO entity is associated (via an explicit link) with the Wikipedia article (in XML format) that describes this entity, the entities can directly be referred to and ranked by the keywords that are imposed over the corresponding Wikipedia article. We thus believe that it is a good idea to translate the scores to the RDF entities from a keyword-based search on the fulltext part of the Wikipedia LOD collection. As discussed earlier, every entity in our collection is essentially a document containing all the DBpedia and YAGO properties about this entity together with the fulltext content from the corresponding Wikipedia page. Thus we perform a keyword search on this fulltext content by using the fulltext condition specified by the FTContains operator (as discussed earlier). From this search, we get a ranked entity list containing the candidates for the answer to the given query. This is can be best explained by an example as shown in Figure <ref type="figure" coords="7,332.61,392.15,4.98,8.64" target="#fig_1">2</ref> . 6 Rewriting SPARQL-Fulltext Queries to SQL</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Basic Idea of a Conjunctive Query</head><p>Conjunctive queries have high practical relevance because they cover a large part of queries issued on relational databases and RDF stores. That is, many SQL and SPARQL queries can be written as conjunctive queries. In our scenario, we are required to generate an appropriate translation of a given SPARQL query with multiple fulltext conditions into an SQL query. Our system-generated queries are essentially conjunctive queries over multiple instances of the DBpediaCore and Keywords tables (as described earlier).</p><p>To capture the idea behind translating a given SPARQL query with fulltext conditions into a conjunctive SQL query, let us take an example query Q taken from the Jeopardy benchmark as shown in Table <ref type="table" coords="8,295.67,143.22,3.74,8.64">6</ref>. Q contains three triple patterns T 1, T 2 and T 3, and two fulltext conditions K1 and K2. Each K i contains a variable occurring in a triple pattern and is bound to a string by an FTContains operator. To begin translation, firstly, every attached string is tokenized and stemmed into the format of terms stored in the Term column of the Keywords table. For every generated token k j where j ≥ 0 from each K i , an instance of the Keywords table is taken, where the Terms column of the instance is restricted to k j . Similarly for every triple pattern T m , we take an instance of the DBpediaCore table t i , where i ≥ 0. In the example, instance t 1 represents triple ?sub ?o ?s, instance t 2 represents the triple ?x ?r ?s, and instance t 3 represents the triple ?sub rdf:type http://dbpedia.org/ontology/Place . These instances t i are further restricted on their Subject or Object by the Entity ID of the k j instance of the Keywords table as specified by the fulltext condition. Finally, the instances t i are restricted by each other on Subject, Predicate or Object as per the logic of the joins in the SPARQL query. The translation of Q into a conjunctive SQL query, as described above, is shown in Table <ref type="table" coords="8,335.03,310.60,3.74,8.64">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Materialization SQL Joins, Temporary Tables, and Join Orders</head><p>In the previous section, we presented a translation method for any given (conjunctive) SPARQL query with fulltext conditions into a conjunctive SQL query. But, there are a few problems with such a direct translation. Firstly, this form of translation does not handle empty results returned from any intermediate join in the desired way. For example, lets say we encounter with a very unlikely keyword term which is missing in the Keywords table. Then an empty result will be returned for that instance, and, since we issue a conjunctive query with all AND conditions, the overall result of the query will also be empty. Secondly, this type of query with many (self-)joins is inefficient and difficult to optimize. During query processing, we rely on the Oracle optimizer for selecting an appropriate query plan. It becomes difficult for the optimizer to choose the best plan due to the redundancy of data in the DBpediaCore table, i.e., due to multiple occurrences of an entity as a Subject or Object and an unknown amount of occurrences of a term in the Keywords table. Due to apparently insufficient statistics on these large tables (although we had analyzed the tables and enabled this feature in A manually translated query in SPARQL syntax: SELECT ?sub WHERE { ?x ?r ?s . ?sub ?o ?s . ?sub rdf:type http://dbpedia.org/ontology/Place . FILTER FTContains (?x, "Canarian"). FILTER FTContains (?sub, "place islands country") . } Table <ref type="table" coords="8,198.11,644.83,3.36,8.06">6</ref>. A given SPARQL-fulltext query of the INEX 2012 Jeopardy task</p><p>The automatically converted conjunctive SQL query: SELECT DISTINCT t1.SUBJECT AS sub FROM dbpediacore t2, dbpediacore t1, dbpediacore t3, keywords k40, keywords k41, keywords k42, keywords k3 WHERE t2.OBJECT = t1.OBJECT AND t1.SUBJECT = t3.SUBJECT AND t3.PREDICATE = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type' AND t3.OBJECT = 'http://dbpedia.org/ontology/Place' AND k0.TERM = 'place' AND k1.TERM = 'island' AND k2.TERM = 'countri' AND k3.TERM = 'canarian' AND t1.SUBJECT = k0.ENTITY ID AND t1.SUBJECT = k1.ENTITY ID AND t1.SUBJECT = k2.ENTITY ID AND t2.SUBJECT = k3.ENTITY ID Table <ref type="table" coords="9,226.48,282.34,3.36,8.06">7</ref>. SQL translation of the SPARQL query of Table <ref type="table" coords="9,407.73,282.69,4.48,7.77">6</ref> the optimizer), we found the Oracle optimizer to often choose a bad query plan, which initially resulted in individual SQL queries that did not even finish after several days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">SQL Joins</head><p>Most join queries contain at least one join condition, either in the FROM (for outer joins) or in the WHERE clause. The join condition compares two columns, each from a different table. To execute a join, the database system combines pairs of rows, each containing one row from each table, for which the join condition evaluates to true. The columns in the join conditions need not also appear in the select list.</p><p>To execute a join of three or more tables, Oracle first joins two of the tables based on the join conditions comparing their columns and then joins the result to another table based on the join conditions containing columns of the previously joined tables and the new table. Oracle continues this process until all tables are joined into the result. The optimizer determines the order in which Oracle joins tables based on the join conditions, indexes on the tables, and any available statistics for the tables.</p><p>FULL OUTER JOIN A FULL OUTER JOIN does not require each record in the two joined tables to have a matching record. The joined table retains each record even if no other matching record exists. Where records in the FULL OUTER JOIN'ed tables do not match, the result set will have NULL values for every column of the table that lacks a matching row. For those records that do match, a single row will be produced in the result set (containing fields populated from both tables). This join can be used to solve the first problem mentioned above. All instances of the Keywords table representing a fulltext condition K i can undergo a FULL OUTER JOIN on the Entity ID attribute. Thus we will have results from the keywords table even if one of the instance matches any tuples or has a NULL as a value.  <ref type="table" coords="10,167.63,473.76,4.15,8.64">B</ref>). It returns all records which satisfy the join predicate. This join returns the same result as the "equality" join as described in the previous section but gives more flexibility to the optimizer to select different types of joins like hash joins, merge joins, or nested loop joins. We can replace all the equality join with Oracle's INNER JOIN. In some queries this trick shows considerable improvement in query processing time by Oracle's query engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Materializing Temporary Tables</head><p>One big conjunctive query forces the Oracle optimizer to choose from a very large number of possible query execution plans, and it turns out that-at least in our setting-it often chooses an inefficient plan. For example, in a big conjunctive query, the optimizer often chose to join instances DBpediaCore tables before restricting the relevant entities with the given conditions. These types of query plans proved to be highly expensive. Thus, to prevent the optimizer from taking such inappropriate decisions, we materialize temporary tables by separately joining the Keywords table instances and the DBpediaCore table instances. This acts as a strong support for the optimizer to select better query plans for smaller intermediate queries and store their results into temporary tables which are later joined together to retrieve the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Evaluating the Join Order and Forcing Orders via Optimizer Hints</head><p>There are some simple techniques by which we can determine the join order of the tables. One such technique is to maintain an IDF index containing the most frequent terms that occur in the collection. This index has a very simple and intuitive schema Features(Term, IDF). The first column represents a term and the second column represents its Inverse Document Frequency (IDF). It can be intuitively be seen that a frequent term will have lower IDF and a select query will result in bigger intermediate joins. At the same time, if a term is absent in the feature index, then it can be assumed to be infrequent and thus have a high IDF value. Every instance of the Keywords table  can now be joined in increasing order of the IDF values of their respective term, thus ensuring the smaller tables to be joined first. This order of joining can be enforced on the Oracle optimizer by adding so-called optimizer hints to the queries.</p><p>A hint is a code snippet that is embedded into an SQL statement to suggest to Oracle how the statement should be executed. There are many hints provided to assist the optimizer. In our case, we found the Ordered hint to force the optimizer to join tables in the specified order written in the FROM clause of the query. So our translator algorithm writes the Keywords table instances in the appropriate order in the FROM clause of the translated SQL query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">The Rewriting Algorithm</head><p>We can now develop an overall rewriting algorithm by putting together all the afore described steps as follows.</p><p>1. Load the features index containing frequent terms and their IDF values into main memory. 2. Tokenize and stem the FTContains fulltext conditions and decide the order of joins among the keywords from the features index. 3. Create temporary Keys i tables for each fulltext condition: these contain the results of the outer join over the Keywords table instances constrained by the terms. This is shown in Figure <ref type="figure" coords="12,227.84,515.28,3.74,8.64" target="#fig_3">3</ref>. 4. Create temporary T ab i tables for each triplet pattern: these contain the results of the inner join over the DBpediaCore table instances which are additionally joined with Keys i temporary tables for each FTContains fulltext condition in the query. This is shown in Figure <ref type="figure" coords="12,289.72,564.97,3.74,8.64" target="#fig_4">4</ref>. 5. Assign a default score of 1 to all triples in absence of a fulltext condition: in absence of a fulltext condition on any triplet pattern, a default score of 1 is assigned to all the triples as a constant score for each triplet condition (as discussed earlier). 6. Final query: the main select query combines the T ab i temporary tables via an inner join; the join logic is based on the joins given in the original SPARQL query. This is shown in Figure <ref type="figure" coords="12,227.84,640.45,3.74,8.64" target="#fig_5">5</ref>. 7. Finally, drop the temporary tables Keys i and T ab i . This is shown in Figure <ref type="figure" coords="12,456.65,654.28,3.74,8.64" target="#fig_6">6</ref>.</p><p>Since a detailed evaluation of the run submissions was not available at the time this paper was submitted, we defer a discussion of the results until to the INEX workshop at the CLEF conference in September.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusions</head><p>We presented an approach for storing structured RDF data and unstructured data in relational database. We also presented the necessary indices required to efficiently process queries over this relational schema. Our approach converts a SPARQL query with fulltext conditions into unions of conjunctive SQL queries by materializing temporary tables. These temporary tables store intermediate results from inner or outer joins over our relations, based on given conditions in the query. We also presented a simple yet effective way to rank entities by translating scores from keywords. Finally, we showed the advantages of predeciding the join orders of tables and techniques to enforce them in the Oracle optimizer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,290.90,345.83,8.12;3,134.77,302.06,122.69,7.93;3,134.77,115.84,345.83,160.33"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example showing an RDF graph and the corresponding triplet representation in a relational database (picture taken from [14])</figDesc><graphic coords="3,134.77,115.84,345.83,160.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,146.02,310.95,323.33,8.12;7,134.77,227.39,345.82,68.83"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example showing the translation of keyword scores to the entity-relationship graph</figDesc><graphic coords="7,134.77,227.39,345.82,68.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,149.71,404.10,330.88,8.64;7,134.77,416.06,345.82,8.64;7,134.77,428.01,345.82,8.64;7,134.77,439.97,345.82,8.64;7,134.77,451.92,345.82,8.64;7,134.77,463.88,345.82,8.64;7,134.77,475.83,345.82,8.64;7,134.77,487.79,345.83,8.64;7,134.77,499.74,345.82,8.64;7,134.77,511.70,50.08,8.64"><head>Figure 2 (</head><label>2</label><figDesc>a) shows an example query containing a simple SPARQL query with one triplet and a fulltext condition that is bound to the subject of the SPARQL query. Figure 2(b) shows fragments of top-100 results obtained by fulltext search on the unstructured part of the collection with keywords "Lucky Jim". As illustrated, we already have the relevant candidates for the answer from the keyword search due to the satisfactory performance of our BM25 scoring scheme applied to score the keywords. The scored entities in the candidate list is again checked for the graph pattern of the SPARQL query in Figure 2(a) and the final top-k entities are retrieved from the entities which qualify for the graph pattern. Figure 2(c) shows the retrieved results after searched for the pattern in the graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,215.19,343.56,184.98,8.12;10,134.77,115.83,345.83,213.00"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Queries to create the Keys temporary tables</figDesc><graphic coords="10,134.77,115.83,345.83,213.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="11,217.40,330.17,180.56,8.12;11,134.77,115.84,345.82,199.60"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Queries to create the TAB temporary tables</figDesc><graphic coords="11,134.77,115.84,345.82,199.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,212.86,654.79,189.64,8.12;11,134.77,559.67,345.83,80.39"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The final SELECT query to obtain the answer</figDesc><graphic coords="11,134.77,559.67,345.83,80.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="12,225.99,190.35,163.37,8.12;12,134.77,115.84,345.83,59.78"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Queries to DROP the temporary tables</figDesc><graphic coords="12,134.77,115.84,345.83,59.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,118.06,337.38,73.83"><head>Table 2 .</head><label>2</label><figDesc>Schema of the DBpediaCore table</figDesc><table coords="4,136.56,118.06,335.59,52.01"><row><cell>Column N3ID Subject Predicate VARCHAR2(1024) Type NUMBER VARCHAR2(1024) Object VARCHAR2(1024)</cell><cell>Index Name DBpediaIDX Obj (Object,Subject,Predicate) Attributes DBpediaIDX Sub (Subject,Predicate,Object) DBpediaIDX Prd (Predicate,Object,Subject)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,167.33,345.82,85.38"><head>Table 3 .</head><label>3</label><figDesc>Indices built over the DBpediaCore table</figDesc><table coords="4,134.77,232.12,345.82,20.59"><row><cell>as a collection of SPO triples, each containing exactly one such subject (S), predicate</cell></row><row><cell>(P), and object (O).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,271.85,156.31,172.76,8.12"><head>Table 5 .</head><label>5</label><figDesc>Indices built over the Keywords table</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.61,374.01,201.72,7.77" xml:id="b0">
	<monogr>
		<ptr target="http://en.wikipedia.org/wiki/MediaWiki" />
		<title level="m" coord="13,150.96,374.01,41.00,7.77">Media Wiki</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,384.97,181.87,7.77" xml:id="b1">
	<monogr>
		<title level="m" coord="13,150.96,384.97,169.72,7.77">Overview of the INEX 2012 Linked Data Track</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,395.77,337.98,7.93;13,150.95,406.73,63.67,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,275.02,395.93,160.36,7.77">XML search: languages, INEX and scoring</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Amer-Yahia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,446.23,395.77,34.36,7.72;13,150.95,406.73,23.83,7.72">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,417.84,337.98,7.77;13,150.95,428.65,315.28,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,331.35,417.84,149.24,7.77;13,150.95,428.80,145.80,7.77">Sesame: A Generic Architecture for Storing and Querying RDF and RDF Schema</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Broekstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kampman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Van Harmelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,314.07,428.65,18.94,7.72">LNCS</title>
		<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2342</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,439.76,337.98,7.77;13,150.95,450.57,300.42,7.93" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,344.00,439.76,136.59,7.77;13,150.95,450.72,156.90,7.77">Probabilistic information retrieval approach for ranking of database query results</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,314.28,450.57,98.07,7.72">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,461.68,337.98,7.77;13,150.95,472.49,103.34,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,338.70,461.68,141.89,7.77;13,150.95,472.64,24.97,7.77">An efficient SQL-based RDF querying scheme</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">I</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Eadon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,193.02,472.49,35.30,7.72">VLDB &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,483.45,325.53,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,211.62,483.60,193.35,7.77">Controlling overlap in content-oriented XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,421.07,483.45,20.54,7.72">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,494.56,337.98,7.77;13,150.95,505.36,116.58,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,262.47,494.56,214.68,7.77">The RDF-3X engine for scalable management of RDF data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,150.95,505.36,66.52,7.72">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,516.47,337.98,7.77;13,150.95,527.28,105.38,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,253.49,516.47,227.10,7.77;13,150.95,527.43,27.67,7.77">Hierarchical Language Models for Expert Finding in Enterprise Corpora</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petkova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,195.52,527.28,34.85,7.72">ICTAI &apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,538.39,338.35,7.77;13,150.95,549.20,140.55,7.93" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,272.31,538.39,208.28,7.77;13,150.95,549.35,26.38,7.77">Modeling Documents as Mixtures of Persons for Expert Finding</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Serdyukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,194.04,549.20,18.94,7.72">LNCS</title>
		<imprint>
			<biblScope unit="volume">4956</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,560.31,338.35,7.77;13,150.95,571.12,83.84,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,294.48,560.31,186.11,7.77;13,150.95,571.27,22.56,7.77">TopX 2.0 at the INEX 2009 Ad-Hoc and Efficiency Tracks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,190.22,571.12,17.73,7.72">INEX</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,582.23,338.35,7.77;13,150.95,593.03,305.51,7.93" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,341.98,582.23,138.61,7.77;13,150.95,593.19,18.88,7.77">Efficient RDF Storage and Retrieval in Jena2</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sayers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kuno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,186.55,593.03,243.49,7.72">Proc. First International Workshop on Semantic Web and Databases</title>
		<meeting>First International Workshop on Semantic Web and Databases</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,604.15,338.35,7.77;13,150.95,614.95,259.05,7.93" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,327.40,604.15,153.19,7.77;13,150.95,615.10,10.28,7.77">Closing the Loop in Webpage Understanding</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,167.88,614.95,202.37,7.72">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.24,623.98,338.35,9.85;13,150.95,636.87,145.93,7.93" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,337.23,626.06,143.36,7.77;13,150.95,637.02,66.77,7.77">gStore: answering SPARQL queries via subgraph matching</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,224.91,636.87,25.11,7.72">PVLDB</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
