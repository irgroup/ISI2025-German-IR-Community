<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,194.01,151.63,207.41,13.13;1,188.06,169.15,219.26,13.13">A Hybrid Tweet Contextualization System using IR and Summarization</title>
				<funder ref="#_yuh6z7X #_KzJyFuN #_c2q8G9e #_kG2kMYA">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.64,207.67,58.89,9.11"><forename type="first">Pinaki</forename><surname>Bhaskar</surname></persName>
							<email>pinaki.bhaskar@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.46,207.67,71.83,9.11"><forename type="first">Somnath</forename><surname>Banerjee</surname></persName>
							<email>s.banerjee1980@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.99,207.67,90.75,9.11"><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,194.01,151.63,207.41,13.13;1,188.06,169.15,219.26,13.13">A Hybrid Tweet Contextualization System using IR and Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D380A1C9A72D38A698EE4D2F260DF50D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Automatic Summarization</term>
					<term>Question Answering</term>
					<term>Information Extraction</term>
					<term>INEX 2012</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The article presents the experiments carried out as part of the participation in the Tweet Contextualization (TC) track of INEX 2012. We have submitted three runs. The INEX TC task has two main sub tasks, Focused IR and Automatic Summarization. In the Focused IR system, we first preprocess the Wikipedia documents and then index them using Nutch with NE field. Stop words are removed and all NEs are tagged from each query tweet and all the remaining tweet words are stemmed using Porter stemmer. The stemmed tweet words form the query for retrieving the most relevant document using the index. The automatic summarization system takes as input the query tweet along with the title from the most relevant text document. Most relevant sentences are retrieved from the associated document based on the TF-IDF of the matching query tweet, NEs text and title words. Each retrieved sentence is assigned a ranking score in the Automatic Summarization system. The answer passage includes the top ranked retrieved sentences with a limit of 500 words. The three unique runs differ in the way in which the relevant sentences are retrieved from the associated document.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the explosion of information in Internet, Natural language Question Answering (QA) is recognized as a capability with great potential. Traditionally, QA has attracted many AI researchers, but most QA systems developed are toy systems or games confined to laboratories and to a very restricted domain. Several recent conferences and workshops have focused on aspects of the QA research. Starting in 1999, the Text Retrieval Conference (TREC) <ref type="foot" coords="1,313.92,606.98,3.00,5.56" target="#foot_0">1</ref> has sponsored a question-answering track, which evaluates systems that answer factual questions by consulting the documents of the TREC corpus. A number of systems in this evaluation have successfully combined information retrieval and natural language processing techniques. More recently, Conference and Labs of Evaluation Forums (CLEF) <ref type="foot" coords="2,451.92,149.30,3.00,5.56" target="#foot_1">2</ref> are organizing QA lab from 2010. INEX 3 has also started Question Answering track. Last year, INEX 2011 designed a QA track <ref type="bibr" coords="2,290.89,172.87,11.61,9.11" target="#b0">[1]</ref> to stimulate the research for real world application. The Question Answering (QA) task performed by the participating groups of INEX 2011 is contextualizing tweets, i.e., answering questions of the form "what is this tweet about?" using a recent cleaned dump of the Wikipedia (April 2011). This year they renamed this task as Tweet Contextualization.</p><p>Current INEX 2012 Tweet Contextualization (TC) track gives QA research a new direction by fusing IR and summarization with QA. The TC track of INEX 2012 had two major sub tasks. The first task is to identify the most relevant document from the Wikipedia dump, for this we need a focused IR system. And the second task is to extract most relevant passages from the most relevant retrieved document. So we need an automatic summarization system. The general purpose of the task involves tweet analysis, passage and/or XML elements retrieval and construction of the answer, more specifically, the summarization of the tweet topic.</p><p>Automatic text summarization <ref type="bibr" coords="2,265.44,323.11,11.57,9.11" target="#b2">[2]</ref> has become an important and timely tool for assisting and interpreting text information in today's fast-growing information age. Text Summarization methods can be classified into abstractive and extractive summarization. An Abstractive Summarization ( <ref type="bibr" coords="2,324.86,357.67,11.22,9.11" target="#b3">[3]</ref> and <ref type="bibr" coords="2,358.05,357.67,11.15,9.11" target="#b4">[4]</ref>) attempts to develop an understanding of the main concepts in a document and then expresses those concepts in clear natural language. Extractive Summaries <ref type="bibr" coords="2,322.98,380.71,11.65,9.11" target="#b5">[5]</ref> are formulated by extracting key text segments (sentences or passages) from the text, based on statistical analysis of individual or mixed surface level features such as word/phrase frequency, location or cue words to locate the sentences to be extracted. Our approach is based on Extractive Summarization.</p><p>In this paper, we describe a hybrid Tweet Contextualization system of focused IR and automatic summarization for TC track of INEX 2012. The focused IR system is based on Nutch architecture and the automatic summarization system is based on TF-IDF based sentence ranking and sentence extraction techniques. The same sentence scoring and ranking approach of <ref type="bibr" coords="2,261.98,484.87,11.61,9.11" target="#b6">[6]</ref> and <ref type="bibr" coords="2,295.19,484.87,11.61,9.11" target="#b7">[7]</ref> has been followed. We have submitted three runs in the QA track <ref type="bibr" coords="2,231.47,496.39,74.37,9.11">(177, 191 and 192)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Recent trend shows hybrid approach of tweet contextualization using Information Retrieval (IR) can improve the performance of the TC system. Reference <ref type="bibr" coords="2,421.35,573.19,11.61,9.11" target="#b8">[8]</ref> removed incorrect answers of QA system using an IR engine. Reference <ref type="bibr" coords="2,385.47,584.71,11.60,9.11" target="#b9">[9]</ref> successfully used methods of IR into QA system. Reference <ref type="bibr" coords="2,299.65,596.47,16.60,9.11" target="#b10">[10]</ref> used the IR system into QA and <ref type="bibr" coords="2,453.93,596.47,16.66,9.11" target="#b11">[11]</ref> proposed an efficient hybrid QA system using IR in QA.</p><p>Reference <ref type="bibr" coords="2,186.00,619.51,16.62,9.11" target="#b12">[12]</ref> presents an investigation into the utility of document summarization in the context of IR, more specifically in the application of so-called query-biased summaries: summaries customized to reflect the information need expressed in a query. Employed in the retrieved document list displayed after retrieval took place, the summaries' utility was evaluated in a task-based environment by measuring users' speed and accuracy in identifying relevant documents. This was compared to the performance achieved when users were presented with the more typical output of an IR system: a static predefined summary composed of the title and first few sentences of retrieved documents. The results from the evaluation indicate that the use of query-biased summaries significantly improves both the accuracy and speed of user relevance judgments.</p><p>A lot of research work has been done in the domain of both query dependent and independent summarization. MEAD <ref type="bibr" coords="3,285.61,253.75,16.63,9.11" target="#b13">[13]</ref> is a centroid based multi document summarizer, which generates summaries using cluster centroids produced by topic detection and tracking system. NeATS <ref type="bibr" coords="3,286.20,276.79,16.62,9.11" target="#b14">[14]</ref> selects important content using sentence position, term frequency, topic signature and term clustering. XDoX <ref type="bibr" coords="3,412.92,288.55,16.60,9.11" target="#b15">[15]</ref> identifies the most salient themes within the document set by passage clustering and then composes an extraction summary, which reflects these main themes. Graph based methods have been also proposed for generating summaries. A document graph based query focused multi-document summarization system has been described by <ref type="bibr" coords="3,436.87,334.63,15.29,9.11" target="#b16">[16]</ref>, <ref type="bibr" coords="3,458.99,334.63,11.61,9.11" target="#b6">[6]</ref> and <ref type="bibr" coords="3,141.74,346.15,10.59,9.11" target="#b7">[7]</ref>.</p><p>In the present work, we have used the IR system as described in <ref type="bibr" coords="3,395.88,357.67,15.30,9.11" target="#b10">[10]</ref>, <ref type="bibr" coords="3,417.66,357.67,16.61,9.11" target="#b11">[11]</ref> and <ref type="bibr" coords="3,453.98,357.67,16.62,9.11" target="#b17">[17]</ref> and the automatic summarization system as discussed in <ref type="bibr" coords="3,355.60,369.19,10.59,9.11" target="#b6">[6]</ref>, <ref type="bibr" coords="3,372.65,369.19,11.61,9.11" target="#b7">[7]</ref> and <ref type="bibr" coords="3,404.54,369.19,15.29,9.11" target="#b17">[17]</ref>. In the later part of this paper, section 3 describes the corpus statistics and section 4 shows the system architecture of combined TC system of focused IR and automatic summarization for INEX 2012. Section 5 details the Focused Information Retrieval system architecture. Section 6 details the Automatic Summarization system architecture. The evaluations carried out on submitted runs are discussed in Section 7 along with the evaluation results. The conclusions are drawn in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus statistics</head><p>The training data is the collection of documents that has been rebuilt based on recent English Wikipedia dump (November 2011). All notes and bibliographic references have been removed from Wikipedia pages to prepare plain xml corpus for an easy extraction of plain text answers. Each training document is made of a title, an abstract and sections. Each section has a sub-title. Abstract and sections are made of paragraphs and each paragraph can have entities that refer to Wikipedia pages. Therefore, the resulting corpus has this simple DTD as shown in table <ref type="table" coords="3,407.33,573.19,3.73,9.11" target="#tab_0">1</ref>.</p><p>Test data is made up of 1142 tweets from Twitter. There are two different formats of tweets, one is the full JSON format with all tweet metadata as shown in the table 2 and another is the two-column text format with only tweet id and tweet text as shown in the table <ref type="table" coords="3,171.75,619.51,3.73,9.11" target="#tab_2">3</ref>.  "created_at":"Fri, 03 Feb 2012 09:10:20 +0000", "from_user":"XXX", "from_user_id":XXX, "from_user_id_str":"XXX", "from_user_name":"XXX", "geo":null, "id":XXX, "id_str":"XXX", "iso_language_code":"en", "metadata":{"result_type":"recent"}, "profile_image_url":"http://XXX", "profile_image_url_https":"https://XXX", "source":"&lt;a href='http://XXX'&gt;", "text":"blahblahblah", "to_user":null, "to_user_id":null, "to_user_id_str":null, "to_user_name":null </p><formula xml:id="formula_0" coords="4,203.04,167.73,184.10,119.81">&lt;!ELEMENT xml (page)+&gt; &lt;!ELEMENT page (ID, title, a, s*)&gt; &lt;!ELEMENT ID (#PCDATA)&gt; &lt;!ELEMENT title (#PCDATA)&gt; &lt;!ELEMENT a (p+)&gt; &lt;!ELEMENT s (h, p+)&gt; &lt;!ATTLIST s o CDATA #REQUIRED&gt; &lt;!ELEMENT h (#PCDATA)&gt; &lt;!ELEMENT p (#PCDATA | t)*&gt; &lt;!ATTLIST p o CDATA #REQUIRED&gt; &lt;!ELEMENT t (#PCDATA)&gt; &lt;!ATTLIST t e CDATA #IMPLIED&gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System Architecture</head><p>In this section the overview of the system framework of the current INEX system has been shown. The current INEX system has two major sub-systems; one is the Focused IR system and the other one is the Automatic Summarization system. The Focused IR system has been developed on the basic architecture of Nutch<ref type="foot" coords="5,398.64,160.82,3.00,5.56" target="#foot_2">4</ref> , which use the architecture of Lucene<ref type="foot" coords="5,216.24,172.34,3.00,5.56" target="#foot_3">5</ref> . Nutch is an open source search engine, which supports only the monolingual Information Retrieval in English, etc. The Higher-level system architecture of the combined Tweet Contextualization system of Focused IR and Automatic Summarization is shown in the Figure <ref type="figure" coords="5,324.46,207.67,3.73,9.11" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Wikipedia Document Parsing and Indexing</head><p>The web documents are full of noises mixed with the original content. In that case it is very difficult to identify and separate the noises from the actual content. INEX 2012 corpus, i.e., Wikipedia dump, had some noise in the documents and the documents are in XML tagged format. So, first of all, the documents had to be preprocessed. The document structure is checked and reformatted according to the system requirements.</p><p>XML Parser. The corpus was in XML format. All the XML test data has been parsed before indexing using our XML Parser. The XML Parser extracts the Title of the document along with the paragraphs.</p><p>Noise Removal. The corpus has some noise as well as some special symbols that are not necessary for our system. The list of noise symbols and the special symbols is initially developed manually by looking at a number of documents and then the list is used to automatically remove such symbols from the documents. Some examples are "&amp;quot;", "&amp;amp;", "'''", multiple spaces etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named Entity Recognizer (NER).</head><p>After cleaning the corpus, the named entity recognizer identifies all the named entities (NE) in the documents and tags them according to their types, which are indexed during the document indexing. Document Indexing. After parsing the Wikipedia documents, they are indexed using Lucene, an open source indexer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Tweets Parsing</head><p>After indexing has been done, the tweets had to be processed to retrieve relevant documents. Each tweet / topic was processed to identify the query words for submission to Lucene. The tweets processing steps are described below: Stop Word Removal. In this step the tweet words are identified from the tweets. The stop words and question words (what, when, where, which etc.) are removed from each tweet and the words remaining in the tweets after the removal of such words are identified as the query tokens. The stop word list used in the present work can be found at http://members.unine.ch/jacques.savoy/clef/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named Entity Recognizer (NER).</head><p>After removing the stop words, the named entity recognizer identifies all the named entities (NE) in the tweet and tags them according to their types, which are used during the scoring of the sentences of the retrieved document.</p><p>Stemming. Query tokens may appear in inflected forms in the tweets. For English, standard Porter Stemming algorithm <ref type="foot" coords="6,274.08,629.30,3.00,5.56" target="#foot_4">6</ref> has been used to stem the query tokens. After stemming all the query tokens, queries are formed with the stemmed query tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Document Retrieval</head><p>After searching each query into the Lucene index, a set of retrieved documents in ranked order for each query is received.</p><p>First of all, all queries were fired with AND operator. If at least one document is retrieved using the query with AND operator then the query is removed from the query list and need not be searched again. The rest of the queries are fired again with OR operator. OR searching retrieves at least one document for each query. Now, the top ranked relevant document for each query is considered for Passage selection. Document retrieval is the most crucial part of this system. We take only the top ranked relevant document assuming that it is the most relevant document for the query or the tweet from which the query had been generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Automatic Summarization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Sentence Extraction</head><p>The document text is parsed and the parsed text is used to generate the summary. This module will take the parsed text of the documents as input, filter the input parsed text and extract all the sentences from the parsed text. So this module has two sub modules, Text Filterization and Sentence Extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Filterization.</head><p>The parsed text may content some junk or unrecognized character or symbol. First, these characters or symbols are identified and removed. The text in the query language are identified and extracted from the document using the Unicode character list, which has been collected from Wikipedia <ref type="foot" coords="7,357.36,482.66,3.00,5.56" target="#foot_5">7</ref> . The symbols like dot (.), coma (,), single quote ('), double quote ("), '!', '?' etc. are common for all languages, so these are also listed as symbols.</p><p>Sentence Extraction. In Sentence Extraction module, filtered parsed text has been parsed to identify and extract all sentences in the documents. Sentence identification and extraction is not an easy task for English document. As the sentence marker '.' (dot) is not only used as a sentence marker, it has other uses also like decimal point and in abbreviations like Mr., Prof., U.S.A. etc. So it creates lot of ambiguity. A possible list of abbreviation had to created to minimize the ambiguity. Most of the times the end quotation (") is placed wrongly at the end of the sentence like .". These kinds of ambiguities are identified and removed to extract all the sentences from the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Key Term Extraction</head><p>Key Term Extraction module has three sub modules like Query Term, i.e., tweet term extraction, tweet text extraction and Title words extraction. All these three sub modules have been described in the following sections.</p><p>Query/Tweet Term Extraction. First the query generated from the tweet, is parsed using the Query Parsing module. In this Query Parsing module, the Named Entities (NE) are identified and tagged in the given query using the Stanford NER<ref type="foot" coords="8,419.76,245.54,3.00,5.56" target="#foot_6">8</ref> engine. Title Word Extraction. The title of the retrieved document is extracted and forwarded as input given to the Title Word Extraction module. After removing all the stop words from the title, the remaining tile words are extracted and used as the keywords in this system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Top Sentence Identification</head><p>All the extracted sentences are now searched for the keywords, i.e., query terms, tweet's text keywords and title words. Extracted sentences are given some weight according to search and ranked on the basis of the calculated weight. For this task this module has two sub modules: Weight Assigning and Sentence Ranking, which are described below.</p><p>Weight Assigning. This sub module calculates the weights of each sentence in the document. There are three basic components in the sentence weight like query term dependent score, tweet's text keyword dependent score and title word dependent score. These three components are calculated and added to get the final weight of a sentence.</p><p>Query/Tweet Term dependent score: Query/Tweet term dependent score is the most important and relevant score for summary. Priority of this query/tweet dependent score is maximum. The query dependent scores are calculated using equation 1.</p><formula xml:id="formula_1" coords="8,189.14,547.26,281.39,38.59">Q s = F q 20 + n q ! q +1 ( ) 1! f p q !1 N s " # $ % &amp; ' p ( " # $ % &amp; ' ) p " # $ % &amp; ' q=1 n q (<label>(1)</label></formula><p>where, Q S is the query/tweet term dependent score of the sentence s, q is the no. of the query/tweet term, n q is the total no. of query terms, f p q is the possession of the word which was matched with the query term q in the sentence s, N s is the total no. of words in sentence s, </p><formula xml:id="formula_2" coords="9,229.88,153.52,39.61,18.07">F q = 0; if</formula><p>At the end of the equation 1, the calculated query term dependent score is multiplied by p to give the priority among all the scores. If the query term is NE and contained in a sentence then the weight of the matched sentence are multiplied by 5 as the value of p is 5, to give the highest priority, other wise it has been multiplied by 3 (as p=3 for non NE query terms).</p><p>Title Word dependent score: Title words are extracted from the title field of the top ranked retrieved document. A title word dependent score is also calculated for each sentence. Generally title words are also the much relevant words of the document. So the sentence containing any title words can be a relevant sentence of the main topic of the document. Title word dependent scores are calculated using equation 4.</p><formula xml:id="formula_4" coords="9,220.94,353.93,249.36,35.94">T s = F t n t ! t +1 ( ) 1 ! f p t !1 N s " # $ % &amp; ' p ( " # $ % &amp; ' t=0 n t (<label>(4)</label></formula><p>where, T S is the title word dependent score of the sentence s, t is the no. of the title word, n t is the total number of title words, f p t is the position of the word which matched with the title word t in the sentence s, N s is the total number of words in sentence s and F t = 0; if title word t is not found 1; if title word t is found</p><formula xml:id="formula_5" coords="9,378.79,456.79,87.87,9.11">. (<label>5</label></formula><formula xml:id="formula_6" coords="9,466.66,456.79,3.87,9.11">)</formula><p>After calculating all the above three scores the final weight of each sentence is calculated by simply adding all the two scores as mentioned in the equation 6.</p><p>W s = Q s + T s <ref type="bibr" coords="9,458.99,520.39,11.61,9.11" target="#b6">(6)</ref> where, W S is the final weight of the sentence s.</p><p>Sentence Ranking. After calculating weights of all the sentences in the document, sentences are sorted in descending order of their weight. In this process if any two or more than two sentences get equal weight, then they are sorted in the ascending order of their positional value, i.e., the sentence number in the document. So, this Sentence Ranking module provides the ranked sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Summary Generation</head><p>This is the final and most critical module of this system. This module generates the Summary from the ranked sentences. As in <ref type="bibr" coords="9,303.42,677.11,16.59,9.11" target="#b13">[13]</ref> using equation 9, the module selects the ranked sentences subject to maximum length of the summary.</p><formula xml:id="formula_7" coords="10,279.43,165.60,190.43,26.79">i i i l S L &lt; ∑<label>(9)</label></formula><p>where l i is the length (in no. of words) of sentence i, S i is a binary variable representing the selection of sentence i for the summary and L (=500 words) is the maximum length of the summary. Now, the selected sentences along with their weight are presented as the INEX output format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Informative Content Evaluation</head><p>The organizers did the Informative Content evaluation <ref type="bibr" coords="10,365.12,349.75,11.61,9.11" target="#b0">[1]</ref> by selecting relevant passages. 50 topics were evaluated which was the pool of 14 654 sentences, 471 344 tokens, vocabulary of 59 020 words. Among them, 2801 sentences, 103889 tokens, vocabulary of 19037 words, are relevant. There are 8 topics with less than 500 relevant tokens. The evaluation measures of Information content divergences over {1,2,3,4gap}-grams (FRESA package) because it was too sensitive to smoothing on the qa-rels. So simple log difference of equation 10 was used: log max P t / reference ( ), P t / summary ( ) ( )</p><formula xml:id="formula_8" coords="10,188.95,441.81,277.82,36.23">min P t / reference ( ), P t / summary ( ) ( ) ! " # $ % &amp; '<label>(10)</label></formula><p>We have submitted three runs <ref type="bibr" coords="10,261.64,493.51,76.55,9.11">(177, 191 and 192)</ref>. The evaluation scores with the baseline system scores of informativeness by organizers of all topics are shown in the table <ref type="table" coords="10,146.74,516.79,3.73,9.11" target="#tab_4">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Readability Evaluation</head><p>For Readability evaluation <ref type="bibr" coords="10,243.37,651.19,11.61,9.11" target="#b0">[1]</ref> all passages in a summary have been evaluated according to Syntax (S), Anaphora (A), Redundancy (R) and Trash (T). If a passage contains a syntactic problem (bad segmentation for example) then it has been marked</p><p>as Syntax (S) error. If a passage contains an unsolved anaphora then it has been marked as Anaphora (A) error. If a passage contains any redundant information, i.e., an information that have already been given in a previous passage then it has been marked as Redundancy (R) error. If a passage does not make any sense in its context (i.e., after reading the previous passages) then these passages must be considered as trashed, and readability of following passages must be assessed as if these passages were not present, so they were marked as Trash (T). The readability evaluation scores are shown in the table <ref type="table" coords="11,215.04,230.71,3.73,9.11" target="#tab_5">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Works</head><p>The tweet contextualization system has been developed as part of the participation in the Tweet Contextualization track of the INEX 2012 evaluation campaign. The overall system has been evaluated using the evaluation metrics provided as part of this track of INEX 2012. Considering that this is the second participation in the track, the evaluation results are satisfactory, which will really encourage us to continue work on it and participate in this track in future. Future works will be motivated towards improving the performance of the system by concentrating on co-reference and anaphora resolution, multi-word identification, para phrasing, feature selection etc. In future, we will also try to use semantic similarity, which will increase our relevance score.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,182.16,496.17,231.14,8.37;5,125.28,228.24,345.12,259.92"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Higher level system architecture of current INEX system</figDesc><graphic coords="5,125.28,228.24,345.12,259.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,226.11,149.37,143.20,8.37"><head>Table 1 .</head><label>1</label><figDesc>The DTD for Wikipedia pages</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,155.14,302.49,285.12,8.37"><head>Table 2 .</head><label>2</label><figDesc>A full JSON format with all tweet metadata of INEX 2012 test corpus</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,126.52,531.69,342.39,74.13"><head>Table 3 .</head><label>3</label><figDesc>A two-column text format with only tweet id and tweet text of INEX 2012 test corpus</figDesc><table coords="4,153.50,549.98,297.17,55.84"><row><cell>Tweet Id</cell><cell>Tweet Text</cell></row><row><cell></cell><cell>"What links human rights, biodiversity and</cell></row><row><cell>170167036520038400</cell><cell>habitat pesticides, Rio +20 and and a sustainable loss, deforestation, pollution,</cell></row><row><cell></cell><cell>future for all?"</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,159.00,539.85,277.36,62.85"><head>Table 4 .</head><label>4</label><figDesc>The evaluation scores of Informativeness by organizers of all topics</figDesc><table coords="10,204.60,557.97,206.27,44.73"><row><cell>Run Id</cell><cell>unigram</cell><cell>bigram</cell><cell>Skip</cell></row><row><cell>192</cell><cell>0.9590</cell><cell>0.9947</cell><cell>0.9947</cell></row><row><cell>191</cell><cell>0.9590</cell><cell>0.9947</cell><cell>0.9947</cell></row><row><cell>177</cell><cell>0.9541</cell><cell>0.9981</cell><cell>0.9984</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,157.03,253.77,299.38,62.85"><head>Table 5 .</head><label>5</label><figDesc>The evaluation scores of Readability</figDesc><table coords="11,157.03,272.13,299.38,44.49"><row><cell>Run Id</cell><cell>Relevancy</cell><cell>Syntax</cell><cell>Structure</cell><cell>Nb</cell></row><row><cell>192</cell><cell>0.6020</cell><cell>0.6020</cell><cell>0.6020</cell><cell>2</cell></row><row><cell>191</cell><cell>0.6173</cell><cell>0.5540</cell><cell>0.5353</cell><cell>3</cell></row><row><cell>177</cell><cell>0.5227</cell><cell>0.4680</cell><cell>0.4680</cell><cell>3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,130.05,686.40,68.40,8.22"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,130.05,675.60,107.33,8.22"><p>http://www.clef-initiative.eu//</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="5,130.05,675.60,85.38,8.22"><p>http://nutch.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="5,130.05,686.40,88.86,8.22"><p>http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="6,130.05,686.40,179.58,8.22"><p>http://tartarus.org/~martin/PorterStemmer/java.txt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5" coords="7,130.05,686.40,204.82,8.22"><p>http://en.wikipedia.org/wiki/List_of_Unicode_characters</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6" coords="8,130.05,686.40,118.86,8.22"><p>http://www-nlp.stanford.edu/ner/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. We acknowledge the support of the <rs type="projectName">IFCPAR</rs> funded <rs type="programName">Indo-French</rs> project "<rs type="projectName">An Advanced Platform for Question Answering Systems</rs>" and the <rs type="projectName">DIT, Government of India</rs> funded project "<rs type="projectName">Development of Cross Lingual Information Access (CLIA) System Phase II</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_yuh6z7X">
					<orgName type="project" subtype="full">IFCPAR</orgName>
					<orgName type="program" subtype="full">Indo-French</orgName>
				</org>
				<org type="funded-project" xml:id="_KzJyFuN">
					<orgName type="project" subtype="full">An Advanced Platform for Question Answering Systems</orgName>
				</org>
				<org type="funded-project" xml:id="_c2q8G9e">
					<orgName type="project" subtype="full">DIT, Government of India</orgName>
				</org>
				<org type="funded-project" xml:id="_kG2kMYA">
					<orgName type="project" subtype="full">Development of Cross Lingual Information Access (CLIA) System Phase II</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,128.16,601.20,342.45,8.22;11,138.30,611.52,332.42,8.22;11,138.30,622.08,332.32,8.22" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,365.83,601.20,104.77,8.22;11,138.30,611.52,148.23,8.22">Overview of the INEX 2011 Question Answering Track (QA@INEX)</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,307.90,611.52,162.82,8.22;11,138.30,622.08,328.08,8.22">Focused Retrieval of Content and Structure, 10th International Workshop of the Initiative for the Evaluation of XML Retrieval (INEX)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.30,632.40,323.13,8.22" xml:id="b1">
	<monogr>
		<title level="m" coord="11,288.14,632.40,107.12,8.22">Lecture Notes in Computer Sc</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,128.16,642.72,342.44,8.22;11,138.30,653.28,332.29,8.22;11,138.30,663.60,117.44,8.22" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,240.31,642.72,114.61,8.22">Automatic Text summarization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jezek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
		<editor>Snasel, V.</editor>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<publisher>FIIT STU Brarislava</publisher>
			<biblScope unit="page" from="1" to="12" />
			<pubPlace>Znalosti</pubPlace>
		</imprint>
	</monogr>
	<note>Ustav Informatiky a softveroveho inzinierstva</note>
</biblStruct>

<biblStruct coords="11,128.16,673.92,342.46,8.22;11,138.30,684.24,329.92,8.22" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,247.35,673.92,223.27,8.22;11,138.30,684.24,53.12,8.22">LexRank: Graph-based Centrality as Salience in Text Summarization</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,210.04,684.24,149.77,8.22">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,149.52,342.46,8.22;12,138.30,159.84,332.29,8.22;12,138.30,170.40,233.23,8.22" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,236.17,149.52,185.50,8.22">The SYNDIKATE text Knowledge base generator</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,441.87,149.52,28.76,8.22;12,138.30,159.84,332.29,8.22;12,138.30,170.40,95.69,8.22">the first International conference on Human language technology research, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,180.72,342.40,8.22;12,138.30,191.04,332.30,8.22;12,138.30,201.60,332.21,8.22;12,138.30,211.92,23.97,8.22" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,352.59,180.72,117.97,8.22;12,138.30,191.04,80.32,8.22">Optimizing Text Summarization Based on Fuzzy Logic</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kyoomarsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">K</forename><surname>Dehkordy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,237.81,191.04,232.79,8.22;12,138.30,201.60,73.98,8.22">Seventh IEEE/ACIS International Conference on Computer and Information Science</title>
		<meeting><address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="347" to="352" />
		</imprint>
		<respStmt>
			<orgName>University of Shahid Bahonar Kerman</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,222.24,342.46,8.22;12,138.30,232.80,332.25,8.22;12,138.30,243.12,251.46,8.22" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,279.43,222.24,191.19,8.22;12,138.30,232.80,53.13,8.22">A Query Focused Multi Document Automatic Summarization</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,216.02,232.80,254.53,8.22;12,138.30,243.12,97.18,8.22">the 24th Pacific Asia Conference on Language, Information and Computation (PACLIC 24)</title>
		<meeting><address><addrLine>Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Tohoku University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,253.44,342.37,8.22;12,138.30,264.00,332.33,8.22;12,138.30,274.32,141.21,8.22" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,279.43,253.44,191.10,8.22;12,138.30,264.00,42.00,8.22">A Query Focused Automatic Multi Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,199.67,264.00,252.81,8.22">the International Conference on Natural Language Processing (ICON)</title>
		<meeting><address><addrLine>Kharagpur, India</addrLine></address></meeting>
		<imprint>
			<publisher>IIT</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,284.64,342.39,8.22;12,138.30,295.19,272.67,8.23" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,383.80,284.64,86.75,8.22;12,138.30,295.20,195.02,8.22">A Question Answering System based on Information Retrieval and Validation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pe˜nas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,339.26,295.19,45.43,7.93">ResPubliQA</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.16,305.76,342.48,8.22;12,138.30,316.08,332.30,8.22;12,138.30,326.40,39.72,8.22" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,368.68,305.76,101.96,8.22;12,138.30,316.08,220.86,8.22">Question Answering using Integrated Information Retrieval and Information Extraction</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,379.33,316.08,49.07,8.22">NAACL HLT</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,336.96,338.34,8.22;12,138.30,347.28,332.30,8.22;12,138.30,357.60,215.71,8.22" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,421.60,336.96,49.02,8.22;12,138.30,347.28,200.65,8.22">JU_CSE_TE: System Description QA@CLEF 2010 -ResPubliQA</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,362.49,347.28,108.11,8.22;12,138.30,357.60,139.71,8.22">Multiple Language Question Answering (MLQA 2010)</title>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>CLEF-2010</note>
</biblStruct>

<biblStruct coords="12,132.28,368.16,338.29,8.22;12,138.30,378.48,332.31,8.22;12,138.30,388.80,332.32,8.22;12,138.30,399.36,68.18,8.22" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,436.24,368.16,34.34,8.22;12,138.30,378.48,314.94,8.22">A Hybrid Question Answering System based on Information Retrieval and Answer Validation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,138.30,388.80,327.80,8.22">Question Answering for Machine Reading Evaluation (QA4MRE), CLEF-2011</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,409.68,338.30,8.22;12,138.30,420.00,99.45,8.22" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,255.21,409.68,215.38,8.22;12,138.30,420.00,31.70,8.22">Advantages of Query Biased Summaries in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tombros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,188.03,420.00,23.42,8.22">SIGIR</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,430.32,338.35,8.22;12,138.30,440.88,275.95,8.22" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,306.88,430.32,163.75,8.22;12,138.30,440.88,37.10,8.22">Centroid-based summarization of multiple documents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Styś</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,181.81,440.88,154.51,8.22">J. Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="919" to="938" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,451.20,338.31,8.22;12,138.30,461.52,176.97,8.22" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,223.22,451.20,247.38,8.22;12,138.30,461.52,63.47,8.22">From Single to Multidocument Summarization: A Prototype System and its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,220.03,461.52,15.17,8.22">ACL</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,472.08,338.34,8.22;12,138.30,482.40,253.19,8.22" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,411.64,472.08,58.98,8.22;12,138.30,482.40,143.53,8.22">Cross-document summarization by concept classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strzalkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Wise</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,299.75,482.40,21.43,8.22">SIGIR</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="65" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,492.72,338.32,8.22;12,138.30,503.28,332.34,8.22;12,138.30,513.60,119.97,8.22" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,271.19,492.72,199.40,8.22;12,138.30,503.28,82.52,8.22">A Document Graph Based Query Focused Multi-Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Paladhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,241.07,503.28,229.57,8.22;12,138.30,513.60,52.78,8.22">the 2nd International Workshop on Cross Lingual Information Access (CLIA)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.28,523.92,338.33,8.22;12,138.30,534.48,332.32,8.22;12,138.30,544.80,332.29,8.22;12,138.30,555.12,332.31,8.22;12,138.30,565.44,273.90,8.22" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,364.60,523.92,106.01,8.22;12,138.30,534.48,227.31,8.22">A Hybrid QA System with Focused IR and Automatic Summarization for INEX 2011</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Neogi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,217.13,544.80,253.46,8.22;12,138.30,555.12,275.11,8.22">Focused Retrieval of Content and Structure: 10th International Workshop of the Initiative for the Evaluation of XML Retrieval, INEX 2011</title>
		<title level="s" coord="12,419.83,555.12,50.78,8.22;12,138.30,565.44,73.91,8.22">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7424</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
