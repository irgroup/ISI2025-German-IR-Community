<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.51,116.95,312.34,12.62;1,242.38,134.89,130.60,12.62">UAIC participation at Robot Vision @ 2012 An updated vision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.60,172.56,69.37,8.74"><forename type="first">Emanuela</forename><surname>Boroş</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science General Berthelot</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<addrLine>16</addrLine>
									<postCode>700483</postCode>
									<settlement>Iaşi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,248.89,172.56,109.16,8.74"><forename type="first">Alexandru</forename><forename type="middle">Lucian</forename><surname>Gînscȃ</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science General Berthelot</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<addrLine>16</addrLine>
									<postCode>700483</postCode>
									<settlement>Iaşi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.34,172.56,58.42,8.74"><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science General Berthelot</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<addrLine>16</addrLine>
									<postCode>700483</postCode>
									<settlement>Iaşi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,181.86,194.12,62.73,7.86"><forename type="first">Alexandru</forename><surname>Ioan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science General Berthelot</orgName>
								<orgName type="institution">Cuza University</orgName>
								<address>
									<addrLine>16</addrLine>
									<postCode>700483</postCode>
									<settlement>Iaşi</settlement>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.51,116.95,312.34,12.62;1,242.38,134.89,130.60,12.62">UAIC participation at Robot Vision @ 2012 An updated vision</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3FE60619F828DB3FAE194B99C2CC8641</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Robot Topological Localization</term>
					<term>Global Features</term>
					<term>Invariant Local Features</term>
					<term>Visual Words</term>
					<term>SVMs</term>
					<term>Genetic Algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe a system that participated in the fourth benchmarking activity ImageCLEF, in the Robot Vision task, for which we approach the task of topological localization without using a temporal continuity of the sequences of images. We provide details for the state-of-the-art methods that were selected: Color Histograms, SIFT (Scale Invariant Feature Transform), ASIFT (Affine SIFT) and RGB-SIFT, Bag-of-Visual-Words strategy inspired from the text retrieval community. We focused on finding the optimal set of features and a deepened analysis was carried out. We offer an analysis of the different features, similarity measures and a performance evaluation of combinations of the proposed methods for topological localization. Also, we detail a genetic algorithm that was used for eliminating the false positives results. In the end, we draw several conclusions targeting the advantages of using proper configurations of visual-based appearance descriptors, similarity measures and classifiers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>In this paper, we present an approach to vision-based mobile robot localization that uses a single perspective camera taken within an office environment. The robot should be able to answer the question where are you? when presented with a test sequence representing a room category seen during training <ref type="bibr" coords="1,433.54,525.61,15.50,8.74" target="#b29">[30,</ref><ref type="bibr" coords="1,450.70,525.61,12.73,8.74" target="#b32">33,</ref><ref type="bibr" coords="1,465.10,525.61,11.62,8.74" target="#b24">25]</ref>. We analyze the problem without taking in consideration the use of the temporal continuity of the sequences of images. We perform an exhaustive evaluation and introduce a new analysis statistic between quantization techniques of a large set of features, from which different system configurations are picked and tested.</p><p>Traditionally, robot vision systems heavily relied on different methods for robotic topological localization such as topological map building which makes good use of temporal continuity <ref type="bibr" coords="1,276.92,609.29,14.61,8.74" target="#b36">[37]</ref>, panoramic vision creation <ref type="bibr" coords="1,413.87,609.29,14.61,8.74" target="#b37">[38]</ref>, simultaneous localization and mapping <ref type="bibr" coords="1,267.06,621.25,9.96,8.74" target="#b6">[7]</ref>, appearance-based place recognition for topological localization <ref type="bibr" coords="1,218.61,633.20,14.61,8.74" target="#b37">[38]</ref>, Monte-Carlo localization <ref type="bibr" coords="1,351.20,633.20,14.61,8.74" target="#b40">[41]</ref>.</p><p>The problem of topological mobile localization has mainly three dimensions: a type of environment (indoor, outdoor, outdoor natural), a perception (sensing modality) and a localization model (probabilistic, basic). Numerous papers deal with indoor environments <ref type="bibr" coords="2,251.91,131.95,15.50,8.74" target="#b36">[37,</ref><ref type="bibr" coords="2,269.07,131.95,12.73,8.74" target="#b37">38,</ref><ref type="bibr" coords="2,283.46,131.95,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,297.85,131.95,12.73,8.74" target="#b20">21]</ref> and a few deal with outdoor environments, natural or urban <ref type="bibr" coords="2,242.55,143.90,15.50,8.74" target="#b35">[36,</ref><ref type="bibr" coords="2,259.71,143.90,11.62,8.74" target="#b12">13]</ref>.</p><p>Current work on robot localization in indoor environments has focused on introducing probabilistic models to improve local feature matching and the integration of specific kernels. Experimental results for wide baseline image matching suggest the need for local invariant descriptors of images. Invariant features have achieved relative success with object detection and image matching. There has also been research into the development of fully invariant features <ref type="bibr" coords="2,455.68,215.85,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,467.86,215.85,12.73,8.74" target="#b25">26,</ref><ref type="bibr" coords="2,134.77,227.81,11.62,8.74" target="#b26">27]</ref>. In his milestone paper <ref type="bibr" coords="2,254.46,227.81,14.61,8.74" target="#b22">[23]</ref>, D. Lowe has proposed a scale invariant feature transform (SIFT) that is invariant to image scaling and rotation, illumination and viewpoint changes. Lately, a new method has been proposed, Affine-SIFT (ASIFT) that simulates all the views obtainable by varying the two camera axis orientation parameters, namely the latitude and the longitude angles <ref type="bibr" coords="2,438.82,275.63,14.61,8.74" target="#b28">[29]</ref>.</p><p>The Bag-of-Visual-Words <ref type="bibr" coords="2,265.75,287.81,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,277.93,287.81,12.73,8.74" target="#b11">12]</ref> model is a great addition to place recognition and was initially inspired by the bag-of-words models in text classification where a document is represented by an unsorted set of the contained words. This data modeling technique was first been introduced in the case of video retrieval <ref type="bibr" coords="2,134.77,335.63,14.61,8.74" target="#b34">[35]</ref>. Due to its efficiency and effectiveness, it became very popular in the fields of image retrieval and classification <ref type="bibr" coords="2,291.57,347.59,15.50,8.74" target="#b19">[20,</ref><ref type="bibr" coords="2,308.73,347.59,11.62,8.74" target="#b42">43]</ref>.</p><p>The classification level of images relies more on unsupervised then supervised learning techniques. Categorizing in unsupervised learning scenarios is a much harder problem, due to the absence of class labels that would guide the search for relevant information. In supervised learning scenarios, image categorizing has been studied widely in the literature. Among supervised learning techniques, the most popular in this context are Bayesian classifiers <ref type="bibr" coords="2,368.17,419.54,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,380.35,419.54,12.73,8.74" target="#b17">18,</ref><ref type="bibr" coords="2,394.75,419.54,12.73,8.74" target="#b11">12,</ref><ref type="bibr" coords="2,409.13,419.54,12.73,8.74" target="#b18">19]</ref> and Support Vector Machines (SVM) <ref type="bibr" coords="2,247.59,431.49,15.50,8.74" target="#b38">[39,</ref><ref type="bibr" coords="2,264.75,431.49,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="2,274.15,431.49,12.73,8.74" target="#b17">18,</ref><ref type="bibr" coords="2,288.54,431.49,11.62,8.74" target="#b43">44]</ref>. <ref type="bibr" coords="2,308.78,431.49,10.52,8.74" target="#b2">[3]</ref> also uses random forests. Actually, state-of-the-art results are due to SVM classifiers: the method described in <ref type="bibr" coords="2,465.09,443.45,15.50,8.74" target="#b43">[44]</ref> combines a local matching of the features and specific kernels based on the Earth Movers Distance <ref type="bibr" coords="2,210.04,467.36,15.50,8.74" target="#b31">[32]</ref> or χ 2 <ref type="bibr" coords="2,255.08,467.36,15.50,8.74" target="#b27">[28]</ref> yielded the best results.</p><p>Our approach represents an extension of our previous work <ref type="bibr" coords="2,409.74,479.54,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,421.92,479.54,7.75,8.74" target="#b1">2]</ref> where each RGB image is processed to extract sets of SIFT keypoints from where the descriptors are defined. Making use of global and local features, a quantization technique, SVMs and a genetic algorithm that aims at eliminating the false positives, we approached the task of recognition with different configurations and the one that got the best results has been reviewed in the 2012 Robot Vision task in ImageCLEF international campaign.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image Analysis</head><p>In this section, we describe the image features that have been used in this work in order to obtain a precise and effective model for the topological localization task. In order to obtain an image representation which captures the essential appearance of the location and is robust to occlusions and changes in image brightness, we compare two different image descriptors and their associated dis-tance measure. In the first case, we use color histograms integrated and in the second case each image is represented by a set of local scale-invariant features, quantized in bags of visual words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Global Features</head><p>Many recognition systems based on images use global features that describe the entire image, an overall view of the image that is transformed in histograms of frequencies. Adopting the analysis of global features has brought great improvement in robot localization systems as in <ref type="bibr" coords="3,311.12,226.73,15.50,8.74" target="#b32">[33]</ref> or in content based image retrieval systems as in medical related images analysis in <ref type="bibr" coords="3,350.23,238.68,14.61,8.74" target="#b33">[34]</ref>. Such features are important because they produce very compact representations of images, where each image corresponds to a point in a high dimensional feature space.</p><p>In the following, we attempt to model image densities using two different color spaces, RGB and HSV.</p><p>RGB (Red, Green, and Blue) Color Model is composed of the primary colors Red, Green, and Blue. They are considered the additive primaries since the colors are added together to produce the desired color. White is produced when all three primary colors at the maximum light intensity (255). The RGB space has the major deficiency of not being perceptually uniform, this being the motivation of adding HSV color histograms.</p><p>HSV (Hue, Saturation, and Value) Color Model defines colors in terms of three constituent components: hue, saturation and value or brightness. The hue and saturation components are intimately related to the way human eye perceives color because they capture the whole spectrum of colors. The value represents intensity of a color, which is decoupled from the color information in the represented image. This color model is attractive because color image processing performed independently on the color channels does not introduce false colors (hues). However, it has also inconvenient due to the necessary nonlinearity in forward and reverse transformations with RGB space.</p><p>A color histogram denotes the joint probabilities of the intensities of the three color channels and is computed by discretizing the colors within the image and counting the number of pixels of each color. Since the number of colors is finite, it is usually more convenient to transform the three channel histogram into a single variable histogram, therefore a quantization of the histograms is needed. The histogram dimension (the number of histogram bins) n is determined by the color representation scheme and quantization level. Most color spaces represent a color as a three-dimensional vector with real values (e.g. RGB, HSV). We quantize the color space of three axes into k bins for the first axis, l bins for the second axis and m bins for the third axis. The histogram can be represented as an n-dimensional vector where n = k • l • m. Because the retrieval performance is saturated when the number of bins is increased beyond some value, normalized color histogram difference can be a satisfactory measure of frame dissimilarity, even when colors are quantized into only 64 bins (4 Green × 4 Red × 4 Blue). As a conclusion, we chose a 18 • 10 • 10 multidimensional HSV histogram, and a 10 • 10 • 10 multidimensional RGB histogram, as differences between colors of the office environment have a high level of similarity and have slight changes in hues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Local Features</head><p>A different paradigm is to use local features, which are descriptors of local image neighborhoods computed at multiple interest points. There are many local features developed in the last years for image analysis, with the outstanding SIFT as the most popular. In the literature, there are several works studying the different features and their descriptors, for instance <ref type="bibr" coords="4,337.69,232.54,15.50,8.74" target="#b21">[22]</ref> evaluates the performance of local descriptors, and <ref type="bibr" coords="4,230.34,244.50,15.50,8.74" target="#b43">[44]</ref> shows a study on the performance of different feature for object recognition.</p><p>The three types of features used in our experiments are SIFT (Scale Invariant Feature Transform), ASIFT (Affine Scale Invariant Feature Transform) and RGB-SIFT (RGB Scale Invariant Feature Transform).These features were extracted using <ref type="bibr" coords="4,195.67,304.57,14.61,8.74" target="#b13">[14]</ref>. Also, the localization experiments using these features show advantages and disadvantages of using one or another.</p><p>SIFT (Scale Invariant Feature Transforms) <ref type="bibr" coords="4,367.45,328.75,20.31,8.77" target="#b22">[23,</ref><ref type="bibr" coords="4,389.42,328.78,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="4,398.82,328.78,12.73,8.74" target="#b23">24]</ref> features correspond to highly distinguishable image locations which can be detected efficiently and have been shown to be stable across wide variations of viewpoint and scale. The algorithm basically extracts features that are invariant to rotation, scaling an partially invariant to changes in illumination an affine transformations. This feature has been explained in our previous work being one of our key level of our systems <ref type="bibr" coords="4,189.48,400.51,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="4,201.65,400.51,7.01,8.74" target="#b1">2]</ref>.</p><p>ASIFT (Affine Scale Invariant Feature Transforms), as described in <ref type="bibr" coords="4,134.77,424.71,14.61,8.74" target="#b28">[29]</ref>, simulates with enough accuracy all distortions caused by a variation of the camera optical axis direction. Then it applies the SIFT method. In other words, ASIFT simulates three parameters: the scale, the camera longitude angle and the latitude angle and normalizes the other three (translation and rotation), what SIFT lacked.</p><p>RGB-SIFT (RGB Scale Invariant Feature Transforms) descriptors are computed for every RGB channel independently. Therefore, each channel is normalized separately which brings another important aspect for SIFT, the invariance to light color change. For a color image, the SIFT descriptions independently from each RGB component and concatenated into a 384-dimensional local feature (RGB-SIFT) <ref type="bibr" coords="4,250.95,544.56,9.96,8.74" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feature Matching</head><p>In this subsection we introduce different dissimilarity measures to compare features. That is, a measure of dissimilarity between two features and thus between the underlying images is calculated. Many of the features presented are in fact histograms (color histograms, invariant feature histograms). As comparison of distributions is a well known problem, a lot of comparison measures have been proposed and compared before <ref type="bibr" coords="4,271.89,657.11,14.61,8.74" target="#b30">[31]</ref>.</p><p>In the following, dissimilarity measures to compare two histograms H and K are proposed. Each of these histograms has n bins and H i is the value of the i-th bin of histogram H.</p><p>-Minkowski-form Distance (L 1 distance is often used for computing dissimilarity between color images, also experimented in color histograms comparison <ref type="bibr" coords="5,186.65,187.27,14.76,8.74" target="#b16">[17]</ref>):</p><formula xml:id="formula_0" coords="5,250.17,209.89,230.42,23.29">D Lr (H, K) = ( i=1 |H i -K i |) 1 r<label>(1)</label></formula><p>-Jensen Shannon Divergence (also referred to as Jeffrey Divergence <ref type="bibr" coords="5,467.31,243.31,9.96,8.74" target="#b8">[9]</ref>, is an empirical extension of the Kullback-Leibler Divergence. It is symmetric and numerically more stable):</p><formula xml:id="formula_1" coords="5,202.04,286.57,278.55,26.65">D JSD (H, K) = i=1 H i log 2H i H i + K i + K i log 2K i K i + H i<label>(2)</label></formula><p>χ 2 Distance (measures how unlikely it is that one distribution was drawn from the population represented by the other, <ref type="bibr" coords="5,355.27,335.30,14.76,8.74" target="#b27">[28]</ref>):</p><formula xml:id="formula_2" coords="5,252.97,354.38,227.62,28.23">D χ 2 (H, K) = i=1 (H i -K i ) 2 H i<label>(3)</label></formula><p>-Bhattacharyya Distance <ref type="bibr" coords="5,277.25,392.71,12.09,8.77" target="#b5">[6]</ref> (measures the similarity of two discrete or continuous probability distributions). For discrete probability distributions H and K over the same domain, it is defined as:</p><formula xml:id="formula_3" coords="5,249.07,442.64,231.52,19.91">D B (H, K) = -ln i=1 (H i K i ) (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Classification</head><p>Many of the features presented in Section 2 are in fact histograms (color histograms, invariant feature histograms, texture histograms, local feature histograms). As comparison of distributions is a well known problem, a lot of comparison measures have been proposed in Section 2.3. To analyze the different measure distances we summarize a well known choice for supervised classification. Support Vector Machines are the state-of-the-art large margin classifiers which recently gained popularity within visual pattern and object recognition <ref type="bibr" coords="5,134.77,609.29,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="5,151.93,609.29,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,161.33,609.29,12.73,8.74" target="#b17">18,</ref><ref type="bibr" coords="5,175.72,609.29,12.73,8.74" target="#b43">44,</ref><ref type="bibr" coords="5,190.12,609.29,12.73,8.74" target="#b39">40,</ref><ref type="bibr" coords="5,204.50,609.29,11.62,8.74" target="#b41">42]</ref>. Choosing the most appropriate kernel highly depends on the problem at hand -and fine tuning its parameters can easily become a tedious task. For our experimental setup, we chose the linear kernel (which is trivial and won't be presented), the radial basis function and the χ 2 kernel, presented below.</p><p>The Gaussian Kernel is an example of radial basis function kernel.</p><formula xml:id="formula_4" coords="6,243.91,136.10,236.68,23.89">K g (x, y) = exp - x -y 2 2σ 2<label>(5)</label></formula><p>The χ 2 Kernel comes from the χ 2 distribution.</p><formula xml:id="formula_5" coords="6,241.58,199.89,239.01,30.32">K χ 2 (x, y) = 1 - n i=1 (x i -y i ) 2 1 2 (x i + y i )<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bag-of-Visual-Words (BoVW)</head><p>Recent advances in the image recognition field have shown that bag-of-visualwords <ref type="bibr" coords="6,168.19,287.16,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="6,180.37,287.16,12.73,8.74" target="#b11">12]</ref> -a strategy that draws inspiration from the text retrieval community -approaches are a good method for many image classification problems.</p><p>BoVWs representations have recently become popular for content based image classification because of their simplicity and extremely good performance. Basically, to give an estimation of the distribution we create histograms of the local features. The key idea of the bag-of-visual-words representation is to quantize each keypoint into one of the visual words that are often derived by clustering. Typically k-means clustering is used. The size of the vocabulary k is a user-supplied parameter. The visual words are the k cluster centers. The baseline of our tests are based on a bag-of-visual-words with a 100 visual words, meaning a 100-means clustering. The resulting k n-dimensional cluster centers c j represent the visual words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we explain the experimental setup, then we present and discuss the results. The different choices of distance measures and classification parameters are analyzed performing also a comparison with previous work results. Conclusions are drawn in benefit of an accurate solution for topological localization, data modeling and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets (Benchmark)</head><p>The chosen dataset contains images from nine sections of an office obtained from CLEF (Conference on Multilingual and Multimodal Information Access Evaluation). Detailed information about the dataset are in the overviews and ImageCLEF publications <ref type="bibr" coords="6,264.27,597.34,15.50,8.74" target="#b29">[30,</ref><ref type="bibr" coords="6,281.43,597.34,12.73,8.74" target="#b32">33,</ref><ref type="bibr" coords="6,295.82,597.34,11.62,8.74" target="#b24">25]</ref>. The dataset has already been split into three training sets of images, as shown in Table <ref type="table" coords="6,352.23,609.29,4.98,8.74" target="#tab_0">1</ref> one different from another. The provided images are in the RGB color space. The sequences are acquired within the same building and floor but there can be variations in the lighting conditions (sunny, cloudy, night) or the acquisition procedure (clockwise and counter clockwise). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Areas</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Eliminating False Positives</head><p>Finally, a method for the elimination of the unwanted results is performed, therefore the retrieved classes for images (Corridor, LoungeArea etc.) depend on a threshold, those below this value being rejected, with the meaning that the system doesn't recognize the image. This becomes an optimization problem of finding the best value that will cut the unwanted results, considering that it is better to have no results than inconsistent results. We adapted the implementation of the genetic algorithm described in <ref type="bibr" coords="7,450.50,393.24,14.61,8.74" target="#b10">[11]</ref>. In order to capture the particularities of the distance measures that are correlated with the rooms on which they are used, we considered a different threshold for each room. As a justification for choosing multiple thresholds rather than a single one, let us consider the case in which we are trying to classify images taken from a room that is more distinguishable from the others. The values returned by the similarity measures when comparing these images to others taken from the same room are further apart from the values returned in the case of comparing these images with others taken from different rooms. In contrast, if we consider a room that is visually similar to others, these values will be closer on the real axis. This is why it is harder to correctly separate erroneous classifications for the good ones with a single threshold.</p><p>For the genetic algorithm, the chromosomes are vectors of length 9, representing the thresholds for the 9 rooms. For the genetic operators we used the binary representation of these vectors. The fitness function evaluates the quality of the thresholds and it is the measure used to score runs in the Robot Vision task. As a selection strategy, we used the rank selection, which sorts the chromosomes accordingly to their value given by the fitness function. In the crossover process, we don't allow the parent chromosomes which are the input for the crossover to be the same individual as it could lead to early convergence. To prevent this from happening, we first select one chromosome from the population and then run the selection process in a loop until a different chromosome is returned. We also used elitism in order to assure the survival of the best chromosomes of each generation. In order to balance the diversity of the population, this method is accompanied by a slightly increased mutation probability.</p><p>For these experiments, we used a population of 200 individuals, the mutation probability of 0 : 15, and the crossover, of 0 : 7. The optimization process is stopped after 1000 generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results Interpretation</head><p>We are interested in observing the performances of the final configurations to see which features/dissimilarity measures lead to good results and which do not. As it is well known that combinations of different methods lead to good results <ref type="bibr" coords="8,166.71,255.05,14.61,8.74" target="#b15">[16]</ref>, an objective is to combine the briefly presented features. However, it is not obvious how to combine the features. To analyze the characteristics of The first column gives a description of the used training method. The descriptions of the configurations are straight forward, for example, Basic-BoVW-SIFT+HSV+RGB means a configuration of a combination of RGB and HSV color histograms and Basic-BoVW-SIFT a bag of visual words formed with SIFT feature vectors. The chosen measure distances were decided like this: Jeffrey Divergence for RGB histograms, Bhattacharyya for HSV histograms and Minkowski for SIFT feature vectors. The second column gives the recall values for the training data, the third -the precisions. The F-measure is computed and represented in the fourth column of the table. The table also shows that feature selection only is not sufficient to increase the recognition rate but more flexibility is needed here and this fact led to different combinations.</p><p>The results are improved by the addition of the SVM classification step. We also add the observation that a SVM classification of SIFT mapped on visual words can get to a maximum of 52% accuracy, but these results are very assuring in the context of a configuration in which are implied the usage of other feature descriptors. Thereby, the configuration that combines SIFT words, HSV and RGB histograms and a classification with a SVM with a RBF kernel yielded the most satisfying result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">ImageCLEF 2012 Robot Vision Task</head><p>The fourth edition of the Robot Vision challenge focused on the problem of multi-modal place classification. We had to classify functional areas on the basis of image sequences, captured by a perspective camera and a kinect mounted on a mobile robot within an office environment with nine rooms. We ranked third out of seven registered groups. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our approach on topological localization is currently applied on an office environment of nine sections: Corridor, ProfessorOffice, StudentOffice, LoungeArea, PrinterRoom, Toilet, VisioConference, ElevatorArea and TechnicalRoom. To address the problem of recognizing these sections separately, we approached the classification with specific thresholds in taking the final decision over the selected room. These thresholds create constraints that have to be loosened in order to obtain an accurate result in treating situations of great similarity between two different rooms. As an example, note that one of the main inconvenient that can appear in this case is that the rooms are very connected and difficult situations can rise as the robot moves around the office. For example, if the robot is in the Corridor, it looks to its right and sees the LoungeArea but its position is still in the Corridor. This type of situation creates noise that cannot be neglected, therefore a proper threshold needs to treat these results that correspond to a humanized interaction with the medium. The threshold on the final decision quality was chosen to avoid erroneous localizations, thus favoring a result that doesn't specify any room and giving less correct localizations but also, less false assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this work, we approached the task of topological localization without using a temporal continuity of the images and involving a broad variety of features for image recognition. The provided information about the environment is contained in images taken with a perspective color camera mounted on a robot platform and it represents an office environment dataset offered by ImageCLEF.</p><p>The main contribution of this work stays in quantifiable examinations of a wide variety of different configurations for a computer vision-based system and significant results. The experiments show that the configurations from different feature descriptors and distance measures depend on the proper combinations.</p><p>From the fact that most of the works cited are from the last couple of years, topological localization is a new and active area of research, which is increasingly producing interest and enforces further development. An important contribution to this field is given in this paper, along with notable experimental results, but there is still room for improvement and further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgement</head><p>The research presented in this paper was funded by the Sector Operational Program for Human Resources Development through the project "Development of the innovation capacity and increasing of the research impact through postdoctoral programs"POSDRU/89/1.5/S/49944.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,136.16,119.77,328.20,139.12"><head>Table 1 .</head><label>1</label><figDesc>Training Sequences of An Office Environment</figDesc><table coords="7,309.03,119.77,155.34,19.22"><row><cell></cell><cell># Images</cell><cell></cell></row><row><cell>training1</cell><cell>training2</cell><cell>training3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,301.64,345.83,196.55"><head>Table 2 .</head><label>2</label><figDesc>Performance Comparison for Topological Localizationfeatures and which features have similar properties, we perform an evaluation on selected configurations as shown in Table2. The evaluation was performed choosing Training 1 and 3 (Table1) for training and Training 2 for testing.</figDesc><table coords="8,136.16,301.64,329.84,106.89"><row><cell>Method</cell><cell>R[%]</cell><cell>P[%]</cell><cell>F</cell></row><row><cell>RGB-Only</cell><cell>73.73</cell><cell>82.02</cell><cell>0.77</cell></row><row><cell>HSV-Only</cell><cell>76.46</cell><cell>82.34</cell><cell>0.79</cell></row><row><cell>RGB-HSV</cell><cell>76.42</cell><cell>79.66</cell><cell>0.780</cell></row><row><cell>Basic-BoVW-SIFT</cell><cell>45.10</cell><cell>46.51</cell><cell>0.45</cell></row><row><cell>Basic-BoVW-SIFT+HSV+RGB</cell><cell>76.85</cell><cell>79.26</cell><cell>0.780</cell></row><row><cell>Basic-BoVW-ASIFT+HSV+RGB</cell><cell>77.60</cell><cell>79.97</cell><cell>0.787</cell></row><row><cell>SVM-RBF-BoVW-SIFT+HSV+RGB</cell><cell>78.87</cell><cell>78.87</cell><cell>0.788</cell></row><row><cell>SVM-LINEAR-BoVW-SIFT+HSV+RGB</cell><cell>78.63</cell><cell>78.94</cell><cell>0.787</cell></row><row><cell>SVM-χ 2 -BoVW-SIFT+HSV+RGB</cell><cell>78.43</cell><cell>78.52</cell><cell>0.784</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,136.16,286.56,350.67,160.64"><head>Table 3 .</head><label>3</label><figDesc>ImageCLEF 2012 Robot Vision final results</figDesc><table coords="9,136.16,286.56,36.15,7.86"><row><cell># Group</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,536.71,337.63,7.86;10,151.52,547.67,191.09,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,287.83,536.71,192.76,7.86;10,151.52,547.67,15.40,7.86">Uaic: Participation in imageclef 2009 robotvision task</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boroş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Roşca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,174.86,547.67,163.03,7.86">Proceedings of the CLEF 2009 Workshop</title>
		<meeting>the CLEF 2009 Workshop</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,558.76,337.63,7.86;10,151.52,569.72,329.07,7.86;10,151.52,580.68,329.07,7.86;10,151.52,591.64,95.42,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,295.15,558.76,185.44,7.86;10,151.52,569.72,325.77,7.86">Using sift method for global topological localization for indoor environments. Multilingual Information Access Evaluation II</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boroş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Roşca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,151.52,580.68,98.42,7.86">Multimedia Experiments</title>
		<imprint>
			<biblScope unit="volume">6242</biblScope>
			<biblScope unit="page" from="277" to="282" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Part II</note>
</biblStruct>

<biblStruct coords="10,142.96,602.73,337.64,7.86;10,151.52,613.69,94.03,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,315.86,602.73,164.74,7.86;10,151.52,613.69,36.12,7.86">Image classification using random forests and ferns</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,195.36,613.69,20.90,7.86">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,624.78,337.63,7.86;10,151.52,635.74,329.07,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,259.25,624.78,177.42,7.86">Invariant features from interest point groups</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,444.72,624.78,35.86,7.86;10,151.52,635.74,140.15,7.86">The 13th British Machine Vision Conference</title>
		<meeting><address><addrLine>Cardiff University, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,646.84,337.64,7.86;10,151.52,657.79,155.13,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,326.32,646.84,154.27,7.86;10,151.52,657.79,38.00,7.86">Performance evaluation of local color invariants</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Burghouts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,197.40,657.79,21.31,7.86">CVIU</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">113</biblScope>
			<biblScope unit="page">4862</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,120.67,337.64,7.86;11,151.52,131.63,165.14,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,245.10,120.67,231.56,7.86">Feature extraction based on the bhattacharyya distance</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,131.63,78.16,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1703" to="1709" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,142.60,337.64,7.86;11,151.52,153.55,329.07,7.86;11,151.52,164.51,125.48,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,272.54,142.60,208.05,7.86;11,151.52,153.55,243.31,7.86">Topological simultaneous localization and mapping (slam): toward exact localization without explicit localization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Choset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nagatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,401.71,153.55,78.88,7.86;11,151.52,164.51,35.54,7.86">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="137" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,175.48,337.63,7.86;11,151.52,186.44,329.07,7.86;11,151.52,197.40,129.57,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,395.79,175.48,84.80,7.86;11,151.52,186.44,89.47,7.86">Visual categorization with bags of keypoints</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,249.40,186.44,231.19,7.86;11,151.52,197.40,67.74,7.86">ECCV International Workshop on Statistical Learning in Computer Vision</title>
		<meeting><address><addrLine>Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,208.36,337.63,7.86;11,151.52,219.32,166.09,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,301.52,208.36,179.07,7.86;11,151.52,219.32,43.82,7.86">Features for image retrieval: An experimental comparison</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,203.80,219.32,85.91,7.86">Information Retrieval</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,230.29,337.97,7.86;11,151.52,241.25,329.07,7.86;11,151.52,252.21,20.99,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,263.13,230.29,217.46,7.86;11,151.52,241.25,32.07,7.86">Robust place recognition using local appearance based methods</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Dudek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jugessur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,191.11,241.25,213.84,7.86">IEEE Intl. Conf. on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1030" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,263.17,337.98,7.86;11,151.52,274.13,329.07,7.86;11,151.52,285.09,172.62,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,272.74,263.17,207.85,7.86;11,151.52,274.13,242.83,7.86">Using a genetic algorithm for optimizing the similarity aggregation step in the process of ontology alignment</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Gînscȃ</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,404.30,274.13,76.29,7.86;11,151.52,285.09,167.65,7.86">Proceedings, of 9th International Conference RoEduNet IEEE</title>
		<meeting>of 9th International Conference RoEduNet IEEE</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,296.06,337.98,7.86;11,151.52,307.02,157.60,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,254.63,296.06,222.01,7.86">Scene classification using bag-of-regions representations</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gokalp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aksoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,307.02,83.15,7.86">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,317.98,337.98,7.86;11,151.52,328.94,329.07,7.86;11,151.52,339.90,279.48,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,310.50,317.98,170.09,7.86;11,151.52,328.94,120.91,7.86">Rover localization in natural environments by indexing panoramic images</title>
		<author>
			<persName coords=""><forename type="first">J.-J</forename><surname>Gonzalez-Barbosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lacroix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,281.20,328.94,199.39,7.86;11,151.52,339.90,178.35,7.86">Proceedings of the 2002 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<meeting>the 2002 IEEE International Conference on Robotics and Automation (ICRA)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1365" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,350.87,337.97,7.86;11,151.52,361.82,329.07,7.86;11,151.52,372.78,69.62,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,332.45,350.87,148.14,7.86;11,151.52,361.82,297.86,7.86">Openimaj and imageterrier: Java libraries and tools for scalable multimedia analysis and indexing of images</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Samangooei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dupplaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,459.15,361.82,21.45,7.86;11,151.52,372.78,44.95,7.86">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,383.75,337.98,7.86;11,151.52,394.71,329.07,7.86;11,151.52,405.67,135.64,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,268.01,383.75,212.58,7.86;11,151.52,394.71,68.55,7.86">Pca-sift: A more distinctive representation for local image descriptors</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,227.26,394.71,253.33,7.86;11,151.52,405.67,44.51,7.86">Proceedings of the Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="511" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,416.63,337.98,7.86;11,151.52,427.59,230.81,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,354.21,416.63,96.65,7.86">On combining classiffers</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hatef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P W</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,458.31,416.63,22.28,7.86;11,151.52,427.59,138.92,7.86">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="226" to="239" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,438.56,337.97,7.86;11,151.52,449.52,329.07,7.86;11,151.52,460.48,152.86,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,342.79,438.56,137.80,7.86;11,151.52,449.52,102.62,7.86">Color matching of images by using minkowski-form distance</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Kurhe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Satonka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">B</forename><surname>Khanale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,263.95,449.52,212.41,7.86">Global Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2011">2011</date>
			<publisher>Global Journals Inc</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,471.44,337.98,7.86;11,151.52,482.40,54.55,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,257.10,471.44,219.57,7.86">Latent mixture vocabularies for object categorization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,482.40,24.39,7.86">BMVC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,493.37,337.98,7.86;11,151.52,504.33,327.34,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,248.27,493.37,232.32,7.86;11,151.52,504.33,51.33,7.86">Latent mixture vocabularies for object categorization and segmentation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,211.21,504.33,153.70,7.86">Journal of Image &amp; Vision Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="523" to="534" />
			<date type="published" when="2009-04">April 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,515.29,337.98,7.86;11,151.52,526.25,329.07,7.86;11,151.52,537.21,194.78,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,257.39,515.29,223.20,7.86;11,151.52,526.25,49.79,7.86">Importance of feature locations in bag-of-words image classification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Aarabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,213.34,526.25,267.26,7.86;11,151.52,537.21,114.99,7.86">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="641" to="I644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,548.18,337.98,7.86;11,151.52,559.14,272.28,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,271.10,548.18,209.49,7.86;11,151.52,559.14,44.23,7.86">Reduced sift features for image retrieval and indoor localisation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ledwich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,203.53,559.14,191.67,7.86">Australasian Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,567.84,337.98,10.13;11,151.52,581.06,319.14,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,407.74,570.10,72.85,7.86;11,151.52,581.06,158.24,7.86">Scalability of local image descriptors: A comparative study</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lejsek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">H</forename><surname>Ásmundsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thór-Jónsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,317.87,581.06,124.40,7.86">ACM Int. Conf. on Multimedia</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,592.03,337.98,7.86;11,151.52,602.99,197.21,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,191.92,592.03,227.57,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,428.00,592.03,52.60,7.86;11,151.52,602.99,112.22,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,613.95,337.98,7.86;11,151.52,624.91,315.66,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,203.98,613.95,212.26,7.86">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,423.97,613.95,56.62,7.86;11,151.52,624.91,215.27,7.86">Proceedings of the 7th International Conference on Computer Vision</title>
		<meeting>the 7th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,635.88,337.98,7.86;11,151.52,646.84,329.07,7.86;11,151.52,657.79,273.60,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="11,264.67,635.88,215.93,7.86;11,151.52,646.84,209.85,7.86">Combination of classifiers for indoor room recognition, cgs participation at imageclef2010 robot vision task</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lucetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Luchetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,370.83,646.84,109.76,7.86;11,151.52,657.79,245.34,7.86">Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,120.67,337.98,7.86;12,151.52,131.63,321.14,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,278.97,120.67,161.40,7.86">An afine invariant interest point detector</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,447.41,120.67,33.18,7.86;12,151.52,131.63,229.96,7.86">Proceedings of the 7th European Conference on Computer Vision</title>
		<meeting>the 7th European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="128" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,142.59,337.98,7.86;12,151.52,153.55,75.05,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,285.05,142.59,191.64,7.86">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,153.55,19.49,7.86">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,164.51,337.97,7.86;12,151.52,175.46,329.07,7.86;12,151.52,186.42,20.99,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,416.91,164.51,63.68,7.86;12,151.52,175.46,199.08,7.86">Learning object representations for visual object class recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Harzallah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,359.78,175.46,116.60,7.86">Visual Recognition Challange</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,197.38,337.98,7.86;12,151.52,208.34,278.84,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="12,247.36,197.38,233.23,7.86;12,151.52,208.34,43.82,7.86">Asift: A new framework for fully affine invariant image comparison</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Morel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,203.80,208.34,141.67,7.86">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="438" to="469" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,219.30,224.35,7.86;12,422.57,219.30,58.02,7.86;12,151.52,230.26,262.40,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="12,422.57,219.30,58.02,7.86;12,151.52,230.26,49.79,7.86">semantic place classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pronobis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Mozos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jensfelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,208.95,230.26,73.13,7.86">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">298320</biblScope>
			<date type="published" when="2010-02">February 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,241.22,337.98,7.86;12,151.52,252.18,329.07,7.86;12,151.52,263.14,189.81,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="12,383.90,241.22,96.69,7.86;12,151.52,252.18,178.40,7.86">Empirical evaluation of dissimilarity measures for color and texture</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,340.55,252.18,140.04,7.86;12,151.52,263.14,67.74,7.86">Proc. International Conference on Computer Vision</title>
		<meeting>International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11651173</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,274.09,337.98,7.86;12,151.52,285.05,319.44,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="12,309.98,274.09,170.62,7.86;12,151.52,285.05,58.69,7.86">The earth mover&apos;s distance as a metric for image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,217.86,285.05,168.11,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="121" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,296.01,337.97,7.86;12,151.52,306.97,329.07,7.86;12,151.52,317.93,207.47,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="12,339.44,296.01,141.15,7.86;12,151.52,306.97,139.57,7.86">Visual localization using global visual features and vanishing points</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Saurer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fraundorfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,302.01,306.97,178.57,7.86;12,151.52,317.93,179.22,7.86">Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,328.89,337.98,7.86;12,151.52,339.85,329.07,7.86;12,151.52,350.81,315.54,7.86" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="12,458.70,328.89,21.89,7.86;12,151.52,339.85,220.83,7.86">Local versus global features for content-based image retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kosaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aisen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Broderick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,380.04,339.85,100.56,7.86;12,151.52,350.81,211.30,7.86">Proc. IEEE Workshop of Content-Based Access of Image and Video Databases</title>
		<meeting>IEEE Workshop of Content-Based Access of Image and Video Databases</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,361.77,337.98,7.86;12,151.52,372.73,329.07,7.86;12,151.52,383.68,125.00,7.86" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="12,271.97,361.77,208.63,7.86;12,151.52,372.73,74.31,7.86">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,233.71,372.73,246.88,7.86;12,151.52,383.68,24.59,7.86">Proceedings of the 9th International Conference on Computer Vision</title>
		<meeting>the 9th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1470" to="1478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,394.64,337.98,7.86;12,151.52,405.60,329.07,7.86;12,151.52,416.56,72.62,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="12,277.41,394.64,199.05,7.86">Finding images of landmarks in video sequences</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,405.60,329.07,7.86;12,151.52,416.56,44.51,7.86">Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,427.52,337.98,7.86;12,151.52,438.48,191.01,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="12,196.61,427.52,279.93,7.86">Learning metric-topological maps for indoor mobile robot navigation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,438.48,83.46,7.86">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="21" to="71" />
			<date type="published" when="1998-02">February 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,449.44,337.98,7.86;12,151.52,460.40,265.26,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="12,273.42,449.44,207.18,7.86;12,151.52,460.40,44.66,7.86">Appearance-based place recognition for topological localization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Nourbakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,203.99,460.40,184.19,7.86">IEEE Intl. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,471.36,188.17,7.86" xml:id="b38">
	<monogr>
		<title level="m" type="main" coord="12,199.12,471.36,102.63,7.86">Statistical learning theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,482.31,337.97,7.86;12,151.52,493.27,167.93,7.86" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="12,310.91,482.31,169.68,7.86;12,151.52,493.27,22.62,7.86">Recognition with local features: the kernel recipe</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wallraven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,182.00,493.27,45.13,7.86">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,504.23,337.98,7.86;12,151.52,515.19,329.07,7.86;12,151.52,526.15,329.07,7.86" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="12,332.35,504.23,148.24,7.86;12,151.52,515.19,299.25,7.86">Robust vision-based localization for mobile robots using an image retrieval system based on invariant features</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Burkhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,459.65,515.19,20.94,7.86;12,151.52,526.15,300.42,7.86">Proc. of the IEEE International Conference on Robotics and Automation (ICRA)</title>
		<meeting>of the IEEE International Conference on Robotics and Automation (ICRA)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,537.11,337.97,7.86;12,151.52,548.07,310.60,7.86" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="12,257.16,537.11,223.43,7.86;12,151.52,548.07,181.62,7.86">Kernel principal angles for classification machines with applications to image sequence interpretation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,341.10,548.07,47.39,7.86">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="635" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,559.03,337.98,7.86;12,151.52,569.99,252.51,7.86" xml:id="b42">
	<monogr>
		<title level="m" type="main" coord="12,380.39,559.03,100.20,7.86;12,151.52,569.99,175.00,7.86">Evaluating bag-of-visualwords representations in scene classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Ngo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>ACM MIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,580.94,337.97,7.86;12,151.52,591.90,329.07,7.86;12,151.52,602.86,58.37,7.86" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="12,374.58,580.94,106.01,7.86;12,151.52,591.90,295.71,7.86">Local features and kernels for classification of texture and object categories: A comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,456.22,591.90,19.49,7.86">IJCV</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
