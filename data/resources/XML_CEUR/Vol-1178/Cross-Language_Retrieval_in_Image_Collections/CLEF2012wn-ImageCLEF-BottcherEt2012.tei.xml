<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.02,115.96,287.31,12.62;1,246.43,133.89,122.49,12.62">BTU DBIS&apos; Plant Identification Runs at ImageCLEF 2012</title>
				<funder ref="#_fM5vZFw">
					<orgName type="full">Federal Ministry of Education and Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.90,171.56,74.31,8.74"><forename type="first">Thomas</forename><surname>Böttcher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.04,171.56,80.23,8.74"><forename type="first">Christoph</forename><surname>Schmidt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.40,171.56,65.83,8.74"><forename type="first">David</forename><surname>Zellhöfer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.00,171.56,56.45,8.74"><forename type="first">Ingo</forename><surname>Schmitt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.02,115.96,287.31,12.62;1,246.43,133.89,122.49,12.62">BTU DBIS&apos; Plant Identification Runs at ImageCLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F1832F12252E979E4C89AED498C5084</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Content-Based Image Retrieval</term>
					<term>Clustering</term>
					<term>Experiments</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we summarize the results of our first participation in the plant identification task. Unlike other contributors, we present a rather untypical approach, which does not rely on classification techniques. In contrast, logical combinations of low-level features expressed in a query language are used to assess a document's similarity to a species. Similar to ImageCLEF 2011, DBIS' approach is based on the commuting quantum query language (CQQL). CQQL was proposed by the workgroup to combine similarity predicates as found in information retrieval and relational predicates common in databases. In order to combine both predicate types, CQQL utilizes the mathematical formalisms of quantum mechanics and logic eventually forming a probabilistic logic. To test the utility of our query language, three different automatic approaches are discussed. First, a query by example approach towards plant identification is presented. Second, the approach is combined with a kmedoid technique to exploit relationships within the top-k results. To conclude with, the aforementioned techniques are compared with the utilization of the k-medoid method alone. With respect to the non-existent experience with the task, the results of the discussed approach are fairly decent but leave room for improvement being outlined as future work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we present the results of the Database and Information Systems Group's (DBIS) participation in the plant identification task that was organized within ImageCLEF 2012. Because it is our first try with the Pl@ntLeaves data set, our main objective was to gain experience with the data set and to investigate future directions of research. Unlike other contributors, we present a rather untypical approach, which does not rely on classification techniques. In contrast, logical combinations of low-level features expressed in a query language are used to assess a document's similarity to a species.</p><p>Similar to ImageCLEF 2011 <ref type="bibr" coords="1,273.33,644.16,14.61,8.74" target="#b14">[15]</ref>, DBIS' approach is based on the commuting quantum query language (CQQL) <ref type="bibr" coords="1,288.89,656.12,9.96,8.74" target="#b7">[8]</ref>. CQQL was proposed by the workgroup to combine similarity predicates as found in information retrieval (IR) and relational predicates common in databases (DB). In order to combine both predicate types, CQQL utilizes the mathematical formalisms of quantum mechanics and logic eventually forming a probabilistic logic <ref type="bibr" coords="2,328.57,154.86,9.96,8.74" target="#b4">[5]</ref>. For the sake of brevity, the theory of CQQL is not covered in this paper. Instead, its relation to probabilistic and other quantum mechanics-derived IR models is covered in <ref type="bibr" coords="2,420.15,178.77,14.61,8.74" target="#b15">[16]</ref>, while <ref type="bibr" coords="2,470.08,178.77,10.52,8.74" target="#b8">[9]</ref> discriminates it from fuzzy logic <ref type="bibr" coords="2,278.01,190.72,14.61,8.74" target="#b10">[11]</ref>.</p><p>The core idea of the presented approach can be summarized as follows. Based on different document representations, e.g. color-based low-level features or accompanying metadata such as GPS information, a logical CQQL query is formulated, e.g. to define the species' characteristics. Based on the CQQL evaluation rules describes in prior work <ref type="bibr" coords="2,258.83,250.50,10.52,8.74" target="#b7">[8]</ref> and summarized in Section 2, the query is transformed into an arithmetic formula which is then used to calculate the similarity between the documents in the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Plant identification Task</head><p>The plant identification task is part of ImageCLEF for the second time. It is focused on tree species identification based on leaf images. In comparison to the last year's challenge there are some novelties. The number of species has been increased from 70 to 126. Furthermore the main objective changed from pure classification to a plant species retrieval task. In the following section we describe the basic characteristics of the data and their identification as far as it is needed for the understanding of this paper. The complete description of the plant identification task 2012 be found in <ref type="bibr" coords="2,318.30,407.09,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Test Data</head><p>The plant identification task is based on the Pl@nt-Leaves data set <ref type="bibr" coords="2,209.26,448.52,9.96,8.74" target="#b5">[6]</ref>, which is divided into training and test data. The training subset was built by including the training and test subsets of last year's Pl@ntLeaves data set, and by randomly selecting 2/3 of the individual plants <ref type="bibr" coords="2,134.77,484.38,9.96,8.74" target="#b2">[3]</ref>. The complete data set contains 11,572 pictures, 126 tree species mainly from the French Mediterranean area, subdivided into 3 different kinds of pictures: scans, scan-like photos and natural photos <ref type="bibr" coords="2,323.48,508.29,9.96,8.74" target="#b2">[3]</ref>. The distribution of training and test data of the Pl@ntLeaves data set is shown in Table <ref type="table" coords="2,381.34,520.25,3.87,8.74" target="#tab_0">1</ref>. Identification and evaluation The goal of this task is to identify the tree species, whose leaf is depicted on a given test image. In consequence, for each test image, a prediction should be made for each of the 126 plant species. For the scope of the task, a prediction is a score between 0 and 1 expressing the confidence that a given sample images belongs to a given species.</p><p>To evaluate the prediction quality, the task organizers calculated a score which is related to the rank of the correct species in the result list. Thereby a mean value is built per author and per plant which is in the collection. An author is a person which helped to built up the Pl@ntLeaves collection. The score is defined in the following formula <ref type="bibr" coords="3,276.49,202.69,9.96,8.74" target="#b2">[3]</ref>:</p><formula xml:id="formula_0" coords="3,236.54,223.46,244.05,31.28">S = 1 U U u=1 1 P Pu p=1 1 N u,p Nu,p n=1 s u,p,n<label>(1)</label></formula><p>U : number of users (who have at least one image in the test data) P u : number of individual plants observed by the u-th user N u,p : number of pictures taken from the p-th plant observed by the u-th user s u,p,n : classification score (1 or 0) for the n-th picture taken from the p-th plant observed by the u-th user</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval Model</head><p>Repeating our summary found in prior work <ref type="bibr" coords="3,337.29,379.02,14.61,8.74" target="#b14">[15]</ref>, CQQL can be considered a query language dealing with probabilities that is consistent with the laws of the Boolean algebra. The probabilities denote how "similar" a document is to a query regarding a given condition in the query, e.g. a color histogram. In the next section, we will sketch the arithmetic evaluation of CQQL as it is necessary for the understanding of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evaluation of CQQL</head><p>Given that f ϕ (d) is the evaluation of a document d w.r.t. a CQQL query q. To form q, various conditions ϕ can be linked in an arbitrary manner using the conjunction (Equation <ref type="formula" coords="3,234.80,512.57,3.87,8.74" target="#formula_1">2</ref>), disjunction (Equation <ref type="formula" coords="3,346.64,512.57,3.87,8.74" target="#formula_2">3</ref>), or negation (Equation <ref type="formula" coords="3,459.42,512.57,3.87,8.74" target="#formula_3">4</ref>). If ϕ is atomic, f ϕ (d) can be directly evaluated yielding a value out of the interval [0; 1] As stated before, the actual value of a representation can be calculated by a similarity measure or a Boolean evaluation carried out by a DB system or the like.</p><p>After a necessary syntactical normalization step <ref type="bibr" coords="3,371.50,572.35,14.61,8.74" target="#b17">[18]</ref>, the evaluation of a CQQL query is performed by recursively applying the succeeding formulas until the atomic base case is reached:</p><formula xml:id="formula_1" coords="3,247.93,620.19,232.67,9.65">f ϕ1∧ϕ2 (d) = f ϕ1 (d) * f ϕ2 (d)<label>(2)</label></formula><formula xml:id="formula_2" coords="3,203.61,638.15,276.98,9.65">f ϕ1∨ϕ2 (d) = f ϕ1 (d) + f ϕ2 (d) -(f ϕ1 (d) ∧ f ϕ2 (d))<label>(3)</label></formula><formula xml:id="formula_3" coords="3,266.22,656.12,214.36,9.65">f ¬ϕ (d) = 1 -f ϕ (d)<label>(4)</label></formula><p>The result of an evaluation of a document d yields the probability of relevance of d w.r.t. the given query. This probability value is then used for the ranking of the result list of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Weighting in CQQL</head><p>In order to steer the influence of certain conditions onto the query evaluation, CQQL has been extended with a weighting scheme <ref type="bibr" coords="4,364.25,213.29,9.96,8.74" target="#b6">[7]</ref>. This weighting scheme can be used for relevance feedback (RF) during the retrieval process. Weighting is a crucial part of our machine-based learning supported user interaction model discussed in <ref type="bibr" coords="4,187.54,249.16,14.61,8.74" target="#b17">[18]</ref>. Although an extensive evaluation of RF for multimodal retrieval is not in the scope of this paper, we will outline how weights are embedded in a CQQL query because the weights are later used for the optimization of the discussed queries (see Table <ref type="table" coords="4,259.05,285.02,3.87,8.74" target="#tab_1">2</ref>). Equation <ref type="formula" coords="4,194.21,297.84,4.98,8.74" target="#formula_4">5</ref>denotes a weighted conjunction, whereas Equation <ref type="formula" coords="4,436.05,297.84,4.98,8.74">6</ref>states a weighted disjunction. A weight θ i is directly associated with a logical connector and steers the influence of a representation ϕ i on the evaluation. To evaluate a weighted CQQL query, the weights are syntactically replaced by constant values according to the following rules:</p><formula xml:id="formula_4" coords="4,223.17,373.02,257.42,9.65">ϕ 1 ∧ θ1,θ2 ϕ 2 (ϕ 1 ∨ ¬θ 1 ) ∧ (ϕ 2 ∨ ¬θ 2 )<label>(5)</label></formula><formula xml:id="formula_5" coords="4,229.81,396.12,250.78,9.65">ϕ 1 ∨ θ1,θ2 ϕ 2 (ϕ 1 ∧ θ 1 ) ∨ (ϕ 2 ∧ θ 2 ) (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Description</head><p>For the scope of this paper, experiments have been conducted on low-level features combined with some of the provided metadata. The discussed approach aims at improving the performance on the plant identification task by using combinations of different features. Hence, the three main objectives of the experiments are as follows:</p><p>First, we will investigate and optimize the efficiency of a combination of visual low-level features alone.</p><p>Second, the performance improvement using low-level features as well as metadata in a CQQL query will be examined.</p><p>Third, the discussed CQQL approach will be compared with other state-ofthe-art systems using classification systems like support vector machines (SVM).</p><p>In order to investigate these points, three different approaches are used in combination with a preparatory study (see Section 3.1). Section 3.2 describes the results of a query by example (QBE) approach, while Section 3.4 presents a solution of the plant identification task using a k-medoid clustering technique. Section 3.3 combines both approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preparatory Study</head><p>In order to conduct the experiments, a preparatory study has been carried out. All assumptions used later are based on this study.</p><p>To conduct the preparatory study, we used our own developed multimodal retrieval system <ref type="bibr" coords="5,208.21,175.76,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="5,225.37,175.76,11.62,8.74" target="#b11">12]</ref>. The retrieval systems allows the extraction and combination of several different document representations, e.g. low-level features, metadata, textual information or database attributes. Additionally, the system allows a preference-based relevance feedback approach for learning weights inside a CQQL formula. A detailed description of the approach is discussed in prior work <ref type="bibr" coords="5,159.15,235.53,15.49,8.74" target="#b16">[17,</ref><ref type="bibr" coords="5,176.30,235.53,11.62,8.74" target="#b17">18]</ref>.</p><p>To get an overview of the performance of the individual low-level features we measured the accuracy of them with the Pl@ntLeaves data set. For our first participation we decided not to evaluate each image type (scan, scan like, photographs) separately. An excerpt of the results of our initial evaluation runs is shown in Figure <ref type="figure" coords="5,216.40,295.47,4.98,8.74" target="#fig_0">1</ref> displaying the values of precision at 5, 10, 20, 30, and mean average precision (MAP). Overall, we tested 15 low-level features in addition to the given GPS information. To calculate the similarity between the GPS data of two images we used the following similarity measure:</p><formula xml:id="formula_6" coords="5,161.86,352.85,318.73,23.51">GP S sim = 1 - (71.5 • (long x -long y )) 2 + (111.3 • (lat x -lat y )) 2 6378.388<label>(7)</label></formula><p>whereas long stands for longitude and lat for latitude.</p><p>The MPEG-7 Color Structure Descriptor (CSD) <ref type="bibr" coords="5,352.00,409.90,9.96,8.74" target="#b3">[4]</ref>, which defines a color distribution and the spatial structure of an image, was the best performing visual feature whereas GPS performed surprisingly poor. The bad performance is due to the distribution of the plant species over several territories. As a single feature it is nearly worthless for this task. Although, it can improve performance when used in combination (see Figure <ref type="figure" coords="5,277.29,469.68,3.87,8.74">2</ref>; U CC 08 ).</p><p>Based on the results of Figure <ref type="figure" coords="5,277.93,481.80,3.87,8.74" target="#fig_0">1</ref>, we tried to find different CQQL combinations that would exceed the performance of the low-level feature runs. Our first combinations were based on our former evaluations with general purpose image collections like Caltech 101 <ref type="bibr" coords="5,260.06,517.66,9.96,8.74" target="#b0">[1]</ref>, Pythia <ref type="bibr" coords="5,311.33,517.66,14.61,8.74" target="#b12">[13]</ref>, or Wang <ref type="bibr" coords="5,376.57,517.66,14.61,8.74" target="#b9">[10]</ref>. Unfortunately, the results could not be transferred successfully because of the specialized nature of the plant identification task. Consequently, new combinations using the best performing low-level visual features were examined. An excerpt of the used CQQL combinations can be found in Table <ref type="table" coords="5,201.73,577.60,3.87,8.74" target="#tab_1">2</ref>.</p><p>Test Design We evaluated the performance using the given training data but using MAP and Precision at n evaluation metrics instead of the special plant identification metric. In total, 14 CQQL formulas containing visual low-level features and two combinations of visual and GPS data were tested. To evaluate the CQQL combinations, we used a Z-Score normalization for each feature similarity  </p><formula xml:id="formula_7" coords="6,136.16,466.77,345.78,141.52">(CEDDsim ∨ θ 1 ,θ 2 FCTHsim ) ∧ (COLORLAYOUTsim ∨ (TAMURAsim ∧ EDGEHISTOGRAMsim )) UCC00 V θ i (COLORSTRUCTUREsim , CEDDsim , FCTHsim ) UCC03 (CEDDsim ∨ θ 1 ,θ 2 F CT Hsim)∧ θ 5 ,θ 6 (COLORST RU CT U REsim ∨ θ 3 ,θ 4 AU T OCOLORCORRELOGRAMsim) UCC04 (REGION SHAP Esim ∨ θ 1 ,θ 2 COLORST RU CT U REsim)∧ θ 5 ,θ 6 (T AM U RAsim ∨ θ 3 ,θ 4 COLCORHIST OGRAMsim) UCC06 (REGION SHAP Esim ∨ θ 1 ,θ 2 COLORST RU CT U REsim)∧ θ 7 ,θ 8 (T AM U RAsim ∨ θ 3 ,θ 4 COLCORHIST OGRAMsim)∧ θ 9 ,θ 10 (EDGEHIST OGRAMsim ∨ θ 5 ,θ 6 COLCORLAY OU Tsim) UCC08 GP Ssim ∧ ((REGION SHAP Esim ∨ θ 1 ,θ 2 COLORST RU CT U REsim)∧ θ 7 ,θ 8 (T AM U RAsim ∨ θ 3 ,θ 4 COLCORHIST OGRAMsim)∧ θ 9 ,θ 10 (EDGEHIST OGRAMsim ∨ θ 5 ,θ 6 COLCORLAY OU Tsim))</formula><p>Weights (θi) are initially set to 1.0. F eaturesim denotes similarity of a representation to the QBE document.</p><p>and the CQQL evaluation rules (see Formulae 2, 3, and 4). Together with the ground truth of the training data and our preference based approach we tried to optimize the weights used in the CQQL formulas in order to improve the retrieval metrics. Initially all weights (θ i ) are set to 1. After a learning run, the weights are set to values between 0 and 1 that fulfill the most preferences given by the ground truth. An excerpt from the final evaluation results can be found in Figure <ref type="figure" coords="7,177.83,190.72,3.87,8.74">2</ref>.</p><p>The best visual-only run gives us a small performance boost of about 14% with a MAP value of 0.39 and a P@5 of 0.75 in comparison to the best single feature ColorStructure. In contrast, the best multimodal CQQL combination (UCC08) gives a clearly greater performance boost of about 39% with a MAP value of 0.47 and P@5 of 0.8. It should be noted that we use no optimization for each image type (scan, scan like or photograph) which should improve the values even further.</p><p>Fig. <ref type="figure" coords="7,162.14,508.17,4.13,7.89">2</ref>. Evaluation of CQQL combinations (unweighted and with learned weights)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">QBE-based Approach</head><p>We used a query by example (QBE) based approach for run 1 and 2 (see Figure <ref type="figure" coords="7,152.38,596.18,3.87,8.74">3</ref>). For this approach, test images are considered QBE documents and the training images form the collection to be used for retrieval. The only difference between both runs of the QBE approach is that the first run (our main run) uses a multimodal CQQL combination (UCC08) whereas the second run is based on a CQQL combination consisting only of visual features (UCC06).</p><p>Based on the preparatory study, CQQL queries were defined using the best performing features. To learn the actual weight values, we picked a small random sample of images of all image types (scans, scan-like and photographs). With this training data, we evaluated the initial retrieval performance. To learn the best weights for a query, three steps were carried out:</p><p>1. A set of QBE images was chosen randomly from the training data. The QBE set includes all image types and some species which have the highest frequency in the training data. 2. For each of the QBE images, a ranking is calculated using a distinct set of weight values. 3. The results were interpreted using precision at n and MAP to reveal the best weight setting.</p><p>In order to find out the optimal weight setting, each QBE image is used to retrieve similar images from the collection eventually generating a ranking. As we know the species for each QBE document the ranking can then be compared with the optimal ranking of a species. This comparison is needed for the automatic preference input in order to learn weights with the presented approach. In order to provide preferences, the first 500 (at most) documents of the generated ranking are checked for irrelevant documents preceding relevant ones regarding the examined species defined by the current QBE document. If such an order d irrelevant &gt; d relevant is detected, and inverted preference d irrelevant &lt; d relevant is defined. After the first 500 (at most) documents have been tested, these preferences serve as input for the weight learning algorithm. Using these weights, a new ranking is generated. This ranking is then evaluated for the aforementioned retrieval metrics. To conclude with, all runs are averaged to determine an average set of weight values for a given query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">QBE-based Approach Combined with Top-k Clustering</head><p>For our second test (run 3), we used an approach combining a QBE-based approach with image clustering. The first part of this approach uses the same techniques as described in the last section. To reveal the relationship of all images found in the top-k result, we applied an image clustering method. We expected to find a homogeneous group of images which could then be used to determine the species of the query document. Therefore we used a distance based clustering approach, a k-medoid clustering. It was necessary to use such a method because we want use the CQQL similarities between all top-k images.</p><p>The result of the k-medoid clustering is a set of clusters. A cluster contains a mixture of training and test data (cluster members). To make a prediction which species should be associated with a given test image, we inspect the cluster containing the test image. Analyzing the rest of the cluster members (considering only training images of which the species is known), we check to which species the training data belongs. Taking the distance between the test image and the nearest training image, a ranking is created. The ordered list gives us the probability of a membership for all species within the cluster. To get a prediction for each type of species, we take the other clusters and continue following the same principle. To optimize our approach, we evaluate which values for top-k and the number of clusters reached the best quality. The idea of the used quality measure is straightforward: a correct classification on the first predicted species will define a score value of 1. If the correct species is on the n-th position we define a score value of n. Then a minimized summed score value defines the best quality.</p><p>The usage of this combined approach gives us the opportunity to use the frequency of occurrence of the plant species. In the next approach, multiple occurrences of a species are ignored. Instead, only the first appearance is regarded important. Considering all top-k documents, we expect some species to occur repeatedly. A clustering on these images (with multiple occurrences of a species) yields a (good) probability that images with the same species belong to the same cluster (because of their high similarity). For a given test image which belongs to the same cluster there is a high probability that this test image belongs to the species too. The handling of images which occur very rarely or never in the training data set is complicated because our prediction is undefined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Cluster-based approach</head><p>For our last try (run 4), we used a pure image clustering approach. Unlike our first methods we do not calculate an individual species prediction for each test image. Instead, we cluster the complete data set including the train and test images. We used a k-medoid clustering approach, which works on distances, calculated by a logical combination of global visual features combined with GPS data (UCC08). In this run, we used no special optimization techniques, so we apply initial weights to the CQQL formula. The species prediction of each test image is similar to the method used in the top-k clustering. For a given test image we analyzed the result list of the cluster which holds these object. To make a prediction for all categories we analyzed the nearest clusters and took all unused categories like we did in top-k clustering approach.</p><p>With this approach we are able to exploit the relationship of the test images and training images as additional information to identify the species. But without an equal distribution of all species we get some problems with categories which occur rarely as we already discussed in last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>According to the official results, our best run achieved place 20 in the overall ranking. Considering only automatic runs, we achieved rank 11. At a closer look, the score values of our results for scans and scan-like photographs are very poor. We cannot fully explain the failure with these image types as there were no indications for the weak performance during the training stage. One reasonable interpretation of the results is that the conducted learning runs led to an overfitting. Another reason could be the gap between the final metric used in the task and the metrics (precision n, MAP) used during our preparatory study. A detailed analysis is not yet possible until the exact score calculation method and the ground truth of the test data is released. To conclude with, further research has to be carried out to find satisfying answers.</p><p>Regarding our general approach and the results in the photograph category we obtained a decent rank 6 (3rd best group) considering only automatic runs as illustrated in Figure <ref type="figure" coords="10,238.81,190.78,3.87,8.74">3</ref>. The fact that our run based on visual features alone Fig. <ref type="figure" coords="10,183.36,386.49,4.13,7.89">3</ref>. Ranking score for fully automatic runs considering photographs (run 2) performed better or as well as the combined run (run 1) for all image types is surprising. This is contradictory to the results we had observed during training runs.</p><p>In comparison to the best submission, our results are far off. One reason for the large distance to the best group can be the training which was realized for all three image types in the same run, while other teams tried to differentiate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>Our participation on the ImageCLEF plant identification task poses a lot of questions. The results are not devastating for our first participation. Anyhow, we are not satisfied because the results during the training were auspiciously. Furthermore, our run relying on visual features alone performed best and the differences between scan, scan-like and photographs were very small. Further research might reveal the reasons. For our next participation, we have to consider some general points that were neglected. First, we learned that concentrating on each individual image type definitely improves performance and should be incorporated in our approach. Additionally, we acknowledge that a reasonably working image segmentation is important for natural photographs in order to extract shape features which could be included into our retrieval model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,152.51,350.28,152.50,7.89;6,320.89,350.31,141.95,7.86;6,134.77,146.64,345.83,188.87"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Low-level feature performance the Pl@ntLeaves data set (excerpt)</figDesc><graphic coords="6,134.77,146.64,345.83,188.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,134.77,304.22,345.83,189.18"><head></head><label></label><figDesc></figDesc><graphic coords="7,134.77,304.22,345.83,189.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="10,134.77,222.31,345.83,149.41"><head></head><label></label><figDesc></figDesc><graphic coords="10,134.77,222.31,345.83,149.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,186.53,549.60,239.23,62.04"><head>Table 1 .</head><label>1</label><figDesc>Distribution of the Pl@ntLeaves data set</figDesc><table coords="2,186.53,569.53,239.23,42.12"><row><cell></cell><cell cols="3">Scan Scan-like Photograph</cell><cell>P</cell></row><row><cell>Train data</cell><cell>4,870</cell><cell>1,819</cell><cell cols="2">1,733 8,422</cell></row><row><cell>Test data</cell><cell>1,760</cell><cell>907</cell><cell cols="2">483 3,150</cell></row><row><cell>Complete data set</cell><cell>6,630</cell><cell>2,726</cell><cell cols="2">2,216 11,572</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,136.16,428.34,253.28,46.30"><head>Table 2 .</head><label>2</label><figDesc>Analyzed CQQL combinations    </figDesc><table coords="6,136.16,453.42,118.87,21.21"><row><cell>Name CQQL combination</cell></row><row><cell>Q10</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by a grant of the <rs type="funder">Federal Ministry of Education and Research</rs> (Grant Number <rs type="grantNumber">03FO3072</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fM5vZFw">
					<idno type="grant-number">03FO3072</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,218.27,337.63,7.86;11,151.52,229.23,329.07,7.86;11,151.52,240.19,329.07,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,299.32,218.27,181.27,7.86;11,151.52,229.23,329.07,7.86;11,151.52,240.19,22.01,7.86">Learning generative visual models from few training examples an incremental Bayesian approach tested on 101 object categories</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,193.67,240.19,258.59,7.86">Proceedings of the Workshop on Generative-Model Based Vision</title>
		<meeting>the Workshop on Generative-Model Based Vision</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,251.94,337.63,7.86;11,151.52,262.90,329.07,7.86;11,151.52,273.86,163.52,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Itheri</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ans Nozha Boujemaa</surname></persName>
		</author>
		<title level="m" coord="11,166.64,262.90,313.95,7.86;11,151.52,273.86,79.80,7.86">Jean-François Molino: The ImageCLEF 2012 Plant Identification Task, CLEF 2012 Working Notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,285.62,337.64,7.86;11,151.52,296.57,20.99,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,151.53,285.62,123.74,7.86">ImageClef: Plant Identification</title>
		<ptr target="http://imageclef.org/2012/plant,12" />
		<imprint>
			<date type="published" when="2012-08">2012. August 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,308.33,337.64,7.86;11,151.52,319.29,329.07,7.86;11,151.52,330.25,25.60,7.86" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Salembier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<title level="m" coord="11,325.47,308.33,155.13,7.86;11,151.52,319.29,121.15,7.86">Introduction to MPEG-7: Multimedia Content Description Interface</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,342.00,337.63,7.86;11,151.52,352.96,182.03,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,226.86,342.00,80.59,7.86">Probabilistic logic</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">N</forename><surname>Nilsson</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=5447.5450" />
	</analytic>
	<monogr>
		<title level="j" coord="11,323.17,342.00,57.80,7.86">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="71" to="88" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,364.71,337.64,7.86;11,151.52,375.67,306.59,7.86" xml:id="b5">
	<monogr>
		<ptr target="http://www.plantnet-project.org/papyrus.php?langue=en,12" />
		<title level="m" coord="11,151.53,364.71,324.78,7.86">Pl@ntNet: Interactive plant identification and collaborative information system</title>
		<imprint>
			<date type="published" when="2012-08">August 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,387.42,205.85,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
		<title level="m" coord="11,200.16,387.42,78.74,7.86">Weighting in CQQL</title>
		<meeting><address><addrLine>Cottbus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,399.18,337.64,7.86;11,151.52,410.14,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,201.50,399.18,136.75,7.86">QQL: A DB&amp;IR Query Language</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,346.57,399.18,79.95,7.86">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="56" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,421.89,337.63,7.86;11,151.52,432.85,329.07,7.86;11,151.52,443.81,296.29,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,329.22,421.89,151.37,7.86;11,151.52,432.85,59.60,7.86">Towards quantum logic based multimedia retrieval</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
		<idno type="DOI">10.1109/NAFIPS.2008.4531329</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,280.64,432.85,199.95,7.86;11,151.52,443.81,71.36,7.86">Proceedings of the Fuzzy Information Processing Society (NAFIPS)</title>
		<meeting>the Fuzzy Information Processing Society (NAFIPS)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,455.56,337.98,7.86;11,151.52,466.52,329.07,7.86;11,151.52,477.48,329.07,7.86;11,151.52,488.44,277.04,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,303.46,455.56,177.13,7.86;11,151.52,466.52,119.61,7.86">SIMPLIcity: Semantics-sensitive Integrated Matching for Picture Libraries</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wiederhold</surname></persName>
		</author>
		<ptr target="http://portal.acm.org/citation.cfm?id=647061.714442" />
	</analytic>
	<monogr>
		<title level="m" coord="11,290.65,466.52,189.94,7.86;11,151.52,477.48,175.01,7.86;11,388.07,477.48,48.86,7.86">Proceedings of the 4th International Conference on Advances in Visual Information Systems</title>
		<meeting>the 4th International Conference on Advances in Visual Information Systems</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="360" to="371" />
		</imprint>
	</monogr>
	<note>VISUAL &apos;00</note>
</biblStruct>

<biblStruct coords="11,142.62,500.19,264.14,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,205.15,500.19,47.42,7.86">Fuzzy Logic</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,259.68,500.19,65.68,7.86">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="83" to="93" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,511.95,337.97,7.86;11,151.52,522.91,329.07,7.86;11,151.52,533.87,178.28,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,208.15,511.95,272.44,7.86;11,151.52,522.91,24.44,7.86">A Permeable Expert Search Strategy Approach to Multimodal Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,196.35,522.91,284.23,7.86;11,151.52,533.87,42.94,7.86">Proceedings of the 4th international information interaction in context symposium</title>
		<meeting>the 4th international information interaction in context symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>to appear. IIiX</note>
</biblStruct>

<biblStruct coords="11,142.62,545.62,337.98,7.86;11,151.52,556.58,329.07,7.86;11,151.52,567.54,231.21,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,206.39,545.62,274.21,7.86;11,151.52,556.58,132.48,7.86">An Extensible Personal Photograph Collection for Graded Relevance Assessments and User Simulation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,304.72,556.58,175.87,7.86;11,151.52,567.54,174.12,7.86">Proceedings of the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</title>
		<meeting>the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,579.29,337.97,7.86;11,151.52,590.25,329.07,7.86;11,151.52,601.21,329.07,7.86;11,151.52,612.17,193.05,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,151.52,590.25,329.07,7.86;11,151.52,601.21,13.44,7.86">PythiaSearch -A Multiple Search Strategy-supportive Multimedia Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bertram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Böttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tillmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,188.92,601.21,291.66,7.86;11,151.52,612.17,34.93,7.86">Proceedings of the 2nd ACM International Conference on Multimedia Retrieval</title>
		<meeting>the 2nd ACM International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>to appear. ICMR &apos;12</note>
</biblStruct>

<biblStruct coords="11,142.62,623.92,337.98,7.86;11,151.52,634.88,329.07,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.80,130.40,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,263.39,623.92,217.21,7.86;11,151.52,634.88,69.81,7.86">BTU DBIS&apos; Multimodal Wikipedia Retrieval Runs at ImageCLEF 2011</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Böttcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,645.84,204.87,7.86">CLEF 2011 Labs and Workshop, Notebook Papers</title>
		<editor>
			<persName><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">September 2011. 2011</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,119.67,123.00,7.86;12,305.04,119.67,175.55,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,329.07,7.86;12,151.52,152.55,329.07,7.86;12,151.52,163.51,329.07,7.86;12,151.52,174.47,272.75,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,446.22,119.67,34.37,7.86;12,151.52,130.63,324.96,7.86">Towards Quantum-Based DB+IR Processing Based on the Principle of Polyrepresentation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,191.49,152.55,289.10,7.86;12,151.52,163.51,86.80,7.86">Advances in Information Retrieval -33rd European Conference on IR Research, ECIR 2011</title>
		<title level="s" coord="12,395.28,163.51,85.32,7.86;12,151.52,174.47,107.98,7.86">Proceedings, Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Foley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Murdoch</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">April 18-21, 2011. 2011</date>
			<biblScope unit="volume">6611</biblScope>
			<biblScope unit="page" from="729" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,185.43,337.98,7.86;12,151.52,196.39,282.60,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,257.92,185.43,203.74,7.86">A Poset Based Approach for Condition Weighting</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,196.39,253.93,7.86">6th International Workshop on Adaptive Multimedia Retrieval</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,207.34,337.97,7.86;12,151.52,218.30,329.07,7.86;12,151.52,229.26,249.25,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,261.66,207.34,218.92,7.86;12,151.52,218.30,274.49,7.86">A Preference-based Approach for Interactive Weight Learning: Learning Weights within a Logic-Based Query Language</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10619-009-7049-4</idno>
	</analytic>
	<monogr>
		<title level="m" coord="12,434.57,218.30,46.02,7.86;12,151.52,229.26,92.53,7.86">Distributed and Parallel Databases</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
