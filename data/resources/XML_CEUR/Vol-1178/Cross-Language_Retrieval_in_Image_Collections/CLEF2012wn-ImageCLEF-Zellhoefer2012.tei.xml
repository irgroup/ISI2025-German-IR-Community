<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.11,115.96,335.13,12.62;1,217.69,133.89,179.98,12.62">Overview of the Personal Photo Retrieval Pilot Task at ImageCLEF 2012</title>
				<funder ref="#_BbbcZUs">
					<orgName type="full">Federal Ministry of Education and Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,274.11,171.56,67.13,8.74"><forename type="first">David</forename><surname>Zellhöfer</surname></persName>
							<email>david.zellhoefer@tu-cottbus.de</email>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.11,115.96,335.13,12.62;1,217.69,133.89,179.98,12.62">Overview of the Personal Photo Retrieval Pilot Task at ImageCLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F4C2988B82CF9393B67CA7690D7A4515</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Content-Based Image Retrieval</term>
					<term>Benchmark</term>
					<term>Experiments</term>
					<term>Personal Photograph Collection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As a consequence of a discussion at ImageCLEF 2011, the personal photo retrieval pilot task has been designed to represent a personal photo collection. In contrast to other existing collections where the contributors often remain unknown, the proposed collection has been sampled from 19 layperson photographers and enriched by their demographics.</p><p>To ensure a variance in photographic motifs and style, the contributors have been chosen from different demographic groups. Thus, one can interpret the content of the collection as a mirror of a photographer's lifespan with typical changing usage behaviors, cameras, topics, and places. The task consists of two subtasks. The first task is aiming at retrieving visual concepts such as trees, animals, or market scenes. The second is focussing on the retrieval of particular events such as parties or rock concerts. To solve both tasks, the participants were provided with queryby-example documents in addition to browsing data. The participation in this task was very low as only three groups submitted results. To summarize the first subtask, the best group achieved a precision at 20 of 0.7333 and a NDCG at 20 of 0.5459. In contrast, the second subtask focussing on events was solved with a precision at 20 of 0.9333 and a NDCG at 20 of 0.9697. Regarding the provided browsing data, only one group decided to exploit this resource instead of the provided metadata. Interestingly, it could use this data successfully to solve subtask 1 but reached the last position at subtask 2. This result indicates that there is a particularly strong influence of metadata on the retrieval of events.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a consequence of a discussion at ImageCLEF 2011, the personal photo retrieval pilot task has been designed to represent a personal photo collection. The presented pilot task is aiming at providing a test bed for QBE-based retrieval scenarios in the scope of personal information retrieval. In contrast to other tasks relying on downloads from Flickr or the like, the underlying data set reflects an amalgamated personal image collection that has been taken by 19 photographers. Hence, it can be used best as a test set for layperson retrieval tasks carried out ad hoc on their own collections such as: "find all images with a street scene", "find a beach similar to this", or more event-based tasks like "show me more pictures from the last U2 concert". The aim of this pilot task is to retrieve relevant images based on typical layperson usage scenarios in their own collections, i.e., the search for similar images or images depicting a similar event, e.g. a rock concert <ref type="bibr" coords="2,247.18,202.68,9.96,8.74" target="#b6">[6]</ref>.</p><p>To ensure a variance in photographic motifs and style, the contributors have been chosen from different demographic groups. Thus, one can interpret the content of the collection as a mirror of a photographer's lifespan with typical changing usage behaviors, cameras, topics, and places.</p><p>Unlike system-centric (Cranfield-based) benchmarks, the pilot tasks tries to establish a more user-centered perspective on multimodal information retrieval (MIR) and content-based image retrieval (CBIR). As such, it features two different retrieval subtasks that can be derived from the camera usage behavior of the contributing photographers (see below). Additionally, it provides simulated browsing data reflecting a user's interaction with the system based on multiple search strategies as observed by <ref type="bibr" coords="2,276.53,335.28,10.52,8.74" target="#b4">[4]</ref> or described by <ref type="bibr" coords="2,360.50,335.28,10.52,8.74" target="#b1">[1]</ref> respectively.</p><p>In order to express the subjectivity of relevance assessments, the ground truth is based on graded relevance judgements. To include these assessments into the evaluation, the pilot tasks uses the NDCG metric <ref type="bibr" coords="2,348.02,371.69,10.52,8.74" target="#b3">[3]</ref> (see Section 4.1) in addition to precision at various cut-off levels.</p><p>As said before, the task consists of two subtasks. The first task is aiming at retrieving visual concepts such as trees, animals, or market scenes. The second is focussing on the retrieval of particular events such as parties or rock concerts. To solve both tasks, the participants were provided with query-by-example documents in addition to browsing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Resources</head><p>The pilot task relies on a subset of the Pythia dataset <ref type="bibr" coords="2,367.48,505.21,10.52,8.74" target="#b6">[6]</ref> which will be described in the next section. To complete the description of the provided resources, Section 2.2 will comment on the acquisition of the ground truth. The following section will then discuss the elicitation of the browsing data offered to the participants as an additional resource.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Pythia Dataset</head><p>To overcome limitations by binary relevance judgments often found in common test collections, the Pythia collection <ref type="bibr" coords="2,303.53,620.25,10.52,8.74" target="#b6">[6]</ref> has been proposed. The collection is aiming at providing a benchmark for user-centered or relevance feedback-related experiments which are affected by subjective relevance levels in particular. The collection differs from collections consisting of Flickr downloads or the like as it has been sampled from 19 layperson photographers. For the individual contribution of the photographers, see Figure <ref type="figure" coords="3,315.08,130.95,3.87,8.74">1</ref>. In addition to the image data, the contributors to the collection completed a survey asking for their photograph taking behavior, their demographics etc. To ensure a variance in photographic motifs and style, the contributors have been chosen from different demographic groups. Thus, one can interpret the content of the collection as a mirror of a photographer's lifespan with typical changing usage behaviors, cameras, topics, and places. The total size of the collection is 5,555 documents.</p><p>The documents within the collection have neither been processed extensively nor have duplicates been removed. Hence, the data can be considered a realistic sample from a typical user's hard-disk. The collection is rich on metadata including GPS, IPTC, EXIF, and information about events depicted on each photography. All this information is available to the participants of the pilot task. For an overview, see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ground Truth Acquisition</head><p>In order to obtain the ground truth, 42 assessors were asked to participate. The core characteristics can be subsumed as follows. The majority of the assessors (28 out of 42) are male and born between 1979 and 1991 (median: 1987). Most of the assessors are students with a background in economics (26), the second largest group (13) has a background in computer science and information technology. Figure <ref type="figure" coords="4,167.64,209.95,4.98,8.74" target="#fig_0">2</ref> illustrates the other fields of education or working area. Regarding their level of expertise in the field of MIR or IR, 9 assessors took classes in MIR while 11 heard IR. When asked directly about their knowledge of the field the median lies at "little knowledge" with an average of 1.40, i.e., a trend towards considering themselves as an 'informed outsiders". Using a web-based evaluation tool (see Figure <ref type="figure" coords="4,355.80,560.48,3.87,8.74" target="#fig_1">3</ref>), the assessors could judge the relevance of an image with respect to a topic on a graded scale ranging from 0 (irrelevant) to 3 (fully relevant). All assessors had to judge all documents regarding a topic. The topics were associated with the assessors by random. To keep them motivated, the assessors were allowed to work with the collection from a place of their choice. Additionally, they could pause an assessment run and continue from later on. A time constraint has not been defined. In average 2.69 topics were evaluated per assessor (standard deviation: 1.60). The individual assessments were saved separately in order to maintain them for later usage.</p><p>Calculation of the Ground Truth for each Topic Based on the individual assessments, an averaged ground truth has been calculated. First, the frequency of each graded relevance judgement (out of an interval from 0 (irrelevant) to 3 (fully relevant)) was counted per image and topic. Based on these relevance judgment frequencies, an estimation value was calculated and rounded. The rounded estimation value of the relevance of an image regarding a topic was then used as the averaged graded relevance assessment for this image. In consequence, each image could be associated with a graded relevance judgment for each topic. Generating Browsing Information As we could not obtain real browsing information, it had to be generated artificially. Using the graded relevance assessments, multiple images were chosen as browsing images. The provided browsed images have a relevance grade ranging from 1 to 2, i.e., they are judged neither irrelevant nor fully relevant for a given topic. In other words, the browsing data consists of interesting images which were not fully relevant for the modeled user which caused him or her to proceed with the search. This change of search strategy (from browsing to a directed QBE search) is reflected by the following subtask.</p><p>3 Task Description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Subtask 1: Retrieval of Visual Concepts</head><p>The objective of the first subtask is to find similar images to a specified visual concept or topic. Out of the 32 topics provided by the Pythia dataset <ref type="bibr" coords="6,437.51,309.63,9.96,8.74" target="#b6">[6]</ref>, the 24 topics with the most relevant images in the corpus were chosen. The topics are listed in Table <ref type="table" coords="6,200.41,333.54,3.87,8.74" target="#tab_2">2</ref>.</p><p>To solve the task, 5 QBE documents were provided to the participants. All QBE documents are fully relevant according to our assessors. In addition to the metadata present in the images, browsing data consisting of images that have been inspected during the search (see above) is offered. The usage of this browsing data is voluntary as the utilization of image features or metadata (e.g. GPS information). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Subtask 2: Retrieval of Events</head><p>With respect to the fact that most contributors to the collection used their cameras only at special events <ref type="bibr" coords="7,276.92,153.16,9.96,8.74" target="#b6">[6]</ref>, an additional event retrieval subtask was defined. Its objective is to find further images from an event specified by 3 QBE images from the same event. In contrast to subtask 1, browsing data is not available. Table <ref type="table" coords="7,205.89,189.03,4.98,8.74" target="#tab_3">3</ref> lists all events.</p><p>The events range from special events such as a U2 concert to their generalization, i.e., a rock concert. It is noteworthy that the events can reoccur and are not always chronologically connected. The focus on events representing a holiday or a city trip is not a freely chosen bias. Instead, it reflects the state of randomly picked images from real-world personal photo collections <ref type="bibr" coords="7,384.66,249.26,9.96,8.74" target="#b6">[6]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>It is widely known that relevance judgments are highly subjective. Because of this fact, the presented ground truth is based on a gradual scale of relevance. Unfortunately, traditional measurements such as the mean average precision (MAP) or precision at n cannot deal with this kind of judgements. Hence, we will rely on the discounted cumulative gain (DCG) measurement <ref type="bibr" coords="7,380.26,536.57,10.52,8.74" target="#b3">[3]</ref> in addition to precision at n. As stated in <ref type="bibr" coords="7,234.53,548.52,10.52,8.74" target="#b6">[6]</ref> "DCG relies on graded relevance assessments and has become more and more used within the information retrieval (IR) community, which is reflected by a performance evaluation of different metrics presented at SIGIR '11 showing that DCG 'really is a useful user-centered measure of system effectiveness' <ref type="bibr" coords="7,228.75,596.34,9.96,8.74" target="#b2">[2]</ref>. Besides its capability of reflecting subjectivity, DCG also provides more appropriate means to evaluate relevance feedback (RF) or adaptive systems as it can be used to measure slight changes or re-orderings of relevant documents with varying degrees of relevance within the result list". The core idea of DCG is to apply "a discount factor to the relevance scores in order to devaluate late-retrieved documents" <ref type="bibr" coords="7,309.32,656.12,9.96,8.74" target="#b3">[3]</ref>. In other words, the metric rewards highly relevant documents at the first positions in the result ranking and punishes systems retrieving less relevant documents at the first places. For the scope of this task, the DCG implementation of trec eval version 9.0 with standard discount settings is used. A full discussion of the metric is available by Järvelin and Kekäläinen <ref type="bibr" coords="8,205.88,166.81,9.96,8.74" target="#b3">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results of the Participants</head><p>Because of the low participation rate, a general interpretation of the results is hardly possible. Table <ref type="table" coords="8,237.16,228.89,4.98,8.74" target="#tab_4">4</ref> and 5 summarize the participants' results. The submitted runs consist of both automatic and manually assisted runs. While two groups worked without relevance feedback (NOFB), the University of Cagliari used it in a binary way. That is, relevance feedback was given with relevance or irrelevance judgments.</p><p>Regarding the retrieval type, the runs are more diverse. The participants could use the following combinations of the provided data and metadata:</p><p>visual features alone (IMG) visual features and metadata (IMGMET) visual features and browsing data (IMGBRO) metadata alone (MET) metadata and browsing data (METBRO) browsing data alone (BRO) a combination of all modalities (IMGMETBRO) None of the participants used all modalities in combination. The participants relied on IMG, MET, IMGMET, or IMGBRO alone. Interestingly, only the group REGIM decided to exploit the browsing data instead of the provided metadata. Surprisingly, it could use this data successfully to solve subtask 1 but reached the last position at subtask 2. This result indicates that there is a particularly strong influence of metadata on the retrieval of events.</p><p>To summarize the first subtask (see Table <ref type="table" coords="8,346.25,484.39,3.87,8.74" target="#tab_4">4</ref>), the best group achieved a precision at 20 of 0.7333 and a NDCG at 20 of 0.5459. In contrast, the second subtask focussing on events was solved with a precision at 20 of 0.9333 and a NDCG at 20 of 0.9697 (see Table <ref type="table" coords="8,283.36,520.26,3.87,8.74" target="#tab_5">5</ref>).</p><p>The Effect of Different User Groups on the Retrieval Quality Because of the nature of the acquisition of the ground truth (see Section 2.2), distinct ground truths could be generated per user groups. The main objective for these different ground truths was to examine if the retrieval metrics for each participant differ per user group. Hence, 6 user groups were defined on basis of the demographics of the assessors. These are:</p><p>Experts A group of users that stated that they have an expertise with IR. Non-Experts The complement of the experts group. Male/Female The assessors divided by gender.</p><p>IT This groups consists of assessors with an IT background (see Figure <ref type="figure" coords="9,452.07,118.99,3.87,8.74" target="#fig_0">2</ref>). Non-IT The complement of the IT group.</p><p>As not all images and topics have been assessed by members of each separate user group, missing assessments had to be added from the averaged ground truth (see above). Figures <ref type="figure" coords="9,229.13,174.37,4.43,8.74" target="#fig_2">4</ref><ref type="figure" coords="9,233.56,174.37,4.43,8.74">5</ref><ref type="figure" coords="9,237.99,174.37,4.43,8.74">6</ref>illustrate the results of some sample runs regarding different user groups. The x-axis indicates different retrieval measurements, i.e., 1) P@10, 2) P@20, 3) P@30, 4) NDCG@10, 5) NDCG@20, and 6) NDCG@30. Besides in Figure <ref type="figure" coords="9,214.86,210.23,3.87,8.74">6</ref>, the results of the individual user groups are very close to the results from the averaged ground truth. Further research is needed to find out why this is the case. For now, it seems that the addition of missing relevance assessments is causing this low level of variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>As this is the pilot phase of a more user-centered benchmark, the task posed more questions and revealed more issues as it actually answered.</p><p>First, it became obvious that the generation of user-centered tasks and the acquisition of the accompanying data takes much more time than expected. Originally, we also wanted to provide data for user simulations to all participants so they could tune their systems with respect to different user groups. Due to the time constraints, this data could not be released on time. If this has had an impact on the low participation rate remains an open question.</p><p>To our surprise, only one group used the provided browsing data. Regarding this data, we expected more interest as studies in interactive IR clearly show that users are changing their search strategies during the search process <ref type="bibr" coords="9,426.22,418.23,9.96,8.74" target="#b4">[4]</ref>. Anyhow, the positive results of this group might motivate further studies of others how to exploit this resource.</p><p>Interestingly, there was no interest in solving the so-called user-centered initiative of the subtasks. The initiative asked for an alternative representation of the top-k results offering a more diverse view onto the results to the user. This challenge reflects the assumption that a user-centered system should offer users good and varying retrieval results. Varying results are likely to compensate for the vagueness inherent in both retrieval and query formulation. Hence, an additional filtering or clustering of the result list could improve the effectiveness and efficiency (in terms of usability) of the retrieval process. It remains unclear, if this task was too complex or just out of the area of expertise of the participants that used the dataset for the first time.</p><p>To conclude with, we are happy that the participants tried to solve to task using diverse techniques and hope to motivate further research in the field of user-centered MIR and CBIR.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,138.67,462.15,338.02,7.89"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Job types of the assessors; economic background is marked blue, IT is green</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,607.70,345.83,7.89;5,134.77,618.69,330.51,7.86;5,175.98,237.32,263.40,355.61"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Web-based assessor's GUI; 1) current sample image, 2) graded relevance scale, 3) free text comment field, 4) task description with relevant and irrelevant images</figDesc><graphic coords="5,175.98,237.32,263.40,355.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,150.13,353.09,315.11,7.89"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Retrieval performance for different user groups (KIDS NUTN IOOA4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,134.77,622.92,345.82,7.89"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Retrieval performance for different user groups (University of Cagliari Run1.1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,183.06,275.17,245.68,249.15"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table coords="3,183.06,314.28,245.68,210.04"><row><cell></cell><cell></cell><cell></cell><cell>actor18</cell><cell cols="2">actor0; 0,85% actor1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>4,07%</cell><cell cols="2">0,90%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>actor3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>actor2</cell><cell>1,15%</cell><cell>actor4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>8,55%</cell><cell>2,03%</cell></row><row><cell></cell><cell cols="2">actor16</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0,94%</cell><cell></cell><cell>actor17 25,06%</cell><cell></cell><cell>actor5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10,69%</cell></row><row><cell></cell><cell cols="2">actor15</cell><cell></cell><cell></cell></row><row><cell>0,07% actor14</cell><cell>actor13</cell><cell>1,10%</cell><cell></cell><cell></cell><cell>actor6 15,46%</cell></row><row><cell></cell><cell>1,96%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>actor12 0,14%</cell><cell cols="2">0,77% actor10 actor11 0,70%</cell><cell>4,21% actor9</cell><cell>actor8 18,02%</cell><cell>3,31% actor7</cell></row><row><cell cols="6">Fig. 1. Photographers' Contribution in Percent [6]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,209.34,573.04,196.67,87.94"><head>Table 1 .</head><label>1</label><figDesc>Metadata Characteristics (Excerpt)<ref type="bibr" coords="3,396.28,573.06,9.73,7.86" target="#b6">[6]</ref> </figDesc><table coords="3,228.00,594.31,156.28,66.67"><row><cell>Characteristic</cell><cell>%</cell></row><row><cell cols="2">EXIF (Date, Camera Info. etc.) 100.00</cell></row><row><cell>GPS Data</cell><cell>81.85</cell></row><row><cell>Event Tags</cell><cell>96.71</cell></row><row><cell>Outdoor Photographies</cell><cell>82.64</cell></row><row><cell>Indoor Photographies</cell><cell>17.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,175.26,438.79,264.84,7.89"><head>Table 2 .</head><label>2</label><figDesc>Topics of subtask 1; bold set topics indicate used topics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,282.22,273.40,167.24"><head>Table 3 .</head><label>3</label><figDesc>Topics of subtask 2</figDesc><table coords="7,134.77,303.02,273.40,146.44"><row><cell>1. Conference</cell><cell>9. Hamburg Holiday</cell></row><row><cell>2. Fire</cell><cell>10. London Holiday</cell></row><row><cell>3. Excursion</cell><cell>11. Party</cell></row><row><cell>4. Flight</cell><cell>12. U2 Concert</cell></row><row><cell>5. Australia Holiday</cell><cell>13. Scuba Diving</cell></row><row><cell>6. Bali Holiday</cell><cell>14. Rock Concert</cell></row><row><cell>7. Egypt Holiday</cell><cell>15. Mountainside Holiday</cell></row><row><cell>8. Greece Holiday</cell><cell></cell></row><row><cell>4 Results</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,136.16,132.24,329.17,313.09"><head>Table 4 .</head><label>4</label><figDesc>Results of subtask 1 (excerpt); bold values indicate the best result</figDesc><table coords="10,136.16,153.51,329.17,291.82"><row><cell>Group</cell><cell cols="3">Run ID Run Type Relevance</cell><cell>Retrieval</cell><cell cols="2">P 20 ndcg cut 20</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Feedback</cell><cell>Type</cell><cell></cell></row><row><cell>KIDS</cell><cell cols="3">IBMA0 Automatic NOFB</cell><cell>IMGMET</cell><cell>0.6896</cell><cell>0.5459</cell></row><row><cell>KIDS</cell><cell cols="3">OBOA0 Automatic NOFB</cell><cell>MET</cell><cell>0.6354</cell><cell>0.4836</cell></row><row><cell>KIDS</cell><cell cols="3">IOMA0 Automatic NOFB</cell><cell>IMGMET</cell><cell>0.6104</cell><cell>0.4872</cell></row><row><cell>KIDS</cell><cell cols="3">OBMA0 Automatic NOFB</cell><cell>MET</cell><cell>0.5771</cell><cell>0.4066</cell></row><row><cell>REGIM</cell><cell>run4</cell><cell cols="2">Automatic NOFB</cell><cell cols="2">IMGBRO 0.7333</cell><cell>0.4563</cell></row><row><cell>REGIM</cell><cell>run2</cell><cell cols="2">Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.7292</cell><cell>0.4561</cell></row><row><cell>REGIM</cell><cell>run1</cell><cell cols="2">Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.7292</cell><cell>0.456</cell></row><row><cell>REGIM</cell><cell>run5</cell><cell cols="2">Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.7292</cell><cell>0.4551</cell></row><row><cell>REGIM</cell><cell>run3</cell><cell cols="2">Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.7292</cell><cell>0.4551</cell></row><row><cell>University</cell><cell cols="2">Run 1 2 Feedback</cell><cell>BINARY</cell><cell>IMG</cell><cell>0.6938</cell><cell>0.5457</cell></row><row><cell>of Cagliari</cell><cell></cell><cell>and/or</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>human</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>assistance</cell><cell></cell><cell></cell><cell></cell></row><row><cell>KIDS</cell><cell cols="3">IOOA4 Automatic NOFB</cell><cell>IMG</cell><cell>0.5354</cell><cell>0.4545</cell></row><row><cell>University</cell><cell cols="2">Run 1 1 Feedback</cell><cell>BINARY</cell><cell>IMG</cell><cell>0.5646</cell><cell>0.4835</cell></row><row><cell>of Cagliari</cell><cell></cell><cell>and/or</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>human</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>assistance</cell><cell></cell><cell></cell><cell></cell></row><row><cell>University</cell><cell cols="2">Run 3 2 Feedback</cell><cell>BINARY</cell><cell>IMG</cell><cell>0.3958</cell><cell>0.3466</cell></row><row><cell>of Cagliari</cell><cell></cell><cell>and/or</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>human</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>assistance</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mean</cell><cell>0.6425</cell><cell>0.4640</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Std. Dev.</cell><cell>0.1028</cell><cell>0.0518</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,136.16,487.47,331.90,157.68"><head>Table 5 .</head><label>5</label><figDesc>Results of subtask 2 (excerpt); bold values indicate the best result</figDesc><table coords="10,136.16,508.74,331.90,136.41"><row><cell>Group</cell><cell cols="2">Run ID Run Type Relevance</cell><cell>Retrieval</cell><cell cols="2">P 20 ndcg cut 20</cell></row><row><cell></cell><cell></cell><cell>Feedback</cell><cell>Type</cell><cell></cell><cell></cell></row><row><cell>KIDS</cell><cell cols="2">OOMA0 Automatic NOFB</cell><cell>MET</cell><cell>0.9333</cell><cell>0.9697</cell></row><row><cell>KIDS</cell><cell cols="2">IOMA0 Automatic NOFB</cell><cell>IMGMET</cell><cell>0.9267</cell><cell>0.9655</cell></row><row><cell>KIDS</cell><cell cols="2">IOMA0-2 Automatic NOFB</cell><cell>IMGMET</cell><cell>0.8100</cell><cell>0.8636</cell></row><row><cell>KIDS</cell><cell cols="2">IOMA0-3 Automatic NOFB</cell><cell>IMGMET</cell><cell>0.7867</cell><cell>0.8357</cell></row><row><cell>KIDS</cell><cell cols="2">IOOA0 Automatic NOFB</cell><cell>IMG</cell><cell>0.4833</cell><cell>0.5446</cell></row><row><cell>REGIM</cell><cell>run8</cell><cell>Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.1767</cell><cell>0.1936</cell></row><row><cell>REGIM</cell><cell>run7</cell><cell>Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.1733</cell><cell>0.1915</cell></row><row><cell>REGIM</cell><cell>run9</cell><cell>Automatic NOFB</cell><cell>IMGBRO</cell><cell>0.1733</cell><cell>0.1913</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mean</cell><cell>0.5579</cell><cell>0.5944</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Std. Dev.</cell><cell>0.3463</cell><cell>0.3580</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by a grant of the <rs type="funder">Federal Ministry of Education and Research</rs> (Grant Number <rs type="grantNumber">03FO3072</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BbbcZUs">
					<idno type="grant-number">03FO3072</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,156.64,459.56,92.09,7.89;6,307.54,459.59,49.25,7.86;6,153.06,470.92,67.99,7.89;6,307.54,470.92,103.40,7.89;6,153.06,482.27,102.95,7.89;6,307.54,482.27,66.02,7.89;6,153.06,493.63,112.90,7.89;6,307.54,493.63,35.95,7.89;6,153.06,504.99,58.39,7.89;6,307.54,504.99,122.60,7.89;6,153.06,516.37,58.72,7.86;6,307.54,516.37,49.15,7.86;6,153.06,527.73,36.45,7.86;6,307.54,527.70,96.43,7.89;6,153.06,539.06,115.10,7.89;6,307.54,539.06,55.66,7.89;6,153.06,550.42,47.94,7.89;6,307.54,550.42,34.61,7.89;6,148.45,561.78,117.35,7.89;6,307.54,561.78,63.73,7.89;6,148.45,573.13,129.76,7.89;6,307.54,573.16,49.94,7.86;6,148.45,584.52,69.12,7.86;6,307.54,584.49,39.51,7.89;6,148.45,595.85,94.11,7.89;6,307.54,595.85,39.36,7.89;6,148.45,607.21,111.62,7.89;6,307.54,607.23,85.03,7.86;6,148.45,618.56,139.95,7.89;6,307.54,618.56,84.99,7.89;6,148.45,629.92,46.45,7.89;6,307.54,629.95,124.77,7.86;12,134.77,362.20,62.94,10.52" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,163.02,459.56,85.72,7.89;6,307.54,459.59,49.25,7.86;6,153.06,470.92,67.99,7.89;6,307.54,470.92,103.40,7.89;6,153.06,482.27,102.95,7.89;6,307.54,482.27,66.02,7.89;6,153.06,493.63,112.90,7.89;6,307.54,493.63,35.95,7.89;6,153.06,504.99,58.39,7.89;6,307.54,504.99,122.60,7.89;6,153.06,516.37,58.72,7.86;6,307.54,516.37,49.15,7.86;6,153.06,527.73,36.45,7.86;6,307.54,527.70,96.43,7.89;6,153.06,539.06,115.10,7.89;6,307.54,539.06,55.66,7.89;6,153.06,550.42,47.94,7.89;6,307.54,550.44,7.85,7.86">Still Life 2. Street Scene 18. Church (Christian) 3. Statue and Figurine 19. Art Object 4. Asian Temple &amp; Palace 20. Cars 5. Landscape 21. Ship / Maritime Vessel 6. Hotel Room 22. Airplane 7. People 23. Temple (Ancient) 8. Architecture (profane) 24. Squirrels 9. Animals 25</title>
		<imprint>
			<publisher>Church Interior References</publisher>
			<pubPlace>City Panorama</pubPlace>
		</imprint>
	</monogr>
	<note>Beach and Seaside 17. Sign 10. Asian Temple Interior 26. Mountains 11. Flower / Botanic Details 27. Monkeys 12. Market Scene 28. Birds 13. Submarine Scene 29. Ceremony and Party 30. Abstract Content 15. Theater / Performing Arts 31. Clouds 32</note>
</biblStruct>

<biblStruct coords="12,138.35,387.19,342.24,7.86;12,146.91,398.15,333.68,7.86;12,146.91,409.11,25.60,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,195.11,387.19,260.41,7.86">Intelligent information retrieval: Whose intelligence? In: ISI &apos;96</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,463.04,387.19,17.56,7.86;12,146.91,398.15,286.90,7.86">Proceedings of the Fifth International Symposium for Information Science</title>
		<meeting>the Fifth International Symposium for Information Science</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,420.07,342.25,7.86;12,146.91,431.03,333.68,7.86;12,146.91,441.99,333.68,7.86;12,146.91,452.95,238.08,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,211.51,420.07,269.08,7.86;12,146.91,431.03,109.10,7.86">System effectiveness, user models, and user utility: a conceptual framework for investigation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<idno type="DOI">10.1145/2009916.2010037</idno>
		<ptr target="http://doi.acm.org/10.1145/2009916.2010037" />
	</analytic>
	<monogr>
		<title level="m" coord="12,276.91,431.03,203.68,7.86;12,146.91,441.99,227.55,7.86;12,436.92,441.99,40.09,7.86">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="903" to="912" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;11</note>
</biblStruct>

<biblStruct coords="12,138.35,463.91,342.24,7.86;12,146.91,474.86,180.59,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,268.44,463.91,208.10,7.86">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,146.91,474.86,89.96,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,485.82,342.25,7.86;12,146.91,496.78,333.68,7.86;12,146.91,507.74,333.68,7.86;12,146.91,518.70,313.02,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,368.88,485.82,111.72,7.86;12,146.91,496.78,132.00,7.86">INSYDER -an information assistant for business intelligence</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mußler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Handschuh</surname></persName>
		</author>
		<idno type="DOI">10.1145/345508.345559</idno>
		<ptr target="http://doi.acm.org/10.1145/345508.345559" />
	</analytic>
	<monogr>
		<title level="m" coord="12,299.98,496.78,180.62,7.86;12,146.91,507.74,314.28,7.86;12,184.80,518.70,39.61,7.86">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="112" to="119" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;00</note>
</biblStruct>

<biblStruct coords="12,138.35,529.66,342.24,7.86;12,146.91,540.62,333.68,7.86;12,146.91,551.58,281.49,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,233.25,529.66,247.34,7.86;12,146.91,540.62,24.44,7.86">On test collections for adaptive information retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Voorhees</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0306457308000253" />
	</analytic>
	<monogr>
		<title level="j" coord="12,183.92,540.62,176.25,7.86">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1879" to="1885" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,562.54,342.25,7.86;12,146.91,573.49,333.68,7.86;12,146.91,584.45,231.21,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,202.80,562.54,277.79,7.86;12,146.91,573.49,133.86,7.86">An Extensible Personal Photograph Collection for Graded Relevance Assessments and User Simulation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,302.42,573.49,178.17,7.86;12,146.91,584.45,174.12,7.86">Proceedings of the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</title>
		<meeting>the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
