<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,172.91,115.96,269.54,12.62;1,224.74,133.89,165.88,12.62">BossaNova at ImageCLEF 2012 Flickr Photo Annotation Task</title>
				<funder>
					<orgName type="full">FAPEMIG</orgName>
				</funder>
				<funder ref="#_PPkDSpw">
					<orgName type="full">FAPESP</orgName>
				</funder>
				<funder ref="#_ydzPSpt">
					<orgName type="full">CAPES</orgName>
				</funder>
				<funder ref="#_VJmGBDB">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.23,171.56,34.87,8.74"><forename type="first">S</forename><surname>Avila</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Pierre and Marie Curie</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">UPMC-Sorbonne Universities</orgName>
								<address>
									<settlement>LIP6</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">NPDI Lab -DCC/UFMG</orgName>
								<orgName type="institution">Federal University of Minas Gerais</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.00,171.56,44.00,8.74"><forename type="first">N</forename><surname>Thome</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Pierre and Marie Curie</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">UPMC-Sorbonne Universities</orgName>
								<address>
									<settlement>LIP6</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.56,171.56,36.83,8.74"><forename type="first">M</forename><surname>Cord</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Pierre and Marie Curie</orgName>
								<orgName type="institution" key="instit1">University</orgName>
								<orgName type="institution" key="instit2">UPMC-Sorbonne Universities</orgName>
								<address>
									<settlement>LIP6</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,314.95,171.56,34.47,8.74"><forename type="first">E</forename><surname>Valle</surname></persName>
							<email>dovalle@dca.fee.unicamp.br</email>
							<affiliation key="aff2">
								<orgName type="department">RECOD Lab -DCA/FEEC/UNICAMP</orgName>
								<orgName type="institution">State University of Campinas</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.33,171.56,70.33,8.74"><forename type="first">A</forename><forename type="middle">De A</forename><surname>Ara√∫jo</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NPDI Lab -DCC/UFMG</orgName>
								<orgName type="institution">Federal University of Minas Gerais</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,172.91,115.96,269.54,12.62;1,224.74,133.89,165.88,12.62">BossaNova at ImageCLEF 2012 Flickr Photo Annotation Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">999D4B7722E0C39F0B3859EAE36C09BA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Classification</term>
					<term>Image Representation</term>
					<term>Bag-of-Words</term>
					<term>Coding</term>
					<term>Pooling</term>
					<term>SVM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the BossaNova scheme for the ImageCLEF 2012 Flickr Photo Annotation Task. BossaNova is a mid-level image representation, recently developed by our team, that enriches the Bag-of-Words representation, by keeping a histogram of distances between the descriptors found in the image and those in the codebook. Our scheme has the advantage of being conceptually simple, non-parametric, and easily adaptable. Compared to other schemes existing in the literature to add information to the Bag-of-Words model, it leads to much more compact representations. Furthermore, it complements well the cutting-edge Fisher Vector representations, showing even better results when employed in combination with them. In our participation, we submitted four purely visual runs. Our best result (MiAP = 34.37%) achieved the second rank by MiAP measure among the 28 purely visual submissions and the 18 teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ImageCLEF 2012 Flickr Photo Annotation Task is a multi-label classification problem. The task can be solved by following three different approaches: i) automatic annotation with visual information only, ii) automatic annotation with textual information only, iii) multi-modal approaches that consider visual and textual information. We consider only the visual content for the feature extraction. The dataset consists of 25, 000 Flickr images, splitting into training (15, 000 images) and test (10, 000 images) subsets.</p><p>The image set is annotated with 94 concepts that are very diverse and range across categories such as people (e.g., male, female), nature (e.g., lake, beach), weather (e.g., rainbow, fog) and even sentiments (e.g., unpleasant, euphoric). A detailed overview of the dataset and the task can be found in <ref type="bibr" coords="1,406.12,632.21,9.96,8.74" target="#b0">[1]</ref>.</p><p>In our participation in the ImageCLEF 2012 Flickr Photo Annotation Task, we present our BossaNova scheme. Our aim is to emphasize the performance of the BossaNova representation, using a single low-level feature (SIFT descriptors) and SVM classifiers. BossaNova is a mid-level image representation <ref type="bibr" coords="2,429.81,130.95,9.96,8.74" target="#b1">[2]</ref>, recently developed by our team, that enriches the Bag-of-Words representation <ref type="bibr" coords="2,444.89,142.91,9.96,8.74" target="#b2">[3]</ref>.</p><p>Bag-of-Words representations can be understood as the application of two critical steps <ref type="bibr" coords="2,193.93,167.03,9.96,8.74" target="#b3">[4]</ref>: coding, which quantizes the image local features according to a codebook or dictionary; and pooling, which summarizes the codes obtained into a single feature vector. Traditionally, the coding step simply associates the image local descriptors to the closest element in the codebook, and the pooling takes the average of those codes over the entire image.</p><p>Bossa Nova focus on the pooling step, by keeping a histogram of distances between the descriptors found in the image and those in the codebook. Our scheme has the advantage of being conceptually simple, nonparametric and easily adaptable. Additionally, it leads to much more compact representations, compared to other schemes to add information to the Bag-of-Words representation. Furthermore, it complements well the cutting-edge Fisher Vector representations <ref type="bibr" coords="2,467.31,286.79,9.96,8.74" target="#b4">[5]</ref>, showing even better results when employed in combination with them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BossaNova Scheme</head><p>Our BossaNova scheme is composed of the following three steps: (i) extraction of local image features (by SIFT descriptors <ref type="bibr" coords="2,332.23,368.57,10.30,8.74" target="#b5">[6]</ref>), (ii) encoding of the local features in a global image representation (by a BossaNova representation <ref type="bibr" coords="2,444.08,380.53,10.30,8.74" target="#b1">[2]</ref>), and (iii) classification of the image representation (by SVM classifiers <ref type="bibr" coords="2,422.35,392.48,10.30,8.74" target="#b6">[7]</ref>). Here, we only provide a brief introduction to the BossaNova representation. More details can be found in <ref type="bibr" coords="2,206.16,416.39,10.20,8.74" target="#b1">[2]</ref> <ref type="bibr" coords="2,216.36,416.39,10.20,8.74" target="#b7">[8]</ref>.</p><p>BossaNova is a mid-level image representation which offers a more information-preserving pooling operation based on a distance-to-codeword distribution. In order to preserve a richer portrait of the information gathered during the coding step, the BossaNova pooling function produces a distance distribution, instead of compacting all information pertaining to a codeword into a single scalar, as performed by Bag-of-Words representations <ref type="bibr" coords="2,371.41,488.33,9.96,8.74" target="#b2">[3]</ref>.</p><p>Figure <ref type="figure" coords="2,181.23,500.50,4.98,8.74" target="#fig_0">1</ref> illustrates the BossaNova and the Bag-of-Words pooling functions. The BossaNova pooling (Figure <ref type="figure" coords="2,273.89,512.45,9.23,8.74" target="#fig_0">1a</ref>) represents the discrete (over B bins) density distribution of the distances between the codeword c m and the local descriptors of an image. For each center c m , we obtain a local histogram z m . The colors (green, yellow and blue) indicate the discretized distances from the center c m to the local descriptors shown by the black dots. For each colored bin z m,b , the height of the histogram is equal to the number of local descriptors, whose discretized distance to codeword c m fall into the b th bin. In Figure <ref type="figure" coords="2,433.80,584.18,8.49,8.74" target="#fig_0">1a</ref>, B = 3. We can note that if B = 1 (Figure <ref type="figure" coords="2,295.43,596.14,8.58,8.74" target="#fig_0">1b</ref>), the histogram z m reduces to a single scalar value N m counting the number of feature vectors falling into center c m .</p><p>To form the whole BossaNova image representation, all local histograms z m are then concatenated. In addition, since the occurrence rate of each codeword c m in the image is lost, BossaNova representation incorporates an additional scalar value N m for each codeword, counting the number of local descrip- tors close to that codeword. That value corresponds to a Bag-of-Words term, accounting for a raw measure of the presence of the codeword c m in the image. Thus, BossaNova image representation z can be written as <ref type="bibr" coords="3,394.13,295.14,9.96,8.74" target="#b1">[2]</ref>:</p><formula xml:id="formula_0" coords="3,190.03,316.70,235.29,12.62">z = [[z m,b ] , sN m ] T , (m, b) ‚àà {1, . . . , M } √ó {1, . . . , B}</formula><p>where z is a vector of size M √ó (B + 1), M is the number of codewords, and s is a weighted term learned via cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BossaNova Parameters</head><p>The m , the idea is to consider only descriptors that are "close enough" to the center, and to discard the remaining ones. For Œ± min m , the idea is to avoid the empty regions that appear around each codeword, in order to avoid wasting space in the final descriptor.</p><p>In BossaNova, Œ± min m and Œ± max m are set up differently for each codeword c m . Since our codebook is created using k-means, we take advantage of the knowledge about the "size" of the clusters, given by the standard deviations œÉ m . We set up the bounds as Œ± min m = Œª min ‚Ä¢ œÉ m and Œ± max m = Œª max ‚Ä¢ œÉ m . In practice, the three parameters of the BossaNova become B (M being fixed), Œª min and Œª max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We first describe our experimental setup (Section 3.1). We then detail our submitted runs (Section 3.2). Finally, we analyze our results at ImageCLEF 2012 Flickr Photo Annotation Task (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>As low-level descriptors, we have extracted SIFT and Opponent SIFT descriptors <ref type="bibr" coords="4,155.22,151.56,10.52,8.74" target="#b8">[9]</ref> on a dense spatial grid, with the step-size corresponding to half of the patch-size, over 10 scales (SIFT) and 5 scales (Opponent SIFT) separated by a factor of 1.2, and the smallest patch-size set to 16 pixels. As a result, roughly 9, 000 SIFT and 7, 000 Opponent SIFT descriptors are extracted from each image of ImageCLEF 2012 Flickr Photo Annotation dataset. The dimensionalities of the descriptors are reduced by using principal component analysis (PCA), resulting in a 64-dimensional SIFT and a 128-dimensional Opponent SIFT.</p><p>To learn the codebooks, we apply the k-means clustering algorithm with Euclidean distance over one million randomly sampled descriptors. For Fisher Vectors <ref type="bibr" coords="4,171.75,259.29,9.96,8.74" target="#b4">[5]</ref>, the descriptor distribution is modeled using a Gaussian mixture model (GMM), whose parameters (w, ¬µ, Œ£) are also trained over one million randomly sampled descriptors, using an expectation maximization algorithm. For all mid-level representations, we incorporate spatial information using the standard spatial pyramidal matching (SPM) scheme <ref type="bibr" coords="4,365.03,307.11,14.61,8.74" target="#b9">[10]</ref>. In total, we extracted 8 spatial cells (1 √ó 1, 2 √ó 2, 3 √ó 1).</p><p>One-versus-all classification is performed by support vector machine (SVM) classifiers. We use a linear SVM for Fisher Vectors, since it is well known that nonlinear kernels do not improve performances for those representations, see <ref type="bibr" coords="4,152.34,367.02,9.96,8.74" target="#b4">[5]</ref>. For BossaNova, we use a nonlinear Gauss-‚Ñì 2 kernel. Kernel matrices are computed as exp(-Œ≥d(x, x ‚Ä≤ )) with d being the distance and Œ≥ being set to the inverse of the pairwise mean distances. For the combination of BossaNova and Fisher Vector representations, we apply a weighted sum of kernel functions. To map the SVM scores to probabilities we used a sigmoid function, f (x) = (1 + exp(Ax + B)) -1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Submitted Runs</head><p>We have submitted four runs in total. All runs use only visual information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>In Table <ref type="table" coords="5,173.78,324.75,3.87,8.74" target="#tab_0">1</ref>, we list the performance of our submitted runs. As detailed in <ref type="bibr" coords="5,450.57,324.75,9.96,8.74" target="#b0">[1]</ref>, the following three quality metrics were evaluated to compare the submitted results: Mean interpolated Average Precision (MiAP), Geometric Mean interpolated Average Precision (GMiAP) and F-measure (F-ex).</p><p>Regarding the MiAP metric, we can notice that our best run reached 34.37% by combining the BossaNova and Fisher Vector representations (Run 1), achieving thus the second rank among the 28 purely visual submissions and the 18 teams. It is worthwhile to point out that, according to <ref type="bibr" coords="5,381.56,408.48,9.96,8.74" target="#b1">[2]</ref>, the combination is performed by concatenating the vectors of BossaNova and Fisher Vector representations. Here, we opted to combine the two representations by a weighted sum of kernel functions, which is less time-consuming. The former combination, however, presents results slightly better over the latter. Therefore, we can improve our results even further. Also, our BossaNova scheme (Run 3) achieved the third rank reporting 33.64% MiAP. Moreover, from Table <ref type="table" coords="5,304.83,492.22,3.87,8.74" target="#tab_0">1</ref>, we can observe that using opponent SIFT (Run 4) as supplementary features does not bring any improvement. However, we consider that result is particularly affected by the severe dimensionality reduction of Opponent SIFT, from 392 to 128 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we presented our BossaNova scheme for the ImageCLEF 2012 Flickr Photo Annotation Task. Our method has the advantage of being conceptually simple, non-parametric and easily adaptable.</p><p>In our participation, we submitted four purely visual runs. Our best result (MiAP = 34.37%), which applied the combination of BossaNova and Fisher Vector representations, achieved the second rank by MiAP measure among the 28 purely visual submissions, while our BossaNova method achieved the third Feature combinations in a kernel learning framework is currently investigated in order to take advantages of all the features together.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,165.85,237.19,283.64,7.89;3,312.20,116.18,82.87,80.57"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of BossaNova and Bag-of-Words pooling functions.</figDesc><graphic coords="3,312.20,116.18,82.87,80.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,155.86,407.20,324.73,8.74;3,134.76,419.15,345.83,9.66;3,134.76,431.11,9.14,8.74;3,143.94,429.53,14.81,6.12;3,143.91,435.61,7.07,6.12;3,159.25,431.11,10.79,8.74;3,170.09,429.53,15.91,6.12;3,170.05,435.61,7.07,6.12;3,186.50,431.11,120.31,8.74;3,306.85,429.53,14.81,6.12;3,306.81,435.61,7.07,6.12;3,325.29,431.11,127.42,8.74;3,452.75,429.53,15.91,6.12;3,452.72,435.61,7.07,6.12;3,472.29,431.11,8.30,8.74;3,134.76,443.05,25.05,9.31;3,159.81,441.49,4.15,6.12;3,167.78,443.06,249.93,8.74;3,149.71,455.17,61.89,8.74;3,211.64,453.60,14.81,6.12;3,211.61,459.68,7.07,6.12;3,230.47,455.17,25.94,8.74;3,256.45,453.60,15.91,6.12;3,256.42,459.68,7.07,6.12;3,276.38,455.17,204.21,8.74;3,134.76,467.13,309.77,8.74;3,444.57,465.55,15.91,6.12"><head></head><label></label><figDesc>key parameters in our BossaNova representation are the number of codewords M , the number of bins B in each histogram z m , and the range of distances [Œ± min m , Œ± max m ] -the minimum distance Œ± min m and the maximum distance Œ± max m in the R d descriptor space that define the bounds of the histogram. The bounds Œ± min m and Œ± max m define the range of distances for the histogram computation. Local descriptors outside those bounds are ignored. For Œ± max</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.76,500.54,345.84,8.77;4,151.70,512.52,328.90,8.74;4,151.70,524.48,328.89,9.30;4,151.70,536.43,328.90,9.66;4,151.70,548.39,328.90,8.74;4,151.70,560.35,328.89,8.74;4,151.70,572.30,328.91,8.74;4,151.70,584.26,196.71,8.74;4,134.76,596.32,345.84,8.77;4,151.70,608.30,328.90,8.74;4,151.70,620.26,328.89,9.30;4,151.70,632.21,328.91,9.66;4,151.70,644.17,328.90,8.74;4,151.70,656.12,254.88,8.74;5,134.76,118.97,345.84,8.77;5,151.70,130.95,329.88,8.74;5,151.70,142.91,328.89,9.65;5,151.70,154.86,328.91,8.74;5,151.70,166.82,328.89,8.74;5,151.70,178.77,260.48,8.74;5,134.76,190.75,345.84,8.77;5,151.70,202.73,328.91,8.74;5,151.70,214.69,328.89,8.74;5,151.70,226.64,328.89,9.66;5,151.70,238.60,328.91,8.74;5,151.70,250.55,328.90,8.74;5,151.70,262.51,328.90,8.74;5,151.70,274.46,111.31,8.74"><head>Run 1 - 1 . 3 -</head><label>113</label><figDesc>ID 1341070721262: Combination of BossaNova and Fisher Vector representations. We use only SIFT descriptors. BossaNova parameters values are: 4096 codewords, 2 bins, 5-nearest codewords in semi-soft coding, [0.4 ‚Ä¢ œÉ m , 2.0 ‚Ä¢ œÉ m ] (range of distances for the histogram computation), see [2] for more details. Fisher Vectors are obtained with 384 Gaussians. We apply a sigmoid function to map the SVM scores to probabilities, where A = 10 and B = 1. This run achieved our best MiAP result and the second score by MiAP measure among all visual submissions. Run 2 -ID 1341070953984: Combination of BossaNova and Fisher Vector representations. We use only SIFT descriptors. BossaNova parameters values are: 4096 codewords, 2 bins, 5-nearest codewords in semi-soft coding, [0.4 ‚Ä¢ œÉ m , 2.0 ‚Ä¢ œÉ m ] (range of distances for the histogram computation). Fisher Vectors are obtained with 384 Gaussians. We apply a sigmoid function to map the SVM scores to probabilities, where A = 20 and B = Run ID 1341348153832: BossaNova representation. We use only SIFT descriptors. BossaNova parameters values are: 4096 codewords, 2 bins, 5-nearest codewords in semi-soft coding, [0.4 ‚Ä¢ œÉ m , 2.0 ‚Ä¢ œÉ m ] (range of distances for the histogram computation). We apply a sigmoid function to map the SVM scores to probabilities, where A = 10 and B = 1. This run achieved the third score by MiAP measure among all visual submissions. Run 4 -ID 1341348523492: Combination of BossaNova and Fisher Vector representations. We use SIFT and Opponent SIFT (only for Fisher Vector) descriptors. BossaNova parameters values are: 4096 codewords, 2 bins, 5nearest codewords in semi-soft coding, [0.4 ‚Ä¢ œÉ m , 2.0 ‚Ä¢ œÉ m ] (range of distances for the histogram computation). Fisher Vectors are obtained with 384 Gaussians (for SIFT descriptors) and 128 Gaussians (for Opponent SIFT descriptors). We apply a sigmoid function to map the SVM scores to probabilities, where A = 10 and B = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.76,115.91,345.84,180.73"><head>Table 1 .</head><label>1</label><figDesc>Overview of the different submissions. MiAP = 33.64%). The absolute difference between the first MiAP and our best MiAP is only 0.44%. We consider that those results are particularly noteworthy considering the fact we have not yet exploited the use of complex combinations of different low-level local descriptors.</figDesc><table coords="6,134.76,138.14,304.70,122.65"><row><cell cols="4">Runs MiAP (%) GMiAP (%) F-ex (%)</cell><cell>Type</cell></row><row><cell>Run 1</cell><cell>34.37</cell><cell>28.15</cell><cell>41.99</cell><cell>Visual</cell></row><row><cell>Run 2</cell><cell>33.56</cell><cell>27.75</cell><cell>37.86</cell><cell>Visual</cell></row><row><cell>Run 3</cell><cell>33.64</cell><cell>27.65</cell><cell>40.09</cell><cell>Visual</cell></row><row><cell>Run 4</cell><cell>33.56</cell><cell>26.88</cell><cell>42.28</cell><cell>Visual</cell></row><row><cell>rank (</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is partially supported by <rs type="funder">CAPES</rs><rs type="grantNumber">/COFECUB 592/08/10</rs>, <rs type="grantNumber">CNPq 14.13-12/2009-2</rs>, <rs type="grantNumber">ANR 07-MDCO-007-03</rs>, <rs type="funder">FAPESP</rs> and <rs type="funder">FAPEMIG</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ydzPSpt">
					<idno type="grant-number">/COFECUB 592/08/10</idno>
				</org>
				<org type="funding" xml:id="_VJmGBDB">
					<idno type="grant-number">CNPq 14.13-12/2009-2</idno>
				</org>
				<org type="funding" xml:id="_PPkDSpw">
					<idno type="grant-number">ANR 07-MDCO-007-03</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.95,429.77,337.62,7.86;6,151.52,440.72,311.28,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,259.96,429.77,220.62,7.86;6,151.52,440.72,101.62,7.86">Overview of the ImageCLEF 2012 Flickr Photo Annotation and Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,275.61,440.72,103.77,7.86">CLEF 2012 working notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,451.37,337.62,7.86;6,151.52,462.33,329.06,7.86;6,151.52,473.29,137.39,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,410.93,451.37,69.64,7.86;6,151.52,462.33,197.97,7.86">Pooling in image representation: the visual codeword point of view</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ara√∫jo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,358.09,462.33,122.49,7.86;6,151.52,473.29,75.13,7.86">CVIU, Special Issue on Visual Concept Detection</title>
		<imprint/>
	</monogr>
	<note>under review</note>
</biblStruct>

<biblStruct coords="6,142.95,483.94,337.63,7.86;6,151.52,494.90,154.65,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,247.09,483.94,233.50,7.86;6,151.52,494.90,34.27,7.86">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,207.87,494.90,26.11,7.86">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,505.55,337.63,7.86;6,151.52,516.51,146.66,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,332.02,505.55,148.56,7.86;6,151.52,516.51,22.38,7.86">Learning mid-level features for recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,195.79,516.51,29.18,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2559" to="2566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,527.15,337.62,7.86;6,151.52,538.11,218.05,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,320.56,527.15,160.02,7.86;6,151.52,538.11,103.12,7.86">Improving the Fisher Kernel for Large-Scale Image Classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>S√°nchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,276.53,538.11,29.05,7.86">ECCV</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,548.73,337.64,7.89;6,151.52,559.72,56.31,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,198.92,548.76,233.16,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,443.91,548.76,21.63,7.86">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,570.37,337.64,7.86;6,151.52,581.33,43.76,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m" coord="6,209.63,570.37,156.91,7.86">The nature of statistical learning theory</title>
		<meeting><address><addrLine>New York, Inc</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,591.98,337.63,7.86;6,151.52,602.94,273.31,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,407.29,591.98,73.29,7.86;6,151.52,602.94,157.01,7.86">BOSSA: extended BoW formalism for image classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ara√∫jo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,330.24,602.94,21.39,7.86">ICIP</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2909" to="2912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.95,613.58,337.62,7.86;6,151.52,624.54,307.59,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,265.03,613.58,215.54,7.86;6,151.52,624.54,67.43,7.86">VLFeat -An open and portable library of computer vision algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,241.22,624.54,184.78,7.86">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,635.19,337.97,7.86;6,151.52,646.15,321.43,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,308.75,635.19,171.84,7.86;6,151.52,646.15,197.06,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,370.57,646.15,29.18,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
