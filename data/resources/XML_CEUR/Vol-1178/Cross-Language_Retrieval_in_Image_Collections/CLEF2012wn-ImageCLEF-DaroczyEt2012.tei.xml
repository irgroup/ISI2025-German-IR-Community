<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.08,99.91,59.55,12.93;1,211.94,99.91,255.88,12.93;1,467.69,99.74,5.73,7.50">SZTAKI</title>
				<funder ref="#_6nu7Tah #_ssgm85g">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,184.90,137.48,65.62,9.62"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute Hungarian Academy of Sciences</orgName>
								<orgName type="laboratory" key="lab1">Data Mining and Web Search Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research</orgName>
								<orgName type="institution">MTA SZTAKI</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.79,137.48,57.49,9.62"><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute Hungarian Academy of Sciences</orgName>
								<orgName type="laboratory" key="lab1">Data Mining and Web Search Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research</orgName>
								<orgName type="institution">MTA SZTAKI</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.58,137.48,83.56,9.62"><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute Hungarian Academy of Sciences</orgName>
								<orgName type="laboratory" key="lab1">Data Mining and Web Search Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research</orgName>
								<orgName type="institution">MTA SZTAKI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.08,99.91,59.55,12.93;1,211.94,99.91,255.88,12.93;1,467.69,99.74,5.73,7.50">SZTAKI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">72484F851F0BC294B53AE95B79F7A48E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>image classification</term>
					<term>biclustering</term>
					<term>generative models</term>
					<term>kernel methods</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our approach to the ImageCLEF2012 Photo Annotation task. We used both visual and textual modalities for all submissions. We described each image with a fixed length representation using different similarity measures. By this method we were able to combine, before the classification, a large variety of descriptors to improve the classification quality. This descriptor is a combination of several visual and textual similarity values between the actual image and a reference image set, containing well selected training images. We trained Gaussian Mixture Models (GMM) to define a generative model for low-level descriptors extracted from the training set using Harris-Laplacian point detection. We used two descriptors, a grayscale gradient and a color moment based one. In order to measure the visual similarity between two images, we extracted several dense Fisher vectors per image. Besides calculating visual features, we adopted a biclustering method to cluster the Flickr tags and the images at the same time. Additionally, we measured the similarity of images according to their Flickr tags using Jensen-Shannon divergence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF 2012 Photo Annotation task <ref type="bibr" coords="1,474.40,435.60,14.60,9.62" target="#b18">[19]</ref>. The main challenge is to select proper image processing and feature extraction methods for our given classification and pre-processing framework. Our image descriptors included spatial pooling based Fisher vectors <ref type="bibr" coords="1,153.40,471.47,15.49,9.62" target="#b12">[13,</ref><ref type="bibr" coords="1,170.57,471.47,12.72,9.62" target="#b14">15]</ref> calculated on point descriptors <ref type="bibr" coords="1,322.00,471.47,10.51,9.62" target="#b5">[6,</ref><ref type="bibr" coords="1,334.18,471.47,12.72,9.62" target="#b10">11,</ref><ref type="bibr" coords="1,348.58,471.47,7.75,9.62" target="#b8">9]</ref> such as Histogram of Oriented Gradients and Color moments <ref type="bibr" coords="1,207.17,483.42,10.51,9.62" target="#b5">[6,</ref><ref type="bibr" coords="1,219.35,483.42,11.62,9.62" target="#b17">18]</ref>. We adopted several different methods to measure the similarity of images based on their Flick tags. Beside Jensen-Shannon divergence, we used a modified version of Dhillan's biclustering algorithm <ref type="bibr" coords="1,243.39,507.33,10.51,9.62" target="#b7">[8]</ref> to explore deeper connections between the images and the Flickr tags.</p><p>In comparison to other teams our best run achieved the second highest MiAP, GMiAP and F-measure scores among the 18 participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Visual feature extraction</head><p>The GMM based Fisher gradient vector computed of SIFT <ref type="bibr" coords="1,351.63,599.22,15.49,9.62" target="#b9">[10]</ref> descriptors is a well-known technique to represent an image with only one vector per pooling <ref type="bibr" coords="1,360.29,611.17,15.49,9.62" target="#b14">[15,</ref><ref type="bibr" coords="1,377.46,611.17,12.72,9.62" target="#b12">13,</ref><ref type="bibr" coords="1,391.85,611.17,11.62,9.62" target="#b17">18]</ref>.</p><p>We used low-level patch feature vectors to describe the visual content of an image by approximately 15k descriptors per image per modality. Our sampling strategy included a dense grid and a Harris-Laplace point detection <ref type="bibr" coords="1,254.61,647.06,14.60,9.62" target="#b10">[11]</ref>. To avoid extracting large number of local features, we downscaled all the images with proper aspect ratio. The maximal width and height was set to 500 pixels. We calculated HOG (Histogram of Oriented Gradients <ref type="bibr" coords="1,363.20,670.96,10.79,9.62" target="#b5">[6]</ref>) and RGB color descriptors for each patch using 16x16 and 48x48 pixel macroblock sizes. Both descriptors were L2 normalized and by HOG we reduced the dimension to 96 by Principal Component Analysis (PCA). The PCA model was trained on a small sample of patches extracted from training images.</p><p>To build an efficient soft codebook, we trained a Gaussian Mixture Model (GMM) for both descriptors. The training procedure of GMM models took about 20 minutes using 3 million training points per descriptor. We used our open-source CUDA GMM implementation. Our training method was based on a standard Expectation Maximization algorithm with a non-hiherarchical structure. We avoided the well-known vulnerability of the EM algorithm to underflow by computing the condiditonal probabilities <ref type="bibr" coords="2,188.93,162.60,9.96,9.62" target="#b1">[2]</ref>. The resulted implementation is an accurate yet fast CUDA based code optimized for fp32 architectures. Our source code along with previously trained GMM models for different patch descriptors and codes for Fisher vector calculation is available free for research use at https://dms.sztaki.hu/hu/projekt/gaussian-mixture-modeling-gmm-es-fisher-vector-toolkit.</p><p>The final high-level dataset independent representation of images was the normalized Fisher gradient vector. We also calculated a separate Fisher vector on the Harris-Laplacian detected corner descriptors. As by our GMM implementation we were able to compute all the conditional probabilites for each feature vector without significant loss of time, which resulted a strongly dense Fisher vector even in fp32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Biclustering Flickr tags and image similarity</head><p>Our previous experiment <ref type="bibr" coords="2,204.95,317.85,9.96,9.62" target="#b6">[7]</ref>, Jensen-Shannon divergence of Flickr tags was an excellent image similarity measure. Our goal was to expand it with determining deeper interrelations between the tags and the documents using content based similarity.</p><p>The applied biclustering was an expansion of Dhillan's information theoretic co-clustering algorithm <ref type="bibr" coords="2,136.05,366.02,9.96,9.62" target="#b7">[8]</ref>. In comparison to the original algorithm we measured document similarity with a combination of visual and textual similarity values. We chose Jensen-Shannon divergence instead of Kullback-Leibler used in the original article. Our choice was inspired by our experiences with other datasets where Jensen-Shannon divergence resulted a significantly better clustering quality instead of Kullback-Leibler <ref type="bibr" coords="2,210.15,413.83,14.60,9.62" target="#b16">[17]</ref>. In order to refine the clustering with non-textual information, we added a similarity measure based on the best performing visual features (both HOG and color Fisher vectors pooled on different partitions such as the whole image, only the detected corner points and 3x1 spatial resolution).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Combination of representations</head><p>Efficient combination of different feature sets based on a wide range of visual modalities is one of the main problems of image classification. This problem becomes more complex if we have additional non-visual features such as Flickr tags. Our starting point was a widely used technique: learning SVM models on textual and visual Bag-of-Words models <ref type="bibr" coords="2,380.86,544.82,15.49,9.62" target="#b19">[20,</ref><ref type="bibr" coords="2,398.03,544.82,7.75,9.62" target="#b4">5,</ref><ref type="bibr" coords="2,407.43,544.82,11.62,9.62" target="#b11">12]</ref>. The selection of the ideal kernel depends on both of the original feature space and the class variable. Therefore the selection procedure is computationally expensive. The dual form of the optimization problem of the standard Support Vector Machine (SVM) classification <ref type="bibr" coords="2,332.99,580.69,10.51,9.62" target="#b3">[4]</ref> with kernel K(x i , x j ) is the following:</p><formula xml:id="formula_0" coords="2,180.10,611.01,332.90,30.40">M aximizeL Dual (α) = m i=1 - 1 2 m i=1 m j=1 α i α j y i y j K(x i , x j )<label>(1)</label></formula><p>subject to y i α i = 0 for all i with α i ≥ 0. Having multiple number of kernels due the representations via different modalities with previously selected kernel functions, we can modify the dual form into a multiple kernel learning problem: subject to y i α i = 0 for all i with α i ≥ 0 , where N is the number of the basic kernels and K n (xi, xj) is the nth kernel function.</p><formula xml:id="formula_1" coords="2,157.75,712.26,355.25,30.40">M aximizeL Dual (α, β) = m i=1 - 1 2 m i=1 m j=1 α i α j y i y j N n=1 β n K n (x i , x j )<label>(2)</label></formula><p>The above problem is a special case of the Multiple Kernel Learning problems where the kernels are computed on different feature sets. In comparison to Bach <ref type="bibr" coords="3,396.43,246.56,15.49,9.62" target="#b13">[14]</ref> we assumed that all of representations are conducive to the train procedure. Bach suggested to solve the MKL problem with an iterative and sparse learning method where in each iteration they solve a standard SVM dual problem and update the weights of the basic kernels. One of the drawbacks of this solution is the increased computational time.</p><p>To avoid the computationally expensive MKL problem we used a feature transformation method. Distance from the training set, as a feature transform for classification is a well-known technique. Schölkopf et al. showed that a class of kernels can be represented as norm-based distances in Hilbert spaces <ref type="bibr" coords="3,200.68,342.69,15.49,9.62" target="#b15">[16]</ref> and Ah-Pine et al. applied L1-norm based feature transformation measuring the distance from the Fisher vectors of the training set for image classification with excellent results <ref type="bibr" coords="3,162.64,366.60,9.96,9.62" target="#b0">[1]</ref>.</p><p>We defined a dense representation combining modality adaptive similarity based feature transforms. Let us consider a set of documents D (we call it as reference set) and their corresponding representations D r . We defined the uniform representation of a document X over the set of representations R of a reference set D as</p><formula xml:id="formula_2" coords="3,174.73,447.41,338.28,30.27">L R (X, D) = [ R r=1 β r sim r (X r , D r1 ), .., R r=1 β r sim r (X r , D rd )]<label>(3)</label></formula><p>where β r = 1 and sim r denotes the selected similarity measure on basic representation r and d is the size of the reference set. The dimensionality of this representation is the cardinality of the reference set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reference set selection and weight determination</head><p>The proper selection of the reference set could decrease significantly the demanding computational time of solving the standard dual problem. More precisely, we are seeking for the minimal set of documents without affecting significantly the quality of the learning procedure.</p><p>To determine the reference set we defined a ranking for the images according to their annotations. The rarer a concept, the higher the score of its positive instances will be. We cut the list where the training documents contain at least a specified quantity of positive samples for all categories. We set the minimal amount of positive samples to p * N where N is the number of training images. If a category did not have the minimal amount of positive instances all the samples were included. The resulted subset of training images using p = 0.01 contained only 6260 images out of the original 15k training images. Since the dimension of the combined representation equals with the number of images in the reference set this selection reduced the dimension by more than 50%.</p><p>To identify the weight vector β of the basic representations per class we sampled the training set. We used 5k images for training and 5k images for validation. We trained binary SVM classifiers using the LibSVM package <ref type="bibr" coords="3,210.28,724.50,10.51,9.62" target="#b2">[3]</ref> separately for each representation and used grid search to find the optimal linear combination per class. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>All of our submissions used both visual and textual features. The main differences were the number of training images used for classification and the size of the reference set. All the runs included the following basic representations: HOG based Fisher vectors (1x1,3x1,Harris-Laplacian), Color moment based Fisher vectors (1x1,3x1,Harris-Laplacian) and Jensen-Shannon divergence using Flickr tags as probability distributions (Table <ref type="table" coords="4,292.51,431.44,3.87,9.62" target="#tab_4">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiments on the validation set</head><p>In order to determine the parameters of the combined representation we experimented on the basic features using a subset of the training set. It can be seen in Table <ref type="table" coords="4,420.52,513.67,4.98,9.62" target="#tab_1">2</ref> that color moment and HOG descriptors complement each other. Although the average number of keypoints detected by Harris-Laplacian was considerably less than for the rest of the poolings (average 2k vs. 15k descriptors per image), we measured small performance differences between them. For Flickr tags we tested three methods (Table <ref type="table" coords="4,235.94,561.49,3.87,9.62" target="#tab_2">3</ref>). We selected the top 25,000 Flickr tags as vocabulary. The refined biclustering using visual similarity and Jensen-Shannon divergence outperformed Jensen-Shannon divergence and the purely tag based biclustering. We experimented with the parameter p for proper reference set selection over the best combined representation including all visual similarity values and Jensen-Shannon divergence. It can be seen in Table <ref type="table" coords="4,412.07,609.31,4.98,9.62" target="#tab_0">1</ref> that the performance loss was negligible even using less than half of the features. If we left only the 11.9% of the training set as reference set the performance dropped significantly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>In jch10ksep we used the ranked reference set with 6260 images and an annotation category based weighting scheme for the combination (19 different weight vectors). We trained binary SVM classifiers per class using a reduced training set containing only 10k images. Addition to jch10ksep, in jchb10ksep we added a refined biclustering representation with 2k clusters to the common representations. Notice that by biclustering the dimension of the representation was significantly the lowest of all (Table <ref type="table" coords="5,311.07,331.30,3.87,9.62" target="#tab_3">4</ref>).</p><p>Our best performing run jchf r15k used the entire training set as reference set and the binary SVM models were trained on the whole training set (15k) per class. The adopted weight vector β were the same for each class. It is worth to mention that we experienced increase in computational time in comparison to jch10ksep or jchb10ksep. The reason for the nonlinear increase is that by jchf r15k we used the whole training set as reference set and the binary SVM classifiers were trained on the entire training set.</p><p>Our second best performing run jchaggsep was a combination of jchf r15k and jch10ksep (Table <ref type="table" coords="5,122.86,426.95,3.87,9.62" target="#tab_5">6</ref>). We simply averaged the predictions of the runs. In jchbicwelf we aggregated the output of the biclustering based classifier and the jchf r15k using a linear combination learned previously on the training-validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Our approach for ImageCLEF 2012 Photo Annotation task employed various representations of the images based on different visual and textual modalities. We extracted several Ficher vectors using a grayscale and a color patch descriptor. We applied a biclustering method to cluster the images and their Flickr tags. We combined the different descriptors and representations before the classification. This combination procedure included a transformation, a feature aggregation and a selection step.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,205.57,99.80,191.85,82.88"><head>Table 1 .</head><label>1</label><figDesc>Reference set selection</figDesc><table coords="3,205.57,118.83,191.85,63.85"><row><cell></cell><cell cols="3">Train. set Ref. set Perc. MAP Loss</cell></row><row><cell>jch5k</cell><cell>5000</cell><cell cols="2">5000 100.0% 0.3485</cell></row><row><cell cols="2">p=0.10 5000</cell><cell cols="2">4280 85.6% 0.3485 0.0000</cell></row><row><cell cols="2">p=0.05 5000</cell><cell cols="2">3630 72.6% 0.3473 0.0012</cell></row><row><cell cols="2">p=0.03 5000</cell><cell cols="2">2414 48.3% 0.3448 0.0037</cell></row><row><cell cols="2">p=0.01 5000</cell><cell>595</cell><cell>11.9% 0.3082 0.0403</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,99.80,422.99,139.42"><head>Table 2 .</head><label>2</label><figDesc>Experimenting on visual descriptors, both the training set and the validation set contained 5k images, we used 16x16 and 48x48 macroblock sizes</figDesc><table coords="4,147.74,131.53,307.53,107.69"><row><cell></cell><cell cols="3">#keypoints #Gaussians Pooling(s)</cell><cell cols="2">Dim F isherV ec. MAP</cell></row><row><cell>HOG</cell><cell>15k</cell><cell>512</cell><cell>full</cell><cell>98304</cell><cell>0.2433</cell></row><row><cell>HOG</cell><cell>2k</cell><cell>512</cell><cell>HL</cell><cell>98304</cell><cell>0.2170</cell></row><row><cell>HOG</cell><cell>15k</cell><cell>512</cell><cell>3x1</cell><cell>3*98304</cell><cell>0.2399</cell></row><row><cell>HOG</cell><cell>15k</cell><cell>512</cell><cell>full+HL+3x1</cell><cell>5*98304</cell><cell>0.2517</cell></row><row><cell>Color</cell><cell>15k</cell><cell>256</cell><cell>full</cell><cell>49152</cell><cell>0.2106</cell></row><row><cell>Color</cell><cell>2k</cell><cell>256</cell><cell>HL</cell><cell>49152</cell><cell>0.2092</cell></row><row><cell>Color</cell><cell>15k</cell><cell>256</cell><cell>3x1</cell><cell>3*49152</cell><cell>0.2131</cell></row><row><cell>Color</cell><cell>15k</cell><cell>256</cell><cell>full+HL+3x1</cell><cell>5*49152</cell><cell>0.2233</cell></row><row><cell>Color+HOG</cell><cell>15k</cell><cell cols="4">256 &amp; 512 full+HL+3x1 5*(98304+49152) 0.2771</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,205.00,256.12,192.96,62.72"><head>Table 3 .</head><label>3</label><figDesc>Biclustering of Flickr tags and images</figDesc><table coords="4,249.89,276.89,103.21,41.94"><row><cell>Method MAP</cell></row><row><cell>baseline JS div. 0.2554</cell></row><row><cell>Bicluster JS div. 0.2185</cell></row><row><cell>Bicluster JS + Vis 0.3133</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,203.50,668.87,195.97,73.67"><head>Table 4 .</head><label>4</label><figDesc>Dimension of the basic representations</figDesc><table coords="4,216.13,689.64,170.75,52.90"><row><cell></cell><cell cols="2">Dimension sparsity</cell></row><row><cell cols="2">HOG Fisher vector 98304</cell><cell>dense</cell></row><row><cell cols="2">Color Fisher vector 49152</cell><cell>dense</cell></row><row><cell>Flickr tag tf</cell><cell cols="2">25000 very sparse</cell></row><row><cell>Biclustering</cell><cell>2000</cell><cell>dense</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,177.62,99.80,247.76,62.72"><head>Table 5 .</head><label>5</label><figDesc>MiAP, GMiAP and F-ex results of basic runs</figDesc><table coords="5,177.62,120.57,247.76,41.94"><row><cell></cell><cell cols="4">TrainSVM RefSet Weightn. MiAP GMiAP F-ex</cell></row><row><cell>jchfr15k</cell><cell>15k</cell><cell>15k</cell><cell>fix</cell><cell>0.4258 0.3676 0.5731</cell></row><row><cell>jch10ksep</cell><cell>10k</cell><cell cols="3">6.2k adapt. 0.4003 0.3445 0.5535</cell></row><row><cell>jchb10ksep</cell><cell>10k</cell><cell cols="3">6.2k adapt. 0.3972 0.3386 0.5533</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,179.03,175.24,244.91,51.74"><head>Table 6 .</head><label>6</label><figDesc>MiAP, GMiAP and F-ex results of late fusion runs</figDesc><table coords="5,192.88,196.01,217.22,30.97"><row><cell></cell><cell>base runs</cell><cell>MiAP GMiAP F-ex</cell></row><row><cell cols="3">jchaggsep jchfr15k + jch10ksep 0.4212 0.3655 0.5724</cell></row><row><cell>jchbicwelf</cell><cell>jchfr15k + bic</cell><cell>0.4173 0.3611 0.5717</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>⋆ This work is supported in part by the <rs type="programName">EC FET Open</rs> project "<rs type="projectName">New tools and algorithms for directed network analysis</rs>" (NADINE No <rs type="grantNumber">288956</rs>) and <rs type="grantNumber">OTKA CNK 77782</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_6nu7Tah">
					<idno type="grant-number">288956</idno>
					<orgName type="project" subtype="full">New tools and algorithms for directed network analysis</orgName>
					<orgName type="program" subtype="full">EC FET Open</orgName>
				</org>
				<org type="funding" xml:id="_ssgm85g">
					<idno type="grant-number">OTKA CNK 77782</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,98.19,617.82,414.78,8.66;5,106.76,628.78,242.66,8.66" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,366.21,617.82,146.76,8.66">XRCEs Participation to ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ah-Pine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cifarelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Renders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,143.35,628.78,177.29,8.66">Working Notes of the 2008 CLEF Workshop</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,98.19,639.50,414.80,8.66;5,106.76,650.46,238.39,8.66" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bodzsár</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Petrás</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
		<ptr target="http://datamining.sztaki.hu/?q=en/GPU-GMM" />
		<title level="m" coord="5,350.64,639.50,162.34,8.66;5,106.76,650.46,30.38,8.66">GMM based fisher vector calculation on GPGPU</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,98.19,661.17,414.82,8.66;5,106.76,672.14,167.54,8.66" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,225.22,661.17,187.19,8.66">Libsvm: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,422.61,661.17,90.40,8.66;5,106.76,672.14,139.28,8.66">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,98.19,682.86,335.15,8.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,213.80,682.86,97.25,8.66">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,319.39,682.86,70.85,8.66">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,98.19,693.56,414.80,8.66;5,106.76,704.53,406.22,8.66;5,106.76,715.49,58.94,8.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,369.76,693.56,143.23,8.66;5,106.76,704.53,36.66,8.66">Visual categorization with bags of keypoints</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,168.35,704.53,255.29,8.66">Workshop on Statistical Learning in Computer Vision, ECCV</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,98.19,726.20,414.82,8.66;5,106.76,737.16,20.99,8.66" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,236.27,726.20,216.37,8.66">Histograms of oriented gradients for human detection</title>
		<author>
			<persName coords=""><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,461.64,726.20,47.09,8.66">CVPR 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,98.19,103.53,414.81,8.66;6,106.76,114.50,45.44,8.66" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,274.71,103.53,98.21,8.66">SZTAKI at ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pethes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,414.67,103.53,98.34,8.66;6,106.76,114.50,17.11,8.66">Working notes of CLEF 2011</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,98.19,125.46,414.82,8.66;6,106.76,136.41,406.23,8.66;6,106.76,147.37,49.65,8.66" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,287.73,125.46,139.82,8.66">Information-theoretic co-clustering</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mallela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,438.90,125.46,74.11,8.66;6,106.76,136.41,375.31,8.66">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,98.19,158.34,414.81,8.66;6,106.76,169.29,54.26,8.66" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,225.72,158.34,152.73,8.66">A combined corner and edge detector</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,388.28,158.34,98.35,8.66">Alvey Vision Conference</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page">147151</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,180.25,415.15,8.66;6,106.76,191.21,209.89,8.66" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,159.41,180.25,216.40,8.66">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,398.23,180.25,114.77,8.66;6,106.76,191.21,67.52,8.66">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,202.17,415.12,8.66;6,106.76,213.13,245.11,8.66" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,162.98,213.13,156.50,8.66">A comparison of affine region detectors</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schaffalitzky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,327.50,213.13,19.49,8.66">IJCV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,224.09,415.16,8.66;6,106.76,235.04,380.63,8.66" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,177.63,224.09,335.38,8.66;6,106.76,235.04,68.87,8.66">New Strategies for Image Annotation: Overview of the Photo Annotation Task at ImageCLEF 2010</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,195.45,235.04,238.50,8.66">Cross Language Evaluation Forum , ImageCLEF Workshop</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,246.00,415.15,8.66;6,106.76,256.97,371.56,8.66" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,223.77,246.00,247.03,8.66">Fisher kernels on visual vocabularies for image categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,490.73,246.00,22.28,8.66;6,106.76,256.97,229.47,8.66;6,368.53,256.97,36.00,8.66">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR&apos;07</note>
</biblStruct>

<biblStruct coords="6,97.85,267.92,415.16,8.66;6,106.76,278.88,71.91,8.66" xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,347.00,267.92,166.01,8.66;6,106.76,278.88,33.43,8.66">Simplemkl. Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,289.84,415.14,8.66;6,106.76,300.80,406.27,8.66;6,106.76,311.76,199.23,8.66" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,262.91,289.84,250.07,8.66;6,106.76,300.80,136.86,8.66">Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,263.68,300.80,249.35,8.66;6,106.76,311.76,78.40,8.66">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,322.72,346.91,8.66" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="6,187.54,322.72,116.81,8.66">The kernel trick for distances</title>
		<author>
			<persName coords=""><forename type="first">Bernard</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="301" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,333.67,415.13,8.66;6,106.76,344.63,406.23,8.66;6,106.76,355.60,247.58,8.66" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,339.17,333.67,173.81,8.66;6,106.76,344.63,60.78,8.66">Content-based trust and bias classification via biclustering</title>
		<author>
			<persName coords=""><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,188.05,344.63,324.94,8.66;6,106.76,355.60,49.13,8.66">Proceedings of the 2nd Joint WICOW/AIRWeb Workshop on Web Quality, We-bQuality &apos;12</title>
		<meeting>the 2nd Joint WICOW/AIRWeb Workshop on Web Quality, We-bQuality &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="41" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,366.55,415.14,8.66;6,106.76,377.51,406.23,8.66;6,106.76,388.47,20.99,8.66" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="6,370.21,366.55,142.78,8.66;6,106.76,377.51,205.33,8.66">LEAR and XRCEs participation to Visual Concept Detection Task at ImageCLEF 2010</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Snchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,330.36,377.51,177.91,8.66">Working Notes for the CLEF 2010 Workshop</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,399.43,415.15,8.66;6,106.76,410.39,243.80,8.66" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="6,262.04,399.43,250.97,8.66;6,106.76,410.39,51.52,8.66">Overview of the imageclef 2012 flickr photo annotation and retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Bart</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,166.21,410.39,103.76,8.66">CLEF 2012 working notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.85,421.34,415.15,8.66;6,106.76,432.30,406.24,8.66;6,106.76,443.27,20.99,8.66" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="6,339.28,421.34,173.72,8.66;6,106.76,432.30,66.57,8.66">Evaluating color descriptors for object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,180.18,432.30,259.16,8.66">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
