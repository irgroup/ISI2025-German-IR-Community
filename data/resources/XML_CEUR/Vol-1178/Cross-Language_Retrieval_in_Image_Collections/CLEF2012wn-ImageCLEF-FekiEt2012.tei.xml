<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.02,168.05,301.06,14.04;1,177.02,186.05,241.22,14.04">REGIMvid at ImageCLEF2012: Improving Diversity in Personal Photo Ranking Using Fuzzy Logic</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,157.34,226.46,49.67,11.04"><forename type="first">Ghada</forename><surname>Feki</surname></persName>
							<email>ghada.feki@yahoo.framel.ksibi</email>
							<affiliation key="aff0">
								<orgName type="laboratory">REGIM: REsearch Group on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<addrLine>BP W</addrLine>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.66,226.46,70.70,11.04"><roleName>Anis</roleName><forename type="first">Amel</forename><surname>Ksibi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REGIM: REsearch Group on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<addrLine>BP W</addrLine>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,287.85,226.46,52.82,11.04"><forename type="first">Ben</forename><surname>Ammar</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REGIM: REsearch Group on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<addrLine>BP W</addrLine>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,362.46,226.46,75.38,11.04"><forename type="first">Chokri</forename><forename type="middle">Ben</forename><surname>Amar</surname></persName>
							<email>chokri.benamar@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="laboratory">REGIM: REsearch Group on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<addrLine>BP W</addrLine>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.02,168.05,301.06,14.04;1,177.02,186.05,241.22,14.04">REGIMvid at ImageCLEF2012: Improving Diversity in Personal Photo Ranking Using Fuzzy Logic</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D039C3A38933AB6F41895AEE91F3373B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>concept-based image retrieval</term>
					<term>diversity-based ranking</term>
					<term>fuzzy logic</term>
					<term>inter-images visual similarity graph</term>
					<term>inter-images semantic similarity graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper handles with two main challenges: retrieving the best matching images to a given query and improving diversity in ranking using fuzzy logic. The proposed scheme proceeds as follows: First, an off line module is performed before starting the image retrieval process in order to reduce both, the execution time and the algorithm complexity. This module contains an inter-images semantic similarity graph and an inter-images visual similarity graph. Second, an on-line part implies the relevance-based ranking, the diversity-based ranking and their combination. We deal with the redundancy problem using fuzzy logic. Moreover, the vector of the relevance scores and the vector of the diversity scores are joined in order to have final scores of each image according to a given query. The experiments are conducted on ImageCLEF12 benchmark for the Personal Photo Retrieval task and show satisfying results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="706.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our group REGIMvid within REGIM laboratory research participates in the Personal Photo Retrieval task <ref type="bibr" coords="1,258.20,589.03,11.37,11.04" target="#b0">[1]</ref>. This task aims to overcome the redundancy in the returned results. The general scheme of our proposed approach is as following. Before starting the image retrieval process, we compute an interimages semantic similarity graph and an inter-images visual similarity graph in order to reduce both, the execution time and the algorithm complexity. This off-line part of the algorithm is supplied to decrease the collection ac-cess and to better organize the images in. The on-line part of the algorithm implies the following steps: First, the relevance-based ranking is the basic part of the process, in which we fix the image semantic similarity scores according to a given query. Second, the diversity-based ranking is a refinement's process, in which we attribute a diversity score for each image according to its relations with other images from the collection while respecting its position in the rank list. Finally, both of these scores are combined. The rest of the paper is organized as follows. Section 2 details our proposed relevance and diversity-based approach. Section 3 discusses the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Relevance and diversity-based approach: Personal Photo Retrieval task</head><p>Relevance computing in our approach implies three phases. First, a matching process is performed basing on concepts from the query and the image data. Second, we compute the diversity scores. Finally, we establish the combination.</p><p>The following notations will be used. Given a set of query concepts = { , ,.., }, we denote by = { , ,.., } the collection of images that are associated with the set of query concepts . This collection is a part of the large collection .</p><p>Giving an image , we denote by = { , ,.., } the set of its associated concepts <ref type="bibr" coords="3,168.97,441.65,11.37,11.04" target="#b1">[2]</ref>. The relevance scores of all images in D are represented in a vector , where denotes the relevance score of image with respect to the set of query concepts .</p><p>(1)</p><p>Relevance score reflects the degree of the existence of a given concept in the image . This score is normalized that we range it from 0 to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance-based scores</head><p>Based on experimental semantic similarity measures study, we decide to adopt an approach for semantic similarity between a given query and an image that is analogous in term of Cosine similarity measure. The semantic similarity between and , which are respectively the sets of query concepts and image concepts, is defined as:</p><p>This semantic similarity is computed between the query set of concepts and each concept sets of images that belong to the sub-collection relative to this query. For other images belonging to , their similarity scores are evidently equal to zero. We denote by the vector of semantic similarity between a query and the collection . It is defined as follows:</p><p>This vector supposed be used as an input for refinement phase is provided thanks to an inter-images semantic similarity based random walk with restart. However, we note that when we use random walk with the collections, which present redundant images, we risk decreasing the diversity. In fact, it supposes that images, which are similar, have generally the same relevance scores. As consequence, in a first step, we use inter-images relationship to get closer the similar images and in a second, we want to separate them. Therefore, we have ignored the random walk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Diversity-based scores</head><p>To satisfy more the user, results should be not only relevant but also diverse. Therefore, the final scores are the combination of relevance scores and diversity scores. In fact, relevance scores, which are computed as mentioned in the previous section, serve not only for the combination but they are the input for the diversity-based algorithm that when we have two related images, we should put the most relevant and neglect the other. So if we verify the diversity characteristic while considering the order, the most relevant will be selected the first and after, when we come to verify the other, we discover that they are similar and we class it at the end without doubt that it can be more relevant than the other. Indeed, we attempt to give higher scores to diverse images. Thanks to the greedy <ref type="bibr" coords="5,158.75,181.82,12.38,11.04" target="#b2">[3]</ref> algorithm, we guarantee that images in the top of the list will be diverse and the other images supposed less diversified will be the last ones. Indeed, it is a double-edged weapon that there is relatively no loss of information since user can find not diverse images in the end of the list but this part is rarely visited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Greedy search ranking.</head><p>The greedy algorithm works in phases. At each phase, we take the best we can get right now, without regard for future consequences. Moreover, we hope that by choosing a local optimum at each step, we will end up at a global optimum. This strategy incrementally builds a more diverse set of results from the existing result set.</p><p>The greedy algorithm seeks to provide a more efficient approach to improve diversity by using a specific condition to guide the construction of a result set in an incremental fashion. During each iteration, the remaining images are ordered according to their diversity degree. The images are chosen according to the order in relevance based ranking list. In other words, the first image to be selected is always the one with the highest similarity to the query. Moreover, we will verify if this selected image is the one with the highest diversity degree with respect to the set of images selected during the previous iteration.</p><p>The following figure shows the greedy search algorithm procedure for image ranking:</p><p>Hence, greedy algorithm builds up a solution piece by piece, always choosing the next piece that offers the most evident and immediate benefit. Indeed, we just rank all images and keep the diverse ones in the top of the list. Therefore, it is a permutation problem, in which users will not miss information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fuzzy logic necessity.</head><p>Diversity can have more than unique definition. In fact it can be solution for ambiguity, uncertainty, redundancy and vagueness which are usually present in the image content, the user query and the similarity measures. Indeed, it is a source of novelty and optimal understanding of the query that results will be different from each other.</p><p>To model these constraints, we make appeal to the fuzzy logic <ref type="bibr" coords="6,412.37,631.15,12.38,11.04" target="#b3">[4]</ref> thanks to its flexibility and its ease-of-use. Fuzzy set theory provides many tools for dealing with this type of problem. In effect, since users communicate and express their needs in linguistic terms, we would suppose that for receiving Fig. <ref type="figure" coords="6,282.53,397.82,3.48,9.00">3</ref>. Greedy search process correct image retrieval, extracting the information with fuzzy logic would be more natural <ref type="bibr" coords="7,188.15,181.82,11.85,11.04" target="#b4">[5]</ref>.In addition, image collection content is not sufficiently organized and cleaned from copies or near-duplicate images. Therefore, selecting diverse images entails a particular dealing with the image collection that demands a fuzzy decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversification strategy.</head><p>We search to be more practical in dealing with diversity intention. For giving high score to an image for a given query, it must be not redundant comparing to others ranked before it. Diversity refers to no redundancy. Therefore, we define diversity score of an image as its minimal difference with the images appearing before it for a given query. It must be visually far from each image ranked before it. In other words, there are no images having higher relevance scores, similar to this image. In fact, scores reflecting the redundancy of an image are computed tanks to the inter-images visual similarity graph representing the collection. Another factor can have an impact on the quality of the diversity-based ranking that the collection contains an image, which has low relevance score but which is highly semantically dissimilar from all other images in this collection.</p><p>As a consequent, it will necessarily have a high diversity score that will make wrong the final score. Therefore, we must include another intermediary score. Based on the inter-images semantic similarity graph, this score should reflect the degree of homogeneity of this image with all images in the collection.</p><p>The following graph illustrates an example of semantic similarities between some images extracted from a collection from ImageCLEF 2012. For optimal diversity, scores take into account these two factors, which are redundancy and prevalence. In fact, we verify the situation of this image not only according to images ranked before it but also in relation with the whole collection. The used connective to combine rules is the logical disjunction taken from the Lukasiewicz logic <ref type="bibr" coords="8,272.29,547.39,11.29,11.04" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Combined scores</head><p>In order to balance between the relevance and the diversity user's needs, the final ranking list is obtained after combining the relevance score and diversity score of an image for given query. As a final stage, the combination between relevance-based ranking scores and diversity-based ranking scores is a decisive phase. In fact, we have thinking a lot about the balancing manner especially about the importance that we should give to one factor at the expense of the other. We consider that diversity requirement has the same degree of importance that has relevance necessity. As a result, global score not only reflects the similarity between the query and the image collection but also respects some specificity in queries like image redundancy constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental results</head><p>We describe the experimental study conducted to evaluate the proposed approach within the relevance computing and the diversity enhancement.</p><p>The relevance and diversity-based approach for image retrieval is evaluated with the Personal photo task<ref type="foot" coords="9,255.65,332.99,3.53,6.96" target="#foot_2">1</ref> , in which the challenge is to overcome the redundancy problem.</p><p>The submitted runs are inspired from our proposed approach described above that for a run, we use only the redundancy factor (run1), for another we add the prevalence factor (run 4) and a baseline run using only relevance constraint (run5). Moreover, we try our two proposed graphs, the semantic graph and the visual one, in calculating these two factors previously mentioned.</p><p>We notice that the forth run, which represents the complete proposed approach has the best result but with restricted difference. In fact, the used diversity strategy, which is proposed by <ref type="bibr" coords="9,312.26,509.35,12.25,11.04" target="#b6">[7]</ref> shows experimentally that it is designed for limited collection. Like for prevalence score previously mentioned, which depends enormously of the number of images in the collection. Therefore, when we add this factor, the original diversity score slightly changes.</p><p>In addition, our results concerning this task revel better in P_5, P_10, P_15 and P_20 than in P_30 and P_100, which is explained by the use of the greedy search algorithm. In fact, we think that user need diversity in the top of the list and prefer to keep the other images judged no diverse in the rest of the list. Diversity-based ranking proved its necessity in eliminating redundancy within the Retrieval of visual concepts task with our five submitted runs.</p><p>Furthermore, the proposed approach shows acceptable results with the Retrieval of events task. Comparing with the results achieved for the Retrieval of visual concepts task, we notice a notable degradation, which can be explained that our proposed approach is designed for image retrieval whereas event retrieval is closer to shot detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this interesting participation in ImageCLEF, we propose an approach, which improves diversity in ranking using fuzzy logic. The proposed scheme proceeds as follow: First, an off line module was performed before starting the image retrieval process in order to reduce both, the execution time and the algorithm complexity. This module contains an inter-images semantic similarity graph and inter-images visual similarity graph. Second, an on-line part implies the relevance-based ranking, the diversity-based ranking and their combination. Thanks to fuzzy logic, we deal with the redundancy problem. Moreover, the vector of the relevance scores and the vector of the diversity scores are joined in order to have final scores of each image according to a given query. The experiments are conducted on ImageCLEF12 benchmark for the Personal Photo Retrieval task and show good results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,256.01,634.72,83.03,9.00;2,128.90,282.41,338.61,338.50"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. General scheme</figDesc><graphic coords="2,128.90,282.41,338.61,338.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,203.81,614.68,187.33,8.10;7,127.40,445.44,339.87,153.69"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Inter-images visual similarity graph example</figDesc><graphic coords="7,127.40,445.44,339.87,153.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,198.62,463.10,197.79,8.10;8,127.40,293.92,340.03,153.43"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Inter-images semantic similarity graph example</figDesc><graphic coords="8,127.40,293.92,340.03,153.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,218.57,437.90,157.83,8.10;10,140.40,205.20,306.92,218.50"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Personal Photo Retrieval task results</figDesc><graphic coords="10,140.40,205.20,306.92,218.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,126.20,205.20,345.75,180.70"><head></head><label></label><figDesc></figDesc><graphic coords="6,126.20,205.20,345.75,180.70" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0" coords="6,124.70,120.83,44.85,9.00"><p>G. Feki et al.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_1" coords="8,124.70,120.83,44.85,9.00"><p>G. Feki et al.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2" coords="9,129.74,675.55,153.06,9.00"><p>http://www.imageclef.org/2012/personal</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,132.67,334.70,338.03,9.00;11,141.74,345.62,328.70,9.00;11,141.74,356.78,70.40,9.00" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,308.69,334.70,162.01,9.00;11,141.74,345.62,191.23,9.00">A Fuzzy Ontology-Based Framework for reasoning in Visual Video Content Analysis and Indexing</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elleuch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,347.96,345.62,122.48,9.00;11,141.74,356.78,44.67,9.00">the intl Workshop on Multimedia Data Mining</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,377.66,337.94,9.00;11,141.74,388.82,257.77,9.00" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,280.01,377.66,190.60,9.00;11,141.74,388.82,187.56,9.00">Effective Concept Detection using Second Order Cooccurence Flickr Context Similarity measure SOCFCS</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ksibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Ben</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,335.65,388.82,37.94,9.00">CBMI</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,409.70,337.63,9.00;11,141.74,420.62,328.60,9.00;11,141.74,431.66,328.96,9.00;11,141.74,442.82,197.59,9.00" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,305.99,409.70,164.31,9.00;11,141.74,420.62,116.17,9.00">Greedy RankRLS: a Linear Time Algorithm for Learning Sparse Ranking Models</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pahikkala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Airola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Naula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,168.14,431.66,302.56,9.00;11,141.74,442.82,22.23,9.00">SIGIR 2010 Workshop on Feature Generation and Selection for Information Retrieval</title>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Evgeniygabrilovich</surname></persName>
		</editor>
		<editor>
			<persName><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><surname>Naftalitishby</surname></persName>
		</editor>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,463.70,337.77,9.00;11,141.74,474.76,207.72,9.00" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="11,309.93,463.70,156.37,9.00">Cock: General Fuzzy Answer Set Programs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schockaert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vermeir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De</surname></persName>
		</author>
		<ptr target="http://ebookbrowse.com/wilf2009-pdf-d5924426" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,495.64,338.03,9.00;11,141.74,506.68,328.99,9.00;11,141.74,517.84,79.08,9.00" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,191.90,495.64,205.09,9.00">Image Retrieval on the Internet -How can Fuzzy Help?</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,236.93,506.68,233.80,9.00;11,141.74,517.84,11.50,9.00">Proceedings. NAFIPS. 2002 Annual Meeting of the North American</title>
		<meeting>NAFIPS. 2002 Annual Meeting of the North American</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="526" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,538.72,337.70,9.00;11,141.74,549.64,328.95,9.00;11,141.74,560.80,78.66,9.00" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,256.01,538.72,214.36,9.00;11,141.74,549.64,185.50,9.00">Tightly Integrated Fuzzy Description Logic Programs under the Answer Set Semantics for the Semantic Web</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Straccia</surname></persName>
		</author>
		<idno>1843-07-03</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,335.82,549.64,57.95,9.00">Infsys Research</title>
		<imprint>
			<date type="published" when="2007-02">February 2007 (2007</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct coords="11,132.67,581.68,337.94,9.00;11,141.74,592.72,328.89,9.00;11,141.74,603.76,215.81,9.00" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,239.83,581.68,230.78,9.00;11,141.74,592.72,29.04,9.00">Cock: Diversification of search results as a fuzzy satisfiability problem</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schockaert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,177.38,592.72,35.02,9.00;11,349.15,592.72,121.48,9.00;11,141.74,603.76,190.05,9.00">conjunction with ECIR 2011 -the 33rd European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04-18">18th April 2011. 2011</date>
		</imprint>
	</monogr>
	<note>DDR-2011</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
