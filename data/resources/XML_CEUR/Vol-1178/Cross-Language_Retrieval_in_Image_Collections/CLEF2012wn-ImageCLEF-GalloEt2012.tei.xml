<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.62,115.96,274.11,12.62;1,164.65,133.89,286.05,12.62;1,243.10,151.82,129.17,12.62">Fast Tree Leaf Image Retrieval using a Probabilistic Multi-class Support Vector Machine Classifier</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,183.29,189.49,56.32,8.74"><forename type="first">Ignazio</forename><surname>Gallo</surname></persName>
							<email>ignazio.gallo@uninsubria.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Scienze Teoriche ed</orgName>
								<orgName type="institution">University of Insubria</orgName>
								<address>
									<addrLine>Applicate via Mazzini 5</addrLine>
									<settlement>Varese</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.29,189.49,100.02,8.74"><forename type="first">Alessandro</forename><surname>Zamberletti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Scienze Teoriche ed</orgName>
								<orgName type="institution">University of Insubria</orgName>
								<address>
									<addrLine>Applicate via Mazzini 5</addrLine>
									<settlement>Varese</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.10,189.49,72.75,8.74"><forename type="first">Simone</forename><surname>Albertini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Scienze Teoriche ed</orgName>
								<orgName type="institution">University of Insubria</orgName>
								<address>
									<addrLine>Applicate via Mazzini 5</addrLine>
									<settlement>Varese</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.82,201.45,61.50,8.74"><forename type="first">Angelo</forename><surname>Nodari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Scienze Teoriche ed</orgName>
								<orgName type="institution">University of Insubria</orgName>
								<address>
									<addrLine>Applicate via Mazzini 5</addrLine>
									<settlement>Varese</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.69,201.45,62.85,8.74"><forename type="first">Marco</forename><surname>Vanetti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Scienze Teoriche ed</orgName>
								<orgName type="institution">University of Insubria</orgName>
								<address>
									<addrLine>Applicate via Mazzini 5</addrLine>
									<settlement>Varese</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.62,115.96,274.11,12.62;1,164.65,133.89,286.05,12.62;1,243.10,151.82,129.17,12.62">Fast Tree Leaf Image Retrieval using a Probabilistic Multi-class Support Vector Machine Classifier</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">27AF688F8F324D649F8E3BAC04157C6B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>image classification</term>
					<term>support vector machine</term>
					<term>pyramid of histograms of orientation gradients</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nowadays an increasing number of people own mobile phones with built-in camera, able to take pictures. Thus, having a fast and fully automatic algorithm of image retrieval is considered a promising way to identify plant leaves on a mobile device. Our solution proposes a Support Vector Machine that provides a multi-class probability estimation with radial basis function kernel based on two descriptors: PHOG and a variant of HAAR. With our method we placed seventh among all the fully automatic methods who participated in the ImageCLEF Plant Identification 2012 task. As showed by the results, the proposed method is very fast and at the same time has a classification accuracy comparable with the state of the art in this domain, aspects which make this method feasible in practice.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the participation of the ArTe-Lab<ref type="foot" coords="1,384.81,505.47,3.97,6.12" target="#foot_0">1</ref> research laboratory (Applied Recognition Technology Laboratory) at University of Insubria in the ImageCLEF Plant Identification 2012 task. The objective of this work is the retrieval of plant species, starting from the images belonging to the dataset proposed by the aformentioned task<ref type="foot" coords="1,275.57,553.29,3.97,6.12" target="#foot_1">2</ref> ; this problem can be solved with a good accuracy using one of the many algorithms proposed in literature, such as: LP-Î² <ref type="bibr" coords="1,467.31,566.82,9.96,8.74" target="#b0">[1]</ref>, MKL <ref type="bibr" coords="1,161.37,578.78,9.96,8.74" target="#b1">[2]</ref>, VLFeat <ref type="bibr" coords="1,214.32,578.78,9.96,8.74" target="#b2">[3]</ref>, R.Forests <ref type="bibr" coords="1,275.43,578.78,9.96,8.74" target="#b3">[4]</ref>, etc. However these algorithms require a lot of computional time and therefore they cannot be used to perform a real time classification of the images. We wanted to follow a different approach by designing and developing a fast algorithm that is able to obtain a good accuracy over all the types of images belonging to the dataset of the task subject of this study.</p><p>In order to identify the species a leaf belongs to, we model the species as classes in a classification framework that is based on a set of simple visual features extracted only from the images; we do not consider any metadata annotated along with each image which belongs to the dataset. In particular, we decided to employ simple features based on edges and intensity values distribution, among all the most successful features proposed in literature for object classification. We address the problem of learning score functions, motivated by ranking tasks in information retrieval (IR). Given an image containing a leaf, the scoring function associates a score to each known class; these class labels are then presented to the user in a decreasing order of scores. The quality of this sorted list of class labels depends on the position (rank) of the labels that are relevant to the image. Since the user considers only the few first class labels, it is desirable to have an high precision on top scored ones. Learning to rank is equivalent to the problem of choosing an effective scoring function, using a training set of images for which relevant classes are known.</p><p>With our method we placed seventh among all the fully automatic methods who participated in the ImageCLEF Plant Identification 2012 task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Method</head><p>The multi-class classification problem refers to assigning each of the observations into one of k classes. In this paper we focus on a technique that provides a multi-class probability estimation by combining all the pairwise comparisons <ref type="bibr" coords="2,467.31,391.84,9.96,8.74" target="#b4">[5]</ref>, using a Support Vector Machine (SVM) <ref type="bibr" coords="2,321.59,403.79,10.52,8.74" target="#b5">[6]</ref> classifier. Pairwise coupling is a popular multi-class classification method that combines all comparisons for each pair of classes; this method can be reduced to a linear system which is easy to implement. In particular, we used the implementation found in LIBSVM library for support vector machines <ref type="bibr" coords="2,260.31,451.61,9.96,8.74" target="#b6">[7]</ref>. The predicted label is the one with the largest probability value but, using the same probability values we sort all the classes, from most to least likely.</p><p>The SVN receives as input two different descriptors: the first is the Pyramid of Histograms of Orientation Gradients (PHOG) <ref type="bibr" coords="2,354.73,499.60,10.52,8.74" target="#b7">[8]</ref> and the second is similar to the HAAR descriptor proposed by Viola and Jones <ref type="bibr" coords="2,386.87,511.56,9.96,8.74" target="#b8">[9]</ref>. We used 15 bins and 3 layers for the PHOG descriptor while the HAAR is composed by two different descriptors. Regarding the latest, the first HAAR descriptor is</p><formula xml:id="formula_0" coords="2,134.77,533.89,345.83,24.16">D 1 = {D 1 1 , . . . , D 1</formula><p>25 } and it is computed as follows: each image is divided into a table of 25 rows and 3 columns; for each row j we calculate the sums S i obtaining a descriptor's component as</p><formula xml:id="formula_1" coords="2,134.77,569.76,345.82,25.26">D 1 j = S 1 + S 2 -S 3 . The second HAAR descriptor D 2 = {D 2 1 , . . . , D<label>2</label></formula><p>50 } is computed similarly to the first one: each image is divided in 25 rows and 6 columns but, for each row j, we compute two components</p><formula xml:id="formula_2" coords="2,134.77,606.72,194.41,12.32">D 2 j = S 2 -S 1 -S 3 and D 2 j+1 = S 5 -S 4 -S 6 .</formula><p>Each descriptor is first normalized and then concatenated to the other in order to form the input pattern. Figure <ref type="figure" coords="2,475.61,620.25,4.98,8.74" target="#fig_0">1</ref> shows a graphical representation of how the input images are transformed in patterns for the used SVM model. In the top row of the figure we can notice the three histograms extracted from the three levels of the PHOG descriptor, while *the source code is not available **taken individually this feature is not relevant in the classification process each histogram is constructed by concatenating the histograms extracted from each cell. In the bottom row we can notice the two HAAR descriptors, each of which is transformed into a new histogram to be concatenated to the previous.</p><p>The SVM is trained for probability estimation and it uses a radial basis function as kernel and C = 8, Î³ = 2 as main parameters.</p><p>We compared PHOG and Haar descriptors along with many others in order to determine the most stable and robust ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In order to choose the best features to manage the problem addressed in this study, we started our experiments comparing different classification algorithms found in the literature: a multiclass method called LP-Î² <ref type="bibr" coords="3,399.65,452.88,9.96,8.74" target="#b0">[1]</ref>, a multi-kernel method called MKL <ref type="bibr" coords="3,225.68,464.84,9.96,8.74" target="#b1">[2]</ref>, an algorithm based on Bag of Words called VLFeat <ref type="bibr" coords="3,470.07,464.84,10.52,8.74" target="#b2">[3]</ref> and an image classification approach based on R.Forests named Random Forests (R.Forests) <ref type="bibr" coords="3,186.87,488.75,9.96,8.74" target="#b3">[4]</ref>. We also considered simpler approaches based on HOG <ref type="bibr" coords="3,445.51,488.75,15.50,8.74" target="#b9">[10]</ref> and PHOG <ref type="bibr" coords="3,167.98,500.70,10.52,8.74" target="#b7">[8]</ref> features, using a SVM classifier <ref type="bibr" coords="3,322.32,500.70,9.96,8.74" target="#b5">[6]</ref>. We also evaluated an interesting feature: the HAAR descriptor proposed by Viola and Jones <ref type="bibr" coords="3,398.70,512.66,9.96,8.74" target="#b8">[9]</ref>; when taken individually this feature has not been shown to be relevant in classification but, in the experimental phase, we have verified that by combining it with other features we increase the object classification accuracy.</p><p>These features are compared using two standard datasets: the Caltech-101 <ref type="bibr" coords="3,466.74,560.48,15.50,8.74" target="#b10">[11]</ref> which contains 9,146 images of generic objects belonging to 101 classes, and the Drezzy-46 <ref type="bibr" coords="3,181.06,584.39,15.50,8.74" target="#b11">[12]</ref> which is composed by 46 classes of different commercial products crawled from the web and, for each class, there are approximately 100 images, leading to a total amount of about 4600 images. The results are reported in Table <ref type="table" coords="3,162.08,620.25,3.87,8.74" target="#tab_0">1</ref>, we also report the computational time, evaluated using a single thread C# code, on a Intel R Core TM i5 CPU at 2.30GHz.</p><p>Because our goal is focused on the development of an application able to properly work on a mobile device, we were looking for good features that can be quickly computed and do not require too much memory. Therefore we have selected the features considering the best balance between accuracy, computational time and memory requirements: PHOG and HAAR descriptors. In particular, the parameters of the PHOG feature were tuned in order to obtain the best compromise between speed and accuracy. Regarding the HAAR feature, we computed the two descriptors by setting the width of the rectangle to fit the image width of each image belonging to the ImageCLEF Plant Identification 2012 task dataset, on the basis of the results obtained during the experimental phase. Even if the predicted output label of our solution is the one having the largest probability value, using the same probability we can provide as output a list of class labels ordered by likelihood.</p><p>After selecting the features to adopt in our model, we evaluated the performance of classification on the Pl@ntLeaves dataset which has been built for the ImageCLEF Plant Identification 2012 competition, showed in Figure <ref type="figure" coords="4,448.86,560.48,3.87,8.74">2</ref>. This dataset contains around 11572 pictures subdivided into 3 different kinds of pictures: scans (Scan), scan-like photos (Pseudoscan) and free natural photos (Photograph). Each picture represents a plant leaf belonging to one of the 126 species present in the dataset. In the Scan category, each scan shows the upper-side of one leaf on a uniform background, centered and oriented vertically along the main natural axis; in the scan-like category the images are similar to the previous category but there are some luminance variations, optical distortions and shadows due to the not flattened acquisition method; in the free natural photos category Fig. <ref type="figure" coords="5,153.45,358.54,3.87,8.74">2</ref>: Examples of images belonging to the Pl@ntLeaves dataset. The dataset is divided in three categories: scans, scan-like photos and free natural photos.</p><p>the images are taken directly on the trees, therefore they may contain one or more leaves with different and complex backgrounds (such as branches, leafage, a trunk, the ground, the sky etc.) and various orientations. We trained a single SVM model for all three categories of images, even if the category Photograph deserves at least a preprocessing in order to improve the overall performance. We used the overall-accuracy to evaluate the results on the Pl@ntLeaves dataset and we obtained an average score of 0.30; considering individual types of images we obtained: 0.40 for annotations of type Scan, 0.37 for Pseudoscan and 0.14 for Photograph. A comparison with the results obtained by the other participants can be found in the figures 3,4 and 5. Our solution was implemented in C++ and tests were conducted on a Linux machine with CPU Intel Core2Duo 4500 2.02GHz. The average time required to transform a single image into a pattern for the SVM model is 90ms (that approximately corresponds to the time required to compute the single feature PHOG), while to predict the ranking for a single image the trained SVM needs approximately 20ms.</p><p>We want to emphasize that the proposed method does not use any a priori or metadata information but is based only on the information extracted from the content of each image and for this reason we believe that it is a very promising result.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Our group submitted just one run in our first participation in the ImageCLEF Plant Identification 2012 task; in this paper we described a simple plant species retrieval model based on a probabilistic SVN using PHOG and HAAR features.</p><p>With our proposed solution we placed seventh among all the fully automatic methods who participated in the aformentioned task and this is a good result because our approach can perform the classification of a single image, belonging to the Pl@ntLeaves dataset, in real time on a low computational power machine. Looking at the results, we can see that the proposed method obtains good results in the classification of the images belonging to the first two classes of images (Scan and Pseudoscan), while it needs much more preprocessing and segmentation work to be effective in the classification of the images belonging to the Photograph class.</p><p>Concerning the computational time, our algorithm turned out to be very fast due to the fact that we employed simple features and also because the Support Vector Machine using a radial basis function kernel requires linear time in the feature pattern size for the predictions phase.</p><p>This work opens a possible deep study of the features adopted to enhance the classification accuracy. Our simple approach allows the proposed algorithm to be very fast, but we could evaluate the possibility of adopting more complex features or even exploiting the pre-processing phases, such as image segmentation or partitioning, in order to improve the number of correct classifications, in spite of the computational performances.</p><p>Another possible future improvement of our model lies in the possibility of exploiting the metadata informations associated to the images belonging to the Pl@ntLeaves dataset, in order to enhance the classification accuracy; for example, we could identify the features that characterize the plants from each different region, as we can obtain the geographical place where the leaf had been taken from the metadata.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,330.95,345.83,8.74;4,134.77,342.91,345.83,8.74;4,134.77,354.86,345.82,8.74;4,134.77,366.82,28.23,8.74"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: A representative example of the PHOG and HAAR features extracted from an image belonging to the dataset used. Each features is normalized and linked to the others, in order to construct the representative pattern of the input image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,134.77,345.96,345.83,8.74;6,134.77,357.92,335.23,8.74;6,169.35,126.94,276.66,207.50"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Comparative results showing the performances of the proposed solution (ARTELAB-gallo) applied on the Scan category of the Pl@ntLeaves dataset.</figDesc><graphic coords="6,169.35,126.94,276.66,207.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,617.51,345.83,8.74;6,134.77,629.47,345.82,8.74;6,134.77,641.42,34.37,8.74;6,169.35,398.49,276.66,207.50"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Comparative results showing the performances of the proposed solution (ARTELAB-gallo) applied on the Pseudoscan category of the Pl@ntLeaves dataset.</figDesc><graphic coords="6,169.35,398.49,276.66,207.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,134.77,334.85,345.83,8.74;7,134.77,346.81,345.83,8.74;7,134.77,358.76,34.37,8.74;7,169.35,115.83,276.66,207.50"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Comparative results showing the performances of the proposed solution (ARTELAB-gallo) applied on the Photograph category of the Pl@ntLeaves dataset.</figDesc><graphic coords="7,169.35,115.83,276.66,207.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,127.36,345.83,139.97"><head>Table 1 :</head><label>1</label><figDesc>Comparison, in terms of overall accuracy, of different images classification algorithms on the Caltech-101 and the Drezzy-46 dataset. It is also reported the average time required to perform the classification of a single image.</figDesc><table coords="3,212.70,166.80,189.94,100.54"><row><cell></cell><cell></cell><cell cols="2">Overall Accuracy %</cell></row><row><cell cols="4">Algorithm Caltech-101 Drezzy-46 Avg. Time</cell></row><row><cell>LP-Î²</cell><cell>82.10</cell><cell>80.12</cell><cell>83.0s</cell></row><row><cell>MKL</cell><cell>73.70</cell><cell>88.89</cell><cell>88.0s</cell></row><row><cell>VLFeat</cell><cell>65.00</cell><cell>71.30</cell><cell>5.27s</cell></row><row><cell cols="2">R.Forests* 80.00</cell><cell>-</cell><cell>45.0s</cell></row><row><cell cols="2">HOG-SVM 28.26</cell><cell>32.90</cell><cell>0.014s</cell></row><row><cell cols="2">PHOG-SVM 54.00</cell><cell>64.87</cell><cell>0.047s</cell></row><row><cell>HAAR**</cell><cell>-</cell><cell>-</cell><cell>0.001s</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,646.48,164.76,7.47"><p>http://artelab.dicom.uninsubria.it/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,657.44,169.46,7.47"><p>http://www.imageclef.org/2012/plant/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,258.15,337.63,7.86;8,151.52,269.11,151.91,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,260.11,258.15,220.48,7.86;8,151.52,269.11,14.75,7.86">On feature combination for multiclass object classification</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,188.11,269.11,51.32,7.86">ICCV, IEEE</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,280.07,337.63,7.86;8,151.52,291.03,329.07,7.86;8,151.52,301.99,61.94,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,372.37,280.07,108.22,7.86;8,151.52,291.03,35.49,7.86">Multiple kernels for object detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,212.56,291.03,268.03,7.86;8,151.52,301.99,28.52,7.86">Proceedings of the International Conference on Computer Vision (ICCV)</title>
		<meeting>the International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,312.95,337.63,7.86;8,151.52,323.91,329.07,7.86;8,151.52,334.87,146.94,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,271.61,312.95,208.98,7.86;8,151.52,323.91,67.76,7.86">Vlfeat: an open and portable library of computer vision algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,458.83,323.91,21.76,7.86;8,151.52,334.87,44.45,7.86">ACM Multimedia</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Bimbo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1469" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,345.83,337.63,7.86;8,151.52,356.78,298.79,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,312.43,345.83,168.16,7.86;8,151.52,356.78,36.12,7.86">Image classification using random forests and ferns</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,209.44,356.78,208.21,7.86">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,367.74,337.63,7.86;8,151.52,378.68,292.95,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,283.97,367.74,196.62,7.86;8,151.52,378.70,81.02,7.86">Probability estimates for multi-class classification by pairwise coupling</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,240.67,378.70,83.91,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="975" to="1005" />
			<date type="published" when="2004-12">December 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,389.64,337.64,7.89;8,151.52,400.62,32.25,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,253.42,389.66,98.94,7.86">Support vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,363.22,389.66,73.20,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,411.58,337.64,7.86;8,151.52,422.51,329.07,7.89;8,151.52,433.50,240.00,9.85" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,252.91,411.58,195.81,7.86">LIBSVM: A library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
	</analytic>
	<monogr>
		<title level="j" coord="8,458.84,411.58,21.75,7.86;8,151.52,422.54,209.39,7.86">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,444.46,337.64,7.86;8,151.52,455.41,329.07,7.86;8,151.52,466.37,192.92,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,307.22,444.46,173.37,7.86;8,151.52,455.41,22.84,7.86">Representing shape with a spatial pyramid kernel</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,199.75,455.41,280.84,7.86;8,151.52,466.37,100.52,7.86">Proceedings of the 6th ACM international conference on Image and video retrieval. CIVR &apos;07</title>
		<meeting>the 6th ACM international conference on Image and video retrieval. CIVR &apos;07</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,477.33,337.63,7.86;8,151.52,488.27,158.39,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,253.12,477.33,124.24,7.86">Robust real-time face detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,384.96,477.33,95.63,7.86;8,151.52,488.29,68.93,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,499.25,337.97,7.86;8,151.52,510.21,117.64,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,242.80,499.25,217.32,7.86">Histograms of oriented gradients for human detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,510.21,53.65,7.86">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,521.17,337.98,7.86;8,151.52,532.10,267.39,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,248.76,521.17,149.17,7.86">One-shot learning of object categories</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei; Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,404.90,521.17,75.69,7.86;8,151.52,532.13,165.88,7.86">IEEE Transactions on Pattern Analysis Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006-04">April 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,543.09,337.98,7.86;8,151.52,554.04,329.07,7.86;8,151.52,565.00,287.60,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,417.47,543.09,63.12,7.86;8,151.52,554.04,306.46,7.86">A mobile visual search application for content based image retrieval in the fashion domain</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nodari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghiringhelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Albertini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vanetti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,565.00,254.10,7.86">Workshop on Content-Based Multimedia Indexing (CBMI2012)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
