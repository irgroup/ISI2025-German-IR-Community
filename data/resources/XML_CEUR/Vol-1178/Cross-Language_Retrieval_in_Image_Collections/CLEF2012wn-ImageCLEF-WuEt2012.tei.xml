<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,166.74,151.79,261.81,12.58">UESTC at ImageCLEF 2012 Medical Tasks</title>
				<funder ref="#_Usmdh8k">
					<orgName type="full">National Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.86,190.56,35.99,9.02"><forename type="first">Hong</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,219.93,190.56,55.04,9.02"><forename type="first">Kuangkai</forename><surname>Sun</surname></persName>
							<email>sunkuangkai@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,281.97,190.56,53.49,9.02"><forename type="first">Xianzhi</forename><surname>Deng</surname></persName>
							<email>dengxian.zhi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.73,190.56,35.87,9.02"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
							<email>zhangyi308@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.78,190.56,33.59,9.02"><forename type="first">Bili</forename><surname>Che</surname></persName>
							<email>blche@sina.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,166.74,151.79,261.81,12.58">UESTC at ImageCLEF 2012 Medical Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0743E6A7F6253BD62F5A6318883FF518</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Retrieval</term>
					<term>Semantic Similarity</term>
					<term>Lemur</term>
					<term>MeSH</term>
					<term>Modality Classification</term>
					<term>MKL</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the methods used and results archived by our research group in the ImageCLEF 2012 medical retrieval and classification tasks. We performed three sub-tasks, ad-hoc retrieval, case-based retrieval, and modality classification. For the retrieval tasks, we combined semantic-based retrieval with traditional text-based retrieval. The semantic-based retrieval was conducted by comparing query concepts and document concepts with semantic similarity measure, and asymmetric similarity measures were also proposed by modifying the existing symmetric measures. For the modality classification task, we used multiple kernel learning to combine various visual features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the third participation of the UESTC group in the ImageCLEF medical retrieval and classification tasks <ref type="bibr" coords="1,293.97,483.66,10.64,9.02" target="#b0">[1]</ref>. For the retrieval tasks, we adopted our retrieval method <ref type="bibr" coords="1,200.41,495.66,11.69,9.02" target="#b1">[2]</ref> which combining semantic-based retrieval with text-based retrieval. In our approach, each query or document has two representations, a textbased one and a concept-based one. The concept-based representations are constructed by mapping the text of a query or document to MeSH [3] descriptors (concepts) by MeSHUP [4], a MeSH classification system. In the semantic-based retrieval model, the query concepts and document concepts are compared with semantic similarity measure, and asymmetrical similarity measures are also proposed. Then the inter-concept similarities are aggregated to compute the relevance score of a document. For the text-based retrieval, any state of the art information retrieval models can be used. Finally, the semantic-based and text-based retrievals are combined. Our retrieval method was implemented on Lemur toolkit <ref type="bibr" coords="1,400.44,615.66,10.58,9.02" target="#b2">[5]</ref>. Based on our previous study <ref type="bibr" coords="1,185.95,627.66,10.64,9.02" target="#b3">[6]</ref>, we used multiple kernel learning (MKL) to combine various visual features for modality classification.</p><p>The remainder of this paper is organized as follows. Our retrieval method used in both ad-hoc retrieval and case-based retrieval is described in section 2, and our MKL-based modality classification method is given in section 3. Finally, our submitted runs and results are presented in section 4, followed by the conclusions in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Improving Medical Retrieval by Incorporating Semantic-Based Retrieval</head><p>In our approach, each document or query has two representations, a text-based representation and a concept-based representation, which are indexed and searched separately. The concept-based representation is constructed by mapping the text of a document or query to MeSH descriptors by MeSHUP [4], and each MeSH descriptor is used as index term as a whole. For the semantic-based retrieval, the query concepts and document concepts are compared with semantic similarity measures. And we also proposed asymmetrical semantic similarity measures which can be built by modifying existing symmetric measures. Then the inter-concept similarities are aggregated to compute the relevance score of a document. In the text-based representation, single words or word stems are used as index term. Any state of the art retrieval models, such as TF-IDF, BM25, etc. can be used for the text-based retrieval. Finally, the semantic-based and text-based searches are combined. Following section will give more details of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Semantic Similarity Measures</head><p>Ontology-based semantic similarity measures use ontology as the primary information source. They can be roughly grouped into three categories: path-based, information-based, and feature-based measures <ref type="bibr" coords="2,323.34,450.18,10.63,9.02" target="#b4">[7]</ref>, and all of them are symmetric measure. Path based similarity measure is a straightforward and efficient approach. It usually utilizes the information of the shortest path between two concepts, of the generality or specificity of both concepts in ontology hierarchy. The informationbased approaches are based on the information theory which use text corpus as secondary information source. They all use information content (IC) of concept nodes derived from the IS-A relations and corpus statistics. Feature based measure assumes that each concept is described by a set of terms indicating its properties or features. Then, the more common characteristics and the less non-common characteristics two concepts have, the more similar they are.</p><p>In this paper, we use a path-base measure, Li's measure <ref type="bibr" coords="2,371.06,570.17,10.64,9.02" target="#b5">[8]</ref>, which combines the shortest path and the depth of ontology information in a non-linear function:</p><formula xml:id="formula_0" coords="2,251.52,599.22,215.20,10.02">, (<label>1</label></formula><formula xml:id="formula_1" coords="2,466.72,600.18,3.89,9.02">)</formula><p>where L stands for the shortest path between two concepts, α and β are parameters scaling the contribution of shortest path length and depth respectively. In our experiment, we set α and β to 0.2 and 0.6 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Asymmetrical Semantic Similarity</head><p>Contrary to document clustering and classification, document retrieval is an asymmetric problem. For example, for a query with term Brain Diseases, the document containing term Alzheimer Disease has a high probability of being relevant. But, for a query with term Alzheimer Disease, the document containing term Brain Diseases would not necessarily be relevant. Based on this observation, we propose asymmetrical semantic similarity, with which the similarity of the former pair in the example is greater than that of the later one. The asymmetric measure is given as</p><formula xml:id="formula_2" coords="3,176.34,258.66,294.28,22.86">, , , , , ,<label>(2)</label></formula><p>where , are two concepts from a query and a document respectively. , can be any semantic similarity measures, such as edge-based, information-based measures etc.. ∈ 0,1 is a punishment factor to reduce the similarity value if is neither an ancestor of, nor equal to . When is set to 0, only the document concept, which is a child of, or equal to a query concept, will contribute to the relevance score of that document.</p><p>If we do not distinguish the document concepts, which are children of, or equal to a query concept, we can get following similarity measure, ,</p><p>when setting to 0, this formula can simulate query expansion which expand query with all descendants of the query concepts.</p><p>The above measures can be used to compare two concept nodes (tree numbers). However, each MeSH descriptor corresponds to one or several nodes in the MeSH trees. When two descriptors are compared, there exit many similarities between the two sets of concept nodes. Therefore, these similarities should be aggregated to get the similarity between descriptors. An easy solution is to choose the maximum similarity among these similarities</p><formula xml:id="formula_4" coords="3,219.66,523.20,250.96,11.39">, ∈ , ∈ , ′<label>(4)</label></formula><p>where , are descriptors from a query and a document respectively. and are the sets of corresponding tree numbers of and , and is the asymmetrical semantic similarity between the two concept nodes. Following Azuaje's work <ref type="bibr" coords="3,147.82,578.16,10.61,9.02" target="#b6">[9]</ref>, an alternative measure for two descriptors is defined as</p><formula xml:id="formula_5" coords="3,173.76,596.40,296.86,19.20">, ∑ ∈ , ∈ ∑ ∈ , ∈ | | | |<label>(5)</label></formula><p>where | • | is the cardinality of a set. Our previous study indicates this measure can achieve better performance, and will be used in following experiments. Both measures have asymmetric property due to the use of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Semantic Similarity between Query and Document</head><p>In semantic-based retrieval, a query is defined as a set of descriptors, , and a document is given as ′ . The similarity between a query and a document, and also the retrieval score can be the average of all the inter-descriptor similarities:</p><formula xml:id="formula_6" coords="4,227.46,212.88,243.16,18.72">, , ∑ , ∈ , ∈ | | | |<label>(6)</label></formula><p>This measure tends to give small results. Alternatively, we can build measure based on the best conceptual matches between the two groups of concepts. Following Azuaje's measure <ref type="bibr" coords="4,198.52,266.16,10.64,9.02" target="#b6">[9]</ref>, the similarity is defined as</p><formula xml:id="formula_7" coords="4,178.20,284.88,292.42,18.72">, , ∑ ∈ , ∈ ∑ ∈ , ∈ | | | |<label>(7)</label></formula><p>Considering the application in retrieval, the relevance score can be further simplied, by ignoring normalization and the comparison from document side, to</p><formula xml:id="formula_8" coords="4,242.94,342.78,227.68,11.81">, ∑ max ∈ S , ′ ∈<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Combination of Semantic-based and Text-based Search</head><p>To combine semantic-based retrieval and text-based retrieval, the score of each ranking should be normalized. Given a ranking, the normalized retrieval score of document is given by</p><formula xml:id="formula_9" coords="4,246.23,437.64,224.38,13.56">′ , ,<label>(9)</label></formula><p>where max and min are the maximum and minimum scores in this ranking. Then the normalized scores of text-based ranking and semantic-based ranking are combined to get the score as</p><formula xml:id="formula_10" coords="4,200.22,513.18,270.40,10.02">, , 1 ′ ,<label>(10)</label></formula><p>where is between 0 and 1, and determined by experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modality Classification with Multiple Kernel Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multiple Kernel Learning</head><p>A normal SVM classifier is designed for two-class problem, and can treat with only a single kernel. Given n training samples</p><formula xml:id="formula_11" coords="4,316.56,630.26,38.97,12.02">n i i i y 1 )} , {(  x</formula><p>, where</p><formula xml:id="formula_12" coords="4,124.74,629.75,345.78,24.56">  i x is the input vector and label   1 , 1    i y .</formula><p>Support vector machines originate from linear classifiers and maximize the margin between samples of both classes. Introducing a feature mapping  from the input space  to a reproducing kernel Hilbert space (RKHS)  , linear classifiers in  of the form</p><formula xml:id="formula_13" coords="5,251.94,177.35,214.50,11.84">b f    ) ( ) ( x w x  (<label>11</label></formula><formula xml:id="formula_14" coords="5,466.44,180.18,4.18,9.02">)</formula><p>which provides a rich set of flexible classifiers in  . The parameters ( w , b) are determined by solving an equivalent dual optimization. The dual optimization depends only on inner products (similarities) of inputs which can be alternatively computed by means of kernel functions k, given by</p><formula xml:id="formula_15" coords="5,239.70,249.29,226.74,16.88">    ) ' ( ), ( ) ' , ( x x x x   k . (<label>12</label></formula><formula xml:id="formula_16" coords="5,466.44,252.18,4.18,9.02">)</formula><p>And the final decision function can be written as</p><formula xml:id="formula_17" coords="5,242.16,282.67,224.28,24.55">    n i i i b k f 1 ) , ( ) ( x x x  . (<label>13</label></formula><formula xml:id="formula_18" coords="5,466.44,288.18,4.18,9.02">)</formula><p>The multiple kernel learning framework extends the regular SVM formulation by an adaptively-weighted combined kernel which fuses different kinds of features. The combined kernel is as follows: <ref type="bibr" coords="5,453.90,348.18,16.72,9.02" target="#b11">(14)</ref> where j  is weight to combine M sub-kernels</p><formula xml:id="formula_19" coords="5,184.92,342.53,197.27,20.90">       M j j j M j j j with k k 1 1 1 , 0 ) ' , ( ) ' , (    x x x x</formula><formula xml:id="formula_20" coords="5,318.96,364.72,29.04,11.56">) ' , ( x x j k</formula><p>. MKL can estimate optimal weights from training data. Sonnenburg et al. <ref type="bibr" coords="5,313.25,378.18,16.69,9.02" target="#b7">[10]</ref> proposed an efficient algorithm of MKL to estimate optimal weights and SVM parameters simultaneously by iterating training steps of a normal SVM. This implementation is available as the SHOGUN machine learning toolbox. For medical modality classification with image features, firstly, one sub-kernel for each image features are prepared, then the weights are estimated by the MKL method, finally, the optimal combined kernel is obtained. In the experiment, we used the MKL library included in the SHOGUN toolbox as the implementation of MKL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual Features for Modality Classification</head><p>In our study, we tested five image features, which are described as following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gray Value Histogram (GH):</head><p>The gray value histogram of an image represents the distribution of the pixels in the image over the gray-level scale. 32 bins are used in our study.</p><p>Edge Histogram Descriptor (EHD): The edge histogram descriptor <ref type="bibr" coords="5,453.98,560.16,16.70,9.02" target="#b8">[11]</ref> represents the spatial distribution of five types of edges, namely vertical, horizontal, 45-degree diagonal, 135-degree diagonal, and non-edge types.</p><p>Tamura Texture Feature <ref type="bibr" coords="5,251.22,596.16,35.99,9.02">(Tamura)</ref>: Based on the research of textural features corresponding to human visual perception, Tamura et al. <ref type="bibr" coords="5,371.17,608.16,15.11,9.02" target="#b9">[12]</ref> proposed six basic textural features, namely, coarseness, contrast, directionality, line likeness, regularity, and roughness. The coarseness, contrast and directionality features are used in this study.</p><p>Gabor Texture Feature (Gabor): It has been proposed that Gobor filters can be used to model the responses of the human visual system, and Gabor filter based approaches are popular for texture feature extraction. We use an implementation proposed by Manjunath et al <ref type="bibr" coords="6,245.72,150.18,15.33,9.02" target="#b10">[13]</ref>. The feature is built by filtering the image with a bank of orientation and scale sensitive filters and computing statistic measures of the output in the frequency domain.</p><p>SIFT: SIFTs <ref type="bibr" coords="6,192.13,186.18,16.68,9.02" target="#b11">[14]</ref> are local features and designed to describe an area of an image so to be robust to noise, illumination, scale, translation and rotation changes. For medical image classification, the SIFT rotation-invariance is not relevant, as the various structures in the radiographs are likely to appear always with the same orientation. Moreover, the scale is not likely to change too much between images of the same class. So, we ignore the scale-and rotation-invariance in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>Our previous study on OHSUMED data indicated that the asymmetric measure (equation 2) with the punishment factor set to 0.5 gets the best results, and it was used in our submitted runs. Since we hadn't study our method on previous ImageCLEF data when submitting the runs, we set the other parameters by guess. For ad-hoc retrieval, we constructed MeSH query representation with the top 5 descriptors returned by MeSHUp, and MeSH document with the top 10 descriptors, and set the combining parameter to 0.6. For case-based retrieval, if the article had MeSH terms assigned to it, we used them as the MeSH document. Otherwise, we constructed both MeSH query and document with the top 10 returned descriptors, and set the combining parameter to 0.8. These guessed setting resulted in unpromising performances in this campaign. When preparing this report, we trained our method on ImageCLEF 2010 ad-hoc retrieval data <ref type="bibr" coords="6,296.71,434.16,10.61,9.02" target="#b1">[2]</ref>, and the best performance was achieved by the asymmetric measure (equation 2) while using the top 10 descriptors for both query and document and setting to 0.15. We then tested our method with the best settings on both ad-hoc and case-based retrieval. All our methods are implemented on Lemur toolkit <ref type="bibr" coords="6,182.56,482.16,15.34,9.02">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Ad-hoc Retrieval</head><p>For ad-hoc image retrieval, we test two document representations 'c' and 'tc', which respectively uses only the caption of each image, and it plus the title of the article. When combining text-based retrieval with MeSH-based retrieval, the run name is also suffixed with 'm'. We also considered use modality classification information to enhance retrieval, and such runs have the name suffixed of 'mc'. All six submitted runs are prefixed with 'UESTC'. Besides the submitted runs, we also report two runs with the parameters trained on ImageCLEF 2010 ad-hoc retrieval data. One is with the asymmetric similarity measure (asym), and the other is with symmetric measure (symm). The text-based retrievals in all runs are based on TF-IDF model. The results of all runs are listed in the Table <ref type="table" coords="6,375.31,640.13,3.75,9.02" target="#tab_0">1</ref>. It indicates that our methods with trained parameters can achieve promising results, and the one with asymmetric measure achieves the best performance, which can rank sixth among all textual runs of this year. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Case-Based Retrieval</head><p>For case-based retrieval, the full text of an article is used for the text-based document representation, and denoted by 'f'. Similar to ad-hoc retrieval, we also report two runs with the trained parameters. And the text-based retrievals in all runs are also based on TF-IDF model. All results are listed in the Table <ref type="table" coords="7,397.64,677.28,3.76,9.02" target="#tab_1">2</ref>. It indicates that our methods with trained parameters can achieve promising results, and the one with asymmetric measure achieves the best, which can rank 3rd among all case-based runs of this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Modality Classification</head><p>Table <ref type="table" coords="8,153.40,224.16,3.74,9.02" target="#tab_2">3</ref>. describes the features used for different runs, and Tables 4. lists all accuracies of different runs. It indicates combining SIFT, Gabor and EHD features achieves the best accuracy among our submitted runs, which ranks equal 3rd among all visual methods of this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper describes our contribution to the ImageCLEF 2012 medical retrieval task. We combine semantic-based retrieval with text-based retrieval for medical retrieval. For semantic-based retrieval, asymmetric similarity measures are also proposed to compare query concepts and document concepts. Our submitted runs for ad-hoc and case-based retrieval are based on guessed parameters and perform unpromisingly. But our new runs with the trained parameters perform well. This validates our methods.</p><p>For modality classification, we use MKL to combine different visual features and achieve good results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,144.36,149.40,291.51,127.28"><head>Table 1 .</head><label>1</label><figDesc>Retrieval performance of ad-hoc retrieval runs</figDesc><table coords="7,144.36,167.64,291.51,109.04"><row><cell>Runs</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell></row><row><cell>ad-tcm-asym</cell><cell>0.1939</cell><cell>0.1761</cell><cell>0.3182</cell></row><row><cell>ad-tcm-symm</cell><cell>0.1817</cell><cell>0.1628</cell><cell>0.3125</cell></row><row><cell>UESTC-ad-tc</cell><cell>0.1769</cell><cell>0.1584</cell><cell>0.3</cell></row><row><cell>UESTC-ad-c</cell><cell>0.1443</cell><cell>0.1446</cell><cell>0.2409</cell></row><row><cell>UESTC-ad-tcm</cell><cell>0.1434</cell><cell>0.1397</cell><cell>0.2182</cell></row><row><cell>UESTC-ad-cm</cell><cell>0.106</cell><cell>0.1154</cell><cell>0.2091</cell></row><row><cell>UESTC-ad-tcm-mc</cell><cell>0.101</cell><cell>0.1223</cell><cell>0.2</cell></row><row><cell>UESTC-ad-cm-mc</cell><cell>0.0653</cell><cell>0.0846</cell><cell>0.1727</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,146.10,291.36,289.71,80.72"><head>Table 2 .</head><label>2</label><figDesc>Retrieval performance of case-based retrieval runs</figDesc><table coords="7,146.10,309.66,289.71,62.42"><row><cell>Runs</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell></row><row><cell>case-fm-asym</cell><cell>0.1437</cell><cell>0.1228</cell><cell>0.1411</cell></row><row><cell>case-fm-symm</cell><cell>0.1368</cell><cell>0.1164</cell><cell>0.1356</cell></row><row><cell>UESTC_case_f</cell><cell>0.1288</cell><cell>0.1092</cell><cell>0.1231</cell></row><row><cell>UESTC-case-fm</cell><cell>0.1269</cell><cell>0.1117</cell><cell>0.1231</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,165.48,388.08,262.84,93.92"><head>Table 3 .</head><label>3</label><figDesc>Features used for different runs</figDesc><table coords="7,165.48,406.38,262.84,75.62"><row><cell>Runs</cell><cell>Features</cell></row><row><cell>UESTC-SIFT.txt</cell><cell>SIFT</cell></row><row><cell>UESTC-MKL2.txt</cell><cell>SIFT+Gabor</cell></row><row><cell>UESTC-MKL3.txt</cell><cell>SIFT+Gabor+EHD</cell></row><row><cell>UESTC-MKL5.txt</cell><cell>SIFT+Gabor+EHD+GH</cell></row><row><cell>UESTC-MKL6.txt</cell><cell>SIFT+Gabor+EHD+GH+Tumura</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,192.96,497.10,207.34,90.62"><head>Table 4 .</head><label>4</label><figDesc>Accuracies of modality classification runs</figDesc><table coords="7,192.96,515.34,194.43,72.38"><row><cell>Runs</cell><cell>Accuracy (%)</cell></row><row><cell>UESTC-MKL3.txt</cell><cell>57.9</cell></row><row><cell>UESTC-MKL2.txt</cell><cell>56.7</cell></row><row><cell>UESTC-MKL5.txt</cell><cell>56.0</cell></row><row><cell>UESTC-MKL6.txt</cell><cell>56.0</cell></row><row><cell>UESTC-SIFT.txt</cell><cell>52.8</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This research is partly supported by the <rs type="funder">National Science Foundation of China</rs> under grants <rs type="grantNumber">60873185</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Usmdh8k">
					<idno type="grant-number">60873185</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,128.12,492.09,342.38,8.10;8,138.96,503.07,331.56,8.10;8,138.96,514.05,287.33,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,283.86,503.07,186.66,8.10;8,138.96,514.05,114.14,8.10">Overview of the ImageCLEF 2012 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Garcia Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sameer</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,258.76,514.05,94.46,8.10">CLEF 2012 working notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.11,525.09,342.53,8.10;8,138.96,536.07,331.67,8.10;8,138.96,547.05,166.60,8.10;8,124.74,557.43,210.35,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,204.63,525.09,266.02,8.10;8,138.96,536.07,93.17,8.10">Improving Context-Based Medical Image Retrieval by Incorporating Semantic-Based Retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://www.nlm.nih.gov/mesh/meshhome.html" />
	</analytic>
	<monogr>
		<title level="m" coord="8,249.08,536.07,221.55,8.10;8,138.96,547.05,96.30,8.10">International Conference on Internet Multimedia Computing and Service, ICIMCS 2012</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>to appear 3</note>
</biblStruct>

<biblStruct coords="8,128.12,583.41,342.47,8.10;8,138.96,594.39,331.66,8.10;8,138.96,605.43,84.52,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,431.11,583.41,39.49,8.10;8,138.96,594.39,243.89,8.10">MeSH Up: effective MeSH text classification for improved document retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong</forename><forename type="middle">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,388.76,594.39,56.21,8.10">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1412" to="1418" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,616.41,342.52,8.10;8,138.96,627.39,331.52,8.10;8,138.96,638.43,46.58,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,225.14,616.41,218.40,8.10">Medical Image Classification with Multiple Kernel Learning</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,459.74,616.41,10.90,8.10;8,138.96,627.39,292.70,8.10">the 2nd International Conference on Internet Multimedia Computing and Service</title>
		<meeting><address><addrLine>ICIMCS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.11,649.41,342.37,8.10;8,138.96,660.39,279.75,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,270.79,649.41,199.69,8.10;8,138.96,660.39,151.72,8.10">A comparative study of ontology based term similarity measures on PubMed document clustering</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,306.10,660.39,45.24,8.10">DASFAA&apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="115" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.10,150.09,342.37,8.10;9,138.96,161.07,331.66,8.10;9,138.96,172.05,60.72,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,287.60,150.09,182.87,8.10;9,138.96,161.07,189.16,8.10">An Approach for Measuring Semantic Similarity between Words Using Multiple Information Sources</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">A</forename><surname>Bandar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mclean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,334.55,161.07,111.39,8.10">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.12,183.09,342.49,8.10;9,138.96,194.07,331.60,8.10;9,138.96,205.05,45.03,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,321.64,183.09,148.97,8.10;9,138.96,194.07,144.52,8.10">Ontology-driven similarity approaches to supporting gene functional assessment</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Azuaje</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,304.30,194.07,166.26,8.10">ISMB&apos;2005 SIG meeting on Bio-ontologies</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="9" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.24,216.09,338.27,8.10;9,138.96,227.07,271.46,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,367.32,216.09,103.19,8.10;9,138.96,227.07,28.16,8.10">Large scale multiple kernel learning</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,172.91,227.07,138.32,8.10">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1531" to="1565" />
			<date type="published" when="2006-07">2006. July 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.23,238.05,338.32,8.10;9,138.96,249.09,118.54,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,278.47,238.05,188.60,8.10">Efficient use of MPEG-7 edge histogram descriptor</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Park S.-J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,138.96,249.09,47.47,8.10">ETRI Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="23" to="30" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.23,260.07,338.33,8.10;9,138.96,271.05,318.11,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,318.25,260.07,152.31,8.10;9,138.96,271.05,36.58,8.10">Texture features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,181.49,271.05,172.07,8.10">IEEE Trans. On Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="473" />
			<date type="published" when="1978-06">1978. June, 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.24,282.09,338.30,8.10;9,138.96,293.07,292.48,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,260.98,282.09,183.56,8.10">Textures for browsing and retrieval of image data</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,451.05,282.09,19.50,8.10;9,138.96,293.07,185.76,8.10">IEEE Trans on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996-08">1996. Aug. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,132.25,304.05,338.40,8.10;9,138.96,315.09,259.77,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,207.03,304.05,193.30,8.10">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,416.55,304.05,54.11,8.10;9,138.96,315.09,201.26,8.10">Proceedings of International Conference on Computer Vision, ICCV&apos;99</title>
		<meeting>International Conference on Computer Vision, ICCV&apos;99</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
