<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.59,117.75,310.19,12.62;1,180.19,135.68,254.96,12.62">Participation of LSIS/DYNI to ImageCLEF 2012 plant images classification task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,182.77,173.35,66.41,8.74"><forename type="first">Sébastien</forename><surname>Paris</surname></persName>
							<email>sebastien.paris@lsis.org</email>
							<affiliation key="aff0">
								<orgName type="department">LSIS/DYNI</orgName>
								<orgName type="institution">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.64,173.35,69.52,8.74"><forename type="first">Xanadu</forename><surname>Halkias</surname></persName>
							<email>halkias@univ-tln.fr</email>
							<affiliation key="aff1">
								<orgName type="department">LSIS/DYNI</orgName>
								<orgName type="institution">University of South Toulon-Var</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.10,173.35,56.55,8.74"><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
							<email>glotin@univ-tln.fr</email>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Institut National de France</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.59,117.75,310.19,12.62;1,180.19,135.68,254.96,12.62">Participation of LSIS/DYNI to ImageCLEF 2012 plant images classification task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">37AF642409B8190E72CC6339FAEA141F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LSIS</term>
					<term>DYNI</term>
					<term>ImageCLEF</term>
					<term>plant</term>
					<term>leaves</term>
					<term>images</term>
					<term>collection</term>
					<term>identification</term>
					<term>classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of the LSIS/DYNI team for the ImageCLEF 2012 plant identification challenge. Image-CLEF's plant identification task provides a testbed for the system-oriented evaluation of tree species identification based on leaf images. The goal is to investigate image retrieval approaches in the context of crowd sourced images of leaves collected in a collaborative manner. The LSIS/DYNI team submitted three runs to this task and obtained the best evaluation scores (S = 0.32) for the "photograph" image category with an automatic method. Our approach is based on a modern computer vision framework involving local, highly discriminative visual descriptors, sophisticated visual-patches encoder and large-scale supervised classification. The paper presents the three procedures employed, and provides an analysis of the obtained evaluation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the contribution of the LSIS/DYNI group for the plant identification task that was organized within ImageCLEF 2012 4 for the systemoriented evaluation of visual based plant identification. Similar to the Image-CLEF 2011 challenge, this second year pilot task was also precisely focused on tree species identification based on leaf images. This year, the challenge was organized as a classification task over 126 tree species with visual content being the main available information. Three types of image content were considered: leaf "scans", leaf photographs with a white uniform background (referred to as "scan-like" pictures) and unconstrained leaf "photographs" acquired on trees with natural background (see Fig. <ref type="figure" coords="1,291.16,616.37,3.87,8.74">1</ref>). The LSIS/DYNI team submitted three runs, all of them based on local feature extraction and large-scale supervised classification. We obtained the best score for the "photographs" category with an automatic method (S = 0.32).</p><p>Fig. <ref type="figure" coords="2,174.41,348.25,4.13,7.89">1</ref>. From left to right: "scans", "scan-like" and "photographs" category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task description</head><p>The task has been evaluated as a plant species retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training and Test data</head><p>A part of Pl@ntLeaves II dataset was provided as training data whereas the remaining part was used later as test data. The training subset was built by including the training AND test subsets of last year's Pl@ntLeaves I dataset, and by randomly selecting 2/3 of the individual plants for each NEW species (several pictures might belong to the same individual plant but cannot be split across training and test data).</p><p>-The training data is comprised of 8422 images (4870 "scans", 1819 "scanlike" photos, 1733 natural photos) with full xml files associated to them (see previous section for few examples). A ground-truth file listing all images of each species was provided complementary. -The test data is comprised of 3150 images (1760 "scans", 907 "scan-like" photos, 483 natural photos) with purged xml files (i.e. without the taxon information that has to be predicted).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task objective and evaluation metric</head><p>The goal of the task was to retrieve the correct species among the top k species of a ranked list of retrieved species for each test image. Each participant was allowed to submit up to 4 runs built from different methods. As many species as possible can be associated to each test image, sorted by decreasing confidence score. However, only the most confident species were used in the primary evaluation metric described below. Providing an extended ranked list of species was encouraged in order to derive complementary statistics (e.g. recognition rate at other taxonomic levels, suggestion rate on top k species, etc.). The primary metric used to evaluate the submitted runs was a normalized classification rate evaluated on the 1st species returned for each test image. Each test image is attributed with a score of 1 if the 1st returned species is correct and 0 if it is wrong. An average normalized score is then computed on all test images. A simple mean on all test images would indeed introduce some bias with regard to a real world identification system. Indeed, we recollect that the Pl@ntLeaves II dataset was built in a collaborative manner; So that few contributors might have provided much more pictures than many other contributors who provided few. Since we want to evaluate the ability of a system to provide correct answers for all users, we would rather measure the mean of the average classification rate per author. Furthermore, some authors sometimes provided many pictures of the same individual plant (to enrich training data with less efforts). Since we want to evaluate the ability of a system to provide the correct answer based on a single plant observation, we also decided to average the classification rate on each individual plant. Finally, our primary metric was defined as the following average classification score S:</p><formula xml:id="formula_0" coords="3,233.24,447.87,247.35,31.28">S = 1 U U u=1 1 P u Pu p=1 1 N u,p Nu,p n=1 s u,p,n ,<label>(1)</label></formula><p>where -U : number of users (who have at least one image in the test data) -P u : number of individual plants observed by the u th user -N u, p : number of pictures taken from the p th plant observed by the u-th user s u,p,n : classification score (1 or 0) for the n th picture taken from the p th plant observed by the u th h user Finally, to isolate and evaluate the impact of the image acquisition type ("scans", "scan-like", "photograph"), a normalized classification score S was computed for each type separately. Participants were therefore allowed to train distinct classifiers, use different training subsets or use distinct methods for each data type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of used methods</head><p>For all submitted runs, whatever the particular image type, we followed the same pipeline: i) feature extraction coupled with spatial pyramid (SP) for local analysis and a linear large-scale supervised classification. For our first participation, we didn't performe any (supervised) segmentation leading to the extraction of more elaborate and specific descriptors for leaf classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Common procedures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial pyramid local analysis</head><p>We define our SP matrix Λ with L levels such as</p><formula xml:id="formula_1" coords="4,134.77,248.28,345.83,20.72">Λ [r y , r x , d y , d x , λ]. Λ is a matrix of size (L × 5</formula><p>). For a level l ∈ {0, . . . , L -1}, the image I, with size (n y × n x ), is divided into potentially overlapping sub-windows R l,v of size (h l × w l ). All these windows are sharing the same associated weight λ l . In our implementation, h l n y .r y,l and w l n x .r x,l where r y,l , r x,l and λ l are the l th element of vectors r y , r x and λ respectively. Sub-window shifts in x -y axis are defined by integers δ y,l n y .d y,l and δ x,l n x .d x,l where d y,l and d x,l are elements of d y and d x respectively. Overlapping can be performed if d y,l ≤ r y,l and/or d x,l ≤ r x,l . The total number of sub-windows is equal to</p><formula xml:id="formula_2" coords="4,199.05,364.44,281.54,30.55">V = L-1 l=0 V l = L-1 l=0 (1 -r y,l ) d y,l + 1 . (1 -r x,l ) d x,l + 1 .<label>(2)</label></formula><p>Fig. <ref type="figure" coords="4,156.06,411.10,4.98,8.74" target="#fig_0">2</ref> shows an example of SP with our particular choice Λ = 1 1 1 1 1</p><formula xml:id="formula_3" coords="4,430.78,415.12,40.39,13.47">1 2 1 4 1 4 1 8 1</formula><p>.</p><p>For this particular Λ matrix, we divided twice more the vertical axis than the horizontal one according to the aspect ratio distribution of images in the dataset.</p><p>Linear support vector machines for large-scale classification Let's assume available a training data set {x i , y i } N i=1 , where x i ∈ R d is a descriptor extracted from image I i and y i ∈ {1, . . . , M }, where M = 126 is the number of classes and N = 8422 is the number of training samples. As in <ref type="bibr" coords="4,419.74,512.46,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="4,436.90,512.46,7.01,8.74" target="#b0">1]</ref>, we will use a simple large-scale linear SVM such as LIBLINEAR <ref type="bibr" coords="4,393.32,523.41,10.52,8.74" target="#b5">[6]</ref> with the 1-vs-all multi-class strategy. The associated binary unconstrained convex optimization problem to solve is:</p><formula xml:id="formula_4" coords="4,213.42,562.81,263.25,26.84">min w 1 2 w T w + C N i=1 max 1 -yiw T xi, 0 2 , (<label>3</label></formula><formula xml:id="formula_5" coords="4,476.67,571.98,3.93,7.86">)</formula><p>where the parameter C controls the generalization error and is tuned on a specific validation set. LIBLINEAR converges to a solution linearly in O(dN ) compared to O(dN 2 sv ). Moreover, in order to obtain an estimate of p(y = l|x), we performed an SVM regression given the output of the previous classification stage for each binary classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multiscale Color Local Phase Quantization (MSCLPQ) → LSIS DYNI run 1</head><p>Following <ref type="bibr" coords="5,181.32,381.37,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="5,193.50,381.37,7.01,8.74" target="#b4">5]</ref>, we extend the basic decorrelated Local Phase Quantization (LPQ) descriptor for a multi-scale and color channel analysis over a spatial pyramid.</p><p>In LPQ, Short Fourier Transforms (SFT) are computed over M ×M windows centered on z at four frequencies</p><formula xml:id="formula_6" coords="5,285.94,427.53,168.26,12.62">u 1 = [a, 0] T , u 2 = [0, a] T , u 3 = [a, a]</formula><p>T and</p><formula xml:id="formula_7" coords="5,134.77,440.79,345.83,45.65">u 4 = [a, -a] T with a = 1 M such that F (u, z) = y∈Nz f (z -y)e -j2πu T y ,<label>(4)</label></formula><p>where z ∈ R ⊂ I. For each pixel, we compute the LPQ code as</p><formula xml:id="formula_8" coords="5,172.18,495.84,308.41,50.03">5 LP Q(z) = 3 i=0 2 2i 1 {Re(F (u,z))≥0} + 3 i=0 2 2i+1 1 {Im(F (u,z))≥0} ,<label>(5)</label></formula><p>where LP Q(z) ∈ {0, . . . , 255}. Local histograms of LPQ codes are retrieved by counting occurrences of each individual LPQ code j such as:</p><formula xml:id="formula_9" coords="5,203.97,587.82,276.62,22.16">x LP Q (j, R) = z∈R 1 {LP Q(z)=j} , j = 0, . . . , 255.<label>(6)</label></formula><p>The local histogram vector is defined by</p><formula xml:id="formula_10" coords="5,209.32,638.52,271.27,9.68">x LP Q (R) [x LP Q (0, R), . . . , x LP Q (255, R)] ,<label>(7)</label></formula><p>where x LP Q (R) is furthermore 2 normalized. The full vector x is obtained by concatenating previous normalized histograms for 4 different scales M ∈ {3, 5, 7, 9}, Λ = 1 1 1 1 1</p><formula xml:id="formula_11" coords="6,214.23,153.37,40.58,13.47">1 2 1 4 1 4 1 8<label>1 8</label></formula><p>(V = 1 + 21) and the 3 (R, G, B) color channels.</p><p>The total dimension of this vector is equal to d = 256.(1 + 21).4.3 = 67584. Finally, we normalize each element of x i such that x i,l ∈ [-1, 1] , l = 1, . . . , d, i = 1, . . . , N followed by 2 normalization on x i . The a posteriori probabilities associated with the MSCLPQ approach are denoted p 1 (y = l|x). T with its 8 neighboring blocks <ref type="bibr" coords="6,450.35,337.27,10.52,8.74" target="#b7">[8]</ref> and also adds a ninth bit encoding a term homogeneous to the differential excitation. This operator can be considered as a non-parametric local texture encoder for scale s. In order to capture information at different scales, the range analysis s ∈ S, is typically set at S = [1, 2, 3, 4] for this task, where S = Card(S). This micro-codes are defined as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Late fusion of MSCLPQ, MSCILBP and MSILBP+ScSPM</head><formula xml:id="formula_12" coords="6,199.41,416.48,281.19,31.81">ILBP (z c , s) = i=7 i=0 2 i 1 {Ai≥Ac} + 2 8 1 7 i=0 Ai≥8Ac ,<label>(8)</label></formula><p>where</p><formula xml:id="formula_13" coords="6,163.57,460.74,138.83,9.96">∀z c ∈ R ⊂ I, ILBP (z c ) ∈ N 2 9 .</formula><p>The different areas {A i } and A c in eq.( <ref type="formula" coords="6,322.79,473.13,4.20,8.74" target="#formula_12">8</ref>) can be computed efficiently using the image integral technique <ref type="bibr" coords="6,261.82,485.09,14.61,8.74" target="#b11">[12]</ref>. Let's define II the image integral of I by: II(y, x)</p><formula xml:id="formula_14" coords="6,293.68,508.17,186.91,30.94">y &lt;y y =0 x &lt;x x =0 I(y , x ).<label>(9)</label></formula><p>Any square area A(y, x, s) ∈ R (see right Fig. <ref type="figure" coords="6,337.82,552.56,4.43,8.74" target="#fig_1">3</ref>) with upper-left corner located in (y, x) and side length s is the addition of only 4 values:</p><formula xml:id="formula_15" coords="6,145.43,587.22,330.73,8.77">A(y, x, s) = II(y + s, x + s) + II(y, x) -(II(y, x + s) + II(y + s, x)). (<label>10</label></formula><formula xml:id="formula_16" coords="6,476.16,587.25,4.43,8.74">)</formula><p>As for MSCLPQ, efficient features are obtained by counting occurrences of the j th visual ILBP at scale s in a ROI R ⊆ I:</p><p>x ILBP (R, j, s) = zc∈R 1 {ILBP (zc,s)=j} , where j = 0, . . . , b -1 is the j th bin of the histogram and b = 512. Full histogram of ILBP, denoted z ILBP is computed by:</p><formula xml:id="formula_17" coords="7,186.19,349.87,294.40,9.68">x ILBP (R, s) [x ILBP (R, 0, s), . . . , x ILBP (R, b -1, s)] .<label>(11)</label></formula><p>Finally, the full vector x is obtained by concatenating previous normalized histograms for 4 different scales s ∈ {1, 2, 3, 4}, Λ = 1 1 1 1 1</p><formula xml:id="formula_18" coords="7,368.43,390.30,112.16,17.49">1 2 1 4 1 4 1 8 1 8 (V = 1 + 21)</formula><p>and the 3 (R, G, B) color channels. The total dimension of this vector is equal to d = 512.(1 + 21).4.3 = 135168. We also normalize each element of x i such that x i,l ∈ [-1, 1] , l = 1, . . . , d, i = 1, . . . , N followed by 2 normalization on x i . The a posteriori probabilities associated with MSCILBP approach are denoted as p 2 (y = l|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparse coding of dense MSILBP patches</head><p>Following the same framework as in <ref type="bibr" coords="7,297.83,500.62,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="7,310.00,500.62,12.73,8.74" target="#b12">13,</ref><ref type="bibr" coords="7,324.39,500.62,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="7,333.80,500.62,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="7,343.21,500.62,11.62,8.74" target="#b9">10]</ref>, we will show here that the traditional Bag of Features (BoF) approach can be advantageously replaced by i) Sparse coding (Sc), ii) max-pooling technique. Specifically, F ILBP patches z ILBP (O k ) of size (m × m) centered on ROI's {O k } (possibly overlapping) are extracted (cf. eq. 7) for k = 0, . . . , F -1 and ∀s ∈ S (see Fig. <ref type="figure" coords="7,206.53,560.93,3.87,8.74" target="#fig_2">4</ref>). For a faster computation for each scale s, the integral image II is first computed from I.</p><p>For a complete dataset containing N images and ∀s ∈ S, we obtain a collection of P = T S patches Z {z i }, i = 1, . . . , P , where T = N F . We define, the subset of patches z i at scale s by Z(s) ⊆ Z with T elements. In order to obtain highly discriminative visual features, a common procedure consists of encoding each patch z i ∈ Z(s) at scale s through an unsupervised trained dictionary D [d 1 , . . . , d K ] ∈ R b×K , where K denotes the number of dictionary elements, and its corresponding weight vector c i ∈ R K . In the BoF framework, the vector  </p><formula xml:id="formula_19" coords="8,272.36,358.45,208.24,12.69">z i -Dc i 2 2 s.t. c i 0 = 1,<label>(12)</label></formula><p>where C [c 1 , . . . , c K ] and • 0 defines the pseudo zero-norm, where here only one element of c i is non-zero. In eq. ( <ref type="formula" coords="8,322.10,407.37,8.19,8.74" target="#formula_19">12</ref>), under these constraints, (D, C) can be optimized jointly by a Kmeans algorithm for example.</p><p>In the Sc approach, in order to i) reduce the quantization error and ii) to have a more accurate representation of the patches, each vector x i is now expressed as a linear combination of a few vectors of the dictionary D and not only by a single one. Imposing the exact number of non-zero elements in c i (sparsity level) involves a non-convex optimization <ref type="bibr" coords="8,293.44,480.12,9.96,8.74" target="#b8">[9]</ref>. In general, it is preferred to relax this constraint and to use instead an 1 penalty which also involves sparsity. The problem is then reformulated using the following equation:</p><formula xml:id="formula_20" coords="8,190.91,526.77,289.68,30.32">arg min D,C T i=1 z i -Dc i 2 2 + β c i 1 s.t. c i 1 = 1,<label>(13)</label></formula><p>where the sparsity in controlled by the parameter β. The last equation is not jointly convex in (D, C) and a common procedure consists of optimizing alternatively D given C by a block coordinate descent and then C given D by a LASSO procedure <ref type="bibr" coords="8,216.18,605.73,14.61,8.74" target="#b10">[11]</ref>. At the end of the process, for each scale s ∈ S, a trained dictionary D(s) is obtained.</p><p>For an image I and given a trained dictionary D(s) for a type of code at scale s, F sparse vectors {c k (s)} are computed by a LASSO algorithm. The final efficient descriptor x(s)</p><p>x 0 (s), . . . , x K-1 (s) ∈ R K is obtained by the following max-pooling procedure <ref type="bibr" coords="9,280.38,119.99,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="9,297.54,119.99,7.01,8.74" target="#b1">2]</ref>:</p><formula xml:id="formula_21" coords="9,214.52,139.39,266.07,20.07">x j (s) max k|O k ∈R (|c j k (s)|), j = 0, . . . , K -1,<label>(14)</label></formula><p>where each element of x(s) represents the max-response of the absolute value of sparse codes belonging to the ROI R. In order to improve accuracy, a spatial pyramidal matching procedure helps to perform a more robust local analysis.</p><p>The spatial pyramid Λ has V = L-1 l=0</p><p>V l ROIs {R l,v } with l = 0, . . . , L -1, v = 0, . . . , V l -1 (see Fig. <ref type="figure" coords="9,249.93,234.49,4.98,8.74" target="#fig_4">5</ref> for an example). The quantity z j l,v (s) for each ROI R l,v is computed by:</p><formula xml:id="formula_22" coords="9,207.32,267.14,268.85,20.07">x j l,v (s) max k|O k ∈R l,v (|c j k (s)|), j = 0, . . . , K -1. (<label>15</label></formula><formula xml:id="formula_23" coords="9,476.16,269.89,4.43,8.74">)</formula><p>We reinforce our model by an important normalization step that improves con- siderably accuracy and consists of the 2 normalization of all vectors {x l,v (s)}, v = 0, . . . , V l -1, s ∈ S, i.e. belonging to the same pyramidal layer l. This step is also very important and often hidden in the existing literature. The final descriptor x(Λ) will be defined by the weighted concatenation of all the x l,v (s) vectors, i.e. x(Λ) {λ l x l,v (s)}, l = 0, . . . , L-1, v = 0, . . . , V l -1 and ∀s ∈ S. The total size of the feature vector x(Λ) is d = K.V.S, where typically in our simulations, we fixed K = 2048, V = 22 and S = 4. A final 2 clamped normalization step is performed on the full vector x(Λ). In our experiment, we extracted F = 35 • 35 patches per scale and per image with m = 26. 2000 patches per class for each scale have been randomly selected to train dictionary (β = 0.2). The a posteriori probabilities associated with MSILBP+ScSPM approach are denoted p 3 (y = l|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Late fusion</head><p>To obtain a final decision, we simple performed an average of all p f (y = l|x) a posteriori probabilities, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(y</head><formula xml:id="formula_24" coords="10,257.46,211.58,223.14,30.55">= l|x) = 1 3 3 f =1 p f (y = l|x).<label>(16)</label></formula><p>3.4 Late fusion of MSCLPQ, MSCILBP, MSILBP+ScSPM and SIFT+ScSPM→ LSIS DYNI run 3</p><p>The three first stages are identical as in LSIS DYNI run 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparse coding of dense SIFT patches</head><p>As for MSILBP parches, we extracted F = 35 • 35 SIFT patches (m = 16) per image and for each of the 4 scales (σ = {0.5, 0.65, 0.8, 1.0}). 2000 patches per class for each scale have been randomly selected to train dictionary (β = 0.2, K = 2048). The a posteriori probabilities associated with SIFT+ScSPM approach are denoted p 4 (y = l|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Late fusion</head><p>We also performed an average of all p f (y = l|x) a posteriori probabilities</p><formula xml:id="formula_25" coords="10,240.56,431.63,240.03,30.55">p(y = l|x) = 1 4 4 f =1 p f (y = l|x).<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Fig. <ref type="figure" coords="10,155.84,501.70,4.98,8.74" target="#fig_5">6</ref> presents the summarized results for the "scans" category. Without any segmentation and/or specific pre-processing, we obtained a score S = 0.41 with LSIS DYNI run 3, i.e. the 6 th best score for all submitted runs (29 in total), relatively close to the top-4 (S = 0.43). Higher scores can probably be obtained with the use of color MBILBP+ScSPM and color SIFT+ScSPM features.</p><p>In Fig. <ref type="figure" coords="10,181.95,561.47,4.98,8.74" target="#fig_6">7</ref> we summarize the results for the "scan-like" category. We obtained a score S = 0.42 with LSIS DYNI run 3, i.e. the 7 th best score for all submitted runs (29 in total). In this case, with an unsupervised detector to "home-in" leafs more precisely, we could also improve results. Ideally, as for all runs above S = 0.42, a prior segmentation is known to help considerably results for "scans" and "scan-like" categories. Finally, Fig. <ref type="figure" coords="10,304.99,621.25,4.98,8.74" target="#fig_7">8</ref> provides the summarized results for the "photographs" category. We obtained a score S = 0.32 with LSIS DYNI run 3, i.e. the 1 th best score for automatic method and for all submitted runs (29 in total). Our 3 runs obtained the best top-3 of all submitted runs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>For our first participation to ImageCLEF plants identification 2012 challenge, we demonstrated that for "photographs" category, our framework offers best performances for automatic method. This category is considered the most challenging due to "real" in-situ conditions and shows that computer vision approaches for image catagorization/fine-grained visual categorization are well adapted for this challenge. Several improvements can be obtained, for example with some better encoding schemes (Fisher vectors) and/or pooling technics. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,287.06,345.83,7.89;5,134.77,298.02,345.82,8.37;5,134.77,309.01,183.64,7.86;5,136.20,116.83,170.08,155.91"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example of SPM Λ with L = 2 and V = 1 + 21. Upper-left corner of each window R l,v is indicated with a red cross. Left: R0,0 = I for l = 0 (first level). Right: {R1,v}, v = 0, . . . , 20 for l = 1 (second level).</figDesc><graphic coords="5,136.20,116.83,170.08,155.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,134.77,259.21,345.83,7.89;7,134.77,270.20,314.23,7.86;7,136.21,116.83,170.08,127.56"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Left: I and ILBP (yx, xc) overlaid. Right: corresponding image integral II and the central block Ac. Ac can be efficiently computed with the 4 corner points.</figDesc><graphic coords="7,136.21,116.83,170.08,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,134.77,259.22,345.83,8.37;8,134.77,270.20,345.82,7.86;8,134.77,281.16,125.61,8.35;8,309.07,116.84,170.08,127.56"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. ExampleLeft: ROI's {O k }, k = 0, . . . , F -1 of extracted patches used to compute each ILBP where F = 10 • 10. Right: associated normalized histograms {zILBP (O k )}, one per column.</figDesc><graphic coords="8,309.07,116.84,170.08,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,134.77,327.34,213.69,9.68;8,213.14,360.52,34.39,8.74;8,228.80,368.99,20.17,8.77;8,255.63,350.11,4.71,6.12;8,252.07,374.32,12.91,6.12"><head></head><label></label><figDesc>c i is assumed to have only one non-zero element: arg min D,C T i=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,134.77,473.05,345.82,7.89;9,134.77,484.01,345.83,8.37;9,134.77,494.96,345.82,8.37;9,134.77,505.92,345.83,8.37;9,134.77,516.91,176.61,7.86;9,136.20,331.16,170.08,127.56"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Example of SPM Λ with L = 2, F = 10 • 10 and V = 1 + 21. The F ROIs {O k }, k = 0, . . . , F -1 associated with each patch z k are represented by blue squares. Sparse codes c k are computed for each ROI O k . Upper-left corner of each max-pooling window R l,v taking {100, 10} c k is indicated with a green cross. Left: R0,0 = I for l = 0. Right: {R1,v}, v = 0, . . . , 20 for l = 1</figDesc><graphic coords="9,136.20,331.16,170.08,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="11,226.35,301.66,162.66,7.89;11,137.62,116.84,340.14,170.05"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Results for the "scans" category.</figDesc><graphic coords="11,137.62,116.84,340.14,170.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="11,219.72,516.64,175.93,7.89;11,137.62,331.81,340.14,170.05"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Results for the "scan-like" category.</figDesc><graphic coords="11,137.62,331.81,340.14,170.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="12,212.03,301.66,191.30,7.89;12,137.62,116.84,340.14,170.05"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Results for the "photographs" category.</figDesc><graphic coords="12,137.62,116.84,340.14,170.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,235.50,345.83,111.43"><head></head><label></label><figDesc>Multiscale Color Improved Local Binary Pattern (MSCILBP)Basically, the operator ILBP encodes the relationship between a central block of (s × s) pixels located in z c = [y x , x c ]</figDesc><table coords="6,134.77,235.50,339.26,54.66"><row><cell>→</cell></row><row><cell>LSIS DYNI run 2</cell></row><row><cell>Multiscale Color Local Phase Quantization</cell></row><row><cell>See sec. 3.2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,144.73,635.88,335.86,7.86;1,144.73,646.84,55.88,7.86;1,137.50,656.03,3.65,5.24;1,144.73,657.79,152.33,7.86"><p>Granded by COGNILEGO ANR 2010-CORD-013 and PEPS RUPTURE Scale Swarm Vision 4 http://www.imageclef.org/2012/plant</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,366.08,337.63,7.86;12,151.52,377.04,113.40,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,331.81,366.08,148.78,7.86;12,151.52,377.04,22.38,7.86">Learning mid-level features for recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,194.78,377.04,41.47,7.86">CVPR&apos; 10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,387.68,337.64,7.86;12,151.52,398.64,156.40,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,302.17,387.68,178.42,7.86;12,151.52,398.64,67.44,7.86">A theoretical analysis of feature pooling in vision algorithms</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,240.22,398.64,39.03,7.86">ICML&apos; 10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,409.28,337.64,7.86;12,151.52,420.24,275.43,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,378.21,409.28,102.38,7.86;12,151.52,420.24,196.73,7.86">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,369.99,420.24,28.28,7.86">BMVC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,430.88,337.64,7.86;12,151.52,441.84,146.78,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,258.27,430.88,222.32,7.86;12,151.52,441.84,56.98,7.86">Methods for local phase quantization in blur-insensitive image analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heikkilä</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ojansivu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,229.45,441.84,40.18,7.86">LNLA&apos; 09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,452.48,337.64,7.86;12,151.52,463.43,183.85,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,305.08,452.48,175.52,7.86;12,151.52,463.43,96.09,7.86">Improved blur insensitivity for decorrelated local phase quantization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Heikkilä</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ojansivu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,268.81,463.43,37.89,7.86">ICPR&apos; 10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,474.07,337.63,7.86;12,151.52,485.03,115.09,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,326.45,474.07,154.14,7.86;12,151.52,485.03,86.42,7.86">A dual coordinate descent method for large-scale linear svm</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Keerthi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,495.67,337.64,7.86;12,151.52,506.63,288.18,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,307.33,495.67,173.27,7.86;12,151.52,506.63,197.07,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,369.56,506.63,41.46,7.86">CVPR&apos; 06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,517.27,337.64,7.86;12,151.52,528.23,207.62,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="12,348.89,517.27,131.70,7.86;12,151.52,528.23,141.36,7.86">Learning multi-scale block local binary patterns for face recognition</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>ICB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,538.87,337.63,7.86;12,151.52,549.83,113.78,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,330.49,538.87,150.10,7.86;12,151.52,549.83,24.79,7.86">Online dictionary learning for sparse coding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,197.60,549.83,39.03,7.86">ICML &apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,560.47,337.97,7.86;12,151.52,571.43,329.07,7.86;12,151.52,582.39,66.55,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,295.36,560.47,185.23,7.86;12,151.52,571.43,309.74,7.86">Sparse coding for histograms of local binary patterns applied for image categorization: Toward a bag-of-scenes analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Halkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,582.39,37.88,7.86">ICPR&apos; 12</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,593.03,337.98,7.86;12,151.52,603.99,182.39,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,215.96,593.03,197.80,7.86">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,421.57,593.03,59.02,7.86;12,151.52,603.99,141.43,7.86">Journal of the Royal Statistical Society (Series B)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,614.63,337.97,7.86;12,151.52,625.59,90.95,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,233.19,614.63,122.51,7.86">Robust real-time face detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,361.86,614.63,118.72,7.86;12,151.52,625.59,49.99,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,636.23,337.98,7.86;12,151.52,647.18,238.57,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,322.83,636.23,157.77,7.86;12,151.52,647.18,147.73,7.86">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,319.96,647.18,41.46,7.86">CVPR&apos; 09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
