<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.66,115.96,272.04,12.62;1,241.98,133.89,131.40,12.62">ZhaoHFUT at ImageCLEF 2012 Plant Identification Task</title>
				<funder ref="#_cYpKhrs">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_HyfvFdP">
					<orgName type="full">Cognilego</orgName>
				</funder>
				<funder ref="#_7nP3pct">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_tBR4pzj">
					<orgName type="full">National 863 Program of China</orgName>
				</funder>
				<funder ref="#_C2xTvzK">
					<orgName type="full">China Post-doctoral Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,192.28,172.09,51.33,8.74"><forename type="first">Peng</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The College of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,254.17,172.09,71.40,8.74"><forename type="first">Zhong-Qiu</forename><surname>Zhao</surname></persName>
							<email>zhongqiuzhao@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">The College of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.50,172.09,56.28,8.74"><forename type="first">Herve</forename><surname>Glotin</surname></persName>
							<email>glotin@univ-tln.fr</email>
							<affiliation key="aff1">
								<orgName type="department">Systems and Information Sciences lab</orgName>
								<orgName type="institution">LSIS CNRS &amp; Univ. of Sud-Toulon</orgName>
								<address>
									<addrLine>Var -La Garde</addrLine>
									<postCode>83957</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Institut Iniversitaire de France</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.66,115.96,272.04,12.62;1,241.98,133.89,131.40,12.62">ZhaoHFUT at ImageCLEF 2012 Plant Identification Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DBBAB4D9A6A44D1D22AB046D79E8048D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plant identification</term>
					<term>feature extraction</term>
					<term>ScSPM</term>
					<term>flip SIFT descriptors</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the contribution of ZhaoHFUT group to the ImageCLEF 2012 Plant identification task. The task involves identifying various species of trees based on images of their leaves. In this task, we adopted the main structure of the ScSPM model and another extension of Scale Invariant Feature Transform (SIFT) descriptors, namely flip SIFT descriptors, to investigate the performance of them considering their good performance in object classification. Although our results are not quite promising as compared to other participant groups, they can still guide our work in this field for some conclusions reached.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There are about 400,000 species in the world, of which only 270,000 have been named and identified by botanists. Accurate knowledge of the identity, geographic distribution and uses of plants is essential for agriculture development and biodiversity. Although there are many researches in this field, the taxonomy of species is still a hard task even for professionals (such as farmers or wood exploiters) or for the botanists themselves because such basic information is usually partially available for professional researchers and the flowers and fruits are not always available for studies throughout the year while the leaves which can be gotten for most of the time don't have sufficient visible characteristics to differentiate between many species.</p><p>Methods of computer vision such as image retrieval technologies can be helpful in reducing this taxonomic gap. Also evaluating recent advances of the IR community on this challenging task might therefore have a strong impact. The ImageCLEF series use this idea and propose an ongoing campaign on plant identification task. The goal of the task is to retrieve the correct species among the top k species of a ranked list of retrieved species for each test image and provide a forum for researchers working on image analysis and artificial intelligence methods to share their ideas and compare their systems in order to help the taxonomic process with leaves information <ref type="bibr" coords="2,340.33,142.91,10.52,8.74" target="#b0">[1]</ref>  <ref type="bibr" coords="2,354.17,142.91,9.96,8.74" target="#b1">[2]</ref>.</p><p>In the continuity of last year pilot, the task will be focused on tree species identification based on leaf images. The main novelties compared to last year are the following:</p><p>(1) More species: the number of species will be this year 126, which is an important step towards covering the entire flora of a given region.</p><p>(2) Plant species retrieval vs. pure classification: last year's task was organized as a pure classification task over 70 species, whereas this year evaluation metric will be slightly modified in order to consider a ranked list of retrieved species rather than a single brute determination <ref type="bibr" coords="2,314.82,251.36,9.96,8.74" target="#b0">[1]</ref>.</p><p>So the task this year is much more challenge than that of last year and the evaluation is also quite reasonable compared with that of last year.</p><p>The following Section 2 describes the materials and methods used. In Section 3, we describe the results of our experiments. Finally, some conclusions reached are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Material and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Database</head><p>The task will be based on Pl@ntLeaves II dataset which focuses on 126 tree species from French Mediterranean area. This database is maintained by the French project Pl@ntNet (INRIA, CIRAD, Telabotanica). It contains 11572 pictures subdivided into three different kinds of pictures: scans (57%), scan-like photos (24%) and free natural photos (19%) <ref type="bibr" coords="2,323.64,439.51,13.10,8.74" target="#b0">[1]</ref>. 1. Scan: These images are oriented vertically along the main natural axis and with the petiole visible collected using flatbed scanners. 2. Scan-like photos: Those images have uniform background but with some luminance variations, optical distortions, shadows and color derivations which look similar to the scans images. 3. Free natural photos: No acquisition protocol is used, which results in a nonuniform background, rotated and bad-scaled images, among others problems. And the images are taken directly on the trees.</p><p>All data are published under a creative commons license. Each image has an xml file associated that contain the date, type (single leaf, single dead leaf or foliage), name of the author and GPS coordinates of the observation etc. But we don't make use of this kind of information and all the data are extracted form the images directly without any segmentation operations. So the experiments are fully automatic without any human assistance.</p><p>The training data finally results in 8422 images (4870 scans, 1819 scan-like photos, 1733 natural photos) with full xml files associated to them. The test data results in 3150 images (1760 scans, 907 scan-like photos, 483 natural photos) with purged xml files (i.e. without the taxon information that has to be predicted) <ref type="bibr" coords="2,464.15,656.12,12.34,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>As the leaf is one kind of object, the methods applied to object classification can be adopted to perform plant identification. Sparse representation is a new method used to solve this problem and achieve promising results <ref type="bibr" coords="3,427.61,160.09,9.96,8.74" target="#b2">[3]</ref>. Here we utilize the ScSPM model proposed by Yang to finish this task. ScSPM is an algorithm which combined spatial pyramid matching and sparse representation getting good results in object classification task <ref type="bibr" coords="3,344.60,195.96,9.96,8.74" target="#b3">[4]</ref>. This algorithm has 4 stages as follows.</p><p>Feature Extraction. Feature extraction has great effects on the stages afterwards. As SIFT descriptors are widely used in pattern recognition, signal processing and computer vision and suitable for classification, in this paper we extracted SIFT descriptors densely in images and normalized them to form the feature vectors <ref type="bibr" coords="3,201.99,282.88,9.96,8.74" target="#b4">[5]</ref>. Also as symmetry can be found in leaves, if we consider this kind of symmetry in feature extraction, a better result may be able to gotten. So here we take advantage of an extension version of SIFT descriptors, namely flip SIFT descriptors, to do another experiment <ref type="bibr" coords="3,327.01,318.75,9.96,8.74" target="#b5">[6]</ref>. The descriptors can be generated by the software package provided by the author. We change it by extracting them densely in the images and omit some descriptors which don't meet the requirements.</p><p>Sparse Coding. Since the introduction of sparse coding, many algorithms have been proposed to solve this problem such as MP, OMP which solve the l 0regularization problem:</p><formula xml:id="formula_0" coords="3,208.23,421.20,268.12,17.10">min a ∥y -Xa∥ 2 2 + λ ∥a∥ 0 subject to ∥x i ∥ &lt; = 1 . (<label>1</label></formula><formula xml:id="formula_1" coords="3,476.35,424.17,4.24,8.74">)</formula><p>and LASSO that solves the l 1 -regularization problem:</p><formula xml:id="formula_2" coords="3,208.23,461.12,268.12,17.10">min a ∥y -Xa∥ 2 2 + λ ∥a∥ 1 subject to ∥x i ∥ &lt; = 1 . (<label>2</label></formula><formula xml:id="formula_3" coords="3,476.35,464.09,4.24,8.74">)</formula><p>Feature search sign is a method solving this problem with high efficiency, so we use it to do sparse coding for saving the time for experiments <ref type="bibr" coords="3,406.36,497.47,9.96,8.74" target="#b6">[7]</ref>.</p><p>Spatial Pooling Scheme. Instead of the histogram representation in traditional SPM method <ref type="bibr" coords="3,222.80,536.57,9.96,8.74" target="#b7">[8]</ref>, this scheme divided the image into several scales and on each scale it performed pooling scheme in the patch formed. Usually there are three different pooling mechanisms which can be used in this model: (1) Average pooling which calculates the mean pooling of absolution value.</p><p>(2) Maximum value pooling which gets the maximum absolute value in a local patch.</p><p>(3) Energy pooling which calculates the square root of mean of energy values in a patch formed.</p><p>The operation of maximum pooling can get the best result usually, so we just report the result of it.</p><p>Classification. The last step of this framework is the training of a classifier to classify the unitary normalized test vectors obtained from the previous stages. As linear classifiers can earn a good result, we use linear Supported Vector Machine (SVM) classifiers to finish this work and the parameters for SVMs are tuned by cross-validation. Also the results for the runs are formed by normalizing the degrees of attribution in different SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Metric</head><p>The only thing that matters in the primary metric evaluating the submitted runs is the rank of the correct species in the list of retrieved species. Each test image will be assigned a score between 0 and 1 which decreases quickly with the increment of the rank of the correct species. At last, a simple mean on all test images will be computed. Since we want to evaluate the ability of a system to provide correct answers to all users and based on a single plant observation, we rather measure the mean of the average classification rate per author and average the classification rate on each individual plant respectively. Finally, the final metric is defined as the following average classification score S:</p><formula xml:id="formula_4" coords="4,230.75,364.22,245.60,31.28">S = 1 U U ∑ u=1 1 P u Pu ∑ p=1 1 N u,p Nu,p ∑ n=1 s u,p,n . (<label>3</label></formula><formula xml:id="formula_5" coords="4,476.35,375.71,4.24,8.74">)</formula><p>where U is the number of users (who have at least one image in the test data), P u is the number of individual plants observed by the u-th user, N u,p is the number of pictures taken from the p-th plant observed by the u-th user and S u,p,n is classification score for the n-th picture taken from the p-th plant observed by the u-th user. Considering different image acquisition type may have different effects, an average classification score S will be computed separately for each type <ref type="bibr" coords="4,157.17,477.91,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Results</head><p>According to the rule of the campaign, we submitted three different runs to the plant identification task. And the details are as follows.</p><p>In the first run, we just extracted the dense-SIFT descriptors from the images, used ScSPM model for generating the feature vectors and took the ls-svm package to form classifiers to classify the test images in the database <ref type="bibr" coords="4,437.75,572.44,9.96,8.74" target="#b8">[9]</ref>.</p><p>In the second run, we changed the descriptors into flip SIFT ones in hope of taking symmetry into account and the others kept the same as the first run.</p><p>In the third run, also the last run, we fused the classifiers of the two runs above to form a new kind of degree of attribution. Then the normalization of the terms formed the rank list we submitted.</p><p>The results are showed in Table <ref type="table" coords="4,295.89,644.17,3.87,8.74" target="#tab_0">1</ref>. From it we can find that the third run achieves the best results in all kinds of pictures. That's to say, the fusion scheme usually can reach a better result for combination of different methods advantages. The run for the SIFT descriptors is in the middle place of the three runs and the one for flip SIFT descriptors gets the worst results which is in contradiction with our expectation. In fact, we have done comparison experiments on these two kinds of descriptors by using the species which have more than 30 images in training database with MAP as the evaluation term. Then the result of flip SIFT descriptors is better than that of original SIFT descriptors. So we can speculate that the reasons for this phenomenon may have a relation to the number of training images in certain species which have very few images and the parameters of the SVMs which are the same as those of the first run for convention and time limit. Also we can find that of the three kinds of images, the results for the scan images are the best, then those of the pseudo-scan images and the ones of the photograph images come at last. The differences between the results of the first two kinds of images may due to optical distortions and shadows in the images which can not be recognized by dense SIFT descriptors. The reason for the worst performance in classifying the photograph images is that the model used considers the natural scenes as parts of leaves which does harm to the identification task afterward. Maybe taking segmentation operation at first for this kind of images is a good choice.</p><p>For the limitation of pages, we don't present it here and you can find it on the homepage of this task <ref type="bibr" coords="5,249.01,500.43,9.96,8.74" target="#b0">[1]</ref>. The results can be divided into two parts, namely fully automatic and others, at first. In the first two kinds of images, the best of ours gets the sixth place in automatic ones. While for the last kind of images, the results of ours fall behind the others and get the last several positions. For the average classification score, we can earn the sixth place in automatic ones. That's to say, the results are not too bad for our first participation in this task and the results can be improved a lot if we improve the performance of classifying the photograph images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This is our first try in the plant identification task. Although the results are not quite promising, we still reach some conclusions and gain some experience.</p><p>(1)At first, as there are some species which have only a few images, the bias for these species may be emphasized and combing some retrieval methods is a good choice.</p><p>(2)Then the flip SIFT descriptors may not be suitable for this task if we can't tune the parameters individually and change it into dense ones in a proper way.</p><p>(3)After that, building different classifiers for different types of images may be helpful and the ScSPM model probably doesn't meet the requirements of classifying the photograph images and it suggests us selecting some other algorithms for this type of images.</p><p>(4)Also it may not be proper for the prediction lists of SVMs to represent the results directly and there are some problems in the normalization scheme. And nonlinear classifiers may improve the results.</p><p>(5)At last, the provided xml files are not used in our experiments and maybe they will provide complementary information for the visual features.</p><p>As this kind of system is quite helpful for researches and agricultural development, we will continue to do researches in this field. And by caring about the details and altering the methods used, we hope to further improve our experiment in future tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,140.97,268.96,333.41,70.90"><head>Table 1 .</head><label>1</label><figDesc>Results for all runs in plant database.</figDesc><table coords="5,140.97,292.75,333.41,47.11"><row><cell>Run name</cell><cell cols="5">Retrieval type run-type scan pseudo-scan photograph avg score</cell></row><row><cell>ZhaoHFUT run1</cell><cell>Visual</cell><cell>Automatic 0,30</cell><cell>0,24</cell><cell>0,09</cell><cell>0,21</cell></row><row><cell>ZhaoHFUT run2</cell><cell>Visual</cell><cell>Automatic 0,24</cell><cell>0,17</cell><cell>0,09</cell><cell>0,17</cell></row><row><cell>ZhaoHFUT run3</cell><cell>Visual</cell><cell>Automatic 0,32</cell><cell>0,26</cell><cell>0,11</cell><cell>0,23</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledges. This research has been supported by the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">61005007</rs>), the <rs type="funder">National 863 Program of China</rs> (<rs type="grantNumber">2012AA011005</rs>), the <rs type="funder">China Post-doctoral Science Foundation</rs> (<rs type="grantNumber">20100470825</rs>, <rs type="grantNumber">201104324</rs>) and <rs type="funder">Cognilego</rs> <rs type="grantNumber">ANR 2010-CORD-013</rs>. The authors would like to thank <rs type="person">Jianchao Yang</rs>, who provided the SIFT and ScSPM codes for sharing.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cYpKhrs">
					<idno type="grant-number">61005007</idno>
				</org>
				<org type="funding" xml:id="_tBR4pzj">
					<idno type="grant-number">2012AA011005</idno>
				</org>
				<org type="funding" xml:id="_C2xTvzK">
					<idno type="grant-number">20100470825</idno>
				</org>
				<org type="funding" xml:id="_HyfvFdP">
					<idno type="grant-number">201104324</idno>
				</org>
				<org type="funding" xml:id="_7nP3pct">
					<idno type="grant-number">ANR 2010-CORD-013</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.34,451.50,342.24,8.11;6,146.91,463.10,23.54,7.47" xml:id="b0">
	<monogr>
		<ptr target="http://www.imageclef.org/2012/plant" />
		<title level="m" coord="6,146.91,451.50,182.33,7.86">ImageCLEF 2012 Plant identification task</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,473.12,342.24,7.86;6,146.91,484.08,333.67,7.86;6,146.91,495.04,184.37,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,286.23,484.08,190.50,7.86">The ImageCLEF 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Itheri</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nozha</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-François</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.91,495.04,103.77,7.86">CLEF 2012 working notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,505.70,342.24,7.86;6,146.91,516.65,333.66,7.86;6,146.91,527.61,94.19,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,256.65,505.70,223.93,7.86;6,146.91,516.65,70.88,7.86">Sparse coding with an overcomplete basis set: a strategy employed by V1?</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0042-6989(97)00169-7</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,221.61,516.65,60.48,7.86">Vision research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,538.27,342.24,7.86;6,146.91,549.23,333.67,7.86;6,146.91,560.19,152.59,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,319.03,538.27,161.55,7.86;6,146.91,549.23,154.81,7.86">Linear Spatial Pyramid Matching Using Sparse Coding for Image Classification</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Jianchao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gong</forename><surname>Yihong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,308.48,549.23,172.09,7.86;6,146.91,560.19,79.79,7.86">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1794" to="1801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,570.85,342.23,7.86;6,146.91,581.80,319.85,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,214.70,570.85,211.24,7.86">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,432.51,570.85,48.07,7.86;6,146.91,581.80,209.37,7.86">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,592.46,342.25,9.85" xml:id="b5">
	<monogr>
		<ptr target="http://www.cs.cityu.edu.hk/~wzhao2/" />
		<title level="m" coord="6,146.91,592.46,162.82,7.86">lip-vireo package for flip SIFT descriptors</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,603.12,342.24,7.86;6,146.91,614.08,322.85,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,338.46,603.12,138.02,7.86">Efficient sparse coding algorithms</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.91,614.08,240.56,7.86">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,624.74,342.24,7.86;6,146.91,635.70,267.69,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,310.23,624.74,170.36,7.86;6,146.91,635.70,197.06,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,362.38,635.70,20.89,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,646.35,304.51,8.11" xml:id="b8">
	<monogr>
		<ptr target="http://www.esat.kuleuven.be/sista/lssvmlab/" />
		<title level="m" coord="6,146.91,646.35,86.24,7.86">lssvm matlab package</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
