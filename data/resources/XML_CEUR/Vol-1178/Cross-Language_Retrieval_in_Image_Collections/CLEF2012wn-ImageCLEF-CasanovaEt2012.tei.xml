<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.36,116.75,272.63,12.62;1,244.55,134.69,126.26,12.62">IFSC/USP at ImageCLEF 2012: Plant identification task</title>
				<funder ref="#_7ptnGak #_tFG9pur">
					<orgName type="full">FAPESP (São Paulo Research Foundation, Brazil)</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder ref="#_mBXu4Zt">
					<orgName type="full">National Council for Scientific and Technological Development)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,141.99,172.36,84.07,8.74"><forename type="first">Dalcimar</forename><surname>Casanova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">USP -Universidade de São Paulo IFSC -Instituto de Física de São Carlos</orgName>
								<address>
									<settlement>São Carlos</settlement>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,236.72,172.36,95.15,8.74"><forename type="first">João</forename><forename type="middle">Batista</forename><surname>Florindo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">USP -Universidade de São Paulo IFSC -Instituto de Física de São Carlos</orgName>
								<address>
									<settlement>São Carlos</settlement>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.62,172.36,107.62,8.74"><forename type="first">Wesley</forename><forename type="middle">Nunes</forename><surname>Gonçalves</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">USP -Universidade de São Paulo IFSC -Instituto de Física de São Carlos</orgName>
								<address>
									<settlement>São Carlos</settlement>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.67,184.31,75.05,8.74"><forename type="first">Odemir</forename><surname>Martinez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">USP -Universidade de São Paulo IFSC -Instituto de Física de São Carlos</orgName>
								<address>
									<settlement>São Carlos</settlement>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,171.36,116.75,272.63,12.62;1,244.55,134.69,126.26,12.62">IFSC/USP at ImageCLEF 2012: Plant identification task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE134F744EAD6B9B6C4BBDF801B5986D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Complex Network</term>
					<term>Fractal</term>
					<term>Taxonomy</term>
					<term>Plant identification</term>
					<term>Leaves</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ImageCLEF 2012 has a challenge based on leaf analysis for plant identification. This paper reports the method proposed by IFSC/USP team in the participation of this task. We try to explore several attributes (i.e. shape, location and texture) to make a system more accurate. The achieved results are promising and show as a principal outcome the power of texture on leaf analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plants identification has become an important and challenging research area since it is estimated that approximately one half of world plant species is still not cataloged. Among such unidentified species one may find, for instance, the healing of a disease or a plant that can cooperate in the equilibrium of the ecosystem around it. Despite the importance of studies related to the description and categorization of plants, this is still a difficult task for a botanist once this specialist still has a limited amount of information about the vegetal. Furthermore, among the information which may be collected, the most relevant for the botanist analysis are flowers and fruits. However, it turns out that in most cases these elements are observed only in specific periods of the year. This is a complicated issue given that the observation may not be possible when these characteristics are noticeable.</p><p>A solution for this impasse is the use of the plant leaf. This structure uses to be observed the whole year and can be collected in a straightforward manner.</p><p>Nevertheless, most leaves lack more distinguishable attributes for a visual analysis. Thus, image analysis based on computational tools is a worthwhile approach in order to help the botanist or even provide by itself a reliable outcome for the classification task.</p><p>In this context, ImageCLEF is a world campaign to encourage the development of novel strategies for the description and identification of objects, in this case, plant leaves, based on computational/mathematical techniques applied over digital images.</p><p>As the group of this work has a significative background on computer vision techniques applied to plant identification <ref type="bibr" coords="2,316.39,226.59,9.96,8.74" target="#b1">[2]</ref>, we decided to engage in this campaign and proposed a methodology combining complex networks and geometric features of the leaf contour in addition to fractal descriptors of the texture inside the leaf. These methods have already corroborated their efficiency on other works related to plant identification tasks <ref type="bibr" coords="2,319.57,274.41,9.96,8.74" target="#b1">[2]</ref>.</p><p>This work is composed by 6 sections, including this introduction. The following section describes briefly the materials and methods employed in the experiments. The following one shows the experiments setup. The fourth section shows obtained results over the training data. The fifth one exhibits the results for the test data set while the last section presents the conclusions of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Material and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Database</head><p>The experiments are performed over Pl@antLeaves dataset <ref type="bibr" coords="2,401.20,409.49,9.96,8.74" target="#b4">[5]</ref>. This database is maintained by the French project Pl@ntNet (INRIA, CIRAD, Telabotanica). The full database contains 11572 images of 126 tree species. The images are taken under 3 different practical conditions:</p><p>1. Scan: contains 6630 scans of leaves collected using flatbed scanners. These images are oriented vertically along the main natural axis and with the petiole visible. 2. Scan-like photos: contains 2726 photos which look similar to the scans images. Those images have uniform background but with some luminance variations, optical distortions, shadows and color derivations. 3. Natural photos: contains 2216 photos taken directly from the trees. No acquisition protocol is used, which results in a non-uniform background, rotated and bad-scaled images, among other problems.</p><p>Each image has an xml file associated that contain the date, type (single leaf, single dead leaf or foliage), name of the author and GPS coordinates of the observation among other data.</p><p>The full database is split into training and testing dataset. The train dataset has 8422 images (4870 scans, 1819 scan-like photos, 1733 natural photos) and de test dataset have 3150 images (1760 scans, 907 scan-like photos, 483 natural photos).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pre-processing</head><p>For scan and scan-like photos in both test and train datasets, the Otsu's method <ref type="bibr" coords="3,134.77,151.35,15.50,8.74" target="#b9">[10]</ref> was employed to automatically perform image thresholding. Since fully automatic image thresholding is usually hard for natural photos, we have used two strategies: (i) semi-automatic image segmentation proposed in <ref type="bibr" coords="3,410.71,175.26,10.52,8.74" target="#b7">[8]</ref> and (ii) fully automatic k-means segmentation.</p><p>Semi-automatic: first, the photo is automatically segmented by the wellknown mean shift segmentation method. Then, the user roughly indicates the location of the leaf and the background by using some strokes (markers). The regions marked by the user guide the merging process, which gradually labels each non-marker region as either leaf or background based on the histogram similarity.</p><p>Automatic: the k-means algorithm is applied to cluster the pixels from the photo into two groups based on the RGB color. Thus, pixels with similar color are in the same group (e.g. green pixels which may be leaves). To decide which group contains the leaf pixels, we calculate the mean RGB value of the central region of the image. The centroid closest to the mean RGB value is chosen as the leaf pixels.</p><p>After the segmentation step, we apply a contour detection method to extract the contour of the leaf. We do not bother to treat open or imperfect contours, because the method of shape analysis is robust to such problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Leaf analysis features</head><p>In order to explore several aspects of the leaf we use different kinds of methods. Each method returns a feature vector that is used together in the final classifier.</p><p>-Complex Network: proposed by <ref type="bibr" coords="3,294.17,488.56,10.52,8.74" target="#b1">[2]</ref> this method explores and describes the shape of objects using measurements of a graph model. In this method we use T = {0.025, 0.050, 0.075, . . . , 0.925}, totalizing 13 thresholds (|T | = 13). We measure, for each threshold, the average and maximum degree resulting in 26 features. -GPS coordinates: the XML file provided with the leaf image has the GPS coordinates of the observation. We can consider this information as an a priori knowledge, since the frequency of a specie may be higher in some places. So, we use the latitude and longitude as feature vector (2 features) -Gabor filters: used before in leaf analysis by <ref type="bibr" coords="3,350.04,596.34,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="3,364.25,596.34,7.01,8.74" target="#b3">4]</ref>, the 2D Gabor filter explores the texture aspect of the leaf. It is basically a bi-dimensional Gaussian function moduled with an oriented sinusoid in a determined frequency and direction. This procedure consists of convolving an input image by a family of Gabor filters, which present various scales and orientations of the same original configuration. We use a family of 64 filters (8 rotation filter and 8 scale filters), with a lower and upper frequency equal to 0.01 and 0.4, respectively. The definition of the individual parameters of each filter follows the mathematical model presented in <ref type="bibr" coords="4,300.11,142.90,9.96,8.74" target="#b6">[7]</ref>. -Volumetric fractal dimension: other method used in leaf texture analysis is the volumetric fractal dimension <ref type="bibr" coords="4,296.81,165.82,9.96,8.74" target="#b0">[1]</ref>. The method is based on analyzing the complexity of the surface generated by a texture. The dilatation procedure is very sensitive to structural changes in the image, which are measured by the influence volume generated. In experiments we use r max = 10, resulting in 85 features. -Local binary patterns: this method <ref type="bibr" coords="4,308.07,224.61,10.52,8.74" target="#b8">[9]</ref> calculates the co-occurrence of graylevels on circular neighborhoods. Each pixel is taken as a central pixel and then we assign 1 to the neighbor pixels whose gray-level is greater than the gray-level of the central pixel and 0 otherwise. Afterthat, a histogram is built using the binary number of each central pixel. Since the histogram contains a lot of features, we have used an extension called uniform local binary patterns, which is used to reduce the length of the feature vector, resulting in 51 features. -Geometric features: these features are extracted from the contour of the leaf which is handled as being a generic shape. Thus, we extract the diameter, aspect ratio, rectangularity, convex area ratio, convex perimeter ratio, form factor, sphericity and eccentricity. These are morphological attributes which are widely used in the literature and have demonstrated their efficiency in works like <ref type="bibr" coords="4,198.28,379.03,9.96,8.74" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data analysis setup</head><p>The imageCLEF task allows the submission of 3 different approaches trying to recognize the leaves. In this way, we configure 3 runs as:</p><p>1. IFSC USP run1: The training classifier is done with all features and we simply concatenate them in order to obtain a single features vector (237 features). Additionally we used all samples for training (scan, like scan and natural photos). 2. IFSC USP run2: this run is similar to IFSC USP run1 and the main difference is that only scan and like-scan images are used on training procedure. The reason is try to avoid the influence of bad-segmented leaves on training set. 3. IFSC USP run3: For this run, we try a fully automated procedure. For natural photos segmentation we use a simple clustering described above. So, we use only Gabor and GPS features, due to the impossibility of measuring shape information of this cluster-segmented images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results over training data</head><p>In order to evaluate the accuracy of methods after submitting the results, we use a 10-fold cross-validation over training data set. The employed classifier is a Linear Discriminant Analysis (LDA), also known as Fisher discriminant.</p><p>In a preliminary analysis, we investigate the accuracy of each method in an independent way. The Table <ref type="table" coords="5,261.84,130.95,4.98,8.74" target="#tab_0">1</ref> shows this result. We notice that VFD provided the best result in this case. This success is justified by the richness intrinsic to the texture of leaves, which contain complex patterns with a high potential to describe accurately the plant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>No In a subsequent analysis we try to concatenate theses features in order to evaluate if each method explores different attributes of leaf data and images. The result is the exact configuration of the run IFSC USP run1 presented above. As expected, we have a very good result showed by Figure <ref type="figure" coords="5,378.63,362.83,3.87,8.74" target="#fig_0">1</ref>: We also comprobe that features which have not presented significative success when used alone showed an expressive contribution when concatenated with other features.</p><p>Additionally, the Figure <ref type="figure" coords="5,257.99,644.16,4.98,8.74" target="#fig_0">1</ref> shows as recognition rate increases if we consider the classes with more a posteriori probabilities. If we are looking only at the class with more higher probabilities, we get a 80.24% as success rate. As expected, the accuracy increases if we consider a higher number of the possible classes. For example, we reach 98.17% of accuracy if we look for the 9 most likely species and 99.09 with 18 species with higher a posteriori probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Test data analysis and results</head><p>We have submitted three runs to the plant identification task. The first two runs are human assisted while the third one is fully automatic. Table <ref type="table" coords="6,419.46,217.59,4.98,8.74">2</ref> presents the classification score obtained for each run and each image type (scans, scan-like photos and photos). We can see that the best average result was obtained by the first run. For the scan and scan-like, the results of the first run show similar results to the second run. For the photos, however, the result of the first run was superior to the other two runs. This result demonstrates that it is important to train the classifier using features extracted from the photos. It is worth to mention that the result of the first run for the photos was the best of all runs including other participants.</p><p>Finally, we conclude that using different types of features (e.g. shape, texture and GPS) improves the classification score in all image types. Moreover, the human assisted segmentation is a good way to improve the discrimination of natural photos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head><p>No. of descriptors scan scan-like photos Avg IFSC USP run1 237 0.35 0.41 0.51 0.42 IFSC USP run2 237 0.34 0.43 0.30 0.36 IFSC USP run3 66 0.20 0.14 0.12 0.16 Table <ref type="table" coords="6,232.31,443.30,4.13,7.89">2</ref>. Results for all runs in the plant database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Although we do not have the best results among all participants, we made some good findings about plant identification using leaves.</p><p>As the main point, we have is the power of texture analysis in leaf discrimination. We employ only simple methods and, besides the lack of standardization of the images, especially images of free natural photos, the texture analysis works fine.</p><p>The results of texture methods are best than shapes approaches. In our previous works <ref type="bibr" coords="6,180.22,608.30,14.61,8.74" target="#b10">[11]</ref>, we had already noticed this phenomena and here we corroborate them. In further, we hope that this morphological character be most studied.</p><p>Otherwise, the synergy from the investigation of various aspects seems to be the most promising ways, with good prospects to make a good system of leaf identification with the use of all variables.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,564.78,345.82,7.89;5,134.77,575.76,31.23,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Recognition rate by rank. With the first choice of classifier the accuracy is 80.24%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,190.88,202.18,233.60,88.91"><head>Table 1 .</head><label>1</label><figDesc>Results for each method over training database.</figDesc><table coords="5,201.93,202.18,211.50,76.01"><row><cell></cell><cell>. of features</cell><cell>Sucess rate (%)</cell></row><row><cell>Complex Network</cell><cell>26</cell><cell>31.76</cell></row><row><cell>GPS</cell><cell>2</cell><cell>12.68</cell></row><row><cell>Gabor</cell><cell>64</cell><cell>43.66</cell></row><row><cell>VFD</cell><cell>85</cell><cell>43.51</cell></row><row><cell>LBP</cell><cell>51</cell><cell>43.24</cell></row><row><cell>Geometric</cell><cell>9</cell><cell>36.04</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p><rs type="person">Dalcimar Casanova</rs> gratefully acknowledges the financial support <rs type="funder">FAPESP (São Paulo Research Foundation, Brazil)</rs> (<rs type="grantNumber">2008/57313-2</rs>) for his PhD grant. <rs type="person">João Batista Florindo</rs> gratefully acknowledges the financial support <rs type="funder">CNPq</rs> (<rs type="funder">National Council for Scientific and Technological Development)</rs> (<rs type="grantNumber">870336/1997-5</rs>) for his PhD grant. <rs type="person">Wesley Nunes Gonçalves</rs> gratefully acknowledges the financial support <rs type="funder">FAPESP (São Paulo Research Foundation, Brazil)</rs> (<rs type="grantNumber">2010/08614-0</rs>) for his PhD grant.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7ptnGak">
					<idno type="grant-number">2008/57313-2</idno>
				</org>
				<org type="funding" xml:id="_mBXu4Zt">
					<idno type="grant-number">870336/1997-5</idno>
				</org>
				<org type="funding" xml:id="_tFG9pur">
					<idno type="grant-number">2010/08614-0</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,155.24,170.80,325.35,8.74;7,155.24,182.75,325.35,8.74;7,155.24,194.71,269.44,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,375.70,170.80,104.89,8.74;7,155.24,182.75,168.36,8.74">Plant leaf identification based on volumetric fractal dimension</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,335.89,182.75,144.70,8.74;7,155.24,194.71,163.02,8.74">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1145" to="1160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,206.67,325.35,8.74;7,155.24,218.62,325.35,8.74;7,155.24,230.58,22.69,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,367.32,206.67,113.27,8.74;7,155.24,218.62,167.24,8.74">A complex network-based approach for boundary shape analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,333.54,218.62,85.37,8.74">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="67" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,242.53,325.35,8.74;7,155.24,254.49,325.34,8.74;7,155.24,266.44,311.40,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,351.24,242.53,129.34,8.74;7,155.24,254.49,115.24,8.74">Measurements of color texture on plant leaf identification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,293.44,254.49,187.14,8.74;7,155.24,266.44,193.13,8.74">BIOMAT 2008 -International Symposium on Mathematical and Computational Biology</title>
		<meeting><address><addrLine>Campos do Jordão</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,278.40,325.35,8.74;7,155.24,290.35,325.35,8.74;7,155.24,302.31,161.91,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,415.11,278.40,65.49,8.74;7,155.24,290.35,131.86,8.74">Plant leaf identification using gabor wavelets</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>De Mesquita Sa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,297.08,290.35,183.51,8.74;7,155.24,302.31,64.92,8.74">International Journal of Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="236" to="243" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,314.26,325.34,8.74;7,155.24,326.22,325.35,8.74;7,155.24,338.17,169.54,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,238.46,326.22,192.31,8.74">The imageclef 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,453.95,326.22,26.64,8.74;7,155.24,338.17,82.42,8.74">CLEF 2012 working notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,350.13,325.35,8.74;7,155.24,362.08,87.11,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,299.72,350.13,180.87,8.74;7,155.24,362.08,82.30,8.74">Automatic Plant Leaf Classification for a Mobile Field Guide</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Painter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,374.04,325.35,8.74;7,155.24,385.99,325.35,8.74;7,155.24,397.95,124.23,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,297.34,374.04,183.25,8.74;7,155.24,385.99,57.40,8.74">Texture features for browsing and retrieval of image data</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,221.14,385.99,259.45,8.74;7,155.24,397.95,27.82,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,409.90,325.35,8.74;7,155.24,421.86,325.34,8.74;7,155.24,433.81,63.65,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,344.00,409.90,136.59,8.74;7,155.24,421.86,194.02,8.74">Interactive image segmentation by maximal similarity based region merging</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,361.10,421.86,85.43,8.74">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="445" to="456" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,445.77,325.35,8.74;7,155.24,457.72,325.35,8.74;7,155.24,469.68,325.35,8.74;7,155.24,481.63,22.69,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,348.34,445.77,132.25,8.74;7,155.24,457.72,290.23,8.74">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,456.48,457.72,24.11,8.74;7,155.24,469.68,255.37,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,493.59,325.35,8.74;7,155.24,505.54,290.58,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,198.79,493.59,247.44,8.74">A threshold selection method from grey-level histograms</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,456.48,493.59,24.11,8.74;7,155.24,505.54,208.69,8.74">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,155.24,517.50,325.34,8.74;7,155.24,529.45,325.35,8.74;7,155.24,541.41,325.35,8.74;7,155.24,553.37,308.73,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,425.11,517.50,55.47,8.74;7,155.24,529.45,325.35,8.74;7,155.24,541.41,325.35,8.74;7,155.24,553.37,58.37,8.74">Fractal analysis of leaf-texture properties as a tool for taxonomic and identification purposes: a case study with species from neotropical melastomataceae (miconieae tribe)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Rossatto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Kolb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">M</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,221.96,553.37,140.18,8.74">Plant Systematics and Evolution</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="116" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
