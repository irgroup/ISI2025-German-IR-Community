<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,134.77,116.95,345.83,12.62;1,142.12,134.89,324.89,12.62">ReVeS Participation -Tree Species Classification using Random Forests and Botanical Features</title>
				<funder ref="#_kFpDjCd">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,146.37,172.56,79.80,8.74"><forename type="first">Guillaume</forename><surname>Cerutti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Lyon 2</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69676</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.06,172.56,73.34,8.74"><forename type="first">Violaine</forename><surname>Antoine</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">LISTIC</orgName>
								<orgName type="institution" key="instit2">Domaine Universitaire</orgName>
								<address>
									<postCode>F-74944</postCode>
									<settlement>Annecy le Vieux</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.96,172.56,60.22,8.74"><forename type="first">Laure</forename><surname>Tougne</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Lyon 2</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69676</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,404.07,172.56,51.34,8.74"><forename type="first">Julien</forename><surname>Mille</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Université Lyon 1</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69622</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.98,184.51,52.72,8.74"><forename type="first">Lionel</forename><surname>Valet</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">LISTIC</orgName>
								<orgName type="institution" key="instit2">Domaine Universitaire</orgName>
								<address>
									<postCode>F-74944</postCode>
									<settlement>Annecy le Vieux</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.26,184.51,61.88,8.74"><forename type="first">Didier</forename><surname>Coquin</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">LISTIC</orgName>
								<orgName type="institution" key="instit2">Domaine Universitaire</orgName>
								<address>
									<postCode>F-74944</postCode>
									<settlement>Annecy le Vieux</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.69,184.51,77.21,8.74"><forename type="first">Antoine</forename><surname>Vacavant</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Clermont Université</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<orgName type="institution" key="instit3">ISIT</orgName>
								<address>
									<postCode>F-63001</postCode>
									<settlement>Clermont-Ferrand</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,134.77,116.95,345.83,12.62;1,142.12,134.89,324.89,12.62">ReVeS Participation -Tree Species Classification using Random Forests and Botanical Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">276ACFEBC3E4452547349BC5CF3DCFE7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes the participation of the ReVeS project to the ImageCLEF 2012 Plant Identification task. Aiming to develop a system for tree leaf identification on mobile devices, our method is designed to cope with the challenges of complex natural images and to enable a didactic interaction with the user. The approach relies on a two step model-driven segmentation and on the evaluation of high-level characteristics that make a semantic interpretation possible, as well as more generic shape features. All these descriptors are combined in a random forest classification algorithm, and their significance evaluated. Our team ranks 4th overall, 3rd on natural images, which constitutes a very satisfying performance with respect to the project's objectives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ability to recognize a plant species and to understand its specificities has now become a task accessible mostly to specialists. Most flora books promise an arduous time to the willing neophyte, who does not possess the compulsory theoretical background. Mobile systems however offer the opportunity to introduce such knowledge in an interactive way, at the level of the user. Mobile guides for plant species identification have already seen light <ref type="bibr" coords="1,373.29,508.27,10.52,8.74" target="#b0">[1]</ref> with great success on white background images. The goal of the ReVeS project is to build a system to help users to recognize a tree in a natural environment, from the photograph of a leaf, in an educational and interactive way.</p><p>With this objective, we participated to the ImageCLEF Plant Identification task <ref type="bibr" coords="1,155.29,568.05,10.52,8.74" target="#b8">[9]</ref> for the second time, treating almost all of the 126 species in the database, making a strong distinction between the 24 species with compound leaves, and the 100 species with simple leaves we considered. The task consisted in associating, after a training phase, each one of the 3150 images in the Test database to an ordered list of species. Our work focused mainly of the application of methods dedicated to the case of photographs of one leaf in a natural environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Based Leaf Segmentation</head><p>Retrieving the leaf contour is the first and crucial step for the understanding of the image. It is a really challenging issue in unsupervised, complex, natural images <ref type="bibr" coords="2,166.66,171.43,16.13,8.74">[21,</ref><ref type="bibr" coords="2,182.79,171.43,12.10,8.74" target="#b19">20]</ref> where it is necessary to incorporate as much knowledge as possible to ease the task <ref type="bibr" coords="2,209.68,183.39,14.61,8.74" target="#b10">[11]</ref>. Including prior knowledge on the expected shape of the object we look for is a good way to reduce the risk of mistakes. But in the context of a mobile application, it would be regrettable not to take advantage of a human user to guide an automatic process that would otherwise be very prone to erratic behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Leaf Color Model</head><p>In potentially imperfect images, and with the idea of approximating the shape of the leaf, color seems to be the most relevant information to rely on. A valid a priori color model for all leaves is impossible given the variety induced by season, species and lighting, but to extract a color model from every image, we first need to have a rough idea of the leaf's location.</p><p>What is quite easily solvable on white background image where a simple thresholding the grey-level image is enough to locate the leaf, becomes much more complicated with natural images. This is where we require the assistance of the user to draw a region inside the leaf, region that has to contain at least three components in the case of a compound leaf. We also rotated and cropped some photographs so that they clearly contain only one leaf of interest, with its apex pointing approximately to the top of the image, which corresponds to our frame of work for a mobile application. This is the only human intervention in the recognition process, and it is performed for photograph images only. . The use of belief function theory <ref type="bibr" coords="2,457.34,661.15,11.62,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,468.96,661.15,11.62,8.74" target="#b17">18]</ref> is here more efficient than simpler combinations (mean, minimum) to take the specificities of two relevant yet distinct sources of information 2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Active Models For Leaf Segmentation</head><p>We rely on explicit shape models to drive the segmentation of the leaves in images. It is however very complicated if not impossible to cover the diversity of leaf types, from needles to bipinnate leaves. This is why we had to introduce two different models, one for simple or palmately lobed leaves and one for compound leaves (pinnate, digitate and bipinnate indifferently) We thus considered only Angiosperm species, leaving Ginkgo biloba and Juniperus oxycedrus aside.</p><p>Parametric Active Polygon In the case of simple or palmately lobed leaves we still use a polygonal leaf model <ref type="bibr" coords="3,287.89,503.42,10.52,8.74" target="#b4">[5]</ref> to produce both a rough segmentation of the leaf and an estimation of its global shape. The number of lobes is estimated during the evolution, which is based only on the previously computed color dissimilarity map.</p><p>Fig. <ref type="figure" coords="3,155.98,643.01,4.46,8.77">3</ref>. Evolution of the parametric active polygon using the distance map, and redundant lobe suppression A Model For Compound Leaves A leaf is supposed to be compound when the initial region (after either colouring or thresholding) has at least three connected components. To evaluate the number of leaflets n F and their organization, we designed a deformable template for compound leaves that will evolve based on the dissimilarity map. This model represents leaflets by a fixed, excessive number of pairs of circles, and relies again on two points B and T and on a set of parameters to be optimized by minimizing an energy based on the total dissimilarity:</p><p>k F , the curvature of the axis r F , the radius of the circles d F , the distance of the circles to the axis p F (i), the relative position of each pair of circles Given the possibility of overlap between leaflets, and subsequently model circles, we chose not to optimize the number of leaflets during the evolution, but to try to estimate it a posteriori with a a global view. Using the radius and position parameters, we first locate groups of connected circles, and based on their sizes and the gaps between them, we estimate how many leaflets actually compose each of them. This is a hard problem, and to reduce the risk of error, we make to estimation the retrieve a minimal and maximal number of leaflets and their location in the image. This process is illustrated in Figure <ref type="figure" coords="4,450.98,571.10,3.87,8.74" target="#fig_2">4</ref>. The numbers of leaflets and the parameters of the model are used as descriptors for the compound leaf structure.</p><p>To additionally represent the shape of the leaflets, we evaluate a simple polygonal model on one of the located leaflets. To minimize the risk of the model overflowing in the neighbouring leaflets and losing any accuracy, we chose the leaflet which stands out the most in the maximal leaflet estimation, considering the distance to the previous and next pair of leaflets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Constrained Active Contour</head><p>We use the polygonal approximation both as an initialization and a shape constraint to retrieve the actual contour of the leaf, using an active contour algorithm for exact segmentation <ref type="bibr" coords="5,267.78,163.58,9.96,8.74" target="#b4">[5]</ref>. In the case of plain background images, the shape constraint is suppressed so that it doesn't prevent the contour to fit the actual leaf margin. Figure <ref type="figure" coords="5,252.92,187.49,4.98,8.74" target="#fig_3">5</ref> shows the interest of including a shape constraint on complicated images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Describing Leaf Shapes</head><p>To represent the discriminating properties encountered on the leaf, we chose to seek for the information investigated by botanists to identify species. The descriptors we use are then high-level morphological features designed to capture these specificities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global Shape Model</head><p>The represent the global shape of the leaf, we use directly the parameters obtained after the evolution of the global models. For simple and palmately lobed leaves, they consist of: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contour Interpretation</head><p>In order to capture more local shapes generally considered in the process of leaf identification, we rely on the axes of the polygonal model to partition the final contour into base, apex, lobe tip and right or left margin areas and know where to look at to estimate the determining features characterizing the leaf margin, basal shape and apical shape.</p><p>Curvature Scale Space Transform A rich representation of the contour used for shape matching is the Curvature Scale Space <ref type="bibr" coords="6,368.71,217.32,15.50,8.74" target="#b12">[13]</ref> that has already been used in the context of leaf image retrieval <ref type="bibr" coords="6,329.58,229.27,14.87,8.74" target="#b11">[12,</ref><ref type="bibr" coords="6,344.45,229.27,7.43,8.74" target="#b3">4]</ref>. It consists simply in piling up curvature measures estimated on a normalized contour, producing a visually intuitive, scale invariant description of a contour. Figure <ref type="figure" coords="6,378.59,253.18,4.98,8.74" target="#fig_5">6</ref> illustrates the interest of this transform for leaf margin analysis. CSS Image Description As such, the CSS image presents already a lot of visual information that may well represent the properties of the margin. Considering it as a describable visual object, we decided to extract texture information on this very image. We computed Haralick descriptors on a grey level version of the image to get a generic source of information on the margin, that does not take the risk of making too many assumptions.</p><p>Detecting and Characterizing Teeth On the other hand, we also wanted to locate and describe explicitly the teeth and pits on the leaf's margin. Considering that such structures clearly stand out in the CSS representation as maxima and minima of curvature, we followed an approach close to the detection of dominant points <ref type="bibr" coords="6,165.25,565.51,16.13,8.74" target="#b18">[19,</ref><ref type="bibr" coords="6,181.38,565.51,12.10,8.74" target="#b13">14]</ref> to retrieve at each scale the salient features on the contour. For each one of them, the last scale at which a point is detected informs us on its size, while its sharpness can be estimated as the mean curvature of the point at all the scales it is detected.</p><p>Such points are searched only in the contour areas corresponding to the margin, so that the largest elements (apex, lobe tips, petiole) do not absorb the interesting smaller teeth. This detection process produces an interpretation of the contour where the base and the apex are precisely located, and with a sequence of convex and concave parts, characterized by their scale S and curvature K, as depicts Figure <ref type="figure" coords="6,200.02,673.11,4.98,8.74" target="#fig_6">7</ref>  To produce descriptors suitable for classification, we chose to compute the average values and standard deviations for both concave (-) and convex (+) structures, giving a set of 8 margin descriptors:</p><p>mean scale of teeth S+ standard deviation σ S+ mean scale of pits S-standard deviation σ S- mean curvature of teeth K+ standard deviation σ K+ mean curvature of pits K-standard deviation σ K- Additionally, we measured what percentage w + of the total margin length was part of a convex element, what percentage w -was part of a concave one, and what percentage w 0 was part of none. These descriptors sum up some of the specificities botanists would look at to characterize a leaf margin, yet in a very condensed and efficient way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Basal and Apical Shape Estimation</head><p>To account for the shape of the leaf int the basal and apical areas, we transposed the approach used with the global shape, by designing a simple, parametric, flexible model to adjust to the contour. It is attached to the contour point detected as the base or apex and composed of two parametric Bzier curves that try to minimize the distance of their points to the contour. Figure <ref type="figure" coords="7,447.10,527.97,4.98,8.74">8</ref> shows examples of the evolution of these models.</p><p>The parameters used to build the necessary control points and optimized during the evolution, are also the descriptors we use to represent those shapes:</p><p>α, the global angle of the model o, the orientation angle relatively to the leaf axis -(α t1 ) l,r , for each side, the tangent angle at the tip point -(α t2 ) l,r , for each side, the tangent angle at the end point -(δ t1 ) l,r , for each side, the distance of the 1st control point from the tip -(δ t2 ) l,r , for each side, the distance of the 2nd control point from the end Fig. <ref type="figure" coords="8,155.98,253.29,4.46,8.77">8</ref>. Evolution of the base and apex models, based on the distance transform of the leaf contour</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Statistical Shape Descriptors</head><p>In addition to these dedicated descriptors, we also consider more generic shape features that could be apply basically to any kind of object. The moments are a popular choice for their invariance properties and have already been used in the context of leaf images <ref type="bibr" coords="8,255.38,346.29,15.50,8.74">[21,</ref><ref type="bibr" coords="8,270.88,346.29,11.62,8.74" target="#b11">12]</ref>. We computed the central moments on the segmented leaves and use them in combination with the other descriptors as a complementary shape representation, less directly pertinent but possibly more stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Feature Selection and Classification</head><p>Segmentation methods previously described enable us to build an ensemble of descriptors which defines the properties of the leaves. First, knowing this ensemble, we chose an appropriate classifier and we selected features that are strongly relevant for the classification, removing useless and noisy descriptors. We studied then the behavior of the selected classifier when its parameters vary. Plant identification was finally carried out using the optimized parameters of the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Particularity of the database</head><p>The extracted descriptors correspond to numerical properties of the images. It forms a vectorial data set that can be study in order to select a suitable classifier.</p><p>Let us first denote that the database may include noise, specially in the case of photographs, since the background images may contain colors quite similar to the leaves. Furthermore, the number of images per class is heterogeneous: some classes contain more than 200 objects whereas some are represented by less than 5 objects. This property can affect the efficiency of some classifiers. Finally, the difference between leaves for the same species are most of the time high. For example the shape or the color of a leaf can be different following its age or depending on the season the picture has been taken. As a result, there exists a large variation of the similarity within species. Conversely, a low variation between classes may happen, as some species have similar leaves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A random forest classification</head><p>Random forest, introduced by Breiman <ref type="bibr" coords="9,309.13,199.11,9.96,8.74" target="#b2">[3]</ref>, is a recent technique which consists in ensemble of decision trees using for the final prediction a majority vote. To build a decision tree in a random forest, a bootstrap sample of the data is used and at each node a set of random variable is selected to split on. This random sampling strategy makes increase the error of each tree and reduces the correlation between trees. As a consequence, the ensemble achieves both low variance and low bias <ref type="bibr" coords="9,231.71,270.84,9.96,8.74" target="#b2">[3]</ref>.</p><p>Random forest has shown high performances in many domains such as bioinformatics <ref type="bibr" coords="9,178.55,295.29,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="9,194.05,295.29,11.62,8.74" target="#b14">15,</ref><ref type="bibr" coords="9,205.67,295.29,7.75,8.74" target="#b6">7]</ref>, ecology <ref type="bibr" coords="9,256.28,295.29,15.50,8.74" target="#b15">[16]</ref> or computer vision <ref type="bibr" coords="9,361.20,295.29,14.61,8.74" target="#b16">[17]</ref>. This method is robust to noise and generalize correctly the class models, even when the database has few examples per class. We decided then to use this classifier for the task of plant identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Methodology</head><p>For the next experiments, we used as decision trees the CART algorithm with the gini impurity measure <ref type="bibr" coords="9,233.38,398.33,9.96,8.74" target="#b1">[2]</ref>. We chose to built 200 trees and we set the parameter mtry, i.e. the number of randomly selected variables at each split, to √ p (where p is the number of attributes), as it is the default value commonly used in the literature. In order to measure the accuracy of the random forest, a 3-fold cross validation is employed. The dataset Pl@ntLeaves II includes three types of leaves: the first one corresponds to compound leaves, the second and third ones to simple leaves with and without lobes. For each type of leaves, the number of attributes differs, as well as the importance of the attributes in the classification process. Thus, we decided to built three random forests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature selection</head><p>For simple leaves, we opted for the four following strategies:</p><p>-Strategy 1 consists in selecting the polygonal leaf model inducing the global shape model, the basal and apical estimations, as well as the attributes extracted from the CSS representation. -Strategy 2 includes the polygonal leaf model, the basal estimation, the apical estimation and the contour characterization with the Haralick descriptors. -Strategy 3 is a mix of the strategies 1 and 2.</p><p>-Strategy 4 includes the strategy 3 and the central moments.</p><p>Figures <ref type="figure" coords="10,185.71,119.99,13.28,8.74" target="#fig_7">9(a</ref>) and (b) present the results. We can remark that the Haralick descriptors applied on the contour of a leaf improve efficiently the classification. The strategy 4 corresponds to the best strategy for both types of simple leaves. We chose then this strategy for the rest of the experiments. Thus, 74 attributes are used for simple leaves with a unique lobe and 81 attributes for simple leaves with multiple lobes. For compound leaves, the previous models (i.e. the polygonal model, the basal and apical model, etc.) characterize a small region of the image corresponding to one leaflet. As the resolution is lower than for simple leaves, the attributes are less efficient. We decided then to automatically erase useless or noisy attributes.</p><p>Such task can be performed using the variable importance measure described in <ref type="bibr" coords="10,145.88,476.28,9.96,8.74" target="#b2">[3]</ref>. This measure consists in observing the variation of the accuracy when one variable of the dataset is randomly permuted. Figure <ref type="figure" coords="10,377.39,488.24,22.69,8.74" target="#fig_8">10(a)</ref> shows the results when the attributes from all the models are taken. We can observe the existence of a quite large amount of useless variables, since they are represented by low measures. We decided then to remove all the variables that have an importance close to 0.</p><p>As a result, we considered 6 strategies which always includes the compound model, the polygonal model and the basal and apical shape estimations:</p><p>-Strategy 1 is composed of the Haralick descriptors computed from the contour detection. -Strategy 2 corresponds to the strategy 1 with the add of the attributes extracted from the CSS representation. -Strategy 3 includes the strategy 2 and the central moments.</p><p>-Finally, the three last strategies consist in the three first strategies suppressing the noisy variables. Results are presented in figure <ref type="figure" coords="11,291.43,324.04,17.34,8.74" target="#fig_8">10(b</ref>). We can observe that deleting noisy variables leads most of the time towards better performances. We eventually chose the last strategy, ending up with 41 attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Setting final parameters for the random forest</head><p>In order to achieve good performances, a random forest needs to fine-tune its parameters. One of the most important to adjust is mtry, the number of variables selected randomly at a split. Figure <ref type="figure" coords="11,291.57,448.51,9.96,8.74" target="#fig_9">11</ref> presents the accuracy varying with mtry for simple leaves with a unique lobe. When mtry = 1 the strength (i.e. the accuracy) of each tree is low and the correlation between trees is minimal. As a consequence, the ensemble performance is low. Conversely, if mtry corresponds to the number of attributes, the decision trees of a random forest are built without randomness. Although the strength of each tree is high, the correlation between trees is quite important and induces low performances. Thus, we set mtry = 20 in order to have a good trade between strength and correlation. However, due to a lack of time when carrying out the experiments concerning this parameter, we chose for the contest to set mtry = √ 74 ≈ 9. The same reasoning has been achieved for the two other types of leaves, resulting in a selection of 16 attributes for simple leaves with several lobes and 15 attributes for compound leaves.</p><p>A second important parameter to fine-tune is the number of trees to build for a forest. This number must be high enough to decrease the variance, leading to stable and accurate results. However, the time execution increases with the number of trees. We decided then to set this parameter to 5000 for the three forests. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ImageCLEF Results</head><p>Three random forests are trained with the previous parameters and the whole dataset. As we only considered Angiosperm species, untreated leaves from the test set are assigned to Ginkgo biloba with a 100 percent confidence. For each leaf resting, a class probability is computed knowing the prediction of each tree of the forest. Results are presented table 1. Surprisingly, it shows better performances with pseudoscan images than scan images. This behavior has been observed by a quite important number of team. Thus, we suppose it is mostly due to the species presence in each type of images, as some class are more difficult to predict than others. In total, 33 runs were submitted by 11 groups. We achieved 4 th place for pseudoscan images and the 5 th place for scan and natural images. As a team, we rank third team for photographs. This last result is a good performance, since we concentrated our effort on photographs and we used a poor human supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>The results we obtained are satisfactory enough to validate our general approach. The investigation of morphological features that model explicitly the criteria used by botanists to identify trees proves to be a convincing way to treat the problem of plant identification. The role of segmentation still seems prevailing, and the performance on photographs, though being better than the average, underlines its importance.</p><p>A first implementation of our identification system on mobile devices has been engaged, with promising results, but not on as many species, leaving notably aside compound leaves. With the number of potential classes increasing, it will become a necessity to reduce the scope of the search, by making advantage of the GPS system that now exists in every smartphone. Fusing geographical information together with image based descriptors is the biggest challenge of our futur work. And knowing in advance which species are likely to be found in the geographical area where the user stands would be a decisive step towards a truly reliable identification.</p><p>The other prospect made possible by the use of high level descriptors will be the possibility of putting words on the extracted information. Explaining what the system understands and rendering it in a comprehensible form is a way to teach a non-specialist user what to look for, and could be used to implicate the user in the decision process by his intuitive corrections. All in all, such an explicative and interactive application would constitute a way not only to help recognize a plant, but to teach and transmit a rare knowledge.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,165.23,577.22,284.89,8.77;2,186.64,465.31,242.08,96.83"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Initial coloring on photograph images to locate leaf pixels</figDesc><graphic coords="2,186.64,465.31,242.08,96.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,313.73,345.83,8.77;3,134.77,325.72,345.82,8.74;3,134.77,337.68,296.17,8.74;3,144.38,214.96,103.75,68.99"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Combination of dissimilarity maps of a leaf image (a) obtained from linear regression (b) and local mean (c) color models : using Dempster-Shafer theory (d) compared to the mean distance (e) and the minimum (f)</figDesc><graphic coords="3,144.38,214.96,103.75,68.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.77,315.73,345.82,8.77;4,134.77,327.72,345.83,8.74;4,134.77,339.67,145.68,8.74;4,165.71,196.90,51.87,89.05"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Compound leaf model initialization (a) and evolution (c) based on the dissimilarity map (b); minimal and maximal estimations of the actual number and arrangement of leaflets (d, e)</figDesc><graphic coords="4,165.71,196.90,51.87,89.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,134.77,326.50,345.83,8.77;5,134.77,338.49,307.10,8.74;5,169.35,218.79,276.66,100.60"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Guided active contour results: polygonal model (left) initial contour (center left) guiding shape function (center right) and final contour (right)</figDesc><graphic coords="5,169.35,218.79,276.66,100.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,157.33,517.88,75.68,8.77;5,157.33,530.84,112.94,8.77;5,157.33,543.79,102.50,9.68;5,157.33,556.74,100.92,9.68;5,333.03,518.11,95.02,9.68;5,333.03,531.06,152.12,9.68;5,333.03,544.01,151.10,9.68;5,149.71,582.56,330.88,8.74;5,134.77,594.52,266.05,8.74;5,157.33,610.54,157.26,9.68;5,157.33,623.49,160.30,9.68;5,157.33,636.44,137.87,9.68;5,157.33,649.39,146.79,9.68;5,157.33,662.34,109.34,9.68;5,333.03,610.32,68.64,9.68;5,333.03,623.27,110.07,9.68;5,333.03,636.22,147.33,9.68;5,333.03,649.17,126.09,9.68;5,333.03,662.12,124.86,9.68"><head>-</head><label></label><figDesc>model width w model center position p model apex angle α A model base angle α B number of lobes n L length of each pair of lobes l L (i) angle of each pair of lobes α L (i) For compound leaves, we keep parameters from the compound leaf model, and those from the polygonal model extracted on one leaflet: minimal number of leaflets n F min maximal number of leaflets n F max position of the first leaflet h F average gap between leaflets g F distance to the axis d F leaflet size s F leaflet model width w F leaflet model center position p F leaf model apex angle α AF leaf model base angle α BF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,134.77,387.22,345.83,8.77;6,134.77,399.20,155.81,8.74;6,143.80,297.13,152.15,75.01"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Example of curvature-scale space transforms of two different contours (green square marks the first point)</figDesc><graphic coords="6,143.80,297.13,152.15,75.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,134.77,227.47,345.83,8.77;7,134.77,239.45,345.83,8.74;7,134.77,251.41,253.61,8.74;7,149.40,121.81,62.25,84.40"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Various leaf contours with detected base, tip, teeth and pits ; tip area in red, base area in dark blue ; convexities in orange, concavities in blue, brightness representing curvature intensity, extent representing scale.</figDesc><graphic coords="7,149.40,121.81,62.25,84.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="10,134.77,367.28,345.82,8.77;10,134.77,379.26,168.89,8.74"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Differences of accuracy for simple leaves with lobes (a) and without lobes (b) depending on the feature selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="11,134.77,271.55,345.82,8.77;11,134.77,283.54,168.89,8.74"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Variable importance for compound leaves (a) and difference of accuracy depending on the feature selection (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="12,178.84,270.16,257.69,8.77"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Accuracy vs mtry for simple leaves with one lobe.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="12,156.29,456.38,302.77,40.50"><head>Table 1 .</head><label>1</label><figDesc>Results using the average classification score of the contest.</figDesc><table coords="12,156.53,477.66,280.73,19.22"><row><cell>Run</cell><cell>Scan</cell><cell cols="3">Pseudoscan Photograph Average</cell></row><row><cell cols="2">LIRIS ReVeS run 01 0.42</cell><cell>0.51</cell><cell>0.33</cell><cell>0.42</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work has been supported by the <rs type="funder">French National Agency for Research</rs> with the reference <rs type="grantNumber">ANR-10-CORD-005</rs> (<rs type="projectName">REVES</rs> project).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_kFpDjCd">
					<idno type="grant-number">ANR-10-CORD-005</idno>
					<orgName type="project" subtype="full">REVES</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,381.49,337.64,7.86;13,151.52,392.45,329.07,7.86;13,151.52,403.41,329.07,7.86;13,151.52,414.37,76.86,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,347.22,392.45,133.37,7.86;13,151.52,403.41,184.10,7.86">Searching the world&apos;s herbaria: A system for visual identication of plant species</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sheorey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,356.29,403.41,124.30,7.86;13,151.52,414.37,48.70,7.86">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,425.56,322.75,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="13,203.75,425.56,134.47,7.86">Classification and regression trees</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,436.75,274.18,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,203.76,436.75,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,273.37,436.75,68.24,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,447.95,337.63,7.86;13,151.52,458.91,329.07,7.86;13,151.52,469.86,220.24,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,329.28,447.95,151.31,7.86;13,151.52,458.91,59.59,7.86">Plant species identification using leaf image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carmen</forename><surname>Aranda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,233.85,458.91,246.74,7.86;13,151.52,469.86,78.50,7.86">Proceedings of the ACM International Conference on Image and Video Retrieval</title>
		<meeting>the ACM International Conference on Image and Video Retrieval<address><addrLine>CIVR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,481.06,337.64,7.86;13,151.52,492.01,329.07,7.86;13,151.52,502.97,113.80,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,420.32,481.06,60.27,7.86;13,151.52,492.01,218.66,7.86">Guiding active contours for tree leaf segmentation and identification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tougne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,393.67,492.01,86.92,7.86;13,151.52,502.97,85.26,7.86">CLEF (Notebook Papers/Labs/Workshop)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,514.17,337.64,7.86;13,151.52,525.12,147.09,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,239.05,514.17,151.02,7.86">A generalization of bayesian inference</title>
		<author>
			<persName coords=""><forename type="first">Arthur</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,398.05,514.17,82.54,7.86;13,151.52,525.12,69.52,7.86">Journal of the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="205" to="247" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,536.32,337.64,7.86;13,151.52,547.27,245.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,294.41,536.32,186.19,7.86;13,151.52,547.27,100.27,7.86">Gene selection and classification of microarray data using random forest</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Díaz-Uriarte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">De</forename><surname>Andres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,259.43,547.27,80.46,7.86">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,558.47,337.63,7.86;13,151.52,569.43,238.87,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="13,186.07,569.43,175.40,7.86">The imageclef 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,580.62,337.63,7.86;13,151.52,591.58,329.07,7.86;13,151.52,602.53,178.26,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,374.46,580.62,106.13,7.86;13,151.52,591.58,329.07,7.86;13,151.52,602.53,49.02,7.86">An application of Random Forests to a genome-wide association dataset: Methodological considerations &amp; new findings</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barcellos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,208.39,602.53,55.11,7.86">BMC genetics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,613.73,337.98,7.86;13,151.52,624.68,329.07,7.86;13,151.52,635.64,82.42,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,392.85,613.73,87.74,7.86;13,151.52,624.68,141.97,7.86">Weed leaf image segmentation by deformable templates</title>
		<author>
			<persName coords=""><forename type="first">A.-G</forename><surname>Manh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rabatel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Assemat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-J</forename><surname>Aldon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,302.35,624.68,174.37,7.86">Journal of agricultural engineering research</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="146" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,646.84,337.98,7.86;13,151.52,657.79,329.07,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,272.88,646.84,207.72,7.86;13,151.52,657.79,76.60,7.86">Matching shapes with self-intersections: Application to leaf classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abbasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,234.46,657.79,158.22,7.86">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="653" to="661" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,120.67,337.98,7.86;14,151.52,131.63,329.07,7.86;14,151.52,142.59,177.24,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,315.46,120.67,165.14,7.86;14,151.52,131.63,155.56,7.86">A theory of multiscale, curvature-based shape representation for planar curves</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Mackworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,317.24,131.63,163.35,7.86;14,151.52,142.59,99.80,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="789" to="805" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,153.55,337.98,7.86;14,151.52,164.51,266.13,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,258.29,153.55,222.31,7.86;14,151.52,164.51,77.13,7.86">The detection of dominant points on digital curves by scale-space filtering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,236.12,164.51,78.16,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1307" to="1314" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,175.46,337.98,7.86;14,151.52,186.42,240.68,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,269.67,175.46,210.92,7.86;14,151.52,186.42,79.27,7.86">Automatic structure classification of small proteins using random forest</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pooja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jonathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,238.44,186.42,82.56,7.86">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">364</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,197.38,337.97,7.86;14,151.52,208.34,329.07,7.86;14,151.52,219.30,40.44,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,299.88,197.38,180.70,7.86;14,151.52,208.34,234.97,7.86">Newer classification and regression tree techniques: bagging and random forests for ecological prediction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Iverson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,393.13,208.34,43.50,7.86">Ecosystems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="199" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,230.26,337.97,7.86;14,151.52,241.22,329.07,7.86;14,151.52,252.18,65.41,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,321.58,230.26,159.01,7.86;14,151.52,241.22,24.97,7.86">Object class segmentation using random forests</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,194.02,241.22,282.64,7.86">Proceedings of the 19th British Machine Vision Conference (BMVC 08)</title>
		<meeting>the 19th British Machine Vision Conference (BMVC 08)<address><addrLine>Lake, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,263.14,337.98,7.86;14,151.52,274.09,20.99,7.86" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Glenn</forename><surname>Shafer</surname></persName>
		</author>
		<title level="m" coord="14,213.24,263.14,145.61,7.86">A Mathematical Theory of Evidence</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,285.05,337.98,7.86;14,151.52,296.01,306.46,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,262.07,285.05,214.56,7.86">On the detection of dominant points on digital curves</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,296.01,263.84,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,306.97,337.97,7.86;14,151.52,317.93,329.07,7.86;14,151.52,328.89,329.07,7.86;14,151.52,339.85,152.88,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,321.72,306.97,158.87,7.86;14,151.52,317.93,310.00,7.86">Leaf segmentation, its 3d position estimation and leaf classification from a few images with very close viewpoints</title>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-T</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,328.89,329.07,7.86;14,151.52,339.85,62.22,7.86">Proceedings of the 6th International Conference on Image Analysis and Recognition, ICIAR &apos;09</title>
		<meeting>the 6th International Conference on Image Analysis and Recognition, ICIAR &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="937" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,350.81,337.98,7.86;14,151.52,361.77,329.07,7.86;14,151.52,372.73,87.03,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,393.18,350.81,87.41,7.86;14,151.52,361.77,162.51,7.86">Classification of plant leaf images with complicated background</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Heutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,321.86,361.77,154.19,7.86">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="916" to="926" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
