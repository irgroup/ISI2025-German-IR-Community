<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.57,116.95,296.21,12.62;1,167.03,134.89,281.29,12.62">Lexical and Machine Learning approaches toward Online Reputation Management</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.64,173.00,45.94,8.74"><forename type="first">Chao</forename><surname>Yang</surname></persName>
							<email>chao-yang@uiowa.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Iowa</orgName>
								<address>
									<settlement>Iowa City</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.87,173.00,100.07,8.74"><forename type="first">Sanmitra</forename><surname>Bhattacharya</surname></persName>
							<email>sanmitra-bhattacharya@uiowa.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Iowa</orgName>
								<address>
									<settlement>Iowa City</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.37,173.00,84.35,8.74"><forename type="first">Padmini</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Iowa</orgName>
								<address>
									<settlement>Iowa City</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.57,116.95,296.21,12.62;1,167.03,134.89,281.29,12.62">Lexical and Machine Learning approaches toward Online Reputation Management</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">851AFE81E54F1F6DC08344DB1B9D11B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Polarity</term>
					<term>Ambiguity</term>
					<term>Company</term>
					<term>Twitter</term>
					<term>SentiWordNet</term>
					<term>Happiness Score</term>
					<term>Google Adwords</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the popularity of social media, people are more and more interested in mining opinions from it. Learning from social media not only has value for research, but also good for business use. RepLab 2012 had Profiling task and Monitoring task to understand the company related tweets. Profiling task aims to determine the Ambiguity and Polarity for tweets. In order to determine this Ambiguity and Polarity for the tweets in RepLab 2012 Profiling task, we built Google Adwords Filter for Ambiguity and several approaches like SentiWordNet, Happiness Score and Machine Learning for Polarity. We achieved good performance in the training set, and the performance in test set is also acceptable.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media has become an integral part of our everyday life. The increasing influence of social media on our daily life can be observed in various scenarios, ranging from gathering movie reviews <ref type="bibr" coords="1,297.42,477.79,10.52,8.74" target="#b0">[1]</ref> to understanding health beliefs <ref type="bibr" coords="1,441.48,477.79,11.31,8.74" target="#b1">[2]</ref> Given the number of online users voicing their personal opinion on various topics on social media streams such as Twitter, it's now feasible to aggregate opinions of the public to create meaningful inferences. Reputation management is one such area where public opinion towards a topic (such as a company or product) is aggregated. Traditional methods of reputation management are essentially based on word-of-mouth or surveys which are not only expensive but also time consuming. With the advent social media, reputation management can be done rapidly, more extensively and at a cheaper cost. The "evaluation campaign for Online Reputation Management Systems" or RepLab 2012, aimed towards this goal of aggregating public views on a company to see how a company (or it's products) are perceived among online users. The goal was also to gauge company strengths and weaknesses and most importantly, from the company's perspective, predict early threats to it's reputation and thereby neutralize them before they become widespread. Keeping this in mind, Replab 2012 had two tasks: Profiling task and Monitoring task using Twitter data.</p><p>Our group only participated in the Profiling task. Here systems were required to automatically work on two different aspects related to tweets: Ambiguity and Polarity. For Ambiguity one needs to judge if there is a relationship between the tweet and the company. For example, in the tweet "Apple May Legally Force Motorola To Destroy Their Phones http://nblo.gs/uFvFb", 'apple' refers to the company Apple, Inc. On the other hand, in the tweet "I need to get off the coffee and eat my apple and carrots.", 'apple' is a fruit. In this task, a tweet needs to be judged as relevant or irrelevant w.r.t. a company name. Polarity of a tweet is defined as the polarity w.r.t. the reputation of a company. For instance, the tweet "Lufthansa announces major expansion in Berlin with opening of new Brandenburg Airport in June 2012" entails a positive view towards the company 'Lufthansa', and hence has a positive influence on the company's reputation. On the contrary, the tweet "#Freedomwaves -latest report, Irish activists removed from a Lufthansa plane within the past hour." entails a negative view towards 'Lufthansa' and hence it may have negative influence on same company's reputation. As a third category, there can also be tweets that have neither positive nor negative influence on a company's reputation (e.g. "I'm at Lufthansa Aviation Center (LAC) (Airportring 1, Frankfurt am Main) w/ 2 others http://4sq.com/vTCDiA"). Such cases are identified as neutral. Participating systems are required to declare each tweet as positive, negative or neutral w.r.t. a company's reputation.</p><p>This paper describes our five run submissions. Run 1 and Run 2, we use the popular sentiment lexicon, SentiWordNet <ref type="bibr" coords="2,318.73,383.00,9.96,8.74" target="#b2">[3]</ref>, to identify the polarity of tweets. To determine the ambiguity of tweets, we use a Google AdWords<ref type="foot" coords="2,418.96,393.38,3.97,6.12" target="#foot_0">1</ref> filter in Run 1, while in Run 2 we treat all tweets as relevant to some companies. For Run 3 and Run 4, we used a Happiness lexicon (discussed later) to identify the polarity of tweets. Similar to Run 1, Run 3 also uses Google AdWords filter to judge the ambiguity tweets, while Run 4 treats all tweets as relevant to some companies. Finally, for Run 5, we again treat all the tweets as relevant to some companies, and use a machine learning approach to classify the polarity of test tweets. The classifier was built using all the tweets in training set.</p><p>Below we describe our Google AdWords filter for judging 'Ambiguity', Sen-tiWordNet and 'Happiness lexicon'-based approaches for polarity, and lastly our classifier-based approach for polarity. We conclude with a discussion of the performance of our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset Acquisition</head><p>Similar to the TREC Microblog track datasets, tweets about the various companies were not distributed directly due to Twitter's data sharing policies, but participating teams were given tweet IDs and associated information for accessing the tweets directly from Twitter. Tools for downloading the tweet contents from the Twitter servers were provided. However, this task proved to be challenging. Since Twitter data is dynamic (users may delete tweets or even delete accounts), this resulted in differences in datasets collected by the different participating research groups at different times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Statistics</head><p>The training set comprised of 300 tweets each for 6 companies. Table <ref type="table" coords="3,446.46,185.55,4.98,8.74" target="#tab_0">1</ref>  The null tweets are the ones which could not be obtained from Twitter because of the aforementioned problem (Section 2). In the training set, most of the tweets are relevant to the company. Armani has the most non-relevant tweets which are only 21. English tweets dominate the training set except the tweets for Apple. We also observed the there are not too many negative tweets for each company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Google AdWords Filter For 'Ambiguity'</head><p>Analysis of Tweets in Training Set Before developing methods to determine the ambiguity of tweets we manually look through the tweets in training set. Basically, we found the tweets for 'Apple' are judged as relevant or non-relevant mostly by the following factors shown in Table <ref type="table" coords="3,341.96,561.47,3.87,8.74" target="#tab_1">2</ref>.</p><p>This table shows the various factors we found in training set that could differentiate the 'Ambiguity' for Apple Inc. So our hypothesis for determining 'Ambiguity' for a company is: if a tweets has one or more keywords related to company factors, it is labeled as relevant. Otherwise, it is labeled as non-relevant.</p><p>It is true that different companies have different factors. But generally, there are some common company factors: specific products, generic products, competitors, official tweet account name, company name hashtag, company leaders, and official website. Automatically acquiring company factors for each company is not a trivial task. In this paper we propose a new method for getting the company factors, using Google AdWords Keyword Tool <ref type="bibr" coords="4,299.54,318.14,12.24,8.74" target="#b3">[4]</ref>. Google AdWords Keyword Tool is a service from Google to help advertisers choose a few search terms related to their business. The keywords are the most frequent searched words by the internet users. Using the Keyword Tool, we can easily get the popular products for the company, generic products, and other company related terms.</p><p>Table <ref type="table" coords="4,176.71,377.91,4.98,8.74" target="#tab_2">3</ref> shows the top 20 out of 787 English Google AdWords for Apple, Inc. collected on Jun. 6th 2012 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank Keyword</head><p>Rank Although there are some keywords maybe mentioned the same product, for example 'apple iphone', 'apple i phones'. But in total number of 787 keywords, they covered most of the popular products and Apple Inc. related keywords.</p><p>We developed two strategies to match the keywords. In the first strategy (Filter 1) we determine if a tweet has a whole keyword or not. In the second strategy (Filter 2) we determine if the tweet has one or more tokens of the keywords. Both strategies we exclude company's name in the keywords. For example, 'iphone 4' is a keyword for Apple Inc. The tweet 'I love iphone', it doesn't contain the whole keyword. Hence by Filter 1 it is considered irrelevant while by Filter 2 it considered relevant.</p><p>Flow Chart of Google AdWords Filter Figure <ref type="figure" coords="5,359.94,182.64,4.98,8.74" target="#fig_0">1</ref> shows the flowchart of our Google AdWords Filter. For one company, we use the company name or website as the search query to extract both English and Spanish keywords. So we have 4 lists of keywords for one company. Then we merge them into one large list, and also automatically add the Twitter account and hashtag for this company. For example, we can add '@apple' and '#apple' as the official account and hashtag for Apple Inc. Finally, if the tweet has one and more keywords, it is labeled as relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SentiWordNet Approach For Polarity</head><p>Although polarity for reputation is substantially different from standard sentiment analysis, it does have some similarity. The polarity of a tweet is, in essence, expressed using certain sentiment-loaded keywords. For instance, in the tweet 'Lehmann Brothers goes bankrupt', the word 'bankrupt' has a negative polarity for reputation. Thus, if we can determine the polarity for each word in tweet, we may be able to determine the polarity of tweet.</p><p>SentiWordNet Since there is no specific polarity scores list for words to determine the polarity of reputation, so we decided to use SentiWordNet to get the polarity of individual words. SentiWordNet is a lexical resource for sentiment analysis and opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity. That is, SentiWordNet has a list of negative and positive scores for words. One word may have several negative and positive scores in different cases. Table <ref type="table" coords="5,383.40,468.22,4.98,8.74">4</ref> shows an example of 'bankrupt'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>POS &amp; ID Word</head><p>PosScore NegScore n 09838370 bankrupt#1 0 -0.625 v 02318165 bankrupt#1 0 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4. Example of 'bankrupt' in SentiWordNet</head><p>The pair (POS &amp; ID) uniquely identifies a WordNet (3.0) synset. Because the word 'bankrupt' has 2 cases in SentiWordNet, we calculate an average PosScore and NegScore for this word.</p><p>To determine the polarity for the tweet we use two strategies. Both strategies assign an polarity score for a tweet, then use two thresholds to determine the polarity of the tweet.</p><p>In the first strategy (MaxS) we use the maximum SentiWordNet scores among all the words to determine the polarity of tweets. Here we find the maximum PosScore and NegScore for each word of the tweet first. For example, in the tweet 'Lehmann Brothers goes bankrupt', after excluding the company name, 'bankrupt' has the maximum NegScore and 'goes' has the maximum PosScore. So the sum of these scores are the polarity score for the tweet.</p><p>In the second strategy (SumS) we use the sum of SentiWordNet scores of all the words. For example, again in 'Lehmann Brothers goes bankrupt', after excluding the company name, the sum of PosScores and NegScores of 'goes' and 'bankrupt', becomes the polarity score of the tweet.</p><p>Thus, both of the strategies give polarity score for each tweet. We then set two fixed thresholds: positive threshold and negative threshold. If the polarity score is larger than positive threshold, we claim the tweet is positive. If the polarity score is smaller than negative threshold, we claim the tweet is negative. Otherwise, the tweet is neutral. For Spanish tweets, we use Google Translate<ref type="foot" coords="6,476.12,285.82,3.97,6.12" target="#foot_1">2</ref> to translate all the words in SentiWordNet to Spanish words. Then we use the translated Spanish SentiWordNet to determine the polarity of Spanish tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Happiness Score Approach For Polarity</head><p>In addition to the SentiWordNet score, we also tried another approach to determine the polarity of words in a tweet. Happiness score <ref type="bibr" coords="6,380.61,373.25,12.29,8.74" target="#b4">[5]</ref> which developed by Dodds et al by crowdsourcing. It has a list of words. Each word is associated with a score to indicate the happiness of this word.</p><p>We use similar strategy with MaxS, using Happiness scores instead of using SentiWordNet scores. Firstly, we get the maximum Happiness score among all the tokens in tweet. Then we denote it as the polarity score for this tweet. Finally we set two threshold to determine the polarity of the tweet. We denote this approach as HappyS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Machine Learning Approach For Polarity</head><p>Instead of SentiWordNet and Happiness score approaches for polarity, we also developed a machine learning approach. Figure <ref type="figure" coords="6,343.49,518.90,4.98,8.74" target="#fig_1">2</ref> shows the flowchart of Classifier. We take all the labeled tweets from the 6 companies (6 * 300 = 1800 tweets) and search for the Google AdWords and replace them with 'xxxx', also replace the company names with 'aaaa'. Then split this set into 2 parts by English and Spanish tweets. Build 2 separate classifiers one for English and other for Spanish. To evaluated the performance of the Classifier Approach, we train the classifiers using the training tweets from 5 companies and test on the remaining company tweets in the training set. Repeat this 6 times such that it covers all possibilities.</p><p>Especially, we use Weka <ref type="bibr" coords="6,249.67,614.56,14.59,8.74" target="#b5">[6]</ref> to test the performance of classifier. We use Bagging <ref type="bibr" coords="6,151.21,626.51,12.34,8.74" target="#b6">[7]</ref> classifier with SVM <ref type="bibr" coords="6,249.76,626.51,16.33,8.74" target="#b7">[8]</ref> kernel (SMO <ref type="bibr" coords="6,322.40,626.51,15.77,8.74" target="#b8">[9]</ref> in weka). We extract unigram, bigram and 3-gram features for the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Performance of Google AdWords Filter in Training Set</head><p>Tables <ref type="table" coords="7,166.09,164.41,4.98,8.74" target="#tab_3">5</ref> and<ref type="table" coords="7,193.77,164.41,4.98,8.74" target="#tab_4">6</ref> show the performance of Filters 1 and 2 on the training set. We used precision, recall and F-score to evaluate the performance on the training set. Especially, we use average F-score (avgF) to evaluate the overall performance. We see that Filter 2 has better performance with not only higher avgF, but also all F-scores for every company are higher except for Armani. The reason is because, as expected, the Google Adwords keywords do not cover all the company factors. For example, 'ios 5' is a Adwords keyword for Apple Inc, but 'ios' is not. Filter 2, which favors more relaxed filtering covers more cases resulting in better performance. Therefore, we use Filter 2 for our submitted runs on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance of SentiWordNet and Happiness Score Approach in Training Set</head><p>Table <ref type="table" coords="7,162.16,573.31,4.98,8.74" target="#tab_5">7</ref> shows the performance of MaxS, SumS and HappyS. avgF is the average F-score of Positive F-score, Neutral F-score, Negative F-score for the six companies in training set. The thresholds are automatically generated by script.</p><p>In the table, MaxS has better performance in English tweets. While HappyS has better performance in Spanish tweets. So we decided to use MaxS and Hap-pyS in the submit runs. In addition, we can see that all the avgF is just around 0.3, which indicate the polarity task is difficult. Basically, Classifier Approach performance worse than SentiWordNet and Happiness score approach. None of the 4 avgF is above 0.3. We also tried using the webpage content linked in tweet, but the performance get worse. The reason is that the polarity of tweets can be expressed by so many ways, we need much more training tweets in order to get better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MaxS</head><p>Thus we denote classifier using 3-gram feature as Cla3. And use it in our submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submit Runs Description</head><p>We submitted five runs which has different combination of our 'Ambiguity' Approach and Polarity Approach. We denote 'AllRel' as treat all the tweets relevant for some companies. Table <ref type="table" coords="8,253.35,514.98,4.98,8.74" target="#tab_7">9</ref>  We describe the performance of test set separately by Filtering ('Ambiguity') and Polarity tasks. In Filtering task, our Run1 and Run 3 ranked in 7th and 8th place out of 33 runs, (5th of 9 teams) by F(R,S) score <ref type="bibr" coords="9,392.65,166.92,15.97,8.74" target="#b9">[10]</ref>. R and S refers Reliability and Sensitivity respectively. Because we treat all the tweets relevant in Run2, Run4, and Run5. They have the same results with the baseline (all relevant). Table <ref type="table" coords="9,177.11,214.74,9.96,8.74" target="#tab_8">10</ref> shows the top 10 results of Filtering task. One of the reason the test set results is not as good as training set is because some of the companies in test set do not have ambiguity. For example, if a tweet has Google or Microsoft in it. It definitely relevant with the company it mentioned. The right thing to do is to determine if the company has ambiguity.</p><p>If not, we should treat all the tweets as relevant.</p><p>In Polarity task, our Run2 ranked in 4th place out of 31 runs, (4th of 9 teams) by F(R,S) score. The result shows using SentiWordNet approach is better than Happniess score and Classifier approach.</p><p>Table <ref type="table" coords="9,176.75,519.42,9.96,8.74" target="#tab_0">11</ref> shows the top 10 results of Polarity task and all of our other Runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In RepLab 2012, we explored using Google AdWords as a filter to determine the ambiguity of tweets. We also developed several approaches like SentiWordNet, Happiness Score, Classifier to determine the polarity of tweets. The results in test set shown our approaches performed well. However, our research still has some limitations. Google AdWord does provide great company related keywords, but it is not free service. We didn't received approve from Google to use AdWord API before submitting the result. So we manually downloaded the English and Spanish keyword list searched by company name as query. The limitation of queries  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="12,203.91,299.14,207.54,7.89;12,134.77,179.21,345.83,105.16"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The Flow Chart for Google AdWords Filter</figDesc><graphic coords="12,134.77,179.21,345.83,105.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="12,206.91,593.65,201.53,7.89;12,134.77,439.75,345.83,139.12"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The Flow Chart for Classifier For Polarity</figDesc><graphic coords="12,134.77,439.75,345.83,139.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,185.55,345.82,172.54"><head>Table 1 .</head><label>1</label><figDesc>shows the statistics of the training set. Statistics of Training Set</figDesc><table coords="3,165.85,230.30,283.66,106.92"><row><cell>Company</cell><cell cols="6">apple lufthansa alcatel armani barclays marriott</cell></row><row><cell cols="2">Total Tweets 300</cell><cell>300</cell><cell>300</cell><cell>300</cell><cell>300</cell><cell>300</cell></row><row><cell>Relevant</cell><cell>281</cell><cell>299</cell><cell>289</cell><cell>179</cell><cell>298</cell><cell>294</cell></row><row><cell cols="2">Non-relevant 19</cell><cell>1</cell><cell>11</cell><cell>21</cell><cell>2</cell><cell>6</cell></row><row><cell cols="2">Null Tweets 33</cell><cell>37</cell><cell>32</cell><cell>92</cell><cell>16</cell><cell>46</cell></row><row><cell>English</cell><cell>74</cell><cell>228</cell><cell>236</cell><cell>270</cell><cell>292</cell><cell>285</cell></row><row><cell>Spanish</cell><cell>226</cell><cell>72</cell><cell>64</cell><cell>30</cell><cell>8</cell><cell>15</cell></row><row><cell>Positive</cell><cell>70</cell><cell>242</cell><cell>221</cell><cell>24</cell><cell>248</cell><cell>94</cell></row><row><cell>Neutral</cell><cell>195</cell><cell>35</cell><cell>64</cell><cell>155</cell><cell>24</cell><cell>192</cell></row><row><cell>Negative</cell><cell>18</cell><cell>20</cell><cell>4</cell><cell>5</cell><cell>27</cell><cell>11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,136.16,119.75,346.36,139.15"><head>Table 2 .</head><label>2</label><figDesc>Factors to Differentiate 'Ambiguity'</figDesc><table coords="4,136.16,119.75,346.36,118.28"><row><cell></cell><cell>Factors</cell><cell>Example</cell></row><row><cell cols="2">Apple as Company Specific products</cell><cell>iTunes, Apple TV, iPad, etc.</cell></row><row><cell></cell><cell>Generic products</cell><cell>phone, tablet, etc.</cell></row><row><cell></cell><cell>Apps &amp; Music</cell><cell>Angry Birds, etc.</cell></row><row><cell></cell><cell cols="2">Competitors &amp; their products Samsung, HTC, etc</cell></row><row><cell></cell><cell>Leader name</cell><cell>Steve Jobs</cell></row><row><cell></cell><cell>Company related term</cell><cell>products, trademark dispute</cell></row><row><cell>Apple as Fruit</cell><cell>Verb.</cell><cell>eat</cell></row><row><cell></cell><cell>Detail fruit related term</cell><cell>apple sauce, apple soup, pie, etc.</cell></row><row><cell></cell><cell>Generic fruit related term</cell><cell>fruit, food, etc.</cell></row><row><cell></cell><cell>Other fruits</cell><cell>banana</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,196.90,421.03,221.56,138.75"><head>Table 3 .</head><label>3</label><figDesc>Top 20 Google AdWords for Apple Inc.</figDesc><table coords="4,339.79,421.03,41.71,7.89"><row><cell>Keyword</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,156.15,197.86,303.06,160.62"><head>Table 5 .</head><label>5</label><figDesc>Performance of Filter 1 on Training Set</figDesc><table coords="7,156.15,197.86,303.06,160.62"><row><cell></cell><cell cols="4">Apple Lufthansa Alcatel Armani Barclays Marriott Avg.</cell></row><row><cell cols="2">Precision 0.9785 0.9955</cell><cell>1</cell><cell>0.9572 1</cell><cell>1</cell></row><row><cell>Recall</cell><cell>0.8114 0.7425</cell><cell cols="2">0.9204 0.9040 0.9161</cell><cell>0.6938</cell></row><row><cell cols="2">F-score 0.8872 0.8506</cell><cell cols="2">0.9586 0.9299 0.9562</cell><cell>0.8193</cell><cell>0.9003</cell></row><row><cell></cell><cell cols="4">Apple Lufthansa Alcatel Armani Barclays Marriott Avg.</cell></row><row><cell cols="2">Precision 0.9710 0.9963</cell><cell>1</cell><cell>0.9171 1</cell><cell>1</cell></row><row><cell>Recall</cell><cell>0.9537 0.9097</cell><cell cols="2">0.9516 0.9274 0.9664</cell><cell>0.7891</cell></row><row><cell cols="2">F-score 0.9623 0.9510</cell><cell cols="2">0.9752 0.9222 0.9829</cell><cell>0.8821</cell><cell>0.9460</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,207.65,371.46,200.05,7.89"><head>Table 6 .</head><label>6</label><figDesc>Performance of Filter 2 on Training Set</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,134.77,118.75,328.06,190.57"><head>Table 7 .</head><label>7</label><figDesc>Performance of MaxS and SumS in Training Set5.3 Performance of Machine Learning Approach in Training SetTable8shows the performance of the classifier.</figDesc><table coords="8,200.40,118.75,214.56,190.57"><row><cell></cell><cell></cell><cell>SumS HappyS</cell></row><row><cell></cell><cell cols="2">En Es En Es En Es</cell></row><row><cell>avgF</cell><cell cols="2">0.34 0.31 0.336 0.30 0.27 0.35</cell></row><row><cell cols="3">Positive threshold 0.62 1.26 0.34 4.08 23.4 27.3</cell></row><row><cell cols="3">Negative threshold -0.3 -0.83 -2.59 -1.11 16.1 16.7</cell></row><row><cell cols="3">Classifier (En) Classifier (Es)</cell></row><row><cell cols="3">unigram 3-gram unigram 3-gram</cell></row><row><cell>avgF 0.264</cell><cell>0.269</cell><cell>0.259 0.273</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,184.49,322.30,246.38,7.89"><head>Table 8 .</head><label>8</label><figDesc>Performance of Classifier Approach in Training Set</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,224.91,514.98,215.17,116.79"><head>Table 9 .</head><label>9</label><figDesc>shows the detail of the five different runs Description of Submitted Runs 7 Performance of Test Set</figDesc><table coords="8,252.67,547.82,110.02,63.08"><row><cell cols="2">Run ID Description</cell></row><row><cell>Run1</cell><cell>Filter2 + MaxS</cell></row><row><cell>Run2</cell><cell>AllRel + MaxS</cell></row><row><cell>Run3</cell><cell>Filter2 + HappyS</cell></row><row><cell>Run4</cell><cell>AllRel + HappyS</cell></row><row><cell>Run5</cell><cell>AllRel + Cla3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,136.16,248.63,355.43,139.25"><head>Table 10 .</head><label>10</label><figDesc>Top 10 Runs of Filtering Task by F(R,S) Score</figDesc><table coords="9,136.16,248.63,355.43,117.88"><row><cell>Run ID</cell><cell>F(R,S)</cell><cell>R</cell><cell>S</cell><cell>Accuracy</cell></row><row><cell>replab2012 related Daedalus 2</cell><cell cols="4">0.263922126 0.243482396 0.432991032 0.722763591</cell></row><row><cell>replab2012 related Daedalus 3</cell><cell cols="4">0.253463929 0.235162463 0.422129397 0.702232013</cell></row><row><cell>replab2012 related Daedalus 1</cell><cell cols="4">0.250619268 0.23968238 0.403657787 0.718006364</cell></row><row><cell>replab2012 related CIRGDISCO 1</cell><cell cols="4">0.227595261 0.217923478 0.336440429 0.701870318</cell></row><row><cell>replab2012 profiling kthgavagai 1</cell><cell cols="4">0.222829043 0.253419399 0.357636447 0.774061038</cell></row><row><cell>replab2012 profiling OXY 2</cell><cell cols="4">0.196601614 0.234666227 0.272356458 0.809025193</cell></row><row><cell cols="5">replab2012 profiling uiowa 1 (Run1) 0.177919294 0.181556704 0.292220139 0.679680848</cell></row><row><cell cols="5">replab2012 profiling uiowa 3 (Run3) 0.177919294 0.181556704 0.292220139 0.679680848</cell></row><row><cell>replab2012 profiling ilps 4</cell><cell cols="4">0.15730978 0.157010828 0.223508777 0.599100149</cell></row><row><cell>replab2012 profiling ilps 3</cell><cell cols="4">0.155698416 0.155160491 0.25552382 0.657567983</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.79,117.11,7.86"><p>https://adwords.google.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.73,657.79,86.85,7.86"><p>translate.google.com/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.35,469.74,342.24,7.86;10,146.91,480.70,49.68,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,310.03,469.74,165.99,7.86">Predicting the Future with Social Media</title>
		<author>
			<persName coords=""><forename type="first">Asur</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huberman</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010-03">March 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,491.91,342.24,7.86;10,146.91,502.87,333.68,7.86;10,146.91,513.83,224.61,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,457.93,491.91,22.66,7.86;10,146.91,502.87,100.93,7.86">Belief Surveillance with Twitter</title>
		<author>
			<persName coords=""><forename type="first">Bhattacharya</forename><surname>Sanmitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tran</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Srinivasan</forename><surname>Padmini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suls</forename><surname>Jerry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,266.16,502.87,214.43,7.86;10,146.91,513.83,64.71,7.86">Proceedings of the Fourth ACM Web Science Conference (WebSci12)</title>
		<meeting>the Fourth ACM Web Science Conference (WebSci12)<address><addrLine>Evanston, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">5558</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,525.04,342.24,7.86;10,146.91,535.99,333.68,7.86;10,146.91,546.95,234.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,288.52,525.04,192.07,7.86;10,146.91,535.99,110.84,7.86">Sentiwordnet: A Publicly Available Lexical Resource For Opinion Mining</title>
		<author>
			<persName coords=""><forename type="first">Esuli</forename><surname>Andrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sebastiani</forename><surname>Fabrizio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,279.57,535.99,201.02,7.86;10,146.91,546.95,142.85,7.86">Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06</title>
		<meeting>the 5th Conference on Language Resources and Evaluation (LREC06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">417422</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,558.16,329.62,7.86;10,146.91,569.12,133.01,7.86" xml:id="b3">
	<monogr>
		<ptr target="http://support.google.com/adwords/bin/answer.py?hl=enanswer=147602" />
		<title level="m" coord="10,146.91,558.16,124.83,7.86">Google Adwords Keyword Tool</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,580.33,342.24,7.86;10,146.91,591.29,333.68,7.86;10,146.91,602.25,182.41,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,442.17,580.33,38.42,7.86;10,146.91,591.29,333.68,7.86;10,146.91,602.25,47.05,7.86">Temporal Patterns of Happiness and Information in A Global Social Network: Hedonometrics and Twitter</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">M</forename><surname>Kloumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Bliss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Danforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,201.21,602.25,42.01,7.86">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">26752</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,613.46,342.24,7.86;10,146.91,624.42,333.68,7.86;10,146.91,635.38,80.96,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,225.08,624.42,181.29,7.86">The Weka Data Mining Software: An Update</title>
		<author>
			<persName coords=""><forename type="first">Hall</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Eibe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pfahringer</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Reutemann</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Witten</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,414.08,624.42,66.52,7.86;10,146.91,635.38,26.49,7.86">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,646.58,235.51,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,195.58,646.58,75.47,7.86">Bagging Predictors</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,278.10,646.58,67.82,7.86">Machine learning</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,657.79,322.16,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,200.41,657.79,168.91,7.86">The Nature of Statistical Learning Theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>HeidelbergA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,120.67,342.24,7.86;11,146.91,131.63,333.68,7.86;11,146.91,142.59,200.71,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,204.98,120.67,275.60,7.86;11,146.91,131.63,51.51,7.86">Fast Training of Support Vector Machines Using Sequential Minimal Optimization</title>
		<author>
			<persName coords=""><forename type="first">Platt</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,431.72,131.63,48.87,7.86;11,146.91,142.59,172.42,7.86">Advances in Kernel Methods -Support Vector Learning</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,153.55,337.98,7.86;11,146.91,164.51,333.67,7.86;11,146.91,175.46,333.68,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,370.63,153.55,109.97,7.86;11,146.91,164.51,257.99,7.86">Reliability and sensitivity: Generic Evaluation Measures For Document Organization Tasks</title>
		<author>
			<persName coords=""><forename type="first">Amigo</forename><surname>Enrique</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gonzalo</forename><surname>Julio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Verdejo</forename><surname>Felisa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Madrid, Spain</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Departamento de Lenguajes y Sistemas Informaticos, UNED</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
