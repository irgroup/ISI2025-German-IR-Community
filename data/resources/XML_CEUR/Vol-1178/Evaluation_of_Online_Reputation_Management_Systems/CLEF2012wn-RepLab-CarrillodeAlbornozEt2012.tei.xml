<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.46,116.95,330.44,12.62;1,153.33,134.89,308.71,12.62;1,268.05,152.82,79.25,12.62">Using an Emotion-based Model and Sentiment Analysis Techniques to Classify Polarity for Reputation</title>
				<funder ref="#_xG3E5pu">
					<orgName type="full">European Unions</orgName>
				</funder>
				<funder ref="#_S2QvtdU">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.10,190.49,116.48,8.74"><forename type="first">Jorge</forename><surname>Carrillo De Albornoz</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.25,190.49,54.26,8.74"><forename type="first">Irina</forename><surname>Chugur</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,379.22,190.49,66.04,8.74"><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
							<email>enrique@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.46,116.95,330.44,12.62;1,153.33,134.89,308.71,12.62;1,268.05,152.82,79.25,12.62">Using an Emotion-based Model and Sentiment Analysis Techniques to Classify Polarity for Reputation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8821AC230FB94B474BA20DCF41755321</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Online Reputation Management</term>
					<term>Polarity for Reputation</term>
					<term>Sentiment Analysis</term>
					<term>Emotions</term>
					<term>Word Sense Disambiguation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Online Reputation Management is a novel and active area in Computational Linguistics. Closely related to opinion mining and sentiment analysis, it incorporates new features to traditional tasks like polarity detection. In this paper, we study the feasibility of applying complex sentiment analysis methods to classifying polarity for reputation. We adapt an existing emotional concept-based system for sentiment analysis to determine polarity of tweets with reputational information about companies. The original system has been extended to work with texts in English and in Spanish, and to include a module for filtering tweets according to their relevance to each company. The resulting UNED system for profiling task participated in the first RepLab campaign. The experimental results prove that sentiment analysis techniques are a good starting point for creating systems for automatic detection of polarity for reputation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Part of eMarketing, Online Reputation Management (ORM) has already become an essential component of corporate communication for public figures and large companies <ref type="bibr" coords="1,183.03,520.00,14.61,8.74" target="#b13">[14]</ref>. Being absolutely vital to maintain the good name and preserve the "reputational capital", ORM comprises activities that aim at building, protecting and repairing the image of people, organizations, products, or services.</p><p>In order to study a brand image, reputation management consultancies perform two main tasks: monitoring and profiling. As its name suggests, the former consists in a constant (daily) monitoring of online media, seeking and analysing information related to the entity, with the objective of detecting any topic that might damage its image. In contrast, profiling refers to a single or periodic (e.g., monthly) revision of a company's reputation as it distils from news, opinions and comments expressed in social media or online press. Unlike monitoring, which is essentially a real-time problem, profiling is a static study of opinions and polar facts concerning a certain entity and extracted for a given period. Normally, this information is contrasted with what has been said in the same period of time about the company's potential competitors, and with the opinions about the entity in earlier periods of time. These practical scenarios have been adopted as tasks for RepLab 2012, the first evaluation campaign for ORM systems <ref type="foot" coords="2,442.15,178.19,3.97,6.12" target="#foot_0">1</ref> . In this paper, we will focus exclusively on the profiling task.</p><p>Although for reputation analysts profiling implies a complex of subtasks such as identifying the dimension of the entity's activity affected by a given content, detecting opinion targets and determining the type of opinion holder<ref type="foot" coords="2,432.31,226.95,3.97,6.12" target="#foot_1">2</ref> , the basis of adequate profiling is undoubtedly an effective named entity disambiguation and detection of polarity for reputation. The system described in the present paper centres precisely on the problem of classifying tweets into related and unrelated with respect to a given company (filtering) and on determining the polarity of tweets based on the emotion concepts they contain. Some tasks considered in profiling are similar to the research problems in opinion mining and sentiment analysis that comprise subjectivity detection <ref type="bibr" coords="2,465.09,313.14,15.50,8.74" target="#b21">[23,</ref><ref type="bibr" coords="2,134.77,325.09,12.73,8.74" target="#b18">19,</ref><ref type="bibr" coords="2,149.16,325.09,11.62,8.74" target="#b15">16]</ref>, polarity classification <ref type="bibr" coords="2,268.03,325.09,15.50,8.74" target="#b17">[18,</ref><ref type="bibr" coords="2,285.19,325.09,12.73,8.74" target="#b20">21,</ref><ref type="bibr" coords="2,299.58,325.09,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,313.97,325.09,12.73,8.74" target="#b22">24]</ref> and intensity classification <ref type="bibr" coords="2,455.69,325.09,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="2,472.85,325.09,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="2,134.77,337.05,11.62,8.74" target="#b23">25]</ref>, among others. Although opinion mining has made significant advances in the last years, most of the work has been focused on products. However, mining and interpreting opinions about companies and individuals generally is a harder and less understood problem, since unlike products or services, opinions about people and organizations cannot be structured around any fixed set of features or aspects, requiring a more complex modelling of these entities.</p><p>Identifying polarity of a given content, ORM system should assess if it has negative, positive or neutral effect on the company's image. Again, this problem is related to sentiment analysis and opinion mining, but significantly differs from the mainstream research in these areas. First of all, what is analysed are not only opinions, subjective content, but also facts, and more to the point, polar facts, i.e. objective information that might have negative or positive implications for the company's reputation. This means that ORM systems have to be able to detect polarity also in non-opinionated texts. On the second place, focus or perspective plays sometimes a decisive role, since the same information may be negative from the point of view of clients and positive from the point of view of investors. We will refer to this complex notion of polarity with the term polarity for reputation.</p><p>In this paper, we study the feasibility of using complex sentiment analysis approaches to classifying polarity for reputation. To this end, as exposed in Section 2, we adapt an existing emotional concept-based system for sentiment analysis to classify tweets with reputation information about companies. The system is also extended to filter tweets according to their relevance to each company and works with texts both in English and in Spanish. It is worthy to mention that one of the applied approaches combines our runs with the algorithm provided by Barcelona Media (see Section 3). Our experimental results, described in detail in Section 4, demonstrate that sentiment analysis techniques are a good starting point to process and classify online reputation information. Finally, after a brief discussion of the obtained results (see Section 5), we outline some lines for future work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">An emotional concept-based approach for polarity for reputation</head><p>As mentioned above, our main concern is to analyze the applicability of sentiment analysis techniques for classifying the polarity of reputation information. To this aim, we have adapted the approach presented in <ref type="bibr" coords="3,354.58,284.94,10.52,8.74" target="#b5">[6]</ref> for polarity and intensity classification of opinionated texts. The main idea of this method is to extract the WordNet concepts in a sentence that entail an emotional meaning, assign them an emotion within a set of categories from an affective lexicon, and use this information as the input of a machine learning algorithm. The strengths of this approach, in contrast to other more simple strategies, are: (1) use of WordNet and a word sense disambiguation algorithm, which allows the system to work with concepts rather than terms, (2) use of emotions instead of terms as classification attributes, and (3) processing of negations and intensifiers to invert, increase or decrease the intensity of the expressed emotions. This system has been shown to outperform previous systems designed for the same task. For filtering, we have implemented a simple approach based on a vote mechanism and contextual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Filtering</head><p>In order to determine if a text is related to a given entity we have implemented a simple vote mechanism that calculates a score depending on how many entity context words are found in the input text. The entity context is obtained from the entity website and from the entity entry in Wikipedia, as provided by RepLab.</p><p>An input text is determined as related or not to a given entity when the final score is upper a certain threshold. Different thresholds have been evaluated, changing from the simple presence of the search query to mentions of the complete entity name or to the presence of more entity context words. Our main objective for this approach is to determine if a simple method of word presence is able to correctly determine the relatedness of the text to a given entity. It is also important to highlight the complexity of the task, since even for humans it is often difficult to decide if a text is ambiguous or not with the respect to a given entity due to the lack of context in the input text. This problem is more evident in microblogging systems such as Twitter, where the text of the post is limited to 140 characters. As a first step, the system pre-processes each input text splitting it in sentences and isolating the tokens of each sentence using the GATE architecture <ref type="bibr" coords="3,470.08,657.11,10.52,8.74" target="#b8">[9]</ref> for English and the FreeLing library for Spanish <ref type="bibr" coords="4,346.35,119.99,9.96,8.74" target="#b4">[5]</ref>. In the same way, the entity contexts, i.e. the entity website and the Wikipedia entry, are also pre-processed. Besides, in this pre-processing step all stop words and symbols included in the input text and the entity contexts are removed to reduce noise. Finally, the search query and the complete entity name from the RepLab 2012 data set are retrieved and preprocessed. The score for an input is calculated using four rules:</p><p>-Rule I: If a text contains the complete entity name, the highest score, 0.75, is added to the input score. This decision is based on the idea that a text that includes the complete name of a company rarely will not refer to the entity, as usually, complete names of the companies are the most meaningful and distinctive (e.g., Banco Santander, S.A., Bank of America Corporation, etc.). -Rule II: However, the most frequent way of referring to companies is by means of short names, which are frequently used as queries, such as "Santander" for Banco Santander, S.A. or "Bank of America" for Bank of America Corporation. That is why, when the input text contains an identical to the search query sequence of tokens, the system adds to the total score 2/3 of the maximum score, 0.5. The reason for using a lower value is that we have found the search queries to be highly ambiguous. For example, "Santander" could be interpreted as a region of Spain or as a bank, depending on the context. Note that in this case we use token matching rather than string matching. -Rule III: Due to the limited length of Twitter posts, in many cases the string of the search query is not tokenized, but included into a hashtag or written omitting blanks (e.g., #bankofamerica or BankofAmerica instead of "Bank of America"), so different tokens cannot be correctly identified by GATE and FreeLing. To solve this, we have included a further rule that checks if the input string contains the search query after removing blanks, and assigns 1/3 of the maximum score, 0.25. -Rule IV: Finally, we assume that an input text that contains words from the entity context is more probably related to the entity than other, the more words in common the higher probability. However, as the website and the Wikipedia entry usually include not only domain specific terms, but also many generic words, for each token in the input text that matches a token in the entity context the score of the input is increased only 0.25.</p><p>The score of each input text is then compared to the threshold to determine if the text is related to the entity or not, filtering all the input texts that are not related to the entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Polarity for reputation</head><p>The original method presented in <ref type="bibr" coords="4,288.00,633.20,10.52,8.74" target="#b5">[6]</ref> has been modified to improve the scope detection approach for negation and intensifiers to deal with the effect of subordinate sentences and special punctuation marks. Besides, the list and weights of the intensifiers have been adjusted to the most frequent uses in English. Moreover, the presented approach uses the SentiSense affective lexicon <ref type="bibr" coords="5,426.00,131.95,9.96,8.74" target="#b6">[7]</ref>, that was specifically designed for opinionated texts. Sentisense attaches an emotional category from a set of 14 emotions to WordNet concepts. It also includes the antonym relationship between emotional categories, which allows to capture the effect of some linguistic modifiers such as negation. We also have adapted the system to work with Spanish texts, as the original system was conceived only for English. The method comprises four steps that are described below:</p><p>Pre-processing: POS Tagging and Concept Identification The objective of the first step is to translate each text to its conceptual representation in order to work at the concept level in the next steps and avoid word ambiguity. To this aim, the input text is split into sentences and the tokens are tagged with their POS using GATE for English texts and FreeLing for Spanish texts. At this stage, the syntax tree of each sentence is also retrieved using the Stanford Parser <ref type="bibr" coords="5,134.77,304.87,15.50,8.74" target="#b14">[15]</ref> for the English texts and the FreeLing library for the Spanish texts. With this information, the system next maps each token to its appropriate WordNet concept using the Lesk word sense disambiguation algorithm as implemented in the WordNet::SenseRelate package <ref type="bibr" coords="5,302.02,340.73,15.50,8.74" target="#b19">[20]</ref> for English, and the UKB algorithm <ref type="bibr" coords="5,134.77,352.69,10.52,8.74" target="#b0">[1]</ref> as included in the FreeLing library for Spanish. Besides, to enrich the emotion identification step, the hypernyms of each concept are also extracted from WordNet.</p><p>Emotion Identification Once the concepts are identified, the next step maps each WordNet synset to its corresponding emotional category in the SentiSense affective lexicon, if any. The emotional categories of the hypernyms are also retrieved. We hypothesize that the hypernyms of a concept entail the same emotions than the concept itself, but decreasing the intensity of the emotion as we move up in the hierarchy. So, when no entry is found in the SentiSense lexicon for a given concept, the system retrieves the emotional category associated to its nearest hypernym, if any. However, only a certain level of hypernymy is accepted, since an excessive generalization introduces some noise in the emotion identification. This parameter has been empirically set to 3. In order to accomplish this step for Spanish texts we have automatically translated the SentiSense lexicon to the Spanish language. To do this, we have automatically updated the synsets in SentiSense to their WordNet 3.0 version using the WordNet mappings. In particular, for nouns and verbs we use the mappings provided by the WordNet team <ref type="bibr" coords="5,159.68,573.43,15.50,8.74" target="#b24">[26]</ref> and for adjectives and adverbs, the UPC mappings <ref type="bibr" coords="5,404.43,573.43,14.61,8.74">[22]</ref>. In this automatic process we have only found 15 labeled synsets without a direct mapping, which were removed in the new SentiSense version. Finally, in order to translate the SentiSense English version to Spanish we use the Multilingual Central Repository (MRC) <ref type="bibr" coords="5,221.21,621.25,14.61,8.74" target="#b11">[12]</ref>. The MCR is an open source database that integrates WordNet versions for five different languages: English, Spanish, Catalan, Basque and Galician. The Inter-Lingual-Index (ILI) allows the automatic translation of synsets from one language to another.</p><p>Post-processing: Negation and Intensifiers In this step, the system has to detect and solve the effect of negations and intensifiers over the emotions discovered in the previous step. This process is important, since these linguistic modifiers can change the polarity and intensity of the emotional meaning of the text. It is apparent that the text #Barclays bank may not achieve 13% on equity target by 2013 entails different polarity than the text #Barclays bank may achieve 13% on equity target by 2013, and reputation systems must be aware of this fact.</p><p>To this end, our system first identifies the presence of modifiers using a list of common negation and intensification tokens. In such a list, each intensifier is assigned a value that represents its weight or strength. The scope of each modifier is determined using the syntax tree of the sentence in which the modifier arises. We assume as scope all descendant leaf nodes of the common ancestor between the modifier and the word immediately after it, and to the right of the modifier. However, this process may introduce errors in special cases, such as subordinate sentences or those containing punctuation marks. In order to avoid this, our method includes a set of rules to delimit the scope in such cases. These rules are based on specific tokens that usually mark the beginning of a different clause (e.g., because, until, why, which, etc.). Since some of these delimiters are ambiguous, their POS is used to disambiguate them. Once the modifiers and their scope are identified, the system solves their effect over the emotions that they affect in the text. The effect of negation is addressed by substituting the emotions assigned to the concepts by their antonyms. In the case of the intensifiers, the concepts that fall into the scope of an intensifier are tagged with the corresponding percentage weight in order to increase or diminish the intensity of the emotions assigned to the concepts.</p><p>In particular, for English texts we use the original list of negation signals from <ref type="bibr" coords="6,158.86,445.96,10.52,8.74" target="#b5">[6]</ref> and an adapted list of intensifiers with the most frequent uses in English. The percentage of each intensifier has been set empirically. In order to determine the scope for English texts, we use the syntax tree as generated by the Stanford Parser. The same process is replicated for the Spanish texts, and a list of common negation tokens in Spanish (such as no, nunca, nada, nadie, etc.) and common intensifiers (más, menos, bastante, un poco, etc.) were developed. In order to determine the scope of each modifier, the syntax tree as generated by the FreeLing library is used.</p><p>Classification In the last step, all the information generated in the previous steps is used to translate each text into a Vector of Emotional Intensities (VEI), which will be the input to a machine learning algorithm. The VEI is a vector of 14 positions, each of them representing one of the emotional categories of the SentiSense affective lexicon. The values of the vector are generated as follows:</p><p>-For each concept, C i , labeled with an emotional category, E j , the weight of the concept for that emotional category, weight(C i ; E j ), is set to 1.0.</p><p>-If no emotional category was found for the concept, and it was assigned the category of its first labeled hypernym, hyper i , then the weight of the concept is computed as:</p><formula xml:id="formula_0" coords="7,229.84,169.76,250.75,9.65">weight(C i ; E j ) = 1/(depth(hyper i ) + 1)<label>(1)</label></formula><p>-If the concept is affected by a negation and the antonym emotional category, E a nton j , was used to label the concept, then the weight of the concept is multiplied by α = 0.6. This value has been empirically determined in previous studies. It is worth mentioning that the experiments have shown that α values below 0.5 decrease performance sharply, while it drops gradually for values above 0.6. -If the concept is affected by an intensifier, then the weight of the concept is increased/decreased by the intensifier percentage, as shown in Equation <ref type="formula" coords="7,467.99,273.82,3.87,8.74">2</ref>.</p><formula xml:id="formula_1" coords="7,156.68,309.16,323.91,9.65">weight(C i ; E j ) = weight(C i ; E j ) * (100 + intensif ier percentage)/100 (2)</formula><p>-Finally, the position in the VEI of the emotional category assigned to the concept is incremented by the weight previously calculated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Heterogeneity based ranking approach for polarity for reputation</head><p>Our last approach consists in combining our runs (Uned 1..4) with the runs provided by Barcelona Media (BMedia 1..5) <ref type="bibr" coords="7,318.38,431.07,9.96,8.74" target="#b7">[8]</ref>. Given that the RepLab 2012 trial data set is not big enough for training purposes we opted for a voting method. In <ref type="bibr" coords="7,134.77,454.98,15.50,8.74" target="#b25">[27]</ref> several voting algorithms for combining classifiers are described. They are focused on the multiplicity of classifiers that support a certain decision. However they do not consider the diversity of classifiers, which is a strong evidence of accuracy when combining classifiers <ref type="bibr" coords="7,304.88,490.84,14.61,8.74" target="#b16">[17]</ref>. There are works in which classifiers are selected to be combined while trying to maximize their diversity <ref type="bibr" coords="7,435.52,502.80,14.61,8.74" target="#b10">[11]</ref>.</p><p>We propose a voting algorithm that directly considers the diversity of classifiers instead of the amount of classifiers that corroborate a certain decision. As far as we know, this perspective has not been applied before due to the lack of a diversity measure to be applied over classifier sets rather than pairwise measures. Our approach is inspired in the Heterogeneity Based Ranking <ref type="bibr" coords="7,407.08,563.06,9.96,8.74" target="#b2">[3]</ref>.</p><p>We define the Heterogeneity of a set of classifiers F = {f 1 ..f n } as the probability over decision cases C that there exists at least two classifiers contradicting each other.</p><formula xml:id="formula_2" coords="7,225.28,625.28,164.80,9.65">H(F) = P C (∃f i , f j ∈ F/f i (c) = f j (c))</formula><p>The approach basically consists in selecting the label (e.g. positive, neutral) that maximizes the heterogeneity of classifiers corroborating this decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>The data set used for evaluation consists of a training set of 1800 tweets crawled for six companies (300 per company) and a test set of 6243 tweets for 31 companies. However, since Twitter's Terms of Service do not allow redistribution of tweets, some of them have been removed from the release version of the data set. So, the training set that has been finally used contains 1662 tweets manually labeled by experts, 1287 for English and 375 for Spanish. For the filtering task, the training set comprises 1504 tweets related to any of the companies and 158 that were not related to any company. In polarity for reputation, the distribution of tweets between classes is: positive=885, neutral=550, and negative=81. The test set contains tweets manually labeled by experts, 3521 of them are in English and 2722 in Spanish. Besides, this set contains 4354 related tweets, and 1889 unrelated tweets, while the distribution of tweets in polarity for reputation classes is 1625, 1488 and 1241 tweets for positive, neutral and negative, respectively. For the profiling task (i.e., combining systems of filtering and polarity), the performance is evaluated as accuracy on a four-class classification problem: irrelevant, relevant negative, relevant neutral and relevant positive. For the individual evaluation of the filtering and polarity tasks, performance is evaluated in terms of reliability (R) and sensitivity (S) <ref type="foot" coords="8,315.69,347.35,3.97,6.12" target="#foot_2">3</ref> . Accuracy (% of correctly annotated cases) is also included for comparison purposes. Overall scores (R, S, F(R,S), accuracy) are computed as the average of individual scores per entity, assigning the same weight to all entities.</p><p>As the system for polarity for reputation is a supervised method, we have tested different machine learning algorithms with the training set in order select the best classifier for the task. To determine the best machine learning algorithm for the task, 20 classifiers currently implemented in Weka <ref type="bibr" coords="8,392.95,432.96,15.50,8.74" target="#b12">[13]</ref> were compared. We only show the results of the best performance classifiers: a logistic regression model (Logistic) and a classifier using decision trees (RandomForest). The best outcomes for the two algorithms were reported when using their default parameters in Weka. For the filtering task, we have evaluated over the training set different thresholds. In particular, we have evaluated the values 0.25 (just the presence of the query search or the presence of an entity context word), 0.5 (the presence of the query search plus some entity context word, or the exact match of tokens with the query search), 0.75 (the presence of the company name, or different combinations of the query search and entity context words) and 1.0 (multiple combinations of the query search or the company name and the entity context word). We have found that, upper this last threshold, the performance of the system decreases sharply. For RepLab 2012, we have selected two thresholds that produce better results, i.e. 0.5 and 0.75.</p><p>Based on these considerations, five systems have been presented to RepLab 2012: Uned 1 (Logistic + threshold=0.5 ), Uned 2 (RandomForest + thresh-old=0.5 ), Uned 3 (Logistic + threshold=0.75 ), Uned 4 (RandomForest + thresh-old=0.75 ), and Uned 5 or Uned-BMedia, which is the system described in the sec-tion 3 that combines the outputs of the algorithms Uned 1..4 and BMedia 1..5 using the heterogeneity-based ranking approach.</p><p>Table <ref type="table" coords="9,176.61,146.77,4.98,8.74">1</ref> shows the results of our systems for the filtering task when evaluated over the test set. As can be seen, the best performance in terms of F(R,S) is obtained by the two approaches that use the 0.75 threshold (Uned 3 and Uned 4), followed by the combined version Uned-BMedia and the two approaches that use the 0.5 threshold (Uned 1 and Uned 2). In terms of accuracy, the best result is obtained by the combined version Uned-BMedia, only 2.0 percentage points more than the two approaches that use the 0.75 threshold and 3.1 percentage points more than the 0.5 threshold approaches. Comparing these results with the All relevant baseline, it is evident that the performance of our approaches is quite acceptable but may be easily improved. It is important to recall the difficulty of the task even for humans. In fact, the best results obtained in the challenge by our systems, Uned 3 and Uned 4, are placed 13th and 14th, respectively, out of 33 participants <ref type="bibr" coords="9,203.21,290.23,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Results for the filtering task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Systems</head><p>Acc. R S F(R,S) Uned 1 0,693414595 0,161145627 0,151777683 0,08899625 Uned 2 0,693414595 0,161145627 0,151777683 0,08899625 Uned 3 0,705452028 0,172086104 0,254595211 0,134324737 Uned 4 0,705452028 0,172086104 0,254595211 0,134324737 Uned-BMedia 0,724939924 0,177089017 0,212287163 0,114018152 All relevant 0,709480928 0 0 0 Table <ref type="table" coords="9,177.90,465.83,4.98,8.74" target="#tab_0">2</ref> summarizes the results obtained by our systems in terms of accuracy, reliability and sensitivity over the test set. The best performance in terms of F(R,S) is achieved by the combined version Uned-BMedia, while the systems Uned 2 and Uned 4 that use the RandomForest classifier are only 4.0 percentage points lower. The systems Uned 1 and Uned 3 that use the Logistic classifier achieve 8.0 percentage points less than the Uned-BMedia, which is an important difference in performance. In contrast, in terms of accuracy the best performance is obtained by the RandomForest classifier (Uned 2 and Uned 4), followed by the combined version Uned-BMedia and the Logistic classifier. As can be seen in the table, all the systems improved over the All positives baseline. It is worth noticing that the results achieved for the polarity for reputation task are much better than the obtained for filtering task. This is evidenced by the fact that the combined system Uned-BMedia obtained the 2nd position within the 35 participating systems in term of F(R,S), and the two approaches that use the RandomForest classifier obtained the 5th and 6th position, respectively. However, in terms of accuracy the results reported by our systems are even better, the two approaches that use the RandomForest classifier have achieved the 1st and 2nd position in the ranking, while the combined version Uned-BMedia has achieved the 4th position. The results of our systems for the profiling task, i.e. combining filtering and polarity for reputation, are shown on Table <ref type="table" coords="10,333.60,307.43,3.87,8.74" target="#tab_1">3</ref>. The best result is achieved by the system Uned 4. However, the difference is not so marked with respect to the Uned 3 and the combined version Uned-BMedia, 0.6 and 1.9 percentage points of accuracy, respectively. The difference becomes higher comparing to the systems Uned 2 and Uned 1, 5.6 and 7.2 percentage points of accuracy. Moreover, all systems considerably improve the performance over the All relevant and positives baseline. As in the polarity for reputation task, the results achieved by our systems compare favorably to those of other participants. In particular, three of our systems are among six best systems out of 28 systems that participated in the task (the 3rd, the 5th and the 6th for Uned 4, Uned 3 and Uned-BMedia, respectively), which proves that the proposed approaches are a good starting point for a more complex profiling system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Analysing and discussing the results obtained by the systems proposed for Re-pLab 2012, first of all and regarding the filtering task, we have to say that our system correctly classified 3352 out of 4354 related tweets (76.9%) and 1019 out of 1831 non-related tweets (55.6%). These results suggest that the 0.75 threshold in the vote mechanism is a good choice for discriminating between related and unrelated tweets. Most of the related tweets were above this threshold, and nearly half of the unrelated tweets were below it. However, a number of unrelated tweets obtained a score far above 0.75, which seems to suggest that the filtering method should take into account not only positive terms but also negative ones, i.e. terms that decrease the score. We also have analyzed which are the most frequent combination of rules for assigning scores, as well as their adequacy. We have found that rule II (i.e. the one that considers the presence in the input of the individual tokens within the search query) and rule III (i.e. the one that looks for the search query without blanks), are frequently launched together producing satisfactory results. The combination of rule III and rule IV (i.e. the presence of entity context words) is the second most frequent one. However, it is also the one that introduces more noise. Finally, the presence of the complete entity name (rule I) is the less launched rule, but the one that produces the best performance, as expected.</p><p>Regarding the polarity for reputation task, our best systems in terms of accuracy (Uned 2 and Uned 4) correctly classified 822 tweets as positive, 810 tweets as neutral and only 179 tweets as negative. These results show the good performance of these systems at identifying the positive and neutral classes. In contrast, the systems only classify 15% of negative tweets correctly. This difference may be due to the fact that the number of negative instances in the training set is not big enough for the classifiers to correctly learn this class.</p><p>Even if the systems achieve a good performance in polarity for reputation, it is worth mentioning that these results are lower than those reported by the same systems when evaluated with other datasets containing product reviews. In order to determine the reason of this, we analyzed the datasets and found that an important number of tweets are not labeled with any emotion. In particular, the coverage of the vocabulary in SentiSense for the training set is 12.5% for English and 12.6% for Spanish, while the coverage in the test set is 11.3% and 11.2% for English and Spanish, respectively. This was expected, since SentiSense is specially designed for processing product reviews. Therefore, taking this low coverage into account, we expect that expanding SentiSense with reputationrelated vocabulary will allow us to significantly improve the classification results.</p><p>However, as we suspected, another important source of classification errors is that many of the tweets labeled with polarity in the dataset (positive and negative) do not contain any emotional meaning per se. These are factual expressions that, from a reputation perspective, entail a polarity, and therefore must be classified as negative or positive. For example, the tweet I bough a Lufthansa ticket to Berlin yesterday does not express any clear emotion, but is considered as positive for reputation purposes. To this aim, reputation management knowledge must be used to allow the system to correctly interpret these expressions.</p><p>The importance of the opinion holder and, specially for microblogging, the importance of the external links in the input text are other two important find-ings of our analysis. On the one hand, we find some examples of tweets that, from our point of view, should be classified as neutral, but were classified by the experts as polar due to the relevance or popularity of the the tweet's author. So, we can conclude that correctly determining the opinion holder is important to weight the final polarity for reputation. On the other hand, we find that many of the tweets that have external links obtain their polarity from the linked documents. This suggests that studying polarity for reputation in social media, especially in such microblogging services as Twitter, needs more context than the posts themselves.</p><p>Finally, the results obtained in the profiling task show the good adequacy of complex sentiment analysis approaches as a starting point to analyze texts according to the reputation of a given entity. Even if the performance of the combined system, filtering + polarity for reputation, is quite acceptable, there is still room for improvement. It is important to notice that the evaluation of this task includes, first, filtering relevant tweets, and next, the polarity classification of these relevant tweets, so that the error of the filtering step is propagated to the polarity for reputation classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have presented a system to address the task of classifying polarity for reputation, based on sentiment analysis techniques. We also face the problem of determining whether a text is related or not to a given entity (e.g., company or brand). The results showed that, even if the task is more complex than classifying polarity in opinionated texts, the use of complex sentiment analysis approaches seems a good basis for classifying polarity for reputation. However, it is still necessary to incorporate a high level of expert knowledge to correctly analyze the reputation of a company.</p><p>As future work, we plan to develop a system for separating objective from subjective statements. This separation will allow us to study objective texts from a reputation perspective, while subjective opinions will be analyzed using sentiment analysis approaches. Our analysis has also revealed the importance of detecting the opinion holder, which may influence the polarity of the text. To address this, we plan to study existing approaches in the area and evaluate them for the polarity for reputation task. Finally, we would like to extend the SentiSense affective lexicon to cover more domain specific vocabulary.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,173.40,163.15,268.57,94.62"><head>Table 2 .</head><label>2</label><figDesc>Results for the polarity for reputation task</figDesc><table coords="10,173.40,184.61,268.57,73.17"><row><cell>Systems</cell><cell>Acc.</cell><cell>R</cell><cell>S.</cell><cell>F(R,S)</cell></row><row><cell>Uned 1</cell><cell cols="4">0,442352774 0,315276995 0,243799781 0,262266787</cell></row><row><cell>Uned 2</cell><cell cols="4">0,486569957 0,325450278 0,314695031 0,307839944</cell></row><row><cell>Uned 3</cell><cell cols="4">0,442352774 0,315276995 0,243799781 0,262266787</cell></row><row><cell>Uned 4</cell><cell cols="4">0,486569957 0,325450278 0,314695031 0,307839944</cell></row><row><cell cols="5">Uned-BMedia 0,449501547 0,340229898 0,374731432 0,341946295</cell></row><row><cell>All positives</cell><cell>0,438481115</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,229.81,470.15,155.75,94.62"><head>Table 3 .</head><label>3</label><figDesc>Results for the profiling task</figDesc><table coords="10,233.14,491.60,149.08,73.17"><row><cell>Systems</cell><cell>Acc.</cell></row><row><cell>Uned 1</cell><cell>0,319710973</cell></row><row><cell>Uned 2</cell><cell>0,335352452</cell></row><row><cell>Uned 3</cell><cell>0,385183273</cell></row><row><cell>Uned 4</cell><cell>0,391658071</cell></row><row><cell>Uned-BMedia</cell><cell>0,372795736</cell></row><row><cell cols="2">All relevant and positives 0,274057566</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,625.56,226.45,7.47"><p>http://www.limosine-project.eu/events/replab2012</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,635.88,335.86,7.86;2,144.73,646.84,335.86,8.12;2,144.73,658.44,88.29,7.47"><p>Both companies' dimensions and the types of opinion holder are standard parameters of RepTrak System http://www.reputationinstitute.com/thought-leadership/ the-reptrak-system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="8,144.73,657.79,296.65,8.12"><p>See guidelines at http://www.limosine-project.eu/events/replab2012</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This research was supported by the <rs type="funder">European Unions</rs> (<rs type="grantNumber">FP7-ICT-2011-7 -Language</rs> technologies -nr <rs type="grantNumber">288024</rs> (LiMoSINe).)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xG3E5pu">
					<idno type="grant-number">FP7-ICT-2011-7 -Language</idno>
				</org>
				<org type="funding" xml:id="_S2QvtdU">
					<idno type="grant-number">288024</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,138.35,602.95,342.24,7.86;12,146.91,613.91,333.68,7.86;12,146.91,624.87,137.95,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,235.97,602.95,226.08,7.86">Personalizing PageRank for Word Sense Disambiguation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,146.91,613.91,333.68,7.86;12,146.91,624.87,105.46,7.86">proceedings of the 12th conference of the European chapter of the Association for Computational Linguistics</title>
		<meeting>the 12th conference of the European chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,635.88,342.24,7.86;12,146.91,646.84,333.68,7.86;12,146.91,657.79,183.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,373.87,635.88,106.72,7.86;12,146.91,646.84,207.96,7.86">Overview of RepLab 2012: Evaluating Online Reputation Management Systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,375.41,646.84,105.18,7.86;12,146.91,657.79,151.05,7.86">proceedings of CLEF 2012 Labs and Workshop Notebook Papers</title>
		<meeting>CLEF 2012 Labs and Workshop Notebook Papers</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,120.67,342.24,7.86;13,146.91,131.63,333.68,7.86;13,146.91,142.59,333.68,7.86;13,146.91,153.55,333.68,7.86;13,146.91,164.51,290.62,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,344.20,120.67,136.39,7.86;13,146.91,131.63,153.77,7.86">UNED: Improving Text Similarity Measures without Human Assessments</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,327.62,131.63,152.97,7.86;13,146.91,142.59,180.95,7.86;13,378.79,142.59,101.81,7.86;13,146.91,153.55,119.27,7.86;13,330.53,153.55,150.06,7.86;13,146.91,164.51,139.20,7.86">SEM 2012: The First Joint Conference on Lexical and Computational Semantics</title>
		<meeting><address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="454" to="460" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct coords="13,138.35,175.47,342.25,7.86;13,146.91,186.43,252.59,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="13,192.02,175.47,232.11,7.86">A Semantic approach to automated text sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Simon Fraser University, Canada</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Unpublished doctoral dissertation</note>
</biblStruct>

<biblStruct coords="13,138.35,197.40,342.24,7.86;13,146.91,208.36,333.68,7.86;13,146.91,219.32,135.29,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,321.02,197.40,159.57,7.86;13,146.91,208.36,64.12,7.86">FreeLing: An Open-Source Suite of Language Analyzers</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Padr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Padr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,232.71,208.36,247.88,7.86;13,146.91,219.32,102.44,7.86">proceedings of the 4th International Conference on Language Resources and Evaluation</title>
		<meeting>the 4th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,230.28,342.24,7.86;13,146.91,241.24,333.68,7.86;13,146.91,252.20,291.36,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,342.02,230.28,138.57,7.86;13,146.91,241.24,183.34,7.86">A Hybrid Approach to Emotional Sentence Polarity and Intensity Classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gervas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,351.84,241.24,128.75,7.86;13,146.91,252.20,206.24,7.86">proceedings of the 14th Conference on Computational Natural Language Learning</title>
		<meeting>the 14th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="153" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,263.17,342.24,7.86;13,146.91,274.13,333.68,7.86;13,146.91,285.09,263.18,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,327.00,263.17,153.59,7.86;13,146.91,274.13,184.89,7.86">SentiSense: An easily scalable conceptbased affective lexicon for Sentiment Analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gervs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,353.86,274.13,126.73,7.86;13,146.91,285.09,230.34,7.86">proceedings of the 8th International Conference on Language Resources and Evaluation</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,296.05,342.25,7.86;13,146.91,307.01,293.71,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,361.16,296.05,96.18,7.86">FBM-Yahoo! at RepLab</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Chenlo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Atserias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,160.99,307.01,246.58,7.86">proceedings CLEF 2012 Labs and Workshop Notebook Paper</title>
		<meeting>CLEF 2012 Labs and Workshop Notebook Paper</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,317.98,342.24,7.86;13,146.91,328.94,177.97,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,219.54,317.98,209.59,7.86">GATE, a General Architecture for Text Engineering</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,436.49,317.98,44.11,7.86;13,146.91,328.94,77.82,7.86">Computers and the Humanities</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="223" to="254" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,339.91,337.97,7.86;13,146.91,350.86,333.68,7.86;13,146.91,361.82,270.93,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,254.88,339.91,225.71,7.86;13,146.91,350.86,58.43,7.86">Determining term subjectivity and term orientation for opinion mining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,226.36,350.86,254.23,7.86;13,146.91,361.82,184.68,7.86">proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 11th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,372.79,337.98,7.86;13,146.91,383.75,241.73,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,240.79,372.79,239.80,7.86;13,146.91,383.75,30.78,7.86">An Approach to the Automatic Design of Multiple Classifier Systems</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Giacinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,185.16,383.75,111.56,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,394.72,337.97,7.86;13,146.91,405.67,333.68,7.86;13,146.91,416.63,200.32,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,333.22,394.72,147.37,7.86;13,146.91,405.67,216.63,7.86">Multilingual Central Repository version 3.0: upgrading a very large lexical knowledge base</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Laparra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,384.01,405.67,96.58,7.86;13,146.91,416.63,167.39,7.86">proceedings of the Sixth International Global WordNet Conference</title>
		<meeting>the Sixth International Global WordNet Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,427.60,337.98,7.86;13,146.91,438.56,333.68,7.86;13,146.91,449.52,25.60,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,464.72,427.60,15.88,7.86;13,146.91,438.56,163.60,7.86">The WEKA data mining software: an update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,318.21,438.56,98.04,7.86">SIGKDD Explor. Newsl</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,460.49,337.97,7.86;13,146.91,471.44,115.41,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,205.43,460.49,223.06,7.86">Online reputation management is hot? But is it ethical?</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,444.76,460.49,35.83,7.86;13,146.91,471.44,28.48,7.86">Computerworld</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<date type="published" when="2008-02">February (2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,482.41,337.98,7.86;13,146.91,493.37,333.68,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,262.30,482.41,124.01,7.86">Accurate Unlexicalized Parsing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,407.42,482.41,73.17,7.86;13,146.91,493.37,249.36,7.86">proceedings of the 41st Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,504.34,337.98,7.86;13,146.91,515.30,291.26,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,242.93,504.34,156.68,7.86">Determining the sentiment of opinions</title>
		<author>
			<persName coords=""><forename type="first">S-M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,422.37,504.34,58.23,7.86;13,146.91,515.30,198.86,7.86">proceedings of the 20th Conference on Computational Linguistic</title>
		<meeting>the 20th Conference on Computational Linguistic</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1367" to="1373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,526.26,337.97,7.86;13,146.91,537.22,333.67,7.86;13,146.91,548.18,199.70,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,415.40,526.26,65.19,7.86;13,146.91,537.22,131.43,7.86">Is Independence Good For Combining Classifiers?</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Shipp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">P W</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,298.78,537.22,181.81,7.86;13,146.91,548.18,113.08,7.86">proceedings of the 15th International Conference on Pattern Recognition</title>
		<meeting>the 15th International Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="168" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,559.15,337.97,7.86;13,146.91,570.11,333.68,7.86;13,146.91,581.07,242.62,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,306.70,559.15,173.89,7.86;13,146.91,570.11,115.83,7.86">Thumbs up? Sentiment classification using Machine Learning techniques</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,283.83,570.11,196.76,7.86;13,146.91,581.07,165.31,7.86">proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,592.03,337.98,7.86;13,146.91,602.99,333.68,7.86;13,146.91,613.95,281.43,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,226.41,592.03,254.18,7.86;13,146.91,602.99,154.37,7.86">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,320.71,602.99,159.88,7.86;13,146.91,613.95,195.18,7.86">proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,624.92,337.98,7.86;13,146.91,635.88,333.68,7.86;13,146.91,646.84,333.68,7.86;13,146.91,657.79,68.60,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,334.48,624.92,146.11,7.86;13,146.91,635.88,190.65,7.86">SenseRelate::TargetWord -A generalized framework for word sense disambiguation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,358.60,635.88,121.99,7.86;13,146.91,646.84,329.79,7.86">proceedings of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</title>
		<meeting>the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="73" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,120.67,337.98,7.86;14,146.91,131.63,333.68,7.86;14,146.91,142.59,251.98,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,208.03,120.67,272.57,7.86;14,146.91,131.63,127.65,7.86">Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,294.91,131.63,185.68,7.86;14,146.91,142.59,168.81,7.86">proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,186.42,337.98,7.86;14,146.91,197.38,333.68,7.86;14,146.91,208.34,252.49,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,293.23,186.42,187.36,7.86;14,146.91,197.38,127.50,7.86">Development and use of a gold-standard data set for subjectivity classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>O'hara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,294.45,197.38,186.15,7.86;14,146.91,208.34,168.81,7.86">proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,219.30,337.98,7.86;14,146.91,230.26,333.68,7.86;14,146.91,241.22,333.68,7.86;14,146.91,252.18,25.60,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,266.85,219.30,213.74,7.86;14,146.91,230.26,159.45,7.86">Bootstrapping supervised machine-learning polarity classifiers with rule-based classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,329.70,230.26,150.89,7.86;14,146.91,241.22,281.33,7.86">proceedings of the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,263.14,337.97,7.86;14,146.91,274.09,333.68,7.86;14,146.91,285.05,79.36,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,307.11,263.14,173.47,7.86;14,146.91,274.09,204.81,7.86">Recognizing contextual polarity: an exploration of features for phrase-level sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,357.87,274.09,104.76,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="399" to="433" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,296.01,298.57,7.86" xml:id="b24">
	<monogr>
		<ptr target="http://wordnet.princeton.edu/wordnet/download/" />
		<title level="m" coord="14,151.52,296.01,76.15,7.86">WordNet mappings</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,306.97,337.97,7.86;14,146.91,317.93,333.68,7.86;14,146.91,328.89,291.18,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="14,289.92,306.97,190.67,7.86;14,146.91,317.93,178.87,7.86">Methods for combining multiple classifiers and their applications to handwriting recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krzyzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,332.63,317.93,147.96,7.86;14,146.91,328.89,188.81,7.86">IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="418" to="435" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
