<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,109.32,60.73,387.91,12.59;1,210.47,78.13,174.34,12.59">Arabic QA4MRE at CLEF 2012: Arabic Question Answering for Machine Reading Evaluation</title>
				<funder ref="#_EdFqNTU">
					<orgName type="full">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</orgName>
				</funder>
				<funder ref="#_Rq5HVqA">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,119.52,114.60,50.16,11.03"><forename type="first">Omar</forename><surname>Trigui</surname></persName>
							<email>omar.trigui@fsegs.rnu.tn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ANLP Research Group-MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.07,114.60,97.13,11.03"><forename type="first">Lamia</forename><forename type="middle">Hadrich</forename><surname>Belguith</surname></persName>
							<email>l.belguith@fsegs.rnu.tn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ANLP Research Group-MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.42,114.60,49.73,11.03"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Natural Language Engineering Lab -ELiRF</orgName>
								<orgName type="institution">Universitat Politècnica de València</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.50,114.60,75.91,11.03"><forename type="first">Hichem</forename><forename type="middle">Ben</forename><surname>Amor</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ANLP Research Group-MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,425.73,114.60,58.08,11.03"><forename type="first">Bilel</forename><surname>Gafsaoui</surname></persName>
							<email>gafsaouibilel@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ANLP Research Group-MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,109.32,60.73,387.91,12.59;1,210.47,78.13,174.34,12.59">Arabic QA4MRE at CLEF 2012: Arabic Question Answering for Machine Reading Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CC37CA313BA75DF9CE1A1884D349E048</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine Reading</term>
					<term>Reading Comprehension</term>
					<term>Knowledge Reasoning</term>
					<term>Arabic Language</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the work carried out at ANLP Research Group for the CLEF-QA4MRE 2012 competition. This year, the Arabic language was introduced for the first time on QA4MRE lab at CLEF whose intention was to ask questions which require a deep knowledge of individual short texts and in which systems were required to choose one answer from multiple answer choices, by analyzing the corresponding test document in conjunction with background collections. In our participation, we have proposed an approach which can answer questions with multiple answer choices from short Arabic texts. This approach is constituted essentially of shallow information retrieval methods. The evaluation results of the running submitted has given the following scores: accuracy calculated overall all questions is 0.19 (i.e., 31 correct questions answered correctly among 160), while overall c@1 measure is also 0.19. The overall results obtained are not enough satisfactory comparing to the top works realized last year in QA4MRE lab. But as a first step at the roadmap of the evolution of the QA to Machine Reading (MR) systems in Arabic language and with the lack of researches investigated in the MR and deep knowledge reasoning in Arabic language, it is an encouraging step. Our proposed approach with its shallow criterion has succeeded to obtain the goal fixed at the beginning which is: select answers to questions from short texts without required enough external knowledge and complex inference.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The QA4MRE lab this year was aimed to evaluate machine reading systems which require a deeper level of text understanding to answer questions with multiple answer choices in a set of seven languages <ref type="foot" coords="1,486.08,463.03,3.24,7.18" target="#foot_0">1</ref> . The way proposed to assess the understanding of a text is the ability to answer a set of questions about it. This evaluation manner is similar to reading comprehension tests designed to evaluate how well a human reader has understood a text. This paper is structured into 6 sections. Section 2 presents a short overall of the state of the arts of Machine Reading Evaluation. Section 3 details our proposal approach to deal with QA4MRE lab in Arabic language. Section 4 presents the experiment carried out. Section 5 discusses the obtained results, and finally, Section 6 presents a general conclusion and perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>The important beginning of the researches on Machine Reading (MR) were on 'Reading comprehension tests as evaluation for computer-based language understanding systems' workshop organized in 2000 2.  Then, separate researches were done on MR such as <ref type="bibr" coords="1,300.82,644.71,11.71,11.03" target="#b0">[1]</ref> until last year where in the framework of CLEF the first version of the Question Answering for Machine Reading Evaluation lab (QA4MRE lab) in five European language versions has been organized. Mainly, the approaches proposed by different researchers show how to adapt QA systems to MR systems. This year CLEF organizes QA4MRE lab with two new languages: Arabic and Bulgarian with more difficult task than in 2011.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed approach</head><p>Our proposed approach is constituted of a shallow process to understand texts based on Information Retrieval (IR) and it requires inferring from texts. Four steps are involved in the shallow method after the preprocess of the corpus based on the anaphoric resolution. The first step is about the question analysis where the stop words in the question were removed and the rest of words are saved as the question focus. The second step is the research of passages containing the focus question. In the third step, the passages collected are aligned with the multiple answer choices for the respective question. The answer which is included at these passages is selected as the correct answer from the multiple answer choices. In case, where there is no answer included in passages. We introduce a list of inference constituted of pair of words generated from the background collection according to a list of inference rules. In the alignment process, any word from the answer option that does not exist in the passage is replaced by its respective inference word. If after using the inference there is not an answer included in the collected passages, the question is considered as unanswered.</p><p>This approach is proposed for dealing exactly with non complex question types such as the factoid question type, and questions whose answers are selected from their respective single short texts. Table1 illustrates an example of these questions introduced in the data set of QA4MRE lab 2012. This part of questions is similar to the part of 76 questions (63%) of the 120 questions used in QA4MRE lab in CLEF 2011 and that do not require extra information from the background collection in order to be answered. They require just information presented in a paragraph or a sentence <ref type="bibr" coords="2,360.57,291.59,10.69,11.03" target="#b1">[2]</ref>. Table <ref type="table" coords="2,123.35,316.61,3.76,8.93">1</ref>. An example of a factoid question related to Aids topic of QA4MRE lab CLEF of 2012. The correct answer is in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A question in Arabic language</head><p>ˮΔϴϧϻΪϴμϟ ΕήπΤΘδϤϟ ωήΘΧ Ε˯ήΒΑ ϑήΘόΗ ΪϨϬϟ ΕΪΑ ϰΘϣ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The translation in English language</head><p>When India began to recognize the patented pharmaceutical products?</p><p>The given multiple answer choice</p><formula xml:id="formula_0" coords="2,333.94,390.34,20.10,37.07">1991 2007 1982</formula><p>2005 1997</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimentation</head><p>The proposed approach was implemented in a system following the architecture shown in Figure <ref type="figure" coords="2,484.04,509.13,3.76,11.03" target="#fig_0">1</ref>. The module 'preprocess of the corpus' where the anaphoric resolution and the construction of inference list by topic according to inference rules were not integrated. The evaluation of our system was carried out using the data given by the CLEF organization. The test set is composed of 16 test documents, 160 questions with a set of five answer choices per question. The test documents are related to 4 topics (i.e. "Aids", "Climate change", "Music and Society", and "Alzheimer"). Each topic includes 4 reading tests and each reading test is composed of one single document with 10 questions related to it. A background collection consisted of un-annotated documents related to the 4 topics in 7 languages are given to the participants to acquire the reading capabilities and the knowledge needed to fill in the gaps required to answer a test on the topic. Our system was required to answer these 160 questions by selecting one answer from the five alternative answers. There is always one and only one correct answer for each question. We have the option to leave a question unanswered if there is no confidence about the correctness of its response. The measure c@1 is applied to encourage systems to leave some questions unanswered in order to reduce the amount of incorrect answers <ref type="bibr" coords="3,215.87,321.58,10.69,11.03" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. The questions distribution according to their answers</head><p>The results of the evaluation measures are as follows: the overall accuracy is equal to 0.19 (i.e. we have succeeded to answer correctly to 31 questions from 160 questions), and C@1 is equal also 0.19</p><formula xml:id="formula_1" coords="3,243.34,507.01,110.51,21.14">K|ĞƌĂůů ĂĐĐƵƌĂĐǇ с ;Ŷƌ ͬ ŶͿ Λϭ с ;Ŷƌ н ŶƵ Ύ ;ŶƌͬŶͿͿ ͬ Ŷ</formula><p>where: nr: is the number of correctly answered questions nu: is the number of unanswered questions n: is the total number of questions  <ref type="figure" coords="4,165.35,56.77,4.98,11.03">2</ref> illustrate the part of the questions answered correctly and those answered wrongly. While Table <ref type="table" coords="4,138.36,68.29,4.98,11.03" target="#tab_1">3</ref> shows the overall c@1 and average per topic. The best measures are realized by "climate change" topic because it contains a big part of its questions in simple type (i.e. factoid).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The overall results obtained are not comparable to the top performance obtained last year for the English language. Nevertheless as a first step at the roadmap of the evolution of the QA to MR evaluation systems in Arabic language and with the lack of researches investigated in deep knowledge reasoning in Arabic language, it could be considered as an encouraging step. Our proposed approach with its shallow criterion has succeeded to obtain the goal fixed at the beginning which is: selecting answers to questions from short texts without required external knowledge and complex inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The QA4MRE lab was focused this year on the evaluation of Machine Reading systems. The goal behind it was to push researches towards a deeper understanding of a single text using inference deduced from document collection. We have participated at this QA4MRE lab which has included Arabic language for the first time. In our work, we have proposed an approach which did not require a deep reasoning and inference. We have succeeded to a certain degree to obtain an overall accuracy of 0.19. We plan in the future to improve this result by investigating further in MR research deep knowledge reasoning in Arabic language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,85.08,287.51,273.27,11.03;3,85.07,332.95,405.50,112.10"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The architecture of the system used at QA4MRE lab 2012</figDesc><graphic coords="3,85.07,332.95,405.50,112.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,96.48,593.24,372.32,61.15"><head>Table 2 .</head><label>2</label><figDesc>The number of the answered and unanswered questions by our system</figDesc><table coords="3,133.55,607.78,335.24,46.61"><row><cell>EƵŵďĞƌ ŽĨ ƋƵĞƐƚŝŽŶƐ ĂŶƐǁĞƌĞĚ</cell><cell>ϭϲϬ</cell></row><row><cell>E^tZ ǁŝƚŚ Z/',d ĐĂŶĚŝĚĂƚĞ ĂŶƐǁĞƌ</cell><cell>ϯϭ</cell></row><row><cell>E^tZ ǁŝƚŚ tZKE' ĐĂŶĚŝĚĂƚĞ ĂŶƐǁĞƌ</cell><cell>ϭϮϵ</cell></row><row><cell>EƵŵďĞƌ ŽĨ ƋƵĞƐƚŝŽŶƐ hE E^tZ</cell><cell>Ϭ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,96.48,667.51,375.69,73.99"><head>Table 3 .</head><label>3</label><figDesc>Average</figDesc><table coords="3,132.36,667.51,339.81,73.99"><row><cell cols="2">and overall c@1 measures per topic of our system</cell><cell></cell></row><row><cell>dŽƉŝĐƐ</cell><cell>K|ĞƌĂůů ĐΛϭ ƉĞƌ ƚŽƉŝĐ</cell><cell>|ĞƌĂŐĞ ƉĞƌ ƚŽƉŝĐ</cell></row><row><cell>ŝĚƐ</cell><cell>Ϭ͘Ϯϯ</cell><cell>Ϭ͘Ϯϯ</cell></row><row><cell>ůŝŵĂƚĞ ĐŚĂŶŐĞ</cell><cell>Ϭ͘Ϯϱ</cell><cell>Ϭ͘Ϯϱ</cell></row><row><cell>DƵƐŝĐ ĂŶĚ ^ŽĐŝĞƚǇ</cell><cell>Ϭ͘ϭϱ</cell><cell>Ϭ͘ϭϱ</cell></row><row><cell>ůǌŚĞŝŵĞƌ</cell><cell>Ϭ͘ϭϱ</cell><cell>Ϭ͘ϭϱ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,85.08,56.77,77.25,11.03"><head>Table 2 and</head><label>2</label><figDesc>Figure</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,99.00,757.53,217.85,8.91"><p>http://celct.fbk.eu/QA4MRE/index.php?page=Pages/mainTask.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,85.08,776.01,412.58,8.91"><p>http://portalparts.acm.org/1120000/1117595/fm/frontmatter.pdf?ip=41.228.226.199&amp;CFID=142563908&amp;CFTOKEN=51195488</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The <rs type="funder">European Commission</rs> as part of the <rs type="programName">WIQ-EI IRSES-Project</rs> (grant no. <rs type="grantNumber">269180</rs>) within the <rs type="projectName">FP 7 Marie Curie People Framework</rs> has partially funded the work of the third author. His work was carried out also in the framework of the <rs type="projectName">MICINN Text-Enterprise</rs> (<rs type="grantNumber">TIN2009-13391-C04-03</rs>) research project and the <rs type="funder">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Rq5HVqA">
					<idno type="grant-number">269180</idno>
					<orgName type="project" subtype="full">FP 7 Marie Curie People Framework</orgName>
					<orgName type="program" subtype="full">WIQ-EI IRSES-Project</orgName>
				</org>
				<org type="funded-project" xml:id="_EdFqNTU">
					<idno type="grant-number">TIN2009-13391-C04-03</idno>
					<orgName type="project" subtype="full">MICINN Text-Enterprise</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,88.48,471.22,421.77,9.97;4,103.08,481.54,345.30,9.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,332.02,471.22,178.24,9.97;4,103.08,481.54,89.46,9.97">Reading comprehension tests for computer-based understanding evaluation</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Wellner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Warren</forename><surname>Greiff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,198.47,481.54,109.14,9.97">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="334" />
			<date type="published" when="2006-12">December 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,88.48,502.18,421.87,9.97;4,103.08,512.62,407.30,9.97;4,103.08,522.94,218.11,9.97" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,210.11,512.62,300.27,9.97;4,103.08,522.94,37.60,9.97">Overview of QA4MRE at CLEF 2011: Question Answering for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Álvaro</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">E</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Corina</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Caroline</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sporleder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">CLEF</note>
	<note>Notebook Papers/Labs/Workshop</note>
</biblStruct>

<biblStruct coords="4,88.49,543.58,421.82,9.97;4,103.08,554.02,407.21,9.97;4,103.08,564.33,153.55,9.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,238.31,543.58,154.57,9.97">A Simple Measure to Assess Non-response</title>
		<author>
			<persName coords=""><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alvaro</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,409.17,543.58,101.13,9.97;4,103.08,554.02,403.31,9.97">Proceedings of 49th Annual Meeting of the Association for Computational Linguistics -Human Language Technologies (ACL-HLT 2011)</title>
		<meeting>49th Annual Meeting of the Association for Computational Linguistics -Human Language Technologies (ACL-HLT 2011)<address><addrLine>Portland. Oregon. USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">June 19-24. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
