<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.30,151.73,330.28,12.58;1,210.48,169.19,174.22,12.58">Biomedical Text Mining about Alzheimer&apos;s Diseases for Machine Reading Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,194.04,208.29,57.74,8.74"><forename type="first">Bing-Han</forename><surname>Tsai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.26,208.29,55.89,8.74"><forename type="first">Yu-Zheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.63,208.29,60.29,8.74"><forename type="first">Wen-Juan</forename><surname>Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.30,151.73,330.28,12.58;1,210.48,169.19,174.22,12.58">Biomedical Text Mining about Alzheimer&apos;s Diseases for Machine Reading Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E2A53D8CD758C97500CFADAB466284BE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>question-answering</term>
					<term>machine reading</term>
					<term>biomedical text mining</term>
					<term>QA4MRE</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper presents the experiments carried out as part of the participation in the pilot task of Biomedical about Alzheimer for QA4MRE at CLEF 2012. We have submitted total five unique runs in the pilot task. One run uses Term Frequency (TF) of the query words to weight the sentence. Two runs use Term Frequency-Inverted Document Frequency (TF-IDF) of the query words to weight the sentences. The two unique runs differ in the way that when multiple answers get the same scores by our system, we choose the different answer in the different runs. The last two runs use TF or TF-IDF weighting scheme as well as the OMIM terms about Alzheimer for query expansion. Stopwords are removed from the query words and answers. Each sentence in the associated document is assigned a weighting score with respect to query words. The sentence that receives the higher weighting score corresponding to the query words is identified as the more relevant sentence to the document. The corresponding answer option to the given question is scored according to the sentence weighting score and the highest ranked answer is selected as the final answer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The machine reading of biomedical texts about Alzheimer's diseases follows the same set up and principles as the QA4MRE, with the difference that it focuses on the biomedical domain. It is important for researchers to perform more efficient processing of Alzheimer-related literature. The task focuses on the reading of single documents and the identification of the answers to a set of questions about information that is stated or implied in the text. Questions are in the form of multiple choices, each having five options, and only one correct answer.</p><p>We have submitted total five unique runs in the pilot task. One run uses Term Frequency (TF) of the query words to weight the sentences. Two runs use Term Frequency-Inverted Document Frequency (TF-IDF) of the query words to weight the sentences. The two unique runs differ in the way that when multiple answers get the same scores by our system, we choose the different answer in the different runs. The last two runs use TF or TF-IDF weighting scheme as well as the OMIM terms about Alzheimer for query expansion.</p><p>The paper is organized as follows. Section 2 describes the corpus we use in this experiment. Section 3 introduces the system architecture and methods we propose. We perform and discuss the evaluation results in Section 4. Finally, the conclusions and future directions are drawn in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Background Collections</head><p>We use three types of background collections provided by the pilot task. The brief introduction of background collections is stated as below.</p><p>Open Access Full Articles PMC. 7,512 articles are provided in text format from PubMed Central. These articles have been selected by performing the search and selecting the full articles that belong to the PubMed Central Open Access subset.</p><p>Open Access Full Articles PMC, Smaller Collection. There are 1,041 full text articles from PubMed Central. To select these documents, a search by the pilot task was performed on PubMed using Alzheimer's disease related keywords and restricting the search to the last three years.</p><p>Elsevier Full Articles. There are 379 full text articles and 103 abstracts from Elsevier. The articles in this subset have been selected from a list of articles provided by Professor Tim Clark from the Massachusetts Alzheimer's Disease Research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Test Data</head><p>The test set is composed of four reading tests. Each reading test consists of one document, with ten questions and a set of five choices per question. So, there are in total forty questions and 200 choices/options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">OMIM Term about Alzheimer</head><p>1,549 entities and related genes about Alzheimer diseases have been retrieved from OMIM website <ref type="bibr" coords="2,188.62,553.29,10.63,8.74" target="#b0">[1]</ref>. We use these terms to do query expansion in Run 4 and Run 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>The main system architecture is illustrated in Fig. <ref type="figure" coords="2,360.61,596.61,3.77,8.74">1</ref>. The expanded system architecture is pictured in Fig. <ref type="figure" coords="2,247.77,608.07,3.76,8.74" target="#fig_0">2</ref>. Fig. <ref type="figure" coords="2,276.23,608.07,5.01,8.74">1</ref> is the system architecture adopted in Runs 1, 2 and 3. In Run 4 and Run 5, we use the OMIM terms about Alzheimer as well as other resource to do query expansion. The detailed architecture for OMIM expanded system is shown in Fig. <ref type="figure" coords="2,194.49,642.57,3.77,8.74" target="#fig_0">2</ref>. Fig. <ref type="figure" coords="2,224.47,642.57,5.01,8.74" target="#fig_0">2</ref> is the expanded system architecture adopted in Run 4 and Run 5. Part A is the part of the main system architecture in Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Main system architecture</head><p>Let's explain the details about Fig. <ref type="figure" coords="4,283.55,575.48,3.76,8.74">1</ref>. Because QA4MRE test data is provided in XML format, we have to do some format cleaning work. Hence, we first split it to three parts: (1) documents, (2) questions and (3) answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing</head><p>After splitting QA4MRE test data to three parts, we need to do some processes so as not to cause implicit query handling during searching. They are described as follows. Stopword Removal. The Stopwords are removed from each question and answer option using a stopword list <ref type="bibr" coords="5,238.37,161.49,10.61,8.74" target="#b1">[2]</ref>.</p><p>Punctuation Removal. Punctuation characters are removed from the questions and answers. For example, "http://wt.jrc.it/" and "doug@nutch.org" are rephrased as "http wt jrc it" and "doug nutch org", respectively.</p><p>Stemming. Standard Porter stemming algorithm <ref type="bibr" coords="5,338.85,231.51,11.71,8.74" target="#b2">[3]</ref> is used to stem words in documents, questions and answers.</p><p>The remaining words in the question and answer are identified respectively as the query words and answer words.</p><p>Also, we expand some key words for the questions. For example, when facing with the word "experiment" in the question, we expand the related word "show" to the question. It is because we think words "experiment" and "show" are highly related each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Retrieving Query Word Related Sentences</head><p>After extraction of the query words, we use it to retrieve sentences from the documents. If a query word exactly matches with words in a sentence, then we view it as the relevant sentence and retrieve it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query Word Weighting Scheme</head><p>Each query word is assigned a weight to determine its importance for the sentences. We use TF and TF-IDF depending on different runs as the weights of the query words. In Run 1 and Run 4, we use TF to weight the query words. The remaining runs use TF-IDF to weight the query words.</p><p>TF Weighting. The formula of TF weighting is listed in Equation (1):</p><formula xml:id="formula_0" coords="5,234.18,498.79,236.32,32.82">i i i i Q Q Q Q f f TF max 1+ =<label>(1)</label></formula><p>where</p><formula xml:id="formula_1" coords="5,155.34,541.99,312.57,12.17">i Q TF is the term frequency of query word i Q . i Q f is the number of i Q</formula><p>appearing in the stemmed document. We assume that the weight of each query word has a baseline of 1. If a query word doesn't exist in the document, the formula will give i Q TF a value of 1.</p><p>TF-IDF Weighting. The formula of Inverted Document Frequency (IDF) is listed in the following.</p><formula xml:id="formula_2" coords="6,196.98,177.93,269.62,88.56">⎪ ⎪ ⎪ ⎪ ⎩ ⎪ ⎪ ⎪ ⎪ ⎨ ⎧ ≠ = ≠ = otherwise 0 0 and 0 if 1 . 0 0 if log 2 i i i i i Q Q Q Q Q f n n n N IDF (<label>2</label></formula><formula xml:id="formula_3" coords="6,466.60,217.83,3.89,8.74">)</formula><p>where i Q IDF is the inverse document frequency of query word i Q . N is the total number of documents in the corpus (i.e., QA4MRE background collections).</p><formula xml:id="formula_4" coords="6,124.74,299.11,345.79,30.07">i Q n is the number of documents in the corpus which i Q appears. i Q f</formula><p>is the number of i Q that appears in the stemmed document. We can't ignore the importance of a query word which doesn't exist in the corpus while counting TF-IDF. So, when 0 = i Q n and if i Q exists in the document, we give the inverse document frequency a value of 0.1 for the smoothing reason.</p><p>The TF-IDF formula is shown as follows:</p><formula xml:id="formula_5" coords="6,220.02,407.90,250.48,15.28">i i i Q Q Q IDF TF IDF TF × = -<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sentence Weighting Scores</head><p>If a query word matches words in the relevant sentence which we found at the sentence retrieval step, then the sentence gets the weight of that word. A sentence weighting score is calculated as Equation (4) and Equation (5):</p><formula xml:id="formula_6" coords="6,220.80,498.89,249.70,55.40">∑ ∈ = j i i S Q Q j TF TF SW _ (4) ∑ ∈ × = j i i i S Q Q Q j IDF TF TFIDF SW ) ( _<label>(5)</label></formula><p>where</p><formula xml:id="formula_7" coords="6,156.12,565.60,36.45,10.78">j TF SW _</formula><p>is the sum of TF for all query words appearing in the sentence S j . j TFIDF SW _ is the sum of TF-IDF for all query words appearing in the sentence S j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Answer Selection Algorithm</head><p>According to the sentence weighting scores, we can compute each answer's score in this phase. If an answer word matches words in the sentence S j , then its weighting value is recorded by the sentence. Each answer's score is the sum of the above values.</p><p>We choose the answer with the highest score to be the final answer. If there are multiple answers with the same highest scores, we select the different answer in the different runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Query Expansion</head><p>In this study, we use the OMIM Alzheimer-related terms as our extra knowledge base in Run 4 and Run 5. As shown in Fig. <ref type="figure" coords="7,283.11,213.99,3.77,8.74" target="#fig_0">2</ref>, OMIM terms are first preprocessed through stopword removal, punctuation removal and stemming. We call them as expanded query words. These expanded query words will combine with query words to compute the new weighting scores. The answer selection algorithm is the same as the approach in Section 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>We have submitted total five runs. Run 1 uses TF of the query words to weight the sentences. Run 2 and Run 3 use TF-IDF of the query words to weight the sentences. Runs 2 and 3 differ in the way that when multiple answers have the same scores in our system, we view them as different runs. Run 4 uses TF weighting scheme and takes OMIM terms about Alzheimer for query expansion. Run 5 uses TF-IDF weighting and takes OMIM terms about Alzheimer for query expansion. In summary, the weighting methods for each run are listing as follows.</p><p>TF: Run 1 TF-IDF: Run 2, Run 3 OMIM+TF: Run 4 OMIM+TF-IDF: Run 5</p><p>The main measure used in this evaluation campaign is called c@1, which is defined as follows.</p><p>) (</p><formula xml:id="formula_8" coords="7,234.66,481.24,235.84,35.55">1 1 @ n n n n n c R U R + = (6)</formula><p>where n R is the number of correctly answered questions, n U is the number of unanswered questions, and n is the total number of questions. Table <ref type="table" coords="7,163.24,548.61,5.01,8.74" target="#tab_1">1</ref> presents the evaluation results at question-answering level. In Table <ref type="table" coords="7,463.08,548.61,3.74,8.74" target="#tab_1">1</ref>, Column "Run ID" identifies five runs we have submitted. Column "C1" is the number of questions our system answered. Column "C2" is the number of questions our system are unanswered. Column "C3" is the number of questions answered with right candidate answer. Column "C4" is the number of questions answered with wrong candidate answer. Column "C5" is the number of questions unanswered with right candidate answer. Column "C6" is the number of questions unanswered with wrong candidate answer. Column "C7" is the number of questions unanswered with empty candidate. Column "c@1" is the value calculated in Equation (6). Table <ref type="table" coords="8,162.38,371.25,5.01,8.74" target="#tab_2">2</ref> presents the evaluation results at reading-test level. In Table <ref type="table" coords="8,423.33,371.25,3.77,8.74" target="#tab_2">2</ref>, Columns "R1", "R2", "R3", "R4" represent the c@1 measure over 4 reading tests respectively. Columns "Median", "Average" and "Standard Deviation" are the median, average and standard deviation values for the c@1 values for all questions.</p><p>From Tables <ref type="table" coords="8,193.60,417.27,5.01,8.74" target="#tab_1">1</ref> and<ref type="table" coords="8,222.20,417.27,3.77,8.74" target="#tab_2">2</ref>, we observe that Run 5 is the best run over other runs. Although Run 3 has the same c@1 measure as Run 5, it also remains some questions unanswered. It shows that using OMIM terms about Alzheimer as expansion has some positive effect in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this study, we utilize TF, TF-IDF and OMIM terms with background collections to help for machine reading comprehension. We observe that the OMIM terms are good features for answering questions in this task and the best c@1 measure is 0.20. The results also show some improvement space.</p><p>Our future work will focus on the query expansion part. Trying to extract some related words to the questions from corpus may improve the performance of the system. Also the anaphora resolution and some semantic inference are considered in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.94,534.12,320.28,9.02;4,134.94,545.91,162.37,8.74"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Expanded system architecture for OMIM background knowledge. Part A is illustrated in the bottom part of Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,379.69,654.09,7.51,8.74"><head></head><label></label><figDesc>1.    </figDesc><table coords="3,153.30,180.64,292.01,465.23"><row><cell></cell><cell>QA4MRE</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Test Data</cell><cell></cell><cell></cell></row><row><cell>Documents</cell><cell>Questions</cell><cell></cell><cell>Answers</cell></row><row><cell>Preprocessing</cell><cell cols="2">Preprocessing</cell><cell></cell></row><row><cell></cell><cell cols="2">Stopword</cell><cell>Stopword</cell></row><row><cell>Stemming</cell><cell>Stemmer Porter's</cell><cell>Removal</cell><cell>List</cell></row><row><cell></cell><cell cols="2">Punctuation</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Removal</cell><cell></cell></row><row><cell>Stemmed</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Documents</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Stemming</cell><cell></cell></row><row><cell>Query Word</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Related Sentence Retrieval</cell><cell>Query Words</cell><cell></cell><cell>Answer Words</cell></row><row><cell>Query Word Retrieved Sentences</cell><cell cols="2">Query Word Weighting Scheme</cell><cell>QA4MRE Background Collections</cell></row><row><cell></cell><cell>Sentence</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Weighting Scores</cell><cell></cell></row><row><cell></cell><cell cols="2">Answer Selection</cell><cell></cell></row><row><cell></cell><cell cols="2">Algorithm</cell><cell></cell></row><row><cell></cell><cell cols="2">Produce Final</cell><cell></cell></row><row><cell></cell><cell>Answers</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>PART A</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,128.94,149.43,325.82,84.36"><head>Table 1 .</head><label>1</label><figDesc>Evaluation results at question-answering level</figDesc><table coords="8,128.94,173.43,325.82,60.36"><row><cell>Run ID</cell><cell>C1</cell><cell>C2</cell><cell>C3</cell><cell>C4</cell><cell>C5</cell><cell>C6</cell><cell>C7</cell><cell>c@1</cell></row><row><cell>1</cell><cell>40</cell><cell>0</cell><cell>7</cell><cell>33</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.18</cell></row><row><cell>2</cell><cell>35</cell><cell>5</cell><cell>6</cell><cell>29</cell><cell>0</cell><cell>0</cell><cell>5</cell><cell>0.17</cell></row><row><cell>3</cell><cell>35</cell><cell>5</cell><cell>7</cell><cell>28</cell><cell>0</cell><cell>0</cell><cell>5</cell><cell>0.20</cell></row><row><cell>4</cell><cell>40</cell><cell>0</cell><cell>7</cell><cell>33</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.18</cell></row><row><cell>5</cell><cell>40</cell><cell>0</cell><cell>8</cell><cell>32</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,125.40,260.85,339.46,94.74"><head>Table 2 .</head><label>2</label><figDesc>Evaluation results at reading-test level</figDesc><table coords="8,125.40,284.91,339.46,70.68"><row><cell>Run ID</cell><cell>R1</cell><cell>R2</cell><cell>R3</cell><cell>R4</cell><cell>Median</cell><cell>Average</cell><cell>Standard</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Deviation</cell></row><row><cell>1</cell><cell>0.00</cell><cell>0.40</cell><cell>0.20</cell><cell>0.10</cell><cell>0.15</cell><cell>0.18</cell><cell>0.17</cell></row><row><cell>2</cell><cell>0.00</cell><cell>0.40</cell><cell>0.13</cell><cell>0.12</cell><cell>0.13</cell><cell>0.16</cell><cell>0.17</cell></row><row><cell>3</cell><cell>0.00</cell><cell>0.40</cell><cell>0.13</cell><cell>0.24</cell><cell>0.19</cell><cell>0.19</cell><cell>0.17</cell></row><row><cell>4</cell><cell>0.00</cell><cell>0.50</cell><cell>0.20</cell><cell>0.00</cell><cell>0.10</cell><cell>0.18</cell><cell>0.24</cell></row><row><cell>5</cell><cell>0.00</cell><cell>0.40</cell><cell>0.20</cell><cell>0.20</cell><cell>0.20</cell><cell>0.20</cell><cell>0.16</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,128.12,618.46,342.51,7.85;8,142.74,628.84,327.75,7.85;8,142.74,639.16,212.84,7.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,446.13,618.46,24.50,7.85;8,142.74,628.84,327.75,7.85;8,142.74,639.16,33.53,7.85">Online Mendelian Inheritance in Man (OMIM), a Knowledgebase of Human Genes and Genetic Disorders</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Amberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Bocchini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">A</forename><surname>Mckusick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,182.27,639.16,64.83,7.85">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="55" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.12,650.02,337.20,7.85" xml:id="b1">
	<monogr>
		<ptr target="http://www.lextek.com/manuals/onix/stopwords1.html" />
		<title level="m" coord="8,142.74,650.02,47.74,7.85">Stopword list</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,128.11,660.64,342.52,7.85;8,142.74,670.96,278.64,7.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,191.05,660.64,123.52,7.85">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,437.10,660.64,33.54,7.85;8,142.74,670.96,86.22,7.85">Readings in Information Retrieval</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Willet</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="313" to="316" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
