<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,126.00,152.74,343.06,12.52;1,168.60,170.74,257.94,12.52">IDRAAQ: New Arabic Question Answering system based on Query Expansion and Passage Retrieval</title>
				<funder ref="#_9aHwpEf">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_U3neTjf">
					<orgName type="full">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.84,208.21,76.28,10.90"><forename type="first">Lahsen</forename><surname>Abouenour</surname></persName>
							<email>abouenour@yahoo.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Mohammadia School of Engineers</orgName>
								<orgName type="institution">Med Vth University-Agdal</orgName>
								<address>
									<settlement>Rabat</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.44,208.21,73.07,10.90"><forename type="first">Karim</forename><surname>Bouzoubaa</surname></persName>
							<email>karim.bouzoubaa@emi.ac.ma</email>
							<affiliation key="aff0">
								<orgName type="department">Mohammadia School of Engineers</orgName>
								<orgName type="institution">Med Vth University-Agdal</orgName>
								<address>
									<settlement>Rabat</settlement>
									<country key="MA">Morocco</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.20,208.21,49.74,10.90"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Natural Language Engineering Lab</orgName>
								<orgName type="institution" key="instit1">ELiRF</orgName>
								<orgName type="institution" key="instit2">Universitat Politècnica de València</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,126.00,152.74,343.06,12.52;1,168.60,170.74,257.94,12.52">IDRAAQ: New Arabic Question Answering system based on Query Expansion and Passage Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">213D4F29BC2F9B5BE124E34D67D39551</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Arabic Question Answering</term>
					<term>Passage Retrieval</term>
					<term>Query Expansion</term>
					<term>Distance N-gram Density Model</term>
					<term>Arabic WordNet</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Arabic is one of the languages which are less concerned by researchers in the field of Question Answering. The paper presents core modules of a new Arabic Question Answering system called IDRAAQ. These modules aim at enhancing the quality of retrieved passages with respect to a given question. Experiments have been conducted in the framework of the main task of QA4MRE@CLEF 2012 that includes this year the Arabic language. Two runs were submitted. Both runs only use reading test documents to answer questions. The difference between the two runs exists in the answer validation process which is more relaxed in the second run. The Passage Retrieval (PR) module of our system presents multi-levels of processing in order to improve the quality of returned passage and thereafter the performances of the whole system. The PR module of IDRAAQ is based on keyword-based and structure-based levels that respectively consist in: (i) a Query Expansion (QE) process relying on Arabic WordNet semantic relations; (ii) a Distance Density N-gram Model based passage retrieval system. The latter level uses passages retrieved on the basis of QE queries and re-ranks them according to a structure-based similarity score.</p><p>Named Entities are recognized by means of a mapping between the YAGO ontology and Arabic WordNet. The experiments that we conducted show that with respect to the accuracy and c@1 measure, IDRAAQ registered encouraging performances in particular with factoid questions. The same experiments allowed us to identify the lacks of the system especially when processing non factoid questions and at the Answer Validation stage. The IDRAAQ system, which is still under construction, will integrate a Conceptual Graph-based passage re-ranking introducing a semantic level to its PR module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Question Answering for Machine Reading Evaluation (QA4MRE) at CLEF 2012 is the fourth campaign which represents an evolution of previous evaluation approaches in Natural Language Processing (NLP), including Question Answering, Recognizing-Textual Entailment and Answer Validation. Like previous editions, the campaign provides large document collections that serve as a background for each particular reading test. Indeed, Machine Reading requires a deeper analysis and inference of text and in turn may need background knowledge acquisition.</p><p>The 2012 test set is composed of 4 topics, namely "Aids", "Climate change" and "Music and Society" -the same topics adopted last year-plus one additional new topic, namely "Alzheimer". This year is also particular in that two languages have been added: Arabic and Bulgarian in addition to the previously considered languages namely English, German, Italian, Romanian and Spanish. Materials are exactly the same in all languages, created using parallel translations.</p><p>We have participated in the main task in order to evaluate an ongoing Arabic QA system called IDRAAQ: Information and Data Reasoning for Answering Arabic Questions. As it is an under construction project, only two runs have been submitted. The two runs have not considered any background collection. Answers were searched within the documents of the reading test in concern.</p><p>Section 2 presents an overview of IDRAAQ. Section 3 describes the main tools and resources used in this system. The experiments carried out on test data sets are discussed in Section 4 along with the results. The conclusions are drawn in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Overview of the IDRAAQ system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Architecture</head><p>The IDRAAQ<ref type="foot" coords="2,193.44,514.74,3.24,7.09" target="#foot_0">1</ref> system is fully programmed in Java. The system also makes use of other third party components and resources. The system is designed around the three typical modules of a Question Answering system, namely (see Figure <ref type="figure" coords="2,405.49,540.25,3.72,10.90">1</ref>): (i) Question analysis and classification module. In this module a question is analyzed in order to extract its keywords, identify the structure of the expected answer and form the query to be passed to the PR module.</p><p>(ii) Passage Retrieval (PR) module. This module is one of the most important components of a Q/A system. The quality of the results returned by such system depends mainly on the quality of the PR module. Indeed, this module uses the query formed by the previous module and extracts a list of passages from an Information Retrieval process (generally a Search Engine such as Google 2 or Yahoo! 3 ). Thereafter, this module has to perform a ranking process in order to improve the relevance of the candidate passages according to the user question.</p><p>(iii) Answer Validation (AV) module. This module tries to validate an answer from a list of candidate answers relying on passages that are provided by the previous module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. The three modules of the IDRAAQ system</head><p>Since the PR module provides candidate passages in which the Answer Validation module tries searching the right answer, the performance of the IDRAAQ system is mainly dependant on this module and on the quality of its returned passages. As illustrated in Figure <ref type="figure" coords="3,190.09,440.29,3.76,10.90">1</ref>, the PR module of IDRAAQ is formed by two implemented levels: keyword-based level (Label 1) and structure-based level (Label 2). The former integrates a semantic QE process and the latter uses a Distance Density N-gram based PR tool.</p><p>Another level (third level) is under construction within the IDRAAQ system: the semantic reasoning level. It is based on comparing representations of question and candidate passages in terms of Conceptual Graphs (CGs) <ref type="bibr" coords="3,361.44,524.29,54.67,10.90" target="#b10">(Sowa, 1984)</ref> through projection and generalization operations. Since this level is on its building and testing stage, we did not consider the corresponding process in the current edition of QA4MRE. Therefore, in the following sub sections we only provide details about the first two levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Keyword-based level</head><p>This level is concerned with a semantic Query Expansion (QE) process. Each question keyword is substituted by its semantically related terms that are extracted from the Arabic WordNet (AWN) <ref type="bibr" coords="3,241.93,646.21,82.53,10.90" target="#b7">(Elkateb et al., 2006)</ref>  c. Words that share the AWN synsets that are hyponyms of each SW i ; Let us refer to these synsets by HYPO(SW i ); d. Words that share the AWN synsets that are hypernyms of each SW i ; These synsets are referred to by HYPR(SW i ); e. Words that appear in the definition of the SUMO concept which is equivalent to each SW i .</p><p>The same process is again performed for words related to HYPO(SW i ) and HYPR(SW i ). Note that in order to avoid endless recursive process we move just 2 levels up and down in the AWN hierarchy starting from the synset SW i . In this way, for each question keyword, we generate a list of words that represent the context of the keyword in the AWN hierarchy as well as semantically related terms in other similar contexts in this hierarchy.</p><p>This process extracts the words belonging to the context of the expanded word by moving up and down in the AWN hierarchy. In order to catch other contexts that are semantically related to the context of the original word (i.e., W i ), we rely on the SUMO concept (SUMO(W i )) which is linked to SW i . In SUMO, each concept has a definition which involves many other SUMO concepts. By moving to the synsets that are equivalent to these latter concepts, we can get other semantically related words.</p><p>The semantic QE process illustrated in Figure <ref type="figure" coords="5,325.70,400.21,4.98,10.90">1</ref> results in a number of new terms. These terms are used to form new queries by substituting a keyword in the question by its related terms. Note that in the case of Named Entities (NEs) keywords, we substitute the keyword just by its synonyms. The hypernyms are just added before the keyword in the question. This is due to the fact that a hypernym of a NE is usually its category (for instance person, country, etc.).</p><p>IDRAAQ uses an enriched version of AWN. This enrichment mainly concerns NEs, noun hyponymy relations and verbs. As factoid questions represent high percentage of processed questions, a mapping between AWN and the large English NE ontology called YAGO<ref type="foot" coords="5,218.04,518.70,3.24,7.09" target="#foot_5">6</ref> was done and was part of the considered AWN release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Structure-based level</head><p>The objective of this level is filtering the passages that would be returned after applying level 1. As mentioned above, for each question, different new queries are generated according to the terms extracted from AWN. These queries are important in number but are not all relevant for the question that may lead in considering irrelevant passages. Thus, the structure-based level introduces a new criterion to efficiently rerank passages: the Distance N-gram Density <ref type="bibr" coords="5,305.17,630.25,81.09,10.90" target="#b8">(Gomez et al., 2005)</ref>. This model considers sequence of n adjacent words (n-gram) extracted from a sentence or a question. All possible n-grams of the question are searched. It also assigns them a score according to the n-grams and weight that appear in the retrieved passages.</p><p>If a passage contains one or more related terms (those generated by the AWNbased QE process) then it is retrieved. However, the relevancy of this passage depends on the structure in which these terms appear. The more this structure is similar to the one of the question, the more relevant the passage is considered.</p><p>In the IDRAAQ system, this model is implemented through the Java Information Retrieval System (JIRS) <ref type="bibr" coords="6,230.53,232.21,86.96,10.90" target="#b8">(Gomez et al., 2005)</ref>. This language independent system underwent some adaptations in order to be used in the context of the Arabic language <ref type="bibr" coords="6,124.68,256.21,84.07,10.90" target="#b6">(Benajiba et al. 2007</ref>). The main modifications were made on the Arabic languagerelated files (text encoding, stop-words, list of characters for text normalization, Arabic special characters, question words, etc.).</p><p>The JIRS is integrated in the PR module of IDRAAQ following many steps:</p><p>Step 1: extract related queries of a question;</p><p>Step 2: the list of queries is formatted using the JIRS input file;</p><p>Step 3: documents are also formatted using the SGML JIRS format so that a collection of documents is built;</p><p>Step 4: the collection built in step 3 is indexed using the corresponding JIRS process;</p><p>Step 5: the JIRS "PassageSearch" process is performed on the indexed collection and using the input file. We customize the system to only the first five passages are retrieved for each query in the input file;</p><p>Step 6: over all the queries, the five passages, with the best JIRS similarity score, are considered in the Answer Validation module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>The 2012 test set is composed of 4 topics; each topic includes 4 reading tests. Each reading test consists of one document, accompanied by 10 questions, each with a set of five answer options per question. Therefore, for each language task, there are in total:</p><p>16 test documents (4 documents for each of the four topics) 160 questions (10 questions for each document) 800 choices/options (5 for each question)</p><p>Questions have the following characteristics: They are in the form of multiple choice, where for each question, 5 possible answers are given; They are designed so that focus on testing the comprehension of one single document;</p><p>Test the reasoning capabilities of systems, which means that inferences, relative clauses, elliptic expressions, meronymy, metonymy, temporal and spatial reasoning, and reasoning on quantities may be exploited;</p><p>They may involve background knowledge, i.e., information that is not present in the test document given. In such cases, information from the Background collections is needed to fill in the knowledge gap to answer the question.</p><p>Questions may be of the following types: 1. FACTOID: Where or When or By--Whom 2. CAUSAL: What was the cause/result of Event X? 3. METHOD: How did X do Y? Or: In what way did X come about? 4. PURPOSE: Why was X brought about? Or: What was the reason for doing X? 5. WHICH IS TRUE: Here one must select the correct alternative from a number of statements, e.g. What can a 14 year old girl do?</p><p>The IDRAAQ system applies for each question the preprocessing stage, the keywordbased stage and the structure-based stage. The answer checking process matches candidate answers with returned passages. The first run that we have submitted uses a strict answer checking process while the second introduces a relaxation especially when the answer is composed of more than two words.</p><p>Each test receives an evaluation score between 0 and 1 using c@1 <ref type="bibr" coords="7,415.44,388.21,55.05,10.90;7,124.68,400.21,21.57,10.90" target="#b9">(Peñas et al., 2011)</ref>. This measure, already tried in previous CLEF QA Tracks, encourages systems to reduce the number of incorrect answers while maintaining the number of correct ones by leaving some questions unanswered. Systems receive evaluation scores from two different perspectives: 1. At the question-answering level: correct answers are counted individually without grouping them; 2. At the reading-test level: figures both for each reading test as a whole and for each separate topic are given.</p><p>Thus, two measures have been considered as follows:</p><p>Overall Accuracy which is calculated using the formula:</p><formula xml:id="formula_0" coords="7,160.08,558.46,69.50,8.88">Accuracy = nr/n</formula><p>where: nr: is the number of correctly answered questions n: is the total number of questions The c@1 measure which is represented by the formula:</p><formula xml:id="formula_1" coords="7,160.08,654.46,118.93,8.88">C@1 = (nr + nu * (nr/n)) / n</formula><p>where: nu: is the number of unanswered questions Obtained results also presents number of unanswered question with right and wrong candidate answers. However, in both runs, we did not consider this possibility in the submitted outputs.</p><p>Table <ref type="table" coords="8,150.25,196.21,4.98,10.90" target="#tab_1">1</ref> and 2 presents the obtained results in terms of: (i) accuracy over all questions and (ii) the overall as well as detailed c@1 measure.  <ref type="table" coords="8,203.88,459.49,4.98,10.90" target="#tab_1">1</ref> above, the overall accuracy reaches 0.13 in the second run. This accuracy is calculated over the 160 questions. If we only consider the 70 answered questions (21+49 in Table <ref type="table" coords="8,232.09,483.49,3.59,10.90" target="#tab_1">1</ref>), the accuracy is 0.30 in the case of run #2.</p><p>Regarding the c@1 measure, Table <ref type="table" coords="8,272.30,507.49,4.98,10.90" target="#tab_2">2</ref> shows the overall of 0.21 as of the second run (versus 0.13 for the first run). With respect to this measure, our system registered different performances over the four topics. Indeed, from Table <ref type="table" coords="8,383.05,531.49,4.98,10.90" target="#tab_2">2</ref> the maximum value was reached over Topic #1 (i.e. AIDS) in the two runs (0.25 in run #1 versus 0.36 in run #2).</p><p>At reading-test level, our system reached its best value of c@1 measure when answering questions belonging to topic #1 (i.e., AIDS). Figure <ref type="figure" coords="8,363.12,591.49,4.98,10.90" target="#fig_1">3</ref> illustrates a comparison between the best c@1 measures obtained over the four topics with respect to this level. Topic #3 is the one for which lower performances have been reached.</p><p>Let us analyze questions for which our system succeeds and those for which it fails, i.e., questions belonging to the above topics (i.e., topic #1 and #3).</p><p>From this analysis, most of the answered questions are factoid ones <ref type="bibr" coords="8,414.61,675.49,55.89,10.90;8,124.68,687.49,43.68,10.90">(When, Who, What, etc.)</ref>. This shows that using Arabic WordNet mapped with YAGO (which con-tains high number of Named Entities) has a positive impact on system performances especially when processing factoid questions. On the other hand, the questions where the system fails to get a correct answer falls into five categories: Questions that are not factoid such as LIST questions (questions starting with Give a list of . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The current edition of QA4MRE has considered for the first time the Arabic language. We took advantage from this opportunity to test our semantic QE process combined with the Distance N-gram Density model. The obtained results are encour-aging in particular for factoid questions. The analysis of IDRAAQ system performances allowed us to identify the category of questions in which the system fails to validate the right answer.</p><p>According to previous preliminary experiments <ref type="bibr" coords="10,331.10,196.21,98.58,10.90">(Abouenour et al., 2009)</ref>, the integration of the third level based on Conceptual Graphs and semantic similarity would improve the performances of the system at the PR module as well as the Answer Validation module. Indeed, representing knowledge in the question and candidate passages would help in comparing them at a semantic level which is more advanced than the keyword and structure levels that we have considered in this experiment. The CLEF 2012 Gold standard for the Arabic language will help us in pre-testing the capabilities of the system with the third level as well as the use of background collection and other resources for answering the questions.</p><p>The perspective of the current work is preparing the system in order to participate in the next edition of QA4MRE for Arabic in an aim of reaching maturity of the best well-known QA systems for other languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,192.36,550.21,210.40,9.85"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. AWN-based QE integrated in the IDRAAQ system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,199.92,369.37,195.40,9.85"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Best c@1 obtained in reading tests over topics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,124.68,245.77,345.84,182.01"><head>Table 1 .</head><label>1</label><figDesc>Overall accuracy of IDRAAQ over the two submitted runs</figDesc><table coords="8,124.68,245.77,345.84,182.01"><row><cell>RUNS</cell><cell>OVERALL ACCURACY</cell><cell cols="2">ANSWERED RIGHT WRONG</cell><cell cols="3">UNANSWERED EMPTY RIGHT WRONG</cell></row><row><cell>run #1</cell><cell>0.08</cell><cell>12</cell><cell>21</cell><cell>127</cell><cell>0</cell><cell>0</cell></row><row><cell>run #2</cell><cell>0.13</cell><cell>21</cell><cell>49</cell><cell>90</cell><cell>0</cell><cell>0</cell></row><row><cell>RUNS</cell><cell>Overall</cell><cell>Topic #1</cell><cell>c@1 measure Topic #2</cell><cell cols="2">Topic #3</cell><cell>Topic #4</cell></row><row><cell>run #1</cell><cell>0.13</cell><cell>0.25</cell><cell>0.18</cell><cell>0.05</cell><cell></cell><cell>0.05</cell></row><row><cell>run #2</cell><cell>0.21</cell><cell>0.36</cell><cell>0.19</cell><cell>0.08</cell><cell></cell><cell>0.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,124.68,442.45,272.07,27.93"><head>Table 2 .</head><label>2</label><figDesc>Overall and detailed c@1 related to IDRAAQ As shown in Table</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,131.16,673.21,339.54,9.85;2,136.08,684.25,221.86,9.85"><p>The word "IDRAAQ" in Arabic has the following meanings and senses: to understand, to recognize, to reach an objective, knowledge, intelligence, etc.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,129.96,694.69,85.49,9.85"><p>http://www.google.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,129.96,705.01,83.08,9.85"><p>http://www.yahoo.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,130.68,682.93,339.79,9.85;4,136.08,693.97,237.45,9.85"><p>In AWN a synset is a group of synonyms that can be used in a specific context. Each word can have many senses according to the synset to which it belongs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,129.96,705.01,140.29,9.85"><p>http://sourceforge.net/projects/alkhalil/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,138.48,694.33,332.04,9.85;5,136.08,705.01,105.70,9.85"><p>Yet Another Great Ontology: available at http://www.mpi-inf.mpg.de/YAGOnaga/YAGO/downloads.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The <rs type="funder">European Commission</rs> as part of the <rs type="programName">WIQ-EI IRSES-Project</rs> (grant no. <rs type="grantNumber">269180</rs>) within the <rs type="projectName">FP 7 Marie Curie People Framework</rs> has partially funded the work of the third author. His work was carried out also in the framework of the <rs type="projectName">MICINN Text-Enterprise</rs> (<rs type="grantNumber">TIN2009-13391-C04-03</rs>) research project and the <rs type="funder">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9aHwpEf">
					<idno type="grant-number">269180</idno>
					<orgName type="project" subtype="full">FP 7 Marie Curie People Framework</orgName>
					<orgName type="program" subtype="full">WIQ-EI IRSES-Project</orgName>
				</org>
				<org type="funded-project" xml:id="_U3neTjf">
					<idno type="grant-number">TIN2009-13391-C04-03</idno>
					<orgName type="project" subtype="full">MICINN Text-Enterprise</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,136.08,537.73,334.64,10.90;10,124.68,549.73,345.93,10.90;10,124.68,561.73,332.49,10.90" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,348.84,539.57,121.88,9.05;10,124.68,551.57,224.20,9.05">Three-level approach for Passage Retrieval in Arabic Question /Answering Systems</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Abouenour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bouzoubaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,369.12,549.73,101.48,10.90;10,124.68,561.73,257.73,10.90">Proc. of the 3rd International Conference on Arabic Language Processing CITALA2009</title>
		<meeting>of the 3rd International Conference on Arabic Language essing CITALA2009<address><addrLine>Rabat, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,136.08,585.73,334.57,10.90;10,124.68,597.73,345.90,10.90;10,124.68,609.73,345.94,10.90;10,124.68,621.73,345.82,10.90;10,124.68,633.73,202.16,10.90" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,351.60,587.57,119.05,9.05;10,124.68,599.57,329.18,9.05">Structure-based evaluation of an Arabic semantic Query Expansion using the JIRS Passage Retrieval system</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Abouenour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bouzoubaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,124.68,609.73,340.91,10.90">Proc. Workshop on Computational Approaches to Semitic Languages, E-ACL-2009</title>
		<meeting>Workshop on Computational Approaches to Semitic Languages, E-ACL-2009<address><addrLine>Athens, Greece; Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04">2009b. April, 2009</date>
			<biblScope unit="page" from="62" to="68" />
		</imprint>
	</monogr>
	<note>Published by the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="10,136.08,657.73,334.53,10.90;10,124.68,669.73,345.90,10.90;10,124.68,681.73,345.91,10.90;11,124.68,148.21,345.97,10.90;11,124.68,160.21,51.82,10.90" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,360.60,659.57,110.01,9.05;10,124.68,671.57,238.09,9.05">An evaluated semantic QE and structure-based approach for enhancing Arabic Q/A</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Abouenour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bouzoubaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,129.51,681.73,173.85,10.90;10,344.89,681.73,125.70,10.90;11,124.68,148.21,231.46,10.90">IEEE International Journal on Information and Communication Technologies (IJICT)</title>
		<imprint>
			<publisher>Serial Publications</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Advances in Arabic Language Processing</note>
</biblStruct>

<biblStruct coords="11,136.08,184.21,334.50,10.90;11,124.68,196.21,345.90,10.90;11,124.68,208.21,345.83,10.90;11,124.68,220.21,291.58,10.90" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,351.84,186.05,118.74,9.05;11,124.68,196.21,345.90,10.90;11,124.68,208.21,345.83,10.90;11,124.68,220.21,166.78,10.90">Using the Yago ontology as a resource for the enrichment of Named Entities in Arabic WordNet. Workshop on Language Resources (LRs) and Human Language Technologies (HLT) for Semitic Languages Status, Updates, and Prospects</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Abouenour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bouzoubaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,298.09,220.21,85.43,10.90">LREC&apos;10 Conference</title>
		<meeting><address><addrLine>Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,136.08,244.21,334.51,10.90;11,124.68,256.21,345.84,10.90;11,124.68,268.21,244.77,10.90" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,231.12,246.05,239.47,9.05;11,124.68,258.05,122.16,9.05">On the Improvement of Passage Retrieval in Arabic Question/Answering (Q/A) Systems</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Abouenour</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-22327-3_50</idno>
	</analytic>
	<monogr>
		<title level="s" coord="11,255.36,256.21,147.85,10.90">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">6716</biblScope>
			<biblScope unit="page" from="336" to="341" />
			<date type="published" when="2011">2011. 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,373.44,268.21,97.05,10.90;11,124.67,280.21,190.67,10.90" xml:id="b5">
	<monogr>
		<title level="m" coord="11,124.67,280.21,37.67,10.90">NLDB&apos;11</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin-Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,136.08,304.21,334.58,10.90;11,124.68,316.21,345.86,10.90;11,124.68,328.21,311.25,10.90" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,335.39,306.05,135.27,9.05;11,124.68,318.05,83.68,9.05">Adapting JIRS Passage Retrieval System to the Arabic</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Benajiba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,228.00,316.21,242.54,10.90;11,124.68,328.21,125.92,10.90">Proc. 8th Int. Conf. on Comput. Linguistics and Intelligent Text Processing, CICLing-2007</title>
		<meeting>8th Int. Conf. on Comput. Linguistics and Intelligent Text essing, CICLing-2007</meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2007">2007. 4394</date>
			<biblScope unit="page" from="530" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,136.08,352.21,334.52,10.90;11,124.68,364.21,345.92,10.90;11,124.68,376.21,165.71,10.90" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,201.00,364.21,189.90,10.90">Arabic WordNet and the Challenges of Arabic</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Elkateb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Farwell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pease</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alkhalifa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,410.40,364.21,60.20,10.90;11,124.68,376.21,112.94,10.90">proceedings of Arabic NLP/MT Conference</title>
		<meeting>Arabic NLP/MT Conference<address><addrLine>London, U</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,290.39,376.21,9.70,10.90;11,136.08,400.21,334.53,10.90;11,124.68,412.21,345.78,10.90;11,124.68,424.21,345.83,10.90;11,124.67,436.21,345.80,10.90;11,124.68,448.21,14.61,10.90" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,158.03,414.05,264.96,9.05">Language independent passage retrieval for question answering</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Montes-Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Villasenor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,443.88,412.21,26.58,10.90;11,124.68,424.21,305.55,10.90">Fourth Mexican International Conference on Artificial IntelligenceMICAI 2005</title>
		<title level="s" coord="11,440.17,424.21,30.35,10.90;11,124.67,436.21,108.83,10.90">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Monterrey, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="816" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,136.08,472.21,334.63,10.90;11,124.68,484.21,345.93,10.90;11,124.68,496.21,345.91,10.90;11,124.68,508.21,37.65,10.90" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,244.68,472.21,172.03,10.90">A Simple Measure to Assess Non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,434.99,472.21,35.72,10.90;11,124.68,484.21,345.93,10.90;11,124.68,496.21,203.03,10.90">Proceedings of 49th Annual Meeting of the Association for Computational Linguistics-Human Language Technologies (ACL-HLT 2011)</title>
		<meeting>49th Annual Meeting of the Association for Computational Linguistics-Human Language Technologies (ACL-HLT 2011)<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">June 19-24, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,136.08,532.21,334.38,10.90;11,124.68,544.21,150.94,10.90" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="11,227.51,532.21,242.95,10.90;11,124.68,544.21,32.74,10.90">Conceptual Structures: Information Processing in Mind and Machine</title>
		<author>
			<persName coords=""><forename type="first">Sowa</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
