<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,268.12,116.95,79.11,12.62;1,185.43,134.89,244.48,12.62;1,165.44,152.82,284.48,12.62;1,258.05,170.75,99.25,12.62">CLaC Labs Processing Modality and Negation Working Notes for QA4MRE Pilot Task at CLEF 2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.13,208.42,75.14,8.74"><forename type="first">Sabine</forename><surname>Rosenberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CLaC Lab</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<addrLine>1455 de Maisonneuve Blvd West</addrLine>
									<postCode>H3W 2B3</postCode>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.38,208.42,61.43,8.74"><forename type="first">Halil</forename><surname>Kilicoglu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CLaC Lab</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<addrLine>1455 de Maisonneuve Blvd West</addrLine>
									<postCode>H3W 2B3</postCode>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,361.65,208.42,63.57,8.74"><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
							<email>bergler@cse.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CLaC Lab</orgName>
								<orgName type="institution">Concordia University</orgName>
								<address>
									<addrLine>1455 de Maisonneuve Blvd West</addrLine>
									<postCode>H3W 2B3</postCode>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,268.12,116.95,79.11,12.62;1,185.43,134.89,244.48,12.62;1,165.44,152.82,284.48,12.62;1,258.05,170.75,99.25,12.62">CLaC Labs Processing Modality and Negation Working Notes for QA4MRE Pilot Task at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D46F01E099E6F89002D676E925048935</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>shallow semantics</term>
					<term>negation</term>
					<term>modality</term>
					<term>factuality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For the QA4MRE 2012 Pilot Task on Negation and Modality, CLaC Labs implemented a general, lightweight negation and modality module based on linguistic rules. The strong results confirm the suitability of linguistic heuristics for low-level semantic features and showcase their robustness across the different subgenres of the QA4MRE corpora.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Processing negation and modality is very relevant for tasks like question anwsering because extracted information that falls within the scope of a negation cue (not, no, never, ...) cannot be presented as asserted information. Similarily, information falling within the scope of a modal cue (could, should, would,...) cannot be presented as factual or certain. Negation and modality have been addressed as independent tasks themselves, rather than as components of other tasks in recent shared tasks and workshops such as detection of negation and hedging at CoNLL <ref type="bibr" coords="1,217.99,505.90,9.96,8.74" target="#b2">[3]</ref>, BioNLP <ref type="bibr" coords="1,272.24,505.90,9.96,8.74" target="#b5">[6]</ref>, the Negation and Speculation in NLP Workshop <ref type="bibr" coords="1,158.13,517.86,10.52,8.74" target="#b8">[9]</ref> and the *Sem 2012 Shared Task on Processing the Scope and Focus of Negation <ref type="bibr" coords="1,177.87,529.81,14.61,8.74" target="#b9">[10]</ref>. The availability of data sets such as the BioScope Corpus <ref type="bibr" coords="1,462.33,529.81,14.61,8.74" target="#b12">[13]</ref>, and the FactBank Corpus <ref type="bibr" coords="1,248.53,541.77,15.50,8.74" target="#b11">[12]</ref> have allowed for further progress on modality and negation research. The QA4MRE Pilot Task: Processing Modality and Negation at CLEF 2012 builds upon these recent efforts.</p><p>The Pilot task has 3 main requirements: The first one being to detect whether any elements of a text are negated. Within the context of this task, negation is defined as a grammatical device which is used to determine if an event or situation has not taken place. Consider Example <ref type="bibr" coords="1,354.05,613.50,11.62,8.74" target="#b0">(1)</ref>, where the event come is negated, and one could now infer that half of Europe's electricity comes from other than fossil fuels.</p><p>(1) Half of Europe's electricity does not come from fossil fuels.</p><p>The second requirement is to detect whether any parts of the text are modalised. For this task: if an event or situation is determined to not be certain nor factual then it is modalised. In Example <ref type="bibr" coords="2,306.24,143.90,11.62,8.74" target="#b1">(2)</ref>, the event come is considered to be modalised due to the auxiliary might which renders the event to be uncertainit is neither true nor false that half of Europe's electricity comes from fossil fuels -but possibly it does.</p><p>(2) Half of Europe's electricity might come from fossil fuels.</p><p>The third requirement of the task is the most complex: to determine, whether and how the two cases might interact. Example (3) demonstrates that the event come is modalised as in Example (2), however it is also negated as in Example <ref type="bibr" coords="2,151.32,248.45,11.62,8.74" target="#b0">(1)</ref>. The interpretation of this sentence is completely different due to both negation and modality affecting the event come -it is not a certain fact that half of Europe's electricity comes from other than fossil fuels -but it possibly does.</p><p>(3) Half of Europe's electricity might not come from fossil fuels.</p><p>The pilot task is framed as an annotation task where each document in the data set is pre-annotated for events. An event is defined as any of the main verbs mentioned within the text. The events are extracted automatically with the Stanford POS Tagger (v. 3.0, 2010-05-10) <ref type="bibr" coords="2,334.06,343.68,9.96,8.74" target="#b7">[8]</ref>. The goal of the task is to then determine whether an event present in the text is within the scope of a negation, in the scope of a modal or within the scope of both.</p><p>We present a linguistically inspired general Negation and Modality detection system that identifies negation and modality triggers, and in a second step determines their scope from dependency graphs. In the final step, the only one specific to the pilot task, we determine whether any mentioned event within the text is within the detected scopes of negation, modality or within the intersection of both. Consequently, the output of the system is a list of all the events, each one with a specific label -the possible labels are NEG: the event is found to be negated only, MOD: the event is found to be modalised only, NEGMOD: the event is found to be both negated and modalised, or NONE: the event is found neither to be negated nor modalised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Data Set</head><p>The test data set for the pilot task is composed of 8 English documents part of the larger test set for the main QA4MRE Task. It is divided into 4 topics: AIDS, Climate Change, Music and Society, and Alzheimer's Disease. Two documents were taken from each topic. Each test document has at least 100 events (on average) to which the relevent label should be assigned. The training set consisted of one document from the Economist. It contained 96 events. 46 of the events in the training example were labeled as MOD, 49 were labeled as NONE, 1 was labeled as NEG and 0 were labeled as NEGMOD. The guidelines for the pilot task <ref type="bibr" coords="2,156.93,633.20,10.52,8.74" target="#b7">[8]</ref> also contained some extra example sentences for each possible labelwhich proved helpful in developing our system. We also utilized the background collection data available for the QA4MRE task in order to develop our heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>For the pilot task, CLaC Labs implemented a general lightweight Negation and Modality module. The heuristics-based system is composed of three modules for the GATE <ref type="bibr" coords="3,183.41,165.76,10.52,8.74" target="#b0">[1]</ref> environment: the first component detects and annotates negation and modality cues present in the corpus, the second component detects and annotates the syntactic scope of the detected instances of negation and modality. We initally developed these first two components for specifically detecting and annotating instances of negation within text. This base system NEGATOR was developed independently drawing on data from MPQA <ref type="bibr" coords="3,372.11,225.54,15.50,8.74" target="#b13">[14]</ref> and TIMEBANK <ref type="bibr" coords="3,456.61,225.54,23.98,8.74" target="#b10">[11]</ref> with validation on Bio-Scope <ref type="bibr" coords="3,267.14,237.49,14.61,8.74" target="#b12">[13]</ref>, and the *SEM 2012 Task <ref type="bibr" coords="3,406.59,237.49,15.50,8.74" target="#b9">[10]</ref> on detecting the focus of Negation. We extended NEGATOR for the requirements of the Pilot task to include the functionality for also detecting instances of modality within text. The third component was specifically developed for the pilot task and is intended to validate the first two, now extended components and for the determination of which of the annotated events are within the detected scopes of negation, modality or within the intersection of both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Preprocessing</head><p>Parser-based, our modality and negation detection pipeline requires as input entire sentences. The system then performs standard preprocessing using prebuilt GATE modules <ref type="bibr" coords="3,206.00,378.85,9.96,8.74" target="#b0">[1]</ref>: sentence splitting, tokenization, parsing using the Stanford Parser <ref type="bibr" coords="3,165.19,390.80,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="3,177.37,390.80,7.01,8.74" target="#b1">2]</ref>, morphological preprocessing, and VP chunking. In the final preprocessing step, the system extracts the pre-annotated events from the text already present in the supplied corpus for the task in order for them to be available in the final step of the pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Detection of Negation and Modality Triggers</head><p>The first component in the CLaC System identifies and annotates any negation or modality triggers present in the text. For the detection of negation triggers we used 3 different xml formatted gazetteer lists. Each list contains entries for a specific negation type: Implicit, Explicit and Affixal. The Explicit trigger list includes not, never, no, don't, can't, ... The Implicit trigger list includes deny, prevent, fail, reject, ... Affixal triggers includes disagree, unimportant, impossible, incoherence, ... Both the Affixal and Implicit gazetteer lists are seeded from the subjective word list from MPQA, complemented with words annotated in MPQA <ref type="bibr" coords="3,134.77,568.02,15.50,8.74" target="#b13">[14]</ref> and nominalization/verbal form variants. For the detection of modality triggers we used a comprehensive modality dictionary developed and compiled for <ref type="bibr" coords="3,134.77,591.93,9.96,8.74" target="#b4">[5]</ref>. From the possible modals we chose the following categories according to the task guidelines <ref type="bibr" coords="3,220.28,603.89,9.96,8.74" target="#b7">[8]</ref>: Assumptive, Conditional, Deductive, Epistemic, Hedge, Intentional, Speculative, Obligative, Modal, Potential, and Volitive.</p><p>Two additional modality trigger classes are (the trigger is underlined):</p><p>1. if the main verb is nonfinite then this verb is considered to be a modal trigger: ... that accompany Alzheimer's memory loss ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>if the main verb is in the present particle tense then this verb is considered to be a modal trigger: Finding evidence of Chlamydia...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Syntactic Scope Detection of Negation and Modality</head><p>The second component in the CLaC System identifies the syntactic scope for an annotated negation or modal trigger present in a sentence within the text.</p><p>The method for detecting the syntactic scope in both cases is inspired by heuristics defined in <ref type="bibr" coords="4,199.56,216.12,9.96,8.74" target="#b3">[4]</ref>, utilizing the parser-derived collapsed dependency graphs <ref type="bibr" coords="4,467.31,216.12,9.96,8.74" target="#b1">[2]</ref>.</p><p>The heuristics specify the dependency relations which identify either a negation or modality scope. Examples ( <ref type="formula" coords="4,271.37,240.03,4.24,8.74">4</ref>) and ( <ref type="formula" coords="4,308.50,240.03,4.24,8.74">5</ref>) from the test dataset show how the resulting scope annotations (in angle brackets) are determined.</p><p>In Example (4) the CLaC System will first detect and annotate never as an Explicit Negation Trigger. The CLaC component for identifying the syntactic scope will then trigger the heuristic for the neg dependency relation as the Explicit Negation Trigger never is a member of an instance of this relation. The resulting syntactic scope is determined to be the VP headed by the verb happened. The verb happened is consequently also marked as an event, therefore the resulting label for this event will be NEG since happened is found by the system to be within the scope of a negation.</p><p>(4) Sentence: The cut never happened.</p><p>Explicit Negation Trigger: never Dependency Relation: neg(governor: happened, dependent: never) Negation Syntactic Scope: The cut never happened . System Labeled Event: happened : LABEL =NEG</p><p>The same process occurs in Example (5): The system will first detect and annotate can as a Modality Trigger. It will then trigger the heuristic for the aux dependency relation as the Modality Trigger can is a member of an instance of this relation. The scope is the VP headed by the verb change. The verb change is also marked as an event, therefore the resulting label for this event will be MOD since changed is found by the system to be within the scope of a modal. There are two trigger classes that do not use the dependency relations to determine the syntactic scope, but rather the constituent parse tree, because it more accurately reflects the extent of the scope:</p><p>1. Modal verbal triggers not marked by a dependent relation already (the syntactic scope is the VP complement: accompany Alzheimer's memory loss 2. not only, not just, are exception cases and the scope of the explicit negation trigger is limited to: (only, just).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Determination of Events: Modalised, Negated or both</head><p>The final component implemented for the pilot task iterates through all the pre-annotated events within the text and will output the following labels:</p><p>1. NEG: if the event is determined to be negated 2. MOD: if the event is determined to be modalised 3. NEGMOD: if the event is determined to be both modalised and negated 4. NONE: if the event is neither negated nor modalised</p><p>For this task we submitted two different runs. The only difference between the two is how the final component of the system determines the label for the event.</p><p>In the 1st run known as the "Narrow" run one mainly considers the direct members of the dependency relation that triggered a relevent scope annotation.</p><p>In contrast, the 2nd run, known as the "Greedy" run, the entire scope annotation in which an event is contained within is considered.</p><formula xml:id="formula_0" coords="5,134.77,357.35,75.53,28.34">Run 1: Narrow 1.</formula><p>The event is determined to be NEG only if it is contained within a negation scope annotation, and is a direct member in the dependency relation with the negation trigger as shown in Example 6. If the event is not a direct member, but the event is contained within a negation scope annotation, and has the infinitive form to be, and is the dependent in a copula dependency relation and the governor of the copula dependency relation is a direct member in the dependency relation with the negation trigger: then this event will also be given the NEG label.</p><p>( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Global Results</head><p>Two methods are used for calculating the performance of a system based on the precision and recall measures: the Macroaverage and the Microaverage. The Microaverage F-Score will be the harmonic mean of the Microaverage precision and recall. In contrast, the Macroaverage method will calculate the Precision by simply taking the average of the Precision values calculated individually for each category. Similarily to calculate the Recall, it will take the average of the Recall values. The Macroaverage F-Score will be the harmonic mean of the Macroaverage precision and recall, shown in Table <ref type="table" coords="7,412.56,412.68,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Narrow Greedy</head><p>Macroaveraged F-measure(beta=1.0): 0.6368 0.6196 Microaveraged F-measure(beta=1.0): 0.7117 0.6750 Overall Accuracy: 0.7130 0.6688</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Averaged Scores for Narrow and Greedy Run</head><p>We observe that the Macroaveraged measure is balanced across both runs with 64% for the Narrow run and 62% for the Greedy run. The Narrow run had better overall performance. The method for allocating the labels in the Narrow run was not overly generous in the MOD/NEG/NEGMOD labeling of the events. Consequently, we observe in Table <ref type="table" coords="7,283.90,585.38,4.98,8.74" target="#tab_1">2</ref> the Narrow run performs better in detecting the NONE label correctly for an event. The detection of the NEGMOD label for an event is the worst performer for both runs. This is possibly due to the manner in which the NEGMOD label is allocated: the correct determination of an event being labeled NEGMOD is reliant on it having been previously correctly allocated the NEG label and the MOD label. Any errors that occur in the allocation of the NEG or MOD label to an event will propogate through to the NEGMOD labeling task. In both runs the F-Measures for both the NEG and MOD labels are fairly stable: 65%-66%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Error Analysis</head><p>This section reviews the results of each run from a more fine grained analysis than the previous section. Here, we investigate how each document in the provided data set performs, and identify the major sources of errors. We approach the analysis of the results at two different levels of granularity.</p><p>The averaged performance of the Narrow and Greedy run for each document in the data set is depicted in Figures <ref type="figure" coords="8,298.65,432.17,4.98,8.74" target="#fig_2">1</ref> and<ref type="figure" coords="8,326.32,432.17,3.87,8.74" target="#fig_3">2</ref>  The macroaveraged scores range between 50%-80% for the Narrow run and 50%-76% for the Greedy run. Given the very small size but very varied nature of the test corpus, it is of interest to us to analyse where a particular document falls within the given range. The worst performing document overall is the aids 2 document for both runs: 50.11% for the Narrow run and 49.24% for the Greedy run. The best performing document in the Narrow run is Music &amp; Soc 1 with   Upon inspection of these figures we see that in both runs the aids 2 does poorly in detecting the NEGMOD label. There is only one event in this document that should have the NEGMOD label allocated; and in both runs the system fails. In both runs as observed in Example 12, the event is labeled as MOD but the system does not detect a negation trigger and therefore the event is not allocated the NEG label: <ref type="bibr" coords="10,147.27,153.69,16.38,7.86" target="#b11">(12)</ref> Sentence: That is two years when a man ignorant of his infection would be less likely to take precautions to stop it spreading. ModalTrigger: take Modal Scope: That is two years when a man ignorant of his infection would be less likely to take precautions to stop it spreading . System Labeled Event: take : LABEL =MOD Gold Labeled Event: take : LABEL =NEGMOD</p><p>The aids 2 document is not the worst performer in either run for detection of the MOD label. In both runs the worst performer when detecting the MOD label is the aids 1 document. This poor performance is due in the majority of cases to a mislabeling of the MOD label: the system labels them MOD and the Gold Standard allocates the NONE label. This mislabeling is relatively frequent and we illustrate it with a few examples:</p><p>1. The CLaC system detects a modal trigger that the Gold Standard does not: <ref type="bibr" coords="10,164.21,336.39,16.38,7.86" target="#b12">(13)</ref>  The worst performer of the NEG label for both the Narrow and Greedy run is Music &amp; Soc 2. This is in part due to the small number of NEG events in comparison to the other documents. The second worst performer of the NEG label in the Narrow run is Alzheimers 1 and in the Greedy Run it is aids 1. The Alzheimers 1 was quite a good NEG Performer in the Greedy Run (2nd best). Of interest is that in the Alzheimers 1 document the Greedy run holds the advantage. As seen in Example 16, the event in question is not directly related to the negation trigger through the relevent dependency relation: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The QA4MRE Pilot Task on Negation and Modality has added crucial data to the analysis not only of the two targeted linguistic phenomena, but indeed to the study of interactions between modules in the light of increased complexity. CLaC Labs converted prototype systems to detect negation and modality that were combined for this Shared Task. We attribute our strong results to the careful linguistic analysis that went into the component systems. The Shared Task confirmed our pretheoretic assumptions that for low-level semantic features, linguistic rules will trump statistical methods for some time to come, since the amount of coherently annotated data is not available for such approaches to excel. We have also been able to show that these general (and very simple) linguistic rules perform similar in the different subgenres of the QA4MRE corpora, an encouraging result. The data set for the shared task is insufficient to make any stronger claims, but we certainly feel encouraged to extend our current approach to more interacting modules. The careful and explicit study of the interactions will, in our opinion, shed light on complexity issues in general, well beyond the task issues annotated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,151.88,517.99,304.60,7.89;4,168.64,528.95,99.09,7.89;4,168.64,539.91,261.63,7.89;4,168.64,550.87,295.01,7.89;4,172.22,561.86,74.04,7.86;4,168.64,572.79,209.98,7.89"><head>( 5 )</head><label>5</label><figDesc>Sentence: But it is hardly evidence that hip-hop can change the world. Modality Trigger: can Dependency Relation: aux(governor: change, dependent: can) Modality Syntactic Scope: But it is hardly evidence that hip-hop can change the world . System Labeled Event: change : LABEL =MOD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,330.20,432.17,3.87,8.74"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,183.87,563.46,247.62,7.89;8,137.40,463.65,340.56,85.04"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Narrow Run: Averaged Scores for each test document</figDesc><graphic coords="8,137.40,463.65,340.56,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,184.23,216.64,246.90,7.89;9,134.77,116.83,351.65,85.04"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Greedy Run: Averaged Scores for each test document</figDesc><graphic coords="9,134.77,116.83,351.65,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,140.41,429.98,334.53,7.89;9,162.28,330.16,290.79,85.04"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Narrow Run: F-Measures of NEG, MOD, NEGMOD and NONE categories</figDesc><graphic coords="9,162.28,330.16,290.79,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,140.77,584.53,333.82,7.89;9,151.59,484.72,312.18,85.04"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Greedy Run: F-Measures of NEG, MOD, NEGMOD and NONE categories</figDesc><graphic coords="9,151.59,484.72,312.18,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,138.97,473.96,341.62,191.70"><head></head><label></label><figDesc>The event is determined to be MOD only if it is contained within a modal scope annotation, and is a direct member in the dependency relation with the modal trigger. If the event is not a direct member, but the event is embedded in certain structural constructions, the event will also be given the MOD label as seen in Example 7. If none of the above is true then the event is labeled as NONE.</figDesc><table coords="5,168.82,624.89,294.84,40.77"><row><cell></cell><cell>Dependency Relation: cop (governor: telling, dependent: be) (11) Sentence: This would probably not be a person you would take very</cell></row><row><cell></cell><cell>Modal Scope: Sometimes the absence of something can be as telling seriously</cell></row><row><cell></cell><cell>as its presence . Modal Trigger: would (2nd one)</cell></row><row><cell></cell><cell>System Labeled Event: be : LABEL =MOD Dependency Relation: aux(governor: take, dependent: would)</cell></row><row><cell></cell><cell>Modal Scope: This would probably not be a person you would take</cell></row><row><cell cols="2">3. The event is determined to be NEGMOD only if it has been allocated both very seriously .</cell></row><row><cell></cell><cell>Preliminary System Labeled Event: take : LABEL =MOD the preliminary MOD and NEG labels as shown in Example 8. Negation Trigger: not (8) Sentence: So you can't simply look at temperature changes over the Dependency Relation: neg (governor: person, dependent: not) 20th century ... Negation Scope: This would probably not be a person you would Modal Trigger: can take very seriously . Dependency Relation: aux(governor: look, dependent: ca) Preliminary System Labeled Event II: take : LABEL =NEG Preliminary System Labeled Event: look : LABEL =MOD Modal Scope: So you ca n't simply look at temperature changes over Final System Labeled Event: take : LABEL =NEGMOD</cell></row><row><cell></cell><cell>the 20th century ...</cell></row><row><cell>4.</cell><cell>Negation Trigger: n't</cell></row><row><cell></cell><cell>Dependency Relation: neg (governor: look, dependent: n't)</cell></row><row><cell></cell><cell>Negation Scope: So you ca n't simply look at temperature changes</cell></row><row><cell></cell><cell>over the 20th century ...</cell></row><row><cell></cell><cell>Modal Trigger: If</cell></row><row><cell></cell><cell>Dependency Relation: mark (governor: symmetrical, dependent:</cell></row><row><cell></cell><cell>if)</cell></row><row><cell></cell><cell>Modal Scope: If matter and antimatter were truly symmetrical ...</cell></row><row><cell></cell><cell>(7) Sentence: Sometimes the absence of something can be as telling as System Labeled Event: were : LABEL =MOD</cell></row><row><cell></cell><cell>its presence .</cell></row><row><cell cols="2">Modal Trigger: can 3. The event is determined to be NEGMOD only if it has been allocated both</cell></row><row><cell></cell><cell>Dependency Relation: aux (governor: telling, dependent: can) the preliminary MOD and NEG labels as shown in Example 11.</cell></row></table><note coords="5,176.67,473.96,286.99,7.89;5,185.57,484.94,73.98,7.86;5,185.57,495.88,98.44,7.89;5,185.57,506.84,254.46,7.89;5,185.57,517.79,278.08,7.89;5,185.57,528.78,109.73,7.86;5,185.57,539.71,201.86,7.89;5,138.97,563.75,7.75,8.74;6,185.57,321.86,267.82,7.89;6,185.57,332.82,247.05,7.89;6,138.97,356.20,288.98,8.74;6,134.77,384.91,74.51,8.77;6,138.97,403.42,341.62,8.74;6,151.70,415.37,153.57,8.74;6,151.70,427.01,328.89,8.77;6,151.70,438.96,220.50,8.77;6,168.82,451.44,195.72,7.89;6,185.57,462.40,100.25,7.89;6,185.57,473.36,278.08,7.89;6,185.57,484.32,214.11,7.89;6,185.57,495.28,186.55,7.89;6,138.97,518.66,341.62,8.74;6,151.70,530.62,328.89,8.74;6,151.70,542.57,328.89,8.74;6,151.70,554.53,27.26,8.74;6,164.21,566.98,271.12,7.89"><p>) Sentence: The mutation means that Duffy receptor proteins are not made in red cells . Negation Trigger: not Dependency Relation: neg (governor:made, dependent: not) Negation Scope: The mutation means that Duffy receptor proteins are not made in red cells . System Labeled Event: made : LABEL =NEG 2. Preliminary System Labeled Event II: look : LABEL =NEG Final System Labeled Event: look : LABEL =NEGMOD 4. If none of the above is true then the event is labeled as NONE. Run 2: Greedy 1. The event is determined to be NEG if it is contained within a negation scope annotation as shown in Example 9. it wowuld be better if the same example could showcase narrow and greedy scope to highlight the difference (9) Sentence: Nor is it as widespread in Africa Negation Trigger: Nor Dependency Relation: dep (governor: widespread, dependent: Nor) Negation Scope: Nor is it as widespread in Africa System Labeled Event: is : LABEL =NEG 2. The event is determined to be MOD if it is contained within a modal scope annotation as shown in Example 10. If the scope was determined not by a dependency relation but by a structural trigger, then this event is labeled MOD. (10) Sentence: If matter and antimatter were truly symmetrical...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,156.57,118.75,299.14,149.71"><head>Table 2 .</head><label>2</label><figDesc>Global Results for Narrow and Greedy Run</figDesc><table coords="8,156.57,118.75,299.14,132.82"><row><cell></cell><cell cols="2">Narrow Run</cell></row><row><cell></cell><cell cols="2">TP FP TN FN Precision Recall F-Measure(beta =1.0)</cell></row><row><cell>MOD</cell><cell>315 158 612 159 0.6660</cell><cell>0.6646 0.6653</cell></row><row><cell>NEG</cell><cell>36 10 1170 28 0.7826</cell><cell>0.5625 0.6545</cell></row><row><cell cols="2">NEGMOD 18 19 1184 23 0.4865</cell><cell>0.4390 0.4615</cell></row><row><cell>NONE</cell><cell>518 170 409 147 0.7529</cell><cell>0.7789 0.7657</cell></row><row><cell></cell><cell cols="2">Greedy Run</cell></row><row><cell></cell><cell cols="2">TP FP TN FN Precision Recall F-Measure(beta =1.0)</cell></row><row><cell>MOD</cell><cell>357 252 518 117 0.5862</cell><cell>0.7532 0.6593</cell></row><row><cell>NEG</cell><cell>36 8 1172 28 0.8182</cell><cell>0.5625 0.6667</cell></row><row><cell cols="2">NEGMOD 28 55 1148 13 0.3373</cell><cell>0.6829 0.4516</cell></row><row><cell>NONE</cell><cell>411 97 482 254 0.8091</cell><cell>0.6180 0.7008</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,138.97,336.36,341.62,283.36"><head></head><label></label><figDesc>Sentence: The fact that some matter was left over shows they are not , in fact , symmetrical. ModalTrigger: fact Modal Scope: The fact that some matter was left over shows they are not , in fact , symmetrical. System Labeled Event: left : LABEL =MOD Gold Labeled Event: left : LABEL =NONE 2. The Gold Standard considers the event to not be affected by the modal context, but the Greedy Run does:</figDesc><table coords="10,138.97,441.22,341.62,178.50"><row><cell>(14) Sentence: A tiny genetic change may help explain why AIDS is so</cell></row><row><cell>common in Africa.</cell></row><row><cell>ModalTrigger: may</cell></row><row><cell>Modal Scope: A tiny genetic change may help explain why AIDS</cell></row><row><cell>is so common in Africa .</cell></row><row><cell>System Labeled Event: explain : LABEL =MOD</cell></row><row><cell>Gold Labeled Event: explain : LABEL =NONE</cell></row><row><cell>3. The ClaC System wrongly allocates a term to be a modal trigger -the term</cell></row><row><cell>may be a modal trigger but in a different context:</cell></row><row><cell>ModalTrigger: had</cell></row><row><cell>Modal Scope: Dr Gallo had initially suggested that AIDS was caused</cell></row><row><cell>by HTLV-I, a virus that no one disputes he discovered.</cell></row><row><cell>System Labeled Event: suggested : LABEL =MOD</cell></row><row><cell>Gold Labeled Event: suggested : LABEL =NONE</cell></row></table><note coords="10,164.21,546.08,299.44,7.89;10,185.57,557.06,212.13,7.86"><p>(15) Sentence: Dr Gallo had initially suggested that AIDS was caused by HTLV-I , a virus that no one disputes he discovered.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,134.77,187.26,330.16,339.13"><head></head><label></label><figDesc>Dr Gallo had initially suggested that AIDS was caused by HTLV-I , a virus that no one disputes he discovered. ModalTrigger: suggested Modal Scope: Dr Gallo had initially suggested that AIDS was caused by HTLV-I, a virus that no one disputes he discovered . NegTrigger: no Negation Scope: Dr Gallo had initially suggested that AIDS was caused by HTLV-I, a virus that no one disputes he discovered . System Labeled Event: disputes : LABEL =NEGMOD Gold Labeled Event: disputes : LABEL =NEG 2. The CLaC System does not recognise the Negation Scope: What the committee did not do was name a third HIV researcher, Robert Gallo, to share the glory and the SKr 10m ($1.4m). What the committee did not do was name a third HIV researcher, Robert Gallo, to share the glory and the SKr 10m ($1.4m). System Labeled Event: share : LABEL =MOD Gold Labeled Event: share : LABEL =NEG</figDesc><table coords="11,134.77,187.26,328.89,295.29"><row><cell>(16) Sentence: Nor does the apparent correlation with Alzheimer 's prove any-</cell></row><row><cell>thing.</cell></row><row><cell>NegTrigger: Nor</cell></row><row><cell>Negation Scope: Nor does the apparent correlation with Alzheimer's</cell></row><row><cell>prove anything .</cell></row><row><cell>System Labeled Event: prove : LABEL =NEG</cell></row><row><cell>Gold Labeled Event: prove : LABEL =NEG</cell></row><row><cell>Error cases illustrating NEG labeling errors from the aids 1 document:</cell></row><row><cell>1. The CLaC System erroneously allocates NEG and MOD labels:</cell></row><row><cell>NegTrigger: not</cell></row><row><cell>ModTrigger share</cell></row><row><cell>Negation Scope:</cell></row></table><note coords="11,164.21,305.48,65.15,7.89;11,164.21,430.83,65.15,7.89"><p><p>(17) Sentence:</p>(18) Sentence:</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="4,167.81,94.77,225.93,7.86"><p>Processing Modality and Negation for Machine Reading</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,256.46,337.63,7.86;12,151.52,267.42,329.07,7.86;12,151.52,278.38,329.07,7.86;12,151.52,289.33,122.31,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,314.06,278.38,162.94,7.86">Text Processing with GATE (Version 6)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Tablan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Aswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Damljanovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Petrak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,289.33,26.30,7.86">GATE</title>
		<imprint>
			<date type="published" when="2011-04-15">April 15, 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,299.99,337.64,7.86;12,151.52,310.95,141.64,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,280.02,299.99,200.58,7.86;12,151.52,310.95,62.88,7.86">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,236.47,310.95,28.03,7.86">LREC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,321.61,337.64,7.86;12,151.52,332.57,329.07,7.86;12,151.52,343.53,329.07,7.86;12,151.52,354.49,25.60,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,370.08,321.61,110.52,7.86;12,151.52,332.57,270.94,7.86">The conll-2010 shared task: Learning to detect hedges and their scope in natural language text</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Móra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Csirik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,445.37,332.57,35.22,7.86;12,151.52,343.53,324.84,7.86">Proceedings of the Fourteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,365.15,337.64,7.86;12,151.52,376.08,296.66,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,260.67,365.15,219.92,7.86;12,151.52,376.11,89.82,7.86">Effective bio-event extraction using trigger words and syntactic dependencies</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kilicoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bergler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,249.67,376.11,109.06,7.86">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="609" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,386.77,337.63,7.86;12,151.52,397.73,82.71,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,217.30,386.77,96.67,7.86">Embedding Predications</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Kilicoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Montreal, Quebec</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Concordia University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="12,142.96,408.39,337.64,7.86;12,151.52,419.34,329.07,7.86;12,151.52,430.30,84.21,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,352.06,408.39,128.53,7.86;12,151.52,419.34,74.23,7.86">Overview of genia event task in bionlp shared task</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yonezawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,268.29,419.34,212.30,7.86;12,151.52,430.30,49.11,7.86">Proceedings of BioNLP Shared Task 2011 Workshop at ACL-HLT</title>
		<meeting>BioNLP Shared Task 2011 Workshop at ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,440.96,337.64,7.86;12,151.52,451.92,315.01,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,255.89,440.96,123.20,7.86">Accurate unlexicalized parsing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,404.50,440.96,76.09,7.86;12,151.52,451.92,282.53,7.86">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,462.58,337.64,7.86;12,151.52,473.54,212.69,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,277.59,462.58,203.00,7.86;12,151.52,473.54,59.54,7.86">Processing modality and negation. a pilot task of the qa4mre lab</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,217.85,473.54,46.20,7.86">CLEF 2012</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Notebook papers</note>
</biblStruct>

<biblStruct coords="12,142.96,484.20,337.63,7.86;12,151.52,495.16,329.07,7.86;12,151.52,506.12,223.31,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,293.90,484.20,58.11,7.86">NeSp-NLP &apos;10</title>
	</analytic>
	<monogr>
		<title level="m" coord="12,359.70,484.20,120.88,7.86;12,151.52,495.16,250.97,7.86">Proceedings of the Workshop on Negation and Speculation in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Morante</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</editor>
		<meeting>the Workshop on Negation and Speculation in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,516.78,337.97,7.86;12,151.52,527.74,329.07,7.86;12,151.52,538.69,324.41,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,263.52,516.78,217.07,7.86;12,151.52,527.74,63.04,7.86">SEM 2012 Shared Task: Resolving the Scope and Focus of Negation</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,241.51,527.74,239.09,7.86;12,151.52,538.69,158.38,7.86">Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM 2012)</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics (*SEM 2012)<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06">June 2012</date>
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,549.35,337.97,7.86;12,151.52,560.31,329.07,7.86;12,151.52,571.27,167.92,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,371.39,560.31,86.58,7.86">The timebank corpus</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sundheim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,571.27,135.43,7.86">Proceedings of Corpus Linguistics</title>
		<meeting>Corpus Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,581.93,337.97,7.86;12,151.52,592.86,235.11,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,266.02,581.93,210.94,7.86">Factbank: a corpus annotated with event factuality</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,592.89,145.66,7.86">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="268" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,603.55,337.97,7.86;12,151.52,614.51,329.07,7.86;12,151.52,625.44,158.68,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,393.20,603.55,87.38,7.86;12,151.52,614.51,297.19,7.86">The bioscope corpus: annotation for negation, uncertainty and their scope in biomedical texts</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Csirik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,458.96,614.51,21.63,7.86;12,151.52,625.47,58.56,7.86">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">Suppl 11</biblScope>
			<biblScope unit="page">S9</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,636.13,337.97,7.86;12,151.52,647.06,263.14,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,286.94,636.13,193.65,7.86;12,151.52,647.09,44.43,7.86">Annotating expressions of opinions and emotions in language</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,204.25,647.09,145.66,7.86">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
