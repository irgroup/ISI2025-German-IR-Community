<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,197.62,115.96,220.11,12.62;1,174.42,133.89,266.53,12.62;1,208.38,153.73,198.60,10.52">On the Use of PU Learning for Quality Flaw Prediction in Wikipedia Notebook for PAN at CLEF 2012</title>
				<funder ref="#_bbHxqPE">
					<orgName type="full">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</orgName>
				</funder>
				<funder ref="#_ZNczqTC">
					<orgName type="full">Universidad Nacional de</orgName>
				</funder>
				<funder ref="#_tc8Qbke">
					<orgName type="full">CONACYT</orgName>
				</funder>
				<funder ref="#_6vY4xwD">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.74,189.76,72.87,8.74"><forename type="first">Edgardo</forename><surname>Ferretti</surname></persName>
							<email>ferretti@unsl.edu.ar</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<settlement>San Luis</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.16,189.76,116.63,8.74"><surname>Donato Hernández Fusilier</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">División de Ingenierías</orgName>
								<orgName type="department" key="dep2">Campus Irapuato-Salamanca</orgName>
								<orgName type="institution">Universidad de Guanajuato. Salamanca</orgName>
								<address>
									<settlement>Guanajuato</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">NLE Lab -ELiRF</orgName>
								<orgName type="institution">Universidad Politècnica de València (UPV)</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.67,189.76,105.70,8.74"><forename type="first">Rafael</forename><forename type="middle">Guzmán</forename><surname>Cabrera</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">División de Ingenierías</orgName>
								<orgName type="department" key="dep2">Campus Irapuato-Salamanca</orgName>
								<orgName type="institution">Universidad de Guanajuato. Salamanca</orgName>
								<address>
									<settlement>Guanajuato</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.87,201.71,108.88,8.74"><forename type="first">Manuel</forename><surname>Montes Y Gómez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Departamento de Ciencias Computacionales</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<address>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.30,201.71,79.10,8.74"><forename type="first">Marcelo</forename><surname>Errecalde</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidad Nacional de San Luis (UNSL)</orgName>
								<address>
									<settlement>San Luis</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,393.33,201.71,52.69,8.74"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff4">
								<orgName type="laboratory">NLE Lab -ELiRF</orgName>
								<orgName type="institution">Universidad Politècnica de València (UPV)</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,197.62,115.96,220.11,12.62;1,174.42,133.89,266.53,12.62;1,208.38,153.73,198.60,10.52">On the Use of PU Learning for Quality Flaw Prediction in Wikipedia Notebook for PAN at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C070534DD977FABDF7EC5E2F2745B13C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article we describe a new approach to assess Quality Flaw Prediction in Wikipedia. The partially supervised method studied, called PU Learning, has been successfully applied in classifications tasks with traditional corpora like Reuters-21578 or 20-Newsgroups. To the best of our knowledge, this is the first time that it is applied in this domain. Throughout this paper, we describe how the original PU Learning approach was evaluated for assessing quality flaws and the modifications introduced to get a quality flaws predictor which obtained the best F1 scores in the task "Quality Flaw Prediction in Wikipedia" of the PAN challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Given the daily increase in the amount of data on the Web, machine-based assessment of Information Quality (IQ) is becoming a topic of enormous interest. This fact is rooted, among others, in the increasing popularity of user-generated Web content and the unavoidable divergence of the delivered content's quality <ref type="bibr" coords="1,455.02,560.48,9.96,8.74" target="#b4">[5]</ref>. In this respect, Wikipedia is a paradigmatic undertaking. This free-access encyclopedia generated from among the content contributed by millions of users, has this characteristic as main strength regarding its increased popularity. Nonetheless, this feature is probably, the main challenge that Wikipedia faces on how to systematically improve the quality of its articles.</p><p>According to our literature review, there are three main research lines related to IQ in Wikipedia, namely: (a) Featured articles identification <ref type="bibr" coords="1,447.94,644.16,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="1,465.09,644.16,11.62,8.74" target="#b11">12]</ref>; (b) Development of quality measurement metrics <ref type="bibr" coords="1,352.15,656.12,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="1,369.31,656.12,11.62,8.74" target="#b15">16]</ref>; and (c) Quality flaws detection <ref type="bibr" coords="2,177.40,118.99,7.75,8.74" target="#b1">[2]</ref><ref type="bibr" coords="2,185.15,118.99,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="2,189.03,118.99,7.75,8.74" target="#b3">[4]</ref>. It is clear that all the efforts made in improving IQ in Wikipedia should be enhanced, nevertheless, as indicated by Anderka et al. in <ref type="bibr" coords="2,429.35,130.95,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,441.52,130.95,7.01,8.74" target="#b2">3]</ref>, a first step towards automatic quality assurance in Wikipedia is detecting quality flaws.</p><p>In <ref type="bibr" coords="2,163.35,154.86,9.96,8.74" target="#b0">[1]</ref>, it has been presented the first complete breakdown of Wikipedia's quality flaw structure, which reveals the quality flaws that actually exist, the distribution of flaws in Wikipedia, and the extent of flawed content. It is important to notice that the majority of quality flaws are not caused due to malicious intentions but stem from edits by inexperienced authors.</p><p>In previous editions of the PAN challenge, assessing quality issues in Wikipedia has been addressed in the form of vandalism detection. Given the context above, in PAN@CLEF 2012, <ref type="foot" coords="2,257.57,236.97,3.97,6.12" target="#foot_0">5</ref> the vandalism detection task has been generalized in focussing on the prediction of quality flaws in Wikipedia articles. In particular, the quality flaws to be predicted are the ten most frequent quality flaws of the English Wikipedia articles, namely: Advert, Empty Section (Empty), No footnotes (No-foot), Notability (Notab), Original research (OR), Orphan (Orph), Primary sources (PS), Refimprove (Ref), Unreferenced (Unref) and Wikify (Wiki). Besides, the task is formally defined as follows: "Given a set of Wikipedia articles that are tagged with a particular quality flaw, decide whether an untagged article suffers from this flaw". That is to say, that detection of text quality flaws is cast as a one-class classification, as proposed in <ref type="bibr" coords="2,344.73,346.14,9.96,8.74" target="#b1">[2]</ref>.</p><p>In our view, the most notable proposals to quality flaw predictions in Wikipedia have been made by Anderka et al. <ref type="bibr" coords="2,301.29,370.05,7.75,8.74" target="#b1">[2]</ref><ref type="bibr" coords="2,309.04,370.05,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="2,312.91,370.05,7.75,8.74" target="#b3">[4]</ref>. In <ref type="bibr" coords="2,339.65,370.05,9.96,8.74" target="#b2">[3]</ref>, it is reported on the exploratory analysis performed to target IQ flaws, and also a one-class classification technology for their identification is devised. The proposed method combines density estimation with class probability estimation. The experimental results show that certain flaws can be detected with a nearly perfect precision, while for others precision deteriorates significantly. In <ref type="bibr" coords="2,299.92,429.83,10.52,8.74" target="#b1">[2]</ref> it is performed a more in-depth experimental analysis, where two settings are considered in deriving outlier examples: an optimistic setting which uses featured articles <ref type="foot" coords="2,348.21,452.16,3.97,6.12" target="#foot_1">6</ref> as outliers, and a pessimistic setting that uses a random sample of documents not tagged as containing the flaw. Finally, in <ref type="bibr" coords="2,207.59,477.65,9.96,8.74" target="#b3">[4]</ref>, this idea is pushed further and previous work is extended with: (a) a comprehensive breakdown of prior work on quality assessment, (b) an in-depth discussion of the clean-up tag mining approach, (c) a description of the quality flaw model, and (d) a detailed analysis of the one-class problem.</p><p>As mentioned above, all the work done in literature with respect to quality flaw prediction in Wikipedia, has been carried out following supervised approaches. Despite the fact that very good results have been achieved in <ref type="bibr" coords="2,449.02,549.38,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,461.20,549.38,7.75,8.74" target="#b3">4]</ref> in the so-called optimistic setting, when using untagged articles as outliers (pessimistic setting) the effectiveness of flaws predictions notably decrease. In this way, motivated by <ref type="bibr" coords="2,219.94,585.25,14.61,8.74" target="#b12">[13]</ref>, where several partially supervised learning techniques are discussed and it is also shown their good performances in Web mining applications, we decided to assess this task by means of a semi-supervised method. After considering several alternatives we came to the decision of following the approach proposed by Liu et al. <ref type="bibr" coords="3,279.55,118.99,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="3,296.71,118.99,11.62,8.74" target="#b14">15]</ref>. This approach, called PU Learning is explained next in Sect. 2. The key feature of this method is that it uses as input a small labelled set of the positive class to be predicted and a large unlabelled set to help learning. To the best of our knowledge, this is the first time that this method is used to predict information quality flaws in Wikipedia.</p><p>In Sect. 3, it is described in detail the research questions which guided the development of our proposal to participate in PAN@CLEF 2012. Besides, in this section it is also described a more intuitive rule-based approach to assess certain quality flaws. Then, Sect. 4 reports and discusses the results obtained in the competition with our PU Learning approach and with the rule-based approach as well. Finally, in Sect. 5 some general conclusions are drawn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PU Learning</head><p>Text classification is an important problem which has numerous applications. As pointed out by Liu et al.: <ref type="foot" coords="3,241.35,298.12,3.97,6.12" target="#foot_2">7</ref> "Although this classic model is important,<ref type="foot" coords="3,428.69,298.12,3.97,6.12" target="#foot_3">8</ref> in practice one also encounters another problem. That is, one has a set of documents of a particular topic or class P (positive class), and is given a large set U of mixed (unlabelled) documents that contains documents from class P and also other types of documents (negative documents). One wants to classify the documents in U into documents from P and documents not from P. The key feature of this problem is that there is no labeled negative training data, which makes the traditional text classification techniques inapplicable. This problem is termed, partially supervised classification (PSC). We also call it PU-learning (Learning from Positive and Unlabelled examples)."</p><p>In particular, given its simplicity and robust performance we decided to implement the two-step strategy proposed in <ref type="bibr" coords="3,322.49,431.20,14.61,8.74" target="#b13">[14]</ref>, which addresses the problem of building two-class classifiers with only positive and unlabelled examples, but no negative examples. This strategy is briefly described below and for extra details, the interested reader should refer to <ref type="bibr" coords="3,294.97,467.06,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="3,312.13,467.06,11.62,8.74" target="#b14">15]</ref>.</p><p>Step 1: Identifying a set of reliable negative documents from the unlabelled set.</p><p>Step 2: Building a set of classifiers by iteratively applying a classification algorithm and then selecting a good classifier from the set.</p><p>Figure <ref type="figure" coords="3,180.51,522.57,4.98,8.74" target="#fig_0">1</ref> depicts the above-mentioned two-step strategy when classifier in the second stage is applied only once. We describe this variant since it was the one implemented, and in Sect. 3.2 it is explained why it was chosen. As it can be observed in this figure, the first stage classifier is trained with an unbalanced training set composed by positive documents (P) and untagged documents (U). Then, this classifier is tested with the untagged documents used for training. From this test, all the documents predicted as negatives compose the set of reliable negatives (RNs). In turn, the RNs set together with the positive documents are used for training the second stage classifier. Finally, the model generated by the second classifier is the one used in the classification task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setting and Preliminary Results</head><p>It is well-known in Machine Learning research community that documents' representation is a key issue. However, given that the team expertise is stronger in the research field of algorithms, we decided to use features already proposed in the literature for modelling the documents and focussing our efforts in exploiting as much as possible the characteristics of the PU learning approach described in Sect. 2. There are four research questions which guided our experiments, namely:</p><p>1. What is the best classifier in each stage? 2. How to determine the sets of untagged documents for training the first stage classifier to improve its performance in selecting RNs? 3. After determining the RNs set, what documents should be used for training the second stage classifier? 4. Which parameters setting of the second classifier improves its performance?</p><p>These four questions are discussed next in below subsections. Regarding the documents' representation, we used as a guide the work performed in <ref type="bibr" coords="4,457.90,473.08,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="4,470.07,473.08,7.01,8.74" target="#b7">8]</ref>, where they explore a significant number of quality features to assess the quality of Wikipedia articles. These features are detailed in the Sect. 3.1. Given the characteristics of some flaws like Empty, No-foot, Ref and Unref, there is no need to generate a complex document model to predict them. This is why, we also devised a simpler rule-based approach based on parsing the articles' wikitexts to find particular patterns indicating the presence of these flaws. This approach is briefly described in Sect. 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Documents Model</head><p>In <ref type="bibr" coords="4,147.40,608.30,9.96,8.74" target="#b7">[8]</ref>, several features are conceptually grouped in three classes: Text Features (those extracted from articles' textual content), Review features (those extracted from articles' review history) and Network features (those extracted from the social network inherent to the collection). Similarly, in <ref type="bibr" coords="4,386.83,644.16,9.96,8.74" target="#b3">[4]</ref>, a four dimension classification of features is devised. Our document model is composed by the In-link count, Internal link count, Inter-language link count features mentioned in Table <ref type="table" coords="5,261.54,403.35,3.87,8.74" target="#tab_0">1</ref>, which are a subset of the ones used in <ref type="bibr" coords="5,446.36,403.35,9.96,8.74" target="#b3">[4]</ref>. The results reported in <ref type="bibr" coords="5,219.45,415.30,10.52,8.74" target="#b7">[8]</ref> show that textual features perform best and this is why almost all of our features belong to this category. It is worth noticing that all the features shown in Table <ref type="table" coords="5,239.28,439.21,4.98,8.74" target="#tab_0">1</ref> have been proposed by different authors <ref type="bibr" coords="5,422.47,439.21,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="5,434.65,439.21,7.75,8.74" target="#b5">6,</ref><ref type="bibr" coords="5,444.06,439.21,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,453.47,439.21,12.73,8.74" target="#b11">12,</ref><ref type="bibr" coords="5,467.86,439.21,12.73,8.74" target="#b15">16]</ref> and for a better understanding they have been organized as suggested in <ref type="bibr" coords="5,455.29,451.17,9.96,8.74" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">What Classifier in Each Stage?</head><p>As mentioned above, in <ref type="bibr" coords="5,236.77,500.70,15.50,8.74" target="#b13">[14]</ref> a benchmark system is proposed where a comprehensive evaluation of sixteen combinations of classifiers for both steps is performed. From this study it is shown that Support Vector Machines (SVM) variants perform best as classifiers for the second step. Also it is corroborated that Naïve Bayes (NB) performs very well as first stage classifier. In this way, based on this evidence we decided to evaluate this combination first. Moreover, given the results reported in <ref type="bibr" coords="5,209.04,572.43,15.50,8.74" target="#b16">[17]</ref> where KNN is proposed as first stage classifier, we decided to study this technique as well. Consequently, several experiments were carried out using NB, SVM and KNN as first and second stage classifiers, respectively. These experiments involved different corpora created from the PAN training release. Similarly to the findings in <ref type="bibr" coords="5,285.02,620.25,14.61,8.74" target="#b13">[14]</ref>, using NB and SVM as first and second stage classifiers, respectively, achieved very good results. Besides, NB + SVM also presented a very good trade-off between running times and good results. Thus, this combination was used in the remaining experimental setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sampling Strategy of Untagged Documents</head><p>As indicated in Sect. 3.2, several corpora were built from the PAN training release. The main concern in building these corpora was studying how the sampling strategy of untagged documents (U) could influence the results obtained by our approach. Instead of using a tenfold cross-validation approach as usual, splitting the documents in U by our own gave us the possibility of having much more control of the experimental setting, mainly on the issues related with determining the proportions of positive vs. untagged documents in the training sets.</p><p>To avoid a bias in how U (⊆ U) was determined, 40 different samples were selected to cover all the 50000 untagged documents in U. Given that the number of positive sample documents for each flaw was highly unbalanced, for each flaw it was also determined the minimum amount of positive documents required to get the best results. For eight of the ten flaws, the number of positive documents in the training sets was set to 1000. Besides, several proportions for the respective test sets were analysed. From these experiments we decided to use for testing only 110 positive documents, since having more of them in average resulted in similar performance rates. Flaws Advert and OR contain 1109 and 507 documents, respectively. Hence, in order to have a unified experimental test setting, it was also set to 110 the number of positive documents to be used in the test sets of these flaws. Hence, the number of positive documents for training were 999 for Advert and 397 for OR, respectively.</p><p>In this way, for each flaw f it was fixed a positive set P f which was combined with each of the 40 different subsets of U depicted in Fig. <ref type="figure" coords="7,399.70,202.68,3.87,8.74" target="#fig_1">2</ref>, thus yielding in 40 different training sets for the first stage classifier. As explained in Sect. 2, set P f also comprise the positive sample of the training set of the second stage classifier. In the following section, the different approaches used to determine the negative training set of the second stage classifier, are explained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Strategies for Selecting Reliable Negatives</head><p>Four strategies were used for selecting the reliable negative documents (RNs) to compose the training set of the second stage classifier, namely:</p><p>1. Selecting all RNs as negative set. Strategy 1 is the original one proposed in <ref type="bibr" coords="7,335.02,405.06,15.50,8.74" target="#b13">[14]</ref> and was the first one used in our experiments. Testing our approach with positive samples only, we realised that this strategy produces in average more false negatives (f n) than strategies 2 -4. Table <ref type="table" coords="7,191.05,440.92,4.98,8.74" target="#tab_1">2</ref> reports the average, median, minimum and maximum f n values for these strategies. Since the performance of the second stage classifier can only be measured by considering its recall values, the average recall values over the ten flaws are also presented. As it can be observed, the maximum number of f n for strategy 1 is 110, the actual number of positive samples in the test set. Besides, the average number of f n for strategy 1 is close to the maximum f n predictions for strategies 2 and 4, and it is higher than the maximum f n value for strategy 3. This shows that having a highly unbalanced training set for the second stage classifier affects the performance of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Selecting</head><p>A statistical analysis (a non-parametric ANOVA) showed that the existing differences in the false negative rates of strategies 2 and 4, were significant when compared against strategies 1 and 3, respectively. For strategy 3, the differences with strategy 1 were found not significant. Similarly, taking into account the median recall values calculated on the ten flaws when trained with the 40 different training sets described in Sect. 3.3, the statistical analysis determined as significant the existing differences between strategies 2 and 4, against 1 and 3. Moreover, the mean rank differences found between strategies 2 vs. 4, and 1 vs. 3, were determined not significant, respectively. Table <ref type="table" coords="7,370.33,644.16,4.98,8.74" target="#tab_2">3</ref> presents the average recall values obtained per each flaw on the 40 training sets. As it can be observed, strategy 1 for five out of the ten flaws performs very poorly. Furthermore, when considering the running times for each strategy, strategy 1 was found at least three times slower than the other ones. Based on this evidence, we decided to continue working with strategies 2 -4. When compared against strategies 3 and 4, strategy 2 is conceptually the simplest one, since it just selects at random |P f | RNs documents to make a balanced training set for the second stage classifier. Conversely, strategy 3 selects those documents assigned the highest confidence prediction values by the first classifier, on the grounds that they are better candidates in representing the real negative documents' features. Finally, strategy 4 aims at selecting those documents that in spite of being predicted as negatives, are still quite similar to the positive ones. The underlying idea of this last strategy, is that selecting these documents could help to build a much more fine-grained borderline between both sets of documents. As shown in Table <ref type="table" coords="8,302.19,480.67,3.87,8.74" target="#tab_1">2</ref>, strategies 2 and 4 perform best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">SVM: Which Parameters?</head><p>In Sect. 3.2, it was mentioned that using a SVM variant as second stage classifier reported the best results in <ref type="bibr" coords="8,281.70,542.01,15.50,8.74" target="#b13">[14]</ref> and in our experiments as well. Following the suggestions of Chang and Lin <ref type="bibr" coords="8,313.97,553.97,9.96,8.74" target="#b6">[7]</ref>, <ref type="foot" coords="8,327.25,552.39,3.97,6.12" target="#foot_4">9</ref> the authors of the SVM implementation we used, we tried all the different combinations of the parameters γ ∈ {2 -15 , 2 -13 , 2 -11 , . . . , 2 1 , 2 3 } and C ∈ {2 -5 , 2 -3 , 2 -1 , . . . , 2 13 , 2 15 } of the RBF kernel which is used by default in this software package. We found that combinations reporting the best results were those having a high penalty value (C) for the error term and very low γ values, which allow reproducing in a highsensitive way decision boundaries. In particular, in our experiments with the training sets described in Sect. 3.3, C = 2 15 was found as the best penalty value </p><formula xml:id="formula_0" coords="9,136.16,136.68,333.86,18.85">Advert Empty No-foot Notab OR Orphan PS Ref Unref Wiki 2 -7 2 -7 2 -5 2 -11 2 -9 2 -9 2 -5 2 -9 2 -9 2 -9</formula><p>for all the flaws, while the best γ values are indicated in Table <ref type="table" coords="9,421.07,187.14,3.87,8.74" target="#tab_3">4</ref>. It is worth mentioning, that values presented in Tables <ref type="table" coords="9,324.33,199.09,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="9,350.75,199.09,4.98,8.74" target="#tab_2">3</ref> were obtained with the RBF kernel, accordingly set with the parameters values reported in Table <ref type="table" coords="9,435.63,211.05,3.87,8.74" target="#tab_3">4</ref>.</p><p>During the training stage, we studied the performance of our algorithm using the default kernel, i.e., RBF. When the PAN test set was released, the only clue we had about it, was that it was balanced. That is to say, that for all the flaws, there were the same amount of positives and untagged documents. In this way, approximately 50% of the documents was expected to be predicted as positives by our algorithm. When we ran the different variants of our algorithm, in average, for all the flaws, they predicted as positive nearly 75% of the test documents.</p><p>With the aim of improving the classifiers expected performance, the same experimental setting carried out for the training set was also run for the test set. Instead of studying the classifiers performance based on recall and f n measures, they were studied with respect to their prediction rates. For each document in the test sets, statistics were gathered considering if a particular classifier predicted it or not as positive. For the flaws Advert, Empty, No-foot, OR and Ref, most of the classifiers agree on their predictions, while for the remaining flaws the classifiers shown different predicting behaviours. As this phenomenon could be caused by an over-fitting in the models learned from the training sets, therefore, it was tried a more simple approach like a linear kernel instead of RBF. With this kernel, in average, the number of documents predicted as positive was 62.55%, a more balanced percentage than the one obtained for RBF.</p><p>Based on these studies on the PAN test set, the linear SVM was also studied as second stage classifier in our PU learning approach for the PAN training set. For this particular kernel, we used the default parameters provided by WEKA <ref type="bibr" coords="9,467.31,476.11,9.96,8.74" target="#b8">[9]</ref>. Table <ref type="table" coords="9,162.63,488.06,4.98,8.74" target="#tab_4">5</ref> reports recall and f n values for RNs selection strategies for the linear kernel. Conversely to the results presented in Table <ref type="table" coords="9,371.52,500.02,3.87,8.74" target="#tab_1">2</ref>, strategy 3 is the best performing for this kernel. We also evaluated the RBF and linear SVM classifiers with positives plus untagged samples to reproduce the experimental conditions of the PAN test set. From these experiments we noticed that strategy 3 tends to predict as positives many untagged documents, while strategies 2 and 4 tend to maintained their positive predictions rates.</p><p>In this way, based on all the experiments performed with both kernels and also considering the prediction statistics gathered for each document for the PAN test set, we decided to use strategy 2 for RNs selection in nine out of the ten flaws. Flaw Orph, was the only one where strategy 4 was used. Regarding the kernel selection for the second stage classifier, the linear kernel was used in eight out of the ten flaws. Flaws Advert and OR were the only ones where the RBF kernel was used. In the Sect. 4 the results obtained with the PAN test set are presented. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Rule-based Approach</head><p>As mentioned above, for some flaws like Empty, No-foot, Ref and Unref, generating a complex document model to predict them is not necessary. In this way, according to our experimental study, a document is predicted as having the Empty flaw when one of the following three conditions hold: the number of empty sections is greater than zero; the number of subsections without content is greater than zero or when the pattern "&lt; ---. . . ---&gt;" is present. Similarly, the No-foot flaw is predicted when at least one of the following conditions hold: there are no external links ("==External link==" = 0); there are no in-text citations ("http" = 0) or when expression "ref" is found less than 80 times. Moreover, the Ref flaw is predicted when: the number of external references is less than 22; the regular expression ("ref &gt;") is found less than 65 times or when reference section is empty. Finally, for Unref flaw three conditions are used: expression "ref" is found less than 45 times; the reference section does not exist or there are no in-text citations ("http" = 0). In <ref type="bibr" coords="10,161.97,400.29,9.96,8.74" target="#b3">[4]</ref>, a rule-based approach has also been proposed to predict flaws Empty, Orphan and Unref, in what they have called the "intensional modeling". Their results are very accurate. It is worth noticing that their rules are applied on particular features belonging to the document model also used by the supervised approach they work with. In our case, our rule-based approach works with a different document model than the one used by our PU Learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PAN Results</head><p>Throughout this paper, we have mainly described the PU Learning approach implemented to participate in the PAN challenge. Despite the fact that we competed with this approach, as indicated in Sect. 3.6, also a rule-based approach was developed to assess the prediction of some quality flaws. As it can be observed in Table <ref type="table" coords="10,202.34,560.48,3.87,8.74" target="#tab_5">6</ref>, the results obtained with our rule-based approach are not very encouraging. Nonetheless, we believe that we have failed in capturing the gist of the wikitext patterns which characterize best these flaws, and as suggested in <ref type="bibr" coords="10,467.31,584.39,9.96,8.74" target="#b3">[4]</ref>, a rule-based approach can be very useful in detecting these particular flaws. Regarding the results obtained with our PU Learning approach, they show a better performance. In fact, as shown in Table <ref type="table" coords="10,313.54,620.25,3.87,8.74" target="#tab_5">6</ref>, we got an average F1 score of 0.81. Table <ref type="table" coords="10,162.46,632.21,4.98,8.74" target="#tab_6">7</ref> shows in row np, the amount of positive documents predicted per flaw to get these performance values in the challenge. Similarly, in row tn, the total amounts of documents composing the test sets, are shown. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The use of a partially supervised method to predict quality flaws in Wikipedia has proven to be effective. In this domain, our PU Learning approach which implements several strategies for selecting RNs has outperformed the original proposal which uses all the RNs found by the first stage classifier. Strategies 2 and 4 achieved the best results. We expected that strategy 4 would perform well. This is due to the fact that its underlying idea consists of building a finegrained borderline between both classes by selecting those documents that in spite of being predicted as negatives, are still quite similar to the positive ones. Likewise, in our view, strategy 2 achieved also very good results since by choosing the RNs randomly it captures in a better way the implicit heterogeneity of the documents not containing the flaw. Also, it has been described the exhaustive experimental setting carried out to set up as best as possible all the features of this approach, in order to participate in the PAN challenge, where our proposal obtained the best F1 scores in the task "Quality Flaw Prediction in Wikipedia". As future work, we think that exploring other different semi-supervised techniques is a promising direction to improve quality flaw predictions in this free-access encyclopedia available to the entire world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,222.75,241.16,169.85,7.89;4,189.98,115.84,235.40,110.55"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Two-step strategy to PU Learning</figDesc><graphic coords="4,189.98,115.84,235.40,110.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,244.67,317.00,126.01,7.89;6,169.68,115.83,276.00,186.40"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Untagged Training Sets</figDesc><graphic coords="6,169.68,115.83,276.00,186.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,372.34,464.84,108.25,8.74;6,134.77,476.76,345.82,9.68;6,134.77,488.75,345.83,9.65;6,134.77,500.70,345.83,9.96;6,134.77,512.66,345.82,9.96;6,134.77,524.61,345.83,9.96;6,134.77,536.57,345.83,9.65;6,134.77,548.52,345.83,8.74;6,134.77,560.48,345.82,8.74;6,134.77,572.43,345.83,8.74;6,134.77,584.39,345.83,8.74;6,134.77,596.34,338.09,8.74"><head></head><label></label><figDesc>Figure2shows how these 40 different samples were obtained. Originally, U was split in 10 sub-sets U i such that |U i | = 5000, for i = 1 . . . 10. Then, subsets U i.1 , were built such that: U i.1 = U i + U (i mod 10)+1 . Hence, |U i.1 | = 10000 for all i = 1 . . . 10. Similarly, subsets U i.2 , were obtained as: U i.2 = U i.1 +U ((i+1) mod 10)+1 . Thus, |U i.2 | = 15000 for all i = 1 . . . 10. Finally, subsets U i.3 , were built as U i.3 = U i.2 + U ((i+2) mod 10)+1 . In this way, for all i = 1 . . . 10, |U i.3 | = 20000. The idea of building these untagged sets in an incremental way aims at analysing the effect of increasing the proportion of untagged documents versus positive documents in the training sets. Larger proportions up to |U | = 50000 were tried but no improvements in the results were achieved. Moreover, increasing the size of U also increases running times, so 20000 was set as the upper amount of untagged samples to be used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,193.77,339.36,181.29,9.65;7,138.97,350.98,341.61,9.65;7,151.70,362.93,150.04,8.74;7,138.97,374.55,341.62,9.65;7,151.70,386.50,150.04,8.74"><head></head><label></label><figDesc>|P f | documents by random from RNs set. 3. Selecting the |P f | best RNs (those assigned the highest confidence prediction values by the first stage classifier). 4. Selecting the |P f | worst RNs (those assigned the lowest confidence prediction values by the first stage classifier).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,136.16,115.91,342.95,258.80"><head>Table 1 .</head><label>1</label><figDesc>List of Features Composing our Document ModelText FeaturesLength: character count, information-to-noise ratio, sentence count, syllables count, one-syllable word count, word count; Structure: average sentence length, average word length, average section length, average subsection length, average subsubsection length, average sections nesting, average subsections nesting, category count, external link count, file count, heading count, image count, longest section length, longest subsection length, longest subsubsection length, mandatory sections count, section count, subsection count, subsubsection count, tables count, templates count, trivia sections count, passive sentences rate, citation count, reference sections count, shortest section length, shortest sentence length, shortest subsection length, shortest subsubsection length; Style: Complex word rate, Conjunction rate, Difficult word rate, Doubt word rate, Easy word rate, stop words rate, longest sentence length, long sentences rate, long words rate, average word syllables, one-syllable word rate, short sentences rate, Peacock words rate, prepositions rate, pronouns rate, questions rate, "To be" verb rate, Auxiliary verb rate, Weasel word rate, rate of sentences beginning with: article coordinating conjunction, interrogative pronoun, preposition, pronoun, subordinating conjunction; Readability: ARI, Bormuth, Coleman-Liau, Dale-Chall, Flesch, Gunning-Fog, Kincaid, Lix, Miyazaki, SMOG-Grading Network Features</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,141.19,115.91,329.90,83.46"><head>Table 2 .</head><label>2</label><figDesc>Recall and f n values for RNs selection strategies</figDesc><table coords="8,141.19,136.68,329.90,62.68"><row><cell>Strategy</cell><cell></cell><cell cols="2">fn prediction rates</cell><cell></cell><cell cols="2">Recall</cell></row><row><cell></cell><cell cols="6">Average Median Minimum Maximum Average Median</cell></row><row><cell>1</cell><cell>22.17</cell><cell>3</cell><cell>0</cell><cell>110</cell><cell>0.80</cell><cell>0.97</cell></row><row><cell>2</cell><cell>4.48</cell><cell>1</cell><cell>0</cell><cell>26</cell><cell>0.96</cell><cell>0.99</cell></row><row><cell>3</cell><cell>4.00</cell><cell>4</cell><cell>0</cell><cell>10</cell><cell>0.96</cell><cell>0.96</cell></row><row><cell>4</cell><cell>4.17</cell><cell>1</cell><cell>0</cell><cell>30</cell><cell>0.96</cell><cell>0.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,136.16,213.24,342.89,83.46"><head>Table 3 .</head><label>3</label><figDesc>Average recall values per flaw</figDesc><table coords="8,136.16,234.01,342.89,62.68"><row><cell>Strategy</cell><cell></cell><cell></cell><cell></cell><cell>Flaws</cell><cell></cell></row><row><cell></cell><cell cols="5">Advert Empty No-foot Notab OR Orphan PS Ref Unref Wiki</cell></row><row><cell>1</cell><cell>0.58</cell><cell>0.98</cell><cell>0.57</cell><cell>0.99 0.30 1.00 0.74 0.61 0.99</cell><cell>0.97</cell></row><row><cell>2</cell><cell>0.90</cell><cell>0.99</cell><cell>0.86</cell><cell>0.99 1.00 1.00 0.90 0.99 0.99</cell><cell>0.98</cell></row><row><cell>3</cell><cell>0.95</cell><cell>0.98</cell><cell>0.94</cell><cell>0.99 0.97 0.99 0.95 0.96 0.97</cell><cell>0.95</cell></row><row><cell>4</cell><cell>0.90</cell><cell>0.99</cell><cell>0.89</cell><cell>0.99 1.00 1.00 0.89 0.99 0.99</cell><cell>0.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,243.07,115.91,129.21,7.89"><head>Table 4 .</head><label>4</label><figDesc>Best γ values per flaw</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,141.19,115.91,329.90,72.50"><head>Table 5 .</head><label>5</label><figDesc>Recall and f n values for RNs selection strategies with linear kernel</figDesc><table coords="10,141.19,136.68,329.90,51.73"><row><cell>Strategy</cell><cell></cell><cell cols="2">fn prediction rates</cell><cell></cell><cell cols="2">Recall</cell></row><row><cell></cell><cell cols="6">Average Median Minimum Maximum Average Median</cell></row><row><cell>2</cell><cell>21</cell><cell>21.5</cell><cell>4</cell><cell>49</cell><cell>0.81</cell><cell>0.80</cell></row><row><cell>3</cell><cell>6.20</cell><cell>6</cell><cell>0</cell><cell>20</cell><cell>0.94</cell><cell>0.94</cell></row><row><cell>4</cell><cell>20</cell><cell>21</cell><cell>1</cell><cell>44</cell><cell>0.82</cell><cell>0.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,136.16,115.91,326.81,158.82"><head>Table 6 .</head><label>6</label><figDesc>Official evaluation results</figDesc><table coords="11,136.16,134.94,326.81,139.80"><row><cell></cell><cell cols="2">PU Learning approach</cell><cell cols="2">Rule-based approach</cell></row><row><cell>Flaw</cell><cell>Precision Recall</cell><cell>F1</cell><cell>Precision Recall</cell><cell>F1</cell></row><row><cell>advert</cell><cell cols="2">0.736133 0.929000 0.821397</cell><cell></cell><cell></cell></row><row><cell>empty section</cell><cell cols="4">0.741546 0.921000 0.821588 0.538670 0.996000 0.699193</cell></row><row><cell>no footnotes</cell><cell cols="4">0.720446 0.969000 0.826439 0.506842 1.000000 0.672721</cell></row><row><cell>notability</cell><cell cols="2">0.739655 0.858000 0.794444</cell><cell></cell><cell></cell></row><row><cell cols="3">original research 0.647462 0.930966 0.763754</cell><cell></cell><cell></cell></row><row><cell>orphan</cell><cell cols="2">0.830365 0.979000 0.898577</cell><cell></cell><cell></cell></row><row><cell cols="3">primary sources 0.716615 0.923000 0.806818</cell><cell></cell><cell></cell></row><row><cell>refimprove</cell><cell cols="4">0.734848 0.970000 0.836207 0.503528 0.999000 0.669571</cell></row><row><cell>unreferenced</cell><cell cols="4">0.744731 0.954000 0.836475 0.510475 0.999000 0.675685</cell></row><row><cell>wikify</cell><cell cols="2">0.742195 0.737000 0.739589</cell><cell></cell><cell></cell></row><row><cell>MEAN</cell><cell cols="4">0.735400 0.917097 0.814529 0.514879 0.998500 0.679292</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,136.16,287.95,337.09,50.58"><head>Table 7 .</head><label>7</label><figDesc>Number of documents predicted as positives per flaw</figDesc><table coords="11,136.16,308.72,337.09,29.81"><row><cell cols="6">Advert Empty No-foot Notab OR Orphan PS Ref Unref Wiki</cell></row><row><cell>np 1262</cell><cell>1242</cell><cell>1345</cell><cell>1160</cell><cell>729</cell><cell>1179 1288 1320 1281 993</cell></row><row><cell>tn 2000</cell><cell>2000</cell><cell>2000</cell><cell cols="2">2000 1014</cell><cell>2000 2000 1998 2000 1998</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="2,152.70,646.48,94.15,7.47"><p>http://pan.webis.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="2,152.70,657.44,303.83,7.47"><p>http://en.wikipedia.org/wiki/Wikipedia:Featured_article_criteria.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2" coords="3,152.70,646.48,245.78,9.21"><p>http://www.cs.uic.edu/ ~liub/NSF/PSC-IIS-0307239.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3" coords="3,152.70,656.80,187.97,7.86"><p>Here, "this" refers to the supervised approach.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_4" coords="8,152.70,657.44,263.61,9.21"><p>http://www.csie.ntu.edu.tw/ ~cjlin/papers/guide/guide.pdf</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p><rs type="person">Edgardo Ferretti</rs> and <rs type="person">Marcelo Errecalde</rs> thank <rs type="funder">Universidad Nacional de</rs> <rs type="institution">San Luis</rs> (<rs type="grantNumber">PROICO 30310</rs>). The collaboration of <rs type="institution">UNSL, INAOE</rs> and <rs type="institution">UPV</rs> has been funded by the <rs type="funder">European Commission</rs> as part of the <rs type="programName">WIQ-EI project</rs> (project no. <rs type="grantNumber">269180</rs>) within the <rs type="programName">FP7 People Programme</rs>. <rs type="person">Manuel Montes</rs> is partially supported by <rs type="funder">CONACYT</rs>, No. <rs type="grantNumber">134186</rs>. The work of <rs type="person">Paolo Rosso</rs> was carried out also in the framework of the <rs type="projectName">MICINN Text-Enterprise</rs> (<rs type="grantNumber">TIN2009-13391-C04-03</rs>) research project and the <rs type="funder">Microcluster VLC/Campus (International Campus of Excellence) on Multimodal Intelligent Systems</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZNczqTC">
					<idno type="grant-number">PROICO 30310</idno>
				</org>
				<org type="funding" xml:id="_6vY4xwD">
					<idno type="grant-number">269180</idno>
					<orgName type="program" subtype="full">WIQ-EI project</orgName>
				</org>
				<org type="funded-project" xml:id="_tc8Qbke">
					<idno type="grant-number">134186</idno>
					<orgName type="project" subtype="full">MICINN Text-Enterprise</orgName>
					<orgName type="program" subtype="full">FP7 People Programme</orgName>
				</org>
				<org type="funding" xml:id="_bbHxqPE">
					<idno type="grant-number">TIN2009-13391-C04-03</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,229.13,336.32,7.86;12,151.52,240.09,200.12,7.86;12,383.38,240.09,50.43,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,248.44,229.13,171.05,7.86">A breakdown of quality flaws in Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,441.01,229.13,38.27,7.86;12,151.52,240.09,180.53,7.86">2nd Joint WICOW/AIRWeb Workshop on Web quality</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,250.48,328.40,7.86;12,151.52,261.44,315.31,7.86;12,151.52,272.40,283.12,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,291.57,250.48,179.78,7.86;12,151.52,261.44,84.79,7.86">Detection of text quality flaws as a one-class classification problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,257.88,261.44,208.96,7.86;12,151.52,272.40,161.94,7.86">20th ACM International Conference on Information and Knowledge Management (CIKM&apos;11)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2313" to="2316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,282.79,315.96,7.86;12,151.52,293.75,323.38,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,291.57,282.79,167.35,7.86;12,151.52,293.75,39.39,7.86">Towards Automatic Quality Assurance in Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,212.45,293.75,203.84,7.86">20th International Conference on World Wide Web</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,304.14,323.88,7.86;12,151.52,315.10,309.52,7.86;12,151.52,326.06,326.16,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,291.57,304.14,175.26,7.86;12,151.52,315.10,128.79,7.86">Predicting Quality Flaws in User-generated Content: The Case of Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,301.85,315.10,159.19,7.86;12,151.52,326.06,268.78,7.86">35rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,336.45,325.01,7.86;12,151.52,347.40,292.63,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,221.20,336.45,246.76,7.86;12,151.52,347.40,143.40,7.86">User generated content: how good is it? In: 3rd Workshop on Information Credibility on the Web</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,303.20,347.40,46.92,7.86">WICOW&apos;09)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,357.80,297.47,7.86;12,151.52,368.75,288.03,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,230.80,357.80,209.62,7.86;12,151.52,368.75,39.39,7.86">Size matters: word count as a measure of quality on Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Blumenstock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,212.45,368.75,168.49,7.86">17th Int&apos;l Conference on World Wide Web</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,379.14,327.21,7.86;12,151.52,390.10,293.59,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,248.54,379.14,192.44,7.86">LIBSVM: A library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,448.41,379.14,21.75,7.86;12,151.52,390.10,209.63,7.86">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,400.49,337.64,7.86;12,151.52,411.45,323.78,7.86;12,151.52,422.41,302.69,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,350.28,400.49,130.31,7.86;12,151.52,411.45,319.41,7.86">Automatic quality assessment of content created collaboratively by Web communities: a case study of Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dalip</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cristo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Calado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.60,422.41,231.29,7.86">9th ACM/IEEE-CS Joint Conference on Digital Libraries</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,432.80,321.81,7.86;12,151.52,443.76,324.42,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,151.52,443.76,173.13,7.86">The weka data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,332.07,443.76,91.14,7.86">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,454.15,334.55,7.86;12,151.52,465.11,318.45,7.86;12,151.52,476.07,291.25,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,212.30,465.11,253.56,7.86">Measuring the quality of web content using factual information</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ferretti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cagnina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.60,476.07,219.95,7.86">2nd joint WICOW/AIRWeb Workshop on Web quality</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,486.46,314.84,7.86;12,151.52,497.42,288.75,7.86;12,151.52,508.38,209.65,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,185.70,486.46,271.76,7.86;12,151.52,497.42,199.04,7.86">Wikipedia as participatory journalism: reliable sources? Metrics for evaluating collaborative media as a news resource</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,371.65,497.42,68.63,7.86;12,151.52,508.38,134.74,7.86">5th International Symposium on Online Journalism</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="16" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,518.77,315.24,7.86;12,151.52,529.73,312.20,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,235.49,518.77,222.37,7.86;12,151.52,529.73,29.18,7.86">Identifying featured articles in Wikipedia: writing style matters</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,202.02,529.73,203.07,7.86">19th international Conference on World Wide Web</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,540.12,321.02,7.86;12,151.52,551.08,296.81,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,185.31,540.12,273.84,7.86">Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,551.08,158.01,7.86">Data-Centric Systems and Applications</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>2nd edn.</note>
</biblStruct>

<biblStruct coords="12,142.62,561.47,334.42,7.86;12,151.52,572.43,317.79,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,324.82,561.47,152.21,7.86;12,151.52,572.43,94.51,7.86">Building text classifiers using positive and unlabeled examples</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,267.55,572.43,173.09,7.86">3rd IEEE Int&apos;l Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,582.82,310.97,7.86;12,151.52,593.78,300.28,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,289.87,582.82,163.71,7.86;12,151.52,593.78,41.06,7.86">Partially supervised classification of text documents</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,214.29,593.78,208.83,7.86">19th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,604.17,336.59,7.86;12,151.52,615.13,328.56,7.86;12,151.52,626.09,179.18,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,342.29,604.17,136.92,7.86;12,151.52,615.13,123.15,7.86">Assessing information quality of a community-based encyclopedia</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stvilia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Twidale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,295.96,615.13,184.12,7.86;12,151.52,626.09,71.06,7.86">10th International Conference on Information Quality (ICIQ&apos;05)</title>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="442" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,636.48,323.76,7.86;12,151.52,647.43,329.07,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,235.61,636.48,230.77,7.86;12,151.52,647.43,153.64,7.86">Reliable Negative Extracting Based on kNN for Learning from Positive and Unlabeled Examples</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,312.56,647.43,87.47,7.86">Journal of Computers</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="101" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
