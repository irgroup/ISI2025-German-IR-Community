<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.74,115.90,285.88,12.90;1,223.43,135.75,168.50,10.75">A Set-Based Approach to Plagiarism Detection Notebook for PAN at CLEF 2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,239.11,172.15,60.60,8.64"><forename type="first">Robin</forename><surname>Küppers</surname></persName>
							<email>kueppers@cs.uni-duesseldorf.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">University of Düsseldorf</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.08,172.15,57.18,8.64"><forename type="first">Stefan</forename><surname>Conrad</surname></persName>
							<email>conrad@cs.uni-duesseldorf.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">University of Düsseldorf</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.74,115.90,285.88,12.90;1,223.43,135.75,168.50,10.75">A Set-Based Approach to Plagiarism Detection Notebook for PAN at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D928BEECB9892ECE2975C87104ED434E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our approach to the Detailed Analysis subtask of the PAN 2012 competition. Our experiments deal with monolingual plagiarism cases, only. We use a simple set-based algorithm, that employs Dice's coefficient as a similarity measure. Furthermore we employ basic strategies from Information Retrieval and Natural Language Processing for stop word removal and language detection. We achieved the 7th place with an overall PlagDet score of 0.35.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism is the misuse of another author's thoughts and ideas without giving credit to the original author. The majority of researchers worldwide deem such plagiarism as an dishonorable act of thievery, that has to be confronted. This confrontation comprises prevention as well as detection of plagiarism, but the manual plagiarism detection is time-consuming and error-prone. Naturally there is a need for automated detection methods. This paper describes our approach to the Detailed Comparison subtask, that was submitted to the PAN 2012 competition. The algorithm is inspired by a standard model of Information Retrieval: the Bag-of-words model. Therefore natural text is treated as a set of words in the course of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Detailed Comparison Task 2.1 A Set-Based Algorithm</head><p>Our detection algorithm is simple and works as follows: in a first step we use a language detection algorithm to determine the natural language the document is written in. This language detector is based on the classification algorithm from <ref type="bibr" coords="1,391.24,560.80,10.58,8.64" target="#b1">[2]</ref>. The classifier was trained to distinguish between 11 European languages -we used the Europarl Corpus <ref type="bibr" coords="1,467.12,572.75,13.47,8.64" target="#b2">[3]</ref> as our training set. The detector works well most of the time, but there is a considerable problem with documents, which contain text in more than one language. This was the case for a few documents in the PAN 2012 training corpus. The next processing step deals with the tokenization of the raw text, whereby we store the original positions of the token within the document. We perform only a simple string normalization by collapsing whitespace.</p><p>Afterwards the token sequence (for both the suspicious and the source document) has to be divided into smaller sequences. This processing step is called chunking. The selection of a suitable chunk size is crucial for the overall performance of the plagiarism detector: a small chunk size leads usually to more accurate results, but the computation effort rises. A longer chunk size tends to reduce the computation complexity, but the overall precision decreases, because longer chunks contain non-plagiarized text with a higher probability than smaller ones. We use a chunking algorithm with a semi-fixed window size of 250 characters. To prevent tokens from being split, the algorithm expands the window by 1 character at a time until a separator character (usually a single space) is hit. We experimented with another chunking algorithm, which produces chunks on a sentence level (1 natural sentence = 1 chunk), but we drop this approach due to a below average implementation of the sentence detection. So we decided to "emulate" a sentence detection algorithm by defining the rough length of a sentence with approximately 250 characters. At this point we chunked the suspicious document into n and the source document into m chunks. We conduct an exhaustive search by comparing all n suspicious chunks to the m source chunks, therefore we have to perform n × m comparisons by computing the pair-wise similarity of the chunks. Before we compute the similarity of two chunks, we use language-dependent pre-compiled stop lists to eliminate stop words (words with a high frequency are usually considered useless or even harmful for comparison tasks). By removing these words, we prevent our algorithm from detecting similarities between chunks, which are solely based on shared articles, pronouns, etc. The adjusted chunks are then treated as a simple set of words, so we can use the Dice coefficient to compute the similarity of the sets. Dice's coefficient is defined as follows:</p><formula xml:id="formula_0" coords="2,279.97,412.22,49.84,22.31">2 × |A B| |A| + |B|</formula><p>Obviously the function's range is the interval [0, 1], whereby 0 means no similarity between the sets and 1 indicates total equality. We consider a chunk (or set) as plagiarized, if the Dice similarity between the sets is higher (or equal) 0.4. The Dice similarity is relatively robust against simple obfuscation techniques like re-ordering or word substitution (to a certain degree). Due to the simple approach we are not able to detect cross-language plagiarisms adequately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Post-Processing</head><p>The described detection algorithm produces a series of detected plagiarism cases, which are analyzed further in a post-processing step. We used non-overlapping chunks (cf. section 2.1), so there is never a plagiarism case contained within another, but adjacent cases are most probable to appear. Therefore two plagiarism cases are merged, if their distance to each other is less than 500 characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Parameter Tuning</head><p>The algorithm described in section 2.1 is adjustable by two parameters: the chunk size (in characters) and the similarity threshold. We performed a series of experiments to determine the optimal parameter pair for a high PlagDet score. Due to runtime issues (which remained unsolved at this point), we were unfortunately unable to perform the experiments on the whole PAN 2012 training corpus. Therefore we generated a smaller subcorpus with roughly 10% of the size of the original corpus and performed our experiments on the smaller one. The experimental results are shown in table <ref type="table" coords="3,435.76,167.13,3.74,8.64" target="#tab_0">1</ref>. A chunk CS ST PD R P G 10000 0.2 0,12 0,29 0,10 1,09 0.4 0,28 0,25 0,45 1,00 0.6 0,22 0,20 0,33 1,00 0.8 0,17 0,17 0,17 1,00 1.0 0,17 0,17 0,17 1,00 5000 0,2 0,20 0,30 0,32 1,08 0,4 0,31 0,28 0,58 1,02 0,6 0,23 0,21 0,33 1,00 0,8 0,17 0,17 0,33 1,00 1,0 0,17 0,17 0,17 1,00 2500 0.2 0,27 0,33 0,49 1,12 0.4 0,36 0,33 0,71 1,02 0.6 0,23 0,22 0,50 1,04 0.8 0,17 0,17 0,33 1,00 1.0 0,17 0,17 0,17 1,00</p><p>CS ST PD R P G 1000 0.2 0,29 0,37 0,57 1,33 0.4 0,40 0,36 0,78 1,08 0.6 0,24 0,24 0,67 1,19 0.8 0,17 0,17 0,33 1,18 1.0 0,17 0,17 0,17 1,00 500 0.2 0,22 0,39 0,47 1,77 0.4 0,38 0,39 0,96 1,46 0.6 0,22 0,24 0,66 1,38 0.8 0,17 0,17 0,33 1,21 1.0 0,17 0,17 0,17 1,00 250 0.2 0,14 0,36 0,34 2,20 0.4 0,43 0,42 0,97 1,27 0.6 0,24 0,27 0,67 1,35 0.8 0,18 0,18 0,33 1,20 1.0 0,17 0,17 0,17 1,00</p><p>size of approximately 250 characters with a similarity threshold of 0.4 seemed to be a good choice for our algorithm. We performed no further experiments with even smaller chunk sizes. It is noticeable, that regardless of the chunk size all experiments with a similarity threshold of 0.4 achieved the highest PlagDet score within their respective series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>Despite our simple approach we achieved 7th place (as a first-time contestant) in the Detailed Comparison sub-task of the Plagiarism Detection task of the PAN 2012 workshop. Table <ref type="table" coords="3,160.16,572.75,4.98,8.64" target="#tab_1">2</ref> shows the final results for our contribution. We achieved an overall PlagDet score of 0.35, that was mainly biased by a low recall of 28%. The low recall can be explained by numerous reasons. The most obvious explanation is the simple nature of our detector, because words from the analyzed documents are not subject to further processing like stemming (e.g. <ref type="bibr" coords="3,228.19,620.57,10.45,8.64" target="#b3">[4]</ref>). Therefore even minor variations on words (e.g. inflections) are most likely to mislead our detection algorithm. Furthermore it is quite probable, that our detection algorithm fails to detect the exact boundaries of a plagiarism case, because of the used chunking algorithm (cf. section 2.1). A different chunking algorithm, that produces overlapping chunks of texts, could be a better choice. At last the PAN 2012 training corpus contained some plagiarism cases, which were shorter than our chosen chunk size (cf. section 2.3). If the PAN 2012 test corpus contained such small cases as well, then it is highly probable our detector missed them. Our algorithm required nearly 28 seconds to analyze a document pair. This runtime issues can easily be explained by a poor implementation of our algorithm. Actually the current version of our detector is much faster and requires only about 10% of the time to analyse a document pair, but naturally the memory requirements increased. We achieved a good precision (≈ 78%) and granularity score (1.27), so there is little requirement on enhancing our merging algorithm at this time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Works</head><p>The proposed algorithm is at least suitable to detect monolingual plagiarism cases with low obfuscation, but most probably fails on highly obfuscated plagiarism. Therefore our future work includes the employment of language-dependent stemming techniques (e.g. <ref type="bibr" coords="4,156.01,414.24,11.20,8.64" target="#b3">[4]</ref>) to reduce the effect of inflections. Furthermore we plan to employ another chunking algorithm, that is similar to the shingle approach from <ref type="bibr" coords="4,398.71,426.20,10.58,8.64" target="#b0">[1]</ref>. Furthermore we plan to extend our approach to deal with cross-language plagiarism cases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,198.94,345.83,19.08"><head>Table 1 .</head><label>1</label><figDesc>Detection Efficiency (showing Chunk Size, Similarity Threshold, PlagDet score, Recall, Precision and Granularity)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,201.86,258.22,209.40,38.62"><head>Table 2 .</head><label>2</label><figDesc>Final ResultsPlagDet Precision Recall Granularity Runtime 0.3499632 0.7762456 0.2820147 1.2692041 27.6457962</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.13,493.59,338.52,7.77;4,146.47,504.55,280.07,7.77;4,146.47,515.51,83.23,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,196.66,493.59,178.25,7.77">Identifying and filtering near-duplicate documents</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,393.46,493.59,83.18,7.77;4,146.47,504.55,240.13,7.77">COM &apos;00: Proceedings of the 11th Annual Symposium on Combinatorial Pattern Matching</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,526.47,313.18,7.77;4,146.47,537.43,323.71,7.77;4,146.47,548.39,57.53,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,251.62,526.47,118.46,7.77">N-gram-based text categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Cavnar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Trenkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,397.77,526.47,53.54,7.77;4,146.47,537.43,306.79,7.77">Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</title>
		<meeting>SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="161" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,559.35,332.31,7.77;4,146.47,570.31,284.10,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,185.51,559.35,225.60,7.77">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,429.11,559.35,41.33,7.77;4,146.47,570.31,184.59,7.77">Conference Proceedings: the tenth Machine Translation Summit</title>
		<imprint>
			<publisher>AAMT</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,581.26,292.21,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,193.96,581.26,116.16,7.77">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,315.78,581.26,30.88,7.77">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
