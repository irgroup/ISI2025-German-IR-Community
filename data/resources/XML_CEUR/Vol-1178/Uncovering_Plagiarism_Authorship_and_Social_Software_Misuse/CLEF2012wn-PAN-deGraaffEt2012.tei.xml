<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,185.23,115.90,244.90,12.90;1,247.83,133.83,119.69,12.90;1,224.93,153.68,165.51,10.75">Bootstrapped Authorship Attribution in Compression Space Notebook for PAN at CLEF2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,227.39,190.08,68.91,8.64"><forename type="first">Ramon</forename><surname>De Graaff</surname></persName>
							<email>ramondegraaff@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Leiden Institute of Advanced Computer Science (LIACS)</orgName>
								<orgName type="institution">Leiden University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.14,190.08,63.36,8.64"><forename type="first">Cor</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
							<email>c.veenman@nfi.minvenj.nl</email>
							<affiliation key="aff1">
								<orgName type="department">Digital Technology and Biometrics Department Netherlands Forensics Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,185.23,115.90,244.90,12.90;1,247.83,133.83,119.69,12.90;1,224.93,153.68,165.51,10.75">Bootstrapped Authorship Attribution in Compression Space Notebook for PAN at CLEF2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2B15965247498E3A61E063B3292F6162</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>From a machine learning standpoint, the PAN 2012 Lab contest had one major challenge. In all authorship attribution tasks, the number of training documents was extremely low. We extended our previous work, in which compression distances to randomly selected prototype documents from the training corpus were used as feature representation. A supervised multi-class classifier was learned in the resulting feature space using the remaining documents. Inspired by the bootstrapped resampling method, we now drew document samples from the few source documents in order to obtain sufficient prototypes and samples to learn a supervised classifier. Using internal validation, we tuned the size of the document samples, compression method, distance measure, classification method, and decision threshold (open-class tasks) for optimal F1 score. With this scheme we submitted for the closed-class and open-class author identification tasks. In the overall results for these tasks we achieved a shared fourth ranking, based on the reported average recall of the 11 teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This years PAN 2012 Lab author identification task had two sub-tasks: the traditional Authorship Attribution and Sexual Predator Identification. From the Authorship Attribution sub-task our interest goes to closed-class and open-class (traditional) authorship attribution. The second problem within this sub-task was authorship clustering or intrinsic plagiarism, which we did not consider.</p><p>The datasets provided had a very low number of candidate authors compared to the last years contest. Moreover, per author the number of sample documents was very low, i.e., only two documents per author. Third, the size of the sample documents was relatively large: order 10kB -100kB. From a machine learning standpoint, the first point makes live easier, while the second point is a major challenge. The sample documents that make up the training set for model learning, hardly enable to generalize with two samples per class. The situation is even worse, to be able to do internal validation for model selection, one document should be kept apart, so that only one document remains for training of the recognition models.</p><p>In our previous work <ref type="bibr" coords="2,242.13,119.31,11.62,8.64" target="#b8">[9]</ref> we proposed the Compression Distance to Prototypes (CDP) method. We applied this method to datasets with similar characteristics as the PAN 2011 Lab authorship attribution contest. These characteristics are a high number of authors, per author tens of sample documents and the size of the training documents was relatively small. In short, the CDP methods randomly selects per author a part of the provided document corpus as prototypes. The remaining documents are used as training set for recognition model learning. The feature representation of the training set is computed as compression distances to the prototypes. Compression distances are distance measures in the sense that similar documents have small distances and dissimilar documents have larger distances.</p><p>Without adaptation, our previous work could not be applied for the PAN 2012 Lab, since there is only one training document per author. One possible adaptation is to compute the compression distance from a test document to all training documents and attribute a test document to the author of the closest training document. This 1-nearestneighbor procedure is known to be sensitive to noise or, in other words, it easily overfits to the training corpus. Besides the 1-nearest neighbor rule, with effectively only one document for model learning there are hardly any methods that can be applied. Moreover, the same risk of overfitting would apply.</p><p>Here, we propose an adaptation of our previous work in which we regenerate a training set from the given corpus such that statistical model learning becomes feasible. In the next section, we first pose the problems derived from the PAN 2012 Lab subtask we take part in. Then, we elaborate on our method and proposed extensions. In the following section, we apply our method to the training corpus for parameter tuning using internal cross-validation. Among the model parameters are the compression method for the compression distance computation and the compression distance measure itself. Finally, we describe the results of applying the tuned models to the test corpus as submitted for the contest. We wrap up with concluding remarks about the obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem statement</head><p>The problems of the traditional authorship attribution sub-task, that we considered for the PAN 2012 Lab, are the closed-class and open-class authorship attribution problems. As statistical pattern recognition problem, closed-class authorship attribution comes down to a standard multi-class classification problem, where each class is one of the known authors. Open-class authorship attribution can be seen as a multi-class problem, where one class is added representing all unknown authors. The problem is to find proper representations and models for the closed-class and open-class authorship attribution task, where precision, recall and F 1 measure will be used as evaluation metrics. These measures are defined as:</p><p>Precision P A for author A is defined as:</p><formula xml:id="formula_0" coords="2,210.04,602.80,270.55,23.23">P A = correct(A) retrieved-documents(A) ≡ T P A T P A + F P A ,<label>(1)</label></formula><p>where T P A (True Positive) is the number of documents that are correctly attributed to author A and F P A (False Positive) is the number of documents that are incorrectly attributed to author A.</p><p>Recall R A for author A is defined as:</p><formula xml:id="formula_1" coords="3,211.17,138.49,269.42,23.23">R A = correct(A) relevant-documents(A) ≡ TP A TP A + FN A<label>(2)</label></formula><p>where F N A (False Negative) is the number of missed attributions to author A. The F 1 measure <ref type="bibr" coords="3,170.45,184.13,16.60,8.64" target="#b14">[15]</ref> is defined as the harmonic mean of recall and precision:</p><formula xml:id="formula_2" coords="3,268.13,203.97,212.46,23.23">F 1 = 2 • P A • R A P A + R A<label>(3)</label></formula><p>These measures can be aggregated by averaging, either author based or document based, leading to macro and micro averages, respectively <ref type="bibr" coords="3,365.16,249.38,15.27,8.64" target="#b18">[19]</ref>. For instance, the macro averaged recall R macro is defined as:</p><formula xml:id="formula_3" coords="3,263.96,280.48,216.63,30.32">R macro = 1 n n i=1 R Ai<label>(4)</label></formula><p>and the micro averaged recall R micro is defined as:</p><formula xml:id="formula_4" coords="3,248.26,337.25,232.34,30.32">R micro = 1 k n i=1 |D Ai | • R Ai ,<label>(5)</label></formula><p>where |D Ai | is the number of documents in the test set for author A i , and</p><formula xml:id="formula_5" coords="3,421.21,372.79,70.28,14.11">k = n i=1 |D Ai |.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>The method we propose for this task is based on the Compression Distance to Prototypes (CDP) method we reported earlier in <ref type="bibr" coords="3,312.91,445.01,10.58,8.64" target="#b8">[9]</ref>. We first summarize the CDP method and then extend it with provisions to deal with the extremely small sample size of the contest, i.e., one training sample per author.</p><p>The CDP method deserves its name from the way the training documents are represented, i.e., its feature representation. In contrast with typical representations for text documents with lexical, syntactical and structural features, we represent a document as being similar (or dissimilar) to a set of other documents. Such a dissimilarity based representation was proposed earlier in <ref type="bibr" coords="3,294.10,528.81,16.60,8.64" target="#b13">[14]</ref> and has proven to give competitive classification results. It can be favorable for obtaining lower dimensional representations, especially if suitable distance measures are available. Importantly, the distance measure to be used should discriminate the samples such that dissimilar samples have large distances and similar samples have small distances. Several compression based distances have these properties and have been applied successfully in different domains <ref type="bibr" coords="3,449.58,588.59,10.58,8.64" target="#b0">[1]</ref>, <ref type="bibr" coords="3,466.48,588.59,10.58,8.64" target="#b1">[2]</ref>, <ref type="bibr" coords="3,134.77,600.55,15.27,8.64" target="#b10">[11]</ref>, <ref type="bibr" coords="3,156.25,600.55,10.58,8.64" target="#b6">[7]</ref>, <ref type="bibr" coords="3,172.75,600.55,10.58,8.64" target="#b7">[8]</ref>, <ref type="bibr" coords="3,189.26,600.55,15.27,8.64" target="#b17">[18]</ref>. These compression-based approaches are practical implementations of the information distances expressed in the non-computable Kolmogorov complexity <ref type="bibr" coords="3,134.77,624.46,15.27,8.64" target="#b11">[12]</ref>. In <ref type="bibr" coords="3,167.13,624.46,10.58,8.64" target="#b8">[9]</ref>, we applied the Compression Dissimilarity Measure (CDM) <ref type="bibr" coords="3,422.53,624.46,10.79,8.64" target="#b6">[7]</ref>:</p><formula xml:id="formula_6" coords="3,244.33,645.03,236.26,22.31">CDM (x, y) = C(xy) C(x) + C(y) ,<label>(6)</label></formula><p>where C(x) is the size of the compressed object x and xy is the concatenation of x and y. Essential in all these measures is a compressor that finds the smallest possible encoding of, in this case, the sample documents. In <ref type="bibr" coords="4,339.89,143.22,10.58,8.64" target="#b8">[9]</ref>, we used the LZ76 compression method <ref type="bibr" coords="4,167.29,155.18,15.27,8.64" target="#b9">[10]</ref>. The contribution of that work was to use compression-based distances as feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bootstrapped document samples</head><p>After having defined the representation of the documents, we propose a way of regenerating sample documents from the single given training document per author. This is possible because, fortunately, the documents of the PAN 2012 Lab contest are relatively large. We use the same idea underlying bootstrapping, a well known resampling method for generalization error estimation <ref type="bibr" coords="4,309.48,264.52,10.58,8.64" target="#b5">[6]</ref>. The rationale behind the bootstrapped resampling method is the best representation of the data distribution is the given dataset itself. In our case, this translates to: the best representation of the writing style of an author is the one document that we have. The method works as follows. First we draw a prototype for the given author from the start of the document with a certain length. The length of the prototype is a parameter to select. Then we proceed similar to the bootstrapped resampling method with the remaining part of the document. That is, in order to get training sample documents written by the author, we draw from her 'model' with replacement, where the model is the one source document. The sampling of training samples works as follows. The starting point in the (remaining) document is chosen randomly. Then the required number of characters is read. In case the sample would read over the end of the document, it continues reading at the start of the document until the required length is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classifier learning</head><p>Closed-class recognition Finally, a classifier must be learned in the compression distance space. For this purpose any multi-class classifier can be used. For model selection and parameter tuning we use the F 1 measure, which is an aggregation of precision and recall that will be used as performance measures in the contest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open-class recognition</head><p>For the open-class tasks, we additionally had to estimate a threshold for deciding for an unknown author. That is, the classifier decides for the most probable class, unless its probability is below the given threshold. In that case, it decides none of the known classes. We estimated the threshold by trying all thresholds in the training set that resulted in the best averaged F 1 score on the test set, where one class was left out in turn and considered as none of the known classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Method parameters</head><p>Below, we list the parameters involved in the method. Some of these are selected a priori, some are estimated in case they seem to be less dependent on the dataset and others are optimized per dataset as will be described in the Section Experiments.</p><p>1. Distance measure: Besides the already mentioned CDM in this work we also consider the Normalized Compression Distance (NCD) <ref type="bibr" coords="5,360.33,131.27,11.62,8.64" target="#b1">[2]</ref> as dissimilarity measure:</p><formula xml:id="formula_7" coords="5,224.54,153.90,256.05,22.31">N CD(x, y) = C(xy) -min{C(x), C(y)} max{C(x), C(y)}<label>(7)</label></formula><p>2. Compressor: The compressor is the core ingredient of the compression-based distance measures. From theory the best compressor should be used. Therefore, in this work we additionally considered a variant of the PPM algorithm, PPMd, that is among the best for text compression <ref type="bibr" coords="5,298.76,222.40,10.58,8.64" target="#b2">[3]</ref>, <ref type="bibr" coords="5,315.36,222.40,15.27,8.64" target="#b16">[17]</ref>, <ref type="bibr" coords="5,336.94,222.40,15.27,8.64" target="#b12">[13]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Below, we first describe the different datasets in the Authorship Attribution sub-task we submitted our runs for. Then, we describe the way we handled the method parameters and we list the internal cross-validation results and submitted runs of the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>The PAN12 authorship identification sub-task had several datasets with different numbers of authors. In every dataset for each author two documents were given.</p><p>The mean document sizes and standard deviations for the datasets of PAN12 are shown in Figure <ref type="figure" coords="5,201.76,474.66,3.74,8.64" target="#fig_1">1</ref>. Details on the datasets in PAN12 can be found in Table <ref type="table" coords="5,433.86,474.66,3.74,8.64" target="#tab_0">1</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameter setting</head><p>The parameters of the method were either chosen a priori, estimated globally for all tasks, tuned per task by two-fold cross-validation for optimal averaged F 1 score, or the exploration of parameter was part of the experiments. Two-fold cross-validation was conducted by taking for each author the first document as training document for prototype sampling and bootstrapped sampling and the second for validation. The validation document was divided up in three parts, to enable better F 1 score differentiation between several parameter settings. Then the sampling and validation set was rotated by using the second document for training and the first for validation. This process was repeated 10 times and the results averaged.</p><p>1. Distance measure: Preliminary experiments on the TASK I dataset showed that the NCD and CDM distance measure performed similarly. The reported experiments were therefore conducted with the CDM measure as before, i.e., as in <ref type="bibr" coords="6,430.57,410.86,10.58,8.64" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Compressor: Preliminary experiments on the PAN 2011 Lab data and the PAN 2012</head><p>Lab TASK I showed that the PPMd compressor clearly outperformed the previously used LZ76 compressor. The reported experiments were therefore conducted with the PPMd method. 3. Bootstrapping: Because we draw the prototypes without replacement, we fixed the number of prototypes to one per author. The size of the prototypes, the number and size of training samples are tuned through two-fold cross-validation for optimal F 1 score per task. 4. Classification: The classification method is explored in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Open-class recognition:</head><p>The threshold for open-class attribution is established through two-fold cross-validation for optimal F 1 score. In the averaging of F 1 scores the unknown class is considered equally important as all known authors taken together.</p><p>We implemented the method in Matlab and used the pattern recognition toolbox PRTools <ref type="bibr" coords="6,170.74,591.07,11.62,8.64" target="#b4">[5]</ref> for the classification models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We separate the description of the experiments in the closed-class tasks and the openclass tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Closed-class</head><p>The datasets used in these tasks consist of three, eight and fourteen authors for TASK A, TASK C and TASK I, respectively. The sizes of the training documents for these tasks differ quite a lot as can be seen in Table <ref type="table" coords="7,329.50,170.92,3.74,8.64" target="#tab_0">1</ref>. In Figures <ref type="figure" coords="7,385.85,170.92,16.02,8.64" target="#fig_3">2, 3</ref> and<ref type="figure" coords="7,423.38,170.92,3.74,8.64">4</ref>, the internal cross-validation results can be seen for some optimized parameter settings as prototype size and bootstrapped training sample document size. Based on these figures we set the method parameters to be used in the runs for submission. We selected Fisher linear discriminant <ref type="bibr" coords="7,175.33,218.74,11.62,8.64" target="#b3">[4]</ref> as classifier for all tasks and the number of bootstrapped training samples to thirty. Further, we set the prototype size, the size of the bootstrapped training samples as shown with the figures for the respective tasks (Figures <ref type="figure" coords="7,367.65,242.65,14.94,8.64" target="#fig_3">2, 3</ref> and<ref type="figure" coords="7,401.96,242.65,4.15,8.64">4</ref>) and Table <ref type="table" coords="7,454.01,242.65,3.74,8.64" target="#tab_1">2</ref>.</p><p>For the submissions, we could exploit both training documents for each author, since the method parameters were tuned. For the first submission, we used two prototypes per author. That is, we took a prototype from both training documents of each author. From the remaining part of the training documents, we drew thirty samples of a size conform the tuned parameter specified in Table <ref type="table" coords="7,346.24,303.98,3.74,8.64" target="#tab_1">2</ref>. For the second submission, we used one prototype per author from the first document and sample both documents for trainings samples with the given parameters.</p><p>This resulted in models based on more training data than in the internal validation. Expectedly, this could only improve the performance. However, the performance of SUBMISSION 2 is quite worse than the performance of the internal validation and SUB-MISSION 1. SUBMISSION 1 performs pretty well. The performances of the two runs on the test documents provided by PAN12 are shown in Table <ref type="table" coords="7,370.62,389.22,3.74,8.64" target="#tab_2">3</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Open-class</head><p>The training data for the open-class tasks TASK B, TASK D and TASK J is the same as for the corresponding closed-class tasks TASK A, TASK C and TASK I.</p><p>The internal validation on the open datasets is done using a ten repeat experiment on the dataset while measuring the F 1 performance. Per repeat, every author is two times offered as the 'Unknown', each of its training documents once. We compute the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>For the PAN 2012 Traditional Authorship Attribution tasks, we modified our previous work to deal with the major challenge of the provided datasets. That is, for all tasks the number of training documents per author was only two. To be able to do model selection, one document must be kept apart, so that one document could be exploited for model learning. We proposed a method for generating additional training documents inspired by the bootstrapped resampling method for generalization error estimation. Both the internal validation results and the results of the submitted runs on the test data show, that this resulted in a promising method for closed-class and open-class authorship attribution. In the overall results, we achieved a shared fourth ranking for the authorship attribution tasks, based on the reported average recall of the 11 teams. Further, the CDM compression distance in combination with the PPMd compressor outperformed other combinations, which is in line with results reported in <ref type="bibr" coords="10,431.40,471.75,15.27,8.64" target="#b15">[16]</ref>.</p><p>The open-class experiments showed how important it is that the training data and test dataset have the same characteristics for statistical pattern recognition methods. In this case, the proportion of known and unknown authors could not be derived from the training data. We guessed the unknown authors to be as frequent as all known authors together. Clearly, this assumption has a strong impact on the results. This was shown in experiments in which we assumed that an unknown author to be as frequent as any single known author.</p><p>Finally, the improved performance of SUBMISSION 1 over SUBMISSION 2 shows that with more prototypes a better representation of the documents and a better recognition performance can be obtained. This is an aspect that should be explored further. For instance, the number of prototypes could be optimized by exploiting the document bootstrapping for prototypes too. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,139.25,234.81,343.69,8.82;5,151.70,246.94,328.89,8.64;5,151.70,258.90,175.43,8.64;5,139.25,271.30,341.35,8.82;5,151.70,283.44,69.73,8.64;5,139.25,295.84,271.25,8.82"><head>3 .</head><label>3</label><figDesc>Bootstrapping: The bootstrapping method adds four additional parameters: the number of prototypes per author, the number of drawn training samples, the size of the prototypes, and the size of training samples. 4. Classification: The classification method to be applied for closed-class and openclass recognition. 5. Open-class recognition: the threshold for open-class recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,194.03,631.49,225.05,8.12;5,134.77,507.24,345.83,109.51"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. PAN12 Distribution of training corpus of the PAN12</figDesc><graphic coords="5,134.77,507.24,345.83,109.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,134.77,311.45,345.83,8.12;8,134.77,322.76,345.82,7.77;8,134.77,333.71,217.91,7.77;8,146.87,352.67,321.61,168.21"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Task A and B: Average F1 score as a function of the number of bootstrapped training samples using CDM and PPMd. The optimized prototype size is 20% of the document and the optimized bootstrapped sample size is 70% of the document.</figDesc><graphic coords="8,146.87,352.67,321.61,168.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,134.77,535.61,345.83,8.12;8,134.77,546.92,345.82,7.77;8,134.77,557.88,217.91,7.77"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Task C and D: Average F1 score as a function of the number of bootstrapped training samples using CDM and PPMd. The optimized prototype size is 20% of the document and the optimized bootstrapped sample size is 90% of the document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="9,146.87,115.83,321.61,168.21"><head></head><label></label><figDesc></figDesc><graphic coords="9,146.87,115.83,321.61,168.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,156.69,117.27,301.99,91.76"><head>Table 1 .</head><label>1</label><figDesc>Dataset 2012  The number of authors and number of documents per dataset</figDesc><table coords="6,231.40,117.27,152.56,81.36"><row><cell>Dataset</cell><cell cols="3">No. classes No. documents Size (kB)</cell></row><row><cell cols="2">TASK A TRAIN 3</cell><cell>6</cell><cell>9-32</cell></row><row><cell cols="2">TASK A TEST 3</cell><cell>6</cell><cell>5-43</cell></row><row><cell cols="2">TASK B TEST 4</cell><cell>10</cell><cell>10-39</cell></row><row><cell cols="2">TASK C TRAIN 8</cell><cell>16</cell><cell>11-72</cell></row><row><cell cols="2">TASK C TEST 8</cell><cell>8</cell><cell>10-43</cell></row><row><cell cols="2">TASK D TEST 9</cell><cell>17</cell><cell>10-74</cell></row><row><cell cols="2">TASK I TRAIN 14</cell><cell>28</cell><cell>179-1023</cell></row><row><cell cols="2">TASK I TEST 14</cell><cell>14</cell><cell>231-1123</cell></row><row><cell cols="2">TASK J TEST 15</cell><cell>16</cell><cell>98-1271</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,389.22,345.83,220.00"><head>Table 2 .</head><label>2</label><figDesc>. Internal validation The internal validation and parameters on the closed-class datasets of PAN12, 10-repeat 2-fold cross validation</figDesc><table coords="7,181.42,424.69,252.53,184.53"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Macro</cell><cell></cell><cell>Micro</cell></row><row><cell cols="7">Dataset Prototypes Samples Precision Recall F1-measure Precision Recall F1-measure</cell></row><row><cell cols="2">TASK A 20%</cell><cell>70%</cell><cell>0.64</cell><cell cols="2">0.71 0.66</cell><cell>0.64</cell><cell>0.71 0.66</cell></row><row><cell cols="2">TASK C 20%</cell><cell>90%</cell><cell>0.77</cell><cell cols="2">0.82 0.78</cell><cell>0.77</cell><cell>0.82 0.78</cell></row><row><cell cols="2">TASK I 50%</cell><cell>70%</cell><cell>0.81</cell><cell cols="2">0.86 0.82</cell><cell>0.81</cell><cell>0.86 0.82</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Macro</cell><cell></cell><cell></cell><cell>Micro</cell></row><row><cell></cell><cell cols="6">Dataset Precision Recall F1-measure Precision Recall F1-measure</cell></row><row><cell>ONE</cell><cell cols="2">Task A 1.0 Task C 0.81 Task I 0.60</cell><cell cols="2">1.0 0.88 0.83 1.0 0.71 0.63</cell><cell>1.0 0.81 0.60</cell><cell>1.0 0.88 0.83 1.0 0.71 0.63</cell></row><row><cell>TWO</cell><cell cols="2">Task A 0.50 Task C 0.55 Task I 0.42</cell><cell cols="2">0.67 0.56 0.79 0.55 0.50 0.44</cell><cell>0.50 0.76 0.42</cell><cell>0.67 0.56 0.47 0.38 0.50 0.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,611.49,345.83,19.08"><head>Table 3 .</head><label>3</label><figDesc>PAN12 Lab (closed-class) The performances on the closed-class tasks of the PAN12 Lab for SUBMISSION 1 and SUBMISSION 2.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,134.77,152.19,345.83,107.13"><head>Table 4 .</head><label>4</label><figDesc>PAN12 (open-class) Testset Distribution of the provided test documents of the openclass tasks for PAN12 Lab, including the calculated thresholds</figDesc><table coords="10,168.07,194.24,279.21,65.09"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Macro</cell><cell></cell><cell>Micro</cell></row><row><cell>Dataset</cell><cell cols="6">Prototypes Samples Precision Recall F1-measure Precision Recall F1-measure</cell></row><row><cell cols="2">TASK B (P N T ) 20%</cell><cell>70%</cell><cell>0.47</cell><cell>0.52 0.48</cell><cell>0.47</cell><cell>0.52 0.48</cell></row><row><cell cols="2">TASK B (P 50 T ) 20%</cell><cell>70%</cell><cell>0.45</cell><cell>0.51 0.47</cell><cell>0.45</cell><cell>0.51 0.47</cell></row><row><cell cols="2">TASK D (P N T ) 20%</cell><cell>90%</cell><cell>0.64</cell><cell>0.70 0.64</cell><cell>0.64</cell><cell>0.70 0.64</cell></row><row><cell cols="2">TASK D (P 50 T ) 20%</cell><cell>90%</cell><cell>0.47</cell><cell>0.51 0.48</cell><cell>0.47</cell><cell>0.51 0.48</cell></row><row><cell cols="2">TASK J (P N T ) 50%</cell><cell>70%</cell><cell>0.75</cell><cell>0.81 0.77</cell><cell>0.75</cell><cell>0.81 0.77</cell></row><row><cell cols="2">TASK J (P 50 T ) 50%</cell><cell>70%</cell><cell>0.55</cell><cell>0.65 0.59</cell><cell>0.55</cell><cell>0.65 0.59</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,261.13,345.83,19.08"><head>Table 5 .</head><label>5</label><figDesc>Internal validation The internal validation performances on open-class datasets of PAN12, 10 repeat 2-fold cross validation</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,134.77,116.88,345.83,107.90"><head>Table 6 .</head><label>6</label><figDesc>PAN12 Lab (open class) The performances on the open class tasks of the PAN12 Lab for SUBMISSION 1 and SUBMISSION 2.</figDesc><table coords="11,196.55,116.88,222.38,86.54"><row><cell></cell><cell></cell><cell></cell><cell>Macro</cell><cell></cell><cell>Micro</cell></row><row><cell></cell><cell>Dataset</cell><cell cols="4">Precision Recall F1-measure Precision Recall F1-measure</cell></row><row><cell></cell><cell cols="2">Task B (P N T ) 0.75</cell><cell>0.63 0.63</cell><cell>0.70</cell><cell>0.60 0.60</cell></row><row><cell></cell><cell cols="2">Task B (P 50 T ) 0.48</cell><cell>0.50 0.44</cell><cell>0.46</cell><cell>0.50 0.44</cell></row><row><cell>ONE</cell><cell cols="2">Task D (P N T ) 0.55 Task D (P 50 T ) 0.71</cell><cell>0.79 0.55 0.85 0.75</cell><cell>0.76 0.78</cell><cell>0.47 0.38 0.76 0.75</cell></row><row><cell></cell><cell cols="2">Task J (P N T ) 0.72</cell><cell>0.80 0.74</cell><cell>0.68</cell><cell>0.75 0.70</cell></row><row><cell></cell><cell cols="2">Task J (P 50 T ) 0.72</cell><cell>0.80 0.74</cell><cell>0.68</cell><cell>0.75 0.70</cell></row><row><cell>TWO</cell><cell>Task B Task D Task J</cell><cell>0.16 0.18 0.62</cell><cell>0.31 0.21 0.44 0.22 0.73 0.65</cell><cell>0.18 0.10 0.58</cell><cell>0.30 0.21 0.24 0.12 0.69 0.61</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>F 1 score in two ways, that we denote as P N and P 50. With P N , we express that the unknown author is as important to recognize as any single author. With P 50, we express that the unknown author is as important as all remaining authors together. Hence, the unknown author is weighted for 50% and the other authors together as the other 50%.</p><p>In Table <ref type="table" coords="9,185.54,431.63,3.74,8.64">5</ref>, we see that P N is higher than P 50 on every dataset. This corresponds to our expectation, because here only 1  n th, with n authors, is offered as 'Unknown'. Distinguishing the 'Unknown' author is here as important as attributing the test documents to every known author. We introduced P 50 because we expect more 'Unknown' authors in the testsets provided by PAN12 than only 1  n th.</p><p>In Table <ref type="table" coords="9,184.74,501.02,3.74,8.64">4</ref>, the number of known versus unknown authors in the testset provided by PAN12 is shown, as well as the optimized thresholds. In Table <ref type="table" coords="9,388.69,512.97,4.98,8.64">6</ref> the performances are shown for the submissions on the testset provided by PAN12. After we optimized the thresholds, we take the same models for SUBMISSION 1 and SUBMISSION 2 as we did for the closed-class. That is, n prototypes for SUBMISSION 1 and 1 2 n for SUBMISSION 2 where n is the number of train documents. As we expect more or equal documents of the 'Unknown' author, we submit the models with the threshold P 50 T . In TASK B, the number of documents by 'Unkown' authors is only four, the threshold P N T would perform slightly better. Fortunately in TASK D, the number of documents by 'Unknown' authors is nine, which is about half of the dataset. The threshold P 50 T performs a lot better than threshold P N T . In TASK J, both thresholds came up with the same labeling for the test dataset. The models from SUBMISSION 2 came up with the same labels for both thresholds on all tasks. Clearly, for optimal performance the proportion of known and unknown authors should be known beforehand. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.61,283.20,332.57,7.77;11,150.95,294.16,67.24,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,291.26,283.20,97.45,7.77">Language trees and zipping</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Caglioti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Loreto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,394.59,283.20,56.69,7.77">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">48702</biblScope>
			<date type="published" when="2002-01">Jan 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,305.20,295.52,7.77;11,150.95,316.16,179.79,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,259.14,305.20,94.42,7.77">Clustering by compression</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,359.76,305.20,78.38,7.77;11,150.95,316.16,70.97,7.77">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1523" to="1545" />
			<date type="published" when="2005-04">Apr 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,327.21,330.79,7.77;11,150.95,338.17,246.23,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,227.46,327.21,241.98,7.77">Data compression using adaptive coding and partial string matching</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cleary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,150.95,338.17,141.89,7.77">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="396" to="402" />
			<date type="published" when="1984-04">Apr 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,349.21,328.77,7.77;11,150.95,360.17,23.90,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="11,256.05,349.21,75.17,7.77">Pattern Classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley and Sons, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,371.21,307.16,7.77;11,150.95,382.17,194.26,7.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="11,150.95,382.17,194.26,7.77">PR-Tools4.1, a Matlab toolbox for pattern recognition</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juszczak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paclík</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pe ¸kalska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>De Ridder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Verzakov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,393.22,337.98,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,188.43,393.22,167.99,7.77">Bootstrap methods: another look at the jacknife</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,361.93,393.22,59.84,7.77">Annals Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,404.26,314.43,7.77;11,150.95,415.22,328.35,7.77;11,150.95,426.18,136.23,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,312.60,404.26,128.30,7.77">Towards parameter-free data mining</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ratanamahatana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,415.22,328.35,7.77;11,150.95,426.18,58.91,7.77">Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,437.22,337.98,7.77;11,150.95,448.18,317.04,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,341.17,437.22,139.42,7.77;11,150.95,448.18,88.93,7.77">Using literal and grammatical statistics for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">V</forename><surname>Kukushkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Polikarpov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">V</forename><surname>Khmelev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,245.42,448.18,138.91,7.77">Problems of Information Transmission</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="184" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,459.23,333.53,7.77;11,150.95,470.19,297.14,7.77;11,150.95,481.14,326.91,7.77;11,150.95,492.10,65.82,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,252.31,459.23,223.84,7.77;11,150.95,470.19,36.45,7.77">Forensic authorship attribution using compression distances to prototypes</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lambers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,205.50,470.19,242.60,7.77;11,150.95,481.14,32.83,7.77">Proceedings of the Third International Workshop on Computational Forensics</title>
		<meeting>the Third International Workshop on Computational Forensics<address><addrLine>The Hague, The Netherlands; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">August 13-14. 2009</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,503.15,298.83,7.77;11,150.95,514.11,135.22,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,222.62,503.15,133.97,7.77">On the complexity of finite sequences</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lempel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,362.69,503.15,78.38,7.77;11,150.95,514.11,70.97,7.77">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="75" to="81" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,525.15,334.74,7.77;11,150.95,536.11,179.30,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,329.61,525.15,74.36,7.77">The similarity metric</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,409.81,525.15,67.17,7.77;11,150.95,536.11,82.18,7.77">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3250" to="3264" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,547.15,331.01,7.77;11,150.95,558.11,124.10,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,238.21,547.15,231.34,7.77">An Introduction to Kolmogorov Complexity and its Applications</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,569.16,189.48,7.77;11,150.95,580.12,154.11,7.77" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mahoney</surname></persName>
		</author>
		<ptr target="http://www.mattmahoney.net/text/text.html" />
		<title level="m" coord="11,203.53,569.16,123.98,7.77">Large text compression benchmark</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,591.16,299.12,7.77;11,150.95,602.12,301.62,7.77;11,150.95,613.08,274.35,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,292.91,591.16,148.44,7.77;11,150.95,602.12,100.07,7.77">Combining fisher linear discriminants for dissimilarity representations</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pe ¸kalska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Skurichina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,269.01,602.12,183.57,7.77;11,150.95,613.08,97.37,7.77">Proceedings of the First International Workshop on Multiple Classifier Systems</title>
		<meeting>the First International Workshop on Multiple Classifier Systems</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1857</biblScope>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,624.12,231.18,7.77" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="11,222.04,624.12,76.27,7.77">Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Butterworth</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,635.17,314.75,7.77;11,150.95,646.13,322.33,7.77;11,150.95,657.08,235.80,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,248.15,635.17,208.85,7.77;11,150.95,646.13,73.79,7.77">Compression and machine learning: A new perspective on feature space vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,242.69,646.13,177.32,7.77;11,150.95,657.08,31.32,7.77">Proceedings of the Data Compression Conference</title>
		<meeting>the Data Compression Conference<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="332" to="332" />
		</imprint>
	</monogr>
	<note>DCC &apos;06</note>
</biblStruct>

<biblStruct coords="12,142.24,119.96,310.22,7.77;12,150.95,130.92,238.89,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,196.78,119.96,102.54,7.77">PPM: one step to practicality</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Shkarin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,316.99,119.96,135.47,7.77;12,150.95,130.92,39.61,7.77">Proceedings of the Data Compression Conference</title>
		<meeting>the Data Compression Conference</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page">202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,141.88,338.35,7.77;12,150.95,152.84,267.96,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,291.69,141.88,188.90,7.77;12,150.95,152.84,84.98,7.77">Normalized compression distance for visual analysis of document collections</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Telles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Paulovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,241.60,152.84,89.15,7.77">Computers and Graphics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="337" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,163.80,300.78,7.77;12,150.95,174.76,137.27,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,186.26,163.80,214.89,7.77">An evaluation of statistical approaches to text categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,406.91,163.80,36.11,7.77;12,150.95,174.76,77.50,7.77">Journal of Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="90" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
