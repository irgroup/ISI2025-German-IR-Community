<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.70,150.38,279.38,14.25;1,137.06,167.78,321.22,14.25;1,194.45,185.18,206.39,14.25;1,211.37,204.04,172.60,12.00">Quite Simple Approaches for Authorship Attribution, Intrinsic Plagiarism Detection and Sexual Predator Identification Notebook for PAN at CLEF 2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,238.49,242.15,77.87,9.05"><forename type="first">Anna</forename><surname>Vartapetiance</surname></persName>
							<email>a.vartapetiance@surrey.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.15,242.15,45.16,9.05"><forename type="first">Lee</forename><surname>Gillam</surname></persName>
							<email>l.gillam@surrey.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Surrey</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.70,150.38,279.38,14.25;1,137.06,167.78,321.22,14.25;1,194.45,185.18,206.39,14.25;1,211.37,204.04,172.60,12.00">Quite Simple Approaches for Authorship Attribution, Intrinsic Plagiarism Detection and Sexual Predator Identification Notebook for PAN at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A695CEC92E08E02B991198D193867EE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tasks such as Authorship Attribution, Intrinsic Plagiarism detection and Sexual Predator Identification are representative of attempts to deceive. In the first two, authors try to convince others that the presented work is theirs, and in the third there is an attempt to convince readers to take actions based on false beliefs or ill-perceived risks. In this paper, we discuss our approaches to these tasks in the Author Identification track at PAN2012, which represents our first proper attempt at any of them. Our initial intention was to determine whether cues of deception, documented in the literature, might be relevant to such tasks. However, it quickly became apparent that such cues would not be readily useful, and we discuss the results achieved using some simple but relatively novel approaches: for the Traditional Authorship Attribution task, we show how a mean-variance framework using just 10 stopwords detects 42.8% and could be obtain 52.12% using fewer; for Intrinsic Plagiarism Detection, frequent words achieved 91.1% overall; and for Sexual Predator Identification, we used just a few features covering requests for personal information, with mixed results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="842.04" lry="595.32"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The PAN activity has been around since the 2007 International Workshop on Plagiarism Analysis, Authorship Identification, and Near-Duplicate Detection, and has subsequently evolved to become Uncovering Plagiarism, Authorship, and Social Software Misuse <ref type="foot" coords="1,194.69,574.34,3.00,5.45" target="#foot_0">1</ref> . The first competitive PAN activity in 2009 had two parts, an external task of checking document content against a collection, which largely remains as the Plagiarism Detection task though with differences in approach between 2009 and 2012, and an intrinsic component apparently looking at writing style changes within a document. This intrinsic component is now just one small part of the Authorship Identification track (Tasks E and F), which also includes Traditional Authorship Attribution (Task A, B, C, D, I, J) and Sexual Predator identification. Authorship Attribution requires identifying, based on a sample of given texts, a likely author -in essence, identifying the closest match to other texts, as author names need not be given. Intrinsic Plagiarism detection involves the separation of text fragments from a single document where fragments are combined from two or more authors. For Sexual Predators, the result comes from a binary classification in which the data of interest relate to those conversations where some are attempting to deceive underage children (mainly) to perform actions of an immoral and potentially illegal nature.</p><p>In this paper, we outline the approach taken at the University of Surrey to these quite varied tasks for PAN2012. In section 2, we discuss why current deception detection cues seem to be unsuited for these tasks, which leads us to develop our own approaches. Sections 3, 4 and 5 focus on each of the individual tasks and the results obtained using relatively few features in most cases. Section 6 concludes the paper with considerations for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Authorship Identification as Deception Detection?</head><p>In Vartapetiance and Gillam <ref type="bibr" coords="2,252.29,341.39,10.78,9.05" target="#b0">[1]</ref>, we discussed why current systems and approaches for deception detection might not be effective in a variety of deceptive situations, one reason being a lack of common data sets upon which to experiment. However, as far as we can tell such approaches had not been explored systematically for PAN. We can readily consider attempts at plagiarism (or copyright infringement) to be deceptive acts, and certainly Sexual Predation would appear to be an attempt to deceive. Hence, the treatment of deception would seem to be relevant to Authorship Identification and vice versa. However, most of the cues for deception (e.g. in DePaulo et al. <ref type="bibr" coords="2,439.73,421.81,11.33,9.05" target="#b1">[2]</ref>) are based on non-verbal behaviour (visual and vocal), so are immediately not fit for such purposes. There are then different sets of verbal cues defined by various research groups, though most are covered by three major categories: (1) Overall Impression (2) Quantitative cues and (3) Qualitative cues. Overall impression covers human judgement -does somebody think it is truthful? -with all its subjective responses, restricting us to Quantitative, including word counts and average words per sentence, and Qualitative, that considers features such as self-references and occurrences of negative words. But such kinds of cues appear to be used in yet other measures, for example the Quantitative elements used in readability measures and the Quantitative elements used to determine sentiment polarity. Indeed, some researchers have used readability as an indication of deception in financial reporting, but unreadable text is not necessarily an indication of deceiving so it is important to understand what is being measured and how <ref type="bibr" coords="2,226.97,571.36,10.69,9.05" target="#b2">[3]</ref>.</p><p>Consider, for example, Pennebaker's work, which has been widely used (e.g. <ref type="bibr" coords="2,459.10,582.88,7.81,9.05" target="#b3">[4]</ref><ref type="bibr" coords="2,466.91,582.88,3.91,9.05" target="#b4">[5]</ref><ref type="bibr" coords="2,124.82,594.40,7.12,9.05" target="#b5">[6]</ref>), it is suggested that deceptive text will have (1) fewer self-references (2) more negative words (3) more exclusive words and (4) fewer motion/action verbs. Pennebaker introduces the Linguistic Inquiry and Word Count (LIWC) system which it is claimed can detect deception based on the same cues <ref type="bibr" coords="2,379.00,628.84,10.80,9.05" target="#b5">[6]</ref>. But note that the requirement for detecting deception is contrastive -more or fewer of something. LIWC can offer information about how much of what kinds of words are contained, but something needs to be available against which to make such a contrast. There is also an issue with the point of reference -are such items to be measured for each document, for each paragraph, for each senteice, or for each sub-clause? How can we have a consistent contrast when we have technical documents, which we expect to have few self-references, reviews of bad products, which we expect to have negative words, and so on? Absent answers to such questions, we explored what might be possible with the online version of LIWC <ref type="foot" coords="3,290.93,195.30,3.00,5.45" target="#foot_1">2</ref>  only would we need to ascertain where more or fewer was relevant, we would also have to determine how many such distinctions to make. Such an ad hoc approach is unlikely to generalise well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Sexual Predators:</head><p>The conversational nature of the task between the predator (deceiver) and the prey (children) requires an initial separation, but in a number of the conversations there is some indication of the desires of the predator but a difference in intention. Indeed, some predators are certainly not being at all deceptive about what they would like to do, and are happy to use quite a number of self references, social words, and indicate positive emotions. Following various apparently unsuccessful attempts to make use of such cues, we considered whether such kinds of deception may not be suited to detection using these cues, and looked instead at what we might obtain first from simple features across the data. <ref type="figure" coords="3,298.93,488.33,9.68,8.89">A,</ref><ref type="figure" coords="3,311.15,488.33,9.20,8.89">B,</ref><ref type="figure" coords="3,322.89,488.33,9.68,8.89">C,</ref><ref type="figure" coords="3,335.11,488.33,9.68,8.89">D,</ref><ref type="figure" coords="3,347.33,488.33,6.33,8.89">I,</ref><ref type="figure" coords="3,356.19,488.33,4.98,8.89">J</ref> Much literature discusses the use of numerous NLP techniques that operate over bags of words, N-grams, and parts of speech (POS), with varying degrees of success. In many cases, stopwords are either an integral part of the analysis, without consideration for how much they drive the analysis, or are dropped from processing. Prior research in this task does not appear to have addressed whether authors' writing styles and preferred topics lead to distinctive positional preferences for stopwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Authorship Attribution: tasks</head><p>Church &amp; Hanks <ref type="bibr" coords="3,212.81,582.88,11.69,9.05" target="#b6">[7]</ref> describe a mean-variance framework for detecting strong associations between co-occurring words and being able to distinguish amongst patterns using this. Their examples are of fixed phrases such as "bread and butter", which demonstrate a clear preference over "butter and bread". As an indicator of style, we explored grammatical preference using a mean-variance framework with just 10 stopwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">AA, Closed dataset</head><p>The approach taken for the closed dataset was:</p><p>Step 1 Select the 10 most frequent words from the Oxford English Dictionary: the, be, to, of, and, a, in, that, have, I Step 2 Generate regular expressions for all pairs of these words, e.g. the+have, have+the, and use a specific size of window N (here, 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 3 Extract concordances containing the regular expressions for all author texts</head><p>Step 4 Calculate per-author frequency, mean and variance information for the pairs.</p><p>Step 5 Calculate the frequency, mean and variance for the test data (per document) in the same way.</p><p>Step 6 Select the author with closest match values An example of the values derived for three authors is shown below in Table <ref type="table" coords="4,462.84,287.51,3.76,9.05" target="#tab_1">1</ref>, against text 12Atest01. The selected author is, in essence, decided on by the number of votes cast by matches to frequency, mean and variance as shown in Table <ref type="table" coords="4,432.55,310.55,3.76,9.05" target="#tab_2">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AA, Open dataset</head><p>For the open dataset, to account for data not belonging to any of the authors in the training set, we used a simple confidence measure: if the count difference between the 1 st and 2 nd highest values is less than 5, it is reported that there is no author. Table <ref type="table" coords="5,465.82,195.56,4.98,9.05" target="#tab_3">3</ref> shows an example where matches have been made to different authors but with insufficient confidence (difference = 3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Results from PAN2012 show that this method achieves 41%, flagging 28 out of 71 documents correctly. In post-competition analysis, we investigated effects of changing the gaps size (5, 10 and 25), changing the confidence (2, 3, 5, 10) and looking at subsets of the 10*10 stopword combinations (four directional subsets of 5*5, denoted as pairs of S1, S2). Table <ref type="table" coords="5,286.44,398.65,4.98,9.05" target="#tab_4">4</ref> shows results those comparable to or better than our competition result. Of particular interest is that:  Judicious use of the 5*5 performs better, with the same threshold of 5 (case 3 and 4).   Depending on the approach, Intrinsic Plagiarism Detection might be categorized as Authorship Attribution -it can be related to identifying parts of a text least likely to have been produced by the current author. However, there are various differences: for Authorship Attribution, (1) texts are usually longer, (2) there are training samples (3) two long texts are usually compared (4) the boundaries for comparison are known <ref type="bibr" coords="6,458.60,223.31,11.69,9.05" target="#b4">(5)</ref> decisions are usually for an individual. But this is not necessarily true for Intrinsic Plagiarism which is often (1) in short sections (2) only internally comparable (3) with unknown boundaries (4) with unknown number of plagiarised sections (5) with many possible decisions. For these reasons, the approach outlined above would not usefully flag the plagiarized content -here, paragraphs. Instead, we looked to a new approach, starting with Task F as it was mentioned that task E might have more than 2 authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Intrinsic Plagiarism, task F</head><p>The approach taken for Task F was:</p><p>Step 1 Select the 50 most frequent words from the file, after removing stopwords.</p><p>Step 2 Determine frequency by paragraph for these 50 words</p><p>Step 3 Select (sequences of) paragraphs with fewer similarities (e.g. &lt; 10)</p><p>If there is more than one sequence: Step 3a Select the longest sequences of paragraphs which do not share the most frequent word, and have the lowest average frequency for top 5 of these 50 words Table <ref type="table" coords="6,162.26,430.33,4.98,9.05">5</ref> shows paragraphs flagged by total frequency below 10. These sequences' average frequency for the top 5 shows that the [P4, P5, P6] sequence is least relevant to the file.</p><p>For 12Ftest02, steps 1-3 identify P01, P04 and [P06, P07, P08]. Calculating with the 5 most frequent words suggested [P06, P07, P08] to be the sequence. However, all similarly shared the most frequent words suggesting that they are all related to the topic. We allocated "no author" to that file, even though it was not suggested in the competition that the dataset could have open answers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5. Example of task F detection process</head><formula xml:id="formula_0" coords="7,147.38,137.54,529.69,73.25">p ALL P01 P02 P03 P04 P05 P06 P07 … P11 P12 P13 P14 P15 P16 P17 P18 P19 P20 id 18 --- 3 2 --- --- --- 3 … --- --- 1 --- 2 1 --- 2 --- 1 time 13 --- --- --- --- 3 3 ---… 2 2 --- --- --- --- 1 --- --- 1 back 12 --- 2 --- 1 --- --- ---… --- --- --- 1 1 2 --- 2 1 1 made 11 1 --- --- 1 1 --- ---… --- --- --- 2 1 1 --- 2 --- --- bowker 11 --- --- --- --- --- --- 1 … --- 1 --- 1 2 --- --- --- --- --- … … … … … … … … … ... … … … … … … … … … …</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Intrinsic Plagiarism, task E</head><p>The approach to Task F would not distinguish as readily. We adapted this for task E as follows:</p><p>Step 1 As task F Step 2 As task F Step 3 Extract the nouns from the 50 most frequent words (excluding stopwords)</p><p>Step 4 For the highest frequency noun, create a cluster and remove from consideration all other nouns enclosed by this -i.e. occurring in the same paragraphs. Repeat this step to produce new clusters from the remaining nouns.</p><p>Where paragraphs are not allocated to a cluster:  If the number of consecutive unallocated paragraphs is greater than 5, these form a new cluster.  For others: (a) paragraphs between two in the same cluster are allocated to that cluster; (b) paragraphs between different clusters are allocated to the subsequent cluster.</p><p>A sample of the process and the results from one of the test sets in presented in Table <ref type="table" coords="8,150.14,346.43,3.77,9.05" target="#tab_6">6</ref>, with errors highlighted with gray.</p><p>To validate our reasoning behind not using the Task F approach, we used the 5 most frequent words (from task F) and used Step 4 of task E to cluster them into groups. Interestingly, for 12Etest01 this only mis-classified P19 as Author 2, but we have mis-classified 2 for our final submission. However, such a gain would have come at the cost of losses elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Competition results show these approaches gave 100% (Task F) and 82.2% (Task E) accuracy, a simple average of which would make us 2 nd in just this task (91.1% against 94.2%). We are now looking further at what might have improved methods to improved performance in Task E without introducing complexity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Sexual Predator Detection</head><p>Just like other sub-tasks in this paper, Sexual Predator actions carry a level of deception which may or may not lie in the text but with the actions followed. Since we have never attempted the analysis of such a corpus or topic previously, we have taken relatively straightforward approach, and with reference to the training corpus this appears to offer good performance (up to f1=0.66), but for which we would have concern over the rate of false negatives as we discuss later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Process of Sexual Predators Identification</head><p>As it was the first time we have attempted such a task, we randomly took 10 predators IDs from the training set to set about manually discovering patterns. We found obvious similarities, and classified these as described below (examples are shown below in Table <ref type="table" coords="9,215.93,206.96,3.72,9.05">7</ref>):</p><p>Address: asking for the address of the house or somewhere close to drive to in other to meet up. Mostly, it's the predator who asks the question about the child's address and it was rare for children to ask whether the predator would need/like their address. This alone detects 58 out of 142 in the training data, appearing more than once, and 28 times it appears twice or more with very high precision (85%).</p><p>Parents: another strong feature. Questions about parents are usually because of:  Secrecy  Making sure children are alone while chatting  Making sure the chat history will be deleted later  Saying nothing to their parents  Seclusion  To determine whether parents are around  To ascertain how long they would be gone for This feature detects 84 out of 142, when appearing once or more, and 49 when appearing twice or more. Combining "address" and "parents" would detect 105 and 74 respectively.</p><p>Age: Some predators might lie about their age but most seem quite open about their age. They would usually highlight the fact that they are older, wishing the child were older, and this is mainly to retain the secrecy.</p><p>Intention: Interestingly, not many of these chats have direct references to their sexual intentions. They usually focus on the concept of meeting up and having fun time, watching TV, listen to music and have some alcohol. In some cases there may be mentions of what they would like to do -these are mostly limited to cuddles and kisses and so sexual activities are more apparent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 7. Bases for accept and reject files Address</head><p>Accept 13 Different spelling combination of following words: "your addres", "ur addres", "the addres" Reject 78 IT and social networking related topics such as URL, Gmail Facebook, email, e-mail, IP, Browser, … Parents Accept 11 Different spelling combination of following words: "your mom", "your dad", "your Parent" Reject 26 Reference to parents' objects or characteristics such as "Ur dads car", "Your mom's face", "Your mom is nice, young, etc". IT related topics such as "Parent Class" Age Accept 11 Different spelling combination of following words: "you are young", "get in trouble", "underage", "to jail", "wish you were" Reject 33 Self-reference such as "I'm underage" Reference to the others such as sister, brother, friend Excluding, "wish you were here /with me" Intentions Accept 6</p><p>Different spelling combination of following words: "go down on you", "make you come"</p><p>We tested all of the above mentioned categories individually, varying the number of occurrences, and in various combinations, with the PAN2012 training data. Our analysis of these results is shown in Table <ref type="table" coords="10,295.47,172.52,3.72,9.05" target="#tab_8">8</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>For the competition, we used the combination of all four categories that occurred twice or more, as this offered the optimal f1 score on training data (precision=0.7, recall=0.62 and F1=0.66).</p><p>However, it can easily be argued that for real detection the false negatives would be of particular concern. Let us consider an application that might filter out possible predatory conversations. What characteristics would a parent rather have: stringent filtering of suspicious behaviour but with a high false positive rate so that some genuine conversations are dropped, or conversations with real predators that may remain and appear acceptable? The competition webpage suggests that the decision on efforts put on investigation are the dominion of the system "to optimize the time of a police agent towards the "right" suspect rather than "all" the possible suspects". This presents a disturbing view of such a system, and we would strongly contend that the system should produce results ranked according to confidence, but resourcing judgements should be left to the conscience of human beings who are fully aware of the consequences of such missed results. Recall, then, should be a higher priority -F2, not F0.5 -even if this would reduce our placing in this task.</p><p>To see if we could have improved our results, post submission but before results, we also tested the combination of best f1 scores of all categories on the training dataset. The result for "one occurrence" across all 4 classes increased from 0.42 to 0.58 because Parent was already based on two occurrences, but the two and three occurrence scores decrease respectively to 0.6 and 0.48. Currently we are looking at other ways to increase the detection rate while keeping the simplicity of the method. We have already found a few words that can improve the detection, especially in case of sexual comments related to "intentions".</p><p>Checking the ground truth of second section raised some questions for us based on the number of lines selected and the content. For example, lines such as:</p><formula xml:id="formula_1" coords="11,140.90,356.81,131.81,8.18">0fe0367fc3735101fbf7aa3df1cb9f4e</formula><p>37 what grade u in 6bf9b33a9f4ae1df54cb89831eac1be2 5 :) 94c71d9e905c390d310f3f315f9c7b19 41 i promise 94c71d9e905c390d310f3f315f9c7b19 45 age</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We attempted, for the first time, the Author Identification track at PAN2012, participating in all three tasks of Authorship Attribution, Intrinsic Plagiarism detection and Sexual Predator Identification. We attempted to use fairly simple approaches in each case to determine the extent to which these might be effective, and believe there is some degree of novelty presented in each approach. It was surprising, for example, that just 5 stopwords with a mean-variance framework might be able to produce reasonable performance in Authorship Attribution, given that it is essentially a stylometric approach.</p><p>Our initial intention was to determine how the supposed cues of deception might be useful against benchmark data collections, but we have seen little indication of relevance to these kinds of deception. What we have learnt from participating in these tasks can now be applied back to reported deception experiments elsewhere to see whether deception is indicated by features which are not usually in the set selected by the researchers -positive evidence being so much easier to discern.</p><p>Our best results appear to have been obtained against Intrinsic Plagiarism, which was very much an 11 th hour effort. However, plenty of room for improvement remains against the other tasks, and the generalisability of our approaches can now be evaluated across previous PAN datasets also.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,124.82,446.05,205.40,9.05;5,124.82,458.29,240.65,9.05;5,124.82,470.53,345.70,9.05;5,142.82,481.93,186.79,9.05"><head></head><label></label><figDesc>Patterns starting with S2 did not help detection  For open datasets, lower threshold seems to work better  Best results would have been achieved with S1*S1 for closed and S1*S2 for open data sets; improving the results by almost 10%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,435.74,580.66,3.94,8.18;5,461.74,580.66,20.32,8.18;5,93.62,591.58,330.21,8.18;5,93.62,601.90,329.89,8.18;5,93.62,612.22,274.87,8.18;5,93.62,622.54,274.87,8.18;6,124.82,150.42,6.00,10.72;6,147.50,150.42,214.96,10.72"><head></head><label></label><figDesc>using S1*S1 for closed dataset and S1*S2 with threshold of 3 or more for open dataset (2) using S1*S1 for closed dataset and S1*S2 with threshold of 5 or more for open dataset (3) using S1*S2 for all dataset with threshold of 5 or more for open dataset (4) using S1*S1 for all dataset with threshold of 5 or more for open dataset 5 Intrinsic Plagiarism Detection: task E and F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,124.82,333.41,345.92,191.92"><head>Table 1 .</head><label>1</label><figDesc>Example comparison of a document to a set of 3 authors, closest matches displayed in bold font.</figDesc><table coords="4,124.82,354.53,345.92,170.80"><row><cell></cell><cell></cell><cell>A*I</cell><cell cols="4">A*And A*Have A*In A*the …</cell><cell></cell></row><row><cell>Frequency</cell><cell>A</cell><cell>5.5</cell><cell>20</cell><cell>---</cell><cell>9.5</cell><cell>28.5</cell><cell>…</cell></row><row><cell></cell><cell>B</cell><cell>19.5</cell><cell>49</cell><cell>1.5</cell><cell>16.5</cell><cell>25.5</cell><cell>…</cell></row><row><cell></cell><cell>C</cell><cell>1.5</cell><cell>21.5</cell><cell>---</cell><cell>5</cell><cell>18.5</cell><cell>…</cell></row><row><cell></cell><cell>12Atest01</cell><cell>---</cell><cell>49</cell><cell>---</cell><cell>14</cell><cell>50</cell><cell>…</cell></row><row><cell></cell><cell>Closest match</cell><cell>---</cell><cell>B</cell><cell>---</cell><cell>B</cell><cell>A</cell><cell>…</cell></row><row><cell>Mean</cell><cell>A</cell><cell>2.75</cell><cell>3.08</cell><cell>---</cell><cell>2.71</cell><cell>3.35</cell><cell>…</cell></row><row><cell></cell><cell>B</cell><cell>2.79</cell><cell>2.88</cell><cell>3</cell><cell>3</cell><cell>3.4</cell><cell>…</cell></row><row><cell></cell><cell>C</cell><cell>3</cell><cell>2.69</cell><cell>---</cell><cell>3.33</cell><cell>3.7</cell><cell>…</cell></row><row><cell></cell><cell>12Atest01</cell><cell>---</cell><cell>3.5</cell><cell>---</cell><cell>3.5</cell><cell>3.57</cell><cell>…</cell></row><row><cell></cell><cell>Closest match</cell><cell>---</cell><cell>A</cell><cell>---</cell><cell>C</cell><cell>C</cell><cell>…</cell></row><row><cell>Variance</cell><cell>A</cell><cell>0.19</cell><cell>0.69</cell><cell>---</cell><cell>0.49</cell><cell>0.46</cell><cell>…</cell></row><row><cell></cell><cell>B</cell><cell>0.6</cell><cell>0.63</cell><cell>0</cell><cell>0.73</cell><cell>0.24</cell><cell>…</cell></row><row><cell></cell><cell>C</cell><cell>0</cell><cell>0.59</cell><cell>---</cell><cell>0.89</cell><cell>0.21</cell><cell>…</cell></row><row><cell></cell><cell>12Atest01</cell><cell>---</cell><cell>0.25</cell><cell>---</cell><cell>0.75</cell><cell>0.39</cell><cell>…</cell></row><row><cell></cell><cell>Closest match</cell><cell>---</cell><cell>C</cell><cell>---</cell><cell>B</cell><cell>A</cell><cell>…</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,124.82,539.50,292.04,72.38"><head>Table 2 .</head><label>2</label><figDesc>Example</figDesc><table coords="4,165.62,539.50,251.24,72.38"><row><cell cols="4">counts, three potential authors with author B selected on totals</cell></row><row><cell>A</cell><cell>B</cell><cell>C</cell><cell></cell></row><row><cell>Frequency</cell><cell>19</cell><cell>54</cell><cell>10</cell></row><row><cell>Mean</cell><cell>22</cell><cell>41</cell><cell>20</cell></row><row><cell>Variance</cell><cell>20</cell><cell>63</cell><cell>63</cell></row><row><cell>Sum</cell><cell>61</cell><cell>158</cell><cell>93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,124.82,241.37,345.98,62.42"><head>Table 3 .</head><label>3</label><figDesc>Example</figDesc><table coords="5,124.82,241.37,345.98,62.42"><row><cell cols="5">count, with no author (NA) selected</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>A</cell><cell>B</cell><cell>C</cell><cell>D</cell><cell>E</cell><cell>F</cell><cell>G</cell><cell>H</cell><cell></cell></row><row><cell>Average Frequency</cell><cell>5</cell><cell>7</cell><cell>15</cell><cell>17</cell><cell>20</cell><cell>13</cell><cell>5</cell><cell>6</cell></row><row><cell>Mean</cell><cell>13</cell><cell>6</cell><cell>15</cell><cell>14</cell><cell>13</cell><cell>10</cell><cell>8</cell><cell>9</cell></row><row><cell>Variance</cell><cell>20</cell><cell>8</cell><cell>10</cell><cell>13</cell><cell>8</cell><cell>13</cell><cell>6</cell><cell>10</cell></row><row><cell>Sum</cell><cell>38</cell><cell>21</cell><cell>40</cell><cell>44</cell><cell>41</cell><cell>36</cell><cell>19</cell><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,93.62,504.79,404.20,40.97"><head>Table 4 .</head><label>4</label><figDesc>Post-competition investigations into the approach/parameters.</figDesc><table coords="5,93.62,515.59,404.20,30.17"><row><cell></cell><cell>A B</cell><cell>C D I</cell><cell>J</cell><cell>A B</cell><cell>C</cell><cell>D I</cell><cell>J</cell><cell>Overall Corr. F</cell></row><row><cell>Correct</cell><cell cols="8">6 10 8 17 14 16 % % % % % % %</cell><cell>%</cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,93.62,537.73,388.44,51.12"><head>AF-3-S1*S1/S1*S2 5 6 4 10 5 4 83 60 50 59 36 25 52.15 47.89</head><label></label><figDesc></figDesc><table coords="5,93.62,548.14,388.44,40.70"><row><cell cols="2">2 AF-5-S1*S1/S1*S2 5 6</cell><cell cols="2">4 11 5</cell><cell>2</cell><cell>83 60 50 65 36 13 51.04</cell><cell>46.48</cell></row><row><cell>3 AF-5-S1*S2</cell><cell>5 3</cell><cell>4 8</cell><cell>5</cell><cell>4</cell><cell>83 30 50 47 36 25 45.18</cell><cell>40.85</cell></row><row><cell>4 AF-5-S1*S1</cell><cell>4 6</cell><cell cols="2">1 11 6</cell><cell>2</cell><cell>67 60 13 65 43 13 43.2</cell><cell>42.25</cell></row><row><cell>5 Surrey</cell><cell>4 6</cell><cell>1 3</cell><cell>7</cell><cell>8</cell><cell>67 60 13 18 50 50 42.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,138.02,213.41,566.19,235.48"><head>Table 6 .</head><label>6</label><figDesc>Example</figDesc><table coords="7,138.02,213.41,566.19,235.48"><row><cell cols="2">Total frequency</cell><cell>50</cell><cell>10</cell><cell>13</cell><cell>10</cell><cell>7</cell><cell></cell><cell>7</cell><cell>9</cell><cell>14 …</cell><cell>12</cell><cell>8</cell><cell>8</cell><cell>8</cell><cell>10</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>7</cell><cell>8</cell></row><row><cell></cell><cell cols="3">Frequency of 5</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>1</cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell>1</cell><cell>3</cell><cell></cell><cell>3</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>3</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1.67</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell>2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">of task E detection process</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="13">Fqall P01 P09 P11 P14 P16 P18 P22 P25 P26 P28 P30</cell><cell cols="9">P04 P07 P08 P12 P13 P15 P17 P21 P29</cell></row><row><cell></cell><cell></cell><cell>A1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>A2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>john</cell><cell>13</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell cols="9">NA NA NA NA NA NA NA NA NA</cell></row><row><cell>johnson</cell><cell cols="9">11 NA NA NA NA NA NA NA NA</cell><cell cols="3">1 NA NA</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>simon</cell><cell cols="12">7 NA NA NA NA NA NA NA NA NA NA NA</cell><cell cols="9">NA NA NA NA NA NA NA NA NA</cell></row><row><cell>rizzo</cell><cell cols="11">6 NA NA NA NA NA NA NA NA NA NA</cell><cell>1</cell><cell cols="9">NA NA NA NA NA NA NA NA NA</cell></row><row><cell>jan</cell><cell>6</cell><cell>1</cell><cell>1</cell><cell cols="7">2 NA NA NA NA NA NA</cell><cell cols="2">2 NA</cell><cell cols="9">NA NA NA NA NA NA NA NA NA</cell></row><row><cell cols="2">correct</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A1</cell><cell>A2</cell><cell>A1</cell><cell>A3</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell><cell>A2</cell></row><row><cell cols="9">Fqall P03 P05 P06 P19 P23 P24 P27</cell><cell></cell><cell cols="3">P02 P10 P20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>A3</cell><cell></cell><cell></cell><cell cols="2">Unknown</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>john</cell><cell cols="8">13 NA NA NA NA NA NA NA</cell><cell></cell><cell cols="3">NA NA NA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>johnson</cell><cell cols="8">11 NA NA NA NA NA NA NA</cell><cell></cell><cell cols="3">NA NA NA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>simon</cell><cell>7</cell><cell>1</cell><cell>2</cell><cell cols="3">2 NA NA</cell><cell cols="2">2 NA</cell><cell></cell><cell cols="3">NA NA NA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>rizzo</cell><cell cols="3">6 NA NA</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell></cell><cell cols="3">NA NA NA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>jan</cell><cell cols="8">6 NA NA NA NA NA NA NA</cell><cell></cell><cell cols="3">NA NA NA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">correct</cell><cell>A3</cell><cell>A3</cell><cell>A3</cell><cell>A3</cell><cell>A3</cell><cell>A3</cell><cell>A3</cell><cell></cell><cell>A2</cell><cell>A3</cell><cell>A2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,124.82,518.83,345.92,51.53"><head>Table 6 .</head><label>6</label><figDesc>Result for PAN2012 for Intrinsic Plagiarism detection only</figDesc><table coords="8,124.82,530.05,345.92,40.32"><row><cell>TEAM</cell><cell>E %</cell><cell>F %</cell><cell>Overall</cell><cell>Docs corr.</cell></row><row><cell>EVL Lab</cell><cell>92.22222</cell><cell>96.25</cell><cell>94.23611</cell><cell>94.11765</cell></row><row><cell>Surrey</cell><cell>82.22222</cell><cell>100</cell><cell>91.11111</cell><cell>90.58824</cell></row><row><cell>CLLE-ERSS 1</cell><cell>73.33333</cell><cell>93.75</cell><cell>83.54167</cell><cell>82.94118</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,124.82,195.38,345.84,246.91"><head>Table 8 .</head><label>8</label><figDesc>Comparing the results from combining different elements for detection.</figDesc><table coords="10,124.82,206.18,345.84,236.11"><row><cell># of Occurrence</cell><cell cols="4">Flagged Unique Correct FP</cell><cell>FN</cell><cell cols="3">Precision Recall F1</cell></row><row><cell></cell><cell></cell><cell cols="3">Address Cues Category</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>159</cell><cell>117</cell><cell>58</cell><cell>59</cell><cell>84</cell><cell>0.5</cell><cell>0.41</cell><cell>0.45</cell></row><row><cell>Twice or more</cell><cell>74</cell><cell>33</cell><cell>28</cell><cell>5</cell><cell cols="2">114 0.85</cell><cell>0.20</cell><cell>0.32</cell></row><row><cell cols="2">Three times or more 18</cell><cell>9</cell><cell>8</cell><cell>1</cell><cell cols="2">134 0.89</cell><cell>0.06</cell><cell>0.11</cell></row><row><cell></cell><cell></cell><cell cols="3">Parents Cues Category</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>440</cell><cell>255</cell><cell>84</cell><cell cols="2">172 58</cell><cell>0.33</cell><cell>0.59</cell><cell>0.42</cell></row><row><cell>Twice or more</cell><cell>257</cell><cell>72</cell><cell>49</cell><cell>24</cell><cell>93</cell><cell>0.68</cell><cell>0.35</cell><cell>0.46</cell></row><row><cell cols="2">Three times or more 151</cell><cell>38</cell><cell>32</cell><cell>6</cell><cell cols="2">110 0.84</cell><cell>0.23</cell><cell>0.36</cell></row><row><cell></cell><cell></cell><cell cols="3">Age Cues Category</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>124</cell><cell>88</cell><cell>33</cell><cell>55</cell><cell cols="2">109 0.38</cell><cell>0.23</cell><cell>0.29</cell></row><row><cell>Twice or more</cell><cell>62</cell><cell>25</cell><cell>17</cell><cell>8</cell><cell cols="2">125 0.68</cell><cell>0.12</cell><cell>0.20</cell></row><row><cell cols="2">Three times or more 21</cell><cell>10</cell><cell>9</cell><cell>1</cell><cell cols="2">133 0.90</cell><cell>0.06</cell><cell>0.12</cell></row><row><cell></cell><cell></cell><cell cols="3">Intentions Cues Category</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>39</cell><cell>35</cell><cell>14</cell><cell>21</cell><cell cols="2">128 0.40</cell><cell>0.10</cell><cell>0.16</cell></row><row><cell>Twice or more</cell><cell>8</cell><cell>5</cell><cell>4</cell><cell>1</cell><cell cols="2">138 0.80</cell><cell>0.03</cell><cell>0.05</cell></row><row><cell cols="2">Three times or more 0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell cols="6">Combining two Cue Categories of Address and Parents</cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>598</cell><cell>333</cell><cell>105</cell><cell cols="2">228 37</cell><cell>0.32</cell><cell>0.74</cell><cell>0.44</cell></row><row><cell>Twice or more</cell><cell>366</cell><cell>101</cell><cell>74</cell><cell>27</cell><cell>68</cell><cell>0.73</cell><cell>0.52</cell><cell>0.61</cell></row><row><cell cols="2">Three times or more 217</cell><cell>53</cell><cell>46</cell><cell>7</cell><cell>96</cell><cell>0.87</cell><cell>0.32</cell><cell>0.47</cell></row><row><cell cols="2">Combining</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="10,124.82,434.26,345.84,105.39"><head>three Cue Categories of Address, Parents and Age</head><label></label><figDesc></figDesc><table coords="10,124.82,444.79,345.84,94.85"><row><cell>Once or more</cell><cell>722</cell><cell>388</cell><cell>112</cell><cell cols="2">276 37</cell><cell>0.29</cell><cell>0.79</cell><cell>0.42</cell></row><row><cell>Twice or more</cell><cell>458</cell><cell>124</cell><cell>85</cell><cell>39</cell><cell>57</cell><cell>0.69</cell><cell>0.60</cell><cell>0.64</cell></row><row><cell cols="2">Three times or more 280</cell><cell>69</cell><cell>58</cell><cell>11</cell><cell>84</cell><cell>0.84</cell><cell>0.41</cell><cell>0.55</cell></row><row><cell></cell><cell cols="5">Combining all four Categories together</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Once or more</cell><cell>761</cell><cell>410</cell><cell>113</cell><cell cols="2">297 29</cell><cell>0.28</cell><cell>0.80</cell><cell>0.41</cell></row><row><cell>Twice or more</cell><cell>478</cell><cell>126</cell><cell>88</cell><cell>38</cell><cell>54</cell><cell>0.70</cell><cell>0.62</cell><cell>0.66</cell></row><row><cell cols="2">Three times or more 298</cell><cell>72</cell><cell>62</cell><cell>10</cell><cell>80</cell><cell>0.86</cell><cell>0.44</cell><cell>0.58</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Main Test Data</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Twice or more</cell><cell>630</cell><cell>159</cell><cell>97</cell><cell></cell><cell></cell><cell>0.61</cell><cell>0.38</cell><cell>0.48</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,132.26,686.16,217.70,8.18"><p>Presumably the N of PAN now comes from the conjunction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,132.38,686.16,171.17,8.18"><p>Available at: http://www.liwc.net/tryonline.php</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,128.58,177.32,342.00,9.05;12,142.82,188.84,327.68,9.05;12,142.82,200.36,327.99,9.05;12,142.82,211.76,96.41,9.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,274.95,177.32,195.64,9.05;12,142.82,188.84,235.32,9.05">I don&apos;t know where he&apos;s not&quot;: Does Deception Research yet offer a basis for Deception Detectives?</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vartapetiance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gillam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,388.63,188.84,81.87,9.05;12,142.82,200.36,279.06,9.05">Proceedings of the Workshop on Computational Approaches to Deception Detection</title>
		<meeting>the Workshop on Computational Approaches to Deception Detection<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,223.31,342.06,9.05;12,142.82,234.83,327.97,9.05;12,142.82,246.35,26.67,9.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,194.57,234.83,74.22,9.05">Cues to Deception</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">M</forename><surname>Depaulo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">E</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Muhlenbruck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Charlton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,276.77,234.83,90.36,9.05">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="118" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,257.87,341.84,9.05;12,142.82,269.39,327.67,9.05;12,142.82,280.79,314.83,9.05" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Moffitt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">B</forename><surname>Burns</surname></persName>
		</author>
		<title level="m" coord="12,248.69,257.87,221.74,9.05;12,142.82,269.39,327.67,9.05;12,142.82,280.79,222.03,9.05">What Does That Mean? Investigating Obfuscation and Readability Cues as Indicators of Deception in Fraudulent Financial Reports: Fifteenth Americas Conference on Information Systems</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,292.31,341.95,9.05;12,142.82,303.83,327.99,9.05;12,142.82,315.35,118.06,9.05" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Skillicorn</surname></persName>
		</author>
		<title level="m" coord="12,244.73,292.31,225.81,9.05;12,142.82,303.83,307.60,9.05">Detecting Deception in Testimony: Proceeding of IEEE International Conference of Intelligence and Security Informatics (ISI 2008)</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,326.87,341.99,9.05;12,142.82,338.39,327.54,9.05;12,142.82,349.79,228.21,9.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,256.85,326.87,208.91,9.05">Improving a Textual Deception Detection Model</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Skillicorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,142.82,338.39,327.54,9.05;12,142.82,349.79,91.56,9.05">Proceedings of the 2006 Conference of the Center for Advanced Studies on Collaborative Research</title>
		<meeting>the 2006 Conference of the Center for Advanced Studies on Collaborative Research<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,361.31,342.06,9.05;12,142.82,372.83,327.77,9.05;12,142.82,384.37,159.19,9.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,412.87,361.31,57.78,9.05;12,142.82,372.83,182.91,9.05">Lying Words: Predicting Deception from Linguistic Styles</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,329.35,372.83,141.24,9.05;12,142.82,384.37,30.80,9.05">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="665" to="675" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,128.58,395.89,341.91,9.05;12,142.82,407.29,284.25,9.05" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,249.89,395.89,106.63,9.05">Word Association Norms</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,367.48,395.89,103.02,9.05;12,142.82,407.29,165.67,9.05">Mutual Information and Lexicography: Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
