<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.68,115.90,310.01,12.90;1,220.53,133.83,174.29,12.90;1,223.43,153.79,168.50,10.75">A learning-based approach for the identification of sexual predators in chat logs Notebook for PAN at CLEF 2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,194.58,190.29,56.36,8.64"><forename type="first">Javier</forename><surname>Parapar</surname></persName>
							<email>javierparapar@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">University of A Coruña</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.39,190.29,66.48,8.64"><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
							<email>david.losada@usc.es</email>
							<affiliation key="aff1">
								<orgName type="department">Centro de Investigación en Tecnoloxías da Información (CITIUS)</orgName>
								<orgName type="institution">Universidade de Santiago de Compostela</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,353.20,190.29,63.10,8.64"><forename type="first">Alvaro</forename><surname>Barreiro</surname></persName>
							<email>barreiro@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="laboratory">Information Retrieval Lab</orgName>
								<orgName type="institution">University of A Coruña</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.68,115.90,310.01,12.90;1,220.53,133.83,174.29,12.90;1,223.43,153.79,168.50,10.75">A learning-based approach for the identification of sexual predators in chat logs Notebook for PAN at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8B5A60A5BE959BC25100AFED8DA3ECCB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The existence of sexual predators that enter into chat rooms or forums and try to convince children to provide some sexual favour is a socially worrying issue. Manually monitoring these interactions is a way to attack this problem. However, this manual approach simply cannot keep pace because of the high number of conversations and the huge number of chatrooms or forums where these conversations daily take place. We need tools that automatically process massive amounts of conversations and alert about possible offenses. The sexual predator identification challenge within PAN 2012 is a valuable way to promote research in this area. Our team faced this task as a Machine Learning problem and we designed several innovative sets of features that guide the construction of classifiers for identifying sexual predation. Our methods are driven by psycholinguistic, chat-based, and tf/idf features and yield to very effective classifiers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many underaged children who are regular Internet users are the targets of unwanted sexual solicitation. This is a socially worrying issue of paramount importance. Health care professionals, educators, parents, police organizations, and the society as a whole should be prepared to respond to this increasingly prevalent problem.</p><p>In 2012, a sexual predator identification task was proposed within the Author Identification Task of the Unconvering Plagiarism, Authorship, and Social Software Misuse Lab <ref type="bibr" coords="1,153.13,536.78,46.65,8.64">(PAN 2012)</ref>. This innovative and important challenge was divided into two parts: sexual identification subtask and line identification subtask. The second subtask was more exploratory and it did not have labeled data to train the systems. Therefore, we devoted our main efforts to the first subtask, which consists of identifying sexual predators from a large set of chat logs.</p><p>We tested different Machine Learning strategies and thoroughly tuned the classifiers to identify sexual predation. Our main contribution is the proposal of an innovative set of features to drive the classification of chat participants (two class problem: predator/non-predator). We utilized standard term-based features (tf/idf) but also other content-based features based on psycholinguistics. In the literature of psycholinguistics, there is strong evidence <ref type="bibr" coords="1,231.04,656.44,16.60,8.64" target="#b9">[10]</ref> that links the use of natural language to personality, social and situational fluctuations, and psychological interventions. Of particular interest are findings that point to the psychological value of studying word usage for identifying deception <ref type="bibr" coords="2,166.24,143.22,10.89,8.64" target="#b5">[6,</ref><ref type="bibr" coords="2,177.13,143.22,7.26,8.64" target="#b1">2,</ref><ref type="bibr" coords="2,184.39,143.22,7.26,8.64" target="#b7">8]</ref>. Since sexual predation in the Internet is an inherently deceptive activity, we felt that incorporating features based on psycholinguistics could help us to search for predatory behaviour within the chats.</p><p>We also defined other global features based on the activity of the users in the chatrooms, the type of conversations in which they tend to engage in, and other contextual factors. This is a ground-breaking set of features that substantially helps to find sexual predators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Learning strategy</head><p>We approached the PAN 2012 sexual predation task as a supervised learning problem. Given the training collection, we focused on selecting the most effective classification strategy and the most effective sets of features to guide the classification. The training collection contains conversations from 97689 different subjects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Representation of the subjects</head><p>Every participant often takes part in several chat conversations and interacts with different subjects in different ways. It is therefore quite challenging to understand how to properly represent the chatroom users from their interactions. Furthermore, the process of sexual predation is known to happen in phases <ref type="bibr" coords="2,339.84,426.07,10.79,8.64" target="#b4">[5]</ref>: gaining access, deceptive trust development, grooming, isolation, and approach. Therefore, every conversation could be classified in accordance to this categorization and, additionally, every user-to-user interaction could be monitorized to estimate what stages of predation have actually occurred. This leads to very intriguing issues related to how to extract relevant patterns of Internet sexual predation from massive amounts of chat conversations.</p><p>We are aware that these user's representation challenges are important to advance in sexual predation identification and we plan to face them in the near future. Anyway, we opted for approaching this year's task in a much simpler way. For every individual, we concatenated together all the lines written by him/her in any conversation in which he/she participated. The resulting text was our document-based representation for this chat participant (i.e. one document per subject). This means that we lose track of individual conversations and we simply record on a file all lines written by this chatter. This textual representation is recognizably simplistic but we expect that it still contains the basic clues to identify predation.</p><p>These document-based representations were used as an input to extract the contentbased features (tf/idf and LWIC) described below. However, observe that we also include in our experiments a set of chat-based features that are not based on the text written by the chat participant but are based on the global behaviour of the subject in the chatrooms. This acts as a complementary representation for the chatters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>We studied different strategies to extract a feature-based representation for the chat participants:</p><p>tf/idf features. This is a baseline representation consisting of a standard unigram representation of the texts. Given the characteristics of the chat conversations, we decided to not apply stemming. We simply pruned the vocabulary by removing those terms appearing in 10 or less documents (i.e. terms used by 10 or less subjects were removed). This pruning eliminates those words that are used by a very limited number of people and it has the advantage of reducing significantly the number of features. This has important implications in the training time taken to build the classifiers. Terms whose character size was greater than 20 were also removed. Each term was weighted with a standard tf/idf weighting scheme <ref type="bibr" coords="3,412.24,270.64,10.79,8.64" target="#b3">[4]</ref>:</p><formula xml:id="formula_0" coords="3,235.22,290.84,245.37,23.22">tf /idf t,d = (1 + log(tf t,d )) × log( N df t )<label>(1)</label></formula><p>where tf t,d in the term frequency of the term t in the document d, N is the number of documents in the collection and df t is the number of documents in the collection that contain t. We also considered bigrams and trigrams in our study. We excluded bigrams and trigrams occurring in three or less documents. This substantially limits the number of these n-grams features and maintains only those expressions whose pattern of usage is not marginal. The n-grams having a character size equal to or greater than 40 were also removed. We tested all the combinations of the tf/idf features, namely: unigrams only, bigrams only, trigrams only, unigrams+bigrams, unigrams+trigrams, bigrams+trigrams, and all n-grams. Anyway, for the sake of clarity, we will only report and discuss those combinations with reasonably good performance. -LWIC features. We felt that predation could be discovered using psycholinguistic features. In the area of psychology <ref type="bibr" coords="3,295.52,465.15,15.27,8.64" target="#b9">[10]</ref>, it has been shown that the words people use in their daily lives can reveal important aspects of their social and psychological worlds. Since we wanted to explore psychological aspects of natural language use, we decided to use Linguistic Inquiry and Word Count (LIWC) <ref type="bibr" coords="3,429.04,501.02,10.58,8.64" target="#b8">[9]</ref>, which is a text analysis software program that calculates the degree to which people use different categories of words. The ways that individuals talk and write provide windows into their emotional and cognitive worlds and can be used to analyze aspects such as deception, honesty, etc. LWIC processes textual inputs and produces output variables such as standard linguistic dimensions, word categories tapping psychological constructs (e.g. affect, cognition), personal concern categories (e.g. work, home, leisure), and some other dimensions (paralinguistic dimensions, punctuation categories, and general descriptor categories). Overall, there are 80 different LWIC dimensions and we processed every document in our collection (as originally written, with no modifications or preprocessing) to obtain 80 LWIC features associated to every individual. The complete set of LWIC features is shown in Table <ref type="table" coords="3,454.47,632.53,3.74,8.64" target="#tab_0">1</ref>. The first two features, wc and wps, are the total count of the number of words and the average number of words per sentence, respectively. The rest of the features are percentages of occurrence of words from different linguistic categories (e.g. % of words in the text that are pronouns). The table includes the LWIC category, the abbreviation and some examples for each LWIC dimension. We used the complete LWIC 2007 English Dictionary with no modification. Therefore, the list of words in the table is just an illustrative example of the words associated to every category. chat-based features. Finally, we defined 11 additional features that capture some global aspects related to the activity of the individuals in the chatrooms. This included features such as the number of subjects contacted by a given individual, the percentage of conversations initiated by a given individual, the percentage of lines written by a given individual (computed across all the conversations in which he/she participated), the average time of day when he/she used to chat, the average number of users participating in the conversations in which he/she participated (e.g. does he/she always participate in 1-to-1 conversations?), etc. Somehow, we expected that this innovative set of features would be indicative of how active, anxious and intense each user is, and indicative of the type of conversations in which he/she usually engages (1-to-1 conversations, night/evening conversations, etc). We felt that these features could reveal some trends related to predation. The chat-based features are reported in Table <ref type="table" coords="5,270.68,427.88,3.74,8.64">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training</head><p>The PAN 2012 training collection has a large number of examples (97689 chatters) and our approach handles a large number of features for each example (e.g. there are more than 10k unigram features). Given these statistics, we decided to use LibLinear <ref type="bibr" coords="5,468.97,506.69,11.62,8.64" target="#b0">[1]</ref> for learning the classifiers. LibLinear is a highly effective library for large-scale linear classification. This library handles Support Vector Machines (SVMs) classification and Logistic Regression classification with different regularization and loss functions. We extensively tested against the training collection all the classifiers supported. We finally chose SVMs as our classifier for all our submitted runs and, therefore, in this article we will only report and discuss results for this learning model. More specifically, we utilized the L2-regularized L2-loss SVM primal solver <ref type="foot" coords="5,352.51,588.71,3.49,6.05" target="#foot_0">3</ref> . This is a highly unbalanced two-class classification problem: 142 out of the 97689 subjects are labeled as predators in the training collection. When dealing with unbalanced problems, discriminative algorithms such as SVMs, which maximize classification accuracy, result in trivial classifiers that completely ignore the minority class <ref type="bibr" coords="5,466.48,638.20,10.58,8.64" target="#b6">[7]</ref>. In our experiments we applied 4-fold cross-validation and focused on optimizing F1 computed with respect to the positive class (being a predator):</p><formula xml:id="formula_1" coords="7,276.06,298.13,204.53,22.31">F 1 = 2 • P • R P + R<label>(2)</label></formula><p>where P = T P/(T P + F P ) and R = T P/(T P + F N ).</p><p>In our initial tests, we observed that performance was relatively insensitive to the SVM cost parameter (C) but very sensitive to the weights that adjust the relative cost of misclassifying positive and negative examples. We therefore focused on fine tuning this weighting. By default, LibLinear assigns a weight equal to 1 to every class label (i.e. w 1 = 1, w -1 = 1). These weights are multiplied by C and the resulting values are used by the SVM's optimization process to penalize wrongly classified examples. Since we need to penalize the misclassification of positive examples, we opted for fixing w -1 to its default value and iteratively optimizing w 1 . The SVM cost parameter (C) was fixed to its default value (C = 1).</p><p>Given the feature sets described in subsection 2.2, we did not apply any feature selection strategy but simply configured a complete set of experiments combining the three sets of features. Essentially, we tested all the 1-set, 2-set and 3-set combinations of the feature sets.</p><p>Although our model selection criterion was based on F1, we also report precision and recall in all the tables. For each feature set, the results reported correspond with the highest F1 run (average 4-fold cross-validation F1) obtained after tuning the w 1 weight. Anyway, for the sake of clarity, we do not include the optimal w 1 in every table. We will analyze the optimal w 1 values after selecting our top runs.</p><p>Table <ref type="table" coords="7,174.53,560.80,4.98,8.64" target="#tab_1">3</ref> depicts the performance results obtained with a single set of features. The results clearly show that the content-based features perform poorly (tf/idf and LWIC both yield to F1 performance lower than 10%). The performance of the chat-based features is substantially higher but it is still rather modest (e.g. precision below 50% and F 1 = 56.73%). The tf/idf results were obtained with unigrams alone, tf/idf(1g). Anyway, we also tested the incorporation of bigrams and/or trigrams into the tf/idf features but they did not give much added value. The main conclusion that we extracted from these initial experiments is that taking features from a single set (tf/idf/LWIC/chatbased) is not enough to have reasonably good effectiveness. Next, we tested the combination of different sets of features, including different types of n-grams for the tf/idf features. This involved extensive exterimentation and validation against the training collection. Anyway, we only report in Table <ref type="table" coords="8,438.15,234.33,4.98,8.64" target="#tab_2">4</ref> the most representative runs. We finally decided to select five of them (those whose label is in italics) as our contribution to PAN 2012. We selected the runs not only based on the average 4-fold F1 performance but also based on how sensitive they were with respect to the w 1 setting. Another technique that we took into account is scaling. Scaling before applying SVM is known to be very important <ref type="bibr" coords="8,280.59,488.29,10.58,8.64" target="#b2">[3]</ref>. The main advantage of scaling is to avoid features in greater numeric range dominating those in smaller numeric ranges. Scaling also avoids numerical difficulties during the calculation. We therefore planned a thorough set of experiments with scaled features (in the interval [0,1]), either using svm_scale from LibLinear or applying other normalization methods (e.g. cosine normalization for the tf/idf features). In Table <ref type="table" coords="8,251.85,548.06,4.98,8.64" target="#tab_3">5</ref> we present the scaled version of the five runs that we selected for PAN 2012. The results with scaling were rather unsatisfactory. We never obtained any substantial gain from scaling and the performance was usually lower than the performance obtained with no scaling. Still, we decided to submit ten runs: the five selected runs in italics in Table <ref type="table" coords="8,260.14,595.88,4.98,8.64" target="#tab_2">4</ref> and their corresponding scaled versions (Table <ref type="table" coords="8,455.36,595.88,3.60,8.64" target="#tab_3">5</ref>).</p><p>Overall, we observed that the unigram tf/idf features combined with the chat-based features were the most effective and robust features. Therefore, we nominated the run tf/idf(1g)+chat-based as our official run <ref type="foot" coords="8,292.30,631.22,3.49,6.05" target="#foot_1">4</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The w 1 weight</head><p>Recall that w 1 controls the penalty given to positive examples that are misclassified. Our strategy to set w 1 was as follows. As argued above, w -1 was fixed to 1 (default value) and we only experimented with varying w 1 values. As recommended in <ref type="bibr" coords="9,134.77,296.73,10.58,8.64" target="#b2">[3]</ref>, we tried out a grid search approach with exponentially growing sequences of w 1 . More specifically, we tested w 1 = 2 -5 , 2 -4 , ..., 2 10 . Once the best w 1 in this sequence was found we conducted a finer grid search on that better region (e.g. after finding out that w 1 = 8 was optimal in the exponentially growing sequence we tested w 1 = 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15). The weight w 1 was finally set to the value yielding the highest F1 across all these experiments. Table <ref type="table" coords="9,173.49,368.46,4.98,8.64" target="#tab_4">6</ref> reports the optimal w 1 weights for the ten selected runs. These tuned weights are slightly lower than expected. Observe that the ratio of predators in the collection is 142/97689. Therefore, we would expect optimal w 1 's greater than 100. Instead, we got optimal w 1 's substantially smaller than 100. We will carefully analyze this issue in the future.</p><p>To further analyze the sensitivity of performance to w 1 , we took our ten runs and selected from them the three runs that perform the best in terms of F1. These three high performing runs are tf/idf(1g)+chat-based, tf/idf(1g)+chat-based+LWIC, and tf/idf(1g, 3g)+chat-based. Given these runs, figure <ref type="figure" coords="9,301.41,464.10,4.98,8.64" target="#fig_1">1</ref> depicts how F1 performance changes with varying w 1 . With w 1 &lt; 1 performance drops substantially for the three methods. This is not surprising because w -1 is set to 1 and, therefore, setting w 1 lower than 1 means that   we are giving more importance to the correct classification of the negative examples (non-predators). This is not a good choice for our task, which aims at finding sexual predators. With w 1 between 2 2 and 2 5 , tf/idf(1g)+chat-based and tf/idf(1g,3g)+chatbased have nearly optimal performance. With w 1 &gt; 2 5 performance starts to fall, showing that we are giving too much emphasis on correctly classifying the positive examples. Observe that setting w 1 to 1 yields to performance results that are not far from the optimal results and, furthermore, performance tends to nearly optimal for all w 1 's in the range [1, 2 8 ]. This figure also shows that tf/idf(1g)+chat-based+LWIC is weaker than the other two methods and its performance quickly falls with w 1 &gt; 2 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Test</head><p>The The performance of our ten selected runs against the test collection is reported in Table <ref type="table" coords="10,159.14,608.62,3.74,8.64" target="#tab_6">7</ref>. The performance of the scaled versions is always poorer than the performance of their non-scaling counterparts. This already happened in the training collection and shows that scaling our features does not work for this learning problem. Again, the tf/idf(1g)+chat-based run is the best performing run. Selecting it as our official run was indeed a good decision. In terms of F1, tf/idf(1g,3g)+chat-based, tf/idf(1g,3g)+chat- based+LWIC, and tf/idf(1g)+chat-based+LWIC are not far from the performance obtained by the best run. A similar relative ordering of the runs was found with the training collection.</p><p>Our best run ranked #3, out of 16 international teams participating in PAN 2012. We believe that this is a pretty decent outcome for our very first contribution to the area of sexual predator identification. Furthermore, some of our modeling decisions (e.g. the representation of the subjects taking all their conversations) are simplistic and, in the future, we might get further gains in performance from more evolved representations of the chatters.</p><p>It seems obvious that recall was our main weakness. Comparing our training results (Table <ref type="table" coords="11,163.11,402.60,4.15,8.64" target="#tab_2">4</ref>) against the test results (Table <ref type="table" coords="11,295.63,402.60,4.15,8.64" target="#tab_6">7</ref>) we can clearly see that we even got higher precision in the test collection. Instead, recall fell substantially at test time. In the near future, we will carefully look into this issue. This might have something to do with the existence of many predators in the test collection, and some of them might have distinctive characteristics that do not match with the trends found for the 142 predators in the training collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Line identification task</head><p>The line identification subtask was particularly difficult because there was not labeled data. We did not have examples of predatory lines and, therefore, the participation of the teams in this subtask was somehow blind. Observe also that some of the features that we used for the subject identification subtask cannot be used at line level. For instance, the chat-based features are global characteristics of the activity of a chat participant and, therefore, it does not make sense to compute them at line level. The LWIC features could be applied at line level because they are essentially word count features. Still, we felt that the main advantage of LWIC features is the ability to extract relevant psycholinguistic patterns from the complete discourse of a chatter, rather than from a single line of text. We therefore decided to also avoid LWIC features for the line identification subtask.</p><p>We took the estimated predators from each of our ten sexual predator identification runs, and processed all their lines with a tf/idf classifier. Since there were not labeled lines, we had to apply a tf/idf classifier tuned for the predator identification task. This limitation and the poor performance of the tf/idf classifier (Table <ref type="table" coords="12,398.43,131.27,4.15,8.64" target="#tab_1">3</ref>) made that our expectations for this task were rather low. The official results for this subtask confirmed our expectations. Our submitted run performed very poorly (2% in terms of F1) and was ranked 9th among the participating teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>This was our first incursion into a cybercrime detection problem. We believe that we have successfully shown that a learning-based approach is a feasible way to approach this problem. We have proposed innovative sets of features to drive the classification of chat participants as predators or non-predators. Our experiments demonstrated that the set of features utilized and the relative weighting of the misclassification costs in the SVMs are the two main factors that should be taken into account to optimize performance.</p><p>In the near future we want to carefully analyze the relative importance of the individual features in each feature set. This will help to understand psycholinguistic, contextual and behavioural characteristics of sexual predators in the Internet. Moving to more evolved representations of the Internet subjects and taking into account the sequential process of predation will be also top priorities in our future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,138.89,250.49,54.14,8.06;6,251.68,250.49,76.06,8.06;6,138.89,264.19,75.52,7.77;6,251.68,264.19,224.79,7.77;6,251.68,275.15,37.61,7.77;6,138.89,286.51,337.57,7.77;6,251.68,297.46,224.79,7.77;6,251.68,308.42,91.40,7.77;6,138.89,319.78,69.72,7.77;6,251.68,319.78,220.14,7.77;6,138.89,331.14,56.77,7.77;6,251.68,331.14,224.79,7.77;6,251.68,342.10,48.56,7.77;6,138.89,353.45,74.47,7.77;6,138.89,364.41,43.82,7.77;6,251.68,353.45,224.79,7.77;6,251.68,364.41,13.95,7.77;6,138.89,375.77,89.65,7.77;6,138.89,386.73,25.40,7.77;6,251.68,375.77,224.79,7.77;6,251.68,386.73,24.41,7.77;6,138.89,398.09,87.79,7.77;6,138.89,409.05,94.51,7.77;6,251.68,398.09,224.79,7.77;6,251.68,409.05,28.14,7.77;6,138.89,420.40,77.17,7.77;6,138.89,431.36,58.28,7.77;6,251.68,420.40,224.79,7.77;6,251.68,431.36,191.75,7.77;6,138.89,442.72,58.76,7.77;6,138.89,453.68,58.28,7.77;6,251.68,442.72,224.79,7.77;6,251.68,453.68,153.90,7.77;6,138.89,465.04,65.74,7.77;6,138.89,475.99,51.30,7.77;6,251.68,465.04,224.79,7.77;6,251.68,475.99,57.03,7.77;6,138.89,487.35,63.08,7.77;6,138.89,498.31,44.02,7.77;6,251.68,487.35,224.79,7.77;6,251.68,498.31,213.91,7.77;6,191.24,520.63,232.88,7.77;7,134.77,119.31,345.82,8.64;7,134.77,131.27,345.82,8.64;7,134.77,143.22,345.82,8.64;7,134.77,155.18,345.82,8.64;7,134.77,167.13,345.82,8.64;7,134.77,179.09,345.82,8.64;7,134.77,191.04,345.82,8.64;7,134.77,203.00,345.82,8.64;7,134.77,214.95,345.82,8.64;7,134.77,226.91,345.82,8.64;7,134.77,238.86,345.82,8.64;7,134.77,250.82,114.54,8.64"><head></head><label></label><figDesc>in characters) of the user's message lines in the collection. avgTimeOfDayOfMessages Average time of day when every message line was sent by the user. Time of day is measured in minutes from/to midnight (the smallest amount applies). noOfMessageLines Number of message lines written by the user in the collection noOfCharacters Character count of all the message lines written by the user in the collection noOfDifferentUsers-Approached Number of different users approached by the user in the collection percentOfConversations-Started Percentage of the conversations started by the user in the collection avgNoOfUsersInvolved-InParticipedConversations Average number of users participating in the conversations with the user percentOfCharacters-InConversations Percentage of the characters written by the user (computed across the conversations in which he/she participates) percentOfLines-InConversations Percentage of lines written by the user (computed across the conversations in which he/she participates) avgTimeBetween-MessageLines Average time, in minutes, between two consecutive message lines of the user avgConversation-TimeLength Average conversation length, in minutes, for the user (computed across the conversations in which he/she participates) Table 2: Chat-level features associated to a given chat participant Some of the typical methods to deal with this problem include oversampling the minority class (by repeating minority examples), undersampling the majority class (by removing some examples from the majority class), or adjusting the misclassification costs. Oversampling the minority class results in considerable computational costs during training because it significantly increases the size of the training collection. Undersampling the majority class is not an option for our sexual predation problem because we have a tiny number of positive examples (142) and we would need to remove most of the negative examples in order to have a sets of positive examples and negative examples that are comparable in size. This massive removal of negative examples would miss much information. We therefore opted for adjusting the misclassification costs to penalize the error of classifying a positive example as negative (i.e. a sexual predator classified as a non-predator).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,203.81,293.29,12.74,5.64;10,270.51,293.29,3.27,5.64;10,304.67,293.29,9.31,5.64;10,329.44,293.29,9.31,5.64;10,389.76,293.29,12.58,5.64;10,185.31,288.81,3.27,5.64;10,182.05,270.98,6.54,5.64;10,182.05,253.18,6.54,5.64;10,182.05,235.35,6.54,5.64;10,182.05,217.55,6.54,5.64;10,182.05,199.72,6.54,5.64;10,182.05,181.92,6.54,5.64;10,182.05,164.09,6.54,5.64;10,182.05,146.29,6.54,5.64;10,182.05,128.50,6.54,5.64;10,307.12,299.65,7.85,9.88;10,314.97,306.23,4.44,7.82;10,170.49,204.99,9.88,11.77;10,254.39,200.28,98.15,9.68;10,254.39,212.48,129.27,9.68;10,254.39,224.70,112.18,9.68"><head>1 F1</head><label>1</label><figDesc>tf_idf(1g)+chat-based tf_idf(1g)+chat-based+LWIC tf_idf(1g,3g)+chat-based</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,176.03,325.77,263.29,8.06"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: F1 performance with varying w1 weights for our three best runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,159.38,188.90,296.59,480.14"><head>Table 1 :</head><label>1</label><figDesc>LWIC dimensions</figDesc><table coords="4,159.38,188.90,296.59,480.14"><row><cell>Category</cell><cell>Abbrev</cell><cell>Examples</cell></row><row><cell>Linguistic Processes</cell><cell></cell><cell></cell></row><row><cell>Word count</cell><cell>wc</cell><cell></cell></row><row><cell>words/sentence</cell><cell>wps</cell><cell></cell></row><row><cell>Dictionary words</cell><cell>dic</cell><cell></cell></row><row><cell>Words&gt;6 letters</cell><cell>sixltr</cell><cell></cell></row><row><cell>Function words</cell><cell>funct</cell><cell></cell></row><row><cell>Pronouns</cell><cell>pronoun</cell><cell>I, them, itself</cell></row><row><cell>Personal pronouns</cell><cell>ppron</cell><cell>I, them, her</cell></row><row><cell>1st pers singular</cell><cell>i</cell><cell>I, me, mine</cell></row><row><cell>1st pers plural</cell><cell>we</cell><cell>We, us, our</cell></row><row><cell>2nd person</cell><cell>you</cell><cell>You, your, thou</cell></row><row><cell>3rd pers singular</cell><cell>shehe</cell><cell>She, her, him</cell></row><row><cell>3rd pers plural</cell><cell>they</cell><cell>They, their</cell></row><row><cell>Impersonal pronouns</cell><cell>ipron</cell><cell>It, it's, those</cell></row><row><cell>Articles</cell><cell>article</cell><cell>A, an, the</cell></row><row><cell>Common verb</cell><cell>verb</cell><cell>Walk, went, see</cell></row><row><cell>Auxiliary verbs</cell><cell>auxverb</cell><cell>Am, will, have</cell></row><row><cell>Past tense</cell><cell>past</cell><cell>Went, ran, had</cell></row><row><cell>Present tense</cell><cell>present</cell><cell>Is, does, hear</cell></row><row><cell>Future tense</cell><cell>future</cell><cell>Will, gonna</cell></row><row><cell>Adverbs</cell><cell>adverb</cell><cell>Very, really, quickly</cell></row><row><cell>Prepositions</cell><cell>prep</cell><cell>To, with, above</cell></row><row><cell>Conjunctions</cell><cell>conj</cell><cell>And, but,whereas</cell></row><row><cell>Negations</cell><cell>negate</cell><cell>No, not, never</cell></row><row><cell>Quantifiers</cell><cell>quant</cell><cell>Few, many, much</cell></row><row><cell>Numbers</cell><cell>number</cell><cell>Second, thousand</cell></row><row><cell>Swear words</cell><cell>swear</cell><cell>Damn, piss, fuck</cell></row><row><cell>Psychological Processes</cell><cell></cell><cell></cell></row><row><cell>Social processes</cell><cell>social</cell><cell>Mate, talk,they, child</cell></row><row><cell>Family</cell><cell>family</cell><cell>Daughter,husband, aunt</cell></row><row><cell>Friends</cell><cell>friend</cell><cell>Buddy, friend, neighbor</cell></row><row><cell>Humans</cell><cell>human</cell><cell>Adult, baby, boy</cell></row><row><cell>Affective processes</cell><cell>affect</cell><cell>Happy, cried, abandon</cell></row><row><cell>Positive emotion</cell><cell>posemo</cell><cell>Love, nice, sweet</cell></row><row><cell>Negative emotion</cell><cell>negemo</cell><cell>Hurt, ugly,nasty</cell></row><row><cell>Anxiety</cell><cell>anx</cell><cell>Worried,fearful, nervous</cell></row><row><cell>Anger</cell><cell>anger</cell><cell>Hate, kill,annoyed</cell></row><row><cell>Sadness</cell><cell>sad</cell><cell>Crying, grief, sad</cell></row><row><cell>Cognitive processes</cell><cell>cogmech</cell><cell>cause, know, ought</cell></row><row><cell>Insight</cell><cell>insight</cell><cell>think, know,consider</cell></row><row><cell>Causation</cell><cell>cause</cell><cell>because, effect, hence</cell></row><row><cell>Discrepancy</cell><cell>discrep</cell><cell>should, would, could</cell></row><row><cell>Tentative</cell><cell>tentat</cell><cell>maybe, perhaps, guess</cell></row><row><cell>Certainty</cell><cell>certain</cell><cell>always, never</cell></row><row><cell>Inhibition</cell><cell>inhib</cell><cell>block,constrain, stop</cell></row><row><cell>Inclusive</cell><cell>incl</cell><cell>And, with, include</cell></row><row><cell>Exclusive</cell><cell>excl</cell><cell>But, without, exclude</cell></row><row><cell>Perceptual processes</cell><cell>percept</cell><cell>Observing, heard, feeling</cell></row><row><cell>See</cell><cell>see</cell><cell>View, saw, seen</cell></row><row><cell>Hear</cell><cell>hear</cell><cell>Listen, hearing</cell></row><row><cell>Feel</cell><cell>feel</cell><cell>Feels, touch</cell></row><row><cell>Biological processes</cell><cell>bio</cell><cell>Eat, blood, pain</cell></row><row><cell>Body</cell><cell>body</cell><cell>Cheek, hands, spit</cell></row><row><cell>Health</cell><cell>health</cell><cell>Clinic, flu, pill</cell></row><row><cell>Sexual</cell><cell>sexual</cell><cell>Horny, love, incest</cell></row><row><cell>Ingestion</cell><cell>ingest</cell><cell>Dish, eat, pizza</cell></row><row><cell>Relativity</cell><cell>relativ</cell><cell>Area, bend, exit, stop</cell></row><row><cell>Motion</cell><cell>motion</cell><cell>Arrive, car, go</cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,177.94,117.32,259.49,63.32"><head>Table 3 :</head><label>3</label><figDesc>Performance results (in percentage) with a single set of features</figDesc><table coords="8,251.39,117.32,112.57,41.40"><row><cell cols="2">Feature Set P</cell><cell>R</cell><cell>F1</cell></row><row><cell>tf/idf(1g)</cell><cell cols="3">2.85 51.35 5.39</cell></row><row><cell>LWIC</cell><cell cols="3">4.79 70.95 8.97</cell></row><row><cell cols="4">chat-based 49.25 66.89 56.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,317.24,345.82,129.47"><head>Table 4 :</head><label>4</label><figDesc>Performance results (in percentage) with feature sets combining tf/idf, LWIC and chatbased. The runs that we submitted to PAN 2012 have their label in italics.</figDesc><table coords="8,215.61,317.24,184.13,96.19"><row><cell>Feature Set</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>tf/idf(1g)+chat-based</cell><cell cols="3">89.15 80.99 84.87</cell></row><row><cell>tf/idf(1g,2g)+chat-based</cell><cell cols="3">91.74 78.17 84.41</cell></row><row><cell>tf/idf(1g,3g)+chat-based</cell><cell cols="3">89.68 79.58 84.33</cell></row><row><cell>tf/idf(1g,2g,3g)+chat-based</cell><cell cols="3">92.44 77.46 84.29</cell></row><row><cell>tf/idf(1g)+LWIC</cell><cell cols="3">78.99 76.76 77.86</cell></row><row><cell>chat-based+LWIC</cell><cell cols="3">45.58 66.22 53.99</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC</cell><cell cols="3">87.69 80.28 83.82</cell></row><row><cell cols="4">tf/idf(1g,3g)+chat-based+LWIC 78.36 73.94 76.09</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,134.77,117.32,345.82,96.59"><head>Table 5 :</head><label>5</label><figDesc>Performance results (in percentage) of the five selected feature sets when the features were scaled in [0,1].</figDesc><table coords="9,200.53,117.32,214.29,63.32"><row><cell>Feature Set</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>tf/idf(1g)+chat-based (scaled)</cell><cell cols="3">80.29 77.46 78.85</cell></row><row><cell>tf/idf(1g,3g)+chat-based (scaled)</cell><cell cols="3">75.19 70.42 72.73</cell></row><row><cell>tf/idf(1g)+LWIC (scaled)</cell><cell cols="3">69.44 70.42 69.93</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC (scaled)</cell><cell cols="3">84.09 78.17 81.02</cell></row><row><cell cols="4">tf/idf(1g,3g)+chat-based+LWIC (scaled) 71.52 76.06 73.72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,209.27,520.75,196.82,140.83"><head>Table 6 :</head><label>6</label><figDesc>Optimal w1 weight for the ten submitted runs.</figDesc><table coords="9,228.21,520.75,158.44,118.51"><row><cell>Feature Set</cell><cell>w1</cell></row><row><cell>tf/idf(1g)+chat-based</cell><cell>11</cell></row><row><cell>tf/idf(1g,3g)+chat-based</cell><cell>10</cell></row><row><cell>tf/idf(1g)+LWIC</cell><cell>1</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC</cell><cell>3</cell></row><row><cell>tf/idf(1g,3g)+chat-based+LWIC</cell><cell>3</cell></row><row><cell>tf/idf(1g)+chat-based (scaled)</cell><cell>4</cell></row><row><cell>tf/idf(1g,3g)+chat-based (scaled)</cell><cell>18</cell></row><row><cell>tf/idf(1g)+LWIC (scaled)</cell><cell>1</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC (scaled)</cell><cell>4</cell></row><row><cell cols="2">tf/idf(1g,3g)+chat-based+LWIC (scaled) 64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,512.50,345.82,80.37"><head></head><label></label><figDesc>test collection contains 218702 subjects, and 254 of them are positive examples (sexual predators). The percentages of predators in the training and test collections are comparable (around 0.1%) and, therefore, both datasets are similarly unbalanced. However, it is important to observe that the number of positive examples in the training collection (142) is substantially smaller than the number of positive examples in the test collection (254). This introduces additional difficulties because the trained classifiers were built from a small set of positive examples.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,138.11,117.32,339.14,140.82"><head>Table 7 :</head><label>7</label><figDesc>Performance results (in percentage) of the ten selected runs against the test collection.</figDesc><table coords="11,200.53,117.32,214.29,118.51"><row><cell>Feature Set</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>tf/idf(1g)+chat-based</cell><cell cols="3">93.92 66.93 78.16</cell></row><row><cell>tf/idf(1g,3g)+chat-based</cell><cell cols="3">94.74 63.78 76.24</cell></row><row><cell>tf/idf(1g)+LWIC</cell><cell cols="3">78.05 62.99 69.72</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC</cell><cell cols="3">90.11 64.57 75.23</cell></row><row><cell>tf/idf(1g,3g)+chat-based+LWIC</cell><cell cols="3">93.06 63.39 75.41</cell></row><row><cell>tf/idf(1g)+chat-based (scaled)</cell><cell cols="3">85.80 57.09 68.56</cell></row><row><cell>tf/idf(1g,3g)+chat-based (scaled)</cell><cell cols="3">76.24 60.63 67.54</cell></row><row><cell>tf/idf(1g)+LWIC (scaled)</cell><cell cols="3">64.00 50.39 56.39</cell></row><row><cell>tf/idf(1g)+chat-based+LWIC (scaled)</cell><cell cols="3">86.29 59.45 70.40</cell></row><row><cell cols="4">tf/idf(1g,3g)+chat-based+LWIC (scaled) 72.20 63.39 67.51</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="5,144.73,657.08,259.86,7.77"><p>This is option -s 2 when running the liblinear training script (train).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="8,144.73,657.08,309.02,7.77"><p>The task organizers asked the participants to nominate only one run as the official run.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.61,400.69,326.52,7.77;12,150.95,411.65,240.32,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,366.21,400.69,102.93,7.77;12,150.95,411.65,68.45,7.77">Liblinear: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,224.92,411.65,73.96,7.77">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06">Jun 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,422.07,337.19,7.77;12,150.95,433.03,316.08,7.77;12,150.95,443.99,44.08,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,339.07,422.07,140.73,7.77;12,150.95,433.03,212.83,7.77">On lying and being lied to: A linguistic analysis of deception in computer-mediated communication</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goorha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Woodworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,370.17,433.03,72.96,7.77">Discourse Processes</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,454.40,332.01,7.77;12,150.95,465.36,270.27,7.77;12,150.95,476.32,161.81,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,276.91,454.40,172.66,7.77">A practical guide to support vector classification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/cjlin/papers.html" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, National Taiwan University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct coords="12,142.61,486.74,325.17,7.77;12,150.95,497.70,157.89,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,196.03,486.74,268.59,7.77">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,150.95,497.70,93.64,7.77">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,508.12,314.52,7.77;12,150.95,519.08,290.22,7.77;12,150.95,530.04,87.15,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,150.95,519.08,161.11,7.77">Learning to identify internet sexual predation</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mcghee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bayzick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kontostathis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mcbride</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Jakubowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,317.92,519.08,123.26,7.77;12,150.95,530.04,39.34,7.77">International Journal of Electronic Commerce</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,540.45,337.98,7.77;12,150.95,551.41,295.37,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,261.23,540.45,219.36,7.77;12,150.95,551.41,67.01,7.77">The lie detector: Explorations in the automatic recognition of deceptive language</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,236.25,551.41,132.89,7.77">Proc. ACL-IJCNLP 2009 Conference</title>
		<meeting>ACL-IJCNLP 2009 Conference</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,561.83,312.00,7.77;12,150.95,572.79,300.99,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,201.26,561.83,169.10,7.77">Discriminative models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,387.98,561.83,66.64,7.77;12,150.95,572.79,233.57,7.77">Proc. ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,583.21,323.77,7.77;12,150.95,594.17,319.30,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,342.69,583.21,123.69,7.77;12,150.95,594.17,74.72,7.77">Lying words: Predicting deception from linguistic styles</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,231.16,594.17,155.42,7.77">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="665" to="675" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,604.59,326.97,7.77;12,150.95,615.55,233.87,7.77;12,150.95,626.50,191.42,7.77" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="12,407.43,604.59,62.15,7.77;12,150.95,615.55,190.79,7.77">The development and psychometric properties of liwc2007 @ONLINE</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ireland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Booth</surname></persName>
		</author>
		<ptr target="http://www.liwc.net/LIWC2007LanguageManual.pdf" />
		<imprint>
			<date type="published" when="2012-06">Jun 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,636.92,333.14,7.77;12,150.95,647.88,272.51,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,308.78,636.92,166.60,7.77;12,150.95,647.88,77.27,7.77">Psychological aspects of natural language use: Our words, our selves</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Niederhoffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,233.90,647.88,105.88,7.77">Annual review of psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="547" to="577" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
