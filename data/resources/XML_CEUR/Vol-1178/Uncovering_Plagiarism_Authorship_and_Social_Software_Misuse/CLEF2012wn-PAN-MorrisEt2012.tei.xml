<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,219.74,115.90,175.88,12.90;1,239.53,133.83,136.30,12.90;1,193.40,151.77,228.56,12.90;1,223.43,171.61,168.50,10.75">Identifying Sexual Predators by SVM Classification with Lexical and Behavioral Features Notebook for PAN at CLEF 2012</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,245.14,208.01,51.76,8.64"><forename type="first">Colin</forename><surname>Morris</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.27,208.01,53.95,8.64"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,219.74,115.90,175.88,12.90;1,239.53,133.83,136.30,12.90;1,193.40,151.77,228.56,12.90;1,223.43,171.61,168.50,10.75">Identifying Sexual Predators by SVM Classification with Lexical and Behavioral Features Notebook for PAN at CLEF 2012</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">474E1564E15C01C7CF363A61C2A0C10B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We identify sexual predators in a large corpus of web chats using SVM classification with a bag-of-words model over unigrams and bigrams. We find this simple lexical approach to be quite effective with an F 1 score of 0.77 over a 0.003 baseline. By also encoding the language used by an author's partners and some small heuristics, we boost performance to an F 1 score of 0.83. We identify the most "predatory" messages by calculating a score for each message equal to the average of the weights of the n-grams therein, as determined by a linear SVM model. We boost performance with a manually constructed "blacklist".</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and motivation</head><p>Our tasks were to distinguish sexual predators from non-predators in a corpus of online chats which was highly biased toward the negative class, and then to identify lines written by these alleged predators which were most indicative of their bad behaviour. Of the approximately 98,000 chat participants (whom we will generically refer to as "authors") in the PAN training corpus, 142 are identified as being sexual predators. We subdivide the complement class of non-predators into "victims" (anyone who ever talks to a predator -we have 142 in our training corpus), and "bystanders" (those who have no interactions with predators).</p><p>Although we read existing literature on the linguistic characteristics of sexual predators, such as <ref type="bibr" coords="1,187.04,512.97,10.58,8.64" target="#b3">[4]</ref>, <ref type="bibr" coords="1,203.92,512.97,10.58,8.64" target="#b4">[5]</ref>, <ref type="bibr" coords="1,220.78,512.97,10.58,8.64" target="#b5">[6]</ref>, and <ref type="bibr" coords="1,254.79,512.97,10.58,8.64" target="#b6">[7]</ref>, unlike some of the other teams we make no a priori assumptions about the language of sexual predators, and only the barest assumptions about predator behaviour (we merely assume that predators and victims chat in pairs, rather than in larger groups). Rather, we use a naive machine learning approach, wherein predators are defined solely and completely by the behaviour and language of the 142 predators identified by the ground truth of the training set.</p><p>We use a set of standard lexical features and features that generically describe the behaviour of chat participants. It's our hope that, given the success of our approach, a post hoc analysis of feature weights will suggest an empirically defensible model of "predatory language", and perhaps add or remove evidentiary weight to existing theories of predator language and behaviour.</p><p>We hypothesize that our classifier will be more effective if it can be attuned to both the language of predatoriness and the language of victimhood. For example, we imagine that an adult engaging in a sexually explicit chat with another consenting adult might use language not unlike that of a sexual predator. However, we would expect the other participant to be an eager participant in the former case, and reticent or evasive in the latter case.</p><p>Thus, an important aspect of our approach is that a given author's feature vector reflects not just that author's language and behaviour, but also the language and behaviour of his or her interlocutor(s). This gives our machine learning algorithm roughly twice as much information to base its model on; we expect at least some of this additional information to be useful for discrimination, since we don't expect the language of one author to wholly determine the language of his or her interlocutor, notwithstanding the effect of lexical entrainment <ref type="bibr" coords="2,249.45,239.36,10.58,8.64" target="#b0">[1]</ref>.</p><p>For the second task of predatory message identification, we return to our set of lexical features from the classification task. We train a linear SVM model for distinguishing predators from non-predators using just lexical features, and use the resulting weights over unigrams and bigrams to induce a weighting of "predatoriness" over all terms. We flag all predator messages where the sum of the weights of the terms in the message is above a certain hand-tuned threshold, along with all messages which contain any terms in a hand-assembled "blacklist".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Features</head><p>Our feature set can broadly be divided into lexical features and what we'll term "behavioural features", which capture patterns in the ebb and flow of conversation. Feature vectors are calculated on a per-author basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lexical features</head><p>We use a standard bag-of-words model, since this has been shown to be robust in the face of a wide variety of text classification problems. Having also experimented with term presence, tf-idf, and log of term frequency, we ultimately settled on simple term frequency as our metric. We used both unigrams and bigrams.</p><p>As noted above, a key aspect of our approach to lexical features was our consideration of the language of the focal author's interlocutors as well as that of the focal author themselves. Thus every token t that appears more often than our threshold (empirically set to 10) yields two features: the number of times the focal author utters t, and the number of times any of the focal author's interlocutors utters t. We will henceforth refer to features of the latter type as "mirror" features. If we take the following short, imagined exchange as an example:</p><p>Author1: hi alice Author2: hi hi then Author1 would be associated with the following vector: {hi : 1, alice : 1, hi alice : 1, OTHER_hi : 2, OTHER_hi hi : 1} and Author2 would be associated with a mirror vector: {hi : 2, hi hi : 1, OTHER_hi : 1, OTHER_alice : 1, OTHER_hi alice : 1}.</p><p>We experimented with a number of standard text preprocessing routines including lowercasing, stripping punctuation, and stemming. None of these routines improved performance, thus our final results use simple space-separated tokens as features.</p><p>We also tried to add "smarts" to our lexical features with some transformation rules. We introduced the following special tokens: \SMILEY For smiley faces matching a collection of emoticons assembled from Wikipedia (http://en.wikipedia.org/wiki/List_of_emoticons). We also introduce the following refinements: \SMILEY_happy \SMILEY_sad \SMILEY_silly \SMILEY_other \MALE_name For tokens matching a list of the 1,000 most common male given names in the United States. <ref type="foot" coords="3,236.69,331.31,3.69,6.39" target="#foot_0">1</ref> We manually removed around 10 names which are more likely to appear as common nouns (e.g. "Guy"). \FEMALE_name As above, for female names. In cases where a name can be both male and female, we choose the sex for which the name is more popular. \NUM For any sequence of digits. We also introduce the following refinements on this category: \NUM_small For n &lt; 13. \NUM_teen For 13 ≤ n &lt; 18. \NUM_adult For 18 ≤ n &lt; 80. \NUM_large For n ≥ 80. \PHONE_num For tokens matching any number of patterns for a phone number, with or without area code, with a variety of possible delimiters.</p><p>To our disappointment, these transformations seemed to add little discriminative power to our model; we will elaborate on and discuss this later in our results section. Unless otherwise specified, all results given below use only the simplest lexical features, without preprocessing or transformation rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Behavioural features</head><p>In addition to using the language of our authors, we explored high-level conversational patterns in order to exploit the small amount of metadata associated with conversations (mostly in the form of timestamps). In addition to looking at what words authors use, we're interested to see how they use them.</p><p>Because we became interested in the secondary problem of distinguishing predators from victims (see section 3.1), many of these features are concerned with the problem of "symmetry-breaking". That is, given two authors who speak to one another using very similar language (which we found is often the case with predators and victims), what non-lexical aspects of the conversation can be used to distinguish them?</p><p>We used two "author-level" features which were straightforward to calculate on a per-author basis:</p><p>NMessages The total number of messages sent by this author in the corpus. NConversations The total number of conversations in the corpus which this author participates in.</p><p>These two features were quite strongly correlated with predatorhood. This is probably an unintended side effect of the corpus construction, and we shouldn't use this fact to draw any conclusions about predator behaviour, such as "predators talk a lot". Because of the large imbalance between the positive and negative class in the corpus and because there were anomalies on both sides (that is, predators with very few messages or conversations, and non-predators with many messages and conversations), these features alone are not enough to attain a reasonable F-score.</p><p>Initiative We employ a number of features which can be thought of as approximating an author's tendency to "initiate" with their partner:</p><p>Initiations The number of times this author initiates a conversation by sending the first message (this is usually something like "hey" or "what's up?"). Initiation rate The above variable normalized by number of conversations. Questions The number of times this author asks a question, where we roughly define a question as any message ending in a question mark or interrobang. Question rate As above, but normalized by number of messages.</p><p>Attentiveness Another set of features correspond to an author's attempts to keep a conversation going, and perhaps their level of commitment to the conversation.</p><p>Response time Messages in our corpus come with timestamps which are not guaranteed to be correct in an absolute sense, but which we assume are at least correct with respect to some time offset; thus, we expect the time deltas between messages to be accurate. Unfortunately, we have only minute-level precision. In a conversation between authors A and B we measure A's response times as follows: when we first see a message from B, we record the timestamp t0. We pass by any subsequent messages from B until we encounter a message from A and record its timestamp t1.</p><p>The response time is t1 -t0. We seek ahead to the next message from B and repeat this process until the end of the conversation. We measure the mean, median, and max response times for each author, aggregated over all response times (rather than over all conversations).</p><p>This measure falls apart somewhat with conversations involving more than two authors. However, one of the few assumptions we make about predators and victims is that they always speak in pairs -and this is certainly true in the training data.</p><p>Repeated messages We measure the lengths of "streaks" of messages from the focal author which are uninterrupted by an interlocutor. The shortest allowable streak length is 1. Again, we record the mean, max, and median repeated messages.</p><p>Conversation dominance Our last set of features can be thought of as reflecting the degree to which the focal author "dominates" his conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Message ratio</head><p>The ratio of messages from the focal author to the number of messages sent by the other authors in the conversation, aggregated over all conversations in which the focal author participates. Wordcount ratio As above, but using the number of "words" (space-separated tokens)</p><p>written by each author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Machine learning techniques and tools</head><p>Our machine learning algorithm of choice was support vector machines, using the LIB-SVM library <ref type="bibr" coords="5,188.66,379.68,10.58,8.64" target="#b2">[3]</ref>. We used a radial kernel, having also experimented with a linear kernel. We return to the linear kernel in the predator message task (below), since unlike the radial kernel, it allows us to inspect feature weights to get a rough idea of the discriminative power of various features. In testing our models, we used cross-validation with n = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results postprocessing</head><p>After classifying unknown authors using our model, we experimented with two later filters for boosting performance. Both steps were motivated by our observation that a large proportion of false positives (usually more than 75%) were in fact victims; thus predators and victims were quite similar in our dataset with respect to our lexical and behavioural features. The first and most obviously effective step hinged on the assumption that the likelihood of two predators talking to one another was negligbly small. Thus, with our set of predicted predators, we returned to our corpus of conversations and found any pairs that ever talked to one another. For every such pair, we flipped the label of the author in whom the SVM had the least confidence (in addition to predicted labels, LIBSVM yields the confidence of each prediction). This increased precision at a small cost to recall.</p><p>The second filter used a second SVM model with the specialized task of distinguishing predators from victims (rather than predators from non-predators). After the first classification, we would run our predator-victim classifier on the alleged predators, and keep only the authors that were again labelled as predators. The rationale behind this step was that the differences between predators and bystanders are quite coarse. This is due to the nature of the training set, where the non-predatory conversations tend to be very different from predatory conversations in terms of topic (e.g. IRC chatrooms on web programming), or in the relationship between interlocutors (e.g. short chats between anonymous strangers on Omegle, which contrast with predators and victims who tend to have repeated, sustained conversations).</p><p>Because predators and victims are discussing the same topics and are virtually identical in terms of number and length of conversations, we need to look to more finegrained differences. This is what motivated our "symmetry-breaking" behavioural features such as message ratio, number of repeated messages, and number of initiations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predatory messages task</head><p>We trained a linear model for discriminating predators from non-predators using only our lexical features. We then treated the weight assigned to each term as an approximation of the "predatoriness" of that term. We assigned a predator score to each message equal to the sum of the weights of all unigrams and bigrams in the message, and flagged as predatory all messages with a predator score above a certain threshold. We handtuned this threshold so that what we deemed was a reasonable proportion of messages were flagged (approximately 2% to 5%).</p><p>We also build by hand a "blacklist" of 122 n-grams (including morphological variations and spelling variants) which automatically flag a message as predatory. Because we begin from the assumption that the messages we're classifying are all from predators to victims, we can choose words which have no conceivable place in an appropriate conversation between an adult and a child. Thus, these words don't automatically signal a message as predatory (since they may be employed in conversations between consenting adults), but they do signal a message as predatory when the message is from a predator to a victim.</p><p>Our blacklist focuses on terms which are sexually explicit, pertain to the exchange of photos, or pertain to arranging meetings. In an analysis of 51 chats between sexual predators and victims, Briggs et al <ref type="bibr" coords="6,276.29,477.23,11.62,8.64" target="#b1">[2]</ref> found that 100% of predators initiated sexually explicit conversations, 68.6% sent nude photos, and 60.8% scheduled a face-to-face meeting. We expect this blacklist to strictly increase recall, at a trivial cost to precision, if any.</p><p>Finally, we heavily penalize very short messages (those consisting of four or fewer space-separated tokens). This is based on the assumption that such short messages are unlikely to convey enough propositional content to be "predatory" (except, perhaps, with respect to the surrounding context), and on the volatility of taking averages over a small set of values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Predator classification</head><p>Using the default parameter settings for LIBSVM (γ = 1/nfeatures, C = 1), gave precision of 0.91, recall of 0.28, and F 1 score of 0.43 on the PAN training data. The large Table <ref type="table" coords="7,159.04,115.83,3.36,8.06">1</ref>. Cross-validated results (n = 5) on the predator classification task. The first row uses our optimized settings of c and γ with all features described in section 2 but without lexical transformation rules and without any postprocessing of results. Subsequent rows add or subtract features or steps for comparison. Note that the second row corresponds to the configuration used for our main submission to the competition. The last row is our baseline, resulting from labelling every author as a predator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variation</head><p>Recall We performed a grid search to optimize the setting of parameters C and γ, varying them on a logarithmic scale. We settled on C = 100 and γ = 10 -4 .</p><p>Table <ref type="table" coords="7,174.62,432.66,4.98,8.64">1</ref> gives our basic cross-validated results on the training data, along with the results associated with certain variations. Section 3.1 describes the "partner flip" and "predator-victim classification" filters. Our set of transformation rules are described in section 2.1. "Only focal lexical features" means that we only count the words used by the author under consideration (the "focal author") and not their interlocutors -see section 2.1.</p><p>Precision and recall alone don't give a full picture of the nature of our errors, since there is a hidden "third class" beyond predators and non-predators. There is a relatively high degree of confusion between predators and "victims" (those who chat with predators). Table <ref type="table" coords="7,184.05,540.85,4.98,8.64" target="#tab_1">2</ref> gives the confusion matrix for these classes in a basic run, and table <ref type="table" coords="7,475.61,540.85,4.98,8.64" target="#tab_2">3</ref> gives the confusion matrix for the same run following our "partner flip" filter. Note that these confusion matrices aren't square because in our classification scheme the "victim" and "bystander" classes are conflated into the class of "non-predators".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Message classification</head><p>Our results for the message classification subtask are given in table 4, evaluated on the ground truth given for the test data. Because our training data contains no ground truth for the message classification task, we're unable to give cross-validated results. a For the sake of clarity and completeness, we include here our results as reported on the competition website, which are hindered by a bug which caused messages by alleged predators and victims to be considered. All other results reported here were obtained after this bug was fixed.</p><p>In preparing our submission, we didn't know that F 3 score would be the evaluation metric, nor what proportion of predator messages would be flagged. Thus our particular "standard" threshold, which resulted in high precision and low recall, put us in a relatively poor position. The "Low predatoriness threshold" run uses the same methods but a much lower minimum predatoriness score for messages (-0.03 rather than 0.01<ref type="foot" coords="9,470.60,165.20,3.69,6.39" target="#foot_1">2</ref> ), with the aim of improving recall and therefore F 3 score.</p><p>Note that our baseline involves selecting every message as predatory, even though it does not have 1.0 recall. This is because the pool of "predators" whose messages we classified was based on our classification in the previous step, rather than the ground truth (and thus, because we didn't achieve perfect recall in the first subtask, some predators don't even have their messages considered in this subtask). The interdependence of the subtasks also means that our baseline applies uniquely to our results, and not to those of other teams, who may have higher or lower baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Predator classification</head><p>Perhaps the most interesting feature of table 1 is the robustness of simple lexical features. Of our innovations -the mirror lexical features for conversational partners (see section 2.1), the partner flip and predator-victim classification filters, transformation rules, and behavioural features -only the mirror lexical features have an unambiguously positive effect on results, and some seem to diminish F-score when compared to the lexical baseline.</p><p>Table <ref type="table" coords="9,157.58,419.89,3.36,8.06">5</ref>. The top and bottom 10 lexical features associated with predatorhood according to a linear SVM model. As in section 2.1 we use the convention that OTHER_ preceding an n-gram denotes the use of that n-gram by the focal author's partner(s), rather than the focal author themselves. Note that in constructing this list, we set the minimum appearance threshold for n-grams to 30 rather than the typical 10, in an attempt to filter out spurious features. The partner flip step was generally effective, especially in maximizing F 0.5 score which was the evaluation measure for the competition. The improvement shown in table 1 is small because the partner flip is a step that's effective in high-recall, low-precision runs, whereas ours tended to be the opposite. While our predator-victim classifier was quite accurate (having a cross-validated accuracy of 0.93 when applied to the predators and victims in our training data), it wasn't ultimately able to increase our F-score in the classification of predators and non-predators. Again, we suspect that the picture might have been different if our results had been skewed toward high recall and low precision rather than the opposite.</p><p>Omitting behavioural features seems to give a slight (0.03) increase in cross-validated F-score. A naive interpretation of this might be that behavioural features are actually harmful to accuracy. In fact, they do convey useful information about predatoriness, since our 12 behavioural features alone attain an F-score of 0.56, which is well above baseline (and which would place in the middle of the competition results). We suspect that the score increase when omitting these features is due to random noise. Applied to the evaluation data, it was the purely lexical model that gave a slightly lesser F-score.</p><p>We suspect that the negligible effects of our innovations are because the Pareto principle is at play in the data, wherein 20% of our features capture 80% of the instances in our corpus (in fact, the ratio may be more like 1% to 99%). This is supported by the fact, as noted above, that our mere 12 behavioural features can attain a stunningly high F-score of 0.56 on our highly imbalanced dataset (where the random baseline is 0.03). We claim that our transformation rules and behavioural features carry useful information about predatorhood, but that they unfortunately don't provide enough new information on top of our simple lexical features to increase performance.</p><p>Table <ref type="table" coords="10,174.41,572.08,4.98,8.64">5</ref> gives the 10 top and bottom lexical features associated with predatorhood. While we know that our simple lexical features are very effective at identifying predators, the feature weightings are surprisingly opaque. While the top 100 features contains a handful of obviously sexual n-grams (e.g. 18:sexy, 23:wanna fuck), the vast majority are common function words (e.g. 10:there, 24:you, 28:my, 40:and). Thus, it's not obvious how to draw a meaningful picture of predator language based on these weights.</p><p>Table <ref type="table" coords="10,175.69,644.48,4.98,8.64" target="#tab_4">6</ref> gives the average of some of our behavioural features across our three classes of authors. Although our behavioural features ultimately offered no improve-ment on top of our lexical features, they were able to form a reasonably accurate classification model alone, and their distribution may offer some insights into predator and victim behaviour (in a way that our lexical features have not). As noted earlier, the trends in number of messages and conversations are artefactual and not much should be read into them. However, it's interesting that predators consistently send more and longer messages than their victim counterparts. Predators also initiate conversations almost twice as often as victims, and take, on average, less than half as long to respond to messages. The standard deviation for average response time among victims is 6.733, quite large compared to 1.053 for predators and 2.267 for bystanders. This suggests that the distribution for victims has a long tail, with victims often waiting long periods of time to respond.</p><p>These numbers paint a behavioural picture of the predator as someone who dominates conversations, and who is the more "eager" participant, tending to initiate conversations, and keep them going by responding quickly and voluminously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Message classification</head><p>Despite our ranking of n-grams based on linear SVM weights being difficult to interpret, they were fairly effective at classifying messages. Our approach gives the highest precision of all submissions, our original submission achieving 0.445 precision, and 0.544 following a bugfix, above the next highest precision submission of 0.350, and well above the baseline of 0.092.</p><p>Our initial parameter setting gives an F 1 score of 0.284, which is well above the baseline of 0.169. Our best F 3 score is achieved by setting a low threshold for predatorscore, giving F 3 = 0.403. To our surprise, our baseline of labelling every message as predatory achieves an F 3 score of 0.363, which bests all but the aforementioned run, and which handily exceeds all submissions to the competition.</p><p>The "Low threshold, only weights" row of table <ref type="table" coords="11,352.11,438.94,4.98,8.64" target="#tab_3">4</ref> shows that our SVM weights alone achieve a respectable F 1 score (0.232, exceeding the baseline of 0.160).</p><p>As we would expect, the blacklist alone achieves the highest precision, at a cost to recall. We were surprised to see that precision was only 0.565, since we had constructed our blacklist in such a way that we thought all terms would be unambiguously "predatory". Examining the false positives from this run reveals that most could be argued to belong to the class of predatory messages, for example: &lt;conversation id=027600c74917a8d2438070be950fc2b6&gt; &lt;message line=40&gt;i wanna kiss, etc&lt;/message&gt; &lt;message line=42&gt;lick&lt;/message&gt; &lt;/conversation&gt; &lt;conversation id=0730400af8a1b5a8aa88146baf417191&gt; &lt;message line=15&gt;so you wont be sleeping naked tonight I take it&lt;/message&gt; &lt;message line=71&gt;so what are you wearing?&lt;/message&gt; &lt;message line=84&gt;so does she have a cam?&lt;/message&gt; &lt;message line=90&gt;what would you show me on cam?&lt;/message&gt; &lt;/conversation&gt;</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,230.69,149.98,153.97,81.46"><head>Table 2 .</head><label>2</label><figDesc>Class confusion in a basic run.</figDesc><table coords="8,230.69,179.08,153.97,52.36"><row><cell>Class</cell><cell cols="2">Predator Non-predator Total</cell></row><row><cell>Predator</cell><cell>104</cell><cell>38 142</cell></row><row><cell>Victim</cell><cell>8</cell><cell>134 142</cell></row><row><cell>Bystander</cell><cell>6</cell><cell>97532 97538</cell></row><row><cell>Total</cell><cell>118</cell><cell>97704</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,146.20,319.41,322.95,83.29"><head>Table 3 .</head><label>3</label><figDesc>Class confusion in a basic run followed by our partner flip filter (see section 3.1).</figDesc><table coords="8,230.69,350.34,153.97,52.36"><row><cell>Class</cell><cell cols="2">Predator Non-predator Total</cell></row><row><cell>Predator</cell><cell>103</cell><cell>39 142</cell></row><row><cell>Victim</cell><cell>3</cell><cell>139 142</cell></row><row><cell>Bystander</cell><cell>6</cell><cell>97532 97538</cell></row><row><cell>Total</cell><cell>112</cell><cell>97710</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,176.20,490.67,262.97,95.24"><head>Table 4 .</head><label>4</label><figDesc>Results of the message classification task on the evaluation data.</figDesc><table coords="8,189.90,511.64,235.57,74.27"><row><cell>Run</cell><cell cols="2">Precision Recall F 1 score F 3 score</cell></row><row><cell>Standard run (submission) a</cell><cell>0.445 0.187 0.263</cell><cell>0.198</cell></row><row><cell>Standard run</cell><cell>0.544 0.192 0.284</cell><cell>0.205</cell></row><row><cell cols="2">Low predatoriness threshold 0.192 0.403 0.260</cell><cell>0.403</cell></row><row><cell cols="2">Low threshold, only weights 0.176 0.345 0.232</cell><cell>0.345</cell></row><row><cell>Only blacklist</cell><cell>0.565 0.181 0.274</cell><cell>0.194</cell></row><row><cell>Baseline</cell><cell>0.094 0.530 0.160</cell><cell>0.363</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,233.10,484.89,149.16,117.91"><head>Table 6 .</head><label>6</label><figDesc>Statistics reflecting the distribution of our behavioural features across predators, victims, and bystanders.</figDesc><table coords="9,233.10,484.89,149.16,117.91"><row><cell>Rank n-gram</cell><cell>Rank n-gram</cell></row><row><cell>1 OTHER_wtf</cell><cell>1 ???</cell></row><row><cell>2 ??? ???</cell><cell>2 now</cell></row><row><cell>3 hiiiii</cell><cell>3 now u?</cell></row><row><cell>4 asl</cell><cell>4 so wat</cell></row><row><cell>5 OTHER_no.</cell><cell>5 hi</cell></row><row><cell>6 OTHER_hi</cell><cell>6 wat</cell></row><row><cell>7 ??</cell><cell>7 OTHER_:(</cell></row><row><cell>8 ?</cell><cell>8 so</cell></row><row><cell>9 hello?</cell><cell>9 around</cell></row><row><cell>10 there</cell><cell>10 what</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,635.17,335.86,7.77;3,144.73,646.13,335.86,7.77;3,144.73,657.08,25.65,7.77"><p>We sourced our name lists from http://www.galbithink.org/names/us200.htm, using births from 1990 to 1999. The figures ultimately come from United States Social Security Administration.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="9,144.73,646.13,335.86,7.77;9,144.73,657.08,300.90,7.77"><p>Feature weights are not necessarily distributed symmetrically about 0; thus it would be facile to say that positive weights are predatory and negative weights are "anti-predatory".</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,138.13,142.87,334.93,7.77;12,146.47,153.83,257.18,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,247.33,142.87,183.72,7.77">Conceptual pacts and lexical choice in conversation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,436.95,142.87,36.11,7.77;12,146.47,153.83,219.83,7.77">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,164.79,321.40,7.77;12,146.47,175.75,315.54,7.77;12,146.47,186.71,261.59,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,286.72,164.79,172.81,7.77;12,146.47,175.75,315.54,7.77;12,146.47,186.71,83.90,7.77">An exploratory study of internet-initiated sexual offenses and the chat room sex offender: Has the internet enabled a new typology of sex offender? Sexual Abuse</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Simonsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,236.82,186.71,133.90,7.77">A Journal of Research and Treatment</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,197.67,338.77,7.77;12,146.47,208.63,289.00,7.77;12,146.47,219.59,144.13,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,230.91,197.67,171.92,7.77">LIBSVM: A library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/cjlin/libsvm" />
	</analytic>
	<monogr>
		<title level="j" coord="12,409.08,197.67,67.81,7.77;12,146.47,208.63,139.84,7.77">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,230.55,325.97,7.77;12,146.47,241.50,334.07,7.77;12,146.47,252.46,97.44,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,202.28,230.55,261.82,7.77;12,146.47,241.50,243.69,7.77">Predatory online behavior: Modus operandi of convicted sex offenders in identifying potential victims and contacting minors over the Internet</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Malesky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,395.75,241.50,84.80,7.77;12,146.47,252.46,22.73,7.77">Journal of Child Sexual Abuse</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,263.42,329.95,7.77;12,146.47,274.38,260.74,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,203.00,263.42,265.08,7.77;12,146.47,274.38,65.88,7.77">Interpreting the intentions of Internet predators: An examination of online predatory behavior</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Marcum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,218.26,274.38,109.77,7.77">Journal of Child Sexual Abuse</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="99" to="114" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,285.34,314.52,7.77;12,146.47,296.30,332.30,7.77;12,146.47,307.26,81.43,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,146.47,296.30,161.60,7.77">Learning to identify Internet sexual predation</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mcghee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bayzick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kontostathis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mcbride</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Jakubowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,313.93,296.30,164.85,7.77">International Journal of Electronic Commerce</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="103" to="122" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,318.22,342.46,7.77;12,146.47,329.18,252.03,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,188.56,318.22,258.08,7.77">Toward spotting the pedophile: Telling victim from predator in text chats</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pendar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,464.15,318.22,16.44,7.77;12,146.47,329.18,198.45,7.77">First IEEE International Conference on Semantic Computing</title>
		<imprint>
			<biblScope unit="page" from="235" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
