<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,206.29,115.90,202.77,12.90;1,157.31,133.83,300.74,12.90">Encoplot -Tuned for High Recall (also proposing a new plagiarism detection score)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.16,172.30,62.80,8.64"><forename type="first">Cristian</forename><surname>Grozea</surname></persName>
							<email>cristian.grozea@brainsignals.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer FOKUS</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.80,172.30,63.92,8.64"><forename type="first">Marius</forename><surname>Popescu</surname></persName>
							<email>popescunmarius@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,206.29,115.90,202.77,12.90;1,157.31,133.83,300.74,12.90">Encoplot -Tuned for High Recall (also proposing a new plagiarism detection score)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">061FD682320071A8B52F306B210B8B98</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes the latest changes to our plagiarism detection system Encoplot. We have sent the modified system to the PAN@CLEF 2012 automatic detection of plagiarism challenge, where it ranked 2nd by the F-measure and 3rd by the "plagdet" scoring method that we had previously shown to be flawed to some extent. The main changes have been done to the heuristic that tries to recognize the clusters of N-grams matches as matching passages in the pair of documents examined. We have aimed for high recall under difficult conditions (sparse matches) which are typical for real-life rephrasing by people. The result of the evaluation on the training and test PAN 2012 corpora shows that we have achieved our goal of improving the performance of this piece of the Encoplot plagiarism detection system. In the final part of this article we analyze the anomalies of the plagdet scoring method, show that those are not negligible, and propose a modified plagdet version that lowers those anomalies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism detection is unfortunately a requirement of the nowadays academic life. More than once an year the press publishes about yet another politician who plagiated in his/her Ph.D. thesis. To quote from <ref type="bibr" coords="1,295.10,476.26,15.27,8.64" target="#b13">[14]</ref>, "A spectre is haunting Europe, and this time it is the spectre of plagiarism and scientific misconduct. Some high-profile politicians have had to resign in the last 18 months -but the revelations are also shaking respected European universities". Scientific articles are written by appropriation of someone else's work through plagiarism, even in fields as medicine where the possible consequences of faking research and results are potentially very severe <ref type="bibr" coords="1,432.67,536.04,10.79,8.64" target="#b3">[4,</ref><ref type="bibr" coords="1,443.46,536.04,7.19,8.64" target="#b2">3]</ref>. Given the large volume of works that should be checked for plagiarism, automatic plagiarism detection is probably the only practical way to prune until the human examiners can finally decide on whether or not the text reuse is a plagiate or not.</p><p>Our team has build a series of very competitive plagiarism detection systems, named Encoplot after the way the core algorithm used functions <ref type="bibr" coords="1,365.54,596.24,10.89,8.64" target="#b4">[5,</ref><ref type="bibr" coords="1,376.43,596.24,7.26,8.64" target="#b6">7,</ref><ref type="bibr" coords="1,383.69,596.24,7.26,8.64" target="#b7">8]</ref>. Those had very good performance in the previous years international competitions on plagiarism detection <ref type="bibr" coords="1,134.77,620.15,39.43,8.64">PAN 2009</ref><ref type="bibr" coords="1,181.17,620.15,19.93,8.64">PAN , 2010</ref><ref type="bibr" coords="1,220.46,620.15,59.66,8.64">PAN and 2011[12,11,13][12,11,13]</ref>.</p><p>This year we have focused only on the detailed comparison subtask, where the strengths of Encoplot lie. This task requires that given a pair of documents (one possible source and a second, suspicious document) all plagiarism instances from the source to the suspicious document are found and reported. That is to say that each copied passage, with or without obfuscation, short or long must be found, even across languages. Given our previous bad experience with automatic translation <ref type="bibr" coords="2,381.03,143.22,11.62,8.64" target="#b7">[8]</ref> we took the easy path of using the opportunity offered by the organizers to process the texts already translated into English. Therefore, for the remaining of this paper we consider that the two texts to be compared share the same language (that doesn't have to be English, as Encoplot is language and character set independent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Encoplot</head><p>Very briefly, Encoplot's core algorithm is a variant of the well-known Dotplot <ref type="bibr" coords="2,442.45,266.47,10.58,8.64" target="#b1">[2]</ref>, faster because the set of N-gram matches (dots on the plot) is guaranteed to be linear and the run-time is also linear; also the matches lost (vs. dotplot) have good chances to bear low information, and thus be insignificant as a proof of plagiarism.</p><p>The Encoplot Core Algorithm -Input: Sequences A and B to compare -Output: list (x,y) of positions in A, respectively B, where there is exactly the same N-gram 1. Extract the N-grams from A and B 2. Sort these two lists of N-grams 3. Intersect these lists using a modified mergesort algorithm. Whenever the two smallest N-grams are the equal, output the position in A and the one in B.</p><p>A simple example is given in Table <ref type="table" coords="2,292.53,449.21,3.74,8.64" target="#tab_0">1</ref>. After obtaining this (sub)set of the positions where the two texts contain the same N-grams, a heuristic process is run in order to identify the passage copying. A passage copied verbatim leads to a perfect diagonal (translated to the starting position of the passage in the source and in the suspicious document). Obfuscation leads to more diffuse clouds of dots -see Figure <ref type="figure" coords="2,274.25,632.53,4.98,8.64" target="#fig_0">1</ref> and Figure <ref type="figure" coords="2,327.10,632.53,3.74,8.64" target="#fig_2">2</ref>.</p><p>What is new in the version for PAN 2012 is that the N-gram matches clustering heuristic part is now tuned for higher recall on the difficult cases: manual plagiarism and high obfuscation (either artificially induced, or occurring as a result of translation). This comes at the expense of diminishing the precision for some easier cases (like the no-obfuscation or the verbatim copying); as those are easily handled by trivially-simple methods, we have decided to ignore that. Also we have identified and fixed a bug which affected the versions we have sent to PAN from 2009 on -this bug reduced the chances of finding passage matches after the first one is found. Tuning has been done by understanding why the heuristic failed in randomly picked cases and adjusting the parameters to improve the behavior on those cases. Also we have checked the effect of the changes on only the first 50 pairs from the lists provided in the training dataset.</p><p>In order to present the changes, we follow the full description of the heuristic used until 2011, as given in the technical report <ref type="bibr" coords="3,309.14,533.98,10.58,8.64" target="#b5">[6]</ref>. Please note that the roles of the suspicious document and source document are now reversed: the first projection is done on the suspicious document, instead of the source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Clustering Heuristic</head><p>The heuristic employed for clustering the "dots" produced by the encoplot core algorithm into passages consists of the following steps:</p><p>1. The dots are projected on the suspicious document's axis, then the presence bits of these projections are smoothed by convolution with a constant vector of size 256, in order to approximate their local density.</p><p>2. Within a Monte-Carlo optimization loop (100 attempts), a random starting position is selected, among the projections of the dots on the axis corresponding to the suspicious document. 3. This start is treated like the seed of a segment which is extended to the left and to the right as much as possible, while keeping the density of the projections in the segment over a certain limit (1/32). 4. If the segment is long enough (128 characters) and the projections within it are dense enough (above 1/32), the dots having projections inside the segment are isolated, their projections on the axis of the source document are pruned of outliers. 5. If the segment on the axis of the source and the segment on the axis of the suspicious document satisfies certain sanity checks (their lengths over 128 and the density of the projections of the dots above 50%), the pair of segments (passages) is selected as a candidate. 6. The best candidate (the one with longest passages found in correspondence) is reported if it satisfies the checks mentioned at the previous step, otherwise the current attempt is labeled as a failure to find a passage match. 7. Either just the dots in the box corresponding to the intersection of the two passages, or all the dots projecting on the suspicious document in the segment grown initially from the seed are removed from the set -the choice is made by evaluating the chances that the remaining dots would be enough for an equally or more dense passage correspondence. Then the Monte-Carlo loop is resumed, up to 100 times. Ten consecutive failures to find an acceptable match of passages lead to an early stop of the algorithm, such that the speed of the algorithm auto-adjusts to the size of the problem, as measured by the number of passages in correspondence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The results computed on all pairs from the training set (after the submission deadline) are show in Table <ref type="table" coords="4,205.93,464.79,3.74,8.64" target="#tab_1">2</ref>. Each sub-corpus contains 1000 document pairs and could therefore provide a good prediction of the actual performance, as only 50 of them have been used for guiding our tuning.</p><p>We have shown in a previous paper <ref type="bibr" coords="4,292.74,500.84,11.62,8.64" target="#b7">[8]</ref> that the so called "plagdet" scoring formula is flawed in that it evaluates as being better detections that are obviously worse (to humans), by over-penalizing the F-measure with the granularity, where by granularity it is mean roughly in how many parts in average a single source passage is split in the reported detections. Our consequent position is that granularity barely matters, unless it's truly excessive (say, 10 or more) -what matters is the compromise between precision and recall (e.g. evaluated by F-measure). Our granularity is listed for reference, it never exceeded 1.25 -but 2 would have been as good. The previous years solutions fixing the granularity simply joined the detections that were close enough to be part of the same plagiarism instance; we focused on what we have specific and did not implement this common technique not needed in practice, but rather imposed by the way the scoring is done at PAN.</p><p>For getting a sense of how much better this year's version of Encoplot is than the one we had last year, we give in Table <ref type="table" coords="4,268.59,656.44,4.98,8.64" target="#tab_2">3</ref> the results on the same corpus of the old method. As one can see, the changes we have done to the heuristic determine significant increases in the recall performance, with minor decreases in the precision. The only sub-corpus for which the recall has diminished was surprisingly the sub-corpora of non-obfuscated plagiarism instances (more or less verbatim copies). After the analysis and the detection of the unrealistic duplicates problem presented in the next section, we have re-run the system on this sub-corpus and have obtained on it recall=0.97, precision=0.73, and thus F-measure=0.83. The PAN benchmark, whereas objective by design and nicely conducted, fails short sometimes. We discuss here two possible improvements.</p><p>Improving the quality of the corpus: In PAN 2010, there was an issue with the plagiarism instance duplicates: same passage from the source copied multiple times into the suspicious document, up to 17 times. We reproduce here from <ref type="bibr" coords="5,249.05,566.18,11.62,8.64" target="#b7">[8]</ref> the description of the problem. "(...) some of the passages from the source were copied multiple times into the destination suspicious document -a substantial amount: out of 55723 external plagiarism instances, 10694 (&gt; 19%) had the multiplicity at least 2, 3483 multiplicity at least 3. The maximum multiplicity of a single passage was 17 (!).</p><p>This probably explains our suspiciously low recall in the 2010 competition on the non-obfuscated cases (and other subcorpora). As a side effect of the  speed and space optimizations the core encoplot algorithm offers over dotplot, for the simple case when there is no obfuscation at all and just verbatim copying multiple times, only the first copy of a passage is matched. To understand why, remember that each position in the source is paired with at most one position in the suspicious document. Therefore a full match of the source passage fully consumes it, and it cannot match any of the subsequent copies. Having a second copy of the same passage in the source would allow for a second match and so on. To cope with that, we have concatenated each source with itself 4 times before analyzing the pair in detail with our heuristic, creating thus 4 copies in the source of each passage previously there. The number 4 has been chosen as a compromise, balancing the effort and the expected increase in recall."</p><p>Although the PAN 2011 corpus was seemingly free of those problems, they have been reintroduced in 2012, judging on the training corpus, where they made a big difference in the recall achieved by Encoplot on the non-obfuscated plagiarism sub-corpus. For example, for the pair suspicious/source 1746/3773 there are no less than 5 copies of the same 19 kB long passage (about 5 pages of printed text each time). Another example, from the source 3812 to the target 1702 the same passage amounting to about 5-6 printed pages is copied no less than 6 times in different positions, as shown in Figure <ref type="figure" coords="6,473.11,656.44,3.74,8.64" target="#fig_2">2</ref>. This is extremely unrealistic, as no real plagiator will copy multiple times the same text into his/her text; for such long passages, certainly not even twice.</p><p>Improving the scoring function: In 2011, we have shown that "plagdet" is flawed, we quote here from <ref type="bibr" coords="7,213.88,415.09,11.62,8.64" target="#b7">[8]</ref> the description of the issue with the granularity correction in the plagdet score.</p><p>"The granularity has been introduced for plagiarism detection in <ref type="bibr" coords="7,434.93,446.10,15.27,8.64" target="#b9">[10]</ref>. It was meant to correct the standard F-score for excessive splitting of the plagiarized passages retrieved. It is an ad-hoc correction that divides the F-score by log 2 (1 + granularity). It exhibits unwanted behavior in certain cases. For example, let's assume we compare with plagdet two methods, one having recall 33.33%, precision 100% and granularity 1 with another method having both precision and recall 100% and granularity 3. The two methods will obtain the very same plagdet score, 0.5, as a result of applying the granularity correction, although the second method is obviously to be preferred. It has 100% recall and precision, it finds everything and nothing more and even the splitting is very far from excessive. No user will ever prefer a software that fails to find two thirds of the cases to a software that finds them all and even displays each as one block (when colouring text blocks, the adjacent parts will visually join). More thought should be spent in finding a reasonable plagiarism detection score."</p><p>The 2012 PAN retained "plagdet" with its anomalies for evaluating the plagiarism detection systems. Here is our analysis and suggestion on how to improve the scoring.</p><p>We start the analysis by giving another example in Figure <ref type="figure" coords="7,380.54,644.48,3.74,8.64" target="#fig_3">3</ref>, where a detection with recall just 50% obtains a plagdet score of 0.67 (left), whereas a detection with recall 100% obtains a plagdet score of just 0.5 (on the right) -despite having both the same precision, 1. The difference is that the solution preferred by plagdet doesn't detect half of the copied text, while the obviously better one finds it all, just that as three separated parts. On this example the anomaly is clear: for the same precision, the score of one system is lower although its recall rate is much higher, due to the over-compensation for granularity.</p><p>Let us define formally the anomaly. Plagdet has this definition plagdet(p, r, g) = F (p, r)/log 2 (1 + g) = 2 1/p+1/r log2(1+g) (following <ref type="bibr" coords="8,323.49,481.96,14.94,8.64" target="#b9">[10]</ref>), where p=precision, r=recall and g=granularity. Then we call formally a situation anomalous when, for two detections with precision, recall and granularity (p 0 , r 0 , g 0 ) and respectively (p, r, g = 1):</p><formula xml:id="formula_0" coords="8,193.05,527.04,287.55,9.65">p = p 0 ∧ r &lt; r 0 ∧ plagdet(p, r, 1) &gt; plagdet(p 0 , r 0 , g 0 )<label>(1)</label></formula><p>The formula 1 states that despite the detection (p 0 , r 0 , g 0 ) having the same precision and higher recall than (p, r, g = 1), it has a lower plagdet score.</p><p>The first question we want to clarify in this analysis is whether or not the anomalous instances we have exemplified above are isolated cases. To this end, we fix r 0 = 1 and plot in Figure <ref type="figure" coords="8,195.61,596.66,4.98,8.64" target="#fig_4">4</ref> the anomalous zone in the precision-recall space for g 0 = 2. It is obviously more than half of that space! Increasing g 0 only increases the anomalous area -which is equal to the probability of reaching such an anomaly, assuming uniform distribution in the precision-recall space. In Figure <ref type="figure" coords="8,199.93,644.48,4.98,8.64" target="#fig_5">5</ref> the areas/probabilities for the first few values of granularity are given. It is important to note that the idea of penalizing the granularity is not faulty per se. It is just this particular penalization method which leads to those anomalies. What qualities an ideal plagiarism detection quality formula should have? It should favor high precision and recalls (or equivalently high F-measures), penalize the excessive granularity (e.g. 100) and should not lead to those anomalies for low granularity values g 0 . In addition, for everything else being equal, it should still prefer the lower granularity detections to the higher granularity ones. Given these requirements, we propose a generalization of the plagdet formula:</p><formula xml:id="formula_1" coords="9,193.27,450.95,287.32,27.43">plagdet β (p, r, g) = F (p, r)/log 2 (β + g) = 2 1/p+1/r log 2 (β + g)<label>(2)</label></formula><p>The change is minor, the 1 in the correction factor log 2 (1 + g) was replaced by a parameter β; therefore plagdet 1 = plagdet. It is our hope that by avoiding a radical departure from the old plagdet formula we increase the chances the new formula 2 is accepted by the automatic plagiarism detection community. We look now at the impact this new parameter has on the area of anomalies. In Figure <ref type="figure" coords="9,366.31,545.42,4.98,8.64" target="#fig_6">6</ref> one can see the progressive decrease of the probability of anomalies with the increase of β; we find the levels for β = 10 more acceptable and recommend the use of plagdet 10 instead of plagdet = plagdet 1 .</p><p>If one desires to maintain the property of plagdet that it coincides with the Fmeasure for granularity=1, then the normalized version of plagdet β can be used, which retains its desirable properties: As a final check, in Figure <ref type="figure" coords="10,255.53,357.79,4.98,8.64">7</ref> the granularity-depending corrections to the F-measure applied when using plagdet β are displayed, in order to show that for granularity keeps being penalized and even in a very similar fashion.</p><formula xml:id="formula_2" coords="9,226.61,645.03,160.94,23.23">plagdet β (p, r, g) = F (p, r) log 2 (β + 1) log 2 (β + g)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have sent Encoplot again this year to the PAN benchmark, and we have obtained a very good ranking, 2 nd by the F-measure. Beyond the limitations of the PAN benchmark, some of which we have explained in this paper, it remains the main benchmark in the automatic detection of plagiarism. We have also proposed here a modified plagdet β scoring which should present a lower level of anomalies than plagdet. After examining the decrease in the level of anomalies, we have proposed using either plagdet 10 or its normalized version plagdet 10 . Ever since we have won the first PAN challenge in 2009 we have managed to stay within the top few teams every year, which justifies the effort we have put into developing and maintaining Encoplot as one of the state of the art automatic plagiarism detection systems. The system can be commercially licensed -as it is, or customized for various applications -through Fraunhofer FOKUS Berlin, Germany. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,348.44,345.82,8.12;3,134.77,359.75,345.82,7.77;3,134.77,370.71,167.35,7.77"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Plagiarism detection with Encoplot -example with several copied passages, with various degrees of obfuscation (using N=16 N-grams). Each dot is a position where the N-grams in the source and suspicious documents coincide.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,362.93,345.82,8.12;6,134.77,374.24,345.82,7.77;6,134.77,385.19,345.82,7.77;6,134.77,396.15,73.72,7.77"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Unrealistic scenario: in this pair of documents in the 2012 PAN training corpus the same passage has been copied from the source 6 times into the suspicious document, at different locations. The six blue diagonals show the matches. The red curve shows their detection by the Encoplot's heuristic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,134.77,297.72,345.83,8.12;7,134.77,309.03,345.82,7.77;7,134.77,319.98,345.82,7.77;7,134.77,330.94,29.39,7.77;7,152.06,115.83,311.24,167.15"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Left: detection preferred by the plagdet scoring, fails to find half of the copied text (in black). Right: detection preferred by humans, all copied text is found, as three parts (in red, blue and magenta). The text provenience is Wikipedia's definition of "Plagiarism", downloaded in 2011.</figDesc><graphic coords="7,152.06,115.83,311.24,167.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,134.77,338.07,345.82,8.12;8,134.77,349.38,345.82,7.77;8,134.77,360.34,98.61,7.77;8,230.89,131.44,160.82,169.06"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Anomaly area (marked black) in precision-recall space where a detection with granu-larity=1 and that recall&lt;1 is better according to plagdet than a 100% recall solution with equal precision and granularity 2.</figDesc><graphic coords="8,230.89,131.44,160.82,169.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,196.29,303.50,220.54,8.12"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Probability of an anomaly with plagdet, for r0 = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="10,134.77,303.50,345.83,8.41;10,134.77,314.52,345.83,8.06;10,134.77,325.76,30.88,7.77"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Progressive decrease of the anomaly level of plagdet β for r0 = 1 and β = 1..10 (from top to down). The curve for β = 1, which corresponds to the old plagdet is in red, the other ones in black.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="11,134.77,441.83,345.83,8.41;11,134.77,452.85,96.63,8.06"><head>10 Figure 7 .</head><label>107</label><figDesc>Figure 7. Granularity-dependent correction curves employed by plagdet β for β = 1 (bottom, red) to β = 10 (top,black).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,196.07,482.71,220.98,66.08"><head>Table 1 .</head><label>1</label><figDesc>Small Encoplot Example: A=abcabd, B=xabdy, N=2</figDesc><table coords="2,255.60,482.71,101.91,41.05"><row><cell cols="2">Encoplot pairs Dotplot pairs</cell></row><row><cell>1 2 ab</cell><cell>1 2 ab</cell></row><row><cell></cell><cell>4 2 ab</cell></row><row><cell>5 4 bd</cell><cell>5 4 bd</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,174.06,115.83,267.24,73.33"><head>Table 2 .</head><label>2</label><figDesc>Results on the 2012 Training Set With the 2012 Encoplot Version</figDesc><table coords="5,176.55,137.15,260.01,52.01"><row><cell>Corpus</cell><cell cols="4">Recall Precision F-measure Granularity</cell></row><row><cell>No obfuscation</cell><cell>0.87</cell><cell>0.74</cell><cell>0.80</cell><cell>1.02</cell></row><row><cell>Artificial low obfuscation</cell><cell>0.81</cell><cell>0.95</cell><cell>0.87</cell><cell>1.25</cell></row><row><cell>Artificial high obfuscation</cell><cell>0.38</cell><cell>0.96</cell><cell>0.54</cell><cell>1.16</cell></row><row><cell>Simulated paraphrase</cell><cell>0.56</cell><cell>0.85</cell><cell>0.67</cell><cell>1.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,134.77,315.94,317.95,163.98"><head>Table 3 .</head><label>3</label><figDesc>Results on the 2012 Training Set with the 2011 Encoplot Version</figDesc><table coords="5,134.77,337.26,301.80,108.61"><row><cell>Corpus</cell><cell cols="4">Recall Precision F-measure Granularity</cell></row><row><cell>No obfuscation</cell><cell>0.82</cell><cell>0.93</cell><cell>0.87</cell><cell>1.00</cell></row><row><cell>Artificial low obfuscation</cell><cell>0.56</cell><cell>0.99</cell><cell>0.72</cell><cell>1.28</cell></row><row><cell>Artificial high obfuscation</cell><cell>0.10</cell><cell>0.99</cell><cell>0.18</cell><cell>1.12</cell></row><row><cell>Simulated paraphrase</cell><cell>0.33</cell><cell>0.99</cell><cell>0.50</cell><cell>1.06</cell></row><row><cell>4 Discussion</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="5,134.77,459.01,317.95,8.96;5,157.18,470.96,86.61,8.96"><p>4.1 What can be done to improve the realism of the PAN benchmarks in plagiarism detection</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.61,624.22,333.00,7.77;10,150.95,635.18,183.26,7.77" xml:id="b0">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="10,312.45,624.22,121.32,7.77">CLEF 2010 LABs and Workshops</title>
		<title level="s" coord="10,440.25,624.22,35.36,7.77;10,150.95,635.18,22.30,7.77">Notebook Papers</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">September 2010. 2010</date>
			<biblScope unit="page" from="22" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,646.13,333.87,7.77;10,150.95,657.08,88.65,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,192.81,646.13,206.44,7.77">Old and new challenges in automatic plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>National Plagiarism Advisory Service</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,485.55,304.97,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,237.49,485.55,78.58,7.77">A tale of two citations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,321.58,485.55,24.40,7.77">Nature</title>
		<imprint>
			<biblScope unit="volume">451</biblScope>
			<biblScope unit="issue">7177</biblScope>
			<biblScope unit="page" from="397" to="399" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,493.95,327.50,9.78;11,150.95,506.92,279.19,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,423.77,493.95,46.34,9.78;11,150.95,506.92,135.58,7.77">Déjà vuâ ȂŤ a study of duplicate citations in medline</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Errami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trusty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Garner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,292.67,506.92,53.80,7.77">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="249" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,517.34,324.91,7.77;11,150.95,528.30,299.42,7.77;11,150.95,539.25,304.66,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,277.96,517.34,189.57,7.77;11,150.95,528.30,135.20,7.77">ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,304.31,528.30,146.07,7.77;11,150.95,539.25,51.52,7.77">UNCOVERING PLAGIARISM</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>3rd PAN WORKSHOP</note>
</biblStruct>

<biblStruct coords="11,142.61,549.67,320.13,7.77;11,150.95,560.63,145.55,7.77;11,150.95,571.59,232.12,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="11,243.34,549.67,219.40,7.77;11,150.95,560.63,141.74,7.77">The Encoplot Similarity Measure for Automatic Detection of Plagiarism -Extended Technical Report</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
		<ptr target="http://brainsignals.de/encsimTR.pdf" />
		<imprint>
			<date type="published" when="2011-08">Aug 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,582.00,326.10,7.77;11,150.95,592.96,292.28,7.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="11,243.34,582.00,225.37,7.77;11,150.95,592.96,186.45,7.77">Encoplot -Performance in the Second International Plagiarism Detection Challenge -Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,603.38,311.65,7.77;11,150.95,614.34,222.12,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,243.34,603.38,210.93,7.77;11,150.95,614.34,149.36,7.77">The encoplot similarity measure for automatic detection of plagiarism -notebook for pan at clef 2011</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
		<editor>Petras et al.</editor>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,624.75,314.05,7.77;11,150.95,635.71,246.40,7.77" xml:id="b8">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="11,300.98,624.75,113.76,7.77">CLEF 2011 Labs and Workshop</title>
		<title level="s" coord="11,421.30,624.75,35.36,7.77;11,150.95,635.71,22.30,7.77">Notebook Papers</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09-22">19-22 September 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,646.13,306.81,7.77;11,150.95,657.08,277.90,7.77;12,150.95,119.96,294.90,7.77;12,150.95,130.92,66.00,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,344.98,646.13,104.06,7.77;11,150.95,657.08,71.70,7.77">An evaluation framework for plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,240.61,657.08,188.25,7.77;12,150.95,119.96,124.76,7.77">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="997" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,141.88,314.45,7.77;12,150.95,152.84,265.23,7.77" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,383.09,141.88,73.60,7.77;12,150.95,152.84,180.34,7.77">Overview of the 2nd International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,163.80,312.95,7.77;12,150.95,174.76,247.79,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="12,383.09,163.80,72.10,7.77;12,150.95,174.76,175.56,7.77">Overview of the 3rd international competition on plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<editor>Petras et al.</editor>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,185.71,330.62,7.77;12,150.95,196.67,327.90,7.77;12,150.95,207.63,324.84,7.77;12,150.95,218.59,128.34,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,172.89,196.67,248.41,7.77">Overview of the 1st international competition on plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Universitãd't Weimar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrãşn-Cedeãśo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">: P</forename><surname>Rosso</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,451.45,196.67,27.40,7.77;12,150.95,207.63,324.84,7.77;12,150.95,218.59,10.65,7.77">SEPLN 2009 Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse (PAN 09)</title>
		<title level="s" coord="12,167.39,218.59,18.87,7.77">CEUR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,229.55,268.34,7.77" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="12,215.61,229.55,194.97,7.77">Viewpoint: The spectre of plagiarism haunting Europe</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weber-Wulff</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
