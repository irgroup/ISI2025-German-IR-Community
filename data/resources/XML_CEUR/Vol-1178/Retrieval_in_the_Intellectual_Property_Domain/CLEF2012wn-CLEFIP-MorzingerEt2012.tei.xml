<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,216.94,116.95,181.48,12.62;1,192.22,134.89,230.92,12.62">Visual Structure Analysis of Flow Charts in Patent Images</title>
				<funder ref="#_uDsE68M">
					<orgName type="full">Austrian Research Promotion Agency (FFG)</orgName>
				</funder>
				<funder ref="#_GHXWxaa">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.79,172.73,76.59,8.74"><forename type="first">Roland</forename><surname>Mörzinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">JOANNEUM RESEARCH Forschungsgesellschaft mbH DIGITAL -Institute for Information and Communication Technologies</orgName>
								<address>
									<addrLine>Steyrergasse 17</addrLine>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.40,172.73,60.04,8.74"><forename type="first">René</forename><surname>Schuster</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">JOANNEUM RESEARCH Forschungsgesellschaft mbH DIGITAL -Institute for Information and Communication Technologies</orgName>
								<address>
									<addrLine>Steyrergasse 17</addrLine>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.14,172.73,56.14,8.74"><forename type="first">András</forename><surname>Horti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">JOANNEUM RESEARCH Forschungsgesellschaft mbH DIGITAL -Institute for Information and Communication Technologies</orgName>
								<address>
									<addrLine>Steyrergasse 17</addrLine>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,388.27,172.73,74.30,8.74"><forename type="first">Georg</forename><surname>Thallinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">JOANNEUM RESEARCH Forschungsgesellschaft mbH DIGITAL -Institute for Information and Communication Technologies</orgName>
								<address>
									<addrLine>Steyrergasse 17</addrLine>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,216.94,116.95,181.48,12.62;1,192.22,134.89,230.92,12.62">Visual Structure Analysis of Flow Charts in Patent Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FE9076940423F3D285B038A2E7345014</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>patent</term>
					<term>flow charts</term>
					<term>images</term>
					<term>technical drawings</term>
					<term>structure analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report presents the work carried out for the flow chart recognition task in the course of the CLEF-IP 2012 competition. The goal is to obtain structural information of flow charts based on the visual content of the images. To this end, for each flow chart a list of its nodes and their interconnections, i.e. its edges, is extracted and the type of the nodes and edges and attached text is recognized. The automatic recognition task is done in three stages: (1) flow chart image pre-processing using connected component analysis, morphological filters and line segmentation, (2) identification of nodes, junction points, end points and edges and (3) recognition of text, geometric node types and edge directions. Examples demonstrate good recognition results obtained for 100 tested flow chart images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In traditional engineering drawings and diagrams, algorithms, operations and processes are frequently represented as flow charts. In patents, these drawings generally are accessible only in image format. For automatic querying the huge information content of the flow charts available in patents, it is important to convert the information in the images into a high-level description <ref type="bibr" coords="1,419.46,540.51,9.96,8.74" target="#b4">[5]</ref>. This problem usually involves techniques in the field of image binarization, segmentation, shape extraction and recognition of text and geometric components <ref type="bibr" coords="1,432.73,564.42,9.96,8.74" target="#b3">[4]</ref>.</p><p>This paper describes our approach for automatically analyzing the visual structure of flow charts and our participation in the flow chart recognition task <ref type="bibr" coords="1,470.07,588.51,10.52,8.74" target="#b0">[1]</ref> in the course of the CLEF-IP 2012 competition.</p><p>At this, it is assumed that a flowchart can be interpreted as a graph with a set of nodes and edges <ref type="bibr" coords="1,221.16,624.54,9.96,8.74" target="#b2">[3]</ref>. To semantically process the data therein, the extracted information should contain:</p><p>1. the number of nodes, 2. the type of each node (e.g. rectangle, diamond, oval, etc), 3. the text annotations (if any) within each node for creating the link between the image and the patent text, 4. the interconnections, i.e. edges, between the nodes and 5. the type of the edges (e.g. continuous, dotted, etc.).</p><p>The rest of this paper is organized as follows: Section 2 describes the applied image processing methods for producing the above mentioned metadata and results are presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Visual Structure Analysis</head><p>A summary of the flow chart recognition process is shown in Figure <ref type="figure" coords="2,440.68,256.75,3.87,8.74">2</ref>, understandably a flow chart itself. First, textual descriptions in the input image are extracted using optical character recognition, followed by pre-processing, line segmentation and grouping. Next, junctions and end points are detected and based on that, nodes and their interconnections (edges) are recognized. Finally, the type of the nodes and the direction of the edges is computed and the visual information content from the flow chart is provided in a textual graph representation (for the format see <ref type="bibr" coords="2,248.90,340.44,10.30,8.74" target="#b0">[1]</ref>).</p><p>The quality of Figure <ref type="figure" coords="2,251.21,352.40,4.98,8.74">2</ref> was deliberately modified in a way to match the look&amp;feel and (sometimes bad) image quality of many technical drawings found in patents. When viewed in full detail, lines are frequently frayed, non-contiguous and not strictly vertical or horizontal, which clearly presents challenges for image processing. The following subsections explain the processing steps of our approach necessary for recognizing the visual structure of flow charts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text, Label and Reference Detection</head><p>A commercial optical character recognition (OCR) software <ref type="bibr" coords="3,393.68,506.41,10.52,8.74" target="#b1">[2]</ref> is used to extract text from the flow chart images. String matching using a regular expression is performed for identifying possible references, like "Fig.</p><p>x ". The locations (image coordinates) of the extracted text blocks are kept for subsequent association with detected nodes and edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">From Binary Image to Line Segments</head><p>First, in the binary input image all connected components with a small number of pixels and aspect ratio typical to characters (as opposed to lines) are removed. Second, the image that is now cleaned from text-like fragments is subjected to a morphological close and binary image thinning operation, see Figure <ref type="figure" coords="3,459.56,645.16,16.83,8.74">1(b)</ref>. Third, edge points are identified and linked to segments. By respecting a specified minimum line length and maximum deviation from the original data, the pixel image can now represented as a list of linked line segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Detection of Junctions, End Points, Nodes and Connecting Edges</head><p>Junctions and end points can be easily found by scanning the linked line segments from the previous step for areas where three or more segments meet (junction) or where a segment has no further connection (end point). In many cases, end points are actually the end of wiggly edges that connect the nodes of the flowchart with their labels.</p><p>Next, the nodes of a flow chart are detected by iteratively finding for each segment another linking segment that is close enough (allowing for nodes with small gaps between segments) and that has the smallest angle between them. A combination of linked segments that meets certain criteria, such as a maximum number of segments per node and sum of angle values, constitutes a node.</p><p>Subsequently, connecting edges are derived from the remaining segments that that link nodes, junctions or end points. These edges may obviously consist of multiple segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Recognition of Node Type and Edge Direction</head><p>The goal is to classify 10 types of nodes (oval, rectangle, double-rectangle, parallelogram, diamond, circle, point, cylinder, no-box and unknown). Their exact definition is given in the task description document <ref type="bibr" coords="4,356.40,410.51,9.96,8.74" target="#b0">[1]</ref>. The node types "no-box" and "point" are a direct result of the methods described in Section 2.3. For the classification of the remaining node types, the input is a sequence of segments with start and end point coordinates. Based on those segments, the following features are calculated:</p><p>-Number of edges -Ratio between maximum and median edge length -Ratio between minimum and median edge length -Ratio between maximum and minimum angle -Median of the angles -Sum of the angles -TopPositionRatio: normalized ratio between top most and second top most point -Normalized ratio between right most and second right most point -Extent: ratio between the area of the bounding box and the convex hull By using 400 annotated examples, discriminating features and their statistics have been empirically determined for each type. The statistics consist of average, standard deviation, minimum and maximum values for each feature and node type. Figure <ref type="figure" coords="4,190.58,645.16,4.98,8.74" target="#fig_1">3</ref> plots 3 features over 3 node types. The characteristics of the data show that it is possible to classify the node types. With help of these statistics a score for each class is calculated and the maximum score results in the classified node type. If the maximum score is below 50% the node type is declared as "unknown". An unknown node type is an indication of a possibly inaccurate preceding node detection result and as a consequence the node can be discarded (c.f. runs with node type filter in Section 3). The edge direction is estimated by comparing the number of black pixels of the edge segments. A window is centered at the end of the edges and the edge is directed if one the windows has clearly more pixels than the other. The related thresholds have been determined using annotations (c.f. Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Evaluation</head><p>For the flow chart recognition task of the CLEF-IP 2012 competition <ref type="bibr" coords="5,452.83,428.60,9.96,8.74" target="#b0">[1]</ref>, 50 images containing flowcharts and the corresponding annotations were provided. The images were used for developing the recognition system and the annotations, i.e. the number and type of the nodes and edges, were used to tune data-specific parameter values.</p><p>For evaluating our approach and different configurations thereof, we produced a set of runs described in Table <ref type="table" coords="5,275.30,502.06,3.87,8.74" target="#tab_0">1</ref>. All of the different configurations of our flow chart recognition system were applied on a test set of 100 images. Details on the evaluation and the applied most common subgraph metric can be found in the task description document <ref type="bibr" coords="6,452.97,143.90,9.96,8.74" target="#b0">[1]</ref>. At the time of writing this paper, quantitative evaluation results for the flow chart recognition track in CLEF-IP 2012 were not available yet.</p><formula xml:id="formula_0" coords="5,155.14,536.55,10.37,7.86">ID</formula><p>Nevertheless, the examples shown in Figure <ref type="figure" coords="6,337.95,179.77,4.98,8.74" target="#fig_2">4</ref> and 5 should give an impression of the quality of the flow chart recognition system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>This paper presented the experiments for our participation in the CLEF-IP 2012 flow chart recognition challenge <ref type="bibr" coords="6,276.86,537.56,9.96,8.74" target="#b0">[1]</ref>. Structural information of flow charts, such as nodes, their interconnections and annotating labels were obtained based on image processing technology using the visual image content only. Although the nodes and interconnections of flow charts seem to be easily recognizable by humans, automatic processing is quite a challenge. On the pixel level, the black lines are frequently non-contiguous, frayed, of varying width and not strictly vertical or horizontal. Flow chart images show different types of nodes (circles, boxes, parallelograms, etc), edges (directed, undirected), typewritten and sometimes handwritten labels. When text is not clearly separated from nodes or lines, difficulties increase. Generally, finding proper values for critical thresholds, such as the minimum length of segments and parameters for morphological filtering, is one of the most crucial parts. For that purpose, the provided annotations have proved very useful. Examples demonstrate good recognition results obtained for 100 tested flow chart images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,590.44,345.83,7.89;2,134.77,601.42,345.83,7.86;2,134.77,612.38,345.82,7.86;2,134.77,623.34,345.83,7.86;2,134.77,634.30,259.65,7.86;2,137.55,442.17,123.03,119.05"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Example showing details of different processing steps. The black and white input image (a) is pre-processed and based on the resulting cleaned and thinned image (b) the final visual structure (c) is recognized. It shows nodes (solid colored border), edges (dashed line), junction points (red filled circle), end points (green filled circle) and the nodes' IDs (numbers in red boxes). Best viewed in color</figDesc><graphic coords="2,137.55,442.17,123.03,119.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,159.83,282.97,295.70,7.89;5,134.77,203.24,345.83,64.96"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Three features over 106 examples with three different node types.</figDesc><graphic coords="5,134.77,203.24,345.83,64.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,393.94,345.83,7.89;6,134.77,404.92,345.83,7.86;6,134.77,415.88,345.83,7.86;6,134.77,426.84,345.82,7.86;6,134.77,437.80,345.83,7.86;6,134.77,448.76,151.99,7.86;6,138.05,223.00,79.67,141.72"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Two examples with parts of the flow chart recognition results. For the input (a, c) flow charts, the output (b, d) of the detection methods for nodes (solid colored border), edges (dashed line), junction points (red filled circle) and end points (green filled circle) is shown. The numbers in red boxes are IDs of detected nodes. The type of the nodes, the direction of the edges and any attached text is also recognized, but not presented in these output images.</figDesc><graphic coords="6,138.05,223.00,79.67,141.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,134.77,453.67,345.83,7.89;7,134.77,464.66,345.82,7.86;7,134.77,475.62,345.83,7.86;7,134.77,486.58,166.53,7.86;7,181.58,282.74,124.78,141.72"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Two exemplary results of flow chart recognition on challenging data. The dashed lines in the lower part of the input flow chart (a) and the variety of directional arrows (a, c) lead to an inaccurate segmentation of lines and edges (b, d). See Figure 4 for detailed explanation of the result images.</figDesc><graphic coords="7,181.58,282.74,124.78,141.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,160.22,116.84,294.92,317.48"><head></head><label></label><figDesc></figDesc><graphic coords="3,160.22,116.84,294.92,317.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,536.55,345.83,117.40"><head>Table 1 .</head><label>1</label><figDesc>Different runs submitted for the flow chart recognition challenge. Details on the mentioned filter and detection methods are given in the Section 2.</figDesc><table coords="5,158.02,536.55,302.20,95.93"><row><cell>RUN</cell><cell>Description</cell></row><row><cell>1 joanneum flow tomato</cell><cell>default settings with node type filter [default]</cell></row><row><cell>2 joanneum flow zuchini</cell><cell>tomato without node type filter</cell></row><row><cell>3 joanneum flow carrot</cell><cell>tomato with adapted edge direction detection</cell></row><row><cell cols="2">4 joanneum flow romanesco tomato with adapted junction detection</cell></row><row><cell>5 joanneum flow basil</cell><cell>tomato with adapted end point detection</cell></row><row><cell>6 joanneum flow radish</cell><cell>tomato with adapted node detection</cell></row><row><cell>7 joanneum flow pepper</cell><cell>tomato with adapted line segmentation 1</cell></row><row><cell>8 joanneum flow rucola</cell><cell>tomato with adapted line segmentation 2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,144.73,658.44,145.93,7.47"><p>http://www.joanneum.at/?id=3922</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">Austrian Research Promotion Agency (FFG)</rs> <rs type="projectName">FIT-IT</rs> project <rs type="projectName">IMPEx 1 Image Mining for Patent EXploration</rs> (No. <rs type="grantNumber">825846</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_uDsE68M">
					<orgName type="project" subtype="full">FIT-IT</orgName>
				</org>
				<org type="funded-project" xml:id="_GHXWxaa">
					<idno type="grant-number">825846</idno>
					<orgName type="project" subtype="full">IMPEx 1 Image Mining for Patent EXploration</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,143.58,342.24,8.11;8,146.91,154.54,270.56,9.85" xml:id="b0">
	<monogr>
		<ptr target="http://www.ifs.tuwien.ac.at/~clef-ip/flowcharts.shtml" />
		<title level="m" coord="8,146.91,143.58,150.82,7.86">CLEF-IP flow chart recognition task</title>
		<imprint>
			<date type="published" when="2012-08">2012. Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,164.51,342.25,8.12;8,146.91,175.46,43.26,7.86" xml:id="b1">
	<monogr>
		<ptr target="http://www.transym.com/" />
		<title level="m" coord="8,146.91,164.51,87.76,7.86">Transym OCR engine</title>
		<imprint>
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,185.43,342.24,7.86;8,146.91,196.39,333.68,7.86;8,146.91,207.35,20.99,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,453.84,185.43,26.75,7.86;8,146.91,196.39,198.38,7.86">Patent images -a glass encased tool / opening the case</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mörzinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schleser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,367.50,196.39,108.82,7.86">Proc. of iKnow Conference</title>
		<meeting>of iKnow Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,217.31,342.24,7.86;8,146.91,228.27,298.01,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,395.61,217.31,84.98,7.86;8,146.91,228.27,123.13,7.86">Flowchart knowledge extraction on image processing</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dhanapanichkul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,289.64,228.27,26.01,7.86">IJCNN</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="4075" to="4082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,238.23,342.24,7.86;8,146.91,249.19,231.34,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,276.96,238.23,203.63,7.86;8,146.91,249.19,33.96,7.86">A system for recognizing a large class of engineering drawings</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Samal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Seth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,189.21,249.19,161.59,7.86">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
