<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,207.75,116.95,199.87,12.62;1,142.32,134.89,330.71,12.62">Chemnitz at CLEF IP 2012: Advancing Xtrieval or a baseline hard to crack</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.52,172.56,72.87,8.74"><forename type="first">Thomas</forename><surname>Wilhelm</surname></persName>
							<email>thomas.wilhelm@cs.tu-chemnitz.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<addrLine>Straße der Nationen 62</addrLine>
									<postCode>09111</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.66,172.56,55.33,8.74"><forename type="first">Jens</forename><surname>Kürsten</surname></persName>
							<email>jens.kuersten@cs.tu-chemnitz.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<addrLine>Straße der Nationen 62</addrLine>
									<postCode>09111</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.41,172.56,70.43,8.74"><forename type="first">Maximilian</forename><surname>Eibl</surname></persName>
							<email>maximilian.eibl@cs.tu-chemnitz.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<addrLine>Straße der Nationen 62</addrLine>
									<postCode>09111</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,207.75,116.95,199.87,12.62;1,142.32,134.89,330.71,12.62">Chemnitz at CLEF IP 2012: Advancing Xtrieval or a baseline hard to crack</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">528DC4C641AA8EE0BAD16C868B906DA4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For the 2012 CLEF-IP Claims to passage task we reused and improved our Xtrieval framework. Our two-step approach comprises creating two Lucene indexes: one containing the whole patent application documents and one containing the same documents split into passages. We prepared three setups and conducted each with a translated and an untranslated topic set, which was just applied to the claims. The submitted setups differ in the way of retrieving the results and merging them. No further techniques were used. Therefore our experiments had very simple setups, which nevertheless achieved good results. There are still plenty of possible improvements, which can easily be tested with our framework, because it offers a comprehensive set of methods for conducting and evaluating retrieval experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year we participated in CLEF-IP: Information Retrieval in the Intellectual Property Domain specifically in the Claims to passage task. In this task the topics consist of claims from patent application documents. The goal was to match passages within patent documents from the data collection to these claims.</p><p>The 2012 CLEF-IP data collection was the same as 2011 <ref type="bibr" coords="1,390.01,474.17,12.45,8.74">[1]</ref>, which was based on the MAREC collection<ref type="foot" coords="1,247.04,484.55,3.97,6.12" target="#foot_0">1</ref> provided by the IRF<ref type="foot" coords="1,343.03,484.55,3.97,6.12" target="#foot_1">2</ref> . It contains approximately 3.5 million well-formatted XML documents representing about 1.5 million patents.</p><p>As in our participation in the CLEF IP 2011 Prior Art task <ref type="bibr" coords="1,409.54,510.03,11.75,8.74" target="#b1">[2]</ref>, we used our Xtrieval framework <ref type="bibr" coords="1,213.66,521.99,13.62,8.74" target="#b2">[3]</ref>, which besides providing a common interface for different search engines<ref type="foot" coords="1,197.14,532.37,3.97,6.12" target="#foot_2">3</ref> also offers a comprehensive set of methods for conducting and evaluating retrieval experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Setup</head><p>In the course of our participation we re-engineered the Xtrieval framework. We further consolidated it and enhanced it for more speed. The speed improvements were necessary because of the size of the data collection (26 gigabytes compressed, 107 gigabytes uncompressed) and the necessity of executing several iteration of the experiments.</p><p>Our experiments last year showed that longer queries outperform shorter ones <ref type="bibr" coords="2,150.84,156.70,12.06,8.74" target="#b1">[2]</ref>. Another point in our thinking was that the passages alone are not sufficient and their context is probably important too. Taking this into account we opted for a two-step approach. For our participation in the ASR transcript task of MediaEval <ref type="bibr" coords="2,188.54,192.56,14.15,8.74" target="#b3">[4]</ref> we used a similar approach to first identify relevant transcripts and in a second step locate the exact time frame, which contained the relevant information.</p><p>We adapted this approach to the claims to passage scenario by creating two indexes: one containing the whole patent application documents and one containing the same documents split into passages.</p><p>For the passage index the following XPaths were use:</p><p>/patent-document/description/p /patent-document/description/heading /patent-document/claims/claim /patent-document/abstract/p</p><p>For the document index the XPaths used were:</p><formula xml:id="formula_0" coords="2,134.77,371.59,345.20,44.16">/patent-document/abstract/p /patent-document/description/* /patent-document/claims/claim /patent-document/bibliographic-data/technical-data/invention-title</formula><p>The Xtrieval framework has a very flexible and fast implementation for reading XML data collections based on the Jaxen library <ref type="foot" coords="2,370.51,439.57,3.97,6.12" target="#foot_3">4</ref> . It exclusively relies on XPath for selecting the content and determining the destination fields in the index.</p><p>For the retrieval phase we prepared three different setups and conducted each with a translated and an untranslated topic set. We did not translate the whole patent but just the claims referenced in the topics. For the translation we used Google's Translator Toolkit <ref type="foot" coords="2,279.89,512.14,3.97,6.12" target="#foot_4">5</ref> and translated all claims to the three most used languages of the data collection: English, German, and French. While other languages occur in the corpus, these three languages provide the vast majority of content according to an intermediate index we created.</p><p>All three setups share the following pre-processing steps:</p><p>1. instead of relying on the given language attributes we used a language detection <ref type="foot" coords="2,181.59,598.89,3.97,6.12" target="#foot_5">6</ref> to eliminate content tagged wrong 2. bag of words We used the standard tokenizer of Lucene, which splits a text stream into tokens and recognizes some entities like URLs and e-mail addresses. Then we applied our own filters (marked with *) and some from the Lucene package. If the filter depends on the token language this was considered for the following languages: English, German, French, Russian, Italian, and Spanish.</p><p>1. LowerCaseFilter -converts the token to lower case 2. RemoveShortWordsFilter * -removes words shorter than 3 characters 3. StopFilter -removes stop words depending on the language 4. RemoveNumbersFilter * -removes different kinds of numbers 5. SnowballFilter<ref type="foot" coords="3,214.65,248.27,3.97,6.12" target="#foot_6">7</ref> -stems the token according to its language</p><p>The following setups differ just in the way of retrieving the results and merging them. No further techniques were used. That is to say: no fields (bag of words) or field weights, no relevance feedback, no language model, and no further query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Passages only (p)</head><p>This setup should be considered as our baseline, because we only used the claims specified in the topics and searched them in the passage index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Documents combined with Passages (dp)</head><p>In this setup the query is constructed by merging the patent documents and the extracted claims. The content of the patent documents got a lesser weight than the claims to focus more on the claims. The queries were issued just on the passage index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Documents before Passages (d2-p)</head><p>Our most sophisticated setup was the two-step approach, which was mentioned earlier. In the first step we retrieved a set of potentially relevant patent documents. For the second step their identifiers were used to amend the query to the passage index. The identifiers in the passage query are just optional to not exclude passages, which are still relevant but are not included in the first step. Some experiments with the provided test set showed beforehand, that limiting the second step to the results obtained in the first one will achieve a significant lower score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Table <ref type="table" coords="4,161.68,144.90,4.98,8.74" target="#tab_0">1</ref> shows the achieved results. Our best run, except for precision at passage level, is 'Documents before Passages' without any translation (tuc-d2-p). The second best run is 'Passages only', which is also the best at precision at passage level.</p><p>Both 'Documents combined with Passages' runs (tuc-dp and tuc-dpmt) gained equal results in the evaluation (see table <ref type="table" coords="4,311.84,204.88,3.87,8.74" target="#tab_0">1</ref>). The source of this lies in the almost equal result set, which both runs produced. But as they slightly differ from each other, we can eliminate an error in our submission. We think it shows that on the one hand the passages had a small impact on the result set and on the other hand that the result set did not benefit as much as hoped from the translation.</p><p>Generally, the machine translation did not lead to better results. It even changed the results for the worse. This is likely owing to the universal translation service, which we used. A translation tailored for patents could perform better. Our focus this year was especially on improving and testing the framework. Therefore our experiments had very simple setups, which nevertheless achieved good results. The passages-only run without translation should be rated as our baseline and all other runs compared with it. This comparison shows that the only run outperforming our baseline, except for the precision at passage level, is our two-step approach without any translation (tuc-d2-p). All other runs achieved lower scores, which show they are not suited to improve the retrieval. Because of the improved speed for the index and retrieval process in our framework, we could iterate more and experiment with different weights for the different combinations of documents and passages.</p><p>There are still plenty of possible improvements, which can easily be tested with our framework: pre-tokenization filters, token filters, retrieval systems (i.e. Lucene and Terrier), query expansion, and query reformulation. As the framework supports the calculation of different measures (i.e. PRES@n, MAP, and so on) one can compare the results with previous experiments. This could more easily be done with tools like EvaluatIR <ref type="bibr" coords="5,307.00,131.95,13.77,8.74" target="#b4">[5]</ref> or Compeval <ref type="bibr" coords="5,374.28,131.95,14.11,8.74" target="#b5">[6]</ref>. Also an integration of these tools could be beneficial.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,321.15,305.42,164.36"><head>Table 1 .</head><label>1</label><figDesc>Results (sorted by MAP at Document level)</figDesc><table coords="4,134.77,342.45,305.42,143.06"><row><cell></cell><cell cols="2">Document level</cell><cell cols="2">Passage level</cell></row><row><cell cols="5">Run name PRES@100 Recall@100 MAP MAP(D) Precision(D)</cell></row><row><cell>tuc-d2-p</cell><cell>0.1599</cell><cell cols="2">0.2094 0.0663 0.0385</cell><cell>0.0490</cell></row><row><cell>tuc-p</cell><cell>0.1430</cell><cell cols="2">0.1941 0.0501 0.0314</cell><cell>0.0522</cell></row><row><cell>tuc-dp</cell><cell>0.1363</cell><cell cols="2">0.1854 0.0424 0.0254</cell><cell>0.0383</cell></row><row><cell>tuc-dpmt</cell><cell>0.1363</cell><cell cols="2">0.1854 0.0424 0.0254</cell><cell>0.0383</cell></row><row><cell>tuc-d2-pmt</cell><cell>0.1218</cell><cell cols="2">0.1599 0.0614 0.0257</cell><cell>0.0297</cell></row><row><cell>tuc-pmt</cell><cell>0.0926</cell><cell cols="2">0.1428 0.0246 0.0167</cell><cell>0.0323</cell></row><row><cell cols="3">4 Summary and future work</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,635.88,262.80,8.12"><p>MAREC IRF, http://www.ir-facility.org/prototypes/marec</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,646.84,252.30,8.12"><p>Information Retrieval Facility, http://www.ir-facility.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="1,144.73,657.79,335.86,7.86"><p>Apache Lucene (http://lucene.apache.org/) and Terrier (http://terrier.org/)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,144.73,635.88,265.47,8.12"><p>jaxen: universal Java XPath engine, http://jaxen.codehaus.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,144.73,646.84,279.95,8.12"><p>Google Translator Toolkit, http://translate.google.com/toolkit/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,144.73,658.44,207.62,7.47"><p>http://code.google.com/p/language-detection/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="3,144.73,657.79,178.24,8.12"><p>Snowball, http://snowball.tartarus.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,199.38,342.24,7.86;5,146.91,210.33,77.26,7.86" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Zenz</surname></persName>
		</author>
		<title level="m" coord="5,319.69,199.38,160.90,7.86;5,146.91,210.33,65.32,7.86">Clef-ip 2011: Retrieval in the intellectual property domain</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,221.29,342.24,7.86;5,146.91,232.25,251.33,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,460.96,221.29,19.63,7.86;5,146.91,232.25,233.30,7.86">Does patent ir profit from linguistics or maximum query length</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Becks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eibl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jürgens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kürsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,243.21,342.24,7.86;5,146.91,254.17,333.68,7.86;5,146.91,265.13,333.68,7.86;5,146.91,276.09,13.82,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,253.98,243.21,222.74,7.86">Extensible retrieval and evaluation framework: Xtrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kürsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilhelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,313.57,254.17,22.66,7.86">LWA</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Baumeister</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Atzmüller</surname></persName>
		</editor>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">448</biblScope>
			<biblScope unit="page" from="107" to="110" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Würzburg</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="5,138.35,287.05,342.24,7.86;5,146.91,298.01,333.68,7.86;5,146.91,308.96,333.68,7.86;5,146.91,319.92,228.11,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,359.43,287.05,121.16,7.86;5,146.91,298.01,141.48,7.86">A two-step approach to video retrieval based on asr transcriptions</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Korner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Heinich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilhelm</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,385.35,308.96,40.66,7.86">MediaEval</title>
		<title level="s" coord="5,157.41,319.92,118.03,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Larson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rae</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Demarty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Kofler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Metze</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Troncy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Mezaris</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">807</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,330.88,342.24,7.86;5,146.91,341.84,333.68,7.86;5,146.91,352.80,199.01,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,366.90,330.88,113.69,7.86;5,146.91,341.84,150.28,7.86">Evaluatir: an online tool for evaluating and comparing ir systems</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,247.19,352.80,23.62,7.86">SIGIR</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">833</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,363.76,342.24,7.86;5,146.91,374.72,333.67,7.86;5,146.91,385.68,147.43,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,296.21,363.76,184.38,7.86;5,146.91,374.72,47.82,7.86">A tool for comparative ir evaluation on component level</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kürsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eibl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,167.96,385.68,23.62,7.86">SIGIR</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1291" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,396.64,342.25,7.86;5,146.91,407.59,333.68,7.86;5,146.91,418.55,296.42,7.86" xml:id="b6">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="5,311.18,396.64,123.63,7.86;5,239.25,418.55,170.77,7.86">CLEF (Notebook Papers/Labs/Workshop)</title>
		<title level="s" coord="5,441.68,396.64,38.91,7.86;5,146.91,407.59,25.63,7.86">Notebook Papers</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">September 2011. 2011</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
	<note>CLEF 2011 Labs and Workshop</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
