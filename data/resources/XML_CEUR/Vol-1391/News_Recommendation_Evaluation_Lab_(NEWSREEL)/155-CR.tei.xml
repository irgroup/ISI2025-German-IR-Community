<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,177.05,115.96,261.27,12.62;1,185.67,133.89,244.01,12.62">The Degree of Randomness in a Live Recommender Systems Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,195.52,171.68,126.92,8.74"><forename type="first">Gebrekirstos</forename><forename type="middle">G</forename><surname>Gebremeskel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Access</orgName>
								<orgName type="institution">CWI</orgName>
								<address>
									<addrLine>Science Park 123</addrLine>
									<postCode>1098 XG</postCode>
									<settlement>Amsterdam, Amsterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.14,171.68,74.69,8.74"><forename type="first">Arjen</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Access</orgName>
								<orgName type="institution">CWI</orgName>
								<address>
									<addrLine>Science Park 123</addrLine>
									<postCode>1098 XG</postCode>
									<settlement>Amsterdam, Amsterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,177.05,115.96,261.27,12.62;1,185.67,133.89,244.01,12.62">The Degree of Randomness in a Live Recommender Systems Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">43756B703C2D7428FC524EDC8A1A3EEC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This report describes our participation in the CLEF NEWS-REEL News Recommendation Evaluation Lab. We report and analyze experiments conducted to study two goals. One goal is to study the effect of randomness in the evaluation of algorithms. The second goal is to see whether geographic information can help in improving the performance of news recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Tasks and Objectives</head><p>In this report we describe the results of experiments we conducted during our participation in the CLEF NEWSREEL News Recommendations Evaluation Lab, the task of Benchmark News Recommendations in a Living Lab <ref type="bibr" coords="1,446.24,404.81,9.96,8.74" target="#b4">[5]</ref>. The experiments have the following goals. The first goal is to investigate the effect of system and/or user behavior randomness on recommender systems evaluations. This randomness refers to the selection of algorithms for providing recommendation request by the Plista framework and the user click behavior which can be influenced by the situation of the user. The second is to study whether geographic information can play a role in news recommendation systems.</p><p>The literature on recommender systems shows that offline and online recommender system evaluations do not concur with each other <ref type="bibr" coords="1,387.42,500.58,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,399.60,500.58,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="1,409.02,500.58,7.01,8.74" target="#b5">6]</ref>. This is to say that recommender systems behave differently in offline and online evaluations, both in terms of absolute and relative performance. This has a serious implication for recommender system research, because the whole point of offline evaluation is the assumption that at least the relative performance of recommender systems is indicative of their relative online performance and thus an important step for selecting algorithms that can be deployed in a live recommendation setting.</p><p>Many reasons can be mentioned for the disparate performances of offline and online evaluations. The three most important papers <ref type="bibr" coords="1,362.73,596.34,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,374.91,596.34,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="1,384.32,596.34,3.87,8.74" target="#b5">6</ref>] that compare online and offline evaluations use different datasets for offline evaluation and online evaluation. It is possible that the difference in performance may be attributed to this difference in dataset. The literature lists some reasons for the disparate performance of recommender systems in offline and online evaluations <ref type="bibr" coords="1,437.99,644.16,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,450.17,644.16,7.01,8.74" target="#b6">7]</ref>. The first reason is that offline evaluations can measure only accuracy; they do not take</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>the user behavior into account. The second reason is that offline data-sets are incomplete and imperfect, and thus recommender systems are being evaluated based on incomplete dataset.</p><p>The first reason, that is, that offline evaluations can measure only accuracy and thus can not take user behavior into account can be understood in two ways. One way is that online evaluations can be influenced by adapted implementations of the algorithms that were used in offline evaluation, to take user behavior into account, in which case it becomes a different implementation. The other way to understand it is that online evaluations happen in an environment that involves user behavior and thus their performances can be influenced by the system and/or user behavior "randomness". The first interpretation implies that offline and online algorithms are differently implemented. The second interpretation implies that the difference in offline and online evaluations can be due to the system and/or user behavior randomness that the online evaluations are subjected to. We attempt to explore this randomness in our participation</p><p>The motivation for the second goal comes from a descriptive study we conducted on a Plista dataset we collected in our previous participation. In the study, there were two findings <ref type="bibr" coords="2,271.26,322.33,9.96,8.74" target="#b3">[4]</ref>. One is that there is a substantial difference in the geographical distribution of the readerships of traditional news portals, and the second is that within the same portal, the geographical distribution of the readerships of the local news category and the rest of the categories shows substantial difference. In our experiments, we tried to exploit the second finding to improve news recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>For the study of the effect of system and/or user behavior randomness on recommender system evaluations, we run two instances of the same news recommender algorithm with the view to measuring the effect of "randomness" involved in news recommendation clicks. For exploiting geographical information for news recommendation, we employ a recommendation diversification approach. Specifically, we include geographically relevant recommendation into the recommendation list, thus diversifying the recommendations in favor of geographic relevance</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Algorithms</head><p>We experimented with five algorithms, all of them modifications of the recency algorithm. The recency algorithm takes into account recency and popularity of an item, and it has been shown to be a strong baseline in previous online evaluations. The algorithmic variations that we experimented with are listed below.</p><p>Recency: This algorithm keeps the 100 most recently viewed items for each publisher in consideration for being recommended to the user. For any recommendation request, the items that are , at the time of the recommendation request, the most recently read (clicked)) are the ones that are recommended.</p><p>We run two instances of this algorithm to get a sense of the randomness involved in the selection of algorithms by the Plista framework <ref type="bibr" coords="3,409.20,130.95,10.52,8.74" target="#b1">[2]</ref> and/or clicks on recommendations by users.</p><p>GeoRec: The geographical recommender takes the geographical region (states to be specific) of users and the local category of news items into account when generating recommendations. We generate two sets of recommendations, one by the recency recommender and one by a purely geographical recommender. For the purely geographical recommender, we take the 100 most recently viewed items and sort them according to their geographic conditional likelihood scores generated by Equation <ref type="formula" coords="3,237.05,226.59,3.87,8.74" target="#formula_0">1</ref>.</p><formula xml:id="formula_0" coords="3,266.94,250.50,213.65,10.32">r ua,i k = P (c i k |g ua )<label>(1)</label></formula><p>Where c i k is the local category of item i k . An item is either in the local category, or not. g ua is the state-level geographical information of the user u a , that is, the state the user belongs to. Then, we take top twice the number of requested recommendations as recommendation of the geographic recommender. For the recency, we take the requested number of recommendations from the from the most recently viewed items. Then we intersect the two sets of recommendations. If the number of elements in the intersection is not equal with the requested number of recommendations, we get half -1 from purely geographic recommender and half + 1 from recency recommender.</p><p>GeoRecHistory: This is a modification of the GeoRec recommender; it excludes from the recommendation list those items that the user has already visited.</p><p>RecencyRandom: This recommender recommends items randomly selected from the circular-buffer. This was started a bit late, and we used it a baseline algorithm.</p><p>The two instances of Recency and the GeoREc algorithms were run for a consecutive period of 53 days, from 2015-04-12 to 2015-06-03. The RecencyRandom algorithm was started 12 days later on 2015-04-24.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussions</head><p>We present two types of performance scores: cumulative and daily click-through rates (CTR). The cumulative CTR is presented in Table <ref type="table" coords="3,395.84,536.57,3.87,8.74">1</ref>. We see that the performances are all close to each other. However, if we rank them, we see that the GeoRec recommender followed by Recency followed by GeoRecHistory end up as the first three best performing algorithms. The daily performances of the algorithms are shown in Figure <ref type="figure" coords="3,273.51,584.39,3.87,8.74">1</ref>, and the cumulative CTR as a function of the number of days is shown in figure <ref type="figure" coords="3,284.71,596.34,3.87,8.74">2</ref>.</p><p>From the daily (figure <ref type="figure" coords="3,252.95,608.30,4.43,8.74">1</ref>) and cumulative (figure <ref type="figure" coords="3,370.42,608.30,4.43,8.74">2</ref>) plots, we see that the performance of any of the algorithms varies greatly. In the cumulative plot, we see that Recency and Recency2 performed differently for a long time, but generally getting closer towards each other until some point after which they seem to stabilize. If one was continuously monitoring the performances of this  <ref type="table" coords="4,233.77,230.38,4.13,7.89">1</ref>. Live performance of different algorithms q q q q q q q q q q q q q q q q q q q q q q q q q qq q q q q q qq q q q q q q q q q q q q q q q q q q q 1 5 9 13 18 23 28 33 38 43 48 53 0.0 0.5 1.0 1.5 2.0 q q q q q q q q q q q q q q q q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Days CTR recency recency2 geoRec geoRecHistory recencyRandom two algorithms, then one would say that the Recency algorithm is better than Recency2 algorithm. This would happen, at least some times, even if one employs statistical significance tests. Let's assume that the experimenter was peeking at the experiments everyday to make a decision on which algorithm is better. How many times would the experimenter declare statistically significant differences between the different algorithms? We examined this by using two baselines: the random recommender (RecencyRandom) and Recency2. The results, when using the RecencyRandom recommender as a baseline, are given in Table <ref type="table" coords="6,344.07,216.99,3.87,8.74" target="#tab_1">2</ref>. Similarly, the results for the baseline of Recency2 are given in Table <ref type="table" coords="6,309.61,228.95,3.87,8.74" target="#tab_2">3</ref>.</p><p>We see that, when RecencyRandom is used a a baseline, Recency, GeoRec and GeoRecHistory achieve statistically significant performance almost more than half of the time. With Recency2 as baseline, we see that only Recency achieves a statistically significant result twice. What is truly interesting is that the same algorithm (Recency) can end up achieving statistically significant performance over another instance of itself (Re-cency2). The two instances of the same algorithm show so big difference in performance that there is a big chance of concluding one is better than itself. The implication of this raises questions on improvement of performance of algorithms that involve live users in general. Specifically, to what extent is one algorithm's improvement over another a real improvement? It seems to us that statistical significance tests alone are not sufficiently indicative of performance improvements. Given the randomness involved in user's clicks on recommendations (and the system), a certain range of performance difference is not worth taking seriously. Studies that involve users must account for some level of randomness, in addition to statistical significance tests.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,187.09,607.71,238.11,7.89"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. The daily CTR performances of the five algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,165.88,316.80,280.54,156.73"><head>Table 2 .</head><label>2</label><figDesc>Statistical significance over the baseline of RecencyRandom</figDesc><table coords="6,204.78,316.80,205.79,156.73"><row><cell>Algorithm</cell><cell cols="2">Days of Significance Percentage (%)</cell></row><row><cell>recency</cell><cell>16</cell><cell>40.0</cell></row><row><cell>geoRec</cell><cell>23</cell><cell>57.5</cell></row><row><cell>geoRecHistory</cell><cell>24</cell><cell>60.0</cell></row><row><cell>Algorithm</cell><cell cols="2">Days of Significance Percentage (%)</cell></row><row><cell>recency</cell><cell>2</cell><cell>5</cell></row><row><cell>geoRec</cell><cell>0</cell><cell>0</cell></row><row><cell>geoRecHistory</cell><cell>1</cell><cell>2.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,180.53,476.15,251.23,7.89"><head>Table 3 .</head><label>3</label><figDesc>Statistical significance over the baseline of Recency2</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Conclusions and Perspectives for Future Work</head><p>We set out to study two factors in news recommendation: geographical information, and user and/or system randomness in news recommendation clicks. Although the geographical recommendation did not show any strikingly useful improvement over the recency algorithm, the user-system randomness seems to indicate that care must be taken to take into account some degree of randomness in recommender systems evaluation that involve users in a live setting, in addition to statistical significance tests. In the future, we would like to extend this work to include a better statistical testing system that can account for this randomness. We also would like to compare the offline and online evaluations, Specifically, we would like run one algorithm on the logs of another to see to what extent they can replace each other.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,317.93,342.25,7.86;7,146.91,328.89,333.68,7.86;7,146.91,339.85,333.68,7.86;7,146.91,350.81,317.53,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,399.51,317.93,81.09,7.86;7,146.91,328.89,333.68,7.86;7,146.91,339.85,70.03,7.86">A comparative analysis of offline and online evaluations and discussion of research paper recommender system evaluation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Genzmehr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>NÃ¼rnberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,235.64,339.85,244.95,7.86;7,146.91,350.81,212.75,7.86">Proceedings of the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation</title>
		<meeting>the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,361.77,342.25,7.86;7,146.91,372.72,333.68,7.86;7,146.91,383.68,207.85,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,279.44,361.77,201.15,7.86;7,146.91,372.72,125.40,7.86">Shedding light on a living lab: the clef newsreel open recommendation platform</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,292.95,372.72,187.64,7.86;7,146.91,383.68,88.60,7.86">Proceedings of the 5th Information Interaction in Context Symposium</title>
		<meeting>the 5th Information Interaction in Context Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="223" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,394.64,342.24,7.86;7,146.91,405.60,333.68,7.86;7,146.91,416.56,333.68,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,453.96,394.64,26.63,7.86;7,146.91,405.60,255.37,7.86">Offline and online evaluation of news recommender systems at swissinfo</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Garcin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Donatsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alazzawi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bruttin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,434.71,405.60,45.88,7.86;7,146.91,416.56,215.22,7.86">Proceedings of the 8th ACM Conference on Recommender systems</title>
		<meeting>the 8th ACM Conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,427.52,342.24,7.86;7,146.91,438.48,333.68,7.86;7,146.91,449.44,333.68,7.86;7,146.91,460.40,20.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,306.99,427.52,173.60,7.86;7,146.91,438.48,49.33,7.86">The role of geographic information in news consumption</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Gebremeskel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,217.29,438.48,263.30,7.86;7,146.91,449.44,328.97,7.86">Proceedings of the 24th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 24th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,471.36,342.24,7.86;7,146.91,482.31,333.68,7.86;7,146.91,493.27,333.68,7.86;7,146.91,504.23,20.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,146.91,482.31,212.39,7.86">Benchmarking news recommendations in a living lab</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Plumbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Heintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,379.15,482.31,101.44,7.86;7,146.91,493.27,223.15,7.86">Information Access Evaluation. Multilinguality, Multimodality, and Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="250" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,515.19,342.24,7.86;7,146.91,526.15,333.68,7.86;7,146.91,537.11,233.18,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,329.48,515.19,151.12,7.86;7,146.91,526.15,191.57,7.86">A live comparison of methods for personalized article recommendation at forbes. com</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kirshenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Forman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,358.30,526.15,122.30,7.86;7,146.91,537.11,111.62,7.86">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="51" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,548.07,342.24,7.86;7,146.91,559.03,333.68,7.86;7,146.91,569.99,324.86,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,338.47,548.07,142.12,7.86;7,146.91,559.03,146.84,7.86">Don&apos;t look stupid: avoiding pitfalls when recommending research papers</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,314.51,559.03,166.08,7.86;7,146.91,569.99,206.09,7.86">Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work</title>
		<meeting>the 2006 20th anniversary conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
