<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.95,115.90,303.46,12.90;1,223.43,135.75,168.50,10.75">Improving Synoptic Quering for Source Retrieval Notebook for PAN at CLEF 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.75,172.15,68.36,8.64"><forename type="first">Šimon</forename><surname>Suchomel</surname></persName>
							<email>suchomel@fi.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.48,172.15,66.13,8.64"><forename type="first">Michal</forename><surname>Brandejs</surname></persName>
							<email>brandejs@fi.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.95,115.90,303.46,12.90;1,223.43,135.75,168.50,10.75">Improving Synoptic Quering for Source Retrieval Notebook for PAN at CLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D3981912A8B204AB70CE59761545BFCA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Source retrieval is a part of a plagiarism discovery process, where only a selected set of candidate documents is retrieved from a large corpus of potential source documents and passed for detailed document comparison in order to highlight potential plagiarism. This paper describes a used methodology and the architecture of a source retrieval system, developed for PAN 2015 lab on uncovering plagiarism, authorship and social software misuse. The system is based on our previous systems used at PAN since 2012. The paper also discusses the queries performance and provides explanation for many implementation settings. The proposed methodology achieved the highest recall with usage of the least number of queries among other PAN 2015 softwares during the official test run. The source retrieval subsystem forms an integral part of a modern system for plagiarism discovery.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In plagiarism detection, the source retrieval is a task for the automated system to retrieve candidate documents from large document collections, which may have served as a pattern for plagiarism, and pass the retrieved documents for further inspection <ref type="bibr" coords="1,466.48,441.24,10.58,8.64" target="#b8">[9]</ref>. The further inspection means to evaluate document similarities in detail, which, however, can be done only among documents that are known to the system. The desired similarities are mainly textual, thus the text of suspicious document is usually aligned with each document from the system's document base. If the collection of potential source documents is too large, it is infeasible to calculate detailed similarities among each document pairs from that collection, therefore, only a small selected subset of potential sources to each input suspicious documents is retrieved. The whole collection of possible source documents is an unknown environment for the plagiarism detection system, thus the document retrieval is carried out by utilization of a search engine which is capable of a document retrieval.</p><p>This paper describes the key aspects and the main changes in the source retrieval methodology from the system used at PAN 2014 <ref type="bibr" coords="1,336.11,584.71,10.58,8.64" target="#b2">[3]</ref>, which is described in <ref type="bibr" coords="1,442.87,584.71,15.27,8.64" target="#b9">[10]</ref>. The queries performance analysis is also provided.</p><p>The task for the PAN lab was to retrieve all plagiarized documents, based on a suspicious document, from the reference document collection by utilizing a web search engine, while minimizing the retrieval costs.</p><p>For the source retrieval, based on each suspicious document the prepared queries were passed to search engines according to their type. The synoptic queries were passed to ChatNoir <ref type="bibr" coords="2,183.38,119.31,11.62,8.64" target="#b3">[4]</ref> and the phrasal queries to Indri <ref type="bibr" coords="2,319.47,119.31,10.58,8.64" target="#b7">[8]</ref>. Both search engines index ClueWeb09 <ref type="foot" coords="2,487.08,117.64,3.49,6.05" target="#foot_0">1</ref>which constituted the corpus of potential source documents. Afterwards, the search engine results were examined and if a similar passage with the suspicious document was found, the result was reported as a candidate document for being a source of plagiarism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Building of Queries</head><p>The system prepared several types of queries for each suspicious document, which we divide into two main groups: the whole document keywords-based queries and the paragraph-based queries. For queries construction, a weight w i was assigned to each term k i from input document d j . A term is represented by a word, extracted from the input text using blank spaces as a separator between two words, and cleaned of all punctuation. The weights follow the TF-IDF weighting scheme <ref type="bibr" coords="2,374.94,272.55,10.58,8.64" target="#b5">[6]</ref>. As a reference corpus for the weights calculation, an English web-based corpus containing more then 4 billion tokens was used<ref type="foot" coords="2,222.73,294.79,3.49,6.05" target="#foot_1">2</ref> . For each term, it's lemma l i was also extracted using Python NLTK<ref type="foot" coords="2,160.41,306.74,3.49,6.05" target="#foot_2">3</ref> lemmatizer, which was performed on the basis of extracted sentences. The ambiguous terms were let in the original form. Each document d j was then represented as</p><formula xml:id="formula_0" coords="2,134.77,332.00,119.13,9.65">(k i , w i , l i ) where i ∈ [1, |d j |].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Keywords-based Queries</head><p>Keywords-based queries were six terms long. The first query -the pilot query, was extracted from the best scored keywords and passed to both search engines in order to aim for theme related documents and starting the synoptic search. For the purpose of the pilot query, the Indri was set to combine all the query tokens.</p><p>For each of those best six keywords, the most frequent in-sentence adjacent words were also extracted. In such a way, collocations were extracted, together with the keywords both three and two terms long. The main difference from the PAN 2014 approach <ref type="bibr" coords="2,164.36,467.80,16.60,8.64" target="#b9">[10]</ref> is in the combining of extracted collocations into the queries.</p><p>Three term long collocations posed individual phrasal queries <ref type="foot" coords="2,397.25,478.27,3.49,6.05" target="#foot_3">4</ref> . Such short queries were executed via the Indri search engine with the setting of the proximity term number to 1, which denotes the search for exact occurrence. From the subsequent two-token long collocations, an additional 6 terms long queries were created, whilst having all terms in one query unique. They were aimed at the ChatNoir search engine. Finally, the remaining keywords were combined into additional keywords-based queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Paragraph-based Queries</head><p>The scored suspicious document was also divided into paragraphs-like chunks using an empty new line (occurring in its plaintext format) as a chunks' separator. From each chunk c i a single query was prepared. Let beg(c i ) denote the position of the first word of the chunk c i in the input file and let end(c i ) denote the position of the last word of the chunk c i in the input file. The paragraph based query from c i comprised from 10 words k i ∈ s i , with maximal 10 j=1 w ij , where s i denotes the interval [beg(c i ), end(c i )]. Ten tokens is the maximum length of a query for the ChatNoir search engine. The maximum length was chosen in order to produce the most specific query for the given paragraph, which should maximize the probability of retrieving texts containing similar paragraphs. The query was constructed from tokens which might be scattered over the whole chunk, therefore it cannot be used as a phrase query. On the contrary, due to its specificity, it is hardly usable as a synoptic query or a theme-related keywords-based query.</p><p>Paragraph-based queries were passed to ChatNoir. The interval s i was associated to all paragraph-based queries, which denotes the file position of the query. The query is said to characterize the text within its interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Queries Scheduling</head><p>In order to acquire maximum information from the top-scored keywords, they were combined into several different types of queries. They appeared in the pilot query and in the collocational queries and they may have appeared in paragraph-based queries. Apart from this distinct appearance of the top scored keywords in different formulated queries, no further query reformulation, such as reformulation based on the results, was applied.</p><p>Queries were scheduled for execution sorted by their priority, starting with the pilot query, next the collocational phrase queries, the collocational synoptic queries, afterwards the queries constructed from remaining keywords if any, and lastly all the paragraph-based queries.</p><p>The paragraph-based queries were executed on demand according to their position, if and only if there was no intersection of the query position interval with any of the intervals from all the so far found similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results Downloading and Assessing</head><p>A maximum of 100 results obtained from search engines were processed based on each query. Only selected results were downloaded and textually aligned with the suspicious document. The decision whether to download a result was made based on the result's 500 characters long snippets, which were generated for each token from the query and concatenated into one text chunk. If this chunk showed promising similarity with the suspicious document, the result was downloaded. This decision making was adopted from our previous years' implementations, for more information see <ref type="bibr" coords="3,409.00,608.07,15.77,8.64" target="#b9">[10,</ref><ref type="bibr" coords="3,424.77,608.07,11.83,8.64" target="#b11">12]</ref>.</p><p>Each downloaded document was thoroughly compared with its suspicious document by calculating common features <ref type="bibr" coords="3,285.03,632.53,16.60,8.64" target="#b10">[11,</ref><ref type="bibr" coords="3,301.63,632.53,12.45,8.64" target="#b11">12]</ref> based on word n-grams and stop-word mgrams <ref type="bibr" coords="3,161.93,644.48,10.58,8.64" target="#b6">[7]</ref>. The common features formed valid intervals, which were covered "densely enough" by the features. Two valid intervals were merged if they were closer than 81 characters, which estimates the length of a text line. Each resulting valid interval represented one plagiarism case. Such an interval s res was marked in the suspicious document and all the waiting paragraph-based queries for which s i ∩s res = ∅ were excluded from the queue of prepared queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method Assessment</head><p>As a training corpus for the source retrieval task, the task organizers provided 98 Englishwritten documents, which contained plagiarized passages from web pages retrieved from the ClueWeb09 document collection. The documents were mostly highly plagiarized, only one document from the corpus was plagiarism free, and this was a short document containing only a single paragraph of 204 words. Each document was about a specific topic and the documents were created manually <ref type="bibr" coords="4,366.51,391.35,10.58,8.64" target="#b4">[5]</ref>. The plagiarism cases for each document were annotated. The size of the plaintexts were 30 KB on average and each document contained around five thousand words on average. During the training phase evaluation, for the whole 98 documents in the training corpus, 32.9 queries per document on average were executed, from which 18.8% were directed to Indri and 81.2% to ChatNoir. In total, 134247 unique URLs were retrieved, provided that each query asked the search engine for 100 results.</p><p>The assumption for preparing queries was that the paragraph-based queries were more specific, thus leading to less number of returned URLs. On the other hand, synoptic queries, such as the pilot query and other keywords-based queries, should retrieve more results provided the corpus is large enough. We can affirm this assumption by measuring the number of results returned from the search engine per query type. However, the query generality is limited by the maximum number of results, for which we asked the search engine. Each type of query's specificity and generality is shown in Tab. 1. The column Scope Usage shows the average from all queries of one type, expressed as a percentage of the potential maximum number of retrieved results. The table also shows the portion of queries based on which the search engines retrieved the maximum allowed number of results -Top Retrieval, which indicates they were general enough under the given conditions. The last column shows portions of queries for which the search engine returned zero answers. Table <ref type="table" coords="4,356.26,619.88,4.98,8.64" target="#tab_0">1</ref> supports the assumption that paragraph-based queries were more biased in retrieval towards their paragraph text.</p><p>The number of results for general queries has little information value. If the query is too general the search engine returns a huge number of results. Therefore, the synoptic query construction must lead to the generation of large number of relevant results. Relevant results can be defined by their purpose, such as, for example, documents following a specific topic or similar to the suspicious document in some extend. We define a result relevant if its text alignment with the suspicious document produces one or more valid intervals, meaning the two documents contain a textually similar passage. From all of the retrieved results, 6392 were found to be relevant. Please note that not all results were downloaded, therefore, some of the similarities might have been missed during the download decision. From all of the discovered URLs, 32538 were actually downloaded and textually aligned with its suspicious document. For all except one suspicious document that contained plagiarism, some relevant documents were found.</p><p>Table <ref type="table" coords="5,175.82,353.09,4.98,8.64" target="#tab_1">2</ref> shows the performance of queries by their type 5 . The third and fourth columns show the number of successful results and the coverage of results of current query type respectively. One relevant URL was counted into the total number of successful results only once, but some queries led to the retrieval of already discovered results. Therefore, in order to make an unbiased evaluation of the coverage, in terms of query execution sequence, each successful result is credited with all queries which retrieved that result. Table <ref type="table" coords="5,243.04,424.82,4.98,8.64" target="#tab_1">2</ref> shows that the portion of retrieved relevant URLs for the pilot, phrasal and paragraph-based queries is getting closer to nearly a half of all relevant retrieved URLs, but phrasal and paragraph-based queries needed nearly 3 times and 11 times more searches than the pilot queries respectively. The average number of hits per query depicts the fifth column of Tab. 2, which supports the assumption that the pilot query is the most important and it is the best choice for the synoptic search to start with, in order to cover the majority of plagiarism as quickly as possible.</p><p>The paragraph-based queries have relatively low yield of relevant results per one query, which is due to their specificity (Tab. 1), but they can cover a large portion of successful results. Therefore, it may be beneficial to skip these queries for some parts of input documents, e.g. parts where plagiarism was already discovered, and use them in order to aim the search for more suspicious parts, for example, parts selected using intrinsic plagiarism methods. Both tables show that 2109 paragraph-based queries were executed, however, the total number of prepared paragraph-based queries was 6693, 5 For all the 98 suspicious documents, there were only 183 pilot based queries executed, despite the fact, that the pilot query should have been processed by both ChatNoir and Indri search engines. For 13 suspicious document, the pilot query was processed by only one search engine. There were missed 12 queries in Indri and one query in ChatNoir because of the timeout. The search engines were utilized during a standard operation over the network with timeout set to 8 minutes. meaning that there was 68.5% of such queries omitted due to their position inside an already discovered interval of textual similarity.</p><p>Since the pilot query yields 15.4 relevant results per query, it is clear that a search engine should be asked to retrieve at least tens of results based on this query type. However, the number of results influences not only recall of the system, but also time and space requirements of the system. Relevant URLs were also retrieved from very high sequence numbers of ranking in the Search Engine Result Page (SERP). Similarities were found even among higher than 100 th result based on one query. The limit 100 results was set due to the time consumption of URLs checking. One of the master hits (see further) was retrieved from SERP's 100 th position. Figure <ref type="figure" coords="6,366.51,435.14,4.98,8.64" target="#fig_0">1</ref> depicts the total number of relevant URLs retrieved at first 20 positions 6 of SERP based on all queries.</p><p>Surprisingly poor performance compared to other types, can be observed at the other keywords-based queries (see both Tab. 1 and Tab. 2), which indicates that extraction of less than 10 quality keywords is sufficient for such texts. Table <ref type="table" coords="6,385.52,486.79,4.98,8.64" target="#tab_0">1</ref> shows that their scope was around half of asked results, despite the fact that they were aimed for synoptic theme related searches. Table <ref type="table" coords="6,254.53,510.70,4.98,8.64" target="#tab_1">2</ref> indicates that they covered only 6.3% of all discovered similarities; on the other hand, in terms of number, they represented the smallest type of queries.</p><p>The discovered relevant URLs contained some portion of similar text with the suspicious document. In the ClueWeb09 corpus, many texts are reused like in a real web, therefore, many web pages may be classified as near-duplicates <ref type="bibr" coords="6,399.21,574.31,11.62,8.64" target="#b1">[2]</ref> and many documents just contain smaller or larger passages identical to other web page. The retrieved relevant results are among those cases. However, the source of each plagiarism in the corpus of suspicious documents were annotated with the original web page from which the text was reused. We call the retrieval of such an original document a master hit.  Taking into account only master hits <ref type="foot" coords="7,285.59,267.95,3.49,6.05" target="#foot_4">7</ref> , for the whole input corpus, the overall recall was 0.45 with 5 document having 100% recall and 12 documents without a master hit. We consider this performance as a very good result providing that no near-duplicates were taken into account. Figure <ref type="figure" coords="7,262.73,305.49,4.98,8.64" target="#fig_2">2</ref> shows the progress of detection during the scheduled querying of two selected<ref type="foot" coords="7,232.90,315.77,3.49,6.05" target="#foot_5">8</ref> documents. The y axis shows the percentage of retrieved relevant documents. The portion of queries covered by specific query type is distinguished with the type-labelled vertical line separators. The number of queries to first detection is also evaluated in PAN, this is the job for pilot queries, which should lead to positive results using the very first two queries. From the right plot of Fig. <ref type="figure" coords="7,433.55,365.26,3.74,8.64" target="#fig_2">2</ref>, it can be seen that paragraph-based queries can highly support the detection, if fewer similarities were discovered using previous types of queries. In a real-world situation, while expecting the documents to contain less plagiarism, we would try to lower the number of executed paragraph-based queries with methods detecting suspicious parts of the input documents, and schedule the paragraph-based queries located only in those parts. The left plot of Fig. <ref type="figure" coords="7,198.90,437.00,4.98,8.64" target="#fig_2">2</ref> shows pilot and phrasal queries as the most profitable, which was in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper described an architecture of PAN 2015 software for source retrieval in a plagiarism detection task. The key settings were discussed and analyses of the settings provided. The software was based on previous versions used in PAN since 2012 <ref type="bibr" coords="7,436.59,531.43,16.00,8.64" target="#b10">[11,</ref><ref type="bibr" coords="7,452.59,531.43,12.00,8.64" target="#b11">12,</ref><ref type="bibr" coords="7,464.59,531.43,12.00,8.64" target="#b9">10]</ref>, this paper also described changes made for 2015 lab at PAN. For the source retrieval, based on each suspicious document, queries of several types were prepared: keywords-based; divided further into the pilot, phrasal collocations, collocations, and other keywords-based; and the paragraph-based queries which were associated with the position in the suspicious document of the paragraph they characterized. Queries were executed sequentially and all results from each query were evaluated, in order to skip some of the paragraph-based queries for whose paragraphs a similarity was already detected. Final results containing the valid intervals with the suspicious document, were reported. The pilot queries proved to be the best choice for synoptic search and the paragraph-based queries manage to perform well in the positional retrieval, which is biased towards searching for specific short texts.</p><p>The retrieval recall in the lab's official test run, compared to the previous year, has increased, but so has the total number of used queries. However, the proposed methodology achieved the highest recall with usage of the least number of queries among the PAN 2015 softwares during the official test run. The discussion and evaluation of PAN can be found in the lab overview paper by the lab organizers <ref type="bibr" coords="8,377.45,226.91,10.58,8.64" target="#b0">[1]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,213.23,281.77,188.90,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Number of relevant results per SERP rank.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,139.00,655.22,2.99,5.18;6,144.73,657.08,131.55,7.77"><head>6</head><label></label><figDesc>20 best ranked URLs for each query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,160.45,234.79,294.45,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Relevant URLs retrieval progress of two selected suspicious documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,139.19,115.83,336.97,87.87"><head>Table 1 .</head><label>1</label><figDesc>Query type scope</figDesc><table coords="4,139.19,137.15,336.97,66.55"><row><cell>Query type</cell><cell cols="5">#Queries #URLs retrieved Scope Usage Top Retrieval Zero Retrieval</cell></row><row><cell>Pilot</cell><cell>183</cell><cell>16341</cell><cell>89.3%</cell><cell>83.6%</cell><cell>1.1%</cell></row><row><cell>Collocational Phrasal</cell><cell>520</cell><cell>34095</cell><cell>65.6%</cell><cell>56.7%</cell><cell>12.3%</cell></row><row><cell>Collocational</cell><cell>311</cell><cell>23188</cell><cell>74.6%</cell><cell>64.3%</cell><cell>2.9%</cell></row><row><cell>Other Keywords-based</cell><cell>101</cell><cell>5367</cell><cell>53.1%</cell><cell>38.6%</cell><cell>8.9%</cell></row><row><cell>Paragraph-based</cell><cell>2109</cell><cell>81788</cell><cell>38.8%</cell><cell>26.8%</cell><cell>18.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,152.52,115.83,310.32,87.87"><head>Table 2 .</head><label>2</label><figDesc>Query type performance</figDesc><table coords="5,152.52,137.15,310.32,66.55"><row><cell>Query type</cell><cell cols="4">#Queries #Relevant URLs Theoretical Portion Hits per Query</cell></row><row><cell>Pilot</cell><cell>183</cell><cell>2815</cell><cell>44.0%</cell><cell>15.4</cell></row><row><cell>Collocational Phrasal</cell><cell>520</cell><cell>2974</cell><cell>46.5%</cell><cell>5.7</cell></row><row><cell>Collocational</cell><cell>311</cell><cell>1730</cell><cell>27.1%</cell><cell>5.6</cell></row><row><cell>Other Keywords-based</cell><cell>101</cell><cell>401</cell><cell>6.3%</cell><cell>4.0</cell></row><row><cell>Paragraph-based</cell><cell>2109</cell><cell>2713</cell><cell>42.4%</cell><cell>1.3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,623.64,161.66,7.77"><p>http://www.lemurproject.org/clueweb09.php/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,634.79,283.96,7.77"><p>http://www.sketchengine.co.uk/documentation/wiki/Corpora/TenTen/enTenTen</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,645.94,72.99,7.77"><p>http://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,144.73,657.08,190.37,7.77"><p>Phrasal queries posed an exception in a query length.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="7,144.73,624.02,335.86,7.77;7,144.73,634.98,335.86,7.77;7,144.73,645.94,244.70,7.77"><p>The master hits analysis is included because of the low precision, which the system achieved in the test phase of the lab. In the real-world, the ani plagiarism system must provide the user the possibility of examination of relatively small textual similarities.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="7,144.73,657.08,292.58,7.77"><p>For those documents, the highest number of distinct relevant URLs was retrieved.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,274.89,327.50,7.77;8,150.95,285.85,327.67,7.77;8,150.95,296.81,270.83,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,277.48,274.89,192.62,7.77;8,150.95,285.85,120.68,7.77">Source Retrieval for Plagiarism Detection from Large Web Corpora: Recent Approaches</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,290.18,285.85,188.45,7.77;8,150.95,296.81,15.74,7.77">Working Notes Papers of the CLEF 2015 Evaluation Labs</title>
		<title level="s" coord="8,172.87,296.81,172.47,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2015-09">Sep 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,306.94,333.25,7.77;8,150.95,317.89,302.73,7.77;8,150.95,328.85,307.14,7.77;8,150.95,339.81,23.90,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,334.02,317.89,119.67,7.77;8,150.95,328.85,132.28,7.77">Overview of the 4th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oberländer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,301.39,328.85,156.71,7.77">CLEF 2012 Evaluation Labs and Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,349.94,304.68,7.77;8,150.95,360.90,326.66,7.77;8,150.95,371.86,316.30,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,150.95,360.90,254.19,7.77">Overview of the 6th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,423.30,360.90,54.32,7.77;8,150.95,371.86,96.64,7.77">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="845" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,381.99,328.34,7.77;8,150.95,392.95,320.28,7.77;8,150.95,403.91,329.64,7.77;8,150.95,414.87,229.31,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,150.95,392.95,195.48,7.77">ChatNoir: A Search Engine for the ClueWeb09 Corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,257.57,403.91,223.02,7.77;8,150.95,414.87,128.24,7.77">International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,425.00,304.90,7.77;8,150.95,435.95,315.67,7.77;8,150.95,446.91,104.11,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,321.97,425.00,125.54,7.77;8,150.95,435.95,132.36,7.77">Crowdsourcing Interaction Logs to Understand Text Reuse from the Web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,302.37,435.95,29.34,7.77">ACL (1)</title>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1212" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,457.04,322.33,7.77;8,150.95,468.00,217.29,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,227.51,457.04,211.87,7.77">On the Specification of Term Values in Automatic Indexing</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<idno>TR-73-173</idno>
		<imprint>
			<date type="published" when="1973">1973</date>
			<pubPlace>Ithaca, NY US</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct coords="8,142.61,477.97,330.24,7.93;8,150.95,489.09,23.90,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,207.24,477.97,160.58,7.93">Plagiarism detection using stopword n-grams</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,374.02,478.13,27.86,7.77">JASIST</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2512" to="2527" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,499.22,332.31,7.77;8,150.95,510.18,326.44,7.77;8,150.95,521.14,96.63,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,332.49,499.22,142.43,7.77;8,150.95,510.18,101.69,7.77">Indri: A Language-model Based Search Engine for Complex Queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,307.82,510.18,169.57,7.77;8,150.95,521.14,70.48,7.77">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,531.27,294.53,7.77;8,150.95,542.23,322.51,7.77;8,150.95,553.19,98.86,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,254.31,531.27,167.16,7.77">Approaches for Candidate Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Š</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,542.23,318.78,7.77">Information and Communication Systems (ICICS), 2014 5th International Conference on</title>
		<meeting><address><addrLine>Irbid</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,563.31,327.72,7.77;8,150.95,574.27,313.09,7.77;8,150.95,585.23,66.49,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,254.31,563.31,199.63,7.77">Heterogeneous Queries for Synoptic and Phrasal Search</title>
		<author>
			<persName coords=""><forename type="first">Š</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,574.27,153.20,7.77">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="1017" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,595.36,296.24,7.77;8,150.95,606.32,316.06,7.77;8,150.95,617.28,317.74,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,302.87,595.36,135.61,7.77;8,150.95,606.32,215.13,7.77">Three way search engine queries with multi-feature document comparison for plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,384.04,606.32,82.97,7.77;8,150.95,617.28,155.33,7.77">CLEF 2012 Evaluation Labs and Workshop, Online Working Notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">September 17-20, 2012 (2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,627.41,330.87,7.77;8,150.95,638.37,313.54,7.77;8,150.95,649.33,112.31,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,302.87,627.41,170.24,7.77;8,150.95,638.37,75.54,7.77">Diverse Queries and Feature Type Selection for Plagiarism Discovery</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,244.82,638.37,154.92,7.77">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
