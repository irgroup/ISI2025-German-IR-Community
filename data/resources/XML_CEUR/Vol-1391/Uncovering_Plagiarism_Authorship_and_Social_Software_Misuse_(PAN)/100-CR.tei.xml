<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.35,115.90,290.67,12.90;1,217.29,133.83,180.78,12.90;1,223.43,153.68,168.50,10.75">XRCE Personal Language Analytics Engine for Multilingual Author Profiling Notebook for PAN at CLEF 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.46,190.08,53.36,8.64"><forename type="first">Scott</forename><surname>Nowson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre</orgName>
								<address>
									<country>Europe</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.37,190.08,46.81,8.64"><forename type="first">Julien</forename><surname>Perez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre</orgName>
								<address>
									<country>Europe</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.77,190.08,54.73,8.64"><forename type="first">Caroline</forename><surname>Brun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre</orgName>
								<address>
									<country>Europe</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.48,190.08,60.44,8.64"><forename type="first">Shachar</forename><surname>Mirkin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre</orgName>
								<address>
									<country>Europe</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.59,190.08,52.30,8.64"><forename type="first">Claude</forename><surname>Roux</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre</orgName>
								<address>
									<country>Europe</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.35,115.90,290.67,12.90;1,217.29,133.83,180.78,12.90;1,223.43,153.68,168.50,10.75">XRCE Personal Language Analytics Engine for Multilingual Author Profiling Notebook for PAN at CLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6B1C95AD212E989B75A1671190DD8F26</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This technical notebook describes the methodology used -and results achieved -for the PAN 2015 Author Profiling Challenge by the team from Xerox Research Centre Europe (XRCE). This year, personality traits are introduced alongside age and gender in a corpus of tweets in four languages -English, Spanish, Italian and Dutch. We describe a largely language agnostic methodology for classification which uses language specific linguistic processing to generate features. We also report on experiments in which we use machine translation to accommodate for languages in which there is less training data. Native language results are successful, but socio-demographic signals in language seem to be lost under MT conditions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Personal Language Analytics is a branch of text mining in which the object of analysis is the author of a document rather than the document itself. Language use in text (or indeed, speech) can reveal a great deal about a person: it can reveal one's gender, age or nationality, among other demographic traits. It can also provide clues as to one of the most important individual differences: personality. For example, when writing personal emails, out-going, social Extraverts are more likely to start by saying 'hi' while Introverts opt for 'hello' <ref type="bibr" coords="1,234.07,489.06,10.58,8.64" target="#b6">[7]</ref>.</p><p>Personality traits (and indeed the other human attributes mentioned) are a valuable source of information for applications such as user modeling or social media engagement. Work in this area, particularly in the computational recognition of personality, is garnering increasing interest with a number of workshops being organized in recent years (e.g. <ref type="bibr" coords="1,180.34,548.84,10.58,8.64" target="#b2">[3]</ref>, <ref type="bibr" coords="1,197.88,548.84,14.94,8.64" target="#b19">[21]</ref>). The addition of personality as a target trait in the PAN Author Profiling challenge in 2015 <ref type="bibr" coords="1,245.46,560.80,16.60,8.64" target="#b16">[18]</ref> serves as further evidence.</p><p>This paper presents the contribution of Xerox Research Centre Europe to the Author Profiling challenge 2015. We leverage our experience in multi-lingual processing by using language specific tools for each the four languages of the data set (see section 2 for more details). However, our methodology beyond this processing is broadly language agnostic: as much as possible we use a comparable feature set across each language; we also use the same parameters in our experiments.</p><p>One notable aspect of the dataset is the varying size of the corpora for the different languages. Therefore, in addition to exploring classification within each language in isolation, we have also used statistical machine translation in order to generate larger datasets. MT has shown to be of use with NLP tasks such as sentiment analysis <ref type="bibr" coords="2,466.20,131.27,10.79,8.64" target="#b1">[2]</ref>; we explore its utility in Author Profiling, where the targets of classification are sociodemographic labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data for the Author Profiling task is drawn from Twitter. For each user, the data consists of a number of tweets (the average is approximately 100 per subject) and a series of gold standard labels: gender (Male or Female), age-class (one of 18-24, 25-34, 35-49, 50-xx) and personality. The labels are provided by the author, with scores on five personality traits being calculated via self-assessment responses to the short big5 test (BFI-10, <ref type="bibr" coords="2,172.57,270.60,14.94,8.64" target="#b15">[17]</ref>), normalized between -0.5 and +0.5. Table <ref type="table" coords="2,368.11,270.60,4.98,8.64" target="#tab_0">1</ref> shows the volume of data per language for the training set. As can clearly be seen, the Italian and Dutch data sets are considerably smaller than the Spanish and English. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data preprocessing</head><p>There are a number of differences between the data provided for the challenge and data typically collected directly from twitter.</p><p>-The data has been anonymised to the extent that all user mentions have been replaced with '@username' -Unicode characters typically representing 'emojis' -a commonly occurring phenomena in Tweets -have not been encoded in the data. Thus, their use have been replaced by unknown character markers, e.g. '?????'</p><p>Other features of tweets, such as URLs and hastags, remain as per the original data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation</head><p>The task of the Author Profiling Challenge is to predict an author's demographics from their tweets. Performance will be evaluated on the prediction of gender and personality traits in the four languages, along with age for the larger corpora, English and Spanish.</p><p>For the official challenge, age and gender will be ranked by accuracy, the personality traits by Root Mean Squared Error (RMSE).</p><p>In this section we describe the methods we have combined to form the core pipeline of our Personal Language Analytics engine: firstly we report on the linguistic analysis which forms our pre-processing and feature extraction steps; secondly, the techniques of the learning framework are outlined. We also introduce the machine translation (MT) process we employed (as introduced earlier) to explore the effect on classification of using translated data to boost smaller corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Linguistic Processing</head><p>In order to feed the prediction models, we use a robust dependency syntactic parser <ref type="bibr" coords="3,468.97,252.42,11.62,8.64" target="#b0">[1]</ref> to extract a wide range of textual features, from standard n-grams to more sophisticated linguistic features.</p><p>Processing Steps Processing here includes tokenization, morpho-syntactic analysis, POS tagging -which is performed via a combination of hand-written rules and HMM -Named Entity Detection, chunking and finally, extraction of dependency relations such as subject, object and modifiers between lexical nodes. This is the stage of processing in which, as mentioned previously, we use-language specific tools. Several grammars have been developed for this parser, among which are the grammars for the PAN languages, i.e. English, Spanish, Italian and Dutch. These grammars are in different stages of development, the English one being more advanced than the others. Consequently, the set of features extracted is different from one language to another (see Table <ref type="table" coords="3,246.57,407.70,3.60,8.64" target="#tab_1">2</ref>). This parser has also been customized to parse social media data, and detects hashtags, mentions, and (ASCII) emoticons, along with labelling the latter with their polarity. For English, we have integrated a normalization dictionary (from <ref type="bibr" coords="3,433.44,443.57,15.93,8.64" target="#b8">[10]</ref>) in the preprocessing steps of the analysis. The English grammar also includes a polarity lexicon and a sentiment analysis layer to detect opinionated relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature extraction</head><p>We apply the parser on the different sets of PAN input data, and select a broad set of linguistically interesting features. In order to be closer to our aim of language independence, we do not draw on the deepest level of morpho-syntactic analysis which our toolset provides. For example, Spanish adjectives can have gender inflections, while English adjectives typically do not at the same level. We recognise that in doing this we may not be using the features of a given language as much as possible. However -tool performance aside -this is in-line with our broader aims.</p><p>The features extracted are of two types: word-level or class-based features. Wordlevel features are associating information to the surface and lemma forms of the words directly, while class-based features are more abstract and more generalised: they encode the presence of a given POS, semantic type, hashtags, etc, without tying the feature to the surface form.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Framework</head><p>Our learning framework is composed of 3 elements. First, the exhaustive tag-set produced by the linguistic preprocessing step is pruned using frequency thresholding determined by cross-validation. This reduces the occurrences of heavily under-used features. In the second step, the resulting index of features is compressed using truncated singular value decomposition. Finally, ensemble models are produced for each personality and demographic trait.</p><p>Truncated Singular Value Decomposition Singular Value Decomposition (SVD) [8] is a widely used technique for predictive data analysis in sparse dataset situations. It decomposes a given input matrix into a product of three matrices such that X = U SV T . Thereby, U and V are unitary matrices which essentially rotate the dataset. S is a diagonal matrix (producing a scaling) with the ordered singular values as entries.</p><p>In the truncated version, the purpose of the method is to compute an approximation of X instead of the exact decomposition such as, for instance, in Principal Components Analysis (PCA) <ref type="bibr" coords="5,202.77,204.43,15.18,8.64" target="#b9">[11,</ref><ref type="bibr" coords="5,217.95,204.43,7.59,8.64" target="#b7">9]</ref>. Indeed, by producing a low-rank approximation, the method copes with the noise present in the data by extracting the principal dimensions describing the data and projecting the data at the same time. Furthermore, the problem of data sparsity and high-dimensionality in the context of text analysis is addressed because the resulting representation of the points of the compressed dataset are dense and of low-dimension. Truncated SVD technically requires the setting of the smaller valued k diagonal entries in S to 0.</p><p>The resulting reconstruction U S k kV T has a rank k. Neglecting all but the first k components is justified since the data noise perturbs the small eigenvalues, whereas the first k components supposedly capture the underlying structure of the data. Selecting the cutoff value k defines the so-called model-order selection problem of truncated SVD. In our framework, the selection has been determined through cross-validation.</p><p>Ensemble decision models Ensemble methods <ref type="bibr" coords="5,323.48,368.46,16.05,8.64" target="#b17">[19,</ref><ref type="bibr" coords="5,339.53,368.46,8.02,8.64" target="#b5">6]</ref> are learning algorithms that construct a set of classifiers with new data being classified by an integrating over the resulting set of predictions. The original ensemble method is Bayesian averaging but more recent algorithms include error correcting output coding bagging and boosting. The efficiency of such an approach for non-convex learning model has been often demonstrated by the capability to cope with variance and biases due to the challenging nature of the considered data. For each personality and demographic trait, an ensemble of 10 classifiers is trained and used for inference.</p><p>Sub-data classification Our framework enables these ensemble classifiers to operate at different levels for any given data point -in the case of this challenge a data point is considered to be a single author. In the first instance, a 'user-level' decision consists in inferring a given trait from the compressed representation of an aggregatied view of the features of the entire dataset, i.e. the full set of tweets.</p><p>A second level -in this setting 'tweet-level' -is to submit each sub-data point (i.e. each tweet) for a decision from the inference model. These sub-decisions are then combined to produce an expected decision at the higher level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Machine translation models</head><p>We created machine translation models from English to each one of Spanish, Italian and Dutch, in order to increase the size of the training data of these languages. The details of these models are described below.</p><p>Parallel corpora We wished to use the same setting for all language-pairs. To that end, we chose parallel corpora that are available for all language pairs, namely: the European Parliament proceedings <ref type="bibr" coords="6,271.26,143.22,16.60,8.64" target="#b11">[13]</ref> <ref type="foot" coords="6,287.86,141.55,3.49,6.05" target="#foot_0">1</ref> and the TED<ref type="foot" coords="6,344.94,141.55,3.49,6.05" target="#foot_1">2</ref> talks parallel corpus, WIT3 <ref type="bibr" coords="6,462.50,143.22,10.58,8.64" target="#b3">[4]</ref>. <ref type="foot" coords="6,476.61,141.55,3.49,6.05" target="#foot_2">3</ref>WIT3, consisting of spoken-language transcripts, represents a corpus which is closer in nature to the tweet data used in the challenge. Europarl was chosen mostly for its size. Our combined training data consists of approximately 2 million bi-sentences for each languages-pair, with 50 million tokens for each language. The Europarl corpus accounts for more than 90% of this data. The two corpora were concatenated to create the training data for the MT models.</p><p>Translation System Moses <ref type="bibr" coords="6,243.44,244.93,15.27,8.64" target="#b12">[14]</ref>, a popular, open-source phrase-based MT system <ref type="foot" coords="6,456.45,243.26,3.49,6.05" target="#foot_3">4</ref> , was used to train translation models and translate the tweets data.</p><p>Preprocessing We used the standard Moses tools to preprocess the data, including tokenization, lowercasing and removal of bi-sentences where at least one of the sentences is empty or longer than 80 tokens.</p><p>Recasing and Language models We used SRILM <ref type="bibr" coords="6,342.89,340.75,16.60,8.64" target="#b18">[20]</ref> version 1.7.1 to train 5-gram language models on the target side of the parallel corpus, with modified Kneser-Ney discounting <ref type="bibr" coords="6,184.72,364.67,10.58,8.64" target="#b4">[5]</ref>. A recasing model was trained from the same corpus, with a 3-gram KenLM <ref type="bibr" coords="6,168.55,376.62,16.60,8.64" target="#b10">[12]</ref> language model. Tuning We tuned the translation models using MERT <ref type="bibr" coords="6,357.52,406.60,15.27,8.64" target="#b14">[16]</ref>. For tuning data, we used the development set of the above mentioned campaign consisting of 887 bi-sentences for each language-pair.</p><p>Translation and post-processing Each of the tweets of the PAN training set was preprocessed in the same fashion as was the training data. It was then translated with the trained model of the corresponding language-pair, and finally underwent quick postprocessing, namely recasing and detokenization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we outline our own internal evaluations of our system. First we report experiments into the parameters of our core pipeline. Following this, our experiments in using machine translation to improve performance of the smaller language subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimenting with Learning Framework Parameters</head><p>Training data is first passed through the linguistic processing pipeline as described in section 3.1. Subsequently, the data encoded as features, along with the labels are passed to the learning framework. We experimented with a number of parameters which included:</p><p>numeric representation of the features: binary, normalised, or absolute frequency feature thresholding (only including features with a frequency greater than a set value). dimensionality of the compressed feature space (see section 3.2 for more details) the level of classification decisions: per user, or per tweet.</p><p>For each combination of settings, we employed the following conditions:</p><p>-We use leave-one-out cross-validation on the training data -Due to random seeding in the bagging used in the cross-validation of the SVD calculations (see section 3.2) we run each setting five times, and average the result. -Since age is a scale, we use regression as our classification model. To do this, we convert the classes into an ordered scale: 0, 1, 2, 3. Performance on age is reported as mean-squared error, similar to the personality traits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In the interests of space, we do not report all runs here. Generally, we found that thresholding the feature space at n &gt;= 5 provided the best results, balancing model performance and computational runtime. Similarly, while increasing the dimensionality generally improved performance, too great an increase significantly impacts runtime.</p><p>We report only those experiments on the optimum value across all settings of 500.</p><p>Results are reported in table <ref type="table" coords="7,249.04,438.90,3.74,8.64">3</ref>.</p><p>The most distinct result is gender: across all languages it is the model trained at a per-tweet level using binary representation of feature frequency that performs the best. Conversely, age -though limited to two languages -shows best performance with normalised frequency at a per-user level.</p><p>Results for personality traits are less clear. Overall, the same conditions as for age -per-user, normalised frequency -perform best. In many of the cases in which they do not, the difference in performance is insignificant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimenting with SMT</head><p>Personality labelled data sets can often be smaller than the ones typically used for text classification tasks. This is largely due to the personal nature of the information and the complexity of collecting such labels. This issue of size is particularly clear in the Dutch and Italian datasets (see table <ref type="table" coords="7,254.01,608.59,3.60,8.64" target="#tab_1">2</ref>).</p><p>One alternative approach to collecting personality labels is the use of perception ratings -wherein the personality labels are judgements made by third parties. In this work, we explored another approach to answering the data sparsity question, namely machine translation.  <ref type="table" coords="8,158.90,315.48,3.36,8.06">3</ref>. Results on all language corpora under different feature 'frequency' and classification decision 'level' conditions. Gender is measured in accuracy, age with mean squared error (MSE) and personality traits with root MSE. Bold is used to highlight the best result per language-trait pair.</p><p>Our main approach was to use the largest corpus -the English -to supplement the remaining smaller datasets. The intention was to see if increasing the size of the dataset, by leveraging non-native labelled data, would improve results. The experiments where conducted thus:</p><p>-The English dataset was translated (using the models described in section 3.3) into each of Spanish, Italian and Dutch. -Each enlarged data set was processed using the linguistic pipeline configured for that language. -Using the same settings as described for the native language experiments, similar trait classification models were trained using the combined dataset. The results reported here are on the same "leave-one-out" approach, though only the original native non-English dat was used to compute the reported results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results of these tests can be seen in table <ref type="table" coords="8,351.30,572.16,4.98,8.64" target="#tab_4">4</ref> along with the results from the previous native experiments for comparison. In the interests of space, we have selected the best result for each language-trait pair. Although Spanish is closest in size to the English corpus, it is also included for completeness. Overall, the results suggest that translation does not help in the classification of socio-demographic traits. In fact, in many cases -particularly gender -it is considerably detrimental to performance. Despite previous finding that SMT to assist NLP tasks provides at least 'comparable' results, the effect here is worse than expected. One issue with working in automatic personality classification is understanding how the manifestation of traits varies between data sources <ref type="bibr" coords="9,352.30,292.80,15.27,8.64" target="#b13">[15]</ref>. This likely extends to variations due to language as well. However, we do not enter into further discussion of this topic here, or other aspects which could effect performance such as translation quality. We intend to pursue this in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PAN Challenge</head><p>In delivering models for the official PAN review, we chose models based on our desire to be as language agnostic as we could be. With this in mind, we chose a single, optimised combination of parameters across all traits and languages. The only variation on this is with gender, for which the settings had a significant -and consistentimpact. As per the settings discussed in section 3, the final parameters for the models uploaded to the evaluation platform are listed in table <ref type="table" coords="9,359.96,440.70,3.74,8.64" target="#tab_5">5</ref>. Additionally, we retain the model dimensionality value of 500. Note that though age is a regression in our setting, for the challenge it is converted to a class, rounding the value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Challenge Results</head><p>The global results can be found in the overview paper for the PAN 2015 Author Profiling challenge <ref type="bibr" coords="9,174.94,632.53,15.27,8.64" target="#b16">[18]</ref>. Here we report the results of our system on the evaluation data in table <ref type="table" coords="9,473.11,632.53,3.74,8.64" target="#tab_0">1</ref> The difference between these results and those of our own tests naturally vary. Gender performance on evaluation is overall lower, but personality traits sees both improvements and worsening of performance. There is no clear pattern in this across language or trait, so there are no general conclusions which can be drawn. Large decreases in expected performance of any trait-language pair (for example NL Extraversion, testing: 0.088, evaluation: 0.135) suggests an overfitting of features under training. Despite attempting to minimise this outcome, with corpora of the sizes of Italian and Dutch, this is to be expected.</p><p>We cannot directly compare age, because we used a different metric (MSE compared with accuracy). However, when we compare our performance to others, we see that for English age prediction, we ranked among the lowest in the challenge. It is expected that this is largely due to our choice of regression modelling. As an ordered trait, even performing class-based learning as a regression makes sense. It is clear, however, that our naive approach of rounding our predicted value to a class label does not perform well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this paper we have presented details of XRCE's Personal Language Analytics engine for multi-lingual author profiling. The system we have described leverages our capabilities in natural language processing and machine learning. We have chosen a largely language agnostic approach to this task, which has shown good performance on the four datasets.</p><p>We expect to continue this work, further refining our models. In particular we intend to explore the contribution of the individual categories of linguistic features to classification across languages and traits. This, we expect, will also lead to a further understanding of the nature of the relationship between language and personality traits in Twitter.</p><p>Related to this, we have also discussed the use of machine translation as a potential means to accommodate for the difficulty of acquiring labelled data of this nature. In the limited context explored here, this has not shown to be helpful. This suggests that though sentiment signals can often be maintained under translation (c.f <ref type="bibr" coords="10,426.70,632.53,11.20,8.64" target="#b1">[2]</ref>) the same cannot be said for socio-demographic signals. We intend to look at tuning translation models to be sensitive to these signals, as a step toward personalised translation systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,141.74,644.09,338.86,9.03;3,151.70,656.44,328.89,8.64;4,151.70,119.31,328.89,8.64;4,151.70,131.27,276.31,8.64;4,141.74,143.82,338.86,9.03;4,151.70,156.16,328.89,8.64;4,151.70,168.12,328.89,8.64;4,151.70,180.07,228.73,8.64"><head>-</head><label></label><figDesc>word-level features: unigram, bigram and trigram of surface and lemmatized form of the words; part-of-speech of surface and normalized word; words with negation, words with at least three repeated letters; bigram of repeated character (cc), trigram of repeated character (ccc), quadrigram of repeated characters (cccc); class-based features: named entities (places, persons, organisation, dates and time expressions); unigram, bigram and trigram of POS tags, positive emoticons, negative emoticons, other emoticons; hashtags, mentions and http links; use of feminine or masculine firstnames and pronouns; capitalized words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.77,328.02,345.83,83.79"><head>Table 1 .</head><label>1</label><figDesc>Data  </figDesc><table coords="2,254.07,328.02,107.21,52.01"><row><cell>Language</cell><cell cols="2">Authors Tweets</cell></row><row><cell cols="3">English (EN) 152 14166</cell></row><row><cell cols="2">Spanish (ES) 100</cell><cell>9879</cell></row><row><cell>Italian (IT)</cell><cell>38</cell><cell>3687</cell></row><row><cell>Dutch (NL)</cell><cell>34</cell><cell>3350</cell></row></table><note coords="2,189.53,393.08,291.07,7.77;2,134.77,404.04,57.28,7.77"><p>volume -by number of authors and tweets -across the four languages of the training dataset.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,139.21,205.94,336.95,304.12"><head>Table 2</head><label>2</label><figDesc>summarizes the set of features we retained for each language.</figDesc><table coords="4,139.21,241.11,289.09,201.20"><row><cell>Feature type</cell><cell>en es it nl Examples (for English)</cell></row><row><cell>Surface unigrams, bigrams</cell><cell>uni(going), bi(going to),</cell></row><row><cell>&amp; trigrams</cell><cell>tri(going to talk)</cell></row><row><cell>Lemmatized unigrams, bigrams</cell><cell>unilem(go), bilem(go to),</cell></row><row><cell>&amp; trigrams</cell><cell>trilem(go to talk)</cell></row><row><cell>word with negation</cell><cell>---NEG(nice) in it is not nice</cell></row><row><cell>Lemmatized word &amp; POS</cell><cell>NOUN(dog), VERB(be)</cell></row><row><cell>Bigram, trigram, quadrigrams</cell><cell>bichar(ii), trichar(iii)</cell></row><row><cell>of repeated characters</cell><cell>quadrichar(iiii)</cell></row><row><cell>lemmatized unigrams, bigrams</cell><cell>unipos(VERB), bipos(VERB PREP),</cell></row><row><cell>&amp; trigrams of POS</cell><cell>tripos(VERB PREP VERB)</cell></row><row><cell>Hashtags</cell><cell>HASHTAG</cell></row><row><cell>Http links</cell><cell>HTTPLINK</cell></row><row><cell>mentions</cell><cell>MENTION</cell></row><row><cell>Fully capitalized words</cell><cell>ALLCAP</cell></row><row><cell>Named entities (Pers, Loc, Org,</cell><cell>-Pers, City, Country</cell></row><row><cell>Date, City, Country)</cell><cell>Org, Date</cell></row><row><cell>Time expressions</cell><cell>---</cell></row></table><note coords="4,303.56,434.54,111.34,7.77;4,139.21,445.89,90.91,7.77;4,274.79,445.89,201.36,7.77;4,139.21,457.25,105.95,7.77;4,303.56,457.25,156.25,7.77;4,139.21,468.61,59.52,7.77;4,303.56,469.78,21.36,6.22;4,139.21,479.97,118.79,7.77;4,285.05,479.97,181.03,7.77;4,139.21,491.32,65.28,7.77;4,303.56,491.16,112.94,7.93;4,139.21,502.28,74.69,7.77"><p>TIMEX (e.g. "three days after") Positive or negative word ---POSW (e.g. "awesome"), NEGW (e.g. "disaster") Positive or negative emoticon POSEMOT (e.g. ":&gt;"), NEGEMOT (e.g. ":&lt;") Other emoticons EMOT Feminine or Masculine firstname --FN-FEM, e.g. "Mary", FN-MASC, e.g. "Peter" Word with at least REPEATLET, e.g. for niiiiiiiiiice three repeated letters</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,134.77,522.81,345.83,19.08"><head>Table 2 .</head><label>2</label><figDesc>Features used per language. where en, es, it and nl denote English, Spanish, Italian and Dutch respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,118.07,345.83,128.42"><head>Table 4 .</head><label>4</label><figDesc>Results on the original non-English datasets, compared with a model trained on additional data translated from English. Gender is measured in accuracy, age with mean squared error (MSE) and personality traits with root MSE. Bold is used to highlight the best result per language-trait pair.</figDesc><table coords="9,199.26,118.07,216.84,74.72"><row><cell>Language</cell><cell cols="2">Gender Age T0 T1 T2 T3 T4</cell></row><row><cell>ES</cell><cell cols="2">0.917 0.327 0.153 0.188 0.155 0.156 0.160</cell></row><row><cell cols="3">ES + EN2ES 0.798 0.472 0.175 0.206 0.157 0.146 0.140</cell></row><row><cell>IT</cell><cell>0.893</cell><cell>0.095 0.168 0.142 0.098 0.137</cell></row><row><cell cols="2">IT + EN2IT 0.706</cell><cell>0.115 0.167 0.127 0.117 0.128</cell></row><row><cell>NL</cell><cell>0.852</cell><cell>0.088 0.117 0.118 0.086 0.098</cell></row><row><cell cols="2">NL + EN2NL 0.740</cell><cell>0.103 0.180 0.143 0.122 0.110</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,194.26,485.03,226.83,62.16"><head>Table 5 .</head><label>5</label><figDesc>Summary of the inference models</figDesc><table coords="9,194.26,485.03,226.83,41.34"><row><cell>Trait</cell><cell cols="3">Encoding n Decision level Decision model</cell></row><row><cell>Gender</cell><cell>binary</cell><cell>5 tweet-level</cell><cell>SVM</cell></row><row><cell>Age</cell><cell cols="2">normalised 5 user-level</cell><cell>linear regression</cell></row><row><cell cols="3">Personality Trait normalised 5 user-level</cell><cell>linear regression</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,134.77,632.53,345.82,32.55"><head>Table 6 .</head><label>6</label><figDesc>. As discussed previously age and gender are measured by accuracy, the personality traits by Root Mean Squared Error (RMSE). Results on all language corpora under different feature 'frequency' and classification decision 'level' conditions. Gender and age are reported in accuracy; the remaining traits with root mean squared error (RMSE).</figDesc><table coords="10,206.52,118.07,202.32,52.01"><row><cell cols="2">Language Gender Age EXT STA AGR CON OPN</cell></row><row><cell>EN</cell><cell>0.775 0.165 0.167 0.206 0.165 0.148 0.142</cell></row><row><cell>ES</cell><cell>0.773 0.136 0.158 0.202 0.136 0.146 0.157</cell></row><row><cell>IT</cell><cell>0.806 0.124 0.091 0.215 0.124 0.160 0.169</cell></row><row><cell>NL</cell><cell>0.781 0.109 0.135 0.132 0.109 0.062 0.070</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,144.73,612.68,227.54,7.77"><p>Version 7, from: http://www.statmt.org/europarl/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.73,624.67,96.84,6.31"><p>http://www.ted.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,144.73,634.98,335.86,7.77;6,144.73,646.78,83.44,6.31"><p>Data from IWSLT 2014 evaluation campaign: https://wit3.fbk.eu/mt.php? release=2014-01.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,144.73,657.08,310.79,7.77"><p>Version 3.0, downloaded 16 Feb 2015 from http://www.statmt.org/moses/.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.61,145.28,337.59,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="11,297.80,145.28,116.52,7.77">A multi-input dependency parser</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ait-Mokhtar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Chanod</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Roux</surname></persName>
		</author>
		<editor>IWPT</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,156.72,320.64,7.77;11,150.95,167.68,299.41,7.77;11,150.95,178.64,318.73,7.77;11,150.95,189.60,109.42,7.77;11,150.95,201.40,263.61,6.31" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,239.59,156.72,211.45,7.77">Multilingual sentiment analysis using machine translation?</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Turchi</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2392963.2392976" />
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,167.68,299.41,7.77;11,150.95,178.64,68.50,7.77;11,265.78,178.64,43.19,7.77">Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
	<note>WASSA &apos;12</note>
</biblStruct>

<biblStruct coords="11,142.61,212.00,329.08,7.77;11,150.95,222.95,310.44,7.77;11,150.95,233.91,205.60,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,409.02,212.00,62.67,7.77;11,150.95,222.95,136.48,7.77">The workshop on computational personality recognition</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Celli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">I</forename><surname>Biel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gatica-Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pianesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,324.29,222.95,137.11,7.77;11,150.95,233.91,94.85,7.77">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1245" to="1246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,245.35,164.74,7.77;11,307.35,243.30,3.65,5.24;11,311.50,245.35,161.14,7.77;11,150.95,256.31,140.95,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,290.42,245.35,16.93,7.77;11,307.35,243.30,3.65,5.24;11,311.50,245.35,161.14,7.77;11,150.95,256.31,15.98,7.77">WIT 3 : Web inventory of transcribed and translated talks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,184.58,256.31,81.18,7.77">Proceedings of EAMT</title>
		<meeting>EAMT</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,267.75,306.73,7.77;11,150.95,278.71,316.79,7.77;11,150.95,289.67,161.28,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,242.89,267.75,206.45,7.77;11,150.95,278.71,32.10,7.77">An empirical study of smoothing techniques for language modeling</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,201.52,278.71,266.23,7.77;11,150.95,289.67,84.20,7.77">Proceedings of the 34th annual meeting on Association for Computational Linguistics (ACL 1996)</title>
		<meeting>the 34th annual meeting on Association for Computational Linguistics (ACL 1996)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,301.11,312.75,7.77;11,150.95,312.07,320.87,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,211.80,301.11,140.18,7.77">Ensemble methods in machine learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,369.94,301.11,85.42,7.77;11,150.95,312.07,195.51,7.77">Proceedings of the First International Workshop on Multiple Classifier Systems</title>
		<meeting>the First International Workshop on Multiple Classifier Systems</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,323.51,285.19,7.77;11,139.25,334.95,341.34,7.77;11,150.95,345.91,169.34,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,243.23,323.51,184.56,7.77;11,139.25,334.95,3.36,7.77;11,245.78,334.95,202.79,7.77">taking care of the linguistic features of extraversion 8</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Oberlander</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reinsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,454.19,334.95,26.40,7.77;11,150.95,345.91,96.12,7.77">Journal of Numerical Mathematics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="403" to="420" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
	<note>Singular value decomposition and least squares solutions</note>
</biblStruct>

<biblStruct coords="11,142.61,357.35,332.21,7.77;11,150.95,368.31,308.86,7.77;11,150.95,379.26,57.53,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,299.98,357.35,174.85,7.77;11,150.95,368.31,227.22,7.77">Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Halko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">G</forename><surname>Martinsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,384.31,368.31,51.60,7.77">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="288" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,390.70,329.08,7.77;11,150.95,401.66,327.98,7.77;11,150.95,412.62,315.02,7.77;11,150.95,423.58,165.54,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,264.37,390.70,206.95,7.77;11,150.95,401.66,38.72,7.77">Automatically constructing a normalisation dictionary for microblogs</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,207.99,401.66,270.95,7.77;11,150.95,412.62,315.02,7.77;11,150.95,423.58,19.30,7.77">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012)</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012)<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,435.02,299.30,7.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,201.51,435.02,172.70,7.77">The truncated svd as a method for regularization</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Hansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct coords="11,142.24,446.46,324.40,7.77;11,150.95,457.42,329.38,7.77;11,150.95,468.38,141.96,7.77;11,150.95,480.18,268.99,6.31" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,199.26,446.46,182.68,7.77">KenLM: faster and smaller language model queries</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Heafield</surname></persName>
		</author>
		<ptr target="http://kheafield.com/professional/avenue/kenlm.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,399.90,446.46,66.74,7.77;11,150.95,457.42,234.50,7.77">Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07">July 2011</date>
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,490.78,337.37,7.77;11,150.95,501.74,70.24,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,189.99,490.78,218.29,7.77">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,426.07,490.78,53.54,7.77;11,150.95,501.74,44.10,7.77">Proceedings of MT Summit</title>
		<meeting>MT Summit</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,513.18,336.33,7.77;11,150.95,524.13,329.44,7.77;11,150.95,535.09,299.49,7.77;11,150.95,546.05,57.03,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,432.83,524.13,47.57,7.77;11,150.95,535.09,169.49,7.77">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,338.24,535.09,112.20,7.77;11,150.95,546.05,30.89,7.77">Proc. of ACL Demo and Poster Sessions</title>
		<meeting>of ACL Demo and Poster Sessions</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,557.49,331.73,7.77;11,150.95,568.45,313.72,7.77;11,150.95,579.41,304.36,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,234.42,557.49,239.55,7.77;11,150.95,568.45,54.87,7.77">Look! Who&apos;s Talking? Projection of Extraversion Across Different Social Contexts</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Gill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,224.05,568.45,240.62,7.77;11,150.95,579.41,278.21,7.77">Proceedings of WCPR14, Workshop on Computational Personality Recognition at ACMM (22nd ACM International Conference on Multimedia)</title>
		<meeting>WCPR14, Workshop on Computational Personality Recognition at ACMM (22nd ACM International Conference on Multimedia)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,590.85,334.74,7.77;11,150.95,601.81,319.77,7.77;11,150.95,612.77,132.63,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,187.34,590.85,218.31,7.77">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,423.44,590.85,53.54,7.77;11,150.95,601.81,255.04,7.77">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">ACL 2003. 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,624.21,326.77,7.77;11,150.95,635.17,323.51,7.77;11,150.95,646.13,99.37,7.77;11,150.95,657.93,231.33,6.31" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,250.09,624.21,218.91,7.77;11,150.95,635.17,194.09,7.77">Measuring personality in one minute or less: A 10-item short version of the big five inventory in english and german</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Rammstedt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">P</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jrp.2006.02.001</idno>
		<ptr target="http://dx.doi.org/10.1016/j.jrp.2006.02.001" />
	</analytic>
	<monogr>
		<title level="j" coord="11,351.44,635.17,123.02,7.77">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="203" to="212" />
			<date type="published" when="2007-02">Feb 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,119.96,334.36,7.77;12,150.95,130.92,309.56,7.77;12,150.95,141.88,323.18,7.77;12,150.95,152.84,98.46,7.77;12,150.95,164.64,296.89,6.31" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,404.50,119.96,72.10,7.77;12,150.95,130.92,115.01,7.77">Overview of the 3rd author profiling task at pan 2015</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Celli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="12,173.36,141.88,117.33,7.77">CLEF 2015 Labs and Workshops</title>
		<title level="s" coord="12,297.17,141.88,176.96,7.77;12,150.95,152.84,19.77,7.77">Notebook Papers. CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>San Juan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015-09">Sep 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,174.76,326.62,7.77;12,150.95,185.71,23.90,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,199.76,174.76,117.42,7.77">The strength of weak learnability</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,322.69,174.76,139.44,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,196.67,329.02,7.77;12,150.95,207.63,280.33,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,195.69,196.67,177.22,7.77">SRILM -an extensible language modeling toolkit</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,390.57,196.67,80.69,7.77;12,150.95,207.63,203.25,7.77">Proceedings Int. Conf. on Spoken Language Processing (INTERSPEECH 2002)</title>
		<meeting>Int. Conf. on Spoken Language Processing (INTERSPEECH 2002)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="257" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,218.59,332.52,7.77;12,150.95,229.55,303.36,7.77;12,150.95,240.51,141.05,7.77" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tkalčič</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Carolis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Gemmis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Odić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Košir</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
		<title level="m" coord="12,382.22,218.59,76.30,7.77;12,150.95,229.55,303.36,7.77;12,150.95,240.51,57.41,7.77">Proceedingsof the 2nd Workshop Emotions and Personality in Personalized Services (EMPIRE 2014)</title>
		<meeting>of the 2nd Workshop Emotions and Personality in Personalized Services (EMPIRE 2014)</meeting>
		<imprint>
			<date>July</date>
		</imprint>
	</monogr>
	<note>Preface: Empire 2014</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
