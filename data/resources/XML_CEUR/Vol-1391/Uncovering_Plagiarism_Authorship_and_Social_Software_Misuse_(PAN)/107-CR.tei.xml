<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.76,115.90,319.83,12.90;1,250.83,133.83,113.71,12.90;1,223.43,153.83,168.50,10.75">A Generic Authorship Verification Scheme Based on Equal Error Rates Notebook for PAN at CLEF 2015</title>
				<funder>
					<orgName type="full">EWV</orgName>
				</funder>
				<funder ref="#_PTW2vVe">
					<orgName type="full">German state government of Hesse</orgName>
				</funder>
				<funder ref="#_aqbnQm8">
					<orgName type="full">German Federal Ministry of Education and Research (BMBF)</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Advanced Security Research Darmstadt CASED</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,238.00,190.38,53.70,8.64"><forename type="first">Oren</forename><surname>Halvani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.07,190.38,66.29,8.64"><forename type="first">Christian</forename><surname>Winter</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.76,115.90,319.83,12.90;1,250.83,133.83,113.71,12.90;1,223.43,153.83,168.50,10.75">A Generic Authorship Verification Scheme Based on Equal Error Rates Notebook for PAN at CLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D34D060F5EA82C47F9C3308EF1F20223</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a generic authorship verification scheme for the PAN-2015 identification task. Our scheme uses a two-step training phase on the training corpora. The first phase learns individual feature category parameters as well as decision thresholds based on equal error rates. The second phase builds feature category ensembles which are used for majority vote decisions because ensembles can outperform single feature categories. All feature categories used in our method are very simple to gain multiple advantages: Our method is entirely independent of any external linguistic resources (even word lists), and hence it can easily applied to many languages. Moreover, the classification is very fast due to simple features. Additionally, we make use of parallelization. The evaluation of our scheme on a 40% split (which we did not use for training) of the official PAN-2015 training corpus led to an average corpus accuracy of 68.12%; in detail 60% for the Dutch, 67.5% for the English, 60% for the Greek and 85% for the Spanish subcorpus. The overall computation runtime was approximately 27 seconds.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship analysis forms a sub-discipline of digital text forensics (a branch of digital forensics). Authorship attribution (AA) and authorship verification (AV) can be seen as the two major disciplines of authorship analysis <ref type="bibr" coords="1,327.54,500.71,10.58,8.64" target="#b4">[4]</ref>.</p><p>AA deals with the problem of attributing a given anonymous text to exactly one author, given a training set of authors for which text samples of undisputed authorship are available <ref type="bibr" coords="1,189.00,536.73,10.58,8.64" target="#b4">[4]</ref>. AV, on the other hand, aims to determine whether a given text was written by a certain author A <ref type="bibr" coords="1,261.43,548.69,10.58,8.64" target="#b4">[4]</ref>. The training set in this case comprises only text samples from the supposed author A, that can be analyzed for distinct features that make up the writing style of A. If it differs significantly from the writing style of the given text, the authorship is considered as false, otherwise true. AVcan be understood as a specialized task of AA with an open set of candidate authors. Conversely, AA can be treated as a sequence of verification problems regarding the given candidate authors <ref type="bibr" coords="1,134.77,620.42,11.62,8.64" target="#b2">[2]</ref> and should be solvable if the verification problem is solved <ref type="bibr" coords="1,386.30,620.42,10.58,8.64" target="#b3">[3]</ref>.</p><p>In this work we propose a new intrinsic AV method that offers a number of benefits. The method provides a universal threshold per language and feature category, used to accept or reject the alleged authorship of a document. Here, universal refers to the ability to generalize across different genres and topics of the texts. In addition, the model generated by the method is highly flexible and can be extended incrementally in order to handle new languages, genres, topics or features. Besides, the method neither requires complex machine learning algorithms nor error-prone natural language processing techniques nor external linguistic resources. Furthermore, it features a very low computational complexity, compared to other existing approaches (including our previous PAN-approaches).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Features</head><p>Features are the core of any AV method. Without features it is not possible to model individual writing styles of authors. Many researchers across different fields (linguistics, computer science, mathematics, etc.) have attempted to distinguish features in various ways. As a result, features have been classified into topic features, non-topic features, stylistic features, lexical features, syntactic features, semantic features, etc. In order to avoid using these terms, which can be very misleading, we decided to use the generic term of features, which we sub-categorize into so-called feature categories. Regarding our approach, we make use of nine feature categories, which are listed in Table <ref type="table" coords="2,454.37,335.68,3.74,8.64" target="#tab_0">1</ref>.</p><formula xml:id="formula_0" coords="2,136.68,369.92,38.83,9.72">F i Name</formula><p>Feature description Parameter range F 1 Punctuation n-grams A sequence of n consecutive punctuation marks (commas, hyphens, etc.) taken from D after reduction to punctuation characters. The extraction of features from a text can be performed on any linguistic layer (e.g., character layer, morphological layer, lexical layer, syntactic layer or semantic layer). Depending on the layer, different tools are required for the extraction process. For example, extracting features from the lexical layer, involves tokenizers, stemmers, or lemmatizers while extracting features from the semantic layer requires part-of-speech taggers, parsers, or thesauri <ref type="bibr" coords="3,212.78,179.09,10.58,8.64" target="#b4">[4]</ref>.</p><p>A feature can be explicit, i.e extracted directly from the text, or implicit, i.e. extracted after the text has been preprocessed. Simple letters, for example, can be seen as explicit features, as they can be looked up in the text itself. In contrast, more complex features like part-of-speech tags (adjectives, articles, pronouns, etc.) are implicit, since they are not annotated in the text and thus can only be extracted after the text has been preprocessed. In our method we focused only on explicit features, extracted from the first four mentioned layers. There are a number of reasons for this decision:</p><p>1. A previous observation <ref type="bibr" coords="3,247.17,288.89,11.62,8.64" target="#b0">[1]</ref> has shown that implicit features not necessarily lead to promising results in contrast to explicit features (for example character n-grams).</p><p>2. Implicit features rely often on natural language processing models that are bounded to only one language and thus are not generalizable.</p><p>3. Implicit features often cause a high computation runtime since various types of natural language processing techniques are utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Used corpora</head><p>In this section we present the training and test corpora used by our method and describe their inner structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training and test corpora</head><p>In order to construct and evaluate our AVmodel, we used the publicly released PAN-2015 training data set<ref type="foot" coords="3,222.41,511.67,3.49,6.05" target="#foot_0">1</ref> denoted by C Pan15 . This corpus is divided into four subcorpora C Dutch , C English , C Greek and C Spanish , where each sub corpus consists of 100 problems {ρ 1 , ρ 2 , . . . , ρ 100 }.</p><p>During the time our method was created and trained, the official test corpus has not been released. Hence, we used 60% of each subcorpus as a training and the remaining 40% as a test corpus.</p><p>We denote<ref type="foot" coords="3,191.86,585.88,3.49,6.05" target="#foot_1">2</ref> the training corpus as C Train = {C Tr-Dutch , C Tr-English , C Tr-Greek , C Tr-Spanish } and the test corpus as C Test = {C Te-Dutch , C Te-English , C Te-Greek , C Te-Spanish }. C Train serves exclusively to construct the models (parameters, thresholds and ensembles) while C Test is used to test our AVscheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Corpus inner structure</head><p>The inner structure of the used corpora (whether training or testing) in our method is described as follows. A corpus C comprises a set of problems {ρ 1 , ρ 2 , . . .}, where a problem ρ = (D A ? , D A ) consists of a questioned document D A ? and a set of known documents D A . The number of known documents in each problem ρ varies from one to five documents. The lengths of the texts in these corpora vary between a few hundred and a few thousand words. The distribution of true and false authorships in each corpus is uniform <ref type="foot" coords="4,176.00,210.26,3.49,6.05" target="#foot_2">3</ref> . We denote a true authorship by Y and a false authorship by N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our method</head><p>In this section we explain first which kind of preprocessing is applied on the training and test corpora. Next, we introduce both models our method relies on, and finally, we describe the treatment of verification problems in the test corpora which involves (among other things) similarity calculation and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preprocessing</head><p>Given some corpus C, for each document D within C, we replace newlines, tabs and multiple spaces by only one space. This enables a better extraction of several features, as for instance, character n-grams. Furthermore, we concatenate all known documents within each problem ρ into one document, such that (from now on) each ρ consists only of the two documents D A and D A ? . Besides this, no other preprocessing techniques are applied on the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model training</head><p>Our AVscheme depends on two models that are learned on each training corpus C ∈ C Train mentioned in Section 3. The first model, denoted as M F , includes those parameters for each feature category (listed in Table <ref type="table" coords="4,327.24,492.64,4.15,8.64" target="#tab_0">1</ref>) that lad to the highest accuracy on C. Moreover, M F includes for each feature category F i ∈ F a threshold θ Fi , which is determined as threshold of the equal error rate (EER). The second model, denoted as M E , builds on M F and includes for each corpus C an ensemble of feature categories F 1 , F 2 , . . . , F 9 that lad to the highest accuracy.</p><p>Constructing M F In order to construct the feature category model M F , we use the Algorithms 1-6. Note that some specific methods are not listed, as for instance Length() or LanguageOfCorpus(C) as the semantics behind these methods is obvious.</p><p>Constructing M E In order to construct the ensemble model M E , we use the Algorithms 7-8.</p><formula xml:id="formula_1" coords="5,149.71,152.41,316.62,105.47">Input: F = {F 1 , F 2 , . . . , F 9 }, C Train = {C Tr-Dutch , C Tr-English , C Tr-Greek , C Tr-Spanish } Output: M F for F ∈ F do // Semantic: Language → (n, k), (θ F , C Accuracy ) ThresholdDictionary ← { , ( , ), ( , ) } for C ∈ C Train do L ← LanguageOfCorpus(C) //</formula><p>The first empty tuple denotes the (n, k) parameters. // The second empty tuple denotes (θ F , C Accuracy ). ThresholdDictionary.Add( L, ( , ), ( , ) ) </p><formula xml:id="formula_2" coords="5,180.39,297.43,265.90,73.91">ThresholdLanguageDictionary ← ThresholdDictionary[L] for k ∈ F 's k-interval do for n ∈ F 's n-interval do θ F ← DetermineThreshold(C, F, n, k) C Accuracy ← CalculateCorpusAccuracy(C, θ F , F, n, k) ThresholdLanguageDictionary.Add( (n, k), (θ F , C<label>Accuracy</label></formula><formula xml:id="formula_3" coords="8,149.71,205.68,303.67,367.57">Input: C, F, n, k Output: θ F if Length(Y) = Length(N) then Exception("The number of Y -does not equal the number of N -cases !") len ← Length(Y ) i ← 0 j ← len -1 θ F ← 0.5 for k ← 0, k &lt; len, k++ do if Y [i] &lt; N [j] then i++ j-- continue if Y [i] == N [j] then θ F ← Y [i] break if Y [i] &gt; N [j] then if i == 0 &amp;&amp; j == len -1 then θ F ← (Y [i] + N [j])/2 else min ← Min(Y [i], N [j + 1]) max ← Max(Y [i -1], N [j]) θ F ← (min + max)/2 break end if i == len then θ F = (Y [i -1] + N [j + 1])/2 return θ F Algorithm 5: DetermineThresholdViaEER(Y, N ). Input: C, θ F , F, n, k Output: C Accuracy truePositives ← 0 Problem2SimilarityDictionary ← ComputeProblemsSmilarities(C, F, n, k)</formula><p>for ρ, (F, sim, trueAuthor) in Problem2SimilarityDictionary do predictedAuthor ← "Undefined"</p><formula xml:id="formula_4" coords="9,165.05,208.53,110.57,44.89">if sim &gt; θ F then predictedAuthor ← "Y" else if sim &lt; θ F then predictedAuthor ← "N"</formula><p>if predictedAuthor == trueAuthor then truePositives++ end</p><formula xml:id="formula_5" coords="9,149.71,301.30,266.29,53.40">C Accuracy = 100 |C| • truePositives return C Accuracy Algorithm 6: CalculateCorpusAccuracy(C, θ F , F, n, k).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model testing</head><p>Now that we have constructed the models we need also to test them. This is done in Algorithm 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In this section we describe the evaluation results. First, we present the models M F and M E learned from the training corpora C Train = {C Tr-Dutch , C Tr-English , C Tr-Greek , C Tr-Spanish }. Afterwards, we show (given both pre-trained models) the evaluation results on the test corpora C Test = {C Te-Dutch , C Te-English , C Te-Greek , C Te-Spanish }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Determining M F</head><p>The training on C Train led to the model M F = {M F1 , M F2 , . . . , M F9 } which is given in the Tables 2-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Determining M E</head><p>Given M F , C Train and F as an input, we applied ConstructM E (M F , C Train , F) on all training subcorpora. The resulting model M E is given in Table <ref type="table" coords="9,388.05,656.44,8.30,8.64" target="#tab_11">11</ref>.   </p><formula xml:id="formula_6" coords="10,149.71,225.33,85.24,57.65">Input: M F , C Train , F Output: M E M E ← { } //</formula><formula xml:id="formula_7" coords="11,149.71,253.55,242.07,296.93">for ρ ∈ C do M F ← LoadModelFromM F (F ) n ← LoadNFromM F () k ← LoadKFromM F () θ F ← LoadThresholdFromM F () sim ← ComputeProblemSmilarity(C, F, n, k) F pairings .Add( ρ, (θ F , sim) ) end end return F pairings Algorithm 8: ConstructF pairings (M F , C, F). Input: M F , M E , C Test , F Output: for C ∈ C Test do F pairings ← ConstructF pairings (M F , C, F) L ← LanguageOfCorpus(C) E ←</formula><formula xml:id="formula_8" coords="13,246.88,144.63,121.59,61.68">C E (Ensemble) C Tr-Dutch {F 1 , F 8 , F 9 } C Tr-English {F 1 } C Tr-Greek {F 1 , F 3 , F 4 , F 6 , F 7 } C Tr-Spanish {F 1 , F 4 , F 6 }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation of the models</head><p>The evaluation of our approach (based on the pre-trained models M F and M E ) on the test corpus C Test led to the results, listed in Table <ref type="table" coords="13,331.68,266.88,8.30,8.64" target="#tab_12">12</ref>. The runtime needed for the entire evaluation was 27 seconds. We presented a generic and fast authorship verification scheme for the Author Identification task within the PAN-2015 competition. Our method provides a number of benefits. The most important benefit (in comparison to our previous PAN-approaches) is that our method finally makes use of trainable models. These models not only contribute to the low runtime since thresholds do not need to be computed over and over again, but also can be extended incrementally and so enable a better generalization in terms of languages, genres or topics. Another benefit that directly comes from the (transparent) models is that it makes the approach better interpretable as one is able to inspect the effects of the different feature category parameters as well as the decision thresholds. In future work we will focus on this detail. A further benefit of our method is that there is no need for deep linguistic processing (e.g., POS-tagging, chunking or parsing) or linguistic resources such as word lists, word-nets, thesauruses, etc. This causes not only a low runtime but also makes the method portable. Besides this, the method can be modified easily regarding its underlying components. For example, the distance function can be replaced by an ensemble of distance functions with almost no effort.</p><p>However, there are also many open issues in our approach that leave room for improvement. Here, the most important issue is that at the moment our method is difficult to comprehend, which makes it complicated to understand and implemented by others. Therefore, it is planed in future work to re-factor the algorithms in order to make the scheme more compact.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,446.78,361.69,17.43,8.96;5,195.73,374.57,15.50,8.96;5,180.39,387.53,15.50,8.96;5,165.05,400.48,15.50,8.96;5,165.05,416.99,304.63,10.04;5,182.98,428.94,286.52,8.74;5,182.98,440.90,250.40,9.65;5,182.98,452.85,83.54,8.74;5,460.77,454.11,11.95,8.76;5,165.05,469.29,230.96,10.04;5,182.98,481.24,57.91,9.65;5,240.89,485.66,33.47,4.91;5,274.87,481.24,9.85,8.74;5,165.05,505.08,143.28,8.96;5,180.39,517.11,145.82,8.96;5,180.39,533.55,289.50,9.65;5,180.39,545.50,220.43,9.64;5,180.39,561.94,125.14,10.04;5,165.05,574.82,15.50,8.96;5,149.71,587.77,15.50,8.96;5,149.71,604.21,47.04,10.11;5,223.42,618.05,161.05,10.11;6,149.71,179.80,66.03,8.96;6,149.71,196.23,45.99,9.72;6,149.71,217.23,297.41,8.96;6,149.71,229.18,218.26,8.96;6,149.71,241.45,121.22,8.64;6,149.71,257.57,287.31,8.96;6,149.71,269.53,288.40,8.96;6,149.71,285.97,170.84,9.65;6,149.71,302.34,39.56,9.72;6,210.74,316.23,186.40,9.03;6,149.71,460.97,66.03,8.96;6,149.71,477.41,157.48,9.03;6,149.71,498.40,144.64,8.96;6,149.71,510.28,51.13,8.96;6,165.05,522.31,156.79,10.32;6,322.83,522.31,53.77,9.65;6,165.05,534.27,106.66,8.96;6,165.05,546.22,245.80,8.96;6,149.71,559.10,15.50,8.96;6,149.71,575.54,151.14,8.96;6,193.29,589.98,221.30,9.03;7,149.71,232.83,46.37,10.39;7,197.08,232.90,50.15,9.65;7,149.71,249.26,157.48,9.03;7,149.71,270.26,182.33,9.65;7,149.71,282.21,17.30,10.32;7,168.01,282.21,135.71,10.32;7,304.71,282.21,34.76,8.74;7,149.71,298.65,150.44,9.65;7,149.71,310.74,220.98,9.51;7,149.71,322.56,17.30,10.32;7,168.01,322.56,135.86,8.74;7,149.71,334.83,182.76,10.00;7,333.46,334.66,40.94,8.59;7,149.71,350.95,219.05,9.65;7,149.71,362.91,168.06,9.65;7,149.71,379.35,118.70,9.65;7,149.71,391.44,225.59,9.51;7,149.71,403.26,17.30,10.32;7,168.01,403.26,104.12,8.74;7,149.71,415.53,101.58,10.00;7,252.29,415.35,126.72,8.59;7,149.71,431.65,158.46,9.65;7,149.71,443.61,40.52,10.32;7,191.23,443.75,119.62,8.59;7,149.71,461.65,27.03,8.74;7,182.42,454.23,7.07,6.12;7,179.50,472.46,12.91,6.12;7,194.07,461.65,183.19,8.74;7,149.71,490.64,26.29,8.74;7,193.25,483.90,4.98,8.74;7,179.96,497.47,31.55,8.74;7,217.69,491.89,209.21,7.01;7,149.71,524.03,43.67,8.96;7,182.53,536.55,185.56,10.39;7,369.09,536.62,56.26,9.65"><head>1 :</head><label>1</label><figDesc>we construct the model M F , which holds for each language (represented through C) those (n, k) parameters and θ F that lead to the highest accuracy on C.* / M F ← { (), ( , , , ) } // Semantic: Language → (n, k, θ F , C Accuracy ).for entry ∈ ThresholdDictionary do L ← LanguageOfCorpus(entry.Key) promisingTuple ← Select the tuple (n, k, θ F , C Accuracy ) from entry where C Accuracy is the maximum among all tuples within entry.M F .Add((L, promisingTuple)) end end return M F Algorithm Construct the M F model. Input: C, F, n, k Output: θ F Problem2SimilarityDictionary ← ComputeProblemsSmilarities(C, F, n, k)psaList ← Select all tuples (ρ, sim, trueAuthor) from Problem2SimilarityDictionary Y = psaList.Filter(trueAuthor == "Y").Select(sim).OrderByAscending() N = psaList.Filter(trueAuthor == "N").Select(sim).OrderByAscending()θ F ← DetermineThresholdViaEER(Y, N ); return θ F Algorithm 2: DetermineThreshold(C, F, n, k).Input: C, F, n, kOutput: Problem2SimilarityDictionaryProblem2SimilarityDictionary = { } for ρ ∈ C do sim ← ComputeProblemSmilarity(D A ? , D A , F, n, k) trueAuthor ← GetTruth(ρ)Problem2SimilarityDictionary.Add( ρ, (F, sim, trueAuthor) ) end return Problem2SimilarityDictionaryAlgorithm 3: ComputeProblemsSmilarities(C, F, n, k).Input: D A ? , D A , F, n, k Output: Problem2SimilarityDictionary D A -Features ← ExtractFeatures(D A , F, n, k) D A ? -Features ← ExtractFeatures(D A ? , F, n, k) D A -NormalizedFeatureDictionary ← NormalizeFeaturesByRelativeFrequency(D A -Features) D A ? -NormalizedFeatureDictionary ← NormalizeFeaturesByRelativeFrequency(D A ? -Features) Vocabulary ← D A -NormalizedFeatureDictionary.Keys ∪ D A -NormalizedFeatureDictionary.Keys D A -VocabularyDictionary ← Restrict2Vocabulary(D A -NormalizedFeatureDictionary) D A ? -VocabularyDictionary ← Restrict2Vocabulary(D A ? -NormalizedFeatureDictionary) X ← D A -VocabularyDictionary.Values Y ← D A ? -VocabularyDictionary.Values dist ← m i=1 |X[i] -Y [i]| // Manhattan Distance sim ← 1 1 + dist // Linear similarity transformation return sim Algorithm 4: ComputeProblemSmilarity(D A ? , D A , F, n, k).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,136.56,384.74,342.24,266.79"><head>Table 1 :</head><label>1</label><figDesc>The nine feature categories used in our AVscheme.</figDesc><table coords="2,399.21,493.53,60.85,8.74"><row><cell>k ∈ {1, 2, 3, 4}</cell></row></table><note coords="2,399.21,384.74,74.61,8.74;2,136.56,432.95,88.93,9.65;2,249.06,432.95,146.97,8.96;2,249.06,444.91,37.57,8.96;2,399.21,432.95,74.61,8.74;2,136.56,457.26,92.44,9.65;2,249.06,457.26,146.96,8.96;2,249.06,469.22,146.96,8.96;2,249.06,481.49,95.37,8.64;2,399.21,457.26,79.59,8.74;2,136.56,493.53,81.32,9.65;2,249.06,493.53,129.07,8.96"><p>n ∈ {1, 2, . . . , 10} F 2 Character n-grams A sequence of n consecutive characters in D. n ∈ {1, 2, . . . , 10} F 3 n% frequent tokens The n% most frequently occurring tokens in D (for n ≈ 30 that will be mostly function words). n ∈ {5, 10, . . . , 50} F 4 Token k-prefixes The first k characters of a token.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,149.71,275.97,313.32,278.67"><head></head><label></label><figDesc>SuitableEnsembles includes only odd-numbered ensembles due to a majority voting.SuitableEnsembles = GetFeatureCategoriesPowerSet(F) for C ∈ C Train do F pairings ← ConstructF pairings (M ConstructM E (M F , C Train , F).</figDesc><table coords="10,149.71,403.55,313.32,149.93"><row><cell>featureCategoryComboAccuracy.Add((ensemble, corpusAccuracy)) end featureCategoryComboAccuracy ← Sort all entries (ensemble, corpusAccuracy) ∈ featureCategoryComboAccuracy by descending, according to corpusAccuracy. E ← Select the most promising ensemble from featureCategoryComboAccuracy, which led to the highest corpusAccuracy M E .Add(bestEnsemble) end return M E Output: F pairings // Semantics: F → { ρ, (θ F , sim) }. F pairings ← { (), (, ) } for F ∈ F do F pairings ← { (), (, ) } Algorithm 7: Input: M F , C, F F pairings .Add( F, F pairings )</cell></row></table><note coords="10,295.91,327.02,30.80,10.04;10,165.05,338.97,231.13,8.74;10,165.05,350.93,181.75,8.96;10,165.05,367.30,151.94,8.96;10,180.39,379.32,275.17,8.96;10,180.39,391.28,271.76,8.96"><p>F , C, F) // Semantic: ensemble → corpusAccuracy featureCategoryComboAccuracy← { (), () } for ensemble ∈ SuitableEnsembles do predictions ← CreateFeatureCategoryEnsembleResults(ensemble, C) corpusAccuracy ← EvaluatePredictionsViaTruthFile(predictions, C)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,142.24,541.75,338.35,90.99"><head>Table 2 :</head><label>2</label><figDesc>Select the most promising ensemble from M E , for C with respect to L The M F1 model.</figDesc><table coords="11,142.24,553.70,338.35,79.04"><row><cell>predictions ← CreateFeatureCategoryEnsembleResults(E, C)</cell></row><row><cell>C Accuracy ← EvaluatePredictionsViaTruthFile(predictions, C)</cell></row><row><cell>Print(predictions, C Accuracy )</cell></row><row><cell>end</cell></row><row><cell>Algorithm 9: Apply the AVscheme, based on the pre-trained models, on test corpora</cell></row><row><cell>C Test .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="12,159.31,186.94,263.32,99.74"><head>Table 3 :</head><label>3</label><figDesc>The M F2 model.</figDesc><table coords="12,159.31,225.04,106.53,61.64"><row><cell>C</cell><cell cols="2">n θ F3 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 10 0,46 66.67 %</cell></row><row><cell cols="3">C Tr-English 5 0,43 56.67 %</cell></row><row><cell cols="3">C Tr-Greek 45 0,45 76.67 %</cell></row><row><cell cols="2">C Tr-Spanish 10 0,57</cell><cell>70 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,160.63,225.04,261.44,78.82"><head>Table 4 :</head><label>4</label><figDesc>The M F3 model.</figDesc><table coords="12,319.30,225.04,102.77,61.64"><row><cell>C</cell><cell cols="2">k θ F4 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 1 0,65 66.67 %</cell></row><row><cell cols="3">C Tr-English 4 0,37 63.33 %</cell></row><row><cell cols="2">C Tr-Greek 2 0,56</cell><cell>70 %</cell></row><row><cell cols="3">C Tr-Spanish 1 0,79 83.33 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="12,161.19,294.21,261.44,99.74"><head>Table 5 :</head><label>5</label><figDesc>The M F4 model.</figDesc><table coords="12,161.19,332.31,102.77,61.64"><row><cell>C</cell><cell cols="2">k θ F5 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 3 0,44 63.33 %</cell></row><row><cell cols="2">C Tr-English 2 0,51</cell><cell>60 %</cell></row><row><cell cols="3">C Tr-Greek 1 0,77 76.67 %</cell></row><row><cell cols="3">C Tr-Spanish 3 0,51 66.67 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,160.63,332.31,266.58,78.82"><head>Table 6 :</head><label>6</label><figDesc>The M F5 model.</figDesc><table coords="12,314.16,332.31,113.04,61.64"><row><cell>C</cell><cell cols="2">n k θ F6 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 1 2 0,40 63.33 %</cell></row><row><cell cols="3">C Tr-English 3 2 0,34 56.67 %</cell></row><row><cell cols="2">C Tr-Greek 4 2 0,33</cell><cell>70 %</cell></row><row><cell cols="3">C Tr-Spanish 4 2 0,33 71.67 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,156.05,401.48,266.58,99.74"><head>Table 7 :</head><label>7</label><figDesc>The M F6 model.</figDesc><table coords="12,156.05,439.59,113.05,61.64"><row><cell>C</cell><cell cols="2">n k θ F7 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 1 2 0,50 66.67 %</cell></row><row><cell cols="3">C Tr-English 2 2 0,35 66.67 %</cell></row><row><cell cols="2">C Tr-Greek 1 2 0,58</cell><cell>80 %</cell></row><row><cell cols="3">C Tr-Spanish 4 3 0,33 66.67 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,160.63,439.59,266.58,78.82"><head>Table 8 :</head><label>8</label><figDesc>The M F7 model.</figDesc><table coords="12,314.16,439.59,113.04,61.64"><row><cell>C</cell><cell cols="2">n k θ F8 C Accuracy</cell></row><row><cell cols="3">C Tr-Dutch 2 3 0,34 73.33 %</cell></row><row><cell cols="3">C Tr-English 3 2 0,34 66.67 %</cell></row><row><cell cols="3">C Tr-Greek 2 1 0,43 76.67 %</cell></row><row><cell cols="2">C Tr-Spanish 1 1 0,62</cell><cell>80 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="12,318.74,508.76,103.89,9.65"><head>Table 9 :</head><label>9</label><figDesc>The M F8 model.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="12,251.16,556.45,113.05,78.95"><head>Table 10 :</head><label>10</label><figDesc>The M F9 model.</figDesc><table coords="12,251.16,573.76,113.05,61.64"><row><cell>C</cell><cell cols="2">n k θ F9 C Accuracy</cell></row><row><cell cols="2">C Tr-Dutch 1 1 0,45</cell><cell>70 %</cell></row><row><cell cols="2">C Tr-English 3 1 0,35</cell><cell>60 %</cell></row><row><cell cols="3">C Tr-Greek 4 1 0,35 76.67 %</cell></row><row><cell cols="2">C Tr-Spanish 1 1 0,60</cell><cell>80 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="13,235.69,127.36,143.97,9.81"><head>Table 11 :</head><label>11</label><figDesc>The M E model for C Train .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="13,134.77,320.07,306.18,152.96"><head>Table 12 :</head><label>12</label><figDesc>Results after applying the M F and M E models on C Test .</figDesc><table coords="13,134.77,337.33,221.62,135.70"><row><cell>C</cell><cell>Accuracy</cell></row><row><cell>C Te-Dutch</cell><cell>60 %</cell></row><row><cell>C Te-English</cell><cell>67.5 %</cell></row><row><cell>C Te-Greek</cell><cell>60 %</cell></row><row><cell>C Te-Spanish</cell><cell>85 %</cell></row><row><cell>C Test</cell><cell>∅ = 68.12 %</cell></row><row><cell>6 Conclusion and future work</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,645.77,305.61,7.93"><p>The original file name is pan15-authorship-verification-training-dataset-2015-04-19.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,656.74,326.03,8.43"><p>The prefixes Tr and Te denote if a corpus C ∈ (CTrain ∪ CTest) is a training or a test corpus.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,657.08,318.74,7.77"><p>Note that the uniform Y / N distribution is important for the training phase of our method.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work was supported by the <rs type="funder">Center for Advanced Security Research Darmstadt CASED</rs> (www.CASED.de), funded by the <rs type="funder">German state government of Hesse</rs> under the <rs type="programName">LOEWE program</rs> and by the <rs type="funder">German Federal Ministry of Education and Research (BMBF)</rs> in the funded projects <rs type="projectName">ALPhA</rs> and <rs type="funder">EWV</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PTW2vVe">
					<orgName type="program" subtype="full">LOEWE program</orgName>
				</org>
				<org type="funded-project" xml:id="_aqbnQm8">
					<orgName type="project" subtype="full">ALPhA</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="14,138.13,288.33,316.00,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="14,236.88,288.33,182.63,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,146.47,299.29,334.12,7.77;14,146.47,310.25,297.95,7.77;14,146.47,321.21,82.77,7.77;14,146.47,333.01,314.02,6.31" xml:id="b1">
	<analytic>
		<ptr target="http://ceur-ws.org/Vol-1179/CLEF2013wn-PAN-JuolaEt2013.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="14,321.50,299.29,154.66,7.77">Working Notes for CLEF 2013 Conference</title>
		<title level="s" coord="14,295.14,310.25,107.26,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
			<biblScope unit="volume">1179</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.13,343.12,337.56,7.77;14,146.47,354.08,186.12,7.77;14,146.47,365.88,247.47,6.31" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,319.79,343.12,155.90,7.77;14,146.47,354.08,38.42,7.77">The &quot;Fundamental Problem&quot; of Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
		<idno type="DOI">10.1080/0013838X.2012.668794</idno>
		<ptr target="http://dx.doi.org/10.1080/0013838X.2012.668794" />
	</analytic>
	<monogr>
		<title level="j" coord="14,190.63,354.08,56.05,7.77">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="284" to="291" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.13,376.00,328.30,7.77;14,146.47,386.96,81.43,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,232.69,376.00,199.70,7.77">Determining if Two Documents are by the Same Author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,438.57,376.00,27.86,7.77">JASIST</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,138.13,397.92,333.91,7.77;14,146.47,408.88,131.85,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,202.76,397.92,190.36,7.77">A Survey of Modern Authorship Attribution Methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,399.56,397.92,72.48,7.77;14,146.47,408.88,31.00,7.77">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009-03">Mar 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
