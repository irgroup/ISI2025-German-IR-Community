<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.90,115.90,301.56,12.90;1,159.35,133.83,296.66,12.90;1,272.14,151.77,71.09,12.90;1,223.43,171.61,168.50,10.75">Random Forest with Increased Generalization: A Universal Background Approach for Authorship Verification Notebook for PAN at CLEF 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,176.10,208.01,90.59,8.64"><forename type="first">María</forename><forename type="middle">Leonor</forename><surname>Pacheco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación y Tecnología de la Información</orgName>
								<orgName type="laboratory">Grupo de Inteligencia Artificial</orgName>
								<orgName type="institution">Universidad Simón Bolívar</orgName>
								<address>
									<postCode>{07-41302, 07-40888, 07</postCode>
									<settlement>Caracas</settlement>
									<country key="VE">Venezuela</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.66,208.01,72.42,8.64"><forename type="first">Kelwin</forename><surname>Fernandes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación y Tecnología de la Información</orgName>
								<orgName type="laboratory">Grupo de Inteligencia Artificial</orgName>
								<orgName type="institution">Universidad Simón Bolívar</orgName>
								<address>
									<postCode>{07-41302, 07-40888, 07</postCode>
									<settlement>Caracas</settlement>
									<country key="VE">Venezuela</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade do Porto</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">INESC TEC</orgName>
								<address>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,384.38,208.01,45.66,8.64"><forename type="first">Aldo</forename><surname>Porco</surname></persName>
							<email>aldo.porco@upf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación y Tecnología de la Información</orgName>
								<orgName type="laboratory">Grupo de Inteligencia Artificial</orgName>
								<orgName type="institution">Universidad Simón Bolívar</orgName>
								<address>
									<postCode>{07-41302, 07-40888, 07</postCode>
									<settlement>Caracas</settlement>
									<country key="VE">Venezuela</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Information and Communication Technologies</orgName>
								<orgName type="institution">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.90,115.90,301.56,12.90;1,159.35,133.83,296.66,12.90;1,272.14,151.77,71.09,12.90;1,223.43,171.61,168.50,10.75">Random Forest with Increased Generalization: A Universal Background Approach for Authorship Verification Notebook for PAN at CLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13F3D4981A945911D061C31BF81ED357</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes our approach for the Author Identification task introduced in PAN 2015. Given a set of documents written by the same author and a questioned document with an unknown author, the task is to decide whether the questioned document was written by the same author as the other documents or not. Our approach uses Random Forest and a feature-encoding scheme based on the Universal Background Model strategy, building different feature vectors that describe: 1) the complete population of authors in a dataset, 2) the known author, 3) the questioned document and combines the three of them in a single representation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship Attribution is the process of attempting to identify the likely authorship of a given document <ref type="bibr" coords="1,210.59,512.97,15.27,8.64" target="#b9">[10]</ref>. Important applications of authorship attribution include: plagiarism detection, deducing the writer of inappropriate communications and resolving historical questions of unclear or disputed authorship <ref type="bibr" coords="1,347.21,536.89,11.62,8.64" target="#b6">[7]</ref>  <ref type="bibr" coords="1,361.11,536.89,10.58,8.64" target="#b4">[5]</ref>. A way of approaching authorship attribution is the authorship verification scenario, where we are given a set of documents written by a single author, and we want to determine whether a questioned document is written by the same author or not <ref type="bibr" coords="1,320.44,572.75,10.58,8.64" target="#b8">[9]</ref>.</p><p>The PAN 2015 Author Identification task focuses on the authorship verification problem. In this article we describe our approach for this task, using a feature-encoding scheme inspired on the Universal Background Model and applying Random Forest for prediction.</p><p>In section 2 we define the problem of authorship verification formally and introduce relevant notations. Section 3 lists and explains in detail the full set of features considered. Two baseline methods: a simple model based on distances between feature vectors and an implementation of a Gaussian Mixture Model -Universal Background Model are introduced in section 4. Section 5 describes our approach, the feature-encoding scheme and the post-processing done to the Random Forest for probabilistic classification. In Section 6 we present our results and evaluations, both on the train and test corpus. Finally in Section 7 conclusions and future research directions are exposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Statement</head><p>In this section we describe the problem of authorship verification as introduced by the PAN 2015 Author Identification task <ref type="bibr" coords="2,283.56,249.11,10.58,8.64" target="#b8">[9]</ref>.</p><p>Let P = (D, q) be a problem, where D is a small set of documents written by a known author and q is a questioned document whose author we do not know. The Author Identification task consists of determining whether the question document q was written by the same author who wrote the documents on set D or not. In our approach we model this as a probabilistic classification problem, where rather than only outputting the most likely class that the sample should belong to, we obtain a probabilistic output that indicates a degree of certainty between 0.0 and 1.0, corresponding to the probability of a positive answer.</p><p>The classification function f is defined as: f (D, q) = pr. Where pr is the probability that the questioned document was written by the same author. The size of D will range from 1 to 5 documents.</p><p>In this task, we have problems for four different languages: Dutch, English, Greek and Spanish. Evaluations will be measured according to the area under the ROC curve (AU C) of pr and the c@1 measure <ref type="bibr" coords="2,276.91,420.76,11.62,8.64" target="#b5">[6]</ref> </p><formula xml:id="formula_0" coords="2,257.67,445.50,222.93,22.31">c@1 = 1 n (n c + ( n u n c n ))<label>(1)</label></formula><p>Where n refers to the number of problems being evaluated, nc refers to the number of correct answers and nu refers to the number of unanswered problems. For measuring the correctness of an answer, a binary evaluation is performed, where pr &gt; 0.5 corresponds to a positive answer, pr &lt; 0.5 corresponds to a negative answer and pr = 0.5 will be considered as an unanswered problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head><p>This section is devoted to the enumeration and description of the features extracted for this task. We extracted a heterogeneous set of features describing properties related to the style of the author from low level features (e.g. vocabulary diversity, document length, etc) to high level features (e.g. part-of-speech, LDA topics, etc). All of our features are expressed at the author level, considering the total set of documents D for each sample. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distributional Features</head><p>-Word distribution: Frequencies of the words contained in the documents written by the author, divided by the total number of words in them. -Character distribution: Frequencies of the alphanumeric characters in the documents written by the author divided by the total number of characters in his documents. Also, we extracted the minimum, average and maximum number of lowercase characters, uppercase characters and digits per document. -Punctuation Bigrams: Frequency of the punctuation characters bigrams observed in the author documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Linguistic Features</head><p>For each author, the following features are extracted independently for each document and then aggregated taking their max, min and average values.</p><p>-Lexical density: measure of how "dense" is the content, i.e, the ratio between each lexical category (nouns, adjectives, verbs and adverbs) divided by the total number of words. -Word diversity: ratio between the number of lemmas found divided by the total number of words. -Lemmas BoW: frequency of the lemmas.</p><p>-Lemmas diversity: for each lemma, the number different words mapped to it.</p><p>-Uniqueness: number of words that appear only one time.</p><p>-Hapax: number of words that appear only one time and are only used by the current author.</p><p>The POS tags and lemmas used were extracted using the Tree Tagger provided by Helmut Schimd <ref type="bibr" coords="3,200.08,656.44,10.58,8.64" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Topics</head><p>-Word Topics: Closeness of a document to the K-th LDA topic.</p><p>-Stop word Topics: Closeness of a document to the K-th LDA topic. Topics are built using only stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline</head><p>As a way to test our proposal, which will be thoroughly described on section 5, we proposed two baseline models: a simple approach based on distances between feature vectors and an implementation of a Gaussian Mixture Model -Universal Background Model (GMM-UBM) <ref type="bibr" coords="4,223.31,250.68,10.58,8.64" target="#b1">[2]</ref>, a method commonly used on Speaker Recognition Systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Distance-based approach</head><p>In Section 2 we described the Author Identification task as a problem P = (D, q), where D is the set of known documents written by author A, and q is a questioned document.</p><p>Let T = {P i (D i , q i ), ..., P m (D m , q m )} be our complete set of samples in the training set and F mxn the matrix of the complete features extracted for each set of known documents D i , where m corresponds to the number of problems and and n to the number of features extracted for each D i . For each row f j in F , corresponding to the values of feature j ∈ {0, ..., n} for all samples in the training set, we adjust a Gaussian distribution.</p><p>We want to determine how unique is each author described by F i,j with respect to the total population of samples. For measuring uniqueness, we do: 1.0 -p(author).</p><p>The lower the probability, the more unique the author described by F i,j and thus the importance of the feature is higher for said author. This is done to derive weights for each feature and normalized per sample so that they sum to 1.0.</p><p>For classifying each questioned document, we measure the weighted Euclidean distance between the question document q i and the set of known documents D i . An acceptance threshold is trained with all distances, maximizing the classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Gaussian Mixture Model -Universal Background Model</head><p>The Universal Background Model (UBM) is a large Gaussian Mixture Model (GMM) trained to represent the distribution of features for all authors in the dataset. The idea is to derive a model for one specific author by updating the trained parameters in the UBM via a form of Bayesian adaptation <ref type="bibr" coords="4,297.19,572.75,10.58,8.64" target="#b2">[3]</ref>.</p><p>The adaptation is a two-step estimation process, similar to the Expectation Maximization (EM) algorithm. The first step is exactly the same as in the EM algorithm, where estimates of the specific author features are computed for each mixture in the UBM. In the second step of the algorithm the new estimates are combined with the old statistics from the UBM mixture parameters using an adjusted mixing coefficient. This allows mixtures to rely more either on old or new estimates depending on the amount of data from the specific author that they explain <ref type="bibr" coords="4,330.64,656.44,10.58,8.64" target="#b1">[2]</ref>.</p><p>Having trained the UBM and its resulting mixtures on the complete set of known authors, we take the feature vector for a specific author documents X = {x1, ..., xt} and compute, for each mixture i in the UBM:</p><formula xml:id="formula_1" coords="5,250.01,165.99,230.58,26.56">P r(i|x t ) = wip i (x t ) M j=1 w j p j (x t )<label>(2)</label></formula><p>We then use P r(i|x t ) to compute statistics for the weight, mean and variance parameters, following the first step in the EM algorithm:</p><formula xml:id="formula_2" coords="5,270.51,238.25,210.08,30.20">n i = T t=1 P r(i|x t )<label>(3)</label></formula><formula xml:id="formula_3" coords="5,249.11,281.73,231.48,73.69">E i (x t ) = 1 n i T t=1 P r(i|x t )x t (4) E i (x 2 t ) = 1 n i T t=1 P r(i|x t )x 2 t (5)</formula><p>Then, these new statistics from the specific author documents are used to update old statistics on the UBM for each mixture i:</p><formula xml:id="formula_4" coords="5,242.82,401.11,237.77,12.69">w i = [α w i n i /T + (1 -α w i )w i ]γ<label>(6)</label></formula><formula xml:id="formula_5" coords="5,247.14,435.66,229.58,12.69">µ i = α m i E i (x) + (1 -α m i )µ i (<label>7</label></formula><formula xml:id="formula_6" coords="5,476.72,438.06,3.87,8.64">)</formula><formula xml:id="formula_7" coords="5,220.02,470.22,256.70,12.69">σ 2 i = α v i E i (x 2 ) + (1 -α v i )(σ 2 i + µ 2 i ) -µ 2 i (<label>8</label></formula><formula xml:id="formula_8" coords="5,476.72,472.61,3.87,8.64">)</formula><p>The adaptation coefficients are {α w i , α m i , α v i } for the weights, means and variance. These are defined by</p><formula xml:id="formula_9" coords="5,281.20,524.68,195.52,23.23">α ρ i = n i n i + r (<label>9</label></formula><formula xml:id="formula_10" coords="5,476.72,531.74,3.87,8.64">)</formula><p>Where r is a fixed relevant factor for all parameters ρ, which was set empirically to 16. For tests, we used a fixed set of 2 mixtures</p><p>The classification was modeled as a hypothesis test between as proposed by Reynolds et. al <ref type="bibr" coords="5,157.96,593.00,10.58,8.64" target="#b1">[2]</ref>. Where: H1: The questioned document q belongs to author A and H0: The questioned document q does not belong to author A. The decision between these two hypothesis is a likelihood ratio test:</p><formula xml:id="formula_11" coords="5,251.30,639.91,229.29,22.31">P (q|H0) P (q|H1) ≥ θ, accept H0 &lt; θ, reject H0<label>(10)</label></formula><p>Having as little as one to five document per author, traditional discriminative methods would fail to fit an accurate decision region. Attempting to improve generalization capabilities, we proposed a feature-encoding scheme based on the Universal Background Model (UBM) <ref type="bibr" coords="6,196.43,183.86,11.62,8.64" target="#b1">[2]</ref> decision strategy, instead of fitting an entirely new model for each author. Thus, we build a feature vector B for the known set of documents for each language, and a feature vector A for each author. Then, we build a vector U for the questioned document considering it as being written by a new author and encode the problem as:</p><formula xml:id="formula_12" coords="6,249.39,254.67,231.20,24.80">(A i -U i ) 2 + 1 (B i -U i ) 2 + 1 |i ∈ [0 . . . N )<label>(11)</label></formula><p>Then, we fed a Random Forest (RF) with each problem. In this way, we are building a model that hierarchically determines the importance of each feature in the identification of authorship. Random Forest is an ensemble discriminative method that trains a set of predictive decision trees to classify a new instance <ref type="bibr" coords="6,366.30,326.18,10.58,8.64" target="#b0">[1]</ref>. In contrast to traditional methods for training Decision Trees, RF considers a subset of randomly selected features to train each individual tree.</p><p>Each feature would be valued with a number in the interval [0 . . . 1) if the features computed for the unknown document is closer to the author than to the general population, otherwise, it would be valued with a number in [1 . . . ∞ + ). This encoding has the advantage that it can model the triad: unknown document -author and population in a single feature vector, making discriminative approaches feasible for this problem (i.e. it does not depend on the number of documents per author but in the number of authors in the dataset). However, as the features grow in an unbounded way with different scales, assuming that all the features lie in the same scale may affect the results. Therefore, we decided to use a Random Forest model which learns the decision region by considering each feature independently <ref type="bibr" coords="6,244.59,470.59,10.58,8.64" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation Results</head><p>On the training set for each language, both baseline models and the RF model were scored based on the measure of AU C * c@1 using repeated randomly selected subsets: 80% of the samples for training and 20% of the samples for validation. Our RF approach scored higher than both baselines on the four datasets. Resumed details are explained in table 1.</p><p>In addition, test sets for each of the languages (Dutch, English, Greek and Spanish) were provided for the competition. We submitted four runs on TIRA <ref type="bibr" coords="6,417.85,608.62,11.62,8.64" target="#b3">[4]</ref> for the final evaluation, one for each test set. Table <ref type="table" coords="6,289.37,620.57,4.98,8.64" target="#tab_1">2</ref> explains our results in detail <ref type="bibr" coords="6,411.66,620.57,10.58,8.64" target="#b8">[9]</ref>. According to these results, our approach performed very well on all datasets, reaching an AUC score above 0.75 for all cases and c@1 above 0.5 for three out four tests. We can also observe relatively low run-time on each of the tests performed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this work we have presented a supervised learning approach for authorship identification based on Random Forests. Previous attempts to solve this problem focused on the computation and interpretation of distance functions and threshold operations. However, it is a well known problem that nearest neighbor approaches are susceptible to the curse of dimensionality problem. In this sense, as we increase the number of discriminative features in the decision task, the amount of data needed to achieve good results grows exponentially.</p><p>Another difficulty related to the proposed problem is the small number of known documents per author, making per-author learning method unfeasible. Therefore, we adopted an discriminative approach with a encoding able to generalize the individual author information by measuring the distance relation between the unknown document, the author's corpora and the entire dataset.</p><p>We obtained remarkable results in the Dutch and Spanish tracks, achieving AUC-ROC values of 0.82229 and 0.9076 in the final assessment of the competition, which are the second and third best results obtained in those tracks respectively.</p><p>Possible improvements for this approach include studying the separation of documents into paragraphs as a way to introduce more examples, analyze the relevance of the proposed features and include texts from other sources to broaden the dataset, given that our method depends greatly on the number of authors processed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,118.92,165.43,8.96;3,141.74,139.19,338.85,9.03;3,151.70,151.53,328.89,8.64;3,151.70,163.49,253.75,8.64;3,141.74,175.12,338.85,9.03;3,151.70,187.47,328.90,8.64;3,151.70,199.42,291.44,8.64;3,141.74,211.06,338.85,9.03;3,151.70,223.40,100.98,8.64;3,141.74,235.03,338.86,9.03;3,151.70,247.38,57.00,8.64;3,141.74,259.01,338.85,9.03;3,151.70,271.36,324.85,8.64;3,141.74,282.99,338.86,9.03;3,151.70,295.33,195.22,8.64"><head>3. 1</head><label>1</label><figDesc>Structure and Extension Features -Number of tokens: minimum, average and maximum number of tokens per document, paragraph and sentence. Also, we extracted the same statistics considering a single occurrence per word, hereafter referred as unique tokens. -Number of stop words: minimum, average and maximum number of stop words (and unique stop words) per document, paragraph and sentence. We considered the stop words dictionaries provided by the Python library many-stop-words. -Number of sentences: minimum, average and maximum number of sentences per paragraph and document. -Number of paragraphs: minimum, average and maximum number of paragraphs per document. -Spacing: minimum, average and maximum number of consecutive spaces, number of consecutive spaces in the beginning/end of the line and number of empty lines. -Punctuation: minimum, average and maximum number of punctuation characters (.,;?¿!¡"') per document, paragraph and sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,204.18,118.07,207.00,242.90"><head>Table 1 .</head><label>1</label><figDesc>Scoring for proposed model and baselines</figDesc><table coords="7,204.18,118.07,207.00,242.90"><row><cell cols="3">Language Model</cell><cell cols="3">AUC c@1 AUC * c@1</cell></row><row><cell></cell><cell>RF</cell><cell></cell><cell cols="2">0.935 0.85</cell><cell>0.795</cell></row><row><cell>Dutch</cell><cell cols="2">UBM</cell><cell>0.6</cell><cell>0.6</cell><cell>0.36</cell></row><row><cell></cell><cell cols="3">Weighted Distance 0.5</cell><cell>0.5</cell><cell>0.25</cell></row><row><cell></cell><cell>RF</cell><cell></cell><cell cols="2">0.61 0.6</cell><cell>0.365</cell></row><row><cell>English</cell><cell cols="2">UBM</cell><cell cols="2">0.55 0.55</cell><cell>0.303</cell></row><row><cell></cell><cell cols="3">Weighted Distance 0.5</cell><cell>0.5</cell><cell>0.25</cell></row><row><cell></cell><cell>RF</cell><cell></cell><cell cols="2">0.755 0.65</cell><cell>0.491</cell></row><row><cell>Greek</cell><cell cols="2">UBM</cell><cell cols="2">0.65 0.65</cell><cell>0.423</cell></row><row><cell></cell><cell cols="3">Weighted Distance 0.7</cell><cell>0.7</cell><cell>0.49</cell></row><row><cell></cell><cell>RF</cell><cell></cell><cell cols="2">1.0 0.95</cell><cell>0.949</cell></row><row><cell>Spanish</cell><cell cols="2">UBM</cell><cell>0.6</cell><cell>0.6</cell><cell>0.36</cell></row><row><cell></cell><cell cols="3">Weighted Distance 0.6</cell><cell>0.6</cell><cell>0.36</cell></row><row><cell cols="3">Language Model AUC</cell><cell cols="3">c@1 AUC * c@1 Runtime</cell></row><row><cell>Dutch</cell><cell>RF</cell><cell cols="4">0.82229 0.75923 0.62431 00:05:08</cell></row><row><cell cols="2">English RF</cell><cell cols="4">0.76287 0.57429 0.43811 00:15:00</cell></row><row><cell>Greek</cell><cell>RF</cell><cell cols="4">0.7728 0.6695 0.51739 00:02:01</cell></row><row><cell cols="2">Spanish RF</cell><cell>0.9076</cell><cell>0.73</cell><cell cols="2">0.66255 00:04:22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,236.00,363.70,143.36,8.12"><head>Table 2 .</head><label>2</label><figDesc>Performance on the test corpus</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,142.87,250.40,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,198.77,142.87,55.51,7.77">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,259.78,142.87,63.00,7.77">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,153.83,319.32,7.77;8,150.95,164.79,325.12,7.77" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Quatieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B D</forename></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.117.338" />
		<title level="m" coord="8,335.90,153.83,126.03,7.77;8,150.95,164.79,91.15,7.77">Speaker verification using Adapted Gaussian mixture models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,175.75,321.67,7.77;8,150.95,186.71,290.35,7.77;8,150.95,197.67,107.59,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,253.58,175.75,210.70,7.77;8,150.95,186.71,138.16,7.77">Maximum a posteriori estimation for multivariate gaussian mixture observations of markov chains</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luc Gauvain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hui Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,294.95,186.71,146.36,7.77;8,150.95,197.67,38.85,7.77">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="291" to="298" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,208.63,301.43,7.77;8,150.95,219.59,318.89,7.77;8,150.95,230.55,327.49,7.77;8,150.95,241.50,246.99,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,274.60,208.63,169.44,7.77;8,150.95,219.59,182.43,7.77">Ousting Ivory Tower Research: Towards a Web Framework for Providing Experiments as a Service</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Burrows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,245.84,230.55,232.61,7.77;8,150.95,241.50,119.02,7.77">International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1125" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,252.46,328.94,7.77;8,150.95,263.42,329.51,7.77;8,150.95,274.38,157.89,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,272.49,252.46,199.06,7.77;8,150.95,263.42,92.80,7.77">Authorship attribution: Performance of various features and classification methods</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">N</forename><surname>Bozkurt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">U</forename><surname>Baglioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,262.28,263.42,218.18,7.77;8,150.95,274.38,28.55,7.77;8,216.70,274.38,40.30,7.77">22nd international symposium on Computer and information sciences</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
	<note>ISCIS 2007</note>
</biblStruct>

<biblStruct coords="8,142.61,285.34,325.86,7.77;8,150.95,296.30,323.27,7.77;8,150.95,307.26,298.24,7.77;8,150.95,318.22,153.76,7.77;8,150.95,329.18,186.21,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,236.87,285.34,146.56,7.77">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2002472.2002646" />
	</analytic>
	<monogr>
		<title level="m" coord="8,401.73,285.34,66.74,7.77;8,150.95,296.30,323.27,7.77;8,150.95,307.26,52.91,7.77;8,303.33,307.26,29.49,7.77">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
	<note>HLT &apos;11</note>
</biblStruct>

<biblStruct coords="8,142.61,340.14,330.36,7.77;8,150.95,351.09,326.94,7.77;8,150.95,362.05,286.65,7.77;8,150.95,373.01,266.58,7.77;8,150.95,383.97,186.21,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,250.46,340.14,222.51,7.77;8,150.95,351.09,167.38,7.77">Short text authorship attribution via sequence kernels, markov chains and author unmasking: An investigation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guenter</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1610075.1610142" />
	</analytic>
	<monogr>
		<title level="m" coord="8,336.21,351.09,141.69,7.77;8,150.95,362.05,184.53,7.77;8,390.78,362.05,43.27,7.77">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="482" to="491" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;06</note>
</biblStruct>

<biblStruct coords="8,142.61,394.93,265.93,7.77;8,150.95,405.89,231.73,7.77" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,196.28,394.93,212.25,7.77">Probabilistic Part-of-Speech Tagging Using Decision Trees</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.1139" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,416.85,322.93,7.77;8,150.95,427.81,309.68,7.77;8,150.95,438.77,306.50,7.77;8,150.95,449.72,298.91,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,186.83,427.81,182.63,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lopez Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="8,406.32,427.81,54.32,7.77;8,150.95,438.77,149.87,7.77">Working Notes Papers of the CLEF 2015 Evaluation Labs</title>
		<title level="s" coord="8,307.00,438.77,150.46,7.77;8,150.95,449.72,19.77,7.77">CEUR Workshop Proceedings, CLEF and CEUR</title>
		<imprint>
			<date type="published" when="2015-09">2015. Sep 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,460.68,321.67,7.77;8,150.95,471.64,319.09,7.77;8,150.95,482.60,328.80,7.77;8,150.95,493.56,214.60,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,221.77,460.68,226.80,7.77">Searching with style: Authorship attribution in classic literature</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1273749.1273757" />
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,471.64,275.66,7.77;8,191.30,482.60,35.95,7.77">Proceedings of the Thirtieth Australasian Conference on Computer Science</title>
		<meeting>the Thirtieth Australasian Conference on Computer Science<address><addrLine>Darlinghurst, Australia, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Australian Computer Society, Inc</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
	<note>ACSC &apos;07</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
