<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.58,115.90,328.20,12.90;1,223.43,135.75,168.50,10.75">GLAD: Groningen Lightweight Authorship Detection Notebook for PAN at CLEF 2015</title>
				<funder ref="#_8YuQqW7">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,195.41,172.15,78.44,8.64"><forename type="first">Manuela</forename><surname>Hürlimann</surname></persName>
							<email>m.f.hurlimann@student.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Cognition Groningen</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.90,172.15,48.44,8.64"><forename type="first">Benno</forename><surname>Weck</surname></persName>
							<email>b.f.o.weck@student.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Cognition Groningen</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,336.82,172.15,78.79,8.64"><forename type="first">Esther</forename><surname>Van Den Berg</surname></persName>
							<email>e.m.van.den.berg.4@student.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Cognition Groningen</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.08,184.10,52.00,8.64"><forename type="first">Simon</forename><surname>Šuster</surname></persName>
							<email>s.suster@rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Cognition Groningen</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.35,184.10,63.93,8.64"><forename type="first">Malvina</forename><surname>Nissim</surname></persName>
							<email>m.nissim@rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language and Cognition Groningen</orgName>
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.58,115.90,328.20,12.90;1,223.43,135.75,168.50,10.75">GLAD: Groningen Lightweight Authorship Detection Notebook for PAN at CLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2A96C55A7E923FCCDEFBDC87D1229AA3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a simple and effective approach to authorship verification for Dutch, English, Spanish and Greek, which can be easily ported to yet other languages. We train a binary linear classifier both on the features describing known and unknown documents individually, and on the joint features comparing these two types of documents. The list of feature types includes, among others, character n-grams, the lexical overlap, visual text properties and a compression measure. We obtain competitive results that outperform the baseline and position our system among the top PAN shared task participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the authorship verification task as set in the PAN competition<ref type="foot" coords="1,393.94,408.54,3.49,6.05" target="#foot_0">1</ref> , a system is given a collection of problem sets containing one or more known documents written by author A k and a new, unknown document written by author A u , and is then required to determine whether A k = A u without access to a closed set of alternatives. In this form, the task is generally interpreted as a one-class classification problem <ref type="bibr" coords="1,395.11,458.23,15.27,8.64" target="#b10">[11]</ref>, in the sense that the negative class is not homogeneously represented and systems are based on recognition of a given class rather than discrimination among classes <ref type="bibr" coords="1,379.94,482.14,10.58,8.64" target="#b0">[1]</ref>. This is akin to outlier or novelty detection <ref type="bibr" coords="1,217.52,494.09,11.45,8.64" target="#b4">[5,</ref><ref type="bibr" coords="1,228.98,494.09,7.64,8.64" target="#b6">7]</ref> and different from standard authorship attribution problems, where a system must choose among a set of candidate authors in a more standard, multi-class text categorisation fashion.</p><p>Since multi-class classification is a more natural and efficient way of performing classification, researchers have experimented with the introduction of negative instances to each problem set by selecting random external documents <ref type="bibr" coords="1,375.77,553.87,15.27,8.64" target="#b17">[18]</ref>, and with the addition of positive examples by splitting long known documents into chunks <ref type="bibr" coords="1,418.84,565.82,15.27,8.64" target="#b10">[11]</ref>. This way, each problem set is turned into a true binary classification task as both positive and negative instances are represented, the latter being mimed by the external documents. Approaches using external documents are referred to as extrinsic approaches, while methods that do not introduce any external documents are called intrinsic approaches <ref type="bibr" coords="1,461.50,613.65,15.27,8.64" target="#b20">[21]</ref>. Building on the impostor method used by <ref type="bibr" coords="1,312.65,625.60,16.60,8.64" target="#b17">[18]</ref> within the PAN 2013 competition, which indeed used sets of external documents to produce negative instances, <ref type="bibr" coords="1,445.14,637.56,16.60,8.64" target="#b9">[10]</ref> also use an extrinsic approach and achieve optimal results at PAN 2014. This result is interesting as most systems participating in PAN 2014 are instead intrinsic in nature. Additionally, only three out of 13 approaches exploit actual trained models <ref type="bibr" coords="2,436.77,143.22,15.27,8.64" target="#b20">[21]</ref>, while the rest pursue a "lazy" strategy.</p><p>In the light of the above discussion, we decided to cast the problem as a binary classification task where class values are Y (A k = A u ) and N (A k ≠ A u ). In order to maximise speed and simplicity, we do not introduce any negative examples by means of external documents, thus adhering to an intrinsic approach. To fit a binary classification setting, we train a model on the whole dataset, which contains both positive (A k = A u ) and negative (A k ≠ A u ) problem sets in equal number. In other words, we treat each problem set as a training vector, exploiting both positive and negative instances in learning. Each instance is represented as a feature vector which contains feature values representing the known document, values representing the unknown document and values comparing the known and unknown document, and is associated with a class value of either Y(es) or N(o). Furthermore, all features that we include in our final models are simple and fast to obtain from any text without requiring any complex processing. An average train or test run of our system on one of the PAN datasets takes only minutes to complete. Finally, to ensure portability, we do not develop any language-specific feature. Rather, we tune the system towards a specific language by means of selecting and combining features in (possibly) different ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach and Data Representation</head><p>There are two reasons for casting an authorship verification problem as a binary classification task: (i) because in the PAN 2015 training data the problem sets are equally distributed for positive and negative evidence and (ii) because of the success of extrinsic methods, which bear more similarities to our multi-class classification than to one-class (detection) approaches (see discussion in Section 1 above). However, theoretically, the problem still resembles one-class classification more than a true binary classification task, especially because the negative class is not inherently homogeneous (our approach is more alike to telling apples from other fruit than telling apples from pears). It also needs to be noted that, in a realistic setting, evidence would not necessarily be balanced, with negative examples outnumbering positive ones (there are many more fruits that are not apples than there are apples).</p><p>For one-class classification, Support Vector Machines (SVM) have been shown to perform very well <ref type="bibr" coords="2,210.84,548.60,15.77,8.64" target="#b12">[13,</ref><ref type="bibr" coords="2,226.61,548.60,11.83,8.64" target="#b22">23]</ref>, and this is especially true when the data are highly unbalanced, as demonstrated by <ref type="bibr" coords="2,245.15,560.56,10.58,8.64" target="#b0">[1]</ref>. They also show that, in presence of a balanced set up to a ratio of 1:3.5, binary classification outperforms one-class classification. Since we are dealing with balanced datasets, we use a binary class SVM. In a different setting, a one-class SVM could be used, without major variations in the algorithm.</p><p>Our system is implemented using Python's scikit-learn <ref type="bibr" coords="2,377.96,608.62,16.60,8.64" target="#b14">[15]</ref> machine learning library as well as the Natural Language Toolkit (NLTK) <ref type="bibr" coords="2,366.91,620.57,10.58,8.64" target="#b1">[2]</ref>. We used an SVM with default parameter settings in all final models, with an implementation based on libsvm. The features we experimented with and the tools used to extract them are described below.</p><p>Building on the existing literature and on observations that came from preliminary exploration of the training data (both from PAN 2014 and from PAN 2015), we developed a set of 29 features. Not all of them were used in the final configuration, as ablation experiments showed little or no contribution of some groups of features. Nevertheless, we describe them all in this section, and present results from ablation experiments in the next.</p><p>There are two major ways to divide up the features we experimented with. The first one has to do with the kind of information they represent, and we clustered them in seven different groups (see Sections 2.1-2.7). The second one has to do with how the information is encoded regarding the known and unknown documents. Specifically, features can describe the known and unknown documents separately, in which case we talk about individual features, or they can describe them together, in which case we talk about joint features. For example, when comparing the average sentence length of the known and the unknown portion of a training instance, one can represent the average sentence lengths as two individual values or compute the difference of the averages to get a single joint feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">N-gram Features</head><p>Information on correspondence of character sequences in known and unknown documents has been shown to be a successful feature for this task <ref type="bibr" coords="3,399.85,369.94,15.77,8.64" target="#b19">[20,</ref><ref type="bibr" coords="3,415.62,369.94,11.83,8.64" target="#b20">21]</ref>. All n-gram features in our model are joint features. We included n-grams with n ranging from 1 to 5, and calculated n-gram similarity in two different ways. According to <ref type="bibr" coords="3,425.73,393.85,10.58,8.64" target="#b8">[9]</ref>, an author profile is defined as the set of the k most frequent n-grams with their normalised frequencies, as collected from training data. In order to deal with sparseness when n &gt; 2, the (dis)similarity measure that they use, and that we adopt, takes into account the difference between the relative frequency of a given n-gram averaged over all knownunknown document pairs of one problem instance. We call this feature group n-gram norm. We also use a simple n-gram overlap measure called SPI (simplified profile intersection <ref type="bibr" coords="3,176.60,477.54,45.49,8.64">[20, p. 548]</ref>). This measure is based on the number of common n-grams in the most frequent k n-grams for each document. We calculate the SPI score separately for each n between 1 and 5.</p><p>Profile size k is another parameter of the n-gram norm and SPI measures. For our system we fixed k at 100, thus taking into account the 100 most frequent n-grams of each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Token Features</head><p>A common way to measure the similarity of two given texts is to compute the cosine similarity of their vector representations. We hypothesise that texts written by different authors are lexically less similar than texts written by the same author. We measure the similarity in each training instance by averaging over the L2-normalised dot product of the raw term frequency vectors of a single known document and the unknown document. The token feature is considered a joint feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sentence Features</head><p>We consider the number of tokens per sentence to be a simple yet effective feature for detecting authorship <ref type="bibr" coords="4,219.30,150.81,15.77,8.64" target="#b11">[12,</ref><ref type="bibr" coords="4,235.07,150.81,11.83,8.64" target="#b16">17]</ref>. The values for average sentence length are obtained and represented both as joint and individual features. Sentence boundaries are determined using language-specific models of the NLTK Punkt Tokeniser 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Entropy Features</head><p>The notion of the entropy of a text was first introduced by Shannon <ref type="bibr" coords="4,397.60,223.76,15.27,8.64" target="#b18">[19]</ref>. We hypothesise that authors have distinct entropy profiles due to the varying lexical and morphosyntactic patterns they use. We use the average entropy of each known and unknown documents (as individual features), as well as two joint measures: (i) the average entropy of each known concatenated with the unknown document, (ii) and the absolute difference between entropies of known and unknown documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Visual Features</head><p>Upon inspecting the training data, it became apparent that while Dutch documents contain no newline characters, and Greek and Spanish texts are visually very uniform, many of the English training instances had been drawn from plays and poems. These documents are characterised by marked usage of white space and punctuation. For instance, the sample text in Figure <ref type="figure" coords="4,264.75,380.41,4.98,8.64" target="#fig_0">1</ref> includes apostrophes to reflect the speakers' accents, many mid-sentence line breaks and the segmentation of the text into turns of dialogue. Compared to a piece of prose, or to a play, we predict that this text has a higher number of apostrophes and newlines and that this information is crucial for distinguishing same-author from different-author instances. Taking into consideration our aim of designing a lightweight system, we opted for straight-forward measures of layout properties: (i) punctuation, to capture differences in use of typographical signs, (ii) line endings, to measure preferred ways of closing lines, (iii) letter case, to capture e.g. the occurrence of names and the capitalisation of the start of sentences, and finally (iv) line length measures and (v) text block size, to capture the amount and distribution of blank space in a document. In detail, the visual features consist of: (i) Punctuation: frequencies of exclamation marks, question marks, semi-colons, colons, commas, full stops, hyphens and quotation marks (ii) Line endings: frequencies of full stops, commas, question marks, exclamation marks, spaces, hyphens, and semi-colons at the end of a line (iii) Letter case ratio of uppercase characters to lowercase characters proportion of uppercase characters  sentences per line words per line proportion of blank lines (v) Block size:</p><p>number of lines per text block number of characters per text block After obtaining vectors for documents, counts were averaged across all known documents in an instance, generating a simple author profile to be compared to the unknown/questioned document. We use the cosine similarity for the property vectors punctuation, line endings and line length, and simple subtraction for letter case and text block. All visual features are joint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Compression Feature</head><p>Compression features have been successfully used for authorship identification, and can yield performance similar to n-gram features <ref type="bibr" coords="5,316.42,525.12,15.27,8.64" target="#b11">[12]</ref>. We used the "Compression Dissimilarity Measure (CDM)" [12, p.19], which, for two documents x and y is defined as the sum of the compressed lengths of x and y divided by the compressed length of the concatenation of the two documents:</p><formula xml:id="formula_0" coords="5,247.24,581.84,233.35,22.53">CDM (x, y) = C(x) + C(y) C(xy) .<label>(1)</label></formula><p>Our implementation of CDM normalises the compressed lengths by the number of characters in each document and uses the zlib algorithm <ref type="foot" coords="5,337.45,622.90,3.49,6.05" target="#foot_1">3</ref> for compression. By definition this is a joint feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">(Morpho)syntactic Features</head><p>We also investigate the role of more elaborate feature types, namely part-of-speech (POS) tags and syntactic functions obtained from dependency trees. Previous attempts have mostly dealt with shallow information obtained from POS tags (see <ref type="bibr" coords="6,436.24,168.45,16.60,8.64" target="#b19">[20]</ref> for an overview), whereas methods using syntactic features are less common, especially those using dependency-rather than phrase-based syntax <ref type="bibr" coords="6,348.59,192.36,11.38,8.64" target="#b5">[6,</ref><ref type="bibr" coords="6,359.97,192.36,11.38,8.64" target="#b15">16]</ref>. There are many possible ways to include (morpho)syntactic features, however the underlying motivation for including them is typically that the frequency and the patterns of (morpho)syntactic categories are not under conscious control by authors. We run these experiments for English only.</p><p>We use the MST dependency parser <ref type="bibr" coords="6,300.54,253.19,16.60,8.64" target="#b13">[14]</ref> for English trained on sections 2-21 of the Penn Treebank WSJ (PTB) prepared using the standard procedures of <ref type="bibr" coords="6,430.39,265.15,16.60,8.64" target="#b21">[22]</ref> and <ref type="bibr" coords="6,466.48,265.15,10.58,8.64" target="#b7">[8]</ref>. The parser achieves a reasonable labelled accuracy of around 0.85 on the testing part of the PTB. POS tags are obtained with the Citar tagger <ref type="foot" coords="6,348.73,287.19,3.49,6.05" target="#foot_2">4</ref> , which achieves an accuracy of around 96% on the PTB test sections. We take a simple approach of comparing POS and dependency label distributions of known and unknown documents, and use two measures for comparing the distributions: cosine similarity and entropy. For the former, we calculate the L2-normalised cosine similarity between two frequency distributions, producing a joint feature. For entropy, we calculate the Shannon entropy (see Section 2.4) of the known and unknown texts separately (averaged in case of multiple known documents), yielding two individual features. We also use the absolute difference between the two as a joint feature. Entropy features are only used for POS tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Selection</head><p>In order to assess the contribution of the feature types discussed in Section 2, we ran a series of feature ablation and single-feature experiments, where "feature" actually stands for each of the groups defined in Sections 2.1-2.7. To these, we added four more categories which simply group selected feature types:</p><p>all individual features all joint features visual and compression features (vis+comp) visual features, n-gram features and token (cosine) feature (vis+n+tok)</p><p>All tests for evaluating the contribution of the various features were conducted in Weka <ref type="bibr" coords="6,134.77,585.22,10.58,8.64" target="#b3">[4]</ref>, using the LibSVM classifier, which has the same default parameters as the scikitlearn implementation (cf. Section 2). We ran the experiments on the PAN 2015 training data, which consist of 100 problem sets per language, with a balanced distribution of positive and negative instances. In Figures <ref type="figure" coords="6,321.43,621.09,4.98,8.64" target="#fig_1">2</ref> and<ref type="figure" coords="6,347.22,621.09,4.98,8.64" target="#fig_2">3</ref> we report results using 10-fold stratified cross-validation, averaged over five runs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ablation Results</head><p>Figure <ref type="figure" coords="8,163.16,139.40,4.98,8.64" target="#fig_1">2</ref> reports on our ablation study, in which we leave out a single feature group at a time. If removing a feature group causes lower scores, it is beneficial, while removing harmful feature groups increases performance. We can see that for Dutch, removing the individual features leads to the greatest drop in performance. These are therefore the most useful features. The joint features, on the other hand, appear to be harmful to the performance of the system. Most other feature groups do not greatly affect the results.</p><p>For English, the most useful combination includes visual features, n-gram features, and the cosine feature. Joint features also perform well, while individual features are harmful. Part-of-speech features also appear to be harmful. We experimented with (morpho)syntactic features in English only. The ablation results indicate that these features are not effective, thus, we do not pursue these further for the other three languages. A possible explanation is that the quality of the dependency parser is not sufficient, however this is less likely to be the case for the POS tagger. We leave the design of more complex (morpho)syntactic feature types for future work.</p><p>Greek and Spanish both experience the greatest drop in performance when joint features are removed, further underlining the usefulness of this feature group. It is interesting that only Dutch shows a preference for individual over joint features, though we could not identify a specific reason as to why this is the case, and it will require further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single-Feature Results</head><p>Figure <ref type="figure" coords="8,163.61,404.80,4.98,8.64" target="#fig_2">3</ref> shows the effects of using single groups of features only. Consistent with the results in Figure <ref type="figure" coords="8,201.04,416.75,3.74,8.64" target="#fig_1">2</ref>, individual features are the most useful combination for Dutch, while sentence and compression features score conspicuously low.</p><p>Visual features score highly for English (with this single feature group outperforming the full feature set), again underlining the importance of capturing layout properties for this data set.</p><p>For Greek, we find character n-grams, visual features and token features to be most beneficial. This cannot be attributed to any of the single component groups but seems to arise out of the specific combination and interaction of these feature groups.</p><p>Finally, scores on Spanish are maximised by the full feature set, which is marginally better than only the joint features. The combination of all available information therefore has a positive effect on Spanish, while the other languages benefit from restricting analysis to a subset of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Final Feature Sets</head><p>Based on the observations gleaned from the above tests, we grouped the features into four combinations with which we experimented in order to define the final feature set for each language. Table <ref type="table" coords="8,240.34,622.40,4.98,8.64" target="#tab_1">1</ref> presents the cross-validated results for the combinations across the four languages.</p><p>-combo1: n-grams, visual -combo2: n-grams, visual, token -combo3: n-grams, visual, token, entropy (joint) -combo4: full set (excluding morpho(syntactic) features) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Runs and Results</head><p>We submitted runs for all four languages. The models were trained on the corresponding four training sets of PAN 2015. Based on the experiments reported in Section 3, we ran our system with the full feature set for English, Dutch, and Spanish (combo4), but with a different configuration for Greek. Indeed, we observed consistent gains in the overall score for this language when using a subset of features (combo2), namely n-grams, visual, and token features. For English, Dutch and Spanish, only marginal gains were observed using different combinations of features; therefore, we did not use a reduced feature set for these languages. We report the combined AUC-c@1 scores for all languages in Table <ref type="table" coords="9,412.60,584.71,3.74,8.64" target="#tab_2">2</ref>. On a balanced test set, these results outperform a baseline system which assigns Y (or N) throughout and thus achieves a combined score of 0.25 (c@1=0.5 and AUC=0.5). The crossvalidation results on the training data show similar performance for all systems except for Spanish, where the score is much higher. This can be explained by the fact that some instances (documents) were repeated in the Spanish training set. On the test set, we obtain a combined score of around 0.6 for both Dutch and Greek, with which we achieve the third-and fourth-best result out of all PAN 2015 participants. For English, the score on the test set (0.41) is lower than for the other languages, and contrasts somewhat with the cross-validation results. A possible explanation is that there is a considerable domain shift between the training and test sets for English. Our method also achieves fast testing times -with some variance per languagewith an average runtime of one minute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented a simple, yet effective approach to the authorship verification task of the PAN competition. The task was to determine whether A k = A u for one or more known documents written by author A k and a "questioned" document written by author A u . Our solution to this problem was to treat it as a binary classification task, training a model across the whole dataset. Based on the prediction that texts written by different authors are less similar than texts written by the same author due to author-specific patterns in writing not under the conscious control of the author, we developed an initial set of 29 features to model similarity or lack thereof.</p><p>Ablation and single-feature experiments were used to assess the contribution of the various features we originally selected, and led to the configuration of the final model for each language. Indeed, to ensure portability, we did not develop any languagespecific features (apart from NLTK language-specific sentence-splitters), and instead tuned the system by feature selection, as we noticed some differences in performance between features combinations when applied to different languages. One interesting observation was that only Dutch showed a preference for individual over joint features, but no aspect of the Dutch training data could be found which might cause this result. This raises the question for further research of whether there are theoretical grounds for preferring joint similarity measures over separate, individual measures for author verification tasks. Also, results for Greek showed that a smaller set of specific features was consistently outperforming the full set, but further investigation is required to understand exactly why.</p><p>With parsimony and speed in mind, all selected features in our final models were straight-forward to implement and easy to obtain for any text. Indeed, our resulting system is easy to run, adaptable to new languages through feature selection, and fast, with runs taking one minute on average.</p><p>The PAN 2015 test results position our system in the third-and fourth-best place out of all participants for the Dutch and Greek datasets. We obtain a somewhat lower score for English, which contrasts with promising cross-validation results. While inspection of the actual test data, once available, might shed light on the causes of such a drop, this result hints at the variability which is inherent to binary classification when applied to moderate-size training and test sets. Further exploration of features, feature parameters and feature combinations for individual languages is left as a challenging avenue for future work. We make our system GLAD publicly available at https://github.com/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,219.86,284.59,175.65,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Text sample from English training data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,189.54,374.95,236.27,8.12;7,186.64,118.15,242.07,242.07"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Combined scores when removing certain feature groups</figDesc><graphic coords="7,186.64,118.15,242.07,242.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,187.85,652.48,239.65,8.12;7,186.64,395.67,242.07,242.07"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Combined scores when using only certain feature groups</figDesc><graphic coords="7,186.64,395.67,242.07,242.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,154.31,186.12,304.49,93.09"><head>Table 1 .</head><label>1</label><figDesc>Cross-validated performance of feature combinations for the four languages</figDesc><table coords="9,179.12,207.89,257.12,71.33"><row><cell></cell><cell>combo1</cell><cell>combo2</cell><cell>combo3</cell><cell>combo4</cell></row><row><cell cols="5">Language avg min max avg min max avg min max avg min max</cell></row><row><cell>Dutch</cell><cell cols="4">.548 .542 .553 .552 .544 .559 .539 .532 .546 .549 .538 .557</cell></row><row><cell cols="5">English .487 .476 .499 .499 .486 .507 .531 .498 .549 .556 .536 .572</cell></row><row><cell>Greek</cell><cell cols="4">.479 .465 .489 .537 .526 .550 .474 .467 .481 .510 .506 .517</cell></row><row><cell cols="5">Spanish .815 .801 .827 .859 .849 .864 .900 .896 .907 .905 .902 .911</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,134.77,468.41,345.83,88.49"><head>Table 2 .</head><label>2</label><figDesc>Combined scores for PAN 2015 on the training set (cross-validation) and on the test set (single runs)</figDesc><table coords="9,242.38,500.29,130.60,56.61"><row><cell>Language</cell><cell>Training Test</cell></row><row><cell>Dutch (full set)</cell><cell>.55 .62</cell></row><row><cell>English (full set)</cell><cell>.56 .41</cell></row><row><cell>Greek (combo2)</cell><cell>.54 .60</cell></row><row><cell>Spanish (full set)</cell><cell>.90 .54</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.93,102.22,6.31"><p>http://pan.webis.de</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="5,144.73,657.93,86.08,6.31"><p>http://zlib.net/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2" coords="6,144.73,657.93,172.15,6.31"><p>http://github.com/danieldk/citar</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements The first three authors were supported by the <rs type="programName">Erasmus Mundus Master's Program in Language and Communication Technologies</rs> (EM LCT). We would also like to thank the anonymous reviewers for their helpful comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8YuQqW7">
					<orgName type="program" subtype="full">Erasmus Mundus Master&apos;s Program in Language and Communication Technologies</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.61,202.31,336.01,7.77;11,150.95,213.27,329.19,7.77;11,150.95,224.23,329.03,7.77;11,150.95,235.18,61.02,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,300.20,202.31,178.41,7.77;11,150.95,213.27,23.40,7.77">One-class versus binary classification: Which and when?</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bellinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,188.80,213.27,291.34,7.77;11,150.95,224.23,45.83,7.77;11,296.99,224.23,41.78,7.77">Proceedings of the 2012 11th International Conference on Machine Learning and Applications</title>
		<meeting>the 2012 11th International Conference on Machine Learning and Applications<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="102" to="106" />
		</imprint>
	</monogr>
	<note>ICMLA &apos;12</note>
</biblStruct>

<biblStruct coords="11,142.61,246.51,332.16,7.77;11,150.95,257.47,43.50,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="11,257.69,246.51,146.22,7.77">Natural language processing with Python</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,268.79,320.47,7.77;11,150.95,279.75,315.15,7.77;11,150.95,290.71,253.68,7.77" xml:id="b2">
	<analytic>
		<ptr target="http://ceur-ws.org/Vol-1180" />
	</analytic>
	<monogr>
		<title level="m" coord="11,351.72,268.79,111.35,7.77;11,150.95,279.75,39.61,7.77">Working Notes for CLEF 2014 Conference</title>
		<title level="s" coord="11,339.24,279.75,107.26,7.77">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Halvey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</editor>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="volume">1180</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,302.03,336.26,7.77;11,150.95,312.99,264.47,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,426.59,302.03,52.28,7.77;11,150.95,312.99,98.78,7.77">The weka data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,255.71,312.99,81.94,7.77">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,324.31,332.66,7.77;11,150.95,335.27,106.13,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,235.97,324.31,156.18,7.77">A survey of outlier detection methodologies</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">J</forename><surname>Hodge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,398.32,324.31,76.95,7.77;11,150.95,335.27,26.94,7.77">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="126" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,346.59,327.64,7.77;11,150.95,357.55,326.27,7.77;11,150.95,368.51,144.52,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,220.11,346.59,234.64,7.77">Using dependency-based annotations for authorship identification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hollingsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="11,325.57,357.55,147.89,7.77">TSD. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Sojka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Horák</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Kopecek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Pala</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">7499</biblScope>
			<biblScope unit="page" from="314" to="319" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,379.83,332.99,7.77;11,150.95,390.79,109.58,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,309.52,379.83,162.81,7.77">A novelty detection approach to classification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,163.16,390.79,24.16,7.77">IJCAI</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="518" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,402.12,334.20,7.77;11,150.95,413.08,176.62,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,247.84,402.12,213.07,7.77">Extended constituent-to-dependency conversion for English</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,413.08,43.41,7.77">NODALIDA</title>
		<meeting><address><addrLine>Tartu, Estonia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,424.40,333.22,7.77;11,150.95,435.36,326.42,7.77;11,150.95,446.32,182.20,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,317.46,424.40,158.37,7.77;11,150.95,435.36,36.14,7.77">N-gram-based author profiles for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Keselj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,204.82,435.36,272.55,7.77;11,150.95,446.32,38.59,7.77">Proceedings of the Conference of the Pacific Association for Computational Linguistics</title>
		<meeting>the Conference of the Pacific Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>PACLING</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,457.64,317.05,7.77;11,150.95,468.60,180.30,7.77;11,150.95,480.40,314.02,6.31" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="11,228.74,457.64,230.54,7.77;11,150.95,468.60,38.30,7.77">A slightly-modified gi-based author-verifier with lots of features (ASGALF)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Khonji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Iraqi</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1180/CLEF2014wn-Pan-KonijEt2014.pdf" />
		<editor>Cappellato et al.</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="977" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,490.88,321.94,7.77;11,150.95,501.84,317.28,7.77;11,150.95,512.80,169.11,7.77;11,150.95,524.60,225.95,6.31" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,233.71,490.88,214.25,7.77">Authorship verification as a one-class classification problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<idno type="DOI">10.1145/1015330.1015448</idno>
		<ptr target="http://doi.acm.org/10.1145/1015330.1015448" />
	</analytic>
	<monogr>
		<title level="m" coord="11,150.95,501.84,282.05,7.77;11,150.95,512.80,35.30,7.77">Proceedings of the Twenty-first International Conference on Machine Learning</title>
		<meeting>the Twenty-first International Conference on Machine Learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">62</biblScope>
		</imprint>
	</monogr>
	<note>ICML &apos;04</note>
</biblStruct>

<biblStruct coords="11,142.24,535.08,318.90,7.77;11,150.95,546.04,196.50,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="11,175.86,535.08,281.38,7.77">An Exploratory Study on Authorship Verification Models for Forensic Purpose</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Delft University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="11,142.24,557.36,314.06,7.77;11,150.95,568.32,169.82,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,255.83,557.36,158.85,7.77">One-class SVMs for document classification</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">M</forename><surname>Manevitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yousef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,420.19,557.36,36.11,7.77;11,150.95,568.32,101.09,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,579.64,334.59,7.77;11,150.95,590.60,61.40,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,247.61,579.64,225.53,7.77">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,163.16,590.60,23.05,7.77">EACL</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,601.93,338.35,7.77;11,150.95,612.89,300.54,7.77;11,150.95,623.84,322.31,7.77;11,150.95,634.80,192.98,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,295.94,623.84,144.73,7.77">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,446.86,623.84,26.40,7.77;11,150.95,634.80,110.80,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,646.13,318.43,7.77;11,150.95,657.08,62.01,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,272.78,646.13,172.28,7.77">Authorship verification based on syntax features</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rygl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zemková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,150.95,657.08,35.87,7.77">RASLAN</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,119.96,337.72,7.77;12,150.95,130.92,318.85,7.77;12,150.95,141.88,297.41,7.77;12,150.95,152.84,159.47,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,364.39,119.96,115.56,7.77;12,150.95,130.92,140.30,7.77">The use of orthogonal similarity relations in the prediction of authorship</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y Gãşmez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,374.41,130.92,95.40,7.77;12,150.95,141.88,109.56,7.77">Computational Linguistics and Intelligent Text Processing</title>
		<title level="s" coord="12,266.50,141.88,126.47,7.77">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7817</biblScope>
			<biblScope unit="page" from="463" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,163.80,336.08,7.77;12,150.95,174.76,329.64,7.77;12,150.95,185.71,113.20,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,198.78,163.80,279.54,7.77;12,150.95,174.76,16.14,7.77">Authorship verification using the impostors method -notebook for pan at clef 2013</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seidman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,323.92,174.76,156.68,7.77;12,150.95,185.71,87.05,7.77">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,196.67,318.92,7.77;12,150.95,207.63,213.99,7.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,207.49,196.67,148.01,7.77">A mathematical theory of communication</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,361.89,196.67,99.27,7.77;12,150.95,207.63,148.25,7.77">ACM SIGMOBILE Mobile Computing and Communications Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="55" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,218.59,325.81,7.77;12,150.95,229.55,114.67,7.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,207.24,218.59,182.01,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,395.57,218.59,72.48,7.77;12,150.95,229.55,31.00,7.77">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,240.51,294.19,7.77;12,150.95,251.47,311.90,7.77;12,150.95,262.43,205.89,7.77;12,150.95,274.23,303.26,6.31" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,304.84,251.47,158.02,7.77;12,150.95,262.43,35.49,7.77">Overview of the author identification task at PAN 2014</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Sánchez-Pérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1180/CLEF2014wn-Pan-StamatosEt2014.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="12,204.92,262.43,58.52,7.77">Cappellato et al</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="877" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,284.34,318.83,7.77;12,150.95,295.30,23.90,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,238.11,284.34,186.96,7.77">Adding Noun Phrase Structure to the Penn Treebank</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vadas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,443.50,284.34,17.57,7.77">ACL</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,306.26,332.34,7.77;12,150.95,317.22,320.75,7.77;12,150.95,328.18,244.34,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,178.85,306.26,223.73,7.77">Svmc: Single-class classification with support vector machines</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,421.04,306.26,53.54,7.77;12,150.95,317.22,229.66,7.77;12,435.60,317.22,32.10,7.77">Proceedings of the 18th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 18th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="567" to="572" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;03</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
