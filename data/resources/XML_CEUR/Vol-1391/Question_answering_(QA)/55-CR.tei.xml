<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.40,110.98,302.57,12.62;1,163.21,128.91,288.93,12.62">IIITH at BioASQ Challange 2015 Task 3b: Bio-Medical Question Answering System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,227.73,166.60,61.24,8.74"><forename type="first">Harish</forename><surname>Yenala</surname></persName>
							<email>harish.yenala@research.iiit.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.53,166.60,80.87,8.74"><forename type="first">Avinash</forename><surname>Kamineni</surname></persName>
							<email>avinash.kamineni@research.iiit.ac.inm.shrivastava@iiit.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,205.73,178.56,84.82,8.74"><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">International Institute of Information Technology Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.48,178.56,84.67,8.74"><forename type="first">Manoj</forename><surname>Chinnakotla</surname></persName>
							<email>manojc@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.40,110.98,302.57,12.62;1,163.21,128.91,288.93,12.62">IIITH at BioASQ Challange 2015 Task 3b: Bio-Medical Question Answering System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">006F0BB9A548B70E6D40EFE5C348C681</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>PubMed</term>
					<term>Biomedical Question Answering</term>
					<term>Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our participation in the 2015 BioASQ challenge on Bio-Medical Question Answering. For Question Answering task (Task 3b), teams were provided with natural language questions and asked to retrieve responses from PubMed corpus in the form of documents, snippets, concepts and RDF triplets (Phase A) and direct answers (Phase B). For Phase A, we took the support of PubMed search engine and our snippet extraction technique. In our QA system, apart from the standard techniques discussed in literature, we tried the following novel techniques to -a) leverage web search results for improving question processing and b) identify domain words and define a new answer ranking function based on number of common domain words. We scored an F-measure of 0.193 for document extraction and F-measure of 0.0717 in snippet generation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The present innovations in the bio-medical domain is leading to the creation of large amounts of data. The bio-medical literature growth can be understood from the vast data in PubMed [2] database of National Library of Medicine (NLM) which contains more than 14 million articles and hundreds of thousands more are being added every year <ref type="bibr" coords="1,279.77,543.52,9.96,8.74" target="#b0">[3]</ref>. However, such a huge repository of data is useful only if it can be easily accessed and the contents retrieved as per the user requirements <ref type="bibr" coords="1,193.88,567.43,14.61,8.74" target="#b11">[14]</ref>. Question Answering (QA) systems enable the user to express their information need in the form of natural language questions and retrieves the precise answers to them.</p><p>QA has been a well studied research area <ref type="bibr" coords="1,334.11,603.32,10.52,8.74" target="#b4">[7,</ref><ref type="bibr" coords="1,346.29,603.32,12.73,8.74" target="#b12">15,</ref><ref type="bibr" coords="1,360.67,603.32,7.75,8.74" target="#b5">8,</ref><ref type="bibr" coords="1,370.08,603.32,11.62,8.74" target="#b15">18]</ref>. However, QA in Bio-Medical Domain has its own challenges like presence of complex technical terms, compound words and domain specific semantic ontologies <ref type="bibr" coords="1,402.89,627.23,14.61,8.74" target="#b13">[16]</ref>. BioASQ-QA (Task 3b) <ref type="bibr" coords="1,183.31,639.18,15.50,8.74" target="#b14">[17]</ref> is a Bio-Medical Question Answering task which uses benchmark datasets containing development and test questions, in English, along with gold standard answers. The benchmark datasets contain at least 500 questions. The participants have to respond with relevant concepts (from designated terminologies and ontologies), relevant articles (in English, from designated article repositories), relevant snippets, relevant RDF triples, exact answers (e.g., named entities in the case of factoid questions) and Ideal (summary) answers.</p><p>In this paper, we describe the approach taken by the IIIT-Hyderabad team for Task 3b of BioASQ Challenge. For retrieving documents as answers, we used chunking, stop word removal and search query formulation techniques. Later, from the top documents, we filter the most relevant phrases as snippets. For extracting the exact and Ideal answers from the snippets, we used cosine similarity and noun chunk identification techniques.</p><p>The rest of the paper is organized as follows: Section 2, describes the previous work done in Bio-Medical QA. Section 3 describes our approach in more detail. Section 4 gives the experimental results. Finally, Section 5 concludes the paper with future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The Bio-medical Question Answering has been a challenge from past few years. There has been not much progress since then. The major challenge for this was a very complex domain. So, only domain expert could understand the inner details for system to be built. Major concentration was done on the factoid based questions and yes/no questions.</p><p>MedQA <ref type="bibr" coords="2,187.43,399.49,15.50,8.74" target="#b8">[11]</ref> is a bio-medical question answering system which has information retrieval, extraction, and summarization techniques to automatically generate paragraph-level answers for definitional questions. However, it is still limited due to its ability to answer only definitional questions. BioinQA <ref type="bibr" coords="2,425.28,435.36,15.50,8.74" target="#b11">[14]</ref> uses the technique of entity recognition and matching. It is based on the search in context and utilizes syntactic information. BioinQA also answers the comparison type questions from multiple documents, a feature which contrasts sharply with the existing search engines, which merely return answers from single document or passage.</p><p>The jikitou <ref type="bibr" coords="2,201.49,507.28,10.52,8.74" target="#b2">[5]</ref> system's architecture is composed of four subsystems: knowledge base, question analysis, answer agents, and user interface. Multiple software agents find possible answers to questions, and the most relevant one is presented to the user. Additional relevant information is presented to the user establishing a kind of dialog with the user to obtain feedback to refine the query.</p><p>OHSU (Oregon Health &amp; Science University) <ref type="bibr" coords="2,351.80,567.26,10.52,8.74" target="#b3">[6]</ref> does multiple iterations of basic QA with each iteration successively refining the original question such as synonymy expansion, ranked series of topic queries and a range of specificities. Finally, they retrieve all the likely relevant passages in ranked order.</p><p>In <ref type="bibr" coords="2,162.41,615.27,15.50,8.74" target="#b10">[13]</ref> and <ref type="bibr" coords="2,201.09,615.27,14.61,8.74" target="#b16">[19]</ref>, similarity between the question and snippet was computed using cosine similarity and was also used for ranking. They also used domain specific tools like MetaMap <ref type="bibr" coords="2,254.32,639.18,10.52,8.74" target="#b1">[4]</ref> for identifying concepts. Only few <ref type="bibr" coords="2,414.48,639.18,10.52,8.74" target="#b6">[9]</ref> have worked on extracting triples, from different linked data domains like disease ontology <ref type="bibr" coords="2,465.09,651.14,15.50,8.74" target="#b7">[10]</ref>  Our current approach differs with the above approaches in the following ways: a) We leverage web search results in question processing and b) We define new similarity metrics based on common domain words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IIITH Bio-Medical QA System</head><p>We have designed an algorithm to extract the high informative documents for a given question from PubMed articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Architecture</head><p>The architecture of the system is shown in Figure <ref type="figure" coords="3,355.21,463.64,4.98,8.74" target="#fig_0">1</ref> 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2 Document Retrieval</head><p>This Algorithm takes a bio medical question 'Q' and outputs a set of 10 PubMed documents which are having high probability to contain answer 'A' for given Q. Detailed explanation of each step of algorithm is given below.</p><p>1. Question Processing: Let the given question be Q, we need to process the question to make it efficient and optimized for searching. For this we have sequence of sub steps which are explained below. (a) Cleaning: We clean the question for making the search efficient. In this step all unnecessary symbols like question mark(?) , dot(.) etc are removed. We have found that (-) makes the chunking task little difficult and wrong which is crucial task in this step. So Hyphens are replaced with some Named Entity Words. return results 18: end function (b) Chunking: We need to do chunking to get the phrases(chunks) to the modified Question Q. These chunks will be very useful to avoid removal of important(Focus) words which will be done in the next step. We used Annotator module from NLTK<ref type="foot" coords="4,303.60,410.12,3.97,6.12" target="#foot_0">3</ref> Package for chunker. (c) Stop Word Removal: The chunks with all the stop words will be removed. As they don't help at all in a keyword based search. This step makes the question more optimized. We have used NLTK corpus English StopWords list for this task. (d) Domain Word Identification: In the processed query sentence Q, there will be generic words which may not be stop words. But, they contribute nothing in getting the relevant documents. Focus Word Identification step finds only the chunks which are Domain-words, Important Words. The pseudocode for identifying the focus word/chunk is shown at Algorithm 1. We have observed the following list of url patterns that are most relevant to Bio-Medical domain <ref type="foot" coords="4,239.29,551.44,3.97,6.12" target="#foot_1">4</ref> . After the question processing step, the question Q will be modified into set of Focus words, namely Set F Q . 2. PubMed Search: The words in the Focus Word Set will be combined <ref type="bibr" coords="4,449.54,587.81,67.45,8.74">(concatenated)</ref> to make a single string. This string will be fired/searched in PubMed search engine and top 200 documents will be retrieved.</p><p>Algorithm 2 Document Re-Ranking Algorithm</p><formula xml:id="formula_0" coords="5,138.66,133.56,194.50,62.66">1: Q ← Query 2: relDocs ← relaventDocuments 3: function RankAllDocuments(Q, relDocs) 4: Q ← RemoveStopWords(Q) 5:</formula><p>scores ← {} 6:</p><p>for all doci ∈ relDocs do 7:</p><p>Ti ← doci.title 8:</p><p>Ti ← RemoveStopWords(Ti) 9:</p><formula xml:id="formula_1" coords="5,134.77,232.19,163.67,18.82">scores[i] ← CosineSim(Q, Ti) 10:</formula><p>end for 11:</p><p>scores, topDocs ← SortScores(scores, relDocs) 12:</p><p>return topDocs 13: end function 3. Document Re-Ranking: As our question processing is not a standard one, we don't completely depend on PubMed ranking of documents. So we rank the obtained 200 documents again with our approaches. (a) Cosine similarity <ref type="bibr" coords="5,256.86,348.09,16.80,8.77" target="#b10">[13]</ref>:</p><p>We take the original query Q, and Document Title T. (b) Existence Test Score: This measure tells number of common Focus words (Domain words) present in Question Q and title of the document T i .</p><formula xml:id="formula_2" coords="5,238.82,417.36,241.77,12.17">Scores[i] = ExistenceT estScore( Q, T i )<label>(1)</label></formula><p>(c) Hybrid Approach: Finally, we combined both the approaches giving them separate weights and interestingly the scores were better. In this approach the score[i] will be defined as below,</p><formula xml:id="formula_3" coords="5,196.47,481.16,284.13,11.26">Score[i] = α * CosSim( Q, Ti ) + β * ExistT estScore( Q, Ti )<label>(2)</label></formula><p>α, β are normalization constants. After this step, high ranked which are most relevant 10 documents to the given query Q will be retrieved and output to the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Snippet Generation and Ranking</head><p>This section explains about retrieving top 10 snippets for given question Q. The algorithm for Snippet Generation and Ranking is shown in Figure <ref type="figure" coords="5,426.19,591.35,4.98,8.74">2</ref> Initially we take the query Q and send in to the'Document Retrieval algorithm. From this step, we will get top 10 documents for the query Q.</p><p>After obtaining top 10 most relevant documents (D1...D10 ) we take abstracts of all those documents. From all the abstracts we extract all the sentences and make a set S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2: Snippet Generation and Ranking Algorithm</head><p>For all the sentences s in S, we compute similarity scores with query Q. After finding similarity scores for all the sentences we sort and take top 10 sentences matching most with the query Q. We call those High-Matching sentences and snippets and output them to the system.</p><p>As we have parsed the PubMed web(search) page to get the abstracts and pmids, we have used Regular Expressions to identify abstracts and also to split sentences correctly. While finding similarity score between sentences s and query Q, we have used above explained 3 approaches and found hybrid approach(Cosine similarity score+Existence Test score) performance was good.</p><p>This algorithms gave good snippets in which always at least 4 of them contained the exact answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ideal Answer Extraction</head><p>Here a Question and related snippets will be given to our algorithm and it should find Ideal answer i.e. a one or two line answer which perfectly answers the given query.</p><p>For this task we have taken all the sentences from the given snippets and calculated similarity scores with the approaches explained in section 3.2. Top 10 Ideal answers with highest similarity scores will be returned. Fig. <ref type="figure" coords="7,243.98,371.83,3.87,8.74">3</ref>: Exact Answer Extraction Flow</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Exact Answer Extraction</head><p>In this section we will be given with a query and set of snippets. We should result the exact one or two word answers. We have designed an algorithm for giving exact answers for Factoid questions. That approach is explained as a flow chart in Figure <ref type="figure" coords="7,203.59,512.66,3.87,8.74">3</ref>.</p><p>As shown in the Figure <ref type="figure" coords="7,260.48,531.59,3.87,8.74">3</ref>, we start with query Q and all snippets S. We apply, Phase A algorithm for finding top Ideal answers. For each, Ideal answer we find chunks and we consider only "Noun chunks" as we are dealing with only Factoid questions. Each time, we modify the given query Q by replacing question words (like what, when, who etc. ) with the considered "Noun chunk", then we name that new query as Q. Then, we find the similarity score between Q and Ideal answer I di . Similarly, we repeat the same procedure for all ideal answers and their noun chunks. At the end, we sort the similarity scores and output top 10 related noun chunks as exact answers. In this algorithm, we used NLTK parser and Cosine similarity measurement. We got good results with proposed approaches.</p><p>As part of the BioASQ 3b challenge 2015, we have participated in the batch wise submissions. We could perform relatively better than the baseline System. These results of all submissions for documents and snippets are shown in Table <ref type="table" coords="8,134.77,195.04,4.98,8.74" target="#tab_1">1</ref> and<ref type="table" coords="8,162.44,195.04,35.15,8.74" target="#tab_2">Table 2.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Details</head><p>Task 3b of BioASQ 2015 released a training dataset <ref type="bibr" coords="8,363.26,287.36,15.50,8.74" target="#b14">[17]</ref> of 810 question-answer pairs and testing data comprising of 100 questions was released for five consecutive weeks. The average length of each question was 10 words. Out of 100 questions, on an average 30 factoid questions, 25 list type, 25 yesno type and 20 summary type of questions were there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>The evaluation metrics used in this task are mean precision, mean recall, and mean F -measure of the documents, snippets, exact and ideal answers returned by the system <ref type="bibr" coords="8,198.80,451.41,14.61,8.74" target="#b14">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Setup</head><p>Different experiments have been conducted to improve the accuracy of system such as:</p><p>1. Increased the retrieved documents after PubMed Search step from 60 documents to 100 documents.</p><p>2. Defined new similarity measure called Existance Similarity and combined it with cosine similarity, which increased the accuracy of the system. Our best results in snippet extraction for Task 3b Phase A has been achieved(see table 2, bold). Our system name for submission was "qaiiit system 1". In fact that was achieved in statistical approach. This approach was found better compared to baseline system.  Automatic scores System Name Rouge-2 Rouge-SU4 qaiiit system 1 0.3036 0.3299</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>In Table <ref type="table" coords="9,189.58,525.22,3.87,8.74" target="#tab_3">3</ref>, from the snippets given by the BioASQ, we found most relevant snippet based on hybrid similarity match and returned respective snippet as the ideal answer. By using this method, rougue score was about 0.303, just below the baseline of 0.46.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we describe the approach taken by IIIT-H team for the Bio-Medical Question Answering task of BioASQ task 3B. Apart from the standard QA techniques, our current approach differs in the following ways -a) We leverage web search results in question processing and b) We define new similarity metrics based on common domain words. By applying our approach, we obtained Fmeasure of 0.193 for document extraction and F-measure of 0.0717 in snippet generation.</p><p>As part of the future work, we would be working on the Triples extraction, which is still under progress, as no one has even attempted it. We will also be using more domain specific entity recognition tools, for more cleaner way of identifying the exact answer. For the ideal answer or summary type answers, we are working on answer generation techniques from snippets of multiple documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,248.33,251.59,118.70,8.74;3,165.95,110.85,283.46,129.21"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: System Architecture</figDesc><graphic coords="3,165.95,110.85,283.46,129.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,161.66,110.85,292.04,240.95"><head></head><label></label><figDesc></figDesc><graphic coords="6,161.66,110.85,292.04,240.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,159.26,110.86,296.83,249.45"><head></head><label></label><figDesc></figDesc><graphic coords="7,159.26,110.86,296.83,249.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,166.95,151.82,281.46,81.57"><head>Table 1 :</head><label>1</label><figDesc>Document Extraction Results of All Batches</figDesc><table coords="9,166.95,169.12,281.46,64.28"><row><cell></cell><cell>Mean</cell><cell></cell></row><row><cell>System Name</cell><cell cols="3">precision Recall F-Measure MAP GMAP</cell></row><row><cell cols="2">batch1-qaiiit system 1 0.1957</cell><cell>0.1757 0.1559</cell><cell>0.1099 0.0006</cell></row><row><cell cols="2">batch2-qaiiit system 1 0.2379</cell><cell>0.2353 0.193</cell><cell>0.1092 0.0022</cell></row><row><cell cols="2">batch3-qaiiit system 1 0.1643</cell><cell>0.1719 0.1448</cell><cell>0.0569 0.0003</cell></row><row><cell cols="2">batch4-qaiiit system 1 0.2144</cell><cell>0.2376 0.1893</cell><cell>0.1057 0.0008</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,157.91,331.21,299.53,70.61"><head>Table 2 :</head><label>2</label><figDesc>Snippet Generation and Ranking Results of All Batches</figDesc><table coords="9,157.91,348.51,299.53,53.32"><row><cell></cell><cell>Mean</cell><cell></cell><cell></cell></row><row><cell>System Name</cell><cell cols="3">precision Recall F-Measure MAP GMAP</cell></row><row><cell>batch1-qaiiit system 1</cell><cell>0.0616</cell><cell>0.0697 0.0511</cell><cell>0.0545 0.0002</cell></row><row><cell cols="2">batch2-qaiiit system 1 0.0819</cell><cell>0.0889 0.0717</cell><cell>0.0709 0.0004</cell></row><row><cell>batch4-qaiiit system 1</cell><cell>0.0976</cell><cell>0.0844 0.0816</cell><cell>0.0913 0.0003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,215.36,449.89,184.64,8.74"><head>Table 3 :</head><label>3</label><figDesc>Ideal Answer Batch 2 Submission</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="4,144.73,629.90,201.81,8.12"><p>Natural Language Toolkit http://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="4,144.73,640.86,335.86,7.86;4,144.73,651.82,187.48,7.86"><p>Patterns in website urls which store bio-medical information "nlm.nih.gov", "webmd.com", "medicine", "biocare", "drugs"</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,277.32,258.63,7.86" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="https://www.nlm.nih.gov/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,288.46,337.64,7.86;10,151.52,299.41,254.29,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,213.52,288.46,267.08,7.86;10,151.52,299.41,93.01,7.86">Effective Mapping of Biomedical Text to the UMLS Metathesaurus: The Metamap Program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,253.31,299.41,69.74,7.86">Proc AMIA Symp</title>
		<meeting>AMIA Symp</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,310.54,337.63,7.86;10,151.52,321.50,285.99,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,244.41,310.54,236.18,7.86;10,151.52,321.50,258.05,7.86">The jikitou Biomedical Question Answering System: Facilitating the Next Stage in the Evolution of Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Anton</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,332.63,337.63,7.86;10,151.52,343.59,329.07,7.86;10,151.52,354.55,329.07,7.86;10,151.52,365.51,270.96,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,151.52,343.59,265.10,7.86">The OHSU Biomedical Question Answering System Framework</title>
		<author>
			<persName coords=""><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Seeger</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,317.91,354.55,142.33,7.86">TREC, volume Special Publication</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lori</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="500" to="274" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,376.64,337.64,7.86;10,151.52,387.60,52.76,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,313.42,376.64,150.48,7.86">A Simple Question Answering System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><forename type="middle">M</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,387.60,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,398.73,337.63,7.86;10,151.52,409.69,76.93,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,236.72,398.73,89.39,7.86">Ibm&apos;s Watson/Deepqa</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">A</forename><surname>Ferrucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,338.96,398.73,136.93,7.86">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,420.82,337.63,7.86;10,151.52,431.78,329.07,7.86;10,151.52,442.74,269.74,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,304.27,420.82,176.32,7.86;10,151.52,431.78,49.25,7.86">Towards Question Answering on Statistical Linked Data</title>
		<author>
			<persName coords=""><forename type="first">Konrad</forename><surname>Höffner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,224.82,431.78,255.77,7.86;10,151.52,442.74,71.28,7.86">Proceedings of the 10th International Conference on Semantic Systems, SEM &apos;14</title>
		<meeting>the 10th International Conference on Semantic Systems, SEM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="61" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,453.87,337.97,7.86;10,151.52,464.83,329.07,7.86;10,151.52,475.79,329.07,7.86;10,151.52,486.75,329.07,7.86;10,151.52,497.71,306.29,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,285.11,475.79,195.48,7.86;10,151.52,486.75,329.07,7.86;10,151.52,497.71,50.67,7.86">Disease Ontology 2015 update: An Expanded and Updated Database of Human Diseases for Linking Biomedical Knowledge through Disease Data</title>
		<author>
			<persName coords=""><forename type="first">Warren</forename><forename type="middle">A</forename><surname>Kibbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cesar</forename><surname>Arze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elvira</forename><surname>Mitraka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evan</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Mungall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janos</forename><forename type="middle">X</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Drashtti</forename><surname>Vasant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Helen</forename><surname>Parkinson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lynn</forename><forename type="middle">M</forename><surname>Schriml</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,210.75,497.71,91.58,7.86">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="1071" to="D1078" />
			<date type="published" when="2015-01">January 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,508.84,337.98,7.86;10,151.52,519.79,329.07,7.86;10,151.52,530.75,329.07,7.86;10,151.52,541.71,121.50,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,219.22,519.79,239.86,7.86">Beyond Information RetrievalMedical Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Minsuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hai</forename><forename type="middle">Ran</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carl</forename><surname>Sable</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vijay</forename><surname>Shanker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Ely</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,530.75,150.08,7.86">AMIA annual symposium proceedings</title>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2006</biblScope>
			<biblScope unit="page">469</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,552.84,337.98,7.86;10,151.52,563.80,329.07,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="10,431.53,552.84,49.07,7.86;10,151.52,563.80,96.17,7.86">Introduction to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prabhakar</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,574.93,337.98,7.86;10,151.52,585.89,329.07,7.86;10,151.52,596.85,329.07,7.86;10,151.52,607.81,93.23,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,349.85,574.93,130.74,7.86;10,151.52,585.89,312.71,7.86">NCBI at the 2014 BioASQ challenge task: Large-scale Biomedical Semantic Indexing and Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Yuqing</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Hsuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,596.85,168.15,7.86">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,618.94,337.98,7.86;10,151.52,629.90,329.07,7.86;10,151.52,640.86,329.07,7.86;10,151.52,651.82,169.53,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,409.27,618.94,71.32,7.86;10,151.52,629.90,329.07,7.86;10,151.52,640.86,27.04,7.86">Bioinqa: Addressing Bottlenecks of Biomedical Domain through Biomedical Question Answering System</title>
		<author>
			<persName coords=""><forename type="first">Sparsh</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saket</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ankush</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sumit</forename><surname>Bhatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,202.65,640.86,277.94,7.86;10,151.52,651.82,82.61,7.86">The International Conference on Systemics, Cybernetics and Informatics (ICSCI-2008)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="98" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,114.69,337.98,7.86;11,151.52,125.65,200.53,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,289.34,114.69,191.25,7.86;11,151.52,125.65,34.04,7.86">QANUS: An Open-Source Question-Answering Platform</title>
		<author>
			<persName coords=""><forename type="first">Jun-Ping</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.00311</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="11,142.62,136.61,337.98,7.86;11,151.52,147.57,329.07,7.86;11,151.52,158.53,329.07,7.86;11,151.52,169.49,186.14,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,343.07,136.61,137.52,7.86;11,151.52,147.57,144.45,7.86">Biomedical Text Retrieval in Languages with a Complex Morphology</title>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Honeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Udo</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,318.09,147.57,162.50,7.86;11,151.52,158.53,219.29,7.86">Proceedings of the ACL-02 workshop on Natural language processing in the biomedical domain</title>
		<title level="s" coord="11,466.98,158.53,13.62,7.86;11,151.52,169.49,158.27,7.86">Association for Computational Linguistics</title>
		<meeting>the ACL-02 workshop on Natural language processing in the biomedical domain</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,180.45,337.98,7.86;11,151.52,191.41,329.07,7.86;11,151.52,202.36,329.07,7.86;11,151.52,213.32,329.07,7.86;11,151.52,224.28,126.91,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,339.89,202.36,140.69,7.86;11,151.52,213.32,299.23,7.86">An Overview of the BioASQ Large-Scale Biomedical Semantic Indexing and Question Answering Competition</title>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Michael R Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anastasia</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergios</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitris</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Polychronopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,459.27,213.32,21.32,7.86;11,151.52,224.28,55.85,7.86">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,235.24,337.98,7.86;11,151.52,246.20,147.60,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,240.17,235.24,219.90,7.86">Multi-Lingual Question Answering using OpenEphyra</title>
		<author>
			<persName coords=""><surname>Menno Van Zaanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,246.20,98.87,7.86">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,257.16,337.98,7.86;11,151.52,268.12,329.07,7.86;11,151.52,279.08,329.07,7.86;11,151.52,290.04,86.28,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,406.16,257.16,74.43,7.86;11,151.52,268.12,145.98,7.86">Answering Factoid Questions in the Biomedical Domain</title>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,226.76,279.08,61.70,7.86">BioASQ@CLEF</title>
		<title level="s" coord="11,359.79,279.08,120.80,7.86;11,151.52,290.04,20.74,7.86">CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">George</forename><surname>Paliouras</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1094">1094. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
