<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.99,116.95,299.38,12.62;1,141.62,134.89,332.11,12.62">CoMiC: Exploring Text Segmentation and Similarity in the English Entrance Exams Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,234.12,172.56,51.05,8.74"><forename type="first">Ramon</forename><surname>Ziai</surname></persName>
							<email>rziai@sfs.uni-tuebingen.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Universität Tübingen</orgName>
								<address>
									<addrLine>SFB 833, Nauklerstr. 35</addrLine>
									<postCode>72070</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.87,172.56,73.36,8.74"><forename type="first">Björn</forename><surname>Rudzewitz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universität Tübingen</orgName>
								<address>
									<addrLine>SFB 833, Nauklerstr. 35</addrLine>
									<postCode>72070</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.99,116.95,299.38,12.62;1,141.62,134.89,332.11,12.62">CoMiC: Exploring Text Segmentation and Similarity in the English Entrance Exams Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BF8D39DF73205460046A3F23BD8A7F05</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Short Answer Assessment</term>
					<term>Question Answering</term>
					<term>Reading Comprehension</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our contribution to the English Entrance Exams task of CLEF 2015, which requires participating systems to automatically solve multiple choice reading comprehension tasks. We use a combination of text segmentation and different similarity measures with the aim of exploiting two observed aspects of tests: 1) the often linear relationship between reading text and test questions and 2) the differences in linguistic encoding of content in distractor answers vs. the correct answer. Using features based on these characteristics, we train a ranking SVM in order to learn answer preferences. In the official 2015 competition we achieve a c@1 score of 0.29, a medium but encouraging result. We identify two main issues that pave the way towards further research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computational approaches to comparing and evaluating meaning of language have been the focus of much research in the last years, as demonstrated by shared tasks such as Recognizing Textual Entailment <ref type="bibr" coords="1,333.50,501.70,10.52,8.74" target="#b5">[6]</ref> and various SemEval tasks, e.g. Semantic Textual Similarity <ref type="bibr" coords="1,260.71,513.65,9.96,8.74" target="#b0">[1]</ref>. While earlier work concentrated on comparing the meaning of sentences and text fragments in isolation, there has been a trend towards contextualizing such tasks in a concrete application scenario, such as evaluating learner answers to comprehension questions, as in the 2013 Joint Student Response Analysis and Recognizing Textual Entailment task <ref type="bibr" coords="1,446.06,561.47,9.96,8.74" target="#b6">[7]</ref>. Our core research focus lies in the same area, and we have participated competitively in the latter task <ref type="bibr" coords="1,212.06,585.38,14.61,8.74" target="#b12">[13]</ref>.</p><p>In this paper, we describe our contribution to the 2015 English Entrance Exams task, a relatively new development in the area. It is similar to our core task of Short Answer Evaluation in that both require evaluation of answers to questions about a text, but differs in that it is a multiple choice task and hence does not include reference answers to which student input can directly be compared. The objective of the Entrance Exams task is to build a system which assumes the role of a test-taker in multiple choice reading comprehension exams. As a subtask of the CLEF Question Answering track, the task involves both pinpointing the location of relevant text passages and recognizing the meaning equivalence or difference of answer candidates, making it an especially challenging undertaking.</p><p>However, the task provides an interesting testbed for various research questions concerning reading comprehension. Among these, one is of particular interest to us: Given a question and a text, how can one accurately and robustly pinpoint to the relevant part in the text? In participating in the Entrance Exams task, we hope to cover some way towards answering that question.</p><p>The structure of the paper is as follows: section 2 gives an overview of the data used, and section 3 explains our approach to the task. Section 4 then discusses results and problems before section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data as provided by the task organizers is comprised of English reading tests posed as an entrance requirement at Japanese universities. Every reading test consists of a text, three to seven questions, and four answer candidates to every question. Out of the answer candidates, exactly one is correct, which sets the random baseline to 25%. The texts are mostly fictional in nature, which is likely intentional because world knowledge would interfere with language competence in factual texts: for example, a specialized text on spiders would be easier for students with prior knowledge of zoology than for those without, regardless of their language skills. Figure <ref type="figure" coords="2,181.59,409.71,4.98,8.74" target="#fig_0">1</ref> shows an example of a test with one question and its four answer candidates. The correct answer to People are normally regarded as old when according to the text is c) they are judged to be old by society. The relevant information can be found in the fourth sentence of the text: But in general, people are old when society considers them to be old, that is, when they retire from work at around the age of sixty or sixty-five. In this case, the test-taker needs to recognize that consider and judge are synonyms according to the context.</p><p>The task organizers provided the data from the 2013 and 2014 editions of the Entrance Exams task as training data, which are both approximately equal in size and do not overlap in language material. The 2015 data set is larger, with 19 reading tests as compared to the 12 in the previous editions. Table <ref type="table" coords="2,438.11,529.26,4.98,8.74" target="#tab_0">1</ref> gives an overview of the three data sets. When is a person old? There are many individuals who still seem 'young' at seventy or more, while others appear 'old' in their fifties.</p><p>From another point of view, sumo wrestlers, for instance, are 'old' in their thirties, whereas artists' best years may come in their sixties or even later. But in general, people are old when society considers them to be old, that is, when they retire from work at around the age of sixty or sixty-five. Nowadays, however, the demand for new work skills is making more and more individuals old before their time.</p><p>Although older workers tend to be dependable, and have much to offer from their many years of experience, they are put at a disadvantage by rapid developments in technology. Older people usually find it more difficult to acquire the new skills required by technological changes, and they do not enjoy the same educational opportunities as young workers. When they finally leave work and retire, people face further problems. The majority receive little or no assistance in adjusting to their new situation in the community. Moreover, since society at present appears to have no clear picture of what place its older members should occupy, it is unable to offer them enough opportunities to have satisfying social roles after they retire. In the past, the old used to be looked upon as experts in solving various problems of life. Today, however, they are no longer regarded as such and are seldom expected to play significant roles in social, economic and community affairs. With the number of older people in the population rapidly increasing, we need greatly to increase and improve the opportunities provided for them so that they can participate in society with dignity and respect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>People are normally regarded as old when Answer Candidates: a) they are in their fifties b) they are judged to be old by to society (correct) c) they consider themselves too old to work d) they reach the age of seventy As mentioned in the introduction, the Entrance Exams task can be seen as a two-step problem: one needs to 1) identify the part of the text that a question is about and 2) identify the answer whose meaning is expressed in that text part. While 1) is mainly needed to narrow down the search space, 2) is where the test-taker needs to demonstrate their grasp of the content. We will first give a short overview of our approach before going into more detail on how each step was handled. Part 1), which we will call Text Segment Identification for the purposes of this paper, was accomplished by i) using a text segmentation algorithm to partition the text into meaningful paragraphs and ii) comparing the question to each paragraph using a similarity metric. The result is an ordering of paragraphs by similarity to the question. Part 2), which will be called Answer Selection was tackled by a) extracting different similarity features of each answer candidate to each paragraph in the order determined before, and b) using these features to train a ranking SVM model for pairwise answer candidate comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing and Architecture</head><p>As a prerequisite to the later steps, a certain amount of pre-processing needs to be done. The whole architecture of our system was realized using the UIMA framework <ref type="bibr" coords="4,185.50,373.65,9.96,8.74" target="#b7">[8]</ref>, with DKPro Core <ref type="bibr" coords="4,289.77,373.65,10.52,8.74" target="#b2">[3]</ref> for the pre-processing components and DKPro Similarity <ref type="bibr" coords="4,217.04,385.60,10.52,8.74" target="#b1">[2]</ref> for the similarity metrics. We experimented with different options, but the final set of NLP components was the one shown in Table <ref type="table" coords="4,472.86,397.56,3.87,8.74">2</ref>. Most of the pre-processing is needed in order to perform coreference resolution, which we use to resolve each coreferent expression to its first mention before we apply any similarity metrics. Clear SRL <ref type="bibr" coords="4,384.28,552.57,9.73,7.86" target="#b4">[5]</ref> Table <ref type="table" coords="4,207.79,573.01,4.13,7.89">2</ref>. NLP components used in our system via DKPro Core</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text Segment Identification</head><p>In order to find meaningful text segments, we employed the C99 text segmentation algorithm <ref type="bibr" coords="4,201.73,657.11,9.96,8.74" target="#b3">[4]</ref>, which groups sentences based on their similarity. The algo-rithm optionally takes the desired number of segments as an argument, which we used in order to get the same number of segments, and hence answer features computed, for every question-text combination. By applying C99 without that parameter first and observing its behaviour, we found that four text segments were chosen in most cases and used that setting.</p><p>In order to determine the similarity of the question and the different text fragments, we employed the VectorIndexSourceRelatedness measure from DKPro, a vector-based metric using an index derived from the English Wiktionary corpus. We complemented this measure by exploiting a fact that we observed about the reading tests: in many cases, the questions follow the text in a linear fashion, i.e. question 1 will likely be answered in the beginning of the text whereas question 4 will probably be answered near the end. Thus, we calculated a weight w for the similarity metric as follows:</p><formula xml:id="formula_0" coords="5,214.97,288.11,265.63,9.65">w = min(num q , num t )/max(num q , num t )<label>(1)</label></formula><p>where num q is the number of the current question and num t is the number of the current text fragment. Using this weight, we penalize similarity scores of question-fragment combinations whose relative position is very different, while leaving those whose relative position is the same unchanged.</p><p>The result of the procedure above is an ordering of text fragments for each question by weighted similarity score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Answer Selection</head><p>In the Answer Selection step, our goal is to extract features for each answer candidate that allow a characterization of its adequacy. To that end, we compare each answer candidate to each text fragment using three different similarity metrics: the vector-space measure we already used in the previous step, the Resnik similarity measure based on WordNet <ref type="bibr" coords="5,309.28,465.68,14.61,8.74" target="#b15">[16]</ref>, and the Greedy String Tiling algorithm <ref type="bibr" coords="5,173.06,477.64,15.50,8.74" target="#b17">[18]</ref> with a minimum match length of 3. The idea behind using these measures of differing linguistic depth was to capture whether answer candidates are expressed literally in the text or whether more language understanding was necessary to compare their meaning to that in the text. Following some manual inspection of training data, we hypothesized that false answer candidates would often be those that can be found literally in the text whereas the correct one would require more work for the test-taker. Consider again the example in Figure <ref type="figure" coords="5,151.85,561.32,3.87,8.74" target="#fig_0">1</ref>, where the correct answer requires the knowledge that consider and judge are synonymous in the context.</p><p>The three similarity measures were extracted for every combination of answer candidate and text fragment, in the order determined by the Text Segment Identification step. The ordering is crucial because the feature positions then encode whether a given measure was obtained on a fragment close to the question or not. In addition to the similarity measures, we also calculated the overlap of dependency head words and the overlap of semantic roles between answer candidate and text fragment.</p><p>The features obtained were used to train a ranking Support Vector Machine <ref type="bibr" coords="6,134.77,131.95,14.61,8.74" target="#b9">[10]</ref>. We used the SVMRank implementation 1 with hyperparameter c = 20. Ranking was chosen as the preferred approach because it allows characterization of answer candidates in relation to each other and it eliminates the problem of ties, i.e. that two given answer candidates are judged to be equally good and no winner can be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we report and discuss the results we obtained. We first briefly describe the experiment setup before turning to the results proper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>We used the 2014 data set as our training set and the 2013 data set as the development set. This was purely arbitrary, as in principle any setup that has completely distinct training and development sets is valid. Both data sets are approximately equal in size with 12 reading tests and 58 ± 2 questions. We used the development set to select the combination of components and measures we would use for the final submission, and we submitted one run only. For training the final model and testing on the official 2015 test data, we naturally used both training and development data. We did not make use of the possibility not to answer some of the questions, so accuracy and the official evaluation measure c@1 <ref type="bibr" coords="6,155.24,409.53,15.50,8.74" target="#b13">[14]</ref> are the same in our case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Quantitative Results</head><p>Table <ref type="table" coords="6,161.87,461.65,4.98,8.74" target="#tab_2">3</ref> shows the results of our system in relation to the best runs according to overall c@1 of each participating team on the official 2015 test set. Additionally, we included the random baseline and the worst submission. A reading test counts as passed if on the total of its questions one achieves a c@1 score of at least 0.5. As can be observed in the table, our system clearly beats the random baseline. However, on the one hand, it does not reach the performance level of the currently top-performing systems. On the other hand, one can observe that there is a steep drop in c@1 from the top system (Synapse) to the runner-up (LIMSI-QAEE). With our result of 0.29, we place ourselves exactly in the middle if one considers all 17 submissions. In the next section, we will try to provide some insight into what the biggest issues are for our system and what can be done to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We proceed by first discussing two particular reading tests of the 2015 test setone where our system did badly, and one where we achieved the best c@1 score among all participants. The remainder of this section is dedicated to discussing the performance of the Text Segment Identification sub-module, since it is of special interest to our research agenda.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Example Reading Tests</head><p>The text of reading test 2 is about tofu, how it came from China to Japan, is used differently in both cuisines, and how it became more popular in western countries as well. Our system did not answer a single question correctly, a fact which we attribute to two main problems: first, the text is quite short with only 312 words which means there is less room for error in identifying the right text fragments -if the algorithm is off by one or two sentences, the fragment will not contain all the necessary information needed to confirm or reject an answer. Second, the vocabulary is not very diverse across text passages, which makes it hard to compare meaning based on the essentially term-based similarity metrics we employ. It seems that what is needed here is a comparison of relations between terms, not just the terms themselves.</p><p>Test 13 is in some ways the opposite of this: it has a long text (738 words) on the success story of a rock-climber who lost his legs but still wants to climb the "highest vertical cliff on earth". Our system achieved a c@1 score of 0.83 on this test -the best result among all participants. The text contains some rather specialized vocabulary which differs across text passages, so we assume this is why our approach does well here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation of Text Segment Identification</head><p>As described in section 3.2, our system first ranks the automatically determined segments of a text according to their similarity to every question. This similarity additionally is weighted by a linearity weight (see equation 1) to prefer selections of segments parallel to the linear order of questions to this text.</p><p>In order to evaluate the performance of the system's text segment identification module in isolation, the official 2015 test questions were manually annotated for this subtask after applying the C99 text segmentation algorithm. We then compared the system's prediction for the segment containing the answer to a given question against the manually annotated gold standard segment. For 48 out of 89 questions, the system predicted the correct text segment (micro-average = 0.54). The macro-average with respect to individual tests was 0.57.</p><p>A manual inspection of the test data indicated a less strong parallelism between the questions and the corresponding segment than we had seen in the training data. Therefore we ran our system without the linearity weight and compared the results. Although the total number of correctly predicted text segments did not change (micro-average = 0.54), the distribution of correctly predicted segments did decrease (macro-average = 0.53). Moving from accuracy to correlation, the difference between the system with and without the linearity weight becomes even more evident: both measures exhibit a drop from 0.57 to 0.37, showing that even if our system does not always identify the correct segment, it gets much closer to doing so by exploiting this task-specific feature.</p><p>We also analyzed the tests for which our system predicted all segments correctly (tests 12 and 16). While test 12 has 4 questions, and the order of the corresponding segments shows a perfect positive correlation with the question IDs, test 16 only has 3 questions, but 4 segments. Our system correctly identified segment 3 as being irrelevant for answering any of the questions.</p><p>This analysis shows that our system can distinguish between relevant and irrelevant segments in certain cases. In a direct comparison, the linearity feature proved to help modeling aspects of the data, although the system was too biased towards modeling a linear order, which indicates a need for fine-tuning the weight of this feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Additional Synonym Feature</head><p>Recall our hypothesis from section 3.3 that correct answers tend to paraphrase content from the text in order to make the recognition task more challenging for humans. In order to further investigate this hypothesis and better distinguish between similarity at the word surface level and deeper lexical similarity, we added an additional feature after our official submission: a similarity score where all lemmas occurring in both the answer candidate and the text segment were filtered out before passing the remaining lemmas to the previously mentioned vector space measure. We tested the result on our development set and found an improvement of 3.3% (2 out of 60 questions) in c@1 compared to our previous model, which suggests that it is beneficial to examine how exactly correct answers differ from false ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented a new approach to the 2015 English Entrance Exams task. The system was developed from scratch and is built on the idea of exploiting reading comprehension task characteristics, such as text structure and the way distractor answers are constructed. We achieve a c@1 score of 0.29 which is a medium but encouraging result considering the limited time in which the system was put together and the various ways in which it could be improved.</p><p>As identified by the results discussion, our system could be improved mainly in two ways. First, a better tuning of our Text Fragment Identification component, concerning the number and size of text fragments as these are dependent on the task and data set. Also, while clearly useful, the linearity weight we used in order to exploit question order introduced a strong bias. The second strand concerns the introduction of a representation that allows for the comparison of relations between entities in answer and text instead of only employing termbased similarity metrics. One way of achieving this could be to explore the use of Lexical Resource Semantics <ref type="bibr" coords="9,271.75,251.50,15.50,8.74" target="#b16">[17]</ref> in answer comparison, a formalism already used successfully in Short Answer Assessment <ref type="bibr" coords="9,337.90,263.45,9.96,8.74" target="#b8">[9]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,162.47,564.05,290.40,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example reading test with text, question and answer candidates</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,184.29,570.96,246.79,61.61"><head>Table 1 .</head><label>1</label><figDesc>Statistics for the 2013, 2014 and 2015 data sets</figDesc><table coords="2,184.29,570.96,246.79,41.14"><row><cell cols="5">Data set # tests # questions Ø questions/text Ø words/text</cell></row><row><cell>2013</cell><cell>12</cell><cell>60</cell><cell>5.0</cell><cell>624.3</cell></row><row><cell>2014</cell><cell>12</cell><cell>56</cell><cell>4.7</cell><cell>520.0</cell></row><row><cell>2015</cell><cell>19</cell><cell>89</cell><cell>4.7</cell><cell>481.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,137.50,530.95,309.00,134.96"><head>Table 3 .</head><label>3</label><figDesc>Quantitative results of our submission in relation to others1 http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html</figDesc><table coords="6,222.54,530.95,170.28,84.97"><row><cell>Team</cell><cell cols="2">Overall c@1 # tests passed</cell></row><row><cell>Synapse</cell><cell>0.58 (52/89)</cell><cell>16/19</cell></row><row><cell cols="2">LIMSI-QAEE 0.36 (32/89)</cell><cell>8/19</cell></row><row><cell>cicnlp</cell><cell>0.30 (27/89)</cell><cell>6/19</cell></row><row><cell>NTUNLG</cell><cell>0.29 (26/89)</cell><cell>6/19</cell></row><row><cell>CoMiC</cell><cell>0.29 (26/89)</cell><cell>5/19</cell></row><row><cell>Random</cell><cell>0.25 (22/89)</cell><cell>N/A</cell></row><row><cell>Worst</cell><cell>0.21 (19/89)</cell><cell>3/19</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We are grateful to <rs type="person">Cornelius Fath</rs> for manual inspection of the training data and to <rs type="person">Detmar Meurers</rs> and <rs type="person">Kordula De Kuthy</rs> for helpful insights during the system development and feedback on the report. We would also like to thank one anonymous reviewer for comments.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="10,155.24,171.80,325.35,8.74;10,155.24,183.75,325.35,8.74;10,155.24,195.71,325.35,8.74;10,155.24,207.66,325.35,8.74;10,155.24,219.62,325.35,9.02;10,155.24,232.29,94.64,8.30" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,382.55,183.75,98.04,8.74;10,155.24,195.71,173.09,8.74">Semeval-2014 task 10: Multilingual semantic textual similarity</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/S14-2010" />
	</analytic>
	<monogr>
		<title level="m" coord="10,352.09,195.71,128.51,8.74;10,155.24,207.66,269.43,8.74">Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)</title>
		<meeting>the 8th International Workshop on Semantic Evaluation (SemEval 2014)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,242.84,325.34,8.74;10,155.24,254.79,325.35,8.74;10,155.24,266.75,325.35,8.74;10,155.24,278.70,325.34,8.74;10,155.24,290.66,261.24,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,302.35,242.84,178.23,8.74;10,155.24,254.79,104.15,8.74">Dkpro similarity: An open source framework for text similarity</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-4021" />
	</analytic>
	<monogr>
		<title level="m" coord="10,284.96,254.79,195.63,8.74;10,155.24,266.75,304.14,8.74">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08">August 2013</date>
			<biblScope unit="page" from="121" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,301.92,325.35,8.74;10,155.24,313.87,325.34,8.74;10,155.24,325.83,325.35,8.74;10,155.24,337.78,325.35,8.74;10,155.24,349.74,325.35,8.74;10,155.24,361.69,48.98,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,294.57,301.92,186.02,8.74;10,155.24,313.87,228.03,8.74">A broad-coverage collection of portable nlp components for building shareable analysis pipelines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>De Castilho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,192.45,325.83,288.14,8.74;10,155.24,337.78,226.06,8.74">Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING 2014</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ide</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Grivolla</surname></persName>
		</editor>
		<meeting>the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING 2014<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08">Aug 2014</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics and Dublin City University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,372.96,325.35,8.74;10,155.24,384.91,325.35,8.74;10,155.24,396.87,325.35,8.74;10,155.24,408.82,325.34,8.74;10,155.24,421.50,245.83,8.30" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,219.29,372.96,256.68,8.74">Advances in domain independent linear text segmentation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">Y Y</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=974305.974309" />
	</analytic>
	<monogr>
		<title level="m" coord="10,172.34,384.91,308.25,8.74;10,155.24,396.87,183.62,8.74;10,398.57,396.87,58.24,8.74">Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference</title>
		<title level="s" coord="10,465.87,396.87,14.72,8.74;10,155.24,408.82,176.99,8.74">Association for Computational Linguistics</title>
		<meeting>the 1st North American Chapter of the Association for Computational Linguistics Conference<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
	<note>NAACL 2000</note>
</biblStruct>

<biblStruct coords="10,155.24,432.04,325.34,8.74;10,155.24,444.00,325.35,8.74;10,155.24,455.95,227.18,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,259.77,432.04,220.82,8.74;10,155.24,444.00,109.29,8.74">Transition-based semantic role labeling using predicate argument clustering</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,287.23,444.00,193.36,8.74;10,155.24,455.95,145.50,8.74">Proceedings of ACL workshop on Relational Models of Semantics (RELMS&apos;11)</title>
		<meeting>ACL workshop on Relational Models of Semantics (RELMS&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,467.22,325.35,8.74;10,155.24,479.17,325.35,8.74;10,155.24,491.13,325.34,8.74;10,155.24,503.08,325.35,8.74;10,155.24,515.04,325.35,8.74;10,155.24,527.71,303.36,10.23" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,328.31,467.22,152.28,8.74;10,155.24,479.17,77.56,8.74">The pascal recognising textual entailment challenge</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<ptr target="http://u.cs.biu.ac.il/~dagan/publications/RTEChallenge.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="10,195.56,491.13,285.03,8.74;10,155.24,503.08,296.63,8.74">Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification and Recognizing Textual Entailment</title>
		<title level="s" coord="10,462.19,503.08,18.40,8.74;10,155.24,515.04,140.45,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Candela</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Buc</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3944</biblScope>
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,155.24,538.25,325.34,8.74;10,155.24,550.21,325.34,8.74;10,155.24,562.17,325.35,8.74;10,155.24,574.12,325.34,8.74;10,155.24,586.08,325.34,8.74;10,155.24,598.03,325.34,8.74;10,155.24,609.99,325.35,9.02;10,155.24,622.66,162.64,8.30" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,364.21,550.21,116.38,8.74;10,155.24,562.17,325.35,8.74;10,155.24,574.12,20.76,8.74">Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dzikovska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Brew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/S13-2045" />
	</analytic>
	<monogr>
		<title level="m" coord="10,199.46,574.12,281.12,8.74;10,155.24,586.08,51.31,8.74;10,266.16,586.08,214.43,8.74;10,155.24,598.03,204.89,8.74">Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation (SemEval 2013)<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06">June 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="263" to="274" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct coords="10,155.24,633.20,325.35,8.74;10,155.24,645.16,325.35,8.74;10,155.24,657.11,325.34,8.74;11,155.24,120.71,324.29,8.30;11,155.24,132.66,303.37,8.30" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,276.95,633.20,203.64,8.74;10,155.24,645.16,325.35,8.74;10,155.24,657.11,34.17,8.74">UIMA: An architectural approach to unstructured information processing in the corporate research environment</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lally</surname></persName>
		</author>
		<ptr target="http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=252253&amp;fulltextType=RA&amp;fileId=S1351324904003523" />
	</analytic>
	<monogr>
		<title level="j" coord="10,204.08,657.11,146.39,8.74">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="327" to="348" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,143.90,325.36,8.74;11,155.24,155.86,325.36,8.74;11,155.24,167.81,325.36,8.74;11,155.24,179.77,325.36,8.74;11,155.24,192.44,241.60,8.30" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,259.11,143.90,221.49,8.74;11,155.24,155.86,219.63,8.74">Evaluating the meaning of answers to reading comprehension questions: A semantics-based approach</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Meurers</surname></persName>
		</author>
		<ptr target="http://purl.org/dm/papers/hahn-meurers-12.html" />
	</analytic>
	<monogr>
		<title level="m" coord="11,399.12,155.86,81.48,8.74;11,155.24,167.81,325.36,8.74;11,155.24,179.77,184.72,8.74">Proceedings of the 7th Workshop on Innovative Use of NLP for Building Educational Applications (BEA-7) at NAACL-HLT 2012</title>
		<meeting>the 7th Workshop on Innovative Use of NLP for Building Educational Applications (BEA-7) at NAACL-HLT 2012<address><addrLine>Montreal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,203.68,325.36,8.74;11,155.24,215.63,325.36,8.74;11,155.24,227.59,149.44,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,217.92,203.68,219.96,8.74">Optimizing search engines using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,461.62,203.68,18.99,8.74;11,155.24,215.63,325.36,8.74;11,155.24,227.59,27.91,8.74">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,239.54,325.36,8.74;11,155.24,251.50,325.36,8.74;11,155.24,263.45,325.36,8.74;11,155.24,275.41,325.36,8.74;11,155.24,287.36,325.35,9.02;11,155.24,300.03,146.95,8.30" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,205.82,251.50,255.89,8.74">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mc-Closky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P/P14/P14-5010" />
	</analytic>
	<monogr>
		<title level="m" coord="11,155.24,263.45,325.36,8.74;11,155.24,275.41,154.91,8.74">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06">June 2014</date>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,311.27,325.36,8.74;11,155.24,323.23,325.36,8.74;11,155.24,335.18,325.36,8.74;11,155.24,347.86,230.14,10.23" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,217.25,323.23,263.36,8.74;11,155.24,335.18,86.37,8.74">MaltParser: A language-independent system for data-driven dependency parsing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Marsi</surname></persName>
		</author>
		<ptr target="http://w3.msi.vxu.se/~nivre/papers/nle07.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="11,251.25,335.18,137.50,8.74">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,359.09,325.36,8.74;11,155.24,371.05,325.36,8.74;11,155.24,383.00,325.36,8.74;11,155.24,394.96,325.35,9.02;11,155.24,407.63,183.57,8.30" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,350.76,359.09,129.85,8.74;11,155.24,371.05,222.64,8.74">CoMeT: Integrating different levels of linguistic modeling for meaning assessment</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ziai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Meurers</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/S13-2102.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,400.54,371.05,80.07,8.74;11,155.24,383.00,278.75,8.74">Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval)</title>
		<meeting>the 7th International Workshop on Semantic Evaluation (SemEval)<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="608" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,418.87,325.36,8.74;11,155.24,430.82,325.36,8.74;11,155.24,442.78,325.36,8.74;11,155.24,454.74,325.35,9.02;11,155.24,467.41,42.34,8.30" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,261.11,418.87,176.97,8.74">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P11-1142" />
	</analytic>
	<monogr>
		<title level="m" coord="11,461.62,418.87,18.99,8.74;11,155.24,430.82,325.36,8.74;11,155.24,442.78,192.87,8.74">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,478.65,325.36,8.74;11,155.24,490.60,325.36,8.74;11,155.24,502.56,325.36,8.74;11,155.24,514.51,325.35,9.02;11,155.24,527.18,240.60,10.23" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,372.69,478.65,107.91,8.74;11,155.24,490.60,175.10,8.74">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<ptr target="http://www.eecs.berkeley.edu/~petrov/data/acl06.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="11,356.69,490.60,123.91,8.74;11,155.24,502.56,325.36,8.74;11,155.24,514.51,259.30,8.74">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,538.42,325.36,8.74;11,155.24,550.38,325.36,8.74;11,155.24,562.33,325.35,9.02;11,155.24,575.00,319.07,8.30" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,205.38,538.42,275.23,8.74;11,155.24,550.38,295.28,8.74">Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
		<ptr target="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/resnik99a.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="11,457.74,550.38,22.86,8.74;11,155.24,562.33,199.39,8.74">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="95" to="130" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,155.24,586.24,325.36,8.74;11,155.24,598.20,325.36,8.74;11,155.24,610.15,325.36,8.74;11,155.24,622.11,289.80,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,252.67,586.24,182.81,8.74">Basic concepts of lexical resource semantics</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sailer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,283.90,598.20,196.71,8.74;11,155.24,610.15,71.67,8.74">European Summer School in Logic, Language and Information</title>
		<title level="s" coord="11,257.84,610.15,168.34,8.74">Course Material I, Collegium Logicum</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Beckmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Preining</surname></persName>
		</editor>
		<meeting><address><addrLine>Wien</addrLine></address></meeting>
		<imprint>
			<publisher>Kurt Gödel Society</publisher>
			<date type="published" when="2003">2003. 2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="87" to="143" />
		</imprint>
	</monogr>
	<note>Publication Series</note>
</biblStruct>

<biblStruct coords="11,155.24,634.06,325.36,8.74;11,155.24,646.02,210.41,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,207.29,634.06,273.31,8.74;11,155.24,646.02,38.13,8.74">String similarity via greedy string tiling and running karp-rabin matching</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Wise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,201.47,646.02,68.55,8.74">Online Preprint</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<date type="published" when="1993-12">December 1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
