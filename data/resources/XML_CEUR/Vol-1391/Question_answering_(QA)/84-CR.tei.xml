<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.07,115.96,329.22,12.62;1,153.93,133.89,307.49,12.62">CoLe and UTAI at BioASQ 2015: experiments with similarity based descriptor assignment</title>
				<funder ref="#_mQJkVqP">
					<orgName type="full">Ministerio de Economía y Competitividad&quot; and feder</orgName>
				</funder>
				<funder>
					<orgName type="full">&quot;</orgName>
				</funder>
				<funder ref="#_sW28SdE">
					<orgName type="full">Autonomous Government of Galicia</orgName>
				</funder>
				<funder ref="#_zTPeKJP #_qws4m9Q">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,210.93,171.56,90.21,8.74"><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Ribadas</surname></persName>
							<email>ribadas@uvigo.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de InformáticaS. Enxeñería Informática</orgName>
								<orgName type="institution">Universidade de Vigo E</orgName>
								<address>
									<addrLine>Edificio Politécnico, Campus As Lagoas, s/n</addrLine>
									<postCode>32004</postCode>
									<settlement>Ourense</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.70,171.56,85.49,8.74"><forename type="first">Luis</forename><forename type="middle">M</forename><surname>De Campos</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Ciencias de la Computación e Inteligencia Artificial de Granada E.T.S.I. Informática y de Telecomunicación</orgName>
								<orgName type="institution">Universidad</orgName>
								<address>
									<addrLine>Daniel Saucedo Aranda, s/n</addrLine>
									<postCode>18071</postCode>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.93,183.51,79.65,8.74"><forename type="first">Víctor</forename><forename type="middle">M</forename><surname>Darriba</surname></persName>
							<email>darriba@uvigo.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de InformáticaS. Enxeñería Informática</orgName>
								<orgName type="institution">Universidade de Vigo E</orgName>
								<address>
									<addrLine>Edificio Politécnico, Campus As Lagoas, s/n</addrLine>
									<postCode>32004</postCode>
									<settlement>Ourense</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.13,183.51,82.83,8.74"><forename type="first">Alfonso</forename><forename type="middle">E</forename><surname>Romero</surname></persName>
							<email>aeromero@cs.rhul.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Centre for Systems and Synthetic Biology</orgName>
								<orgName type="institution" key="instit1">Royal Holloway</orgName>
								<orgName type="institution" key="instit2">University of London Egham</orgName>
								<address>
									<postCode>TW20 0EX</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.07,115.96,329.22,12.62;1,153.93,133.89,307.49,12.62">CoLe and UTAI at BioASQ 2015: experiments with similarity based descriptor assignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DDAF8BDDBD386E3C821CACF185B029E0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our participation in the third edition of the BioASQ biomedical semantic indexing challenge. Unlike our participation in previous editions, we have chosen to follow an approach based solely on conventional information retrieval tools. We have evaluated various alternatives for creating textual representations of MED-LINE articles to be stored in an Apache Lucene textual index. Those indexed representations are queried using the contents of the article to be annotated and a ranked list of candidate descriptors is created from the retrieved similar articles. Several strategies to post-process those lists of candidate descriptors were evaluated. Performance in the official runs were far from the most competitive systems, but taking into account that our approach in the performed runs did not employ any external knowledge sources, we think that the proposed method could benefit from richer representations for MEDLINE contents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This article describes the joint participation of a group from the University of Vigo and another group from the University of Granada in the biomedical semantic indexing task of the 2015 BioASQ challenge. Participants in this task are asked to classify new MEDLINE articles, labeling those documents with descriptors taken from MeSH hierarchy.</p><p>Both groups (CoLe 4 from University of Vigo and UTAI 5 from University of Granada) have participated in the previous BioASQ editions. Our previous par-ticipations assessed the use of two different machine learning based techniques: a top-down arrangement of local classifiers and a Bayesian network induced by the thesaurus structure. Both approaches modelled the task of assigning descriptors from the MeSH hierarchy to MEDLINE documents as a hierarchical multilabel classification problem.</p><p>In this year participation we have changed the basic approach of our systems, following a similarity based strategy, where the final list of MESH descriptors assigned to a given article is created from the set of most similar MEDLINE articles stored in a textual index created from the training dataset. This neighbor based strategy was partially explored in our previous participations in BioASQ challenge, where a sort of k nearest neighbor was employed as a guide in the topdown traversal of local classifiers approach and also in the selection of submodels (one per MeSH subhierarchy) in the Bayesian network based method. The employment of this k nearest neighbor filtering was mainly due to performance and scalability reasons, but it also had some positive effects on overall annotation quality. For the third BioASQ challenge we have concentrated our efforts on testing the suitability of this similarity based approach and on evaluating several strategies to improve the final ranked list of descriptors.</p><p>The rest of the paper is organized as follows. Section 2 briefly describes the main ideas behind the proposed similarity based approach for MEDLINE article annotation and also describes the text processing being applied. Section 3 gives details about the strategies for improving the final list of ranked descriptors by means of several post-processing methods. Finally, section 4 discusses our official runs in the BioASQ challenge and details the most relevant conclusions of our participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Similarity based descriptor selection</head><p>Approaches based on k nearest neighbors (k-NN) have been widely used in the context of large scale multilabel categorization, even with MEDLINE documents <ref type="bibr" coords="2,163.84,491.59,9.96,8.74" target="#b0">[1]</ref>. The choosing of k-NN based methods is mainly due to its scalability, minimum parameter tuning requirements and, despite its simplicity, its ability to deliver acceptable results in cases where large amounts of examples are available. The approach we have followed in our BioASQ challenge participation is essentially a large k-NN classifier, backed by an Apache Lucene<ref type="foot" coords="2,422.30,537.84,3.97,6.12" target="#foot_2">6</ref> index, with some optimizations due to MeSH usage recommendations on MEDLINE articles annotation. In the case of MEDLINE annotation with MeSH descriptors, despite of being a complex problem, with more than 25,000 possible classes, arranged in a directed acyclic graph (DAG), the availability of a huge training set labeled by human experts supposes an a priori favorable scenario for labeling estimates based on k-NN.</p><p>In our case we have tried to take advantage of certain aspects of semantic indexing process with the MeSH thesaurus to improve the labeling process based  on similarity. Following MeSH annotation guidelines <ref type="bibr" coords="3,365.22,313.93,10.52,8.74" target="#b4">[5]</ref> we propose a differentiated treatment for Check Tags. According to MeSH guidelines, Check Tags are widely used descriptors, shown in Figure <ref type="figure" coords="3,315.55,337.84,3.87,8.74" target="#fig_0">1</ref>, which describe some of the broader aspects of the MEDLINE articles. MeSH annotators can assign an arbitrary number of these Check Tags without any restriction regarding their location in the thesaurus hierarchy.</p><p>To try to exploit this singularity, our system separates the processing of Check Tags and the processing of regular MeSH descriptors. In this way, our annotation scheme starts by indexing the contents of the MEDLINE training articles. For each new article to annotate that index is queried using its contents as query terms. The list of similar articles returned by the indexing engine and their corresponding similarity measures are exploited to determine the following results:</p><p>predicted number of Check Tags to be assigned predicted number of regular descriptors to be assigned ranked list of predicted Check Tags ranked list of predicted regular descriptors The first two aspects conform a regression problem, which aims to predict the number of Check Tags and descriptors to be included in the final list, depending on the number of Check Tags and descriptors assigned to the most similar articles identified by the indexing engine and on their respective scores. The other two tasks are multilabel classification problems, which aim to predict a Check Tags list and a regular descriptors list based on the descriptors and Check Tags manually assigned to the most similar MEDLINE articles. In both cases, regression and multilabel classification based on k-NN, similarity scores calculated by the indexing engine are exploited. These scores are computed during the query processing phase. Query terms employed to retrieve the similar articles are extracted from the original article contents and linked using a global OR operator to conform the final query sent to the indexing engine.</p><p>In our case, the scores provided by the indexing engine are similarity measures resulting from the engine internal computations and the weighting scheme being employed, which do not have an uniform and predictable upper bound. In order to get those similarity scores behave like a real distance metric we have applied the following normalization procedure:</p><p>1. Articles to be annotated are preprocessed in the same way than the training articles and are indexed by the Lucene engine 2. In classification time, all of the relevant index terms from the article being annotated are joined by an OR operator to create the search query 3. In the similar articles ranking returned by the indexing engine the top result will be the same article used to query the index, this result is discarded but its score value (score max ) is recorded for future normalization 4. For each element on the remaining articles set the number of Check Tags and regular descriptors are recorded and it is also recorded the list of real Check Tags and the list of real descriptors, assigning to each of them an estimated distance to the article being annotated, equals to 1 -score scoremax , which will be employed in the weighted voting scheme of the k-NN classification.</p><p>With this information the number of Check Tags and the number of regular descriptors to be assigned to the article being annotated is predicted using a weighted average scheme, where the weight of each similar article is the inverse of the square of the estimated distance to the article being annotated, that is,</p><formula xml:id="formula_0" coords="4,135.96,392.29,47.63,17.63">1 (1-score scoremax )</formula><p>2 . To create the ranked list of Check Tags and the ranked list of regular descriptors a distance weighted voting scheme is employed, associating the same weight values (the inverse of squared estimated distances) to the respective similar article. Since this is actually a multilabel categorization task, there are as many vote tasks as candidate Check Tags or candidate regular descriptors were extracted from the articles retrieved by the indexing engine. For each candidate, positive votes come from similar articles annotated with it and negative votes come from articles not including it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evaluation of article representations</head><p>In our preliminary experiments we have tested several approaches to extract the set of index terms to represent MEDLINE articles in the indexing process. We have also evaluated the effects in annotation performance of the different weighting schemes available in the Apache Lucene indexing engine.</p><p>Regarding article representation, we have employed three index term extraction approaches. In this experiment and also in the official BioASQ runs we have worked only with MEDLINE articles from year 2000 onwards, indexing a total amount of 6,697,747 articles. Index terms which occurred in 5 or less articles were discarded and terms which were present in more than 50 % of training documents were also removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Evaluation of term extraction approaches</head><p>iria-1: n-grams from noun phrase chunks weighting k MiF MiP MiR MaF MaP MaR LCA-F LCA-P LCA-R HiF HiP HiR tfidf 5 0,4662 0,4853 0,4485 0,3289 0,4316 0,3339 0,4098 0,4376 0,4108 0,6125 0,6522 0,6183 10 0,4884 0,5170 0,4628 0,3400 0,4865 0,3413 0,4211 0,4578 0,4146 0,6276 0,6789 0,6225 20 0,4937 0,5297 0,4624 0,3302 0,5057 0,3297 0,4231 0,4664 0,4119 0,6284 0,6881 0,6169 25 0,4940 0,5321 0,4609 0,3294 0,5150 0,3274 0,4220 0,4678 0,4094 0,6276 0,6893 0,6149 30 0,4946 0,5341 0,4606 0,3256 0,5173 0,3235 0,4229 0,4700 0,4090 0,6277 0,6909 0,6136 bm25 5 0,4667 0,4849 0,4497 0,3291 0,4302 0,3354 0,4105 0,4374 0,4117 0,6133 0,6516 0,6191 10 0,4871 0,5154 0,4618 0,3390 0,4824 0,3412 0,4203 0,4574 0,4136 0,6252 0,6753 0,6209 20 0,4922 0,5280 0,4610 0,3315 0,5071 0,3317 0,4209 0,4635 0,4104 0,6268 0,6852 0,6162 25 0,4921 0,5297 0,4595 0,3272 0,5103 0,3265 0,4211 0,4655 0,4089 0,6263 0,6866 0,6141 30 0,4918 0,5304 0,4584 0,3246 0,5133 0,3235 0,4195 0,4657 0,4064 0,6255 0,6883 0,6115 iria-2: stemming and stop-word removal weighting k MiF MiP MiR MaF MaP MaR LCA-F LCA-P LCA-R HiF HiP HiR tfidf 5 0,4746 0,4929 0,4576 0,3410 0,4323 0,3496 0,4168 0,4446 0,4188 0,6199 0,6586 0,6267 10 0,4959 0,5240 0,4706 0,3548 0,4899 0,3588 0,4287 0,4660 0,4228 0,6363 0,6876 0,6311 20 0,5043 0,5401 0,4729 0,3531 0,5249 0,3547 0,4322 0,4762 0,4214 0,6403 0,6998 0,6293 25 0,5036 0,5413 0,4708 0,3485 0,5290 0,3493 0,4310 0,4761 0,4192 0,6394 0,7013 0,6262 30 0,5038 0,5432 0,4697 0,3453 0,5301 0,3456 0,4301 0,4775 0,4168 0,6392 0,7032 0,6246 bm25 5 0,4760 0,4935 0,4597 0,3456 0,4332 0,3555 0,4186 0,4449 0,4214 0,6231 0,6594 0,6316 10 0,4983 0,5259 0,4734 0,3578 0,4912 0,3629 0,4311 0,4677 0,4260 0,6395 0,6898 0,6343 20 0,5061 0,5413 0,4752 0,3530 0,5212 0,3554 0,4330 0,4760 0,4229 0,6409 0,6998 0,6302 25 0,5073 0,5444 0,4750 0,3509 0,5291 0,3534 0,4329 0,4778 0,4214 0,6410 0,7025 0,6283 30 0,5060 0,5446 0,4724 0,3472 0,5290 0,3488 0,4315 0,4776 0,4185 0,6407 0,7040 0,6264 iria-3 lemmatization and PoS tags filtering weighting k MiF MiP MiR MaF MaP MaR LCA-F LCA-P LCA-R HiF HiP HiR tfidf 5 0,4765 0,4932 0,4609 0,3409 0,4346 0,3503 0,4188 0,4445 0,4215 0,6265 0,6610 0,6354 10 0,4982 0,5251 0,4740 0,3561 0,4952 0,3600 0,4304 0,4655 0,4256 0,6408 0,6888 0,6383 20 0,5061 0,5404 0,4758 0,3522 0,5292 0,3531 0,4327 0,4754 0,4221 0,6461 0,7022 0,6364 25 0,5060 0,5429 0,4737 0,3477 0,5328 0,3481 0,4314 0,4758 0,4195 0,6427 0,7029 0,6306 30 0,5062 0,5436 0,4735 0,3458 0,5358 0,3466 0,4314 0,4765 0,4194 0,6430 0,7024 0,6314 bm25 5 0,4792 0,4948 0,4646 0,3465 0,4343 0,3566 0,4203 0,4453 0,4239 0,6283 0,6619 0,6386 10 0,5016 0,5274 0,4782 0,3594 0,4976 0,3650 0,4324 0,4658 0,4292 0,6450 0,6914 0,6435 20 0,5082 0,5416 0,4787 0,3561 0,5261 0,3587 0,4347 0,4761 0,4248 0,6457 0,7019 0,6368 25 0,5090 0,5444 0,4779 0,3528 0,5336 0,3548 0,4345 0,4784 0,4231 0,6456 0,7019 0,6360 30 0,5087 0,5453 0,4767 0,3486 0,5335 0,3496 0,4335 0,4784 0,4217 0,6453 0,7036 0,6350</p><p>Our aim with these experiments was to determine whether linguistic motivated index term extraction could help to improve annotation performance in the k-NN based method we have described. We employed the following methods:</p><p>Stemming based representation. This was the simplest approach which employs stop-word removal, using a standard stop-word list for English, and the default English stemmer from the Snowball project <ref type="foot" coords="5,375.09,537.10,3.97,6.12" target="#foot_3">7</ref> . Some additional post-processing was done using regular expression patterns to remove the most frequent ill-formed stems, like tokens starting with numbers or non-alphabetic characters, which did not resemble chemical compound names and similar cases. Morphosyntactic based representation. To try to deal with the effects of morphosyntactic variation we have employed a lemmatizer to identify lexical roots instead of using word stems and we also replaced stop-word removal with a content-word selection procedure based on part-of-speech (PoS) tags.</p><p>We have delegated the linguistic processing tasks to the tools provided by the ClearNLP project <ref type="foot" coords="6,267.68,129.37,3.97,6.12" target="#foot_4">8</ref> . ClearNLP project offers a set of state-of-theart components written in the Java programming language, together with a collection of pre-trained models, ready to be used in typical natural language processing tasks, like dependence parsing, semantic role labeling, PoS tagging and morphological analysis.</p><p>In our case we have employed the PoS tagger <ref type="bibr" coords="6,378.96,190.00,10.52,8.74" target="#b3">[4]</ref> from the ClearNLP project to tokenize and assign PoS tags to the MEDLINE articles contents. We employed the biomedical tagging models available on ClearNLP repository to feed this PoS tagger, since those pre-trained resources offered fairly good results with no need of additional training.</p><p>In order to filter the content-words from the processed MEDLINE abstracts, we have applied a simple selection criteria based on the employment of the PoS that are considered to carry the sentence meaning. Only tokens tagged as a noun, verb, adjective or as unknown words are taken into account to constitute the final article representation. In case of ambiguous PoS tag assignment, if the second most probable PoS tag is included in the list of acceptable tags, that token is also taken into account.</p><p>After PoS filtering, the ClearNLP lemmatizer is applied on the surviving tokens in order to extract the canonical form of those words. This way we have a method to normalize the considered forms that is slightly more consistent than simple stemming. Like in the previous case, we have customized the lemmatization process using the biomedical dictionary model available at the ClearNLP project repositories. Noun phrases based representation. In order to evaluate the contribution of more powerful Natural Language Processing tools, we have employed a surface parsing approach to identify syntactic motivated noun phrases from which meaningful multi-word index terms could be extracted.</p><p>We have employed a chunker from the Genia Tagger project <ref type="foot" coords="6,429.81,448.56,3.97,6.12" target="#foot_5">9</ref> to process MEDLINE abstracts and to identify chunks of words tagged as noun phrases. Genia Tagger employs a maximum entropy cyclic dependency network <ref type="bibr" coords="6,458.35,474.05,10.52,8.74" target="#b5">[6]</ref> to model the PoS tagging process and its PoS tagger is specifically trained and tuned for biomedical text such as MEDLINE abstracts. Once the input text has been tokenized and PoS tagged by Genia Tagger, a simple surface parser searches for specific PoS patterns in order to detect the boundaries of the different chunks which can constitute a syntactical unit of interest (nominal phrases, prepositional phrases, verbal phrases and other).</p><p>In our processing of MEDLINE articles, from each noun phrase chunk identified in the Genia Tagger output we extract the set of word unigrams (lemmas) and all possible overlapping word bigrams and word trigrams, which will constitute the final list of index terms that will represent the given MEDLINE article in the generated Lucene index.</p><p>The reason to limit this multi-word index term extraction process to only word bigrams and trigrams was to try to get a balance between repre-sentation power and flexibility and generalization capabilities. The chunks identified by Genia Tagger use to be fairly correct and consistent, even when detecting large noun phrases, but employing as index terms the chunker output without some kind of generalization could lead to poor results during the search phase of the k-NN based annotation. With no generalization this approach could degenerate in being able to find similar articles only when an exact match occurs in large multi-word terms.</p><p>All these representation methods shared a common preprocessing phase, where local abbreviation and acronyms were identified and expanded employing a slightly adapted version of the local abbreviation identification method described in <ref type="bibr" coords="7,180.97,252.94,9.96,8.74" target="#b2">[3]</ref>. This method 10 scans the input texts searching for &lt;short-form, long-form&gt; pair candidates, using several heuristics to identify the correct long forms in the ambiguous cases.</p><p>Table <ref type="table" coords="7,178.44,290.95,4.98,8.74">1</ref> summarizes the results obtained in our preliminary tests. To get the performance measures of the different configurations we have employed the BioASQ Project Oracle and as evaluation data we used the MEDLINE articles included in test set number 2 in the second batch of the 2014 edition of BioASQ challenge, which were removed from the training collection the three Lucene indexes were built from.</p><p>We have evaluated the three index term generation methods using different values for k, the number of similar articles to be used <ref type="bibr" coords="7,364.89,376.77,12.73,8.74" target="#b0">(1)</ref> in the estimation of the number of Check Tags and regular descriptors to be assigned and (2) in the set of vote procedures that will construct the final list of Check Tags and descriptors to attach to a given article. We have also evaluated the effect of two index term weighting methods available in version 4.10 of Apache Lucene: a classical tf-idf weighting scheme <ref type="bibr" coords="7,211.97,436.55,10.52,8.74" target="#b8">[9]</ref> and a more complex one inspired by the Okapi BM25 family of scoring formulae <ref type="bibr" coords="7,223.43,448.51,9.96,8.74" target="#b7">[8]</ref>. These weighting schemes are employed by the Lucene engine to compute the similarity scores used to create the ranking of documents relevant to a given query. In our case, the query terms are all of the index terms extracted from the article to be annotated using one of the methods described before.</p><p>As can be seen in table <ref type="table" coords="7,253.25,510.42,4.98,8.74">1</ref> and also in the results of our official BioASQ runs, the best results are obtained with stemming and lemmatization with very similar performance values in both cases. There was a marginal gain in flat measures in favor of stemming based representation and with the hierarchical measures in the case of lemmatization. The representation using multi-word terms extracted from noun phrase chunks had poor performance, probably because of the use of overlapping word trigrams. capabilities of our k-NN method and also in the scoring functions of Lucene engine. Very infrequent index terms can have the undesired effect of boosting internal scores in schemes where inverse document frequencies are taken into account.</p><p>Finally, regarding the effect of taking into account different number of nearest neighbors, the best results are obtained when using values of k around 20, which was the default value in our official runs in BioASQ challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Candidate descriptors post-processing</head><p>In order to improve the results obtained by the Lucene based k-NN approach depicted in previous sections, we have evaluated several alternatives to try to get better annotation performance. We have followed two different lines of work to improve the prediction accuracy out k-NN based system.</p><p>The first weak point in the proposed k-NN based method is related with the fairly simple local decisions performed by our k-NN annotator, given that the generalization is just a weighted average and an inverse distance weighted vote. We have tested a couple of approaches employing more sophisticated decision making. In both cases a two-steps procedure is applied.</p><p>In a first step an expanded list with a larger amount of candidate Check Tags and candidate regular descriptors is created. Those expanded sets of descriptors will be filtered and refined during the second step. In order to add diversity to these expanded candidates lists, the size of both lists (expanded candidates Check Tags and expanded candidate regular descriptors) is twice the size previously predicted by the weighted average procedure described in section 2. Two methods were tested to perform the filtering step:</p><p>Training a per-article multilabel classifier. In this approach, after creating the expanded list of candidate Check Tags and the expanded list of regular descriptors for the MEDLINE article being annotated, two multilabel classifiers, on per expanded list, are trained. The label set for these classifiers are the two lists of expanded candidates, and the training instances comprises up to 1000 most similar articles extracted by the indexing engine.</p><p>Once the training of both classifiers is completed, the contents of the article being annotated are used as input to those models in order to extract the final ranked list of Check Tags and the final list of regular descriptors, using the cut off limits identified by the weighted average estimator.</p><p>In our preliminary evaluation we have employed as multilabel categorization strategy a custom implementation of Classifier Chains <ref type="bibr" coords="8,435.33,525.42,14.61,8.74" target="#b10">[11]</ref>, using as base classifiers instances of Support Vector Machines trained using the LibSVM project <ref type="bibr" coords="8,225.89,549.33,10.52,8.74" target="#b1">[2]</ref> tools. This evaluation was done with a reduced test set and the obtained results were slightly better than the basic k-NN, but still far from the most competitive teams in BioASQ challenge.</p><p>Unfortunately, we were unable to use this method effectively in our official runs of BioASQ challenge. Due to the time restrictions imposed in the challenge and the large training times required by this approach, we were unable to finish any submission on time. Iterative k-NN vote. Instead of employing a multilabel classifier to support the second step we tested the use of another k-NN method backed by the same Lucene index to post-process the expanded lists of candidates.</p><p>For each candidate (both Check Tag or regular descriptor) in each expanded list a new query is sent to the index engine. Our index is queried using the representation of the article being annotated in order to get the list of similar articles which have among their respective extended candidate list the candidate descriptor being evaluated at this moment.</p><p>This new list of similar articles, their normalized distances, is employed in a second voting process. In this case, similar articles where the candidate descriptor was actually assigned as a relevant descriptor are considered as positive votes. Whereas, similar articles where the candidate descriptor would have been a wrong assignment are treated as negative votes.</p><p>What this second step does with the extended candidate lists can be seen as a sort of "learning to discard" procedure. We are evaluating the actual usage of every candidate descriptor in a similar document which also had it as one of its own extended candidates. So, extended candidates that have not been considered as relevant descriptors in the weighted majority of similar documents retrieved during this second phase are discarded.</p><p>Although this approach imposes an extreme use of the Lucene index and implies large disk reading loads, we were able to make it suitable to fulfill the BioASQ challenge time restrictions.</p><p>Another weak point of our basic k-NN method when applied in the context of MeSH annotation is that it does not exploit the hierarchical information carried by the thesaurus structure, whose usage is explicitly described in official MeSH annotation guidelines. To try to overcome this limitation we evaluated the use of semantic similarity measures among MeSH descriptors as a method to expand and rearrange the ranked list of regular descriptor assigned by the basic k-NN method described in previous sections.</p><p>Descriptor expansion with hierarchical similarity measures. We have employed D. Lin's semantic similarity measure <ref type="bibr" coords="9,343.47,468.34,9.96,8.74" target="#b6">[7]</ref>, a well known semantic measure suitable to capture and summarize in a number between 0 and 1 the proximity of two concepts belonging to a common concept taxonomy.</p><formula xml:id="formula_1" coords="9,236.91,514.89,243.68,23.23">sim(s i , s j ) = 2 × logP (LCA(s i , s j )) logP (s i ) + logP (s j )<label>(1)</label></formula><p>We have followed the original formula <ref type="bibr" coords="9,335.84,547.97,11.62,8.74" target="#b0">(1)</ref>, where s i and s j are concepts in a taxonomy, LCA(s i , s j ) represents the lowest common ancestor of both concepts and P (s k ) is an estimation of the probability assigned to concept s k . In our case this probability is computed as the ratio between the number of MeSH descriptors belonging to the subtree rooted at descriptor s k and the total number of descriptor in the MeSH thesaurus.</p><p>In our preliminary tests we applied Lin's measure in a very simple fashion. The ranked list of candidate regular descriptors returned by the basic k-NN based method is expanded adding all MeSH descriptors in a radio of 3 hops, according to the thesaurus hierarchical relationships. The score of those new added descriptors is computed by multiplying the score of the original candidate descriptor with the value of Lin's similarity between it and the added descriptor. For a given descriptor (original or expanded), combined scores coming from the expansion process of different initial candidate descriptors are accumulated.</p><p>Once the expanded list of descriptors created and ranked according to the new scores, two simple heuristics derived from MeSH annotation guidelines <ref type="bibr" coords="10,197.09,202.06,10.52,8.74" target="#b4">[5]</ref> are employed to remove redundant annotations. These removal heuristics are applied iteratively and limited to a window of the top-most n + 3 descriptors, where n is the number of regular descriptors predicted by our k-NN based scheme.</p><p>when tree or more siblings appear in the descriptor window, all of them are replaced by their common parent more specific descriptors (descendants) are preferred over more general ones (ancestors) occurring inside the considered window, and replace them The surviving descriptors are cut off at the number of descriptor predicted by the weighted average predictor, using the combined scores to rank the list.</p><p>A priori this approach seemed to be a promising and effective way to add hierarchical information from the MeSH thesaurus to the k-NN prediction. However, the results we obtained were very disappointing, even worse than the vanilla k-NN approach, and lead us to not submit the results obtained with this method in our official runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Official BioASQ runs and discussion</head><p>Even we have tested several alternatives to try to improve the results obtained by the basic Lucene based k-NN method, only the most simple ones have been submitted to the official batches of BioASQ challenge. Our original objective was to try to approximate to the performance values obtained by the two NLM Medical Text Indexer (MTI) <ref type="bibr" coords="10,260.29,483.14,15.50,8.74" target="#b9">[10]</ref> baselines ("Default MTI" and "MTI First Line Indexer"), since this is the reference tool employed by MEDLINE indexers.</p><p>In table <ref type="table" coords="10,186.24,507.05,4.98,8.74">2</ref> the official performance measures obtained by our runs in the Test Batch number 3 are shown. The name of our runs ("iria") originally stood for Information Retrieval based Iterative Annotator since the initial aim of this participation at BioASQ challenge was to evaluate different approaches to improve the initial ranked list of candidate descriptors retrieved by the indexing engine. The official runs sent by our group during our participation in the Test Batch number 3 were created using the following configurations.</p><p>iria1. Representation of MEDLINE articles using unigrams, bigrams and trigrams extracted from noun phrase chunks identified by means of Genia Tagger.</p><p>As described at the end of section 2.1 only articles from year 2000 onwards were indexed, discarding terms appearing in 5 or less abstracts and term used in more than 50% of total documents. The predicted number of Check Tags and regular descriptors to be returned is increased a 10% in order to ensure slightly better values in recall related measures. iria2. Representation of MEDLINE articles using terms extracted using standard English stop-words removal and stemming. All other parameter are identical to iria1. iria3. Representation of MEDLINE articles using lemmas extracted with ClearNLP tools after PoS tag filtering. All other parameter are identical to iria1 iria4. Using the Lucene index created for iria2 this set of runs employs the Iterative k-NN vote approach described in section 3, using a two step k-NN method. iria-mix. This was a "control" set of runs employed to measure how close were our methods to MTI baselines. In test sets 1,2,3 and 4 iria-mix was simply a weighted mix of our results in iria-2 run with the MTI-DEF and MTI-FLI results distributed by BioASQ organization each week. Weight assigned to each one of these three lists was the respective official MiF values obtained in the previous week. Every descriptor in iria-2, MTI-DEF and MTI-FLI accumulates the weight of the descriptors list where it was included. The final list of descriptors is ranked according to these accumulated scores and the n top-most descriptors are returned as candidates, being n the number of Check Tags and regular descriptors originally predicted by iria-2 run.</p><p>In test set 5, iria-mix used the Lucene index created for iria-2 to test a different k-NN search. In this case, a more complex type of query to find similar documents was evaluated. This query was constituted by the index terms extracted from the abstract to be annotated, like in iria-2 case, but it also included the descriptors assigned in the MTI-DEF results distributed by BioASQ organization that week. That is, in this case the similarity query searches for articles sharing index terms with the abstract being annotated and also with real MeSH descriptors included in the MTI-DEF prediction.</p><p>The results of our participation in the third edition of the BioASQ biomedical semantic indexing challenge are far from the results of the most competitive teams and our particular objective, try to reach performance levels similar to MTI baselines, was not achieved. As positive aspects of our participation, we have shown that k-NN methods backed by conventional textual indexers like Lucene are a viable alternative for this kind of large scale problems, with minimal computational requirements and not so bad results. We also have performed an exhaustive evaluation of the performance of several alternatives to index term extraction, ranging from simple ones, based on stemming rules, to more complex ones were natural language processing is required.</p><p>Our a priori main contribution, the proposed methods to improve initial k-NN predictions, has not obtained real performance improvements, except in the case of training a per-article multilabel classifier. More work needs to be done in this case and also in the use of taxonomy based similarity measures, like Lin's measure, since we still think that is a promising alternative to include hierarchical information on flat categorization approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,178.35,283.04,258.66,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Check Tag list according to MeSH annotation guidelines</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="1,144.73,645.84,242.15,7.86"><p>Compiler and Languages group, http://www.grupocole.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="1,144.73,656.80,327.24,7.86"><p>Uncertainty Treatment in Artificial Intelligence group, http://decsai.ugr.es/utai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="2,144.73,656.80,107.60,7.86"><p>https://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="5,144.73,656.80,113.82,7.86"><p>http://snowball.tartarus.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="6,144.73,645.84,158.48,7.86"><p>Available at http://www.clearnlp.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="6,144.73,656.80,253.18,7.86"><p>Available at http://www.nactem.ac.uk/tsujii/GENIA/tagger/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Research reported in this paper has been partially funded by <rs type="funder">"</rs><rs type="funder">Ministerio de Economía y Competitividad" and feder</rs> (under projects <rs type="grantNumber">FFI2014-51978-C2-1</rs> and <rs type="grantNumber">TIN2013-42741-P</rs>) and by the <rs type="funder">Autonomous Government of Galicia</rs> (under projects <rs type="grantNumber">R2014/029</rs> and <rs type="grantNumber">R2014/034</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mQJkVqP">
					<idno type="grant-number">FFI2014-51978-C2-1</idno>
				</org>
				<org type="funding" xml:id="_sW28SdE">
					<idno type="grant-number">TIN2013-42741-P</idno>
				</org>
				<org type="funding" xml:id="_zTPeKJP">
					<idno type="grant-number">R2014/029</idno>
				</org>
				<org type="funding" xml:id="_qws4m9Q">
					<idno type="grant-number">R2014/034</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,138.35,228.27,342.24,7.86;12,146.91,239.23,333.68,7.86;12,146.91,250.18,114.22,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,456.02,228.27,24.58,7.86;12,146.91,239.23,276.50,7.86">MeSH Up: effective MeSH text classification for improved document retrieval</title>
		<author>
			<persName coords=""><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F De</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Rebholz-Schuhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,429.25,239.23,51.35,7.86;12,146.91,250.18,10.29,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1412" to="1418" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,261.14,342.24,7.86;12,146.91,272.10,287.71,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,259.50,261.14,192.07,7.86">LIBSVM : a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,458.84,261.14,21.75,7.86;12,146.91,272.10,207.14,7.86">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,283.06,342.24,7.86;12,146.91,294.02,286.63,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,264.98,283.06,215.62,7.86;12,146.91,294.02,64.28,7.86">Algorithm for Identifying Abbreviation Definitions in Biomedical Text</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,218.46,294.02,148.52,7.86">Pacific Symposium on Biocomputing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,304.98,342.25,7.86;12,146.91,315.94,333.68,7.86;12,146.91,326.90,276.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,274.77,304.98,205.83,7.86;12,146.91,315.94,89.50,7.86">Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,243.15,315.94,237.45,7.86;12,146.91,326.90,159.96,7.86">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL&apos;12)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL&apos;12)<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="363" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,337.86,342.24,7.86;12,146.91,348.81,306.17,8.11" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="http://www.nlm.nih.gov/bsd/indexing/training" />
		<title level="m" coord="12,294.80,337.86,181.47,7.86">MEDLINE Indexing Online Training Course</title>
		<imprint>
			<date type="published" when="2015-06-05">5th june, 2015</date>
		</imprint>
		<respStmt>
			<orgName>Library of Medicine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,359.77,342.24,7.86;12,146.91,370.73,333.68,7.86;12,146.91,381.69,333.68,7.86;12,146.91,392.65,186.30,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,337.46,370.73,143.13,7.86;12,146.91,381.69,108.93,7.86">Developing a Robust Part-of-Speech Tagger for Biomedical Text</title>
		<author>
			<persName coords=""><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuka</forename><surname>Tateishi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Mc-Naught</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun'ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,263.13,381.69,217.46,7.86;12,146.91,392.65,56.98,7.86">Advances in Informatics, 10th Panhellenic Conference on Informatics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3746</biblScope>
			<biblScope unit="page" from="382" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,403.61,342.24,7.86;12,146.91,414.57,333.68,7.86;12,146.91,425.53,139.48,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,199.39,403.61,199.18,7.86">An Information-Theoretic Definition of Similarity</title>
		<author>
			<persName coords=""><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,405.64,403.61,74.95,7.86;12,146.91,414.57,288.88,7.86">Proceedings of the Fifteenth International Conference on Machine Learning (ICML 1998)</title>
		<meeting>the Fifteenth International Conference on Machine Learning (ICML 1998)<address><addrLine>Madison, Wisconsin, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">July 24-27, 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,436.49,342.25,7.86;12,146.91,447.44,333.68,7.86;12,146.91,458.40,255.69,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,225.53,447.44,69.99,7.86">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,315.82,447.44,164.77,7.86;12,146.91,458.40,100.89,7.86">Proceedings of the Third Text REtrieval Conference (TREC 1994)</title>
		<meeting>the Third Text REtrieval Conference (TREC 1994)<address><addrLine>Gaithersburg, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,469.36,342.25,7.86;12,146.91,480.32,223.40,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,215.67,469.36,264.93,7.86;12,146.91,480.32,45.68,7.86">A Statistical Interpretation of Term Specificity and Its Application in Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,199.54,480.32,105.75,7.86">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,491.28,337.98,7.86;12,146.91,502.24,333.68,7.86;12,146.91,515.06,339.37,5.81;12,146.91,524.16,95.98,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="12,396.21,491.28,84.38,7.86;12,146.91,502.24,297.47,7.86">The NLM Medical Text Indexer System for Indexing Biomedical Literature</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Mork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jimeno Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<ptr target="http://ii.nlm.nih.gov/Publications/Papers/MTISystemDescriptionExpanded2013Accessible.pdf" />
		<imprint>
			<date type="published" when="2013-06-05">2013. 5th june, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,535.12,337.98,7.86;12,146.91,546.07,333.68,7.86;12,146.91,557.03,20.99,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,413.54,535.12,67.05,7.86;12,146.91,546.07,115.08,7.86">Classifier Chains for Multi-label Classification</title>
		<author>
			<persName coords=""><forename type="first">Jesse</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoff</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,269.39,546.07,105.39,7.86">Machine Learning Journal</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="359" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
