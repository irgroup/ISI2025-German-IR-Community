<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.21,116.95,290.94,12.62;1,153.18,134.89,309.00,12.62;1,251.58,152.82,112.19,12.62">A generic retrieval system for biomedical literatures: USTB at BioASQ2015 Question Answering Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,181.62,191.52,67.11,8.74"><forename type="first">Zhi-Juan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.03,191.52,60.58,8.74"><forename type="first">Tian-Tian</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.25,191.52,62.96,8.74"><forename type="first">Bo-Wen</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,401.49,191.52,28.32,8.74"><forename type="first">Yan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,164.60,203.48,67.63,8.74"><forename type="first">Chun-Hua</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.43,203.48,62.16,8.74"><forename type="first">Shao-Hui</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,310.58,203.48,61.43,8.74"><forename type="first">Xu-Cheng</forename><surname>Yin</surname></persName>
							<email>xuchengyin@ustb.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,404.12,203.48,46.63,8.74"><forename type="first">Fang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology Beijing (USTB)</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.21,116.95,290.94,12.62;1,153.18,134.89,309.00,12.62;1,251.58,152.82,112.19,12.62">A generic retrieval system for biomedical literatures: USTB at BioASQ2015 Question Answering Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AE4C04B833627F3A81A0D0F5DD2E3295</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>generic retrieval</term>
					<term>sequential dependence model</term>
					<term>Word Embedding</term>
					<term>Ranking</term>
					<term>MetaMap</term>
					<term>Banner</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our participation in the 2015 BioASQ challenge task on question answering (Phase A). Participants need to respond to the natural language questions in the format of documents, snippets, concepts and RDF triplets. In document retrieval, we build a generic retrieval model based on the sequential dependence model, Word Embedding and Ranking Model. In addition, from the view of the special significance of titles(Title Significance Validation), we re-rank the top-K results by counting the meaningful nouns in the titles. The top-K documents are split into sentences and indexed for snippets retrieval. The similar models of document retrieval are applied for this part. To extract the biomedical concepts and corresponding RDF triplets, we use concept recognition tools MetaMap and Banner 1 . Statistics indicate that our systems outperform other results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The challenge of BioASQ consists of two tasks <ref type="bibr" coords="1,333.07,538.76,9.96,8.74" target="#b0">[1]</ref>: a large-scale semantic indexing task (Task 3a) and a question answering task (Task 3b). We only focus on phase A of Task 3b which includes four parts: retrieving the gold relevant articles and the most relevant snippets from the benchmark datasets, retrieving relevant concepts from designated terminologies and ontologies and RDF triples from designated ontologies. For this task, participants are provided with about 100 questions in each batch and required to return at most 10 answers for each part.In all of the following experiments,we utilize the training datasets 3b which includes 810 queries.</p><p>In our system, we deploy Galago <ref type="foot" coords="2,277.33,142.60,3.97,6.12" target="#foot_1">2</ref> , an open source search engine developed as an improved JAVA version of Indri, over large clusters for indexing and retrieval. We lease 2015 MEDLINE/PubMed Journal Citations from the U.S. National Library of Medicine, composed of about 22 million MEDLINE citations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Pre-Processing</head><p>For documents retrieval, the fields of title and abstract are extracted from document resources and indexed with Galago. On the basis of experimental results of document retrieval, the top-K documents are chosen from the candidates as the source of retrieval for snippets retrieval part. Titles and abstracts of the articles are separated into several sentences according to some specific rules. These sentences make up a pile of new files with the field name Text for indexing. For concepts retrieval part, participants are required to return relevant concepts in five ontologies or terminologies: MeSH, GO, SwissProt, Jochem and DO. We download all the resources and index the fields of term and ID.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Pre-Processing</head><p>Except the experiment of triples retrieval, original queries are processed with the same approaches. The stop words in queries are removed and the queries are case-folded, stemmed and tagged with Porter Stemmer and Part-Of-Speech. Finally we filter out the special symbols.</p><p>MetaMap <ref type="bibr" coords="2,195.52,424.26,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,207.70,424.26,7.01,8.74" target="#b2">3]</ref>, which is a semantic tool in medical text processing, maps concepts in the UMLS Metathesaurus. Biomedical terminologies and ontologies are identified from queries by MetaMap and composed new queries to retrieval concepts. Linked life Data is aggregation of more than 25 popular biomedical data sources. Users are able to access 10 billion RDF statements through a single SPARQL endpoint.</p><p>In the following sections, the procedures of retrieval models sequential dependence model(SDM ), Word Embedding(Word2Vec), Ranking Model(RM ) and Title Significance Validation(TSV ) are introduced in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Searching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Sequential Dependence Model</head><p>Our baseline of documents retrieval is the unigram language model referred as query likelihood model (QL). In this model, the likelihood of query term q i occurring assumed is that not affected by the occurrence of any other query terms. But for a natural language query, the terms depend on each other. So our retrieval models should take the sequence of terms into account.</p><p>Metzler and Crofts Markov Random Field (MRF ) model <ref type="bibr" coords="3,408.09,119.99,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="3,420.26,119.99,7.01,8.74" target="#b4">5]</ref>, also called undirected graphical models, is commonly used in the statistical machine learning domain to succinctly model joint distributions. The sequential dependence model (SDM ) is a special case of the MRF. It assumes the occurrences of adjacent query terms are related.</p><p>Three types of features are considered in SDM : single term features (standard unigram language model features, f T ), exact ordered phrase features (words appearing in sequence, f O ) and unordered window features (require words to be close together, but not necessarily in an exact sequence order, f U ).</p><p>For the query Q after pre-processing, Q=q 1 , q 2 ,. . . ,q i ,. . . . Document D is ranked according to the following equation ( <ref type="formula" coords="3,328.26,239.96,3.87,8.74" target="#formula_0">1</ref>):</p><formula xml:id="formula_0" coords="3,231.31,264.29,249.28,93.97">score SDM (Q, D) = λ T q⊂Q f T (q, D) +λ O |Q|-1 i=1 f O (q i , q i + 1, D) +λ U |Q|-1 i=1 f U (q i , q i + 1, D)<label>(1)</label></formula><p>(λ T , λ O , λ U ) are weight parameters for single terms, ordered terms and unordered terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Word2Vec</head><p>One of the most critical language issues for retrieval performance is the term mismatching problem. The 810 queries of training datasets 3b after pre-processing contains 4609 terms. There are about 5.7 terms on average for each query. The queries are short and the natural language is inherently ambiguous. The queries may not use the same terms as the retrieval sources. Query expansion is usually utilized to select the golden relevant terms to the original queries. However, the main challenge of the query expansion is to find the expansion terms, especially in specific areas, such as biomedicine.</p><p>The result vectors of words offered by BioASQ officials can be used to estimate the relatedness of two words. With the similarities of each two words, the query expansion can be easily applied. The resulting vectors of 1,701,632 distinct words (types) is trained by the Word2Vec<ref type="foot" coords="3,353.68,564.18,3.97,6.12" target="#foot_2">3</ref> tool which processes a large corpus and maps the words in the corpus to vectors of a continuous space. We use these word vectors based on SDM. The feature f T is replaced with f W , which represents the expansion terms feature.</p><p>For a query Q=q 1 , q 2 ,. . . ,q i ,. . . , we calculate the distance between the term q i and all the distinct terms from the dictionary by cosine similarity. Then all the terms are sorted by the distances with q i . The nearest k terms are chosen to enrich the original query. The original terms q i with the additional terms q i1 ,q i2 ,. . . ,q ik , used as expansion terms with corresponding weights w i (i=1,2,. . . ).A new query can be reformulated as Q new =(t 1 ,t 2 ,. . . ,t i ,. . . ),where t i T i =q i ,q i1 ,q i2 ,. . . ,q ik . Documents are ranked by the enriched SDM query T according to the following scoring equation <ref type="bibr" coords="4,240.56,179.99,11.62,8.74" target="#b1">(2)</ref>:</p><formula xml:id="formula_1" coords="4,219.32,204.34,261.27,93.14">score W ord2V ec (Q, D) = λ W t⊂T f W (T, D) +λ O |Q|-1 i=1 f O (q i , q i + 1, D) +λ U |Q|-1 i=1 f U (q i , q i + 1, D)<label>(2)</label></formula><p>(λ W , λ O , λ U ) are the weights for expansion terms, ordered phrases and unordered phrases in SDM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Re-ranking of Word2Vec Results</head><p>In order to improve the retrieval performance, we propose a Reranking Model (RM ) <ref type="bibr" coords="4,160.63,385.34,10.79,8.74" target="#b5">[6,</ref><ref type="bibr" coords="4,173.09,385.34,7.75,8.74" target="#b6">7]</ref> based on the Word2Vec results. For each query, a subset D of results composed by the top-K documents is represented by a vector according to TF-IDF. Then the similarity of each two documents is calculated by the cosine similarity of corresponding vectors. The similarity of the K documents make up the K*K dimension matrix M .M[i][j] represent the similarity of the D i and D j . Via these similarities, we update the score of the documents for each query by Equation (3).score i is the initial score for the D i ,</p><p>The updated score of the document D i for the query Q is calculated by the following equation:</p><formula xml:id="formula_2" coords="4,164.39,512.66,316.21,30.55">score RM (Q, D i ) = λscore i + 1 k -1 (1 -λ) k j=0,j =i (score j * M [i][j])<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Title Significance Validation</head><p>With a specific request and several relevant literatures, people usually directly judge the titles rather than carefully reading the full text of the abstract. In order to investigate the special significance of titles, we design an interesting experiment to validate it. We pick top-K documents retrieved by the Word2Vec model and look up the corresponding titles. Then we compare these titles with the processed query. Different from other type of words, nouns are a meaningful linguistic unit and have virtual influence in natural language.</p><p>Hence, we filter out all types of words from the queries other than the nouns labeled by the Stanford-POS tagger when processing the queries. The frequency with which the nouns occur in the titles are counted as title-hit. We combine the title-hit and initial score by linear combination. We respectively compare (stemmed query, stemmed titles) and (non-stemmed query, non-stemmed titles) to see if title-hit can influence the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments on Generic Retrieval Models</head><p>We train and validate our methods on the training datasets 3b which contains 810 queries based on the 22 million MEDLINE documents. We utilize trec eval <ref type="bibr" coords="5,134.77,256.70,10.52,8.74" target="#b7">[8]</ref> to evaluate the top 100 ranked search lists. Mean average precision(MAP ) <ref type="bibr" coords="5,469.80,256.70,10.79,8.74" target="#b8">[9,</ref><ref type="bibr" coords="5,134.77,268.65,12.73,8.74" target="#b9">10]</ref> serves as our evaluation metric.In the previous years,we are required to return at most 100 relevant results.But the participating systems are required to return at most 10 relevant results in 2015.So we select the best parameters through the training datasets 3b,then the parameters are utilized to the testsets 3b.The results with testsets 3b are offered by BioASQ officials. The scalar µ which is a hyper-parameter controls the amount of collection smoothing applied. We set the value in the range between 500 and 5000.The following tables are only parts of our documents experiments for setting up the parameters on training datasets 3b.</p><p>In SDM, there are three weighting parameters (λ T , λ O , λ U ) to be trained. We set each of the parameters values from 0.00 to 1.00 in steps of 0.01. Based on this, w i in the Word2Vec model, which is the weights for expansion terms, needs to be set. In addition, another issue for query expansion is to confirm how many expansion terms are suitable for retrieval. As a comparison, on all training data, the performance with the expansion terms from 1 to 10 are measured for an optimum parameter. The results are shown in Table <ref type="table" coords="5,379.40,447.98,3.87,8.74" target="#tab_0">1</ref>. Overall, it works well when those parameters are optimized in the datasets 3b.Obviously, Word2Vec shows greater performance compared with QL and SD-M. Especially,the average result with Word2Vec is higher than the other two.So Reranking Model and Title Significance Validation are evaluated based on this model.</p><p>Afterwards, the top-K documents determined by the initial ranking are reranked by RM . The value of K is trained by groups of experiments.The initial scores and similarities are also taken into account. The value λ is changed from 0.000 to 1.000 in steps of 0.001.After many experiments, we get the stable parameter values.The parts of comparison results are shown in Table <ref type="table" coords="6,428.61,167.81,3.87,8.74" target="#tab_1">2</ref>. The RM performs well compared with Word2Vec which the value of λ is 1. Results for the TSV model which contains non-stemmed queries and stemmed queries are presented in Table <ref type="table" coords="6,268.63,309.64,3.87,8.74" target="#tab_2">3</ref>. Experimental results show that the effectiveness is improved when applying title significance validation appropriately.</p><p>We choose the parameters in RM model with best result on the five Batch respectively and then compare to the official results of top 3 winning participants in BioASQ 2014 <ref type="foot" coords="6,206.28,472.01,3.97,6.12" target="#foot_3">4</ref> .Table <ref type="table" coords="6,240.17,473.58,4.98,8.74" target="#tab_3">4</ref> shows the results of our system and top 3 participants. Form the Table <ref type="table" coords="7,222.17,119.99,4.78,8.74" target="#tab_3">4</ref>,we find our results are better than the Top 1 except the Batch3 because of the random data.So our generic retrieval system is more effective in biomedical retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Due to the limited time, we only participate in the phase A of task 3b. But our approaches performs competitive especially during the documents and snippets retrieval. We adopt various retrieval models and adjust almost all possible parameters to improve the final performance. Although our trained system performs stable on the training set 2015 (810 queries), the MAP value on batch 3(testsets 3b) is unusual. Giving a deep analysis of the query set of batch 3, we think the cause may be the count of terms and biomedical nouns in each query.</p><p>In the future, we will focus on the strategies of query expansion on biomedical text, probabilities of improving the document retrieval accuracy through the feedback results of snippets retrieval. Besides, our research will add natural language processing (NLP ) into our system to improve the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,159.01,478.78,296.12,103.37"><head>Table 1 .</head><label>1</label><figDesc>Comparison of QL, SDM, Word2Vec measured with MAP@100</figDesc><table coords="5,226.58,508.08,162.21,74.07"><row><cell>Method</cell><cell>QL SDM Word2Vec</cell></row><row><cell cols="2">Training Set2b 0.2235 0.2381 0.2438</cell></row><row><cell>Batch1</cell><cell>0.2726 0.2947 0.3014</cell></row><row><cell>Batch2</cell><cell>0.2608 0.2771 0.294</cell></row><row><cell>Batch3</cell><cell>0.2588 0.2723 0.2767</cell></row><row><cell>Batch4</cell><cell>0.2476 0.2606 0.2739</cell></row><row><cell>Batch5</cell><cell>0.2389 0.2681 0.2781</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,141.00,204.44,333.36,45.74"><head>Table 2 .</head><label>2</label><figDesc>Results of 810 queries for Reranking Model with MAP@100</figDesc><table coords="6,141.00,230.91,333.36,19.27"><row><cell>λ</cell><cell>0.9</cell><cell>0.91 0.92 0.93 0.94 0.95 0.96</cell><cell>0.97</cell><cell>0.98 0.99 1.00</cell></row><row><cell cols="5">RM 0.2879 0.2884 0.2890 0.2894 0.2897 0.2899 0.2899 0.2901 0.2891 0.2886 0.2878</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,205.58,346.27,204.19,43.95"><head>Table 3 .</head><label>3</label><figDesc>MAP@100 results for TSV</figDesc><table coords="6,205.58,371.00,204.19,19.22"><row><cell>Method</cell><cell cols="2">Word2Vec non Stem Stem</cell></row><row><cell cols="2">Training Datasets 3b 0.2878</cell><cell>0.2932 0.2988</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,134.77,520.23,345.83,114.82"><head>Table 4 .</head><label>4</label><figDesc>Comparison between our system and Top 3 participants in BioASQ 2014(Phase A) measured with MAP@100</figDesc><table coords="6,213.60,560.99,188.16,74.07"><row><cell>Method</cell><cell>Top 1 Top 2 Top 3 Our system</cell></row><row><cell>Batch1</cell><cell>0.2794 0.1108 0.1040 0.3067</cell></row><row><cell>Batch2</cell><cell>0.3016 0.2508 0.0797 0.3059</cell></row><row><cell>Batch3</cell><cell>0.2918 0.2773 0.1022 0.2793</cell></row><row><cell>Batch4</cell><cell>0.2713 0.0898 0.0881 0.2850</cell></row><row><cell>Batch5</cell><cell>0.2661 0.0889 0.0883 0.2806</cell></row><row><cell cols="2">Mean Value 0.2820 0.1635 0.0925 0.2915</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,658.44,160.05,7.47"><p>http://ikmbio.csie.ncku.edu.tw/GN/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,658.44,131.81,7.47"><p>http://www.galagosearch.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,658.44,164.76,7.47"><p>https://code.google.com/p/word2vec/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,144.73,658.44,301.76,7.47"><p>http://participants-area.bioasq.org/oracle/results/taskB/phaseA/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,374.72,337.64,7.86;7,151.52,385.68,329.07,7.86;7,151.52,396.64,276.73,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,272.70,385.68,207.89,7.86;7,151.52,396.64,87.62,7.86">Results of the BioASQ Track of the Question Answering Lab at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,266.27,396.64,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="1181" to="1193" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,407.59,337.64,7.86;7,151.52,418.55,20.99,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,209.02,407.59,212.81,7.86">MetaMap: Mapping Text to the UMLS Metathesaurus</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Bethesda</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,429.51,337.64,7.86;7,151.52,440.47,273.84,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,263.20,429.51,217.39,7.86;7,151.52,440.47,71.47,7.86">An overview of MetaMap: historical perspective and recent advances[J]</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,230.06,440.47,97.85,7.86">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229C" to="236" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,451.43,337.63,7.86;7,151.52,462.39,180.35,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,246.55,451.43,229.72,7.86">A Markov random field model for term dependencies[C]</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,163.04,462.39,107.29,7.86">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,473.35,337.64,7.86;7,151.52,484.31,329.07,7.86;7,151.52,495.27,63.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,276.56,473.35,204.03,7.86;7,151.52,484.31,201.45,7.86">Classification and Retrieval of Biomedical Literatures: SNUMedinfo at CLEF QA track BioASQ</title>
		<author>
			<persName coords=""><forename type="first">Sungbin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinwook</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,382.90,484.31,97.70,7.86">CLEF (Working Notes)</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="1283" to="1295" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,506.22,337.64,7.86;7,151.52,517.18,329.07,7.86;7,151.52,528.14,177.22,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,266.64,517.18,213.96,7.86;7,151.52,528.14,76.73,7.86">Social Book Search Reranking with Generalized Con-tentBased Filtering</title>
		<author>
			<persName coords=""><forename type="first">Bo-Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xu-Cheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao-Ping</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiao</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong-Wei</forename><surname>Hao</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Submitted to CIKM14</note>
</biblStruct>

<biblStruct coords="7,142.96,539.10,337.64,7.86;7,151.52,550.06,329.07,7.86;7,151.52,561.02,79.66,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,216.94,550.06,189.49,7.86">USTB at INEX2014: Social Book Search Track</title>
		<author>
			<persName coords=""><forename type="first">Bo-Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xu-Cheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao-Ping</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiao</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hong-Wei</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,414.45,550.06,66.14,7.86;7,151.52,561.02,22.02,7.86">CLEF (Working Notes</title>
		<imprint>
			<biblScope unit="page" from="536" to="554" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,571.98,208.27,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="7,198.75,571.98,124.18,7.86">trec eval IR evaluation package</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,582.94,337.63,7.86;7,151.52,593.90,185.97,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,307.24,582.94,145.61,7.86">Introduction to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,604.85,337.97,7.86;7,151.52,615.81,329.07,7.86;7,151.52,626.77,276.17,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,256.45,604.85,156.40,7.86">Evaluating evaluation measure stability</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,432.52,604.85,48.07,7.86;7,151.52,615.81,329.07,7.86;7,151.52,626.77,116.05,7.86">Proceedings of the 23rd annual international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on research and development in information retrieval<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="33C" to="40" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
