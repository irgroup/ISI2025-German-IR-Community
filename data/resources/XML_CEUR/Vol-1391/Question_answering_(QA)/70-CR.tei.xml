<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.15,116.95,317.05,12.62;1,146.41,134.89,322.54,12.62">Biomedical question-focused multi-document summarization: ILSP and AUEB at BioASQ3</title>
				<funder ref="#_pjQHeFP #_Yh57RW3">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.04,172.56,104.70,8.74"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
							<email>malakasiotis@ilsp.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Language and Speech Processing</orgName>
								<orgName type="institution">Research Center &apos;Athena&apos;</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.12,172.56,105.39,8.74"><forename type="first">Emmanouil</forename><surname>Archontakis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.06,172.56,91.19,8.74"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Language and Speech Processing</orgName>
								<orgName type="institution">Research Center &apos;Athena&apos;</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,207.56,184.51,77.00,8.74"><forename type="first">Dimitrios</forename><surname>Galanis</surname></persName>
							<email>galanisd@ilsp.gr</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Language and Speech Processing</orgName>
								<orgName type="institution">Research Center &apos;Athena&apos;</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.50,184.51,88.83,8.74"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Language and Speech Processing</orgName>
								<orgName type="institution">Research Center &apos;Athena&apos;</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.15,116.95,317.05,12.62;1,146.41,134.89,322.54,12.62">Biomedical question-focused multi-document summarization: ILSP and AUEB at BioASQ3</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEDA83EA16DC44F1F78F1DB965732D64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>biomedical question answering, text summarization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Question answering systems aim to find answers to natural language questions by searching in document collections (e.g., repositories of scientific articles or the entire Web) and/or structured data (e.g., databases, ontologies). Strictly speaking, the answer to a question might sometimes be simply 'yes' or 'no', a named entity, or a set of named entities. In practice, however, a more elaborate answer is often also needed, ideally a summary of the most important information from relevant documents and structured data. In this paper, we focus on generating summaries from documents that are known to be relevant to particular questions. We describe the joint participation of AUEB and ILSP in the corresponding subtask of the bioasq3 competition, where participants produce multi-document summaries of given biomedical articles that are relevant to English questions prepared by biomedical experts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Biomedical experts are extremely short of time. They also need to keep up with scientific developments happening at a pace that is probably faster than in any other science. The online biomedical bibliographic database PubMed currently comprises approximately 21 million references and was growing at a rate often exceeding 20,000 articles per week in 2011. <ref type="foot" coords="1,347.76,555.04,3.97,6.12" target="#foot_0">3</ref> Figure <ref type="figure" coords="1,389.61,556.61,4.98,8.74" target="#fig_1">1</ref> shows the number of biomedical articles indexed by PubMed per year since 1964. Rich sources of structured biomedical information, like the Gene Ontology, umls, or Diseasesome are also available. <ref type="foot" coords="1,258.78,590.90,3.97,6.12" target="#foot_1">4</ref> Obtaining sufficient and concise answers from this wealth of information is a challenging task for traditional search engines, which instead of answers return lists of (possibly) relevant documents that the experts themselves have to study. Consequently, there is growing interest for biomedical question answering (QA) systems <ref type="bibr" coords="2,300.93,131.95,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,313.11,131.95,7.01,8.74" target="#b3">4]</ref>, which aim to produce more concise answers. To foster research in biomedical QA, the bioasq project constructs benchmark datasets, evaluation services, and organizes international biomedical QA competitions since 2012 <ref type="bibr" coords="2,261.26,167.81,14.61,8.74" target="#b19">[20]</ref>.  Given a question expressed in natural language, QA systems aim to provide answers by searching in document collections (e.g., repositories of scientific articles or the entire Web) and/or structured data (e.g., databases, ontologies). Strictly speaking, the answer to a question might sometimes be simply a 'yes' or 'no' (e.g., in biomedical questions like "Do CpG islands co-localize with transcription start sites?"), a named entity (e.g., in "What is the methyl donor of DNA (cytosine-5)-methyltransferases?"), or a set of named entities (e.g., in "Which species may be used for the biotechnological production of itaconic acid?"). Following the terminology of bioasq, we call short answers of this kind 'exact' answers. In practice, however, a more elaborate answer is often needed, ideally a paragraph summarizing the most important information from relevant documents and structured data; bioasq calls answers of this kind 'ideal' answers. In this paper, we focus on generating 'ideal' answers (summaries) from documents that are known to be relevant to particular questions. We describe our participation in the corresponding subtask of the bioasq3 competition (Task 3b, Phase B, generation of 'ideal' answers), where the participants produce summaries of biomedical articles that are relevant to English questions prepared by biomedical experts. In this particular subtask, the input is a question along with the PubMed articles that a biomedical expert identified as relevant to the question; in effect, a perfect search engine is assumed (see Fig. <ref type="figure" coords="3,389.50,155.86,3.87,8.74" target="#fig_2">2</ref>). More precisely, in bioasq3 only the abstracts of the articles were available; hence, we summarize sets of abstracts (one set per question). We also note that the abstracts contain annotations showing the snippets (one or more consecutive sentences each) that the biomedical experts considered most relevant to the corresponding questions. We do not use the snippet annotations of the experts, since our system includes its own mechanisms to assess the importance of each sentence. Hence, our system may be at a disadvantage compared to systems that use the snippet annotations of the experts. Nevertheless, experimental results we present indicate that it still performs better than its competitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Engine</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Documents, RDF triples …</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QA, summarization, NLG</head><p>"Ideal" answer (summary): Yes. It is generally known that the presence of a CpG island around the TSS is related to the expression pattern of the gene. CGIs (CpG islands) often extend into downstream transcript regions. This provides an explanation for the observation that the exon at the 5' end of the transcript, flanked with the transcription start site, shows a remarkably higher CpG density than the downstream exons.</p><p>Question: Do CpG islands co-localize with transcription start sites?</p><p>Query: e.g., "CpG islands" AND "transcription start sites"</p><p>"Exact" answer: Yes. We also note that when relevant structured information is also available (e.g., rdf triples), concept to text natural language generation (nlg) <ref type="bibr" coords="3,417.73,558.76,10.51,8.74" target="#b0">[1]</ref> can also be used to produce 'ideal' answers or texts to be given as additional input documents to the summarizer. We did not consider nlg, however, since in bioasq3 the questions were not accompanied by manually selected (by the biomedical experts) relevant structured information, unlike bioasq1 and bioasq2, and we do not yet have mechanisms to select structured information automatically.</p><p>Section 2 below describes the different versions of the multi-document summarizer that we used. Section 3 reports our experimental results. Section 4 concludes and provides directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our question-focused multi-document summarizer</head><p>We now discuss how the 'ideal' answers (summaries) of our system are produced. Recall that for each question, a set of documents (article abstracts) known to be relevant to the question is given. Our system is an extractive summarizer, i.e., it includes in each summary sentences of the input documents, without rephrasing them. The summarizer attempts to select the most relevant (to the question) sentences, also trying to avoid including in the summary redundant sentences, i.e., pairs of sentences that convey the same information. bioasq restricts the maximum size of each 'ideal' answer to 200 words; including redundant sentences wastes space and is also penalized when experts manually assess the responses of the systems <ref type="bibr" coords="4,202.67,252.94,14.61,8.74" target="#b19">[20]</ref>. The summarizer does not attempt to repair (e.g., replace pronouns by their referents), order, or aggregate the selected sentences <ref type="bibr" coords="4,452.09,264.89,9.96,8.74" target="#b5">[6]</ref>; we leave these important issues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Baseline 1 and Baseline 2</head><p>As a starting point, we used the extractive summarizer of Galanis et al. <ref type="bibr" coords="4,457.90,329.54,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="4,470.08,329.54,7.01,8.74" target="#b7">8]</ref>. Two versions of the summarizer, known as Baseline 1 and Baseline 2, have been used as baselines for 'ideal' answers in all three years of the bioasq competition. <ref type="foot" coords="4,476.12,351.88,3.97,6.12" target="#foot_3">6</ref>Both versions employ a Support Vector Regression (svr) model <ref type="bibr" coords="4,419.33,365.41,10.52,8.74" target="#b4">[5]</ref> to assign a relevance score rel (s i ) to each sentence s i of the relevant documents of a question q. <ref type="foot" coords="4,142.34,387.74,3.97,6.12" target="#foot_4">7</ref> An svr learns a function f : R n → R in order to predict a real value y i ∈ R given a feature vector x i ∈ R n that represents an instance. In our case, x i is a feature vector representing a sentence s i of the relevant documents of a question q, and y i is the relevance score of s i . Consult Galanis et al. <ref type="bibr" coords="4,436.90,425.18,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="4,449.07,425.18,7.75,8.74" target="#b7">8]</ref> for a discussion of the features that were used in the svr of Baseline 1 and Baseline 2. During training, for each q we compute the rouge-2 and rouge-su4 scores <ref type="bibr" coords="4,134.77,461.05,15.50,8.74" target="#b12">[13]</ref> between each s i and the gold (provided by an expert) 'ideal' answer of q, and we take y i to be the average of the rouge-2 and rouge-su4 scores. The motivation for using these scores is that they are the two most commonly used measures for automatic evaluation of machine-generated summaries against gold ones. Roughly speaking, both measures compute the word bigram recall of the summary (or sentence) being evaluated against, possibly multiple, gold summaries. However, rouge-su4 also considers skip bigrams (pairs of words with other ignored intervening words) with a maximum distance of 4 words between the words of each skip bigram. Both measures have been found to correlate well with human judgements in extractive summarization <ref type="bibr" coords="4,441.49,568.65,15.50,8.74" target="#b12">[13]</ref> and, hence, training a component (e.g., an svr) to predict the rouge score of each sentence can be particularly useful. Intuitively, a sentence with a high rouge score has a high overlap with the gold summaries; and since the gold summaries contain the sentences that human authors considered most important, a sentence with a high rouge score is most likely also important.</p><p>Baseline 1 uses Integer Linear Programming (ilp) to jointly maximize the relevance and diversity (non-redundancy) of the selected sentences s i , respecting at the same time the maximum allowed summary length. The ilp model maximizes the following objective function:</p><formula xml:id="formula_0" coords="5,230.29,178.52,250.31,55.30">8 max b,x λ n i=1 α i l i l max x i + (1 -λ) |B| i=1 b i n<label>(1)</label></formula><p>subject to:</p><formula xml:id="formula_1" coords="5,276.41,261.15,199.93,30.32">n i=1 l i x i ≤ l max (<label>2</label></formula><formula xml:id="formula_2" coords="5,476.35,271.56,4.24,8.74">)</formula><formula xml:id="formula_3" coords="5,236.61,298.75,243.98,20.06">gj ∈Bi b j ≥ |B i | x i , for i = 1, . . . , n<label>(3)</label></formula><formula xml:id="formula_4" coords="5,241.84,328.07,238.75,20.06">si∈Sj x i ≥ b j , for j = 1, . . . , |B|<label>(4)</label></formula><p>where α i is the relevance score rel (s i ) of sentence s i normalized in [0, 1]; l i is the word length of s i ; l max is the maximum allowed summary length in words; n is the number of input sentences (sentences in the given relevant documents); B is the set of all the word bigrams in the input sentences; x i and b i show which sentences s i and word bigrams, respectively, are present in the summary; B i is the set of word bigrams that occur in sentence s i ; g j ranges over the word bigrams in B i ; and S j is the set of sentences that contain bigram g j . Constraint (2) ensures that the maximum allowed summary length is not exceeded. Constraint (3) ensures that if an input sentence is included in the summary, then all of its word bigrams are also included. Constraint (4) ensures that if a word bigram is included in the summary, than at least a sentence that contains it is also included. The first sum of Eq. 1 maximizes the total relevance of the selected sentences. The second sum maximizes the number of distinct bigrams in the summary, in effect minimizing the redundancy of the included sentences. Finally, λ ∈ [0, 1] controls how much the model tries to maximize the total relevance of the selected sentences at the expense of non-redundancy and vice versa. Consult Galanis et al. <ref type="bibr" coords="5,434.79,541.69,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="5,446.97,541.69,7.75,8.74" target="#b7">8]</ref> for a more detailed explanation of the ilp model. Baseline 2 first uses the trained svr to rank the sentences s i of the relevant documents of q by decreasing relevance rel (s i ). It then greedily examines each s i from highest to lowest rel (s i ). If the cosine similarity between s i and any of the sentences that have already been added to the summary exceeds a threshold t, then s i is discarded; the cosine similarity is computed by representing each sentence as a bag of words (using Boolean features), and t is tuned on development data. Otherwise, if s i fits in the remaining available summary space, it is added to the summary; if it does not fit, the summary construction process stops.</p><p>Baselines 1 and 2 were trained on news articles, as discussed by Galanis et al. <ref type="bibr" coords="6,149.61,155.86,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="6,161.79,155.86,7.01,8.74" target="#b7">8]</ref>, and were used in bioasq without retraining and without modifying the features of their svr. However, there are many differences between news and biomedical articles, and many of the features that were used in the svr of Baselines 1 and 2 are irrelevant to biomedical articles. For example, Baselines 1 and 2 use a feature that counts the names of organizations, persons, etc. in sentence s i , as identified by a named entity recognizer that does not support biomedical entity types (e.g., names of genes, diseases). They also use a feature that considers the order of s i in the document it was extracted from, based on the intuition that news articles usually list the most important information first, a convention that does not always hold in biomedical abstracts. Hence, we also experimented with modified versions of Baselines 1 and 2, discussed below, which were trained on bioasq datasets and used different feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The ILP-SUM-0 and ILP-SUM-1 summarizers</head><p>The first new version of our summarizer, called ilp-sum-0, is the same as Baseline 1 (the baseline that uses ilp, with the same features in its svr), but was trained on bioasq data, as discussed in Section 3 below.</p><p>Another version, ilp-sum-1, is the same as ilp-sum-0, it was also trained on bioasq data, but uses a different feature set in its svr, still close to the features of Baselines 1 and 2 <ref type="bibr" coords="6,228.80,393.32,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="6,240.97,393.32,7.01,8.74" target="#b7">8]</ref>, but modified for biomedical questions and articles. The features of ilp-sum-1 are the following. All the features of all the versions of the summarizer, including Baselines 1 and 2, are normalized in [0, 1].</p><p>(1.1) Word overlap: The number of common words between the question q and each sentence s i of the relevant documents of q, after removing stop words and duplicate words from q and s i . (1.2) Stemmed word overlap: The same as Feature (1.1), but the words of q and s i are stemmed, after removing stop words. (1.3) Levenshtein distance: The Levenshtein distance <ref type="bibr" coords="6,384.87,495.29,15.50,8.74" target="#b10">[11]</ref> between q and s i , taking insertions, deletions, and replacements to operate on entire words. (1.4) Stemmed Levenshtein distance: The same as Feature (1.3), but the words of q and s i are stemmed, before computing the Levensthein distance. (1.5) Content word frequency: The average frequency CF (s i ) of the content words of sentence s i in the relevant documents of q, as defined by Schilder and Ravikumar <ref type="bibr" coords="6,230.96,566.11,14.61,8.74" target="#b17">[18]</ref>:</p><formula xml:id="formula_5" coords="6,268.46,584.57,102.70,27.68">CF (s i ) = c(si) j=1 p c (w j ) c(s i )</formula><p>where c(s i ) is the number of content words in sentence s i , p c (w) = m M , m is the number of occurrences of content word w j in the relevant documents of q, and M is the total number of content word occurences in the relevant documents of q.</p><p>(1.6) Stemmed content word frequency: The same as Feature (1.5), but the content words of the relevant documents of q (and their sentences s i ) are stemmed before computing CF (s i ). (1.7) Document frequency: The average document frequency of the content words of sentence s i in the relevant documents of q, as defined by Schilder and Ravikumar <ref type="bibr" coords="7,230.96,179.46,14.61,8.74" target="#b17">[18]</ref>:</p><formula xml:id="formula_6" coords="7,267.97,198.63,103.68,27.68">DF (s i ) = c(si) j=1 p d (w j ) c(s i )</formula><p>where p d (w) = d D , d is the number of relevant documents of q that contain the content word w j , and D is the number of relevant documents of q.</p><p>(1.8) Stemmed document frequency: The same as Feature (1.7), but the content words of the relevant documents of q (and their sentences s i ) are stemmed before computing DF (s i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The ILP-SUM-2 and GR-SUM-2 summarizers</head><p>In recent years, continuous space vector representations of words, also known as word embeddings, have been found to capture several morphosyntactic and semantic properties of words <ref type="bibr" coords="7,251.06,356.08,15.50,8.74" target="#b11">[12,</ref><ref type="bibr" coords="7,268.21,356.08,8.70,8.74" target="#b13">[14]</ref><ref type="bibr" coords="7,276.91,356.08,4.35,8.74" target="#b14">[15]</ref><ref type="bibr" coords="7,276.91,356.08,4.35,8.74" target="#b15">[16]</ref><ref type="bibr" coords="7,281.26,356.08,13.05,8.74" target="#b16">[17]</ref>. bioasq employed the popular word2vec tool <ref type="bibr" coords="7,155.91,368.04,13.05,8.74" target="#b13">[14]</ref><ref type="bibr" coords="7,168.96,368.04,4.35,8.74" target="#b14">[15]</ref><ref type="bibr" coords="7,173.31,368.04,13.05,8.74" target="#b15">[16]</ref> to construct embeddings for a vocabulary of 1,701,632 words occurring in biomedical texts, using a corpus of 10,876,004 English abstracts of biomedical articles from PubMed. <ref type="foot" coords="7,288.19,390.38,3.97,6.12" target="#foot_6">9</ref> The ilp-sum-2 and gr-sum-2 versions of our summarizer use the following features in their svr, which are based on the bioasq word embeddings, in addition to Features (1.1)-(1.8) of ilp-sum-1. ilpsum-2 also uses the ilp model (like Baseline 1, ilp-sum-0, ilp-sum-1), whereas gr-sum-2 uses the greedy approach of Baseline 2 instead (see Section 2.1).</p><p>(2.1) Euclidean similarity of centroids: This is computed as:</p><formula xml:id="formula_7" coords="7,264.64,478.89,215.95,23.22">ES (q, s i ) = 1 1 + ED( q, s i )<label>(5)</label></formula><p>where q, s i are the centroid vectors of q and s i , respectively, defined below, and ED( q, s i ) is the Euclidean distance between q and s i . The centroid t of a text t (question or sentence) is computed as:</p><formula xml:id="formula_8" coords="7,246.90,552.63,233.69,55.66">t = 1 |t| |t| i=1 w i = |V | j=1 w j • TF(w j , t) |V | j=1 TF(w j , t)<label>(6)</label></formula><p>where |t| is the number of words (tokens) in t, and w i is the embedding (vector) of the i-th word (token) of t, |V | is the number of (distinct) words in the vocabulary, and TF(w j , t) is the term frequency (number of occurrences) of the j-th vocabulary word in the text t.<ref type="foot" coords="8,374.81,130.37,7.94,6.12" target="#foot_7">10</ref> (2.2) Euclidean similarity of IDF-weighted centroids: The same as Feature (2.1), except that the centroid of a text t (question or sentence) now also takes into account the inverse document frequencies of the words in t:</p><formula xml:id="formula_9" coords="8,251.39,189.44,229.20,55.66">t = |V | j=1 w j • TF(w j , t) • IDF(w j ) |V | j=1 TF(w j , t) • IDF(w j )<label>(7)</label></formula><p>where IDF(w j ) = log |D| |D(wj )| , |D| = 10, 876, 004 is the total number of abstracts in the corpus the word embeddings were obtained from, and |D(w j )| is the number of those abstracts that contain the word w j .</p><p>(2.3) Pairwise Euclidean similarities: To compute this set of features (8 features in total), we create two bags, one with the tokens (word occurrences) of the question q and one with the tokens of the sentence s i . We then compute the similarity ES (w, w ) (as in Eq. 5) for every pair of tokens w, w of q and s i , respectively, and we construct the following features:</p><p>-the average of the similarities ES (w, w ), for all the token pairs w, w of q and s i , respectively, -the median of the similarities ES (w, w ), -the maximum similarity ES (w, w ), -the average of the two largest similarities ES (w, w ), -the average of the three largest similarities ES (w, w ), -the minimum similarity ES (w, w ), -the average of the two smallest similarities ES (w, w ), -the average of the three smallest similarities ES (w, w ). (2.4) IDF-weighted pairwise Euclidean similarities: The same set of features (8 features) as Features (2.3), but the Euclidean similarity ES (w, w ) of each pair of tokens w, w is multiplied with IDF(w)•IDF(w )</p><formula xml:id="formula_10" coords="8,369.93,502.75,27.35,7.12">maxidf 2</formula><p>to reward pairs with high idf scores. The idf scores are computed as in Feature (2.2), and maxidf is the maximum idf score of the words we have embeddings for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental results</head><p>We used the datasets of bioasq1 and bioasq2 to train and tune the four new versions of our summarizer (ilp-sum-0, ilp-sum-1, ilp-sum-2, gr-sum-2). We then used the dataset of bioasq3 to test the two best new versions of our summarizer (ilp-sum-2, gr-sum-2) on unseen data, and to compare them against Baseline 1, Baseline 2, and the other systems that participated in bioasq3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiments on BioASQ1 and BioASQ2 data</head><p>The bioasq1 and bioasq2 datasets consist of 3 and 5 batches, respectively, called Batches 1-3 and Batches 4-8 in this section. Each batch contains approximately 100 questions, along with relevant documents, and 'ideal' answers provided by the biomedical experts.</p><p>In a first experiment, we aimed to tune the λ parameter of ilp-sum-0, ilp-sum-1, and ilp-sum-2, which use the ilp model of Section 2.1, and compare the three systems. Figure <ref type="figure" coords="9,273.43,212.02,4.98,8.74">3</ref> shows the average rouge scores of the three systems on Batches 4-6, for different values of λ, using Batches 1-3 to train them (train their svrs); Batches 7-8 were reserved for another experiment, discussed below. In more detail, we first computed the rouge-2 and rouge-su4 scores on Batch 4, training the systems on Batches 1-3 and 5-6. We then computed the average of the rouge-2 and rouge-su4 scores of Batch 4, i.e., rouge(Batch4) = 1 2 (rouge-2(Batch4)+rouge-su4(Batch4)), for each λ value. We repeated the same process for Batches 5 and 6, obtaining rouge(Batch5) and rouge(Batch6), for each λ value. Finally, we computed (and show in Fig. <ref type="figure" coords="9,471.73,307.67,4.43,8.74">3</ref>) the average 1 3 (rouge(Batch4) + rouge(Batch5) + rouge(Batch6)), for each λ valuer. Figure <ref type="figure" coords="9,197.35,331.58,4.98,8.74">3</ref> shows that ilp-sum-2 performs better than ilp-sum-1, which in turn outperforms ilp-sum-0. The differences in the rouge scores are larger for greater values of λ, because greater λ values place more emphasis on the rel (s i ) scores returned by the svr, which are affected by the different feature sets of the three systems. For λ &gt; 0.8, the rouge scores decline, because the systems place too much emphasis on avoiding redundant sentences. The best of the three systems, ilp-sum-2, achieves its best performance for λ = 0.8.</p><p>In a second experiment, we compared ilp-sum-2, which is the best of our new versions that use the ilp model, against gr-sum-2, which uses the same features, but the greedy approach instead of the ilp model. We set λ = 0.8 in ilp-sum-2, based on Fig. <ref type="figure" coords="9,194.48,451.19,3.87,8.74">3</ref>. In gr-sum-2, we set the cosine similarity threshold (Section 2.1) to t = 0.4, based on Galanis et al. <ref type="bibr" coords="9,280.15,463.15,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="9,292.32,463.15,7.01,8.74" target="#b7">8]</ref>. Figure <ref type="figure" coords="9,336.00,463.15,4.98,8.74">4</ref> shows the average rouge-2 and rouge-su4 score of each system on Batches 7 and 8, using an increasingly larger training dataset, consisting of Batches 1-3, 1-4, 1-5, or 1-6. A first observation is that ilp-sum-2 outperforms gr-sum-2. Moreover, it seems that both systems would benefit from more training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments on BioASQ3 data</head><p>In bioasq3, we participated with ilp-sum-2 (with λ = 0.8) and gr-sum-2 (with t = 0.4), both trained on all 8 batches of bioasq1 and bioasq2. Baseline 1 and Baseline 2, which are also versions of our own summarizer, were used again as the official baselines for 'ideal' answers, as in bioasq1 and bioasq2, i.e., without modifying their features or retraining them for biomedical data. The test dataset of bioasq3 contained five new batches, hereafter called bioasq3 Batches 1-5; these are different from Batches 1-8 of bioasq1 and bioasq2.</p><p>For each bioasq3 batch, Table <ref type="table" coords="9,290.05,645.16,4.98,8.74">1</ref> shows the rouge-2, rouge-su4, and average of rouge-2 and rouge-su4 scores of the four versions of our summarizer (ilp-sum-2, gr-sum-2, Baseline 1, Baseline 2), ordered by decreasing average rouge-2 and rouge-su4. The results of the three other best (in terms of average rouge-2 and rouge-su4) participants per batch are also shown, as part-sys-1, part-sys-2, part-sys-3; part-sys-1 is not necessarily the same system in all batches, and similarly for part-sys-2 and part-sys-3. <ref type="foot" coords="11,391.87,166.24,7.94,6.12" target="#foot_8">11</ref> The four versions of our summarizer are the best four systems in all five batches of Table <ref type="table" coords="11,448.79,179.77,3.87,8.74">1</ref>.</p><p>As in the experiments of Section 3.1, Table <ref type="table" coords="11,350.90,191.72,4.98,8.74">1</ref> shows that ilp-sum-2 consistently outperforms gr-sum-2. Similarly, Baseline 2 (which uses the greedy approach) performs better than Baseline 1 (which uses the ilp model) only in the third batch. It is also surprising that ilp-sum-2 and gr-sum-2 do not always perform better than Baselines 1 and 2, even though the former systems were tailored for biomedical data by modifying their features and retraining them on the datasets of bioasq1 and bioasq2. This may be due to the fact that Baseline 1 and Baseline 2 were trained on larger datasets than ilp-sum-2 and gr-sum-2 <ref type="bibr" coords="11,134.77,287.36,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="11,146.95,287.36,7.01,8.74" target="#b7">8]</ref>. Hence, training our summarizer on more data, even from another domain (news) may be more important than training it on data from the application domain (biomedical data, in the case of bioasq) and modifying its features.</p><p>It would be interesting to check if the conclusions of Table <ref type="table" coords="11,402.93,323.23,4.98,8.74">1</ref> continue to hold when the systems are ranked by the manual (provided by biomedical experts) evaluation scores of their 'ideal' summaries, as opposed to using rouge scores. At the time this paper was written, the manual evaluation scores of the 'ideal' answers of bioasq3 had not been announced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and future work</head><p>We presented four new versions (ilp-sum-0, ilp-sum-1, ilp-sum-2, gr-sum-2) of an extractive question-focused multi-document summarizer that we used to construct 'ideal' answers (summaries) in bioasq3. The summarizer employs an svr to assign relevance scores to the sentences of the given relevant abstracts, and an ilp model or an alternative greedy strategy to select the most relevant sentences avoiding redundant ones. The two official bioasq baselines for 'ideal' answers, Baseline 1 and Baseline 2, are also versions of the same summarizer; they use the ilp model or the greedy approach, respectively, but they were trained on news articles and their features are not always appropriate for biomedical data. By contrast the four new versions were trained on data from bioasq1 and bioasq2. ilp-sum-0, ilp-sum-1, and ilp-sum-2 all use the ilp model, but ilp-sum-0 uses the original features of Baselines 1 and 2, ilp-sum-1 uses a slightly modified feature set, and ilp-sum-2 uses a more extensive feature set that includes features based on biomedical word embeddings. gr-sum-2 uses the same features as ilp-sum-2, but with the greedy mechanism.</p><p>A preliminary set of experiments on bioasq1 and bioasq2 data indicated that ilp-sum-2 performs better than ilp-sum-0 and ilp-sum-1, showing the importance of modifying the feature set. ilp-sum-2 was also found to perform  <ref type="table" coords="12,163.09,640.84,4.13,7.89">1</ref>. Results of four versions of our summarizer (ilp-sum-2, gr-sum-2, Baseline 1, Baseline 2) on the bioasq3 batches, along with results of the three other best systems (part-sys-1, part-sys-2, part-sys-3) per batch. Baselines 1 and 2 were not retrained or otherwise modified for biomedical data. ilp-sum-2 and gr-sum-2 were trained on the datasets of bioasq1 and bioasq2. The total numbers of systems and teams that participated in each batch are shown in brackets.</p><p>better than gr-sum-2, which uses the same feature set, showing the benefit of using the ilp model instead of the greedy approach. Our experiments also indicated that ilp-sum-2 and gr-sum-2 would probably benefit from more training data. In bioasq3, we participated with ilp-sum-2 and gr-sum-2, tuned and trained on bioasq1 and bioasq2 data. Along with Baselines 1 and 2, which are also versions of our own summarizer, ilp-sum-2 and gr-sum-2 were the best four systems in terms of rouge scores in all five batches of bioasq3. Again, ilp-sum-2 consistently outperformed gr-sum-2, but surprisingly ilp-sum-2 and gr-sum-2 did not always perform better than Baselines 1 and 2. This may be due to the fact that Baselines 1 and 2 were trained on more data, suggesting that the size of the training set may be more important than improving the feature set or using data from the biomedical domain.</p><p>Future work could consider repairing, ordering, or aggregating the sentences of the 'ideal' answers, as already noted. The centroid vectors of ilp-sum-2 and gr-sum-2 could also be replaced by paragraph vectors <ref type="bibr" coords="13,377.62,287.50,15.50,8.74" target="#b9">[10]</ref> or vectors obtained by using recursive neural networks <ref type="bibr" coords="13,294.64,299.46,14.61,8.74" target="#b18">[19]</ref>. Another possible improvement could be to use metamap <ref type="bibr" coords="13,225.90,311.41,9.96,8.74" target="#b1">[2]</ref>, a tool that maps biomedical texts to concepts derived from umls. <ref type="foot" coords="13,184.41,321.79,7.94,6.12" target="#foot_9">12</ref> We could then compute new features that measure the similarity between a question and a sentence in terms of biomedical concepts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,279.53,166.24,3.97,6.12"><head>5</head><label>5</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,134.77,413.77,345.83,8.39;2,134.77,424.75,259.32,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Number of new PubMed articles (blue line) indexed over the period 1964-2013 per year, and the respective logarithmic trend (red dashed line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,134.77,485.66,345.83,7.89;3,134.77,496.65,345.82,7.86;3,134.77,507.61,340.31,8.37;3,257.60,376.58,220.85,89.39"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Using QA, multi-document summarization, and concept-to-text generation to produce 'exact' and 'ideal' answers to English biomedical questions. The blue box indicates the focus of our participation in bioasq3. We did not consider rdf triples.</figDesc><graphic coords="3,257.60,376.58,220.85,89.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="10,134.77,353.79,345.82,8.39;10,134.77,364.78,340.90,7.86"><head>2 Fig. 3 . 2 Fig. 4 .</head><label>2324</label><figDesc>Fig. 3. Average rouge-2 and rouge-su4 on Batches 4-6 of bioasq1 and bioasq2, for different λ values, each time using the five other batches of Batches 1-6 for training.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="1,144.73,635.88,201.67,8.12"><p>Consult http://www.ncbi.nlm.nih.gov/pubmed/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="1,144.73,646.84,335.86,8.12;1,144.73,658.44,96.71,7.47"><p>See http://www.geneontology.org/, http://www.nlm.nih.gov/research/umls/, http://diseasome.eu/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="2,144.73,657.79,140.99,8.12"><p>See also http://www.bioasq.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,144.73,624.92,335.86,8.37;4,144.73,635.88,271.21,7.86"><p>Baseline 1 and Baseline 2 are the ilp2 and greedy-red methods, respectively, of Galanis et al.<ref type="bibr" coords="4,201.68,635.88,9.22,7.86" target="#b7">[8]</ref>. Baseline 2 had also participated in TAC 2008<ref type="bibr" coords="4,403.65,635.88,9.22,7.86" target="#b8">[9]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,144.73,646.84,335.87,8.37;4,144.73,657.79,316.87,9.85"><p>We use the svr implementation of libsvm (see http://www.csie.ntu.edu.tw/ ~cjlin/libsvm/) with an rbf kernel and libsvm's parameter tuning facilities.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="5,144.73,646.84,335.87,8.37;5,144.73,657.79,330.90,8.12"><p>We use the implementation of the Branch and Cut algorithm of the gnu Linear Programming Kit (glpk); consult http://sourceforge.net/projects/winglpk/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="7,144.73,646.84,335.87,8.12;7,144.73,657.79,147.52,8.12"><p>See https://code.google.com/p/word2vec/ and http://bioasq.lip6.fr/tools/ BioASQword2vec/ for further details.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7" coords="8,144.73,646.84,335.86,7.86;8,144.73,657.79,58.72,7.86"><p>Tokens for which we have no embeddings are ignored when computing the features of this section.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8" coords="11,144.73,646.84,335.86,8.12;11,144.73,658.44,106.12,7.47"><p>The results of all the systems can be found at http://participants-area.bioasq. org/results/3b/phaseB/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9" coords="13,144.73,657.79,146.05,8.12"><p>See http://metamap.nlm.nih.gov/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The work of the first author was funded by the <rs type="programName">Athens University of Economics and Business Research Support Program 2014-2015</rs>, "<rs type="programName">Action 2: Support to Postdoctoral Researchers</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pjQHeFP">
					<orgName type="program" subtype="full">Athens University of Economics and Business Research Support Program 2014-2015</orgName>
				</org>
				<org type="funding" xml:id="_Yh57RW3">
					<orgName type="program" subtype="full">Action 2: Support to Postdoctoral Researchers</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,473.28,337.64,7.86;13,151.52,484.24,329.07,7.86;13,151.52,495.20,163.28,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,362.50,473.28,118.10,7.86;13,151.52,484.24,241.79,7.86">Generating natural language descriptions from OWL ontologies: the NaturalOWL system</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lampouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,400.81,484.24,79.78,7.86;13,151.52,495.20,84.43,7.86">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="671" to="715" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,506.30,337.63,7.86;13,151.52,517.25,329.07,7.86;13,151.52,528.21,253.19,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,214.35,506.30,266.24,7.86;13,151.52,517.25,90.00,7.86">Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,263.53,517.25,217.07,7.86;13,151.52,528.21,82.99,7.86">Proceedings of the American Medical Informatics Association Symposium</title>
		<meeting>the American Medical Informatics Association Symposium<address><addrLine>Washington DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="18" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,539.31,337.64,7.86;13,151.52,550.27,212.87,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,245.67,539.31,161.11,7.86">Biomedical question answering: A survey</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Athenikos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,413.27,539.31,67.33,7.86;13,151.52,550.27,136.08,7.86">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,561.37,337.63,7.86;13,151.52,572.33,136.04,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,248.58,561.37,227.80,7.86">Usability survey of biomedical question answering systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Berleant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,151.52,572.33,71.53,7.86">Human Genomics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,583.43,337.64,7.86;13,151.52,594.38,329.07,7.86;13,151.52,605.34,60.92,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,448.06,583.43,32.54,7.86;13,151.52,594.38,104.20,7.86">Support vector regression machines</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,262.66,594.38,208.18,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="155" to="161" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,616.44,337.64,7.86;13,151.52,627.40,329.07,7.86;13,151.52,638.36,200.18,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,265.23,616.44,211.09,7.86">Sentence fusion via dependency graph compression</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,166.98,627.40,313.61,7.86;13,151.52,638.36,40.95,7.86">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,120.67,337.64,7.86;14,151.52,131.63,325.92,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="14,203.98,120.67,215.93,7.86">Automatic generation of natural language summaries</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Department of Informatics, Athens University of Economics and Business</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="14,142.96,142.59,337.64,7.86;14,151.52,153.55,329.07,7.86;14,151.52,164.51,267.89,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,350.52,142.59,130.07,7.86;14,151.52,153.55,309.71,7.86">Extractive multi-document summarization with integer linear programming and support vector regression</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lampouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,164.51,118.56,7.86">Proceedings of COLING 2012</title>
		<meeting>COLING 2012<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="911" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,175.46,337.63,7.86;14,151.52,186.42,214.93,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,269.73,175.46,51.96,7.86">AUEB at tac</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,361.36,175.46,119.23,7.86;14,151.52,186.42,60.38,7.86">Proceedings of the Text Analysis Conference</title>
		<meeting>the Text Analysis Conference<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,197.38,337.98,7.86;14,151.52,208.34,329.07,7.86;14,151.52,219.30,110.72,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,236.58,197.38,224.94,7.86">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,208.34,282.93,7.86">Proceedings of the 31st International Conference on Machine Learning</title>
		<meeting>the 31st International Conference on Machine Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,230.26,337.98,7.86;14,151.52,241.22,205.99,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,220.77,230.26,259.82,7.86;14,151.52,241.22,25.64,7.86">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,183.90,241.22,94.77,7.86">Soviet Physice-Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,252.18,337.97,7.86;14,151.52,263.14,329.07,7.86;14,151.52,274.09,117.47,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,290.70,252.18,189.89,7.86;14,151.52,263.14,120.45,7.86">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,279.02,263.14,201.57,7.86;14,151.52,274.09,43.24,7.86">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,285.05,337.97,7.86;14,151.52,296.01,329.07,7.86;14,151.52,306.97,96.66,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,196.62,285.05,243.05,7.86">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,463.03,285.05,17.56,7.86;14,151.52,296.01,274.16,7.86">Proceedings of the ACL workshop &apos;Text Summarization Branches Out</title>
		<meeting>the ACL workshop &apos;Text Summarization Branches Out<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,317.93,337.97,7.86;14,151.52,328.89,329.07,7.86;14,151.52,339.85,233.41,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,332.76,317.93,147.83,7.86;14,151.52,328.89,90.11,7.86">Efficient estimation of word representations in vector space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,263.35,328.89,217.24,7.86;14,151.52,339.85,113.75,7.86">Proceedings of Workshop at International Conference on Learning Representations</title>
		<meeting>Workshop at International Conference on Learning Representations<address><addrLine>Scottsdale, AZ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,350.81,337.97,7.86;14,151.52,361.77,329.07,7.86;14,151.52,372.73,197.60,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,284.43,350.81,196.16,7.86;14,151.52,361.77,104.36,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,277.30,361.77,203.29,7.86;14,151.52,372.73,95.29,7.86">Proceedings of the Conference on Neural Information Processing Systems</title>
		<meeting>the Conference on Neural Information Processing Systems<address><addrLine>Lake Tahoe, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,383.68,337.98,7.86;14,151.52,394.64,329.07,7.86;14,151.52,405.60,329.07,7.86;14,151.52,416.56,78.91,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,287.73,383.68,192.86,7.86;14,151.52,394.64,59.42,7.86">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,231.22,394.64,249.38,7.86;14,151.52,405.60,324.97,7.86">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics -Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics -Human Language Technologies<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,427.52,337.98,7.86;14,151.52,438.48,329.07,7.86;14,151.52,449.44,168.97,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,349.29,427.52,131.30,7.86;14,151.52,438.48,55.76,7.86">GloVe: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,226.54,438.48,254.05,7.86;14,151.52,449.44,82.56,7.86">Proceedings of the Conference on Empirical Methods on Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods on Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,460.40,337.97,7.86;14,151.52,471.36,329.07,7.86;14,151.52,482.31,329.07,7.86;14,151.52,493.27,147.75,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,278.19,460.40,202.40,7.86;14,151.52,471.36,99.81,7.86">Fastsum: Fast and accurate query-based multidocument summarization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schilder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kondadadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,272.34,471.36,208.25,7.86;14,151.52,482.31,268.09,7.86">Proceedings of 46th Annual Meeting of the Association for Computational Linguistics -Human Language Technologies</title>
		<title level="s" coord="14,426.19,482.31,50.14,7.86">Short Papers</title>
		<meeting>46th Annual Meeting of the Association for Computational Linguistics -Human Language Technologies<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="205" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,504.23,337.98,7.86;14,151.52,515.19,329.07,7.86;14,151.52,526.15,329.07,7.86;14,151.52,537.11,282.34,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,371.83,504.23,108.76,7.86;14,151.52,515.19,155.00,7.86">Semantic compositionality through recursive matrix-vector spaces</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,327.79,515.19,152.80,7.86;14,151.52,526.15,329.07,7.86;14,151.52,537.11,109.48,7.86">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,548.07,337.98,7.86;14,151.52,559.03,329.07,7.86;14,151.52,569.99,329.07,7.86;14,151.52,580.94,329.07,7.86;14,151.52,591.90,329.07,7.86;14,151.52,602.86,241.54,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,151.52,591.90,329.07,7.86;14,151.52,602.86,89.05,7.86">An overview of the BioASQ large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Artieres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ngonga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,247.85,602.86,83.26,7.86">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">138</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
