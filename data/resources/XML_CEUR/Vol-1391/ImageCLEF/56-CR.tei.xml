<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.34,116.95,258.67,12.62;1,221.57,134.89,172.21,12.62">IBM Research at Image CLEF 2015: Medical Clustering Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.97,172.56,54.88,8.74"><forename type="first">Suman</forename><surname>Sedai</surname></persName>
							<email>ssedai@au1.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,199.51,172.56,36.28,8.74"><forename type="first">Xi</forename><surname>Liang</surname></persName>
							<email>xiliang@au1.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.65,172.56,58.18,8.74"><forename type="first">Mani</forename><surname>Abedini</surname></persName>
							<email>mabedini@au1.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.79,172.56,49.71,8.74"><forename type="first">Qiang</forename><surname>Chen</surname></persName>
							<email>qiangchen@au1.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.91,172.56,79.08,8.74"><forename type="first">Rajib</forename><surname>Chakravorty</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,455.00,172.56,23.39,8.74;1,290.20,184.51,34.96,8.74"><forename type="first">Rahil</forename><surname>Garnavi</surname></persName>
							<email>rahilgar@au1.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research Australia Level</orgName>
								<address>
									<addrLine>5, 204 Lygon Street</addrLine>
									<postCode>3053</postCode>
									<settlement>Carlton Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.34,116.95,258.67,12.62;1,221.57,134.89,172.21,12.62">IBM Research at Image CLEF 2015: Medical Clustering Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9679E4208C260DFEE486C09B624F096</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical image classification</term>
					<term>Local binary pattern</term>
					<term>Sparse coding</term>
					<term>Fisher vector</term>
					<term>Fisher encoding</term>
					<term>Spatial pyramid</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the learning strategies and feature extraction techniques that were applied by the IBM Research Australia team to the Medical Clustering challenge of ImageCLEF 2015. The challenge is to automatically annotate and categorize X-ray images into head-neck, body, upper-limb, lower-limb and foreign object categories. Our proposed methodology and details of experiments for each submitted run has been discussed in this paper, followed by final results provided by the competition organizers. The key components used in our submissions are based on sparse coding of SIFT, local binary patterns and multi-scale local binary patterns with spatial pyramid, advanced fisher vector, various SVM kernels, and an effective fusion methodology, to ensure high classification accuracy. Comprehensive experiments demonstrate the effectiveness of the proposed system. Six out of the ten submissions of IBM Research were among the top 10 best results, where two of our submissions outperformed all other submissions, therefore the team has achieved the first place in the competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF medical clustering task [0] is a new category in ImageCLEF 2015 <ref type="bibr" coords="1,467.31,537.56,9.96,8.74">[0]</ref>. The objective of this task is to categorize digital X-ray images into four clusters: head-neck, upper-limb, body, and lower-limb [0]. X-ray is the most common medical image modality as it accounts for one third of the the radiographs taken in a typical radiology department <ref type="bibr" coords="1,272.78,585.38,9.96,8.74">[0]</ref>. Automatic categorization of medical images has a number of applications including efficient retrieval, archiving, and patient similarity matching. For example, for search and retrieval task, the image needs to be pre-classified. However, X-ray image classification is a challenging task due to variation in the patients location, exposure, subject motion and the presence of artifacts and foreign objects. In this work, we present a X-ray annotation and categorization system which accurately performs in presence of such artifacts.</p><p>Existing methods on X-ray image classification are based on local patch features such as local binary pattern (LBP) histogram, edge histogram and SIFT <ref type="bibr" coords="2,134.77,143.90,9.96,8.74">[0]</ref>. Recently, the choice of the local feature has gone beyond the traditional local patch descriptor, and higher dimensional representation such as pooled coding vectors and multi-resolution feature modeling have shown to improve the performance. In this paper, we investigated several feature extraction techniques based on higher level feature coding of local feature and multi-resolution analysis for X-ray image clustering challenge in ImageClef 2015. The rest of the paper is organized as follows: Section describes the methodologies applied for the medical clustering task. Section discusses the experimental setup, which has been applied for training and our internal evaluation, and the comparison of our methods before submission. Section reviews the submission runs and presents the results. Finally, Section concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Feature Extraction and Learning Methodologies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multi-scale LBP Histogram with Spatial Pyramid</head><p>LBP describes gray-scale local texture of the image by detecting local patterns between adjacent pixels. For example, original LBP operator labels the pixels of an image by thresholding the 3 × 3-neighborhood of each pixel with the center value and considering the result as binary string resulting in 256 different patterns. In multi-scale LBP (MSLBP) [0], comparison operator between single pixels in LBP is simply replaced with comparison between average gray-values of sub-regions where each sub-region is a square block containing neighboring pixels, and the size of the square block is governed by the scale of LBP. Once the MSLBP values are computed for each pixel, a feature vector for a given image region can be computed as 256 dimensional histogram of the LBP values inside the region. However, such global histogram does not encode spatial information that may be crucial for image recognition task.</p><p>In this paper, we compute the MSLBP histogram at multiple scales of spatial resolution by partitioning the image into increasingly smaller overlapping subregions and computing the MSLBP histogram inside each region. The resulting spatial pyramid has shown improvements in the performance of image classification tasks. We computed LBP histogram at two levels of spatial pyramid. Let w and h denote the width and the height of the image. In the first level, the MSLBP histogram is computed in a block where the block covers the entire image. In the second level, MSLBP histogram is computed across the 9 overlapping blocks with size of w/2 × h/2 which are obtained by moving a block along x axis with increment of w/4, and along y-axis with increment of h/4. Therefore, the total number of blocks is 10. The MSLBP feature computed in all the spatial pyramid blocks are then concatenated to form a single feature vector which we name as MSLBP-SP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sparse Coding with Max-pooling and Spatial Pyramid</head><p>Sparse coding is a popular approach for adaptively learning feature representations. Given a set of input signals {x i } N i=1 , where x ∈ R m , the goal is to find the sparse approximation over a dictionary D in R m×k , with k columns referred to as basis vectors, so that a linear combination of basis vectors from D reconstructs the signal x. Rather than using pre-defined dictionaries, sparse coding algorithms aim to learn a dictionary of basis functions. The objective function of sparse coding is stated as:</p><formula xml:id="formula_0" coords="3,223.31,232.39,253.04,30.32">min D,α 1 N N i=1 1 2 x i -Dα i 2 2 +λ α i 1 (<label>1</label></formula><formula xml:id="formula_1" coords="3,476.35,242.80,4.24,8.74">)</formula><p>where λ is a regularization parameter and the l 1 penalty ensures sparse solution. A general approach to minimize the objective function is to alternate between the two variables, i.e., minimizing over one while keeping the other fixed. In this paper, we use on-line algorithm based on stochastic approximation which minimizes the sequential quadratic approximation of the expected cost [0]. Once the dictionary D is trained, the sparse representation α of a feature vector x can be computed by minimizing the following objective function:</p><formula xml:id="formula_2" coords="3,243.01,360.54,237.58,22.31">min α 1 2 x -Dα 2 2 +λ α 1<label>(2)</label></formula><p>For any image represented by a set of M features, we can compute a single feature vector using a pooling function. For example, the pooling function defined as average function results in a histogram feature. In this paper, we define the pooling function as the max-pooling function over the absolute sparse codes:</p><formula xml:id="formula_3" coords="3,240.52,447.91,240.07,9.65">z j = max {| α 1,j |, • • • , | α M,j |}<label>(3)</label></formula><p>where z j is the j th element of the final pooled vector z which is compact representation of the given image region. The max-pooling process is well established by biophysical evidence is visual cortex [0] and is empirically justified by many image recognition algorithms.</p><p>Given an image, we first divide the image into 10 spatial pyramid blocks in a similar manner described in Section and compute the local features in each block. The sparse representation of the local features is then computed in each block using the method described above. In this paper, we investigate two types of local feature for sparse coding: (a) dense SIFT (b) dense MSLBP. Dense SIFT is a faster version of SIFT where the SIFT descriptors with fixed scale and orientation are computed in densely sampled locations, inside a given image block. In our implementation SIFT descriptor is computed on a 100×100 patches densely sampled in a given block on a grid with step size of 30 × 30. Similarly, we compute the MSLBP described in Section in 100 × 100 patch densely sampled in a given block on a grid with step size of 30 × 30.</p><p>The sparse coded features computed in spatial pyramid taking dense SIFT as local features is named SC-DenseSIFT-SP and the sparse coded features computed in spatial pyramid by taking dense MSLBP features is named SC-DenseMSLBP-SP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Fisher Kernel Feature Coding</head><p>Fisher Kernel [0,0] feature encoding is one of bag-of-word model [0,0] and recent evaluation [0] shows this encoding method achieved best results in many cases. Fisher Kernel encodes the distribution information of the feature points which can separate the image specific information from the noisy local features. Fisher Kernel encoded features can be represented using a linear model which is computationally efficient.</p><p>Let X = {x 1 , • • • , x N } be the set of N local features extracted from an image I and u λ (x) is a probability density function which models a generative process in the feature space. The image I can be described by the gradient vector of log likelihood with respect to the model parameters λ:</p><formula xml:id="formula_4" coords="4,254.71,312.44,221.64,22.31">G X λ = 1 N ∇ λ log u λ (X). (<label>4</label></formula><formula xml:id="formula_5" coords="4,476.35,319.18,4.24,8.74">)</formula><p>Let F λ is the Fisher information matrix of u λ , a natural kernel on these gradients is</p><formula xml:id="formula_6" coords="4,255.08,367.32,225.51,13.38">K(X, Y ) = G X λ F -1 λ G Y λ ,<label>(5)</label></formula><formula xml:id="formula_7" coords="4,221.59,389.21,259.00,10.32">F λ = E x∼u λ [∇ λ log u λ (x)∇ λ log u λ (x) ].<label>(6)</label></formula><p>As F λ is symmetric and positive definite, it can be decomposed as,</p><formula xml:id="formula_8" coords="4,281.83,433.38,198.76,10.62">F λ = L λ L λ ,<label>(7)</label></formula><p>and the kernel K(X, Y ) is defined as a dot-product between normalized vectors, called Fisher vectors:</p><formula xml:id="formula_9" coords="4,278.90,475.18,201.69,12.69">G X λ = L λ G X λ .<label>(8)</label></formula><p>Linear classifiers typically consume less time than non-linear ones in training and testing phases. Learning a kernel classifier using the Fisher kernel is equivalent to learning a linear classier on the Fisher vectors G X λ . The probability density function u λ in Fisher Vecter encoding is presented using a Gaussian Mixture Model (GMM), defined as</p><formula xml:id="formula_10" coords="4,263.46,566.29,217.13,30.55">u λ (x) = K k=1 π k u k (x)<label>(9)</label></formula><p>The GMM is trained on local features of a large image set using Maximum Likelihood (ML) estimation. The parameters of the trained GMM are denoted as,</p><formula xml:id="formula_11" coords="4,240.51,657.11,240.09,9.65">λ = {π k , µ k , Σ k , k = 1, • • • , K},<label>(10)</label></formula><p>where {π, µ, Σ} are the prior probability, mean vector and diagonal covariance matrix of the Gaussian mixture respectively. This GMM is used to describing low level features X = {x 1 , • • • , x N } extracted from an image I. The soft assignments of the descriptor x i to the kth Gaussian component γ ik is defined as</p><formula xml:id="formula_12" coords="5,256.67,176.31,223.92,26.56">γ ik = π k u k (x i ) K k=1 π k .u k (x i )<label>(11)</label></formula><p>Fisher vector (FV) for X is denoted as</p><formula xml:id="formula_13" coords="5,134.77,212.62,345.83,65.26">φ(X) = {G X µ1 , G X σ1 , • • • , G X µ K , G X σ K }. G µ k and G σ k is defined as: G X µ k = N i=1 1 N √ π k γ ik x i -µ k σ k ,<label>(12)</label></formula><formula xml:id="formula_14" coords="5,225.21,282.51,255.38,30.32">G X σ k = N i=1 1 N √ 2π k γ ik [ (x i -µ k ) 2 σ 2 k -1],<label>(13)</label></formula><p>Where σ k is the square root of the diagonal values of Σ k . When increasing the number of Gaussian kernels, the Fisher vectors gets sparser, and the distribution of the features in a given dimension gets closer to zero. We apply a combination of power normalization and L 2 normalization to each Fisher vector descriptor.</p><p>In z-dimension of the Fisher vector φ, the power normalization is defined as,</p><formula xml:id="formula_15" coords="5,263.33,391.39,217.26,10.81">f (z) = sign(z)|z| α ,<label>(14)</label></formula><p>where 0 ≤ α ≤ 1 is a parameter of the normalization and we choose α = 0.5 in all the experiments. Subsequently, the Fisher vectors are L 2 normalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Visual global descriptors</head><p>This section explains four of our submissions which were based on extracting global visual features [0], and using SVM and Random Forest, two of the very common yet effective classification techniques. For visual features we extracted Edge Histogram and Local Binary Patterns (LBP) using pyramid spatial granularity. The spatial pyramid refers to extracting the entire image as first level then in the second level in 2x2 grids followed by (3x3) grids in the third level. All grid blocks are eventually concatenated. Edge Histogram: We consider 8 edge direction bins and 8 edge magnitude bins, based on a Sobel filter (64-dimensional).</p><p>Local Binary Patterns: We also used LBP histograms of 8-bits local binary patterns, each of which is generated by comparing the gray-scale value of a pixel with those of its 8 neighbors in circular order, and setting the corresponding bit to 0 or 1, accordingly. A pattern is called uniform if it contains at most two bitwise transitions from 0 to 1. The final histogram for each region in our granularity contains 59 bins; 58 for uniform patterns and 1 for all the non-uniform patterns.</p><p>We investigated various classifiers implemented in Weka [0], including: Decision Tree, Support Vector Machine (RBF Kernel, Poly kernel, Normalized Ploy kernel and Puk kernel), Random Forest, Logistic Model Tree (LMT) and Naive Bayesian. The validation results suggested that SMO (with normalized poly kernel) and Random forest were the best choice with respect to classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Fusion of Multiple Methods</head><p>In an attempt to build a strong classifier by leveraging various learning methods explained previously, we have applied two fusion methods: early fusion and late fusion .</p><p>Early feature fusion: In early fusion, we concatenated three types of features to form a single feature vector before classification. Specifically, we concatenated MSLBP-SP (described in Section ), SC-DenseSIFT-SP (described in Section ) and SC-DenseMSLBP-SP (described in Section ).</p><p>Late fusion: In late fusion, we combine the classification scores of the classification models trained on the feature described in Section -. Let a model k provides a confidence score s k i,j for each image i and for each class j. We apply optimization to get the final confident score as the weighted sum: S i,j = k w k * s k i,j , using 10-fold cross validation. At each fold, we select the model with the highest accuracy and tune the weight to get the best combined accuracy. The final weight parameters have been used to calculate the confidence score on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section we explain the detail of experiments and our performance evaluation methodology.</p><p>Dataset: The training set provided for the medical clustering task contains 500 images where each image belongs to one of five categories: head-neck, upperlimb, body, lower-limb and true negative (foreign objects), and each category has 100 images. An independent test set containing 250 images without any class information was also provided.</p><p>Model Tuning: In order to tune the classification models and identify the best parameter values, we used 10 fold cross validation. At each fold we train on 90% of the data and evaluate the models on the remaining 10%. This process is repeated 10 times, each time using different train/test partition. We use average F -Score among all the validation runs to select the best classification model for each feature representation.</p><p>Testing: The best classification model trained on each feature is used to evaluate on the test set. The list of submitted runs is described in Section and the performance is reported in Table . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submitted Runs and results</head><p>Run1: Early fusion of three features: (a) MSLBP-SP (described in Section ) (b) SC-DenseSIFT-SP (described in Section ) (c) SC-DenseMSLBP-SP (described in Section ). SVM classifier with homogenous kernel map and Chi-square kernel is used and multi label classification is employed. Run2: Same as Run1, except that a single label classification is employed. Run3: MSLBP-SP feature described in Section , and SVM classifier with homogenous kernel map and Chi-square kernel is used.</p><p>Run4: SC-DenseMSLBP-SP described in Section , with SVM classifier with homogenous kernel map and Chi-square kernel is applied.</p><p>Run 5: Advanced feature encoding explained in : First, we extracted dense SIFT feature, then applied Fisher Kernel encoding, by learning Mixture of Gaussian (GMMs). As a result, each image has represented by a Fisher Vector. In the next step, we trained linear SVM on the training set and applied it on test set.</p><p>Run 6: Edge Histogram for visual feature descriptor and SMO as classification: in this run, we used global edge histogram using spatial pyramid technique and then SMO, normalized poly kernel, which has been explained in section .</p><p>Run 7: Edge Histogram for visual feature descriptor and Random Forest as classification: in this run, we used the same feature extracted in run 6, and Random Forest as the classification method.</p><p>Run 8: LBP Histogram for visual feature descriptor and SMO as classification: in this run, we extracted LBP histogram using spatial pyramid technique. SMO was used as classification method.</p><p>Run 9: LBP Histogram for visual feature descriptor and Random Forest as classification: Similar to run 8, we used LBP global features, followed by training a Random Forest.</p><p>Run 10: This run was presented from the late fusion model as explained in section .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we described feature extraction and learning methodologies and the fusion strategy applied by the IBM Research Australia team to the medical clustering challenge of ImageCLEF 2015. We utilized advanced feature extraction methods to extract local and global features, as well as advanced feature encoding and classification techniques. We also applied early fusion of low-level features, and late fusion of the results of all trained classifier. Overall, six out of the ten submissions of IBM Research team were among the top 10 best results. All runs has been evaluated based on three metrics: exact match, any match and hamming distance metrics. Two of our ten submitted runs demonstrated outstanding results, and outperformed all other submissions across all teams participating in the competition. The early fusion of MSLBP-SP, SC-DenseSIFT-SP and SC-DenseMSLBP-SP with homogeneous kernel map and Chi-Square kernel based SVM classification achieved highest exact match and any match, whereas Fisher vector resulted in highest hamming distance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,134.77,117.41,345.83,177.10"><head>Table 1 .</head><label>1</label><figDesc>Results of the runs in the test set. Three metrics (Exact Match, Any Match and Hamming distance) have been used to evaluate the accuracy of submissions. Two of our runs which achieved the highest scores across all submitted runs in the competition, have been highlighted by bold font in the table.</figDesc><table coords="7,204.15,171.08,207.05,123.43"><row><cell></cell><cell cols="3">Exact Match Any Match Hamming distance</cell></row><row><cell>Run1</cell><cell>0.752</cell><cell>0.864</cell><cell>0.863</cell></row><row><cell>Run2</cell><cell>0.695</cell><cell>0.840</cell><cell>0.889</cell></row><row><cell>Run3</cell><cell>0.672</cell><cell>0.812</cell><cell>0.874</cell></row><row><cell>Run4</cell><cell>0.599</cell><cell>0.724</cell><cell>0.838</cell></row><row><cell>Run5</cell><cell>0.692</cell><cell>0.832</cell><cell>0.896</cell></row><row><cell>Run6</cell><cell>0.692</cell><cell>0.732</cell><cell>0.755</cell></row><row><cell>Run7</cell><cell>0.470</cell><cell>0.568</cell><cell>0.835</cell></row><row><cell>Run8</cell><cell>0.603</cell><cell>0.708</cell><cell>0.778</cell></row><row><cell>Run9</cell><cell>0.510</cell><cell>0.616</cell><cell>0.849</cell></row><row><cell>Run10</cell><cell>0.689</cell><cell>0.820</cell><cell>0.890</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,147.56,345.63,333.03,7.86;8,156.13,356.59,324.47,7.86;8,156.13,367.54,279.23,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,366.09,345.63,114.51,7.86;8,156.13,356.59,115.47,7.86">Overview of the ImageCLEF 2015 medical clustering task</title>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashraful</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mahmood</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mohammed</forename></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,294.67,356.59,185.93,7.86;8,156.13,367.54,46.41,7.86">CLEF2015 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,377.80,333.02,7.86;8,156.13,388.76,324.46,7.86;8,156.13,399.72,324.46,7.86;8,156.13,410.67,324.46,7.86;8,156.13,421.63,324.46,7.86;8,156.13,432.59,161.52,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,408.51,410.67,72.09,7.86;8,156.13,421.63,162.96,7.86">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Josiah</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefano</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Ashraful</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mahmood</forename><surname>Kazi Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Burak</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Neda</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">María</forename><surname>Del Mar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roldán</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,330.80,421.63,145.83,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,442.85,333.03,7.86;8,156.13,453.81,324.46,7.86;8,156.13,464.76,68.09,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,192.67,453.81,170.97,7.86">Determining the view of chest radiographs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Guumlld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">B</forename><surname>Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,367.61,453.81,51.19,7.86">J. Dig. Imag</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="280" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,475.02,333.03,7.86;8,156.13,485.98,324.47,7.86;8,156.13,496.94,324.46,7.86;8,156.13,507.89,114.57,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,453.97,475.02,26.63,7.86;8,156.13,485.98,324.47,7.86;8,156.13,496.94,47.53,7.86">Teaching &amp; Learning System for Diagnostic Imaging; Phase I: X-ray Image Analysis &amp; Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S S</forename><surname>Faruque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,223.42,496.94,257.18,7.86;8,156.13,507.89,85.91,7.86">Proceedings of the 6th International Conference on Computer Supported Education</title>
		<meeting>the 6th International Conference on Computer Supported Education</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,518.15,333.03,7.86;8,156.13,529.11,324.47,7.86;8,156.13,540.07,83.25,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,374.57,518.15,106.03,7.86;8,156.13,529.11,203.23,7.86">Sao Deroski Hierarchical annotation of medical images Pattern Recognition</title>
		<author>
			<persName coords=""><forename type="first">Ivica</forename><surname>Dimitrovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dragi</forename><surname>Kocev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzana</forename><surname>Loskovska</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page">1011</biblScope>
		</imprint>
	</monogr>
	<note>Oc-toberNovember 2011</note>
</biblStruct>

<biblStruct coords="8,147.56,550.32,333.02,7.86;8,156.13,561.28,324.46,7.86;8,156.13,572.24,228.39,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,445.12,550.32,35.47,7.86;8,156.13,561.28,231.82,7.86">Learning multi-scale block local binary patterns for face recognition</title>
		<author>
			<persName coords=""><forename type="first">Shengcai</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangxin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,406.72,561.28,73.87,7.86;8,156.13,572.24,228.39,7.86">Proceedings of the 2007 international conference on Advances in Biometrics</title>
		<meeting>the 2007 international conference on Advances in Biometrics</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,582.49,333.02,7.86;8,156.13,593.45,324.46,7.86;8,156.13,604.41,185.26,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,409.73,582.49,70.86,7.86;8,156.13,593.45,156.81,7.86">Guillermo Online Dictionary Learning for Sparse Coding</title>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sapiro</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,317.22,593.45,163.37,7.86;8,156.13,604.41,156.97,7.86">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,614.66,333.03,7.86;8,156.13,625.62,273.56,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,279.42,614.66,201.17,7.86;8,156.13,625.62,57.36,7.86">Fisher Kernels on Visual Vocabularies for Image Categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,233.19,625.62,168.39,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,147.56,635.88,333.03,7.86;8,156.13,646.84,324.46,7.86;8,156.13,657.79,52.76,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,394.43,635.88,86.16,7.86;8,156.13,646.84,169.08,7.86">Improving the Fisher Kernel for Large-Scale Image Classification</title>
		<author>
			<persName coords=""><forename type="first">Florent</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,342.17,646.84,138.43,7.86;8,156.13,657.79,24.59,7.86">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,147.22,120.67,333.37,7.86;9,156.13,131.63,306.37,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,271.55,120.67,209.04,7.86;9,156.13,131.63,74.46,7.86">Video Google: a text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,250.12,131.63,184.22,7.86">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,147.22,142.59,333.37,7.86;9,156.13,153.55,254.17,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,256.51,142.59,224.09,7.86;9,156.13,153.55,38.24,7.86">A bayesian hierarchical model for learning natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,213.79,153.55,168.39,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,147.22,164.51,333.37,7.86;9,156.13,175.46,324.46,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,323.87,164.51,156.72,7.86;9,156.13,175.46,138.10,7.86">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,313.41,175.46,139.24,7.86">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,147.22,186.42,333.37,7.86;9,156.13,197.38,324.46,7.86;9,156.13,208.34,324.47,7.86;9,156.13,219.30,259.91,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,191.71,219.30,142.56,7.86">Asaf IBM Research at ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">Mani</forename><surname>Abedini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rahil</forename><surname>Garnavi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Geva</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Amir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michele</forename><surname>Merler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc-Bao And</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pankanti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sharathchandra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xingzhi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tzadok</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Medical Tasks</note>
</biblStruct>

<biblStruct coords="9,147.22,230.26,333.37,7.86;9,156.13,241.22,324.46,7.86;9,156.13,252.18,234.84,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,320.35,241.22,160.24,7.86;9,156.13,252.18,124.92,7.86">The WEKA Data Mining Software: An Update SIGKDD Explorations</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
