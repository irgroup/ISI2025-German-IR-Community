<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.59,116.95,334.18,12.62;1,138.57,134.89,338.22,12.62">FHDO Biomedical Computer Science Group at Medical Classification Task of ImageCLEF 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,215.59,172.56,61.02,8.74"><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
							<email>obioma.pelka@googlemail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science of Applied Sciences and Arts Dortmund (FHDO)</orgName>
								<orgName type="institution">University</orgName>
								<address>
									<addrLine>Emil-Figge-Strasse 42</addrLine>
									<postCode>44227</postCode>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.30,172.56,100.46,8.74"><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
							<email>christoph.friedrich@fh-dortmund.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science of Applied Sciences and Arts Dortmund (FHDO)</orgName>
								<orgName type="institution">University</orgName>
								<address>
									<addrLine>Emil-Figge-Strasse 42</addrLine>
									<postCode>44227</postCode>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.59,116.95,334.18,12.62;1,138.57,134.89,338.22,12.62">FHDO Biomedical Computer Science Group at Medical Classification Task of ImageCLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">98CD689C1918351128A8CC6DC3ACC57F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>bag-of-keypoints</term>
					<term>bag-of-words</term>
					<term>compound figure detection</term>
					<term>modality classification</term>
					<term>medical imaging</term>
					<term>image border profile</term>
					<term>principal component analysis</term>
					<term>random forest</term>
					<term>support vector machine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the modelling approaches performed by the FHDO Biomedical Computer Science Group for the compound figure detection and subfigure classification tasks at ImageCLEF 2015 medical classification. This is the first participation of the group at an accepted lab of the Cross Language Evaluation Forum. For image visual representation, various state-of-the-art visual features such as Bag-of-Keypoints computed with dense SIFT descriptors and the new Border Profile presented in this work, were adopted. Textual representation was obtained by vector quantisation on Bag-of-Words codebook generated using attribute importance derived from Ï‡ 2 -test and the Characteristic Delimiters feature presented in this paper. To reduce feature dimension and noise, the principal component analysis was computed separately for all features. Various multiple feature fusion were adopted to supplement visual image information with their corresponding textual information. Random forest models with 100 to 500 deep trees grown by resampling, a multi class linear kernel SVM with C = 0.05 and a late fusion of the two classifiers were used for classification prediction. Six and Eight runs of submission categories: Visual, Textual and Mixed were submitted for the compound figure detection task and subfigure classification task, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the modelling methods and experiments performed by the FHDO Biomedical Computer Science Group (BCSG) at the ImageCLEF 2015 medical classification. This is the first participation of the BCSG, a research group from the University of Applied Sciences and Arts Dortmund, at the crosslanguage image retrieval track ImageCLEF <ref type="bibr" coords="1,326.95,627.66,15.50,8.74" target="#b27">[28]</ref> of the Cross Language Evaluation Forum (CLEF) <ref type="foot" coords="1,221.41,638.04,3.97,6.12" target="#foot_0">1</ref> .</p><p>The ImageCLEF 2015 medical classification task consists of four subtasks: compound figure detection, multi-label classification, figure separation and subfigure classification of which the BCSG participated in two subtasks <ref type="bibr" coords="2,435.30,143.90,14.61,8.74" target="#b13">[14]</ref>. The remaining of this paper is organised as follows: In section 2 for the subtask compound figure detection, various image representations extracted are presented and the model classifier setup as well as submitted runs and their corresponding results are described. Modelling approach, submitted runs and results for the subfigure classification task are elaborated in section 3. Finally, conclusions are drawn in section 4. Several figures found in biomedical literature consist of several subfigures. To obtain efficient image retrieval on a given search, it is necessary that these figures are separated and not considered as single figures. The first step in achieving this goal is to detect these compound figures. The detailed task definition is presented in <ref type="bibr" coords="2,191.03,355.81,14.61,8.74" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Compound</head><note type="other">Figure Detection</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Features</head><p>For the visual image representation, a combination of high level and low level features was pursued. This is an important step in order to have 'whole-image' and 'detail' representation of an image. The Bag-of-Keypoints feature and the new Border Profile feature specifically adapted for this task were used for the visual image representation. The feature definitions and extraction procedures are described in the following subsections.</p><p>Border Profile: A highly distinguishing feature characterising a compound figure is the existence of a separating border. These borders are usually of white or black color. Hence the first visual feature computed is to detect the presence of such horizontal and vertical black and white color profiles for all images. For comprehension, a white or black border is present when all pixels of a row or column have RGB V alue = [255, 255, 255] or RGB V alue = [0, 0, 0] respectively. To detect this presence, the functions listed in Table <ref type="table" coords="2,372.54,572.32,4.98,8.74" target="#tab_3">1</ref> were implemented and their respective results were concatenated to obtain the complete feature vector. Fig. <ref type="figure" coords="2,155.27,596.23,4.98,8.74" target="#fig_0">1</ref> depicts a flowchart containing the steps computed for detection of white horizontal borders.</p><p>To visually demonstrate the outcomes of the functions in Table <ref type="table" coords="2,424.89,621.25,3.87,8.74" target="#tab_3">1</ref>, compound figures separated with white as well as black borders were selected. The compound figure in Fig. <ref type="figure" coords="2,225.58,645.16,4.98,8.74">2</ref> displays the central nervous system and skeletal involvement by breast cancer of a rat and was adapted from <ref type="bibr" coords="2,370.78,657.11,14.61,8.74" target="#b24">[25]</ref>.  Compound figures can also be separated using borders with colors other than white. Figure <ref type="figure" coords="4,195.76,131.95,4.98,8.74">3</ref> display the detection of horizontal and vertical black separating borders. The compound figure adapted from <ref type="bibr" coords="4,335.12,143.90,14.61,8.74" target="#b9">[10]</ref>, shows a planning CT image and its corresponding follow-up CT image acquired at week 6 of combined radiochemotherapy of a patient. The same cut-off threshold outlined above was used.</p><p>Bag-of-Keypoints: For whole-image classification tasks, the bag of feature approach has achieved high accuracy results <ref type="bibr" coords="4,321.06,222.09,15.50,8.74" target="#b28">[29]</ref> and <ref type="bibr" coords="4,359.56,222.09,14.61,8.74" target="#b17">[18]</ref>. The motivation to this idea comes from bag-of-word approach used for text categorisation. Limitations of invariance present in <ref type="bibr" coords="4,243.44,246.00,15.50,8.74" target="#b18">[19]</ref> was eliminated in the comprehensively evaluated approach presented in <ref type="bibr" coords="4,233.16,257.95,9.96,8.74" target="#b6">[7]</ref>, which has now become a common state of the art approach for image classification. They proposed a method called Bag-of-Keypoints (BoK) which is based on vector quantization of affine invariant descriptors of image patches. Apart from the invariance to affine transformation, another advantage that comes with this method is the simplicity.</p><p>The task here to tackle being a whole-image classification task, the Bag-of-Keypoints approach was adopted as a visual image representation. The functions used for this approach are from the VLFEAT library <ref type="bibr" coords="4,366.57,341.73,14.61,8.74" target="#b26">[27]</ref>. As visual descriptors, dense SIFT descriptors applied at several resolutions were uniformly extracted with an interval grid of 4 pixels using the vl-phow function. To speed up computational time, k-means clustering with approximated nearest neighbours (ANN) <ref type="bibr" coords="4,134.77,389.56,15.50,8.74" target="#b14">[15]</ref> was computed on these randomly chosen descriptors using the vl-kmeans function, to partition the observations into k clusters so that the within-cluster sum of squares is minimised <ref type="bibr" coords="4,260.16,413.47,14.61,8.74" target="#b11">[12]</ref>.</p><p>A maximum of 20 iterations was defined to allow the k-means algorithm converge. The cluster centres were initialised using random data points. As k = 12000, a codebook containing 12, 000 keypoints was generated and was further optimised by adapting a kd-tree with metric distance L 2 for quick nearest neighbour lookup using vl-kdtreebuild function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Textual Features</head><p>Text representations for all images was derived from their figure caption. All figures in the ImageCLEF collection originate from biomedical literature published in PubMed Central<ref type="foot" coords="4,218.98,546.44,3.97,6.12" target="#foot_1">2</ref> . The original figure caption and journal title are extracted from the provided XML files of this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag-of-Words:</head><p>The Bag-of-Words (BoW) approach <ref type="bibr" coords="4,369.74,590.34,15.50,8.74" target="#b23">[24]</ref> is one of the common methods used for text classification. The basic concept here is to extract features by counting the frequency or presence of words in the text to be classified. These words have to be defined first in a dictionary or codebook. To generate the needed dictionary, all words from the captions of all images in the distributed collection were extracted. Several text processing procedures such as removal of stop-words and stemming using PorterStemmer <ref type="bibr" coords="5,359.88,131.95,15.50,8.74" target="#b22">[23]</ref> were induced to obtain a positive effect on computational time performance. The occurrence (%) for all words in both classes was computed. Words with less than 85% difference between the two classes were eliminated to further reduce the dictionary size. For the BoW representation two dictionaries were created:</p><p>-Dictionary 1 (D 1 ): 455 words obtained with porter stemming, removal of stop-words and word occurrence. -Dictionary 2 (D 2 ): 3906 words obtained with removal of stop-words and word occurrence. The benefit of Ï‡ 2 -test and Information Gain have been investigated, but not further used since no relevant advantage was detected during feature selection.</p><p>Charateristic Delimiters: When captions of compound figures are written, it is most likely that existing subfigures are addressed using some delimiter. Depending on the certainty that a figure can only be called 'compound figure' when it contains at least two subfigures, the presence of two delimiters was determined.</p><p>To achieve this task, a set of possible double delimiters characterising compound figures was computed. This step was manually done by analysing the captions of compound figures from the training set and selecting words with very high occurrence. Such words that appear often and hence significantly characterise the presence of subfigures are referred in this work as 'Characteristic Delimiters'. A sub-collection of delimiters used are listed in Table <ref type="table" coords="5,424.19,401.19,3.87,8.74" target="#tab_0">2</ref>.</p><p>If existence of a delimiter pair is detected in the caption of an image, the figure is textually represented by assigning the value <ref type="bibr" coords="5,371.87,425.10,10.51,8.74" target="#b0">[1,</ref><ref type="bibr" coords="5,384.03,425.10,7.75,8.74" target="#b0">1]</ref> and otherwise [0, 0] to the feature vector. ii.</p><p>First subfigure Second subfigure 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">(1).</head><p>(2). 1).</p><p>2). Left Right I). II).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Classifier Setup</head><p>A fusion of all textual and visual representations will result to a feature vector with 15910 columns. To model an efficient and effective classifier, the feature dimensions and noise is reduced using the principal component analysis <ref type="bibr" coords="5,467.32,621.25,9.96,8.74" target="#b7">[8]</ref>.</p><p>The principal component analysis is separately computed on each feature vector group as shown in Fig. <ref type="figure" coords="5,233.39,645.16,3.87,8.74" target="#fig_3">4</ref>. Subsequently, the best number of principal components needed to describe the feature were estimated by model selection.  The feature vector Border Profile and Characteristic Delimiter have both 2 columns and hence do not need any dimension reduction. Different combinations of the derived principal components are concatenated to obtain the final feature vector used for training the classifier. These combinations are the various runs submitted for evaluation. Table <ref type="table" coords="6,301.07,395.77,4.98,8.74" target="#tab_1">3</ref> lists the effects on prediction accuracy when certain features are left out during the feature fusion stage. In this ex-post analysis, the contribution (%) for each feature was computed by applying the classifier model of Run4 on the evaluation set and on 10 sampled learning and validation sets. It can be seen that all features contribute positively.</p><p>The distributed collection was split into 10 different learning and validation sets using the bootstrap algorithm <ref type="bibr" coords="6,287.79,467.87,9.96,8.74" target="#b8">[9]</ref>. For category prediction, a random forest (RF) classifier <ref type="bibr" coords="6,199.28,479.82,10.52,8.74" target="#b1">[2]</ref> using the fitensemble function from the MATLAB software package <ref type="bibr" coords="6,172.60,491.78,15.50,8.74" target="#b21">[22]</ref> was modelled. The list below is an excerpt of several parameters used to tune the classifier model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Results</head><p>Six runs (four Mixed, one Visual and one Textual) were submitted for evaluation. Table displays the official evaluation accuracy and retrieval type for each run.</p><p>The fourth column displays the standard mean accuracy and standard deviation achieved on 10 sampled learning and validation set derived using the bootstrap algorithm. 3 Subfigure Classification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>Clinicians have implied on the importance of the modality of an image in several user-studies. The usage of modality information significantly increases the retrieval efficiency, thus image modality has become an essential and relevant factor regarding medical information retrieval <ref type="bibr" coords="7,339.54,645.16,14.61,8.74" target="#b12">[13]</ref>. The subfigure classification subtask aims to evaluate approaches that automatically predict the modality of medical images from biomedical Journals. For further task definition, refer to <ref type="bibr" coords="8,134.77,131.95,14.61,8.74" target="#b13">[14]</ref>. Some image categories were represented by few annotated examples, thus the expansion of the original collection was strived in order to counteract the imbalanced dataset. Additional datasets created are described below: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual Features</head><p>Over the years, various techniques for medical imaging have been developed. Each having not only its advantages and disadvantages, but also different acquiring technique. Hence various feature extracting methods are needed to apprehend the possible characteristics of medical images <ref type="bibr" coords="8,378.09,417.14,9.96,8.74" target="#b4">[5]</ref>. In addition, images have to be completely represented, i.e. 'whole image' and 'detail' representation. This can be acquired by extracting global and local features. These features: BAF, Gabor, JCD, Tamura, PHOG were extracted using functions from the LIRE: Lucene Image Retrieval library <ref type="bibr" coords="8,303.25,464.96,14.61,8.74" target="#b20">[21]</ref>.</p><p>-Bag-of-Keypoints: Visual image representation using the Bag-of-Keypoints approach described in the subsection 2.2. With the distinction, that three different datasets were used to create various codebooks accordingly. -BAF: The global features (brightness, clipping, contrast, hueCount, saturation, complexity, skew and energy) represented as a 8-dimensional vector. -CEDD: Low-level feature CEDD (Color and Edge Directivity Descriptor) <ref type="bibr" coords="8,470.09,544.75,10.52,8.74" target="#b3">[4]</ref> incorporating color and textures information were extracted and represented as a 144-dimensional vector. -FCH: The Fuzzy Color Histogram considers through fuzzy-set membershipp function the color similarity of each pixel's color to all histogram binis and is represented as a 10-dimensional vector using the fuzzy linking method <ref type="bibr" coords="8,151.70,616.49,14.61,8.74" target="#b10">[11]</ref>, <ref type="bibr" coords="8,169.97,616.49,14.61,8.74" target="#b16">[17]</ref>. -Gabor: A 60-dimensional vector was used to represent texture features based on Gabor functions.</p><p>-JCD: The Joint Composite Descriptor (JCD) is a combination of two Compact Composite Descriptors: Color and Edge Directivity Descriptor (CEDD) and Fuzzy Color Texture Histogram (FCTH) <ref type="bibr" coords="9,356.76,143.90,9.96,8.74" target="#b3">[4]</ref>. The feature made up of merging the texture areas of CEDD and FCTH was represented as a 168dimensional vector. -Tamura: The Tamura features consisting of six basis textural feature: coarseness, contrast, directionality, line-likeness, regularity and roughness, were represented as a 18-dimensional vector <ref type="bibr" coords="9,323.26,204.13,14.61,8.74" target="#b25">[26]</ref>. -PHOG: The Pyramid of Histograms of Oriented Gradients (PHOG) feature proposed in <ref type="bibr" coords="9,205.24,228.49,10.52,8.74" target="#b0">[1]</ref> represents an image by its local shape and the spatial layout of the shape. A 630-dimensional vector was used for feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Textual Features</head><p>Similar to the compound figure detection task, textual representation for the figures was adopted using their corresponding captions.</p><p>Bag-of-Words: The process of textual representation executed is complementary to the process for the compound figure detection task described in subsection 2.3. With an adjustment in dictionary generation and word selection method. The figures distributed for the subfigure classification task are subfigures extracted from compound figures, hence their corresponding captions actually describe compound figure and not the single subfigures. Considering that multipane figures consist of subfigures not only from the same category but also from multiple categories, using the original captions to represent the subfigures will not lead to a valuable characterisation.</p><p>To overcome this limitation, the dictionary was built using the DataSet 4 . The figures in this dataset do not originate from multipane figures and thus have characteristic captions that can be mapped to the 30 subfigure categories. All words from all captions were retrieved, removal of stop-words and stemming was done in the text preprocessing stage. To develop a dictionary containing relevant words for each category, vector quantisation on all figures and the Ï‡ 2 -test <ref type="bibr" coords="9,470.08,506.70,10.52,8.74" target="#b5">[6]</ref> was computed on the derived matrix. With this step, attribute importance for all words was effectuated.</p><p>A dictionary with 438 words was finally obtained by selecting words with attribute importance over a fixed cutoff threshold. The captions of the subfigures were trimmed to relevance using the characteristic delimiters presented in subsection 2.3 before vector quantisation on the generated dictionary was performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classifier Setup</head><p>Contrary to the compound figure detection task, not only a random forest classifier model was used. A multiclass linear kernel SVM from the libSVM library <ref type="bibr" coords="9,470.09,657.11,10.52,8.74" target="#b2">[3]</ref> was modelled to compare prediction accuracies between the two classifier models, as it has been a popular approach in former ImageCLEF medical challenges <ref type="bibr" coords="10,134.77,143.90,14.61,8.74" target="#b12">[13]</ref>. The cost parameter used was C = 0.05. The random forest model was tuned with the same parameters mentioned in subsection 2.4. Ten samples of learning and validation sets were obtained using the bootstrap algorithm <ref type="bibr" coords="10,417.91,167.81,9.96,8.74" target="#b8">[9]</ref>.</p><p>To reduce computational time, feature dimension and noise reduction was achieved using the principal component analysis. All features beside the BAF features were reduced using this method. Table <ref type="table" coords="10,341.18,209.92,4.98,8.74" target="#tab_4">5</ref> presents the original and truncated vector size after computing the principal component analysis on each feature. The contribution of a feature to prediction performance is an important attribute that assists efficient feature selection. To obtain each feature contribution, the difference between the accuracy when all features are combined and the accuracy when a certain feature is omitted was calculated and displayed in the fourth column of Table <ref type="table" coords="10,240.54,281.65,3.87,8.74" target="#tab_4">5</ref>. The feature contribution analysis was done ex-post. The prediction accuracy used for this analysis was computed by applying the classifier model Run1 on the original evaluation set. Drawing conclusions using Table <ref type="table" coords="10,300.78,573.43,3.87,8.74" target="#tab_4">5</ref>, it can be seen that omitting most of the extracted features leads to a negative effect on prediction performance. The representations BoK, BoW and BAF have the most contributions. In contrary, the omission of PHOG feature has a positive effect on the prediction performance and hence increases the evaluation accuracy with +0.27%. The principal components computed from Gabor image representation did not improve the prediction accuracy and was omitted from the final fused feature vector used for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Submitted Runs</head><p>The BCSG submitted eight (six Mixed, one Textual and one Visual) runs for evaluation. The several fusion approaches defining the submitted runs are displayed in Table <ref type="table" coords="11,204.51,161.04,3.87,8.74" target="#tab_5">6</ref>. In addition for each set, the prediction performance obtained on 10 sampled learning and validation set using the same modelling approach is listed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Results</head><p>The BCSG submitted runs in all submission categories: Visual, Textual and Mixed. Most of the submitted runs belong to the submission category 'Mixed' which is a combination of textual and visual representation. This decision was made because not only were better accuracies obtained during development, but also evaluation results presented by other ImageCLEF participant groups in the previous years tasks have proven to be better when the 'Mixed' submission category is induced <ref type="bibr" coords="11,243.38,621.25,14.61,8.74" target="#b12">[13]</ref>, <ref type="bibr" coords="11,261.64,621.25,14.61,8.74" target="#b15">[16]</ref>. Figure <ref type="figure" coords="11,315.08,621.25,4.98,8.74" target="#fig_5">5</ref> depicts the achieved performance of all submitted runs for the subfigure classification task. Runs belonging to the Biomedical Computer Science Group are represented in as colored bars and the gray bars represent submissions of other participants. The prediction confusion obtained applying the modelling setup Run5 on the official evaluation set is shown in Fig. <ref type="figure" coords="12,326.63,398.63,3.87,8.74" target="#fig_7">6</ref>. Applying the same model setup on a sampled validation set results to the prediction confusion displayed in Fig.   Various classification prediction approaches based on multiple feature fusion and combination of classifier models were explored for the ImageCLEF 2015 medical classification task. Negative differences in the prediction performance were observed when the Bag-of-Keypoints representation was computed using SIFT <ref type="bibr" coords="13,160.81,192.90,15.50,8.74" target="#b19">[20]</ref> instead of dense SIFT descriptors, feature vectors weren't normalised and single precision format was used rather than double precision format to define floating-points numbers. The discrepancy between prediction performance on the evaluation set and on the sampled learning and validation sets is assumed to be an overfitting problem. Supplementing visual image representation with corresponding textual representation proved to be a beneficial strategy regarding classification accuracy. Omitting any of the described features apart from the PHOG feature, results to a negative decrease on the official evaluation accuracy. The proposed Border Profile image representation could be further enhanced by implementing additional functions to detect border profile of colors other than black and white.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,282.49,102.75,8.77"><head>2. 1</head><label>1</label><figDesc>Task Definition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,312.60,212.60,7.89;3,134.77,323.58,212.59,7.86;3,134.77,334.54,28.75,7.86;3,139.84,117.83,202.46,180.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. detectWhiteHorizontalBorder() function, computed for detection of white horizontal border profiles</figDesc><graphic coords="3,139.84,117.83,202.46,180.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,134.77,634.11,164.40,7.89;3,134.77,645.09,164.40,7.86;3,134.77,656.05,164.40,7.86;3,134.77,475.34,143.74,144.00"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Detected horizontal and vertical white separating borders as dark blue bars and frame borders as light blue bars</figDesc><graphic coords="3,134.77,475.34,143.74,144.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,134.77,275.18,170.07,7.89;6,134.77,286.17,170.07,7.86;6,134.77,297.13,170.07,7.86;6,134.77,308.09,141.73,7.86;6,134.77,117.83,179.99,142.58"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Original and truncated vector size for extracted visual and textual representations after dimension and noise reduction with principal components analysis</figDesc><graphic coords="6,134.77,117.83,179.99,142.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,140.99,519.05,112.94,8.77;6,140.99,531.36,179.97,8.77;6,140.99,543.68,113.58,8.77;6,140.99,556.00,158.94,8.77;6,134.77,587.70,108.11,8.77;6,134.77,609.47,345.84,8.74;6,134.77,621.43,255.15,8.74;6,140.99,645.13,339.10,9.68;6,151.70,657.11,315.03,8.74;7,140.99,119.96,339.61,8.77;7,151.70,131.95,328.91,8.74;7,151.70,143.90,53.34,9.65;7,140.99,156.09,339.60,8.77;7,151.70,168.08,50.73,8.74;7,140.99,180.27,339.60,8.77;7,151.70,192.26,148.43,9.65;7,140.99,204.45,346.08,8.77;7,151.70,216.44,293.21,8.74;7,140.99,228.63,339.61,8.77;7,151.70,240.62,266.94,9.65"><head>-</head><label></label><figDesc>Number of Trees = 200 -Number of Leaf Size = [0.04, 0.06, 0.3] -Split Criterion = Exact -Ensemble grown = By resampling 2.5 Submitted Runs In this section, the six compound figure detection runs submitted by the Biomedical Computer Science Group for evaluation are presented. -task1 run1 mixed stemDict: A combination of BoW with Dictionary 1 textual features and BoK visual features was used to train the classifier. -task1 run2 mixed sparse1: Visual features: Border profile and Characteristic Delimiter combined with textual features derived from the BoW Dictionary 1 . -task1 run3 mixed sparse2: Same as run2 without the BoW textual representation. -task1 run4 mixed bestComb: Fusion of all features described. BoW features extracted using Dictionary 2 . -task1 run5 visual sparseSift: This random forest model classifier is trained only with the visual features: Bag-of-Keypoints and Border Profile. -task1 run6 text sparseDict: Model was trained only with the textual features BoW with Dictionary 1 and Characteristic Delimiter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="12,134.77,340.40,345.81,7.89;12,134.77,351.38,328.50,7.86;12,172.38,116.83,270.60,208.80"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Official evaluation prediction performance(%) of all submitted runs. Colored bars represent the performance of BCSG and gray bars that of other participants</figDesc><graphic coords="12,172.38,116.83,270.60,208.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="12,134.77,422.54,345.84,8.74;12,134.77,434.49,345.84,8.74;12,134.77,446.45,345.84,8.74;12,134.77,458.41,325.40,8.74"><head>7 .</head><label>7</label><figDesc>The prediction performance achieved for this task is not comparable to that of the ImageCLEF 2013 Modality Classification subtask. The two tasks have a similar modality hierarchy, however 37.74% of the ImageCLEF 2013 training set represents the additional 'Compound or Multipane images (COMP)' class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="12,134.77,649.10,155.90,7.89;12,134.77,660.08,134.97,7.86;12,134.77,491.96,180.00,142.36"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Confusion matrix by applying run5 on the official evaluation set</figDesc><graphic coords="12,134.77,491.96,180.00,142.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="12,324.69,650.74,155.90,7.89;12,324.69,661.72,131.96,7.86;12,324.69,491.97,178.90,144.00"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Confusion matrix by applying run5 on a sampled validation set</figDesc><graphic coords="12,324.69,491.97,178.90,144.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,149.98,461.31,288.34,86.75"><head>Table 2 .</head><label>2</label><figDesc>Delimiters characterising captions of compound figures</figDesc><table coords="5,149.98,483.53,149.76,64.53"><row><cell cols="2">First subfigure Second subfigure</cell></row><row><cell>A.</cell><cell>B.</cell></row><row><cell>(A).</cell><cell>(B).</cell></row><row><cell>A).</cell><cell>B).</cell></row><row><cell>Lower</cell><cell>Upper</cell></row><row><cell>i.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,326.35,131.60,144.14,184.73"><head>Table 3 .</head><label>3</label><figDesc>Adjustment in accuracy on classification model Run4 by omitting a feature in comparison to when all features are used. The evaluation was done ex-post</figDesc><table coords="6,328.14,186.18,142.34,119.19"><row><cell>Feature</cell><cell>Loss of Eval.</cell><cell>Accuracy (%)</cell><cell>Loss of Dev.</cell><cell>Accuracy</cell><cell>(% Â± sd)</cell></row><row><cell>BoK</cell><cell cols="5">-4.50 -2.63(Â±0.54)</cell></row><row><cell>Border Profile</cell><cell cols="5">-2.65 -2.69(Â±0.58)</cell></row><row><cell>Characteristic</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Delimiter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note coords="6,402.19,286.55,68.29,7.86;6,328.14,308.47,20.60,7.86;6,402.19,308.47,68.29,7.86"><p>-0.94 -1.62(Â±0.63) BoW -1.81 -1.09(Â±0.63)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,368.29,345.82,155.49"><head>Table 4 .</head><label>4</label><figDesc>Official evaluation accuracy of submitted runs showing retrieval type with standard mean accuracy and corresponding standard deviation achieved on 10 sample validation sets using the same modelling approach</figDesc><table coords="7,138.49,412.43,327.30,111.35"><row><cell>Run ID</cell><cell>Retrieval</cell><cell>Evaluation</cell><cell>Development</cell></row><row><cell></cell><cell>Type</cell><cell>Accuracy (%)</cell><cell>Accuracy (% Â± sd)</cell></row><row><cell>task1 run1 mixed stemDict</cell><cell>Mixed</cell><cell>83.88</cell><cell>85.64 (Â±0.44)</cell></row><row><cell>task1 run2 mixed sparse1</cell><cell>Mixed</cell><cell>85.39</cell><cell>85.71 (Â±0.54)</cell></row><row><cell>task1 run3 mixed sparse2</cell><cell>Mixed</cell><cell>80.07</cell><cell>86.24 (Â±0.54)</cell></row><row><cell cols="2">task1 run4 mixed bestComb Mixed</cell><cell>73.32</cell><cell>90.11 (Â±0.36)</cell></row><row><cell cols="2">task1 run5 visual sparseSift Visual</cell><cell>72.51</cell><cell>85.69 (Â±0.48)</cell></row><row><cell cols="2">task1 run6 textual sparseDict Textual</cell><cell>78.34</cell><cell>85.17 (Â±0.45)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,138.97,187.78,347.91,152.27"><head>1 .</head><label>1</label><figDesc>DataSet 1 (DS 1 ): The original training collection distributed for the subfigure classification task in ImageCLEF2015 Medical Classification. 2. DataSet 2 (DS 2 ): Additive to DataSet 1 , the complete collection distributed in ImageCLEF2013 AMIA 3 Medical Task. The collection contains over 300,000 images from over 45,000 biomedical research articles of the PubMed Central Repository hosted by the U.S. National Library of Medicine. 3. DataSet 3 (DS 3 ): Additive to DataSet 1 , the collection distributed for the Modality Classification ImageCLEF2013 AMIA medical subtask. This is a sub-collection of DataSet 2 and contains figures annotated into 31 categories. Figures belonging to the compound figure 'COMP' category were eliminated to attain the same categories in DataSet 1 . 4. DataSet 4 : (DS 4 ) The sub-collection for the Modality Classification task in ImageCLEF 2013 AMIA medical task without the 'COMP' category.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,350.55,345.82,170.93"><head>Table 5 .</head><label>5</label><figDesc>Descriptors with original and truncated feature vector size and feature contribution (%) evaluated on classifier model Run1. The evaluation done ex-post</figDesc><table coords="10,154.08,384.22,307.20,137.26"><row><cell>Descriptor</cell><cell>Original</cell><cell>Reduced</cell><cell>Loss of Prediction</cell></row><row><cell></cell><cell>Vector Size</cell><cell>Vector Size</cell><cell>Accuracy (%)</cell></row><row><cell>Bag-of-Keypoints</cell><cell>12000</cell><cell>25</cell><cell>-2.99</cell></row><row><cell>Bag-of-Words</cell><cell>438</cell><cell>40</cell><cell>-6.42</cell></row><row><cell>BAF</cell><cell>8</cell><cell>8</cell><cell>-4.06</cell></row><row><cell>CEDD</cell><cell>144</cell><cell>5</cell><cell>-0.49</cell></row><row><cell>FCH</cell><cell>10</cell><cell>3</cell><cell>-0.67</cell></row><row><cell>Gabor</cell><cell>60</cell><cell>0</cell><cell>00.00</cell></row><row><cell>JCD</cell><cell>168</cell><cell>5</cell><cell>-0.43</cell></row><row><cell>Tamura</cell><cell>18</cell><cell>2</cell><cell>-0.76</cell></row><row><cell>PHOG</cell><cell>630</cell><cell>2</cell><cell>+0.27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,134.77,208.44,345.81,294.12"><head>Table 6 .</head><label>6</label><figDesc>Breakdown of feature fusion approach applied for the subfigure classification submitted runs</figDesc><table coords="11,147.52,238.35,316.13,264.21"><row><cell>Run ID: task4 run</cell><cell>Submission Type</cell><cell>Category</cell><cell>Classifier Model</cell><cell>DataSet used</cell><cell>for Training</cell><cell>Bag-of-Keypoints</cell><cell>Codebook Build</cell><cell>Bag-of-Words</cell><cell>Codebook Build</cell><cell>Vector Size</cell><cell>Feature Fusion</cell><cell>Official Evaluation</cell><cell>Accuracy (%)</cell><cell>Development Mean</cell><cell>(% Â± sd)</cell></row><row><cell>1 combination</cell><cell cols="3">Mixed Random</cell><cell cols="12">DS1 DS3 DS4 90 66.48 91.27</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.40)</cell></row><row><cell>2 visual</cell><cell cols="3">Visual Random</cell><cell cols="12">DS1 DS2 DS4 50 60.91 87.58</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.61)</cell></row><row><cell>3 textual</cell><cell cols="3">Textual Random</cell><cell cols="12">DS1 DS1 DS4 40 60.91 79.73</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.87)</cell></row><row><cell>4 clean rf</cell><cell cols="3">Mixed Random</cell><cell cols="12">DS1 DS1 DS4 90 67.24 91.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.40)</cell></row><row><cell cols="4">5 train 20152013 Mixed Random</cell><cell cols="12">DS3 DS3 DS4 90 67.60 82.92</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.59)</cell></row><row><cell>6 clean libnorm</cell><cell cols="15">Mixed LibSVM DS1 DS3 DS4 90 64.34 88.95</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.84)</cell></row><row><cell cols="4">7 clean comb librf Mixed LibSVM</cell><cell cols="12">DS1 DS 1/3 DS4 90 65.99 88.85</cell></row><row><cell></cell><cell></cell><cell></cell><cell>RF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.76)</cell></row><row><cell>8 clean short rf</cell><cell cols="3">Mixed Random</cell><cell cols="12">DS1 DS3 DS4 90 66.44 88.62</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Forest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Â±0.64)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.79,120.33,7.86"><p>http://www.clef-initiative.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,144.73,657.80,144.12,7.86"><p>http://www.ncbi.nlm.nih.gov/pmc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="8,144.73,657.80,162.32,7.86"><p>http://www.imageclef.org/2013/medical</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,370.28,337.62,7.86;13,151.52,381.24,329.05,7.86;13,151.52,392.19,306.18,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,306.67,370.28,173.91,7.86;13,151.52,381.24,22.84,7.86">Representing shape with a spatial pyramid kernel</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,196.92,381.24,283.66,7.86;13,151.52,392.19,61.29,7.86;13,273.52,392.19,37.49,7.86">Proceedings of the 6th ACM International Conference on Image and Video Retrieval</title>
		<meeting>the 6th ACM International Conference on Image and Video Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
	<note>CIVR &apos;07</note>
</biblStruct>

<biblStruct coords="13,142.96,403.39,261.12,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,205.30,403.39,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,273.90,403.39,53.39,7.86">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,414.58,337.62,7.86;13,151.52,425.54,293.58,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,252.32,414.58,198.12,7.86">LIBSVM: A library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,458.83,414.58,21.75,7.86;13,151.52,425.54,209.62,7.86">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,436.74,337.62,7.86;13,151.52,447.69,329.06,7.86;13,151.52,458.65,65.62,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="13,308.48,436.74,172.10,7.86;13,151.52,447.69,211.78,7.86">Compact Composite Descriptors for Content Based Image Retrieval: Basics, Concepts, Tools</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>VDM Verlag</publisher>
			<pubPlace>SaarbrÃ¼cken, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,469.85,302.02,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="13,200.67,469.85,144.51,7.86">Computer vision in medical imaging</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>World Scientific</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,481.04,99.37,7.86;13,242.32,479.27,3.65,5.24;13,249.28,481.04,231.30,7.86;13,151.52,492.00,25.60,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,217.89,481.04,24.43,7.86;13,242.32,479.27,3.65,5.24;13,249.28,481.04,85.37,7.86">The Ï‡ 2 test of goodness of fit</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">G</forename><surname>Cochran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,340.29,481.04,78.87,7.86">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="315" to="345" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,503.19,337.62,7.86;13,151.52,514.15,329.05,7.86;13,151.52,525.11,126.11,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,407.70,503.19,72.87,7.86;13,151.52,514.15,107.72,7.86">Visual categorization with bags of keypoints</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,291.65,514.15,188.92,7.86;13,151.52,525.11,54.26,7.86">Workshop on Statistical Learning in Computer Vision, ECCV</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,536.31,337.62,7.86;13,151.52,547.27,329.06,7.86;13,151.52,558.22,70.78,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,223.85,536.31,124.95,7.86">Principal Components Analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">H</forename><surname>Dunteman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,355.76,536.31,124.81,7.86;13,151.52,547.27,154.43,7.86">Sage University paper. Quantitative applications in the social sciences</title>
		<meeting><address><addrLine>Newbury Park, London, New Delhi</addrLine></address></meeting>
		<imprint>
			<publisher>Sage publications</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,569.42,337.62,7.86;13,151.52,580.38,68.62,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<title level="m" coord="13,265.15,569.42,135.60,7.86">An Introduction to the Bootstrap</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,591.57,337.96,7.86;13,151.52,602.53,329.06,7.86;13,151.52,613.49,289.53,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,430.17,591.57,50.40,7.86;13,151.52,602.53,329.06,7.86;13,151.52,613.49,101.28,7.86">Evolution of surface-based deformable image registration for adaptive radiotherapy of non-small cell lung cancer (NSCLC)</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guckenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Baier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flentje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,260.97,613.49,80.24,7.86">Radiation Oncology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">68</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,624.68,337.96,7.86;13,151.52,635.64,227.43,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,227.78,624.68,224.71,7.86">Fuzzy color histogram and its use in color image retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,458.44,624.68,22.14,7.86;13,151.52,635.64,136.81,7.86">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="944" to="952" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,646.84,337.96,7.86;13,151.52,657.80,127.57,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,274.51,646.84,128.97,7.86">A k-means clustering algorithm</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Hartigan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,411.85,646.84,68.72,7.86;13,151.52,657.80,36.96,7.86">JSTOR: Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,120.67,337.96,7.86;14,151.52,131.63,329.06,7.86;14,151.52,142.59,235.13,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,210.48,131.63,190.62,7.86">Overview of the ImageCLEF 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">GarcÃ­a</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demner Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,421.10,131.63,59.48,7.86;14,151.52,142.59,201.48,7.86">Working Notes of CLEF 2013 (Cross Language Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,152.87,337.96,7.86;14,151.52,163.83,329.06,7.86;14,151.52,174.79,104.96,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,364.69,152.87,115.89,7.86;14,151.52,163.83,122.74,7.86">Overview of the ImageCLEF 2015 medical classification task</title>
		<author>
			<persName coords=""><forename type="first">GarcÃ­a</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,294.06,163.83,186.52,7.86;14,151.52,174.79,71.33,7.86">Working Notes of CLEF 2015 (Cross Language Evaluation Forum</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,185.07,337.96,7.86;14,151.52,196.03,329.05,7.86;14,151.52,206.99,329.06,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,254.19,185.07,226.39,7.86;14,151.52,196.03,90.78,7.86">Approximate nearest neighbors: Towards removing the curse of dimensionality</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,263.93,196.03,216.64,7.86;14,151.52,206.99,84.70,7.86;14,296.81,206.99,39.08,7.86">Proceedings of the 30th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 30th Annual ACM Symposium on Theory of Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="604" to="613" />
		</imprint>
	</monogr>
	<note>STOC &apos;98</note>
</biblStruct>

<biblStruct coords="14,142.61,217.27,337.96,7.86;14,151.52,228.23,329.06,7.86;14,151.52,239.19,329.05,7.86;14,151.52,250.15,212.11,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,263.29,228.23,217.29,7.86;14,151.52,239.19,324.65,7.86">Evaluating performance of biomedical image retrieval systems-an overview of the medical image retrieval task at ImageCLEF 2004-2014</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>GarcÃ­a Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,250.15,183.44,7.86">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,260.43,337.96,7.86;14,151.52,271.39,319.77,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,355.79,260.43,124.78,7.86;14,151.52,271.39,105.52,7.86">Image retrieval based on fuzzy color histogram processing</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Andreadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,264.11,271.39,96.61,7.86">Optics Communications</title>
		<imprint>
			<biblScope unit="volume">248</biblScope>
			<biblScope unit="issue">4-6</biblScope>
			<biblScope unit="page" from="375" to="386" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,281.67,337.96,7.86;14,151.52,292.63,329.06,7.86;14,151.52,303.59,329.05,7.86;14,151.52,314.55,182.76,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,307.32,281.67,173.26,7.86;14,151.52,292.63,204.60,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,380.11,292.63,100.47,7.86;14,151.52,303.59,329.05,7.86">Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,324.83,337.96,7.86;14,151.52,335.79,329.06,7.86;14,151.52,346.75,142.14,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,394.94,324.83,85.63,7.86;14,151.52,335.79,100.44,7.86">Statistical learning of multi-view face detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,285.61,335.79,194.97,7.86;14,151.52,346.75,67.49,7.86">Proceedings of the 7th European Conference on Computer Vision</title>
		<meeting>the 7th European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="67" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,357.03,337.96,7.86;14,151.52,367.99,213.19,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,205.63,357.03,234.10,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,448.30,357.03,32.27,7.86;14,151.52,367.99,138.96,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,378.27,337.97,7.86;14,151.52,389.23,329.05,7.86;14,151.52,400.19,284.35,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="14,283.80,378.27,196.78,7.86;14,151.52,389.23,44.95,7.86">Lire: Lucene image retrieval an extensible java cbir library</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<editor>El-Saddik, A., Vuong, S., Griwodz, C., Bimbo, A.D., Candan, K.S., Jaimes, A.</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1085" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,410.47,337.96,7.86;14,151.52,421.43,69.27,7.86" xml:id="b21">
	<monogr>
		<title level="m" coord="14,151.52,410.47,130.32,7.86">MATLAB: version 8.5.0.197613</title>
		<meeting><address><addrLine>Natick, Massachusetts</addrLine></address></meeting>
		<imprint>
			<publisher>The MathWorks Inc</publisher>
			<date type="published" when="2015">R2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,431.72,337.96,7.86;14,151.52,442.68,153.71,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,199.70,431.72,131.00,7.86">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,337.80,431.72,142.77,7.86;14,151.52,442.68,74.87,7.86">Program-electronic Library and Information Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,452.96,337.96,7.86;14,151.52,463.92,242.97,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="14,255.61,452.96,180.77,7.86">Introduction to modern information retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,443.12,452.96,37.45,7.86;14,151.52,463.92,110.15,7.86">McGraw-Hill computer science series</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,474.20,337.96,7.86;14,151.52,485.16,329.05,7.86;14,151.52,496.12,329.06,7.86;14,151.52,507.08,139.07,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="14,271.34,485.16,209.23,7.86;14,151.52,496.12,292.00,7.86">Rat model of metastatic breast cancer monitored by MRI at 3 tesla and bioluminescence imaging with histological correlation</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">K</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ganjei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Klaunberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Despres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,450.23,496.12,30.35,7.86;14,151.52,507.08,102.72,7.86">Journal of Translational Medicine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,517.36,337.96,7.86;14,151.52,528.32,294.72,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="14,312.00,517.36,168.57,7.86;14,151.52,528.32,40.74,7.86">Texture features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,199.42,528.32,210.48,7.86">IEEE Transactions on System, Man and Cybernatic</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,538.60,337.96,7.86;14,151.52,549.56,329.05,7.86;14,151.52,560.52,134.89,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="14,258.82,538.60,221.76,7.86;14,151.52,549.56,41.02,7.86">Vlfeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
		<idno>MM &apos;10</idno>
	</analytic>
	<monogr>
		<title level="m" coord="14,215.79,549.56,243.47,7.86">Proceedings of the International Conference on Multimedia</title>
		<meeting>the International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1469" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,570.80,337.96,7.86;14,151.52,581.76,329.06,7.86;14,151.52,592.72,329.05,7.86;14,151.52,603.68,329.05,7.86;14,151.52,614.64,126.65,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="14,398.62,592.72,81.95,7.86;14,151.52,603.68,142.90,7.86">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar RoldÃ¡n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>GarcÃ­a</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="14,301.24,603.68,139.06,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,624.92,337.96,7.86;14,151.52,635.88,329.05,7.86;14,151.52,646.84,329.05,7.86;14,151.52,657.80,182.76,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="14,345.85,624.92,134.73,7.86;14,151.52,635.88,212.32,7.86">Svm-knn: Discriminative nearest neighbor classification for visual category recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,384.80,635.88,95.77,7.86;14,151.52,646.84,329.05,7.86">Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2126" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
