<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,221.03,116.95,173.29,12.62;1,204.30,134.89,206.75,12.62">IIS at ImageCLEF 2015: Multi-label classification task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.35,173.13,128.71,8.74"><forename type="first">Antonio</forename><forename type="middle">J</forename><surname>Rodríguez-Sánchez</surname></persName>
							<email>antonio.rodriguez-sanchez@uibk.ac.athttps</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Intelligent and Interactive Systems</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.62,173.13,81.80,8.74"><forename type="first">Sabrina</forename><surname>Fontanella</surname></persName>
							<email>fontanellasabrina@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Intelligent and Interactive Systems</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Salerno</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.36,185.08,57.97,8.74"><forename type="first">Justus</forename><surname>Piater</surname></persName>
							<email>justus.piater@uibk.ac.athttps</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Intelligent and Interactive Systems</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,313.27,185.08,72.25,8.74"><forename type="first">Sandor</forename><surname>Szedmak</surname></persName>
							<email>sandor.szedmak@uibk.ac.athttps</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Intelligent and Interactive Systems</orgName>
								<orgName type="institution">University of Innsbruck</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,221.03,116.95,173.29,12.62;1,204.30,134.89,206.75,12.62">IIS at ImageCLEF 2015: Multi-label classification task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D10132BB1AF2BA668656E0F51AC4557A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>Kronecker decomposition</term>
					<term>Maximum Margin</term>
					<term>MMR</term>
					<term>SVM</term>
					<term>multi-label classification</term>
					<term>medical images</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose an image decomposition technique that captures the structure of a scene. An image is decomposed into a matrix that represents the adjacency between the elements of the image and their distance. Images decomposed this way are then classified using a maximum margin regression (MMR) approach where the normal vector of the separating hyperplane maps the input feature vectors into the outputs vectors. Multiclass and multilabel classification are native to MMR, unlike other more classical maximum margin approaches, like SVM. We have tested our approach with the ImageCLEF 2015 multi-label classification task, obtaining high rankings at that task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic image classification is a fundamental part of computer vision. An image is classified according to the visual content it contains. Tasks in image classification include if an image contains a certain object, person, animal or plant; if the image is from a street or it is indoors; or in the case that applies to this paper, if it is a medical figure and the type of medical images and/or graphs it contains. Image classification spans several decades from the first character or digit recognition challenges (still used today), such as the MNIST dataset <ref type="bibr" coords="1,134.77,584.81,10.52,8.74" target="#b0">[1]</ref> to more recent, challenging image classification tasks, such as the Pascal <ref type="bibr" coords="1,467.31,584.81,9.96,8.74" target="#b1">[2]</ref>, Imagenet <ref type="bibr" coords="1,178.21,596.77,10.52,8.74" target="#b2">[3]</ref> or ImageCLEF <ref type="bibr" coords="1,260.57,596.77,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="1,272.75,596.77,7.75,8.74" target="#b4">5]</ref> challenges.</p><p>Image classification algorithms usually consist of a first step where keypoints or regions are found, which are then assigned a representation in terms of a feature vector. During training, the feature vectors extracted from a set of training images are usually grouped into histograms that approximate the distribution of the features for the different types of images. These histograms compose the input to a classification algorithm, such as an SVM (discriminative) or Naive Bayes (generative).</p><p>One of the central problems in exploring the general structure of an image is to recognize the relations between the objects appearing on the image. The task is not really the recognition of the objects but rather building a model on the structure: what belongs to what and how they can be related. It might be similar to the way how an animal could observe the world without labels attached to the object but only relying on relations among them in a certain environment. Those relations could provide the knowledge needed to identify scenes.</p><p>One of the most popular streams of machine learning research is to find efficient methods for learning structured outputs. Several researchers introduced similar approaches to these kind of problems <ref type="bibr" coords="2,332.08,251.50,8.07,8.74" target="#b5">[6]</ref><ref type="bibr" coords="2,340.14,251.50,4.03,8.74" target="#b6">[7]</ref><ref type="bibr" coords="2,340.14,251.50,4.03,8.74" target="#b7">[8]</ref><ref type="bibr" coords="2,340.14,251.50,4.03,8.74" target="#b8">[9]</ref><ref type="bibr" coords="2,344.17,251.50,12.10,8.74" target="#b9">[10]</ref>. Those methods directly incorporate the structural learning into a specially chosen optimization framework.</p><p>It is generally assumed that to learn a discriminating function when the output space is a labeled hierarchy is a much more complex problem than binary classification. In this paper we show that the complexity of this kind of problem can be detached from the optimization model and can be expressed by an embedding into Hilbert space. This allows us to apply a universal optimization model, processing inputs and outputs represented in a properly chosen Hilbert space which can solve the corresponding optimization task without tackling with the underlying structural complexity. The optimization model is an implementation of a certain type of maximum margin regression, an algebraic generalization of the well-known Support Vector Machine. The computational complexity of the optimization scales only with the number of input-output pairs and it is independent from the dimensions of both spaces. Furthermore its overall complexity is equal to a binary classification. Our approach can be easily extended towards other structural learning problems without giving up efficiency on the basic optimization framework.</p><p>Three fundamental steps are needed for structural learning:</p><p>Embedding The structures of the input and output objects are represented as abstract vectors in properly chosen Hilbert spaces reflecting the similarity and the dissimilarity of the objects. Optimization The optimization phase is implemented via a universal solver which tries to find the best similarity based matching between the input and the output representations. Since these representation are expressed as general vectors, the optimizer needs not directly tackle the underlying structural complexity. Inversion The optimizer provides a decision function which emits a vector. The inversion phase has to find the best fitting output structure by projecting the image vector back. This is often referred to as the pre-Image problem, see some alternatives presented in <ref type="bibr" coords="2,309.03,603.09,14.61,8.74" target="#b9">[10]</ref>. If the embedding is realized as a bijective mapping the inversion task is well defined.</p><p>We will make use of the following mathematical notation conventions in the rest of the paper: X stands for the space of the input objects, Y for the space of the outputs. H φ is a Hilbert space comprising the feature vectors, the images of the input vectors with respect to the embedding φ(). H ψ is a Hilbert space comprising the image of label vectors with respect to the embedding ψ(). W is a matrix representing the linear operator projecting the feature space H φ into H ψ . ., . Hz denotes the inner product in Hilbert space H z , . Hz is the norm defined in Hilbert space H z . tr(W) is the trace of matrix W. dim(H) is the dimension of the space H. x 1 ⊗ x 2 denotes the tensor product of the vectors x 1 ∈ H 1 and x 2 ∈ H 2 , and it represents a linear operator A : H 2 → H 1 which acts on a vector z ∈ H 2 as (x 1 ⊗ x 2 )z def = (x 1 x 2 )z = x 1 x 2 , z H2 . A, B F is the Frobenius inner product of a matrix represented by the linear operators A and B and it is defined by tr(A B). A F stands for the Frobenius norm of a matrix represented by the linear operator A and defined by A, A F . A • B is the element-wise(Schur) product of the matrices A and B. A , a is the transpose of any matrix A or any vector a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image feature generation via decomposition</head><p>Let us consider a real 2D image decomposition, where we can expect that the points close to each other within continuous 2D blocks relate more strongly to each other than only considering their connection in 1D rows and columns. To represent the image decomposition, the Kronecker product is applied, which can be expressed as</p><formula xml:id="formula_0" coords="3,172.85,386.16,307.74,65.34">X = A ⊗ B      A 1,1 B A 1,2 B • • • A 1,n A B A 2,1 B A 2,2 B • • • A 2,n A B . . . . . . . . . . . . A m A ,1 B A m A ,2 B • • • A m A ,n A B      A ∈ R m A ×n A , B ∈ R m B ×n B , m X = m A × m B , n X = n A × n B<label>(1)</label></formula><p>In the Kronecker decomposition the second component (B) can be interpreted as a 2D filter of the image represented by the matrix X. We can try to find a sequence of filters by the following procedure:</p><formula xml:id="formula_1" coords="3,138.97,506.82,221.27,90.60">1. k = 1 2. X (k) = X 3. DO 4. d(A (k) , B (k) ) = min A k ,B k X (k) -A (k) ⊗ B (k) 2 5. IF d(A (k) , B (k) ) ≤ STOP 6. X (k+1) = X (k) -A (k) ⊗ B (k) 7. k = k + 1 8. Goto 3</formula><p>The question is, if X is given, how do we compute A and B? It turns out that the Kronecker decomposition can be carried out by Singular Value Decomposition (SVD) working on a reordered representation of the matrix X.</p><p>For an arbitrary matrix X with size m × n the SVD is given by X = USV T where U ∈ R m×m is an orthogonal matrix, UU T = I m , of left singular vectors, V ∈ R n×n , is an orthogonal matrix, VV T = I n , of right singular vectors, and S ∈ R m×n , is a diagonal matrix containing the singular values with nonnegative components in its diagonal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reordering of the matrix</head><p>Since the algorithm solving the SVD problem does not depend directly on the order of the elements of the matrix <ref type="bibr" coords="4,297.97,201.48,14.61,8.74" target="#b10">[11]</ref>, any permutation of the indexes, i.e. reordering the columns and(or) rows, preserves the same solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Kronecker decomposition as SVD</head><p>The solution to the Kronecker decomposition via the SVD can be found in <ref type="bibr" coords="4,462.34,259.07,14.61,8.74" target="#b10">[11]</ref>. This approach considers the aforementioned observation regarding the invariance of the SVD on the reordering of the matrix elements.</p><p>In order to show how the reordering of matrix X can help to solve the Kronecker decomposition problem we present the following example. The matrices in the Kronecker product where the blocks of X and the matrices A and B are vectorized in row wise order. In this vectorization we follow that order which is applied in most of the well known programming languages, C, Java, Python, MATLAB, instead of the column wise order, e.g. used in the Fortran language.</p><formula xml:id="formula_2" coords="4,183.99,340.13,200.87,70.99">X = A ⊗ B         x 11 x</formula><p>We can recognize that X = Ã ⊗ B can be interpreted as the first step in the SVD algorithm where we might apply the substitution √ su = Ã and √ sv = B. The proof that this reordering generally provides the correct solution to the Kronecker decomposition can be found in <ref type="bibr" coords="4,319.19,633.20,14.61,8.74" target="#b10">[11]</ref>.</p><p>We can summarize the main steps of the Kronecker decomposition in the following steps:</p><p>1. Reorder(reshape) the matrix, 2. Compute the SVD decomposition, 3. Compute the approximation of X by Ã ⊗ B 4. Invert the reordering. This kind of Kronecker decomposition is often referred as Nearest Orthogonal Kronecker Product as well <ref type="bibr" coords="5,253.22,186.82,14.61,8.74" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning task</head><p>The learning task that we are going to solve is the following: There is a set -called sample -of pairs of output and input objects {(y i , x i ) : y i ∈ Y, x i ∈ X , i = 1, . . . , m, } independently and identically chosen out of an unknown multivariate distribution P(Y, X). Here we would like to emphasize that the input and the output objects can be arbitrary, e.g. they may be graphs, matrices, functions, probability distributions etc. To these objects, let's consider two functions φ : X → H φ and ψ : Y → H ψ mapping the input and output objects respectively into linear vector spaces, called from now on, the feature space in case of the inputs and the label space when the outputs are considered.</p><p>The objective is to find a linear function acting on the feature space</p><formula xml:id="formula_3" coords="5,256.99,370.30,223.60,8.87">f (φ(x)) = Wφ(x) + b,<label>(2)</label></formula><p>that produces a prediction of every input object in the label space and in this way could implicitly give back a corresponding output object. Formally we have</p><formula xml:id="formula_4" coords="5,238.06,423.24,242.53,10.41">y = ψ -1 (ψ(y)) = ψ -1 (f (φ(x))).<label>(3)</label></formula><p>The learning procedure can be summarized as follows:</p><p>Embedding φ :</p><formula xml:id="formula_5" coords="5,197.47,466.23,219.02,114.58">X input space → H φ feature space, : Y output space → H ψ label space, Similarity W = (W, b) ⇒ ψ(y) ∼ Wφ(x), transformation Inversion ψ -1 : H ψ label space → Y output space .</formula><p>4 Optimization model 4.1 The "Classical" scheme of Support Vector Machine (SVM)</p><p>In the framework of the Support Vector Machine the outputs represent two classes and the labels are chosen out of the set y i ∈ {-1, +1}. The aim is to find a separating hyperplane, via its normal vector, such that the distance between the elements of the two classes, called margin, is the largest one measured in the direction of this normal vector. This base scheme can be extended allowing some sample items to fall closer to the separating hyperplane than to the margin. This learning scenario can be formulated as an optimization problem:</p><formula xml:id="formula_6" coords="6,220.66,186.87,172.38,58.44">min 1 2 w 2 2 + C1 ξ w.r.t. w : H φ → R, normal vector b ∈ R, bias, ξ ∈ R m , error vector s.t. y i (w φ(x i ) + b) ≥ 1 -ξ i ξ ≥ 0, i = 1, . . . , m.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reinterpretation of the normal vector w</head><p>The normal vector w formally behaves as a linear transformation acting on the feature vectors whose capabilities can be even further extended. This extension can be characterized briefly in the following way SVM ExtendedView -w is the normal vector of the separating hyperplane.</p><p>-W is a linear operator projecting the feature space into the label space. y i ∈ {-1, +1} binary outputs.</p><p>-The labels are equal to the binary objects.</p><p>y i ∈ Y arbitrary outputs -ψ(y i ) ∈ H ψ are the labels, the embedded outputs in a linear vector space</p><p>If we apply a one-dimensional normalized label space invoking binary labels {-1, +1} in the general framework, one can restore the original scenario of the SVM, and the normal vector is a projection into the one dimensional label space.</p><p>To summarize the learning task, we end up in the following optimization problem when compared to the original primal form of the SVM:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Primal problems for maximum margin learning Binary class learning</head><p>Vector label learning Support Vector Machine(SVM) Maximum Margin Regression(MMR)</p><formula xml:id="formula_7" coords="6,144.25,505.58,323.53,91.36">min 1 2 w 2 2 + C1 ξ 1 2 W 2 F + C1 ξ w.r.t. w : H φ → R, normal vector W : H φ → H ψ , linear operator, b ∈ R, bias, b ∈ H ψ , translation(bias), ξ ∈ R m , error vector , s.t. y i (w φ(x i ) + b) ≥ 1 -ξ i , ψ(y i ), Wφ(x i ) + b H ψ ≥ 1 -ξ i , ξ ≥ 0, i = 1, . . . , m.</formula><p>In the extended formulation we exploit the fact that the Frobenius norm and inner product correspond to the linear vector space of matrices with dimension equal to the number of elements of the matrices, hence it gives an isomorphism between the space spanned by the normal vector of the hyperplane occurring in the SVM and the space spanned by the linear transformations.</p><p>One can recognize that if no bias term is included in the MMR problem then we have a completely symmetric relationship between the label and the feature space via the representations of the input and the output items, namely</p><formula xml:id="formula_8" coords="7,162.17,159.68,295.71,14.39">ψ(y i ), Wφ(x i ) H ψ = W * ψ(y i ), φ(x i ) H φ = φ(x i ), W * ψ(y i ) H φ .</formula><p>Thus, in predicting the input items as the image of a linear function defined on the outputs the, adjugate of W, W * is involved. This adjugate is equal to the transpose of the matrix representation of W whenever both, the label space and the feature space are finite dimensional spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dual problem</head><p>The dual problem of MMR presented in (4.2) is given by</p><formula xml:id="formula_9" coords="7,178.24,279.53,258.88,65.24">min m i,j=1 α i α j κ φ ij φ(x i ), φ(x j ) κ ψ ij ψ(y i ), ψ(y j )) - m i=1 α i , w.r.t. α i ∈ R, s.t. m i=1 (ψ(y i )) t α i = 0, t = 1, . . . , dim(H ψ ), 0 α i ≤ C, i = 1, . . . , m,</formula><p>where κ φ ij kernel items correspond to the feature vectors, and κ ψ ij kernel items correspond to the label vectors.</p><p>The symmetry of the objective function is clearly recognizable showing that the underlying problem without bias is completely reversible. The explicit occurrences of the label vectors can be transformed into implicit ones by exploiting that the feasibility domain covered by the constraints: m i=1 (ψ(y i )) t α i = 0, t = 1, . . . , dim(H ψ ), coincides with the domain of m i=1 κ ψ ij α i = 0, j = 1, . . . , m involving only inner products of the label vectors.</p><p>In the case of the original SVM κ ψ ij collapses into the product y i y j of the binary labels +1 and -1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Prediction</head><p>After solving the dual problem with the help of the optimum dual variables we can write up the optimal linear operator</p><formula xml:id="formula_10" coords="7,249.98,537.28,115.39,14.11">W = m i=1 α i ψ(y i )φ(x i ) .</formula><p>We can solve this expression by comparing it to the corresponding formula which gives the optimal solution to the SVM, i.e. w = m i=1 α i y i φ(x i ). The new part includes the vectors representing the output items which in the SVM were only scalar values but we could say in the new interpretation that they are one-dimensional vectors. With the expression of the linear operator W at hand, the prediction to a new input item x can be written as</p><formula xml:id="formula_11" coords="7,203.42,636.22,198.49,27.90">ψ(y) = Wφ(x) = m i=1 α i ψ(y i ) φ(x i ), φ(x) κ φ (xi,x)</formula><p>. which involves only the input kernel κ φ and provides the implicit representation of the prediction ψ(y) to the corresponding output y.</p><p>Because only the implicit image of the output is given, we need to invert the function ψ to obtain its corresponding y. This inversion problem is called the pre-image problem. Unfortunately there is no general procedure to do that. We mention here a scheme that can be applied when the set of all possible outputs is finite with a reasonable small cardinality. The meaning of the "reasonable small" cardinality depends on the given problem, e.g. how expensive is to compute the inner product between the output items in the label space where they are represented.</p><p>At the conditions mentioned we can follow this scenario</p><formula xml:id="formula_12" coords="8,153.43,253.68,226.08,43.30">y * = arg max y∈ Y ψ(y) Wφ(x) = arg max y∈ Y m i=1 α i κ ψ (y,yi) ψ(y), ψ(y i ) κ φ (xi,x) φ(x i ) φ(x)</formula><p>where y ∈ Y = {y 1 , . . . , y N } ⇐ is the set of the possible outputs</p><p>The main advantage of this approach is that it requires only the inner products in label space. in addition to this, it is independent from the representation of the output items and can be applied in any complex structural learning problem, e.g. on graphs. Probably the best candidate for Y could be the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hierarchy learning</head><p>As mentioned above in this paper we focus on the case where the output space is a labeled hierarchy (Figure <ref type="figure" coords="8,273.91,421.53,8.30,8.74" target="#fig_0">1a</ref>). The hierarchy learning is realized via an embedding of each path going from a node to the root of the tree. Let V be the set of nodes in the tree. A path p(v) ⊂ V is defined as a shortest path from the node v to the root of the tree and its length is equal to |p(v)|. The set I = 1, . . . , |V | gives an indexing of the nodes. The embedding is realized by a vector valued function ψ : V → R |V | , and the components of ψ(v) are given by</p><formula xml:id="formula_13" coords="8,196.64,499.51,283.95,21.70">ψ(v) i = r if v i / ∈ p(v), sq k if v i ∈ v(p) and k = |p(v)| -|p(v i )|,<label>(4)</label></formula><p>where r, q, s are the parameters of the embedding. The parameter q expresses the diminishing weight of the nodes being closer to the root. If q = 0, assuming 0 0 = 1, then the intermediate nodes and the root are disregarded, thus we have a simple multiclass classification problem. The value of r can be 0 but some experiments show it may help to improve the classification performance. We might conjecture the best choice of the parameters are those which minimize the correlation between all pairs of the label vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Input and output kernels</head><p>For the concrete learning task we need to construct the input and output kernels.</p><p>To build the input kernel, the second component of the Kronecker decomposition of each image -the matrix B in (1) -is used. The inner product between those matrices is computed by applying the Frobenius inner product. The output kernel is created from the inner products of the vectors representing the path in the hierarchy in (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental evaluation</head><p>5.1 ImageCLEF multi-label classification <ref type="bibr" coords="9,349.59,215.17,12.09,8.77" target="#b3">[4,</ref><ref type="bibr" coords="9,363.60,215.17,8.91,8.77" target="#b4">5]</ref> The challenge we participated was the characterization of compound figures. These figures contain subfigures from different types and sources (see figure <ref type="figure" coords="9,462.89,248.85,13.28,8.74" target="#fig_0">1b,</ref><ref type="figure" coords="9,476.17,248.85,4.43,8.74">c</ref> for two examples). The task consists of labeling the compound figures with each of the 30 classes that appear in the hierarchy in figure <ref type="figure" coords="9,367.37,272.76,9.96,8.74" target="#fig_0">1a</ref> without knowing where the separation lines are. The training set consists of 1,071 figures, the test set consists of 927 figures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on the challenge</head><p>In the computation of the prediction results, a 5-fold cross-validation procedure is applied. The original dataset is split uniformly and randomly into 5 equal parts. Then, each part is chosen as test data in a loop and the remaining four parts are taken as training. In the learning procedure, first, a kernel is computed from the corresponding features. Parameters corresponding to each kernel are found by cross validation restricted to the training data, namely it is divided into validation test and validation training parts. Then the learner is trained only on the validation training items. The values of the parameters are chosen which maximize the F 1 score on the validation test. We will report here on two types of kernels: polynomial and Gaussian. We submitted ten runs to the challenge providing our predictions on the labels for the test set (before it was made public). For the ten runs, we used a third degree polynomial kernel, the only factor changing at each run was the random selection in the 5-fold cross-validation. Generation of the feature vectors for the training set took around 60 minutes. The training of MMR would take around one minute, and obtaining the labels for the test set took less than a minute for each run. The ImageCLEF organizers provided the Hamming loss, which is a classical measure for multi-label classification tasks and evaluates the fraction of wrong labels to the total number of labels. The perfect case would be obtaining a Hamming loss of 0. Hamming loss values for the challenge in our case were exceptionally low (very close to 0) and ranged from 0.0671 to 0.0817.</p><p>Once the test set was available we performed extra evaluation. We used three other different evaluation measures that are popular in multi-label classification, namely precision, recall and their combination into the F1 score. They are given by a combination of the true positives T p , false positives F p and false negatives where P is the precision and R is the recall. Here, the perfect case would have a recall value of 1 for any precision. The F 1 measure combines both values into one so that false positives and false negatives are taken into account in this one value. Precision-Recall curves for six different Kronecker 2D filter sizes (4, 8, 12, 20, 28, 34) are given in figure <ref type="figure" coords="10,229.79,585.38,9.96,8.74">2a</ref> for polynomial kernerls of different degrees and in figure <ref type="figure" coords="10,134.77,597.34,9.96,8.74">3a</ref> for Gaussian kernels having different standard deviations. Their respective F1 scores are in figures 2b and 3b. The parameter for the Precision-Recall curve (and the F1 plot) in the polynomial kernel was the degree of the polynomial, from 1 to 10. The parameter that was varied in the Gaussian kernel to generate its Precision-Recall curve (and the F1 plot) was the standard deviation of the Gaussian: 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5 and 10. These results show that larger filter sizes provide better results, although at the largest filter sizes, Precision, Recall and F1 score are very similar. Regarding kernels, when using a polynomial kernel, there is a dramatically increase in F1 scores when using a cubic kernel as compared to a linear or quadratic one. Although at kernels of degree 4 and larger, F1 scores are very similar. In the case of a Gaussian kernel, the best scores happen at standard deviations smaller than 1, although values in the middle (e.g. 0.5, 0.6) provide better results than very small values (e.g. 0.01, 0.05). The best F1 score using a polynomial kernel was 0.38, in the case of a Gaussian kernel, the highest F1 score was 0.43.</p><formula xml:id="formula_14" coords="9,134.77,649.63,345.83,18.66">F n : P = Tp Tp+Fp , R = Tp Tp+Fn , F 1 = 2P R P +R<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have presented an approach based on a structured decomposition of the environment. For example, elements appearing on a scene can be incorporated into a graph in which the objects play the role of the vertices and the edges related to the distances between those objects. Then the knowledge about the environment can be represented by the adjacency matrix of the graph. By decomposing the image matrix into a similar structure, e.g. into a sequence of Kronecker products, the structure behind the scene could be captured. For classification we have applied a version of a maximum margin based regression (MMR) technique <ref type="bibr" coords="12,462.34,167.81,14.61,8.74" target="#b11">[12]</ref>. MMR relies on the fact that the normal vector of the separating hyperplane can be interpreted as a linear operator mapping the feature vectors of input items into the space of the feature vectors of the outputs. The evaluation of our methodology in the ImageCLEF 2015 <ref type="bibr" coords="12,324.31,215.63,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="12,336.49,215.63,7.75,8.74" target="#b4">5]</ref> multi-label challenge provided promising results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgement</head><p>The research leading to these results received funding from the EU 7th Framework Programme FP7/2007-2013 under grant agreement no. 270273, Xperience.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,134.77,486.62,345.81,7.89;10,134.77,497.61,138.07,7.86;10,150.49,339.96,155.64,114.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. a) The hierarchy of classes in the ImageCLEF 2015 [4, 5] multi-label challenge; b) and c) are two figure examples.</figDesc><graphic coords="10,150.49,339.96,155.64,114.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,134.77,264.72,345.82,7.89;11,134.77,275.71,250.99,7.86;11,135.46,296.20,155.62,109.41"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Results for six filter sizes: 4, 8, 12, 20, 18 and 32, training with a polynomial kernel of degrees 1 to 10. a) Precision and Recall, b) F1 score.</figDesc><graphic coords="11,135.46,296.20,155.62,109.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,350.95,298.00,192.31"><head>x</head><label></label><figDesc>12 x 13 x 14 x 15 x 16 x 21 x 22 x 23 x 24 x 25 x 26 x 31 x 32 x 33 x 34 x 35 x 36 x 41 x 42 x 43 x 44 x 45 x 46 x 51 x 52 x 53 x 54 x 55 x 56 x 61 x 62 x 63 x 64 x 65 x 66 11 a 12 a 13 a 21 a 22 a 23 a 31 a 32 a 33 11 x 13 x 15 x 31 x 33 x 35 x 51 x 53 x 55 x 12 x 14 x 16 x 32 x 34 x 36 x 52 x 54 x 56 x 21 x 23 x 25 x 41 x 43 x 45 x 61 x 63 x 65 x 22 x 24 x 26 x 42 x 44 x 46 x 62 x 64 x 66 11 a 12 a 13 a 21 a 22 a 23 a 31 a 32 a 33 ,</figDesc><table coords="4,134.77,350.95,298.00,192.31"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>      </cell><cell>=</cell><cell> </cell><cell>a   ⊗</cell><cell>b 21 b 22 b 11 b 12</cell><cell>,</cell></row><row><cell cols="4">can be reordered into</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">X = Ã ⊗ B =</cell><cell>  </cell><cell></cell><cell>  </cell></row><row><cell></cell><cell></cell><cell>b 11</cell><cell></cell><cell></cell><cell></cell></row><row><cell>=</cell><cell>  </cell><cell>b 12 b 21</cell><cell>   ⊗ a</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>b 22</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,330.55,337.62,7.86;12,151.52,341.48,296.63,7.89" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,341.56,330.55,139.02,7.86;12,151.52,341.51,85.69,7.86">Gradient-based learning applied to document recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,245.22,341.51,99.65,7.86">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,351.61,337.62,7.86;12,151.52,362.57,329.06,7.86;12,151.52,373.50,203.00,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,189.95,362.57,230.87,7.86">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,428.34,362.57,52.24,7.86;12,151.52,373.53,112.85,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,383.63,337.62,7.86;12,151.52,394.59,329.06,7.86;12,151.52,405.55,329.06,7.86;12,151.52,416.51,57.46,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,415.86,394.59,64.72,7.86;12,151.52,405.55,144.22,7.86">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,307.60,405.55,172.97,7.86;12,151.52,416.51,28.79,7.86">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,426.61,337.62,7.86;12,151.52,437.57,329.06,7.86;12,151.52,448.53,329.05,7.86;12,151.52,459.49,329.06,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,396.67,448.53,83.90,7.86;12,151.52,459.49,145.73,7.86">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar Roldán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,305.64,459.49,141.32,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,469.59,337.62,7.86;12,151.52,480.55,329.06,7.86;12,151.52,491.50,277.29,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,364.91,469.59,115.67,7.86;12,151.52,480.55,122.58,7.86">Overview of the ImageCLEF 2015 medical classification task</title>
		<author>
			<persName coords=""><forename type="first">García</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,294.39,480.55,186.19,7.86;12,151.52,491.50,203.02,7.86">Working Notes of CLEF 2015 (Cross Language Evaluation Forum</title>
		<imprint>
			<date type="published" when="2015-09">September 2015</date>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="12,142.96,501.60,337.62,7.86;12,151.52,512.56,25.60,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,296.69,501.60,117.86,7.86">Max-margin markov networks</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,435.46,501.60,40.92,7.86">NIPS 2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,522.66,337.62,7.86;12,151.52,533.62,133.78,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,335.86,522.66,144.72,7.86;12,151.52,533.62,23.08,7.86">Hidden markov support vector machines</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,196.62,533.62,33.70,7.86">ICML&apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,543.72,337.62,7.86;12,151.52,554.68,329.06,7.86;12,151.52,565.62,178.24,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,389.16,543.72,91.42,7.86;12,151.52,554.68,204.45,7.86">Large margin methods for structured and interdependent output variables</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,364.08,554.68,116.50,7.86;12,151.52,565.64,71.75,7.86">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1453" to="1484" />
			<date type="published" when="2005-09">Sep. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,575.74,337.62,7.86;12,151.52,586.70,239.62,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,394.26,575.74,86.32,7.86;12,151.52,586.70,160.67,7.86">Learning hierarchical multi-category text classification models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rousu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,334.72,586.70,26.74,7.86">ICML</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,596.80,337.96,7.86;12,151.52,607.76,210.76,7.86" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bakir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<title level="m" coord="12,173.58,607.76,108.72,7.86">Predicting Structured Data</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J S</forename><surname>Taskar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,617.86,337.96,7.86;12,151.52,628.79,284.64,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,193.99,617.86,136.28,7.86">The ubiquitous kronecker product</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,307.51,628.82,124.39,7.86">The nearest Kronecker product</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="85" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,638.92,337.96,7.86;12,151.52,649.88,233.97,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,304.14,638.92,176.43,7.86;12,151.52,649.88,130.02,7.86">Scalable, Accurate Image Annotation with Joint SVMs and Output Kernels</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Piater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,289.73,649.88,67.08,7.86">Neurocomputing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
