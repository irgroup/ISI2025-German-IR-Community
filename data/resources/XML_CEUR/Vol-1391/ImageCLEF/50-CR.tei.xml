<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.84,117.80,330.94,13.90;1,151.76,135.74,315.09,13.90;1,277.03,153.16,64.56,13.90">Regimvid at ImageCLEF 2015 Scalable Concept Image Annotation Task: Ontology based Hierarchical Image Annotation</title>
				<funder ref="#_Vh3489U">
					<orgName type="full">General Direction of Scientific Research (DGRST), Tunisia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,199.46,191.29,89.93,9.65"><roleName>Anis</roleName><forename type="first">Mohamed</forename><surname>Zarka</surname></persName>
							<email>mohamed.ezzarka@ieee.orgben.ammar.regim@gmail.comadel.alimi@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Reaserch Groups on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.87,191.29,48.98,9.65"><forename type="first">Ben</forename><surname>Ammar</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Reaserch Groups on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.22,191.29,58.95,9.65"><forename type="first">Adel</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Reaserch Groups on Intelligent Machines</orgName>
								<orgName type="institution" key="instit1">University of Sfax</orgName>
								<orgName type="institution" key="instit2">ENIS</orgName>
								<address>
									<postBox>BP 1173</postBox>
									<postCode>3038</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.84,117.80,330.94,13.90;1,151.76,135.74,315.09,13.90;1,277.03,153.16,64.56,13.90">Regimvid at ImageCLEF 2015 Scalable Concept Image Annotation Task: Ontology based Hierarchical Image Annotation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA0EF18C6A9EE78665C25939E122C350</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Annotation</term>
					<term>Classification</term>
					<term>Concept Detection</term>
					<term>fuzzy Ontology</term>
					<term>fuzzy Reasoning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our participation in the Image-CLEF 2015 Scalable Concept Image Annotation task. In this participation, we display our approach for an automatic image annotation by the use of an ontology-based semantic hierarchy handled at both learning and annotation steps. While recent works focused on the use of semantic hierarchies to improve concept detector accuracy, we are investigating the use of such hierarchies to reduce detector complexity and then, to handle efficiently large-scale image datasets. Our framework is based on two steps: (1) constructing a fuzzy ontology through analyzing learning dataset, and (2) guiding the annotation process through a reasoning engine. The obtained results confirm that this approach is promising for scalable image annotation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For the ImageCLEF2015 Scalable Concept Image Annotation task, our aim is to construct an automated image annotation framework that focuses on the scalability aspect through reducing semantic concept detection cost and complexity.</p><p>Automatic photo annotation is considered as a classification problem that consists in assigning a set of semantic concepts to a semantic content of a given image <ref type="bibr" coords="1,163.54,560.97,15.50,8.74" target="#b32">[33,</ref><ref type="bibr" coords="1,180.71,560.97,11.62,8.74" target="#b38">39]</ref>.</p><p>Image collections are increasing staggeringly. Thus, retrieving from largescale image datasets is a challenging task <ref type="bibr" coords="1,328.45,585.13,15.50,8.74" target="#b35">[36,</ref><ref type="bibr" coords="1,345.60,585.13,12.73,8.74" target="#b34">35,</ref><ref type="bibr" coords="1,360.00,585.13,12.73,8.74" target="#b15">16,</ref><ref type="bibr" coords="1,374.39,585.13,11.62,8.74" target="#b33">34]</ref>. The access to such enormous contents has forced the image retrieval community to look for advanced approaches and techniques in order to make the availability of automated and efficient semantic annotation for such contents <ref type="bibr" coords="1,340.31,621.00,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="1,352.49,621.00,12.73,8.74" target="#b29">30,</ref><ref type="bibr" coords="1,366.87,621.00,11.62,8.74" target="#b28">29]</ref>.</p><p>In the previous ImageCLEF Scalable Concept Image Annotation task, <ref type="bibr" coords="1,465.10,633.20,15.50,8.74" target="#b28">[29]</ref> focused on the use of a knowledge based approach. Thus, an ontology was generated and used both: <ref type="bibr" coords="1,232.40,657.11,12.73,8.74" target="#b0">(1)</ref> in training phase to select images that should be used for optimizing classifiers, and (2) in testing phase for deducing new annotations through concept inter-relationships. This approach was considered as the winner within ImageCLEF2014 Scalable Concept Image Annotation task.</p><p>Aspiring to reconcile and exploit the semantic assets provided by the use of knowledge based approaches, number of initiatives have investigated the knowledge engineering for image retrieval ( <ref type="bibr" coords="2,295.76,182.54,15.50,8.74" target="#b25">[26,</ref><ref type="bibr" coords="2,312.92,182.54,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="2,322.32,182.54,12.73,8.74" target="#b9">10]</ref> to cite a few). Yet, ontologies (as a knowledge database) are powerful tools to design concepts and their interrelationships. In general, ontology-based approaches consists in defining a knowledge conceptualization and a reasoning process in order to handle and enhance a semantic interpretation. An immediate effect of such efforts is the alleviation of the semantic barriers and many promising works raised <ref type="bibr" coords="2,379.57,242.32,14.61,8.74" target="#b17">[18]</ref>.</p><p>Aiming to contribute towards this direction, in <ref type="bibr" coords="2,364.61,257.05,14.61,8.74" target="#b37">[38]</ref>, we presented a fuzzy ontology based framework for enhancing a multimedia content indexing accuracy. Key dimensions of this inquiry constitute the three main issues addressed by the existing ontologies, namely a generic ontology structure aspect, an automated knowledge extraction process for populating an ontology content, and a machine-driven context detection for a multimedia content. What was accomplished in this study is a novel ontology management method which is intended to a machine-driven knowledge database construction. The experiment that we conducted on the ImageCLEF2012 dataset displayed semantic improvements over a classical image annotation framework used in large-scale multimedia contents.</p><p>Our submitted runs within ImageCLEF2015 Scalable Concept Image Annotation rely on a visual analysis of the provided testing dataset. As visual features, we used a k-means <ref type="bibr" coords="2,260.83,415.24,15.50,8.74" target="#b31">[32]</ref> algorithm to classify training local feature extract by Surf algorithm <ref type="bibr" coords="2,246.61,427.19,9.96,8.74" target="#b2">[3]</ref>. For scalability, our runs aim to show that we can go further in such aspect by reducing computing cost. In fact, we propose an ontology based approach that alleviates the computing cost for labeling a given testing image by candidate semantic concepts. By reading papers that have been published within ImageCLEF Labs <ref type="bibr" coords="2,291.57,475.01,15.50,8.74" target="#b24">[25,</ref><ref type="bibr" coords="2,308.74,475.01,12.73,8.74" target="#b35">36,</ref><ref type="bibr" coords="2,323.12,475.01,12.73,8.74" target="#b34">35,</ref><ref type="bibr" coords="2,337.51,475.01,7.75,8.74" target="#b6">7,</ref><ref type="bibr" coords="2,346.93,475.01,11.62,8.74" target="#b33">34]</ref>, it can be clearly seen that there are a serious focus made on scalability through reducing the candidate concept list to be analyzed within an image content. Mainly, these works rely on dividing candidate concepts into: (1) initial concepts that can be detected directly through analyzing an image content, and (2) extended concepts that can be detected through reasoning with the initial ones. In <ref type="bibr" coords="2,401.60,534.79,14.61,8.74" target="#b37">[38]</ref>, we presented a fuzzy framework for enhancing a semantic interpretation through reasoning with a given initial concept set. In our submitted runs, we focused on detecting initial concepts. Thus, our contribution consists in developing a fuzzy ontology to guide the annotation process through reducing the number of concepts to be detected.</p><p>The present working note is organized as follows: Section 2 describes the proposed framework. Section 3 describes our submitted runs to ImageCLEF2015 Scalable Concept Image Annotation task as well as comparison results with other participants runs. Finally, a conclusion and some future directions of our work are described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The RegimVid Image Annotation System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Framework overview</head><p>The RegimVid <ref type="bibr" coords="3,208.45,166.95,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="3,225.61,166.95,12.73,8.74" target="#b11">12,</ref><ref type="bibr" coords="3,240.00,166.95,12.73,8.74" target="#b18">19]</ref> is a semantic video indexing, retrieval and visualization system developed within our team. In this paper, we propose a scalable image annotation framework based on hierarchical annotators. We investigate research works on semantic hierarchies for hierarchical image annotation. Our framework relies on constructing and managing a fuzzy ontology that handle a semantic hierarchy. Such a hierarchy is used then to train more accurate image annotators (see figure <ref type="figure" coords="3,232.34,238.68,3.87,8.74" target="#fig_0">1</ref>). Image annotation is considered as a multi-class classification problem. Many approaches were proposed to handle the annotation scalability aspect (large number of concept to annotate with) through combining semantic hierarchical structures with classification techniques (like Svm : Support Vector Machine) <ref type="bibr" coords="3,134.77,585.07,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="3,146.95,585.07,12.73,8.74" target="#b21">22,</ref><ref type="bibr" coords="3,161.33,585.07,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="3,170.74,585.07,11.62,8.74" target="#b23">24]</ref>.</p><p>Mainly, two different approaches were proposed for constructing the semantic hierarchy. The first one is qualified as top-down method: the semantic hierarchy is build through recursive class set clustering <ref type="bibr" coords="3,333.97,621.25,9.96,8.74" target="#b7">[8]</ref>. The second one is qualified as bottom-up method: the hierarchy is defined by agglomerative partitioning of the classes <ref type="bibr" coords="3,166.67,645.16,14.61,8.74" target="#b21">[22]</ref>. Furthermore, two different approaches were proposed also for hierarchical image classification: the first is the Binary Hierarchical Decision Trees (Bhdts) <ref type="bibr" coords="4,167.53,119.99,14.04,8.74" target="#b7">[8]</ref>, and the second is the Decision Directed Acyclic Graphs (Ddags) <ref type="bibr" coords="4,134.77,131.95,14.61,8.74" target="#b14">[15]</ref>.</p><p>Let C = {c 1 , c 2 , . . . , c N } be a set of N semantic concept. The Ddags approach trains N * (N -1)/2 binary classifiers and uses a DAG to decide if an image image belongs or not to a semantic concept class c i ∈ C. At each given node at a distance d from the tree root, d semantic concept classes are eliminated, and N -d decision nodes remain to be evaluated. The Bhdts approach handle the semantic hierarchy as a binary tree: concept classes are clustered hierarchically into two subsets. This clustering step is iterated until a single concept class set is reached. For every clustering step, an Svm classifier is trained in order to decide if an image image could be annotated by the first or the opposite semantic concept class. A total of log 2 (N ) Svm classifiers are trained and used for analyzing a test image. Despite the fact that these two approaches enable accurate classifiers, they handle semantic hierarchy as binary structures which requests a considerable structure to handle with large amount of concept classes.</p><p>In our proposed framework, we aim to define a new method for constructing a hierarchical classifiers for scalable image annotation. At first, an annotated image dataset is analyzed to construct the hierarchy tree for concept classes. Then, and for every level of the defined tree structure, an Svm is trained for predicting if a test image image belongs to the first concept class set or the second one. By starting by the first level (root node), the hierarchy is walked until reaching leafs nodes through computing classifier votes (see figure <ref type="figure" coords="4,448.48,371.84,3.87,8.74">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. Ontology based Hierarchical image classification</head><p>Our method is inspired from fuzzy decision tree based method <ref type="bibr" coords="4,426.88,621.25,15.50,8.74" target="#b36">[37,</ref><ref type="bibr" coords="4,444.04,621.25,7.75,8.74" target="#b5">6]</ref> to extract uncertain knowledge in a classification problem. Fuzzy set theory is used to model the tree structure. Thus, our proposed approach is based on a fuzzy ontology that handles such a decision tree. In what follows, we discuss the struc-ture of our fuzzy ontology, we show how we populate its content, and how to infer available knowledge in order to use the hierarchical classifiers to annotate a test image accurately.</p><p>Ontology Structure The ontology structure is based on three conceptual classes : the semantic concept Concept, the hierarchical node Node, and the test image Image.</p><p>We define also a set of relationships between these conceptual classes (see table <ref type="table" coords="5,159.67,229.66,3.87,8.74" target="#tab_0">1</ref>). The relationship isChildOf depicts that a node node 1 ∈ Node is a child of another node node 2 ∈ Node. This relationship is used then for modeling the semantic hierarchy for concept classes.</p><p>The relationship existsIn enumerates for each node node ∈ Node the contained set of concept classes. A concept concept ∈ Concept can exists in many nodes, but for separate levels.</p><p>The relationship votesFor is used when an image image is being annotated and the hierarchy is walked from the root node to the leafs. A node node ∈ Node votes for an image image ∈ Image by a fuzzy weight p 2 when a Svm classification on that image predicts that the image image could annotated by the set of semantic concepts that exists in the node node.</p><p>Finally, the relationship isIndexedBy depicts that an image image ∈ Image is annotated by the concept concept ∈ Concept by a fuzzy weight equal to p 1 .</p><p>The proposed ontology structure is used to enable handling the hierarchical classifiers, to trace the hierarchy walk for classifying a given test image, and then to model the set of semantic concepts that annotate that image (see figure <ref type="figure" coords="5,457.01,633.20,3.87,8.74" target="#fig_1">3</ref>). In what follows, we expose the population process for our ontology, then, we discuss the reasoning process used to guide and assist the hierarchical annotation. At first, we apply a binary clustering for the whole concept set, and we define two new nodes in the ontology node 1 and node 2 . We use a k-means clustering algorithm with k = 2. Then, each concept is instantiated within the ontology, and for every concept concept that belongs to the node node, a new relationship existsIn is instantiated between concept and node. This process is recursively called on node 1 and node 2 until a sub-node contains only one semantic concept class, or the clustering process seems unable to cluster a given semantic concept classes. At each iteration, the new defined nodes are populated within the ontology through instantiating the isChildOf relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical classificators construction</head><p>Once the hierarchical structure is defined through the above mentioned recursive binary clustering, an Svm based classifier is trained for all the nodes that belong to the same level. As training images, we select some development images for every concept that belongs to a node. In section 2.2, we detail the development image dataset used for the training task.</p><p>At a given level, two possible nodes are figuring (see figure <ref type="figure" coords="6,409.73,561.09,3.87,8.74" target="#fig_2">4</ref>). By exploring existsIn relationships, we construct a training image dataset. For the first node (see node Root in figure <ref type="figure" coords="6,244.49,585.00,3.87,8.74" target="#fig_2">4</ref>), and for each concept that belongs to that node, a subset of images that are annotated by this concept are selected to be training images for corresponding node.</p><p>For a leaf node (see node Node1 in figure <ref type="figure" coords="6,350.02,621.25,3.87,8.74" target="#fig_2">4</ref>), we proceed as follow: let C m = {c 1 , c 2 , . . . , c k } be a set of k concepts that belongs to the node node m . We construct then k classifiers. Each classifier is related to a given concept and trained against the other concepts. Then, and for a classifier f of a concept For a leaf node that contain only one concept class (see node Node2 in figure <ref type="figure" coords="7,134.77,365.46,3.87,8.74" target="#fig_2">4</ref>), no Svm classifier will be constructed. And an image annotation for this concept will be computed through the leaf node classification vote.</p><p>Reasoning We start reasoning from the root node (top node) of the constructed fuzzy tree (see figure <ref type="figure" coords="7,229.34,418.01,3.87,8.74" target="#fig_1">3</ref>). For a given node, we compute the values of the membership functions (µ) for the child nodes through firing the corresponding Svm classifiers. The classification results (the vote) are populated into the fuzzy ontology through instantiating the votesFor relationship.</p><p>In order to improve reasoning accuracy and to minimize the decision tree walk (which will also minimize the number of Svm classifiers to be fired), we define a Fuzziness control threshold θ r = 0.1: given two sub-nodes node 1 and node 2 , firing the Svm classifier at this level provides two membership function values µ 1 for node 1 and µ 2 for node 2 . Then, we compute θ r = |µ 1 -µ 2 |.</p><p>if θ r ≤ 0.1, then we could not be sure if the Svm classifier is discriminative to judge if the content of a test image belongs to the first or to the second node. We proceed so to walk both sub-nodes (node 1 and node 2 ). For the opposite case (θ r &gt; 0.1), the reasoner walks only the node that has the greater membership function value (µ).</p><p>Given the example in figure <ref type="figure" coords="7,273.61,585.38,3.87,8.74" target="#fig_1">3</ref>, the Svm classifier of the node root computed µ 1 = 0.2 for the node N ode1, and µ 2 = 0.8 for the node N ode2. Then, the reasoning algorithm stops walking the node N ode1 and proceeds to walk the N ode2 since θ r = 0.8 -0.2 = 0.6 and 0.1 ≤ 0.6.</p><p>A leaf node can contain a set of concept classes, or only one concept class. In the first case, and for every contained concept class, an Svm classifier is fired for that concept against the other contained concept classes. The classification result is populated in the ontology through the instantiation of the relationship isIndexedBy between the concept class and the test image. The fuzzy weight for the new relationship is computed as an average of µ values computed from the root node to the leaf one. In case of a single concept class, a new isIndexedBy relationship is instantiated within the ontology between that concept and the test image. The fuzzy weight as in the first case.</p><p>Our proposed fuzzy decision tree reasoner assists the annotation of a given test image through firing recursive trained Svm classifiers in order to optimize the number of concept to be detected. Such an optimization should reduce also the computing cost of a given test image annotation process.</p><p>In the next section, we expose how we construct an Svm classifier for each node in the constructed fuzzy hierarchical semantic structure of concept classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Svm Classifier Construction</head><p>In our participation within ImageCLEF 2015 Scalable Concept Image Annotation task, we aimed basically to evaluate the scalability aspect of our preliminary automatic annotation framework. For semantic concept detector/annotator, we have not really defined an original approach, but we implemented state-of-the-art bags of quantized local features and linear classifiers learned by support vector machines. In fact, and as pointed in <ref type="bibr" coords="8,290.48,359.66,14.61,8.74" target="#b27">[28]</ref>, bag-of-features and codebook approach has gained a great attention by image classification and annotation community as it showed notable semantic accuracy <ref type="bibr" coords="8,305.67,383.57,15.50,8.74" target="#b25">[26,</ref><ref type="bibr" coords="8,322.83,383.57,12.73,8.74" target="#b16">17,</ref><ref type="bibr" coords="8,337.22,383.57,7.01,8.74" target="#b8">9]</ref>. In what follow, we expose how we construct Svm classifiers for semantic concept detection and annotation.</p><p>Construct a learning dataset Image annotation has always been heavily dependent to good development datasets. First, datasets were mainly handcollected. However, and recently, several researches attempt to automate such a laborious task. Re-ranking images gathered from popular Image search engines (Google, Yahoo!, Bing, . . . ) can construct automatically an image learning dataset <ref type="bibr" coords="8,169.69,484.48,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="8,186.85,484.48,12.73,8.74" target="#b12">13,</ref><ref type="bibr" coords="8,201.24,484.48,11.62,8.74" target="#b30">31]</ref>.</p><p>As a development dataset, we have not used one provided by the ImageCLEF 2015 Scalable Concept Image Annotation task. In fact, not all the concepts were annotated. We relied then on Flickr image search engine to obtain image set and construct a learning dataset. We used so the information provided with concept list to query the search engine and we gathered first 100 result images for each given concept.</p><p>At the outset, it seems to be curious to use an external data source as a development dataset. Our aim is to explore available on-line data-sources (like search engines) to train non annotated semantic concepts.</p><p>Local Feature Extraction Our framework extracts features from an input image through a robust local feature extractor. We followed a basic and stateof-the-art framework for such purpose (as described in <ref type="bibr" coords="8,384.80,645.16,14.76,8.74" target="#b27">[28]</ref>). Leading extractors for such a purpose includes Scale Invariant Feature Transform (Sift) and Speeded Up Robust Features (Surf). Local feature descriptors handle a pixel within an image by analyzing its neighborhood pixels. Many different descriptors and interest-point detectors were proposed and discussed in the literature. While the Sift descriptor <ref type="bibr" coords="9,250.52,155.86,15.50,8.74" target="#b22">[23]</ref> is considered as the most widely used descriptor, Surf <ref type="bibr" coords="9,161.58,167.81,10.52,8.74" target="#b2">[3]</ref> is known as robust local feature extraction to various image perturbations.</p><p>Our framework extracts local features and descriptors using Surf. Such a choice is argued by Surf concise descriptor length (64 floating point values). The Surf implementation that we used is provided by OpenCv <ref type="bibr" coords="9,420.21,215.89,9.96,8.74" target="#b4">[5]</ref>.</p><p>For query image analysis, local features are extracted and mapped into nearest computed cluster centroids. The query image is then handled by a vector that represents defined visual bag-of-words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification of local Features and Contructing the bag-of-words model</head><p>After extracting local features, a bag-of-words model is used to represent these descriptors. The latter are extracted from training images and are grouped into N clusters of visual words using k-means. Each defined descriptor is classified into its cluster centroid by computing the Euclidean distance metric. For our runs, we choose a value of N = 100. This value is argued by a balance between high bias (under-fitting) and high variance (over-fitting).</p><p>In order to alleviate the computing cost of k-means clustering, we used Mini Batch k-means <ref type="bibr" coords="9,204.76,379.07,15.50,8.74" target="#b31">[32]</ref> as an alternative to the k-means algorithm for clustering massive datasets. Mini Batch k-means reduces the computational cost by handling fixed size subsample instead of all the data in the database. This strategy reduces the amount of distance to be computed at each clustering iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning Algorithm</head><p>The learning algorithm consists in training one-vs.one linear Svm to operate in the bag of Surf feature space. Training images are classified through a histogram vector conctructed in the k-means based clustering. We used a linear kernel for our Svm based learning algorithm in view of its simplicity and computational efficiency in training and classification: K(x, y) = x T y + c.</p><p>Basically, Svm are binary classifier. For a given detector, an image is annotated by one of two distinct groups. A one-vs.-one scheme is used in which each Svm trained for each combination of individual classes. The Svm implementation used in our runs is given by Scikit-Learn library <ref type="bibr" coords="9,359.43,553.96,14.61,8.74" target="#b26">[27]</ref>.</p><p>Decision As an Svm decision function, a class membership probability estimation fits the decision values.</p><p>Scikit-Learn library uses a Platt Scaling in order to calibrate the Svm classifier to produce, in addition to class predictions, probabilities. When the Svm is trained, an optimization process is called to optimize parameter vectors A and B such that : P (y|X) = 1/(1 + exp(A * f (X) + B)) where f (X) is the signed distance of a sample from the hyperplane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Object Localization</head><p>Our developed framework does not handle yet concept localization. As future work, we are motivated to use state-of-the-art based techniques (such as <ref type="bibr" coords="10,444.06,149.81,15.50,8.74" target="#b20">[21,</ref><ref type="bibr" coords="10,461.22,149.81,11.62,8.74" target="#b19">20]</ref>). In our submitted runs, we considered the whole image content as a localization for all annotated concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submitted Runs</head><p>We submitted two runs, where the only difference is the value of the threshold weight for all computed annotation:</p><p>-Run 1 (regimvid at imageclef2015 task1 ): In this run, we considered all the annotation weights performed by our annotation framework. -Run 2 (regimvid at imageclef2015 task1 0.7 ): In this run, we considered only annotation weights that are greater or equal to 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>We would like to notice that we annotated only 300 000 images of the 500 000 images provided in the test dataset. And, since many test images were not accessible on-line, we extracted features from the provided image thumbnails<ref type="foot" coords="10,449.38,375.91,3.97,6.12" target="#foot_0">1</ref> (with low resolutions). Due to these facts, our runs haven't reached an advanced position compared to the other runs (see tables 2 and 3). Furthermore, our system used a state-of-the-art based Svm classifier. We think that a complete image annotation on real (full size) images with more tweaked Svm classifiers should give better results. Furthermore, fuzzy ontology based semantic enhancement (described in <ref type="bibr" coords="10,194.34,449.22,15.50,8.74" target="#b37">[38]</ref>) should also enhance our framework annotation accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Runtime</head><p>Training process: Training the Svm classifiers task elapsed about 4 days (we used 100 learning images per a concept). This task was executed on a moderm machine (Intel i5 processor with 16 GB RAM memory). Annotation process: The annotation task was done on 10 Vps machines (each one has one core CPU and 1 GB of RAM). The annotation of 300 000 images elapsed about 1 633 hours (without taking into consideration the Vps parallel computing).</p><p>Our framework annotates a test image with an average of 19.615 seconds (the maximum record was 597.250 seconds and the minimum one was 0.066 second).</p><p>And for a given test image, an average of 52 Svm classifiers were fired (the maximum was 175 and the minimum was 6). Our framework has reduced the number of Svm classifiers to be fired in order to annotate a given test image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this working note, we described our annotation framework for the ImageCLEF 2015 Scalable Concept Image Annotation task. We discussed our ontology based framework for reducing the number of concepts to be detected for a given image. We developed a state-of-the art bag-of-words based concept detector (that uses Surf feature extractor and k-means classification). Then, concept detectors are selected through reasoning with a fuzzy ontology content. Thus, not all the concept detectors are used for a given image.</p><p>In our experiment, we showed how the use of such a method could reduce the number of concept detectors to be used in order to efficiently annotate a largescale image dataset. While the obtained results were not really impressive, we still believe that our framework can reveal better results through tweaking local feature extraction and training, and exploiting semantic enhancement through fuzzy reasoning. Thus, we are considering potential future directions to further improve our proposed framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,156.81,503.39,301.73,7.89;3,136.00,271.27,343.35,217.35"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Ontology based semantic annotator hierarchy for image annotation</figDesc><graphic coords="3,136.00,271.27,343.35,217.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,195.97,290.81,223.41,7.89;6,134.77,116.83,348.87,159.21"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Ontology based hierarchical image classification</figDesc><graphic coords="6,134.77,116.83,348.87,159.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,205.05,285.16,205.27,7.89;7,144.55,116.83,326.25,153.56"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Hierarchical SVM classificator construction</figDesc><graphic coords="7,144.55,116.83,326.25,153.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="4,147.70,404.61,319.95,167.85"><head></head><label></label><figDesc></figDesc><graphic coords="4,147.70,404.61,319.95,167.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,136.16,264.40,356.90,152.80"><head>Table 1 .</head><label>1</label><figDesc>Semantic Relationships between conceptual classes</figDesc><table coords="5,136.16,285.17,62.30,7.89"><row><cell>Relationships</cell></row></table><note coords="5,251.89,285.17,46.01,7.89;5,351.32,285.17,40.12,7.89;5,144.54,298.45,348.52,7.96;5,351.33,309.41,141.73,7.96;5,351.33,320.46,37.46,7.86;5,151.08,331.72,32.34,7.96;5,213.45,331.72,122.40,7.96;5,351.33,331.72,141.73,8.46;5,351.33,342.68,141.74,7.96;5,351.33,353.74,37.46,7.86;5,153.18,365.00,28.27,7.96;5,211.29,365.00,281.77,7.96;5,351.33,375.96,105.31,7.96;5,149.41,387.31,35.17,7.96;5,223.70,387.31,102.39,7.96;5,351.33,387.31,141.73,7.96;5,351.33,398.37,141.73,7.86;5,351.33,409.23,20.24,7.96"><p>Definition Meaning isIndexedBy ( Image, Concept : isIndexedBy) ≥ p1 The image Image is annotated by the concept Concept by a fuzzy weight p1 votesFor ( Node, Image : votesFor) ≥ p2 The Svm for the node Node votes for the image image by a fuzzy weight p2 existsIn ( Concept, Node : existsIn) ≥ p3 The image image exists in the node Node by a fuzzy weight p3 isChildOf ( Node, Node : isChildOf) The first node Node has a semantic concept subset of the second node Node</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,148.24,480.24,318.88,74.89"><head>Table 2 .</head><label>2</label><figDesc>MAP 0 Overlap Runs evaluation</figDesc><table coords="10,148.24,501.01,318.88,54.12"><row><cell></cell><cell>MAP</cell></row><row><cell>Best run</cell><cell>0, 795403 (/SMIVA/21.run)</cell></row><row><cell>Worst run</cell><cell>0, 0305398 (/REGIM/regimvid at imageclef2015 task1 0.7.txt)</cell></row><row><cell>Average</cell><cell>0, 31046</cell></row><row><cell cols="2">Our best run 0, 0366072 (position 85/89)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,193.33,116.91,228.70,74.89"><head>Table 3 .</head><label>3</label><figDesc>MAP 0.5Overlap Runs evaluation</figDesc><table coords="11,193.33,137.68,228.70,54.12"><row><cell></cell><cell>MAP</cell><cell></cell></row><row><cell>Best run</cell><cell>0, 659507</cell><cell>(/SMIVA/21.run)</cell></row><row><cell>Worst run</cell><cell cols="2">0, 000231898 (/MLVISP6/run blur1.txt)</cell></row><row><cell>Average</cell><cell>0, 18673</cell><cell></cell></row><row><cell cols="3">Our best run 0, 0161687 (position 75/89)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="10,144.73,657.79,234.78,8.12"><p>compressed in the webupv15 data visual images.zip file.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The authors would like to acknowledge the financial support of this work by grants from <rs type="funder">General Direction of Scientific Research (DGRST), Tunisia</rs>, under the <rs type="programName">ARUB program</rs>. The authors would like to acknowledge also the Image-CLEF2015 Organising Committee.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Vh3489U">
					<orgName type="program" subtype="full">ARUB program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,140.47,337.64,7.86;12,151.52,151.43,329.07,7.86;12,151.52,162.39,329.07,7.86;12,151.52,173.35,47.61,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,262.87,140.47,217.72,7.86;12,151.52,151.43,18.17,7.86">Hierarchical image annotation using semantic hierarchies</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bannour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,191.51,151.43,289.08,7.86;12,151.52,162.39,115.82,7.86;12,340.89,162.39,40.26,7.86">Proceedings of the 21st ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 21st ACM International Conference on Information and Knowledge Management<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2431" to="2434" />
		</imprint>
	</monogr>
	<note>CIKM &apos;12</note>
</biblStruct>

<biblStruct coords="12,142.96,183.69,337.64,7.86;12,151.52,194.65,314.71,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,260.06,183.69,220.53,7.86;12,151.52,194.65,98.97,7.86">Building and using fuzzy multimedia ontologies for semantic image annotation</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bannour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,257.76,194.65,142.43,7.86">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,204.98,337.63,7.86;12,151.52,215.94,329.07,7.86;12,151.52,226.90,187.97,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,339.65,204.98,137.28,7.86">Speeded-up robust features (surf)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,442.64,215.94,37.95,7.86;12,151.52,226.90,187.97,7.86">similarity Matching in Computer Vision and Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="346" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,237.24,337.63,7.86;12,151.52,248.20,329.07,7.86;12,151.52,259.16,329.07,7.86;12,151.52,270.12,122.39,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,233.72,248.20,246.88,7.86;12,151.52,259.16,65.10,7.86">A multimedia ir-based system for the photo annotation task at imageclef2013</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Benavent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>De Ves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hernández-Aranda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Granados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,237.67,259.16,170.10,7.86">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,280.45,337.63,7.86;12,151.52,291.41,64.58,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,273.05,280.45,117.10,7.86">Learning Opencv, 1st Edition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G R</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kaehler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
	<note>first edn.</note>
</biblStruct>

<biblStruct coords="12,142.96,301.75,337.64,7.86;12,151.52,312.71,329.07,7.86;12,151.52,323.67,329.07,7.86;12,151.52,334.62,329.07,7.86;12,151.52,345.58,183.02,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,318.94,301.75,161.65,7.86;12,151.52,312.71,33.16,7.86">Intuitionistic fuzzy decision tree: A new classifier</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bujnowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Szmidt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kacprzyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,439.88,323.67,40.71,7.86;12,151.52,334.62,250.54,7.86">Intelligent Systems&apos;2014, Advances in Intelligent Systems and Computing</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Angelov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Atanassov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Doukovska</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hadjiski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Jotsov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kacprzyk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Kasabov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sotirov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Szmidt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Zadrony</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="page" from="779" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,355.92,337.63,7.86;12,151.52,366.88,329.07,7.86;12,151.52,377.84,195.95,8.11" xml:id="b6">
	<analytic>
		<ptr target="http://ceur-ws.org/Vol-1391" />
	</analytic>
	<monogr>
		<title level="m" coord="12,391.74,355.92,88.85,7.86;12,151.52,366.88,41.81,7.86">CLEF 2015 Labs and Workshops</title>
		<title level="s" coord="12,201.31,366.88,67.87,7.86;12,322.36,366.88,152.69,7.86">CEUR Workshop Proceedings (CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>San Juan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">994</biblScope>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="12,142.96,388.18,337.64,7.86;12,151.52,399.13,329.07,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,210.00,388.18,270.59,7.86;12,151.52,399.13,99.21,7.86">New clustering algorithms for the support vector machine based hierarchical classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cevikalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,257.33,399.13,112.81,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1285" to="1291" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,409.47,337.63,7.86;12,151.52,420.43,329.07,7.86;12,151.52,431.39,70.14,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,311.38,409.47,169.21,7.86;12,151.52,420.43,201.81,7.86">A generic framework for semantic video indexing based on visual concepts/contexts detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elleuch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,359.68,420.43,94.96,7.86">Multimedia Tools Appl</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1397" to="1421" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,441.73,337.97,7.86;12,151.52,452.68,329.07,7.86;12,151.52,463.64,329.07,7.86;12,151.52,474.60,225.14,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,380.76,441.73,99.83,7.86;12,151.52,452.68,288.40,7.86">A fuzzy ontology: based framework for reasoning in visual video content analysis and indexing</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elleuch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,463.04,452.68,17.56,7.86;12,151.52,463.64,309.03,7.86;12,170.98,474.60,58.99,7.86">Proceedings of the Eleventh International Workshop on Multimedia Data Mining</title>
		<meeting>the Eleventh International Workshop on Multimedia Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note>MDMKDD &apos;11</note>
</biblStruct>

<biblStruct coords="12,142.62,484.94,337.98,7.86;12,151.52,495.90,329.07,7.86;12,151.52,506.86,267.12,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,417.73,484.94,62.86,7.86;12,151.52,495.90,141.93,7.86">REGIMVID at TRECVID2010: semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elleuch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,318.17,495.90,162.43,7.86;12,151.52,506.86,65.05,7.86">TRECVID 2010 workshop participants notebook papers</title>
		<meeting><address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-11">November 2010 (2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,517.19,337.98,7.86;12,151.52,528.15,329.07,7.86;12,151.52,539.11,329.07,7.86;12,151.52,550.07,25.60,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,337.42,517.19,143.18,7.86;12,151.52,528.15,219.03,7.86">Regimvid at imageclef2012: Improving diversity in personal photo ranking using fuzzy logic</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ksibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,389.57,528.15,91.02,7.86;12,151.52,539.11,176.00,7.86">CLEF 2012 Evaluation Labs and Workshop, Online Working Notes</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">September 17-20, 2012 (2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,560.41,337.97,7.86;12,151.52,571.37,329.07,7.86;12,151.52,582.33,256.78,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,353.06,560.41,127.53,7.86;12,151.52,571.37,84.69,7.86">Learning object categories from google&apos;s image search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,257.20,571.37,67.45,7.86;12,355.70,571.37,124.89,7.86;12,151.52,582.33,91.42,7.86">ICCV 2005. Tenth IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2005-10">2005. Oct 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1816" to="1823" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct coords="12,142.62,592.66,337.97,7.86;12,151.52,603.62,329.07,7.86;12,151.52,614.58,309.74,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,309.93,592.66,166.40,7.86">A visual category filter for google images</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,280.21,603.62,125.41,7.86">Computer Vision -ECCV 2004</title>
		<title level="s" coord="12,413.12,603.62,67.47,7.86;12,151.52,614.58,71.32,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3021</biblScope>
			<biblScope unit="page" from="242" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,624.92,337.97,7.86;12,151.52,635.88,329.07,7.86;12,151.52,646.84,329.07,7.86;12,151.52,657.79,47.61,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,238.53,624.92,242.06,7.86;12,151.52,635.88,69.80,7.86">Discriminative learning of relaxed hierarchy for large-scale visual recognition</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,242.76,635.88,237.83,7.86;12,151.52,646.84,48.00,7.86;12,267.86,646.84,36.81,7.86">Proceedings of the 2011 International Conference on Computer Vision</title>
		<meeting>the 2011 International Conference on Computer Vision<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2072" to="2079" />
		</imprint>
	</monogr>
	<note>ICCV &apos;11</note>
</biblStruct>

<biblStruct coords="13,142.62,120.67,337.98,7.86;13,151.52,131.63,329.07,7.86;13,151.52,142.59,329.07,7.86;13,151.52,153.55,324.61,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,234.94,131.63,245.65,7.86;13,151.52,142.59,170.54,7.86">Overview of the ImageCLEF 2015 Scalable Image Annotation, Localization and Sentence Generation task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,342.70,142.59,137.89,7.86;13,151.52,153.55,154.08,7.86">CLEF2015 Working Notes. CEUR Workshop Proceedings, CEUR-WS.org</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,165.30,337.97,7.86;13,151.52,176.26,329.07,7.86;13,151.52,187.22,329.07,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,463.06,165.30,17.53,7.86;13,151.52,176.26,230.35,7.86">MIL at imageclef 2014: Scalable system for image annotation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kanehira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hidaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Makuta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Tsuchiya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,404.86,176.26,75.74,7.86;13,151.52,187.22,91.32,7.86">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,198.97,337.98,7.86;13,151.52,209.93,329.07,7.86;13,151.52,220.89,294.58,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,282.27,198.97,198.32,7.86;13,151.52,209.93,102.41,7.86">A comparative study of multimedia retrieval using ontology for semantic web</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Aghila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,275.03,209.93,205.56,7.86;13,151.52,220.89,41.30,7.86;13,222.55,220.89,99.63,7.86">Advances in Engineering, Science and Management (ICAESM)</title>
		<imprint>
			<date type="published" when="2012-03">2012. March 2012</date>
			<biblScope unit="page" from="400" to="405" />
		</imprint>
	</monogr>
	<note>International Conference</note>
</biblStruct>

<biblStruct coords="13,142.62,232.64,337.97,7.86;13,151.52,243.60,329.07,7.86;13,151.52,254.55,242.99,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,408.48,232.64,72.11,7.86;13,151.52,243.60,186.54,7.86">Regimrobvid: Objects and scenes detection for robot vision 2013</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ksibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,358.69,243.60,121.91,7.86;13,151.52,254.55,44.32,7.86">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,266.31,337.98,7.86;13,151.52,277.27,329.07,7.86;13,151.52,288.22,275.46,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,335.18,266.31,145.41,7.86;13,151.52,277.27,158.26,7.86">Beyond sliding windows: Object localization by efficient subwindow search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,330.48,277.27,150.12,7.86;13,151.52,288.22,22.38,7.86;13,204.77,288.22,123.28,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008-06">2008. June 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference</note>
</biblStruct>

<biblStruct coords="13,142.62,299.98,337.98,7.86;13,151.52,310.93,329.07,7.86;13,151.52,321.89,329.07,7.86;13,151.52,332.85,25.60,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,307.33,299.98,173.27,7.86;13,151.52,310.93,192.32,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.91,310.93,117.68,7.86;13,151.52,321.89,46.11,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,344.60,337.98,7.86;13,151.52,355.56,329.07,7.86;13,151.52,366.52,196.11,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,351.52,344.60,129.08,7.86;13,151.52,355.56,79.69,7.86">Building and using a semantivisual image hierarchy</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,251.28,355.56,203.12,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2010-06">2010. June 2010</date>
			<biblScope unit="page" from="3336" to="3343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,378.27,337.98,7.86;13,151.52,389.23,198.86,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,193.30,378.27,227.75,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,428.35,378.27,52.25,7.86;13,151.52,389.23,112.86,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,400.98,337.98,7.86;13,151.52,411.94,329.07,7.86;13,151.52,422.90,37.89,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,424.54,400.98,56.06,7.86;13,151.52,411.94,202.70,7.86">A hierarchical classification approach to automated essay scoring</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Crossley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">K</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,361.39,411.94,71.88,7.86">Assessing Writing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="35" to="59" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,434.65,337.97,7.86;13,151.52,445.61,329.07,7.86;13,151.52,456.57,60.47,7.86" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="13,344.06,434.65,136.53,7.86;13,151.52,445.61,145.14,7.86">ImageCLEF: Experimental Evaluation in Visual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
	<note>1st edn.</note>
</biblStruct>

<biblStruct coords="13,142.62,468.32,337.97,7.86;13,151.52,479.28,329.07,7.86;13,151.52,490.24,100.34,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="13,362.26,468.32,118.33,7.86;13,151.52,479.28,191.13,7.86">Using visual context and region semantics for high-level concept detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mylonas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Spyrou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kollias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,350.56,479.28,130.03,7.86;13,151.52,490.24,9.73,7.86">Multimedia, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="243" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,501.99,337.98,7.86;13,151.52,512.95,329.07,7.86;13,151.52,523.91,329.07,7.86;13,151.52,534.87,324.48,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="13,394.26,523.91,86.33,7.86;13,151.52,534.87,73.64,7.86">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,232.82,534.87,155.11,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,546.62,337.98,7.86;13,151.52,557.58,329.07,7.86;13,151.52,568.54,329.07,7.86;13,151.52,579.50,130.50,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="13,250.16,546.62,230.43,7.86;13,151.52,557.58,38.27,7.86">Open issues on codebook generation in image classification tasks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Giacinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,211.26,557.58,269.33,7.86;13,151.52,568.54,155.84,7.86">Machine Learning and Data Mining in Pattern Recognition -10th International Conference, MLDM 2014</title>
		<meeting><address><addrLine>St. Petersburg, Russia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">July 21-24, 2014. 2014</date>
			<biblScope unit="page" from="328" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,591.25,337.98,7.86;13,151.52,602.21,329.07,7.86;13,151.52,613.17,329.07,7.86;13,151.52,624.12,42.49,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,303.72,591.25,176.87,7.86;13,151.52,602.21,273.55,7.86">KDEVIR at imageclef 2014 scalable concept image annotation task: Ontology based automatic image annotation</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">A</forename><surname>Reshma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Z</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,446.52,602.21,34.07,7.86;13,151.52,613.17,131.75,7.86">Working Notes for CLEF 2014 Conference</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">September 15-18, 2014. 2014</date>
			<biblScope unit="page" from="386" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,635.88,337.97,7.86;13,151.52,646.84,329.07,7.86;13,151.52,657.79,329.07,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="13,194.01,635.88,286.57,7.86;13,151.52,646.84,273.29,7.86">CNRS -TELECOM paristech at imageclef 2013 scalable concept image annotation task: Winning annotations with context dependent svms</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,446.53,646.84,34.06,7.86;13,151.52,657.79,132.43,7.86">Working Notes for CLEF 2013 Conference</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">September 23-26, 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,120.67,337.97,7.86;14,151.52,131.63,329.07,7.86;14,151.52,142.59,25.60,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="14,313.44,120.67,162.60,7.86">Harvesting image databases from the web</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,151.52,131.63,266.24,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="754" to="766" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,153.55,337.97,7.86;14,151.52,164.51,329.07,7.86;14,151.52,175.46,47.61,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="14,198.41,153.55,115.36,7.86">Web-scale k-means clustering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,333.08,153.55,147.51,7.86;14,151.52,164.51,124.91,7.86;14,345.63,164.51,41.58,7.86">Proceedings of the 19th International Conference on World Wide Web</title>
		<meeting>the 19th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1177" to="1178" />
		</imprint>
	</monogr>
	<note>WWW &apos;10</note>
</biblStruct>

<biblStruct coords="14,142.62,186.42,337.97,7.86;14,151.52,197.38,214.25,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="14,280.13,186.42,122.49,7.86">Concept-based video retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,411.30,186.42,69.29,7.86;14,151.52,197.38,128.24,7.86">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="215" to="322" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,208.34,337.97,7.86;14,151.52,219.30,329.07,7.86;14,151.52,230.26,329.07,7.86;14,151.52,241.22,329.07,7.86;14,151.52,252.18,126.65,7.86" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="14,398.63,230.26,81.96,7.86;14,151.52,241.22,142.90,7.86">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar Roldán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="14,301.24,241.22,139.07,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,263.14,337.98,7.86;14,151.52,274.09,329.07,7.86;14,151.52,285.05,51.50,7.86" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="14,258.20,263.14,222.39,7.86;14,151.52,274.09,62.05,7.86">Overview of the imageclef 2014 scalable concept image annotation task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,234.68,274.09,245.91,7.86;14,151.52,285.05,22.84,7.86">CLEF 2014 Evaluation Labs and Workshop, Online Working Notes</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,296.01,337.98,7.86;14,151.52,306.97,329.07,7.86;14,151.52,317.93,185.92,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="14,315.61,296.01,164.99,7.86;14,151.52,306.97,133.93,7.86">Overview of the imageclef 2013 scalable concept image annotation subtask</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thomee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,305.36,306.97,175.23,7.86;14,151.52,317.93,87.99,7.86">CLEF 2013 Evaluation Labs and Workshop, Online Working Notes</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,328.89,337.98,7.86;14,151.52,339.85,135.29,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="14,323.49,328.89,120.55,7.86">Fuzzy rule based decision trees</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,449.98,328.89,30.62,7.86;14,151.52,339.85,47.75,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="59" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,350.81,337.97,7.86;14,151.52,361.77,329.07,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="14,319.04,350.81,161.55,7.86;14,151.52,361.77,116.10,7.86">Fuzzy reasoning framework to improve semantic video interpretation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,274.22,361.77,141.38,7.86">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,372.73,337.98,7.86;14,151.52,383.68,204.74,7.86" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="14,288.45,372.73,192.14,7.86;14,151.52,383.68,23.96,7.86">A review on automatic image annotation techniques</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,182.55,383.68,65.55,7.86">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="346" to="362" />
			<date type="published" when="2012-01">Jan 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
