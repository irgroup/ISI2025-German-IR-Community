<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.86,77.31,413.58,12.64;1,221.33,95.31,152.81,12.64">Clustering of Medical X-ray Images by Merging Outputs of Different Classification Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,181.82,134.82,66.30,8.96"><forename type="first">Ibrahim</forename><surname>Zeiadan</surname></persName>
							<email>ieziedan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Professor, Computers and Systems Engineering Department</orgName>
								<orgName type="institution">Zagazig University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.01,134.82,48.81,8.96"><forename type="first">Amr</forename><surname>Zamel</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Teaching Assistance, Computers and Systems Engineering Department</orgName>
								<orgName type="institution">Zagazig University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.07,134.82,77.06,8.96"><forename type="first">Ahmed</forename><surname>Al Zohairy</surname></persName>
							<email>alzohairy@yahoo.com</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Genetics Department</orgName>
								<orgName type="department" key="dep2">Faculty of Agriculture</orgName>
								<orgName type="institution">Zagazig University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.86,77.31,413.58,12.64;1,221.33,95.31,152.81,12.64">Clustering of Medical X-ray Images by Merging Outputs of Different Classification Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">82FB2D47B5649115A69E8A8E7E6B7005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>classification</term>
					<term>image processing</term>
					<term>x-ray</term>
					<term>neural network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clustering x-ray images is a complex task, due to the great variations within each class including orientation, alignment and deformation. In this paper, an automatic medical x-ray image clustering is developed by merging the outputs from five different neural networks classifiers. Each classifier employs a set of features derived through different feature-extraction techniques. Such techniques are based on (i) pixel-value, (ii) local binary patterns, (iii) global means of rows and columns, (iv) local means of rows and columns, and (v) local histogram. A test accuracy of 86.2 % was achieved from merged output of the five NN classifiers using the ImageCLEF 2015 database. A somewhat higher accuracy of 87.2% was obtained when merging outputs of only three classifiers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The problem of x-ray image classification is gaining a growing interest of many researchers now-adays. In recent years medical images have increased and so demands for indexing, storing and analyzing such images have also increased. The problem of automatic medical image clustering involves mainly three steps, preprocessing, feature extraction and a classification technique. The key point in the clustering task is classifier features. Features are mainly generated from two levels (i) low-level representation and (ii) patch based image representation <ref type="bibr" coords="1,303.89,528.83,16.89,8.96">[ref]</ref>. Low-level image representation is such as edge histogram, local binary patterns, SIFT histogram, Gray Level Co-occurrence Matrix (GLCM), and Canny edge operator. The local binary patterns (LBP) have been used by several researchers in various domains <ref type="bibr" coords="1,126.86,564.86,11.01,8.96" target="#b0">[1,</ref><ref type="bibr" coords="1,137.87,564.86,7.34,8.96" target="#b1">2,</ref><ref type="bibr" coords="1,145.22,564.86,7.34,8.96" target="#b2">3]</ref>. Combination of block based local binary patterns with edge histogram was used as a medical image representation for the task of automatic medical image annotation in ImageCLEF 2007 <ref type="bibr" coords="1,90.02,588.86,10.68,8.96" target="#b3">[4]</ref>.</p><p>Local patch-based image representation has been developed for use in feature extraction by M. Zare et al. <ref type="bibr" coords="1,113.66,612.86,10.69,8.96" target="#b4">[5]</ref>. A local feature is obtained by dividing the image into sub images (regions or partitions) or selecting interesting points from the image. Bag of words (BoW) is one of the intersection point techniques used to represent images using histograms of quantized appearances of local patches <ref type="bibr" coords="1,459.22,636.86,10.69,8.96" target="#b5">[6]</ref>.</p><p>Merging neural network-classifiers' outputs obtained by using different features extracted through different extraction techniques is proposed in this paper. The paper is organized as follows. In section 2, preprocessing techniques are used to improve x-ray images and remove the noise. Section 3, presents the different feature-extraction techniques generated from the image. In section 4, a clustering frame work using a merging technique of different classifiers is described. Section 5, test results and test accuracy are presented. Section 6, presents conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing</head><p>X-ray images are usually given with different resolutions and usually contain some boundary and image noise. Image enhancement methods are needed to adjust digital images so that they are more suitable for display or further analysis. Such enhancement includes resizing and removing the boundary or image noise as well as enhancement of the contrast or image intensity. However the image is resized to 512 x 512 pixels after converting it into gray-level one.</p><p>Histogram equalization, as one of image enhancement techniques, is applied to improve the quality of the image as well as its contrast <ref type="bibr" coords="2,231.17,173.82,10.69,8.96" target="#b6">[7]</ref>. Such contrast adjustment provides better gray intensity distribution.</p><p>Generally noise in an image may follow three possibilities a Gaussian distribution, Poisson distribution or a combination of both. To remove such noise, two types of filters, namely linear and median filter may be used <ref type="bibr" coords="2,166.22,221.82,11.72,8.96" target="#b6">[7]</ref> .Median filtering <ref type="bibr" coords="2,252.05,221.82,11.72,8.96" target="#b7">[8]</ref> is similar to an averaging filter, in which each output pixel is set to an average of the pixel values in the neighborhood of the corresponding input pixel. However, with median filtering, the value of an output pixel is determined by the median of the neighborhood pixels, rather than the mean. The median is less sensitive than the mean to extreme values (called outliers). Median filtering is therefore better at removing these outliers without reducing the sharpness of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Extraction</head><p>This section describes the features that may be obtained from x-ray images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pixel Level (Value)</head><p>Pixel value is the simplest form of image representation techniques. It carries only intensity information. The intensity of a gray image pixel is expressed within a given range between a minimum and a maximum, inclusive. This range is represented in an abstract way as a range from 0 (total absence, black) and 1 (total presence, white), with any fractional values in between <ref type="bibr" coords="2,388.27,460.91,10.69,8.96" target="#b8">[9]</ref>.</p><p>The size of the image is scaled down to (32*32) pixels to reduce the number of features. The feature vector of pixel intensity value is then obtained as a single column of size 1024 elements for each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Local Binary Patterns</head><p>Local-binary patterns extract the texture in the gray image <ref type="bibr" coords="2,341.11,546.83,15.53,8.96" target="#b9">[10]</ref>. Normally, LBP labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number that is converted to decimal value. Firstly, the image is divided into non-overlapping square image blocks with the same size of neighbor set. Secondly, the square image is converted into binary by finding the center pixel value and using it as a threshold. If the value of a neighborhood is greater than the threshold it is represented by a one otherwise it is represented by a zero. Thirdly, the decimal value for each square block in the image is calculated. Finally, the binary pattern distribution for each square block included in the image can be represented as a histogram having 59 bins. To reduce the effect of position variation a local binary pattern at different sub levels (L0, L1, L2) from the image is obtained <ref type="bibr" coords="2,117.50,654.86,16.88,8.96">[ref]</ref>, The levels of LBP is obtained by dividing the image into 2x2 or 4x4 non-overlapping regions for levels L1 and L2. Level L0 is obtained for the whole image. The final LBP features are generated by combining local histogram features. Since there are 21 sub regions (whole image, 2x2 sub image, 4x4 sub images) a total of 59×21= 1239 histogram bins are generated for the feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global Means of Rows and Columns</head><p>The image is represented as a matrix of pixel intensity values, so we can calculate some statistical properties such as the mean of rows and columns. The mean value for the pixel intensity of each row and column is calculated and then combined to form a feature vector of the global image. So, the final length of the global feature vector is the number of rows plus the number of columns. Since the image size is 512 x 512 a total of 1024 value (feature) is generated for the global means-feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Local Means of Rows and Columns</head><p>Local features are more robust to occlusion and clutter. An average per region technique was used in face recognition task and produced high accuracy rate <ref type="bibr" coords="3,310.97,216.78,15.45,8.96" target="#b10">[11]</ref>. Therefore, the image was divided into 4×4 non-overlapping sub-images and then for each sub-image the mean value of each row and each column was obtained. A final mean feature vector is generated by combining the mean of each row and column of each sub image. Since the image size is 512x512 pixels, each sub image size is 128 x128. The mean feature vector length of each sub image is 128+128 = 256. The final local-mean feature vector of the whole image is 16x256 = 4096.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Local Histogram</head><p>As is well-known a histogram measures the distribution of intensity level in gray images. Image histogram features were used for face recognition based on minimum distance between a test image and a gallery of database of images <ref type="bibr" coords="3,210.29,350.85,15.43,8.96" target="#b11">[12]</ref>. Local features are extracted from small sub-images that are generated by partitioning the original image into a number of segments. In this paper, the gray level of the image is divided into 30 pins. Local histograms are obtained for the x-ray 4x4 non-overlapping subimages. Final histogram features vector was generated by combining features of each sub-image. Since there are 16 sub-images, a total of 30×16=480 feature vector elements are generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Image Clustering Framework</head><p>Clustering x-ray images is a complex task, due to the great variations within each class including orientation, alignment and deformation. In this paper, the image clustering framework is consisting of three different phases namely feature extraction, training neural network (NN) classifiers, and a merging technique as shown in Fig. <ref type="figure" coords="3,212.00,503.87,3.93,8.96">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Image clustering framework</head><p>In the first phase, features are extracted from the preprocessed images as mentioned before (section 3). Pixel level and local binary patterns, global means of rows and columns, local means of rows and column, and local histogram are the basic means of feature extraction in this work, and a feature vector is derived for each.</p><p>In the second phase, a NN is developed for each feature vector. Each neural network consists of two hidden layers and five outputs for the five clusters. The number of inputs for each network equals the number of elements of its corresponding feature vector as derived in section 3.</p><p>In the third phase, the outputs from five NN's are merged to get the final output. The merging processing is done in four steps. Step 1, Normalize the output of each classifier by dividing each output by the total sum from the classifier outputs. Step 2, a weighted sum of the outputs from different classifiers constitutes the merging operation. The weight of each classifier is taken equal to the accuracy obtained from it. The accuracy may be defined as follows.</p><formula xml:id="formula_0" coords="4,210.65,236.41,268.69,17.91">𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 = 𝑇𝐶 𝑇𝐶 + 𝐹𝐶 (1)</formula><p>Where, TC is the number of true classifications. FC is the number of false classifications. TC + FC is the total number of the test images. It is should be noted that a true classification means a test image belongs to only its cluster. Step 3, the final outputs are normalized by dividing each output by the total sum. Step 4, the final clustering of the test image is obtained by selecting the group that has the maximum value in the merged outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>In this section, a set of five classifiers is developed, one for each feature vector using a neural network. The database used in this research work is the ImageCLEF 2015 <ref type="bibr" coords="4,382.15,392.73,16.09,8.96" target="#b12">[13,</ref><ref type="bibr" coords="4,398.24,392.73,12.07,8.96" target="#b13">14,</ref><ref type="bibr" coords="4,410.31,392.73,12.07,8.96" target="#b14">15]</ref>. This database contains 500 x-ray images belonging to five main groups (Body, Head-Neck, Lower Limb, Upper Limb, and True Negative). Each group has 100 images. 25 % of the 500 images were randomly selected and used in the testing phase. The remaining 75% are used in the training phase of NN's. After training, the accuracy of each classifier is calculated first and then used as a weight in the merging process as mention before (section 4). Each NN consists of two hidden layers of size 200 and 100 neurons. These were selected after trying different numbers of hidden layer neurons.</p><p>Testing was carried out using 25 images from each group first and then it was performed for the 125 testing images. Results are shown in table <ref type="table" coords="4,266.55,488.75,4.98,8.96" target="#tab_0">1</ref> where the accuracy of each NN classifiers is listed. The pixel-value classifier shows a total accuracy of 79.2% with a highest accuracy of 92% for the true negative cluster and a lowest one of 64% for the upper limb cluster. The LBP classifier gives 80% as a total accuracy and 84% for the Body and Head-Neck clusters and a lower accuracy rate of 76% for the upper-limb and lower-limb. The global means of rows and columns classifier shows a higher total accuracy of 83.2% with a highest accuracy of 96% for the true negative cluster and a lowest one of 60% for the lower-limb cluster. The local means classifier shows a higher accuracy rate for the true-negative and body clusters of 88% and a lower accuracy rate for the lower limb of 52% with a total accuracy of 70.4%. The local histogram classifier gives a total accuracy of 71.2% and shows a higher accuracy rate of 88% for the body cluster and a lower one of 48% for the lower-limb cluster.</p><p>Merged outputs from different classifiers are then used to improve the overall accuracy. The weight of each classifier is equal to its accuracy. Two experiments were performed in this respect.</p><p>First, merging all classifier outputs gave a total accuracy of 86.4%. A higher accuracy of 92% was obtained in three cluster and a lower accuracy of 72% occurred in the lower-limb cluster. This merged classifier was submitted to the "Medical Clustering task of ImageCLEF 2015" <ref type="bibr" coords="4,412.51,656.78,15.43,8.96" target="#b13">[14]</ref>. In this task result was the tenth among the 29 participating groups with a total accuracy of 78% and hamming similarity of 86.8% for 250 test images.</p><p>Second, merging the first three higher accuracy classifiers (pixel level, LBP and Global mean of rows and columns) raised the total accuracy to 87.2% .obviously this is due to the increase in the accuracy of the true negative cluster (96%).  The proposed approach can be easily extended with new feature extraction methods, and can thus be applied to other domains. The proposed approach for merged classifier outputs can be easily applied to arbitrary domains with different feature extraction techniques with different sizes. Also, matching techniques may be employed for classification other than using NN.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,411.67,338.85,93.64,8.96;2,90.02,350.75,415.34,9.06;2,90.02,362.85,415.08,8.96;2,90.02,374.85,158.97,8.96"><head></head><label></label><figDesc>Features from different feature-extraction techniques are used to train different classifiers. Such techniques are namely pixelvalue of the gray image, Local Binary Patterns (LBP), local and global means of pixel value of the rows and columns, and local histogram.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,90.02,303.73,6.00,10.80;5,118.34,303.73,147.81,10.80;5,101.42,329.37,403.71,8.96;5,90.02,341.37,415.27,8.96;5,90.02,353.37,415.35,8.96;5,90.02,365.37,415.26,8.96;5,90.02,377.37,415.35,8.96;5,90.02,389.37,415.09,8.96;5,90.02,401.39,415.29,8.96;5,90.02,413.39,128.66,8.96"><head>6</head><label></label><figDesc>Conclusion and Future work In this paper an automatic medical x-ray images clustering system was developed by merging the outputs from different neural-network classifiers with different feature extraction techniques. These techniques are based on pixel-value, local binary pattern, global means of rows and columns, localpartition means of rows and columns, and local histogram features. Merged outputs from different classifiers show improvement in overall accuracy than individual classifiers. The best individual classifier is the global means of rows and columns classifier with 83.2% accuracy rate. The merged outputs from the five classifiers gave an accuracy of 86.2 %. The merged outputs from the top three classifiers produced an accuracy of 87.2%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,102.85,525.00,415.27,211.99"><head></head><label></label><figDesc></figDesc><graphic coords="3,102.85,525.00,415.27,211.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,113.30,74.61,366.24,182.24"><head>Table 1 .</head><label>1</label><figDesc>Accuracy of each NN classifiers</figDesc><table coords="5,113.30,92.34,366.24,164.51"><row><cell></cell><cell>Body</cell><cell>Head-</cell><cell>Upper-</cell><cell>Lower-</cell><cell>True-</cell><cell>accuracy</cell></row><row><cell></cell><cell></cell><cell>Neck</cell><cell>Limb</cell><cell>Limb</cell><cell>Negative</cell><cell></cell></row><row><cell>Pixel Value classifier</cell><cell>80%</cell><cell>80%</cell><cell>80%</cell><cell>64%</cell><cell>92%</cell><cell>79.2%</cell></row><row><cell>LBP classifier</cell><cell>84%</cell><cell>84%</cell><cell>76%</cell><cell>76%</cell><cell>80%</cell><cell>80%</cell></row><row><cell cols="2">Global mean classifier 80%</cell><cell>92%</cell><cell>88%</cell><cell>60%</cell><cell>96%</cell><cell>83.2%</cell></row><row><cell>Local mean classifier</cell><cell>88%</cell><cell>68%</cell><cell>56%</cell><cell>52%</cell><cell>88%</cell><cell>70.4%</cell></row><row><cell>Local histogram</cell><cell>88%</cell><cell>84%</cell><cell>72%</cell><cell>48%</cell><cell>64%</cell><cell>71.2%</cell></row><row><cell>classifier</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Merged the five</cell><cell>92%</cell><cell>92%</cell><cell>84%</cell><cell>72%</cell><cell>92%</cell><cell>86.4%</cell></row><row><cell>classifiers outputs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Merged the upper</cell><cell>92%</cell><cell>92%</cell><cell>84%</cell><cell>72%</cell><cell>96%</cell><cell>87.2%</cell></row><row><cell>three classifiers</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.19,532.43,399.63,8.96;5,119.90,544.43,363.25,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,363.61,532.43,141.20,8.96;5,119.90,544.43,264.79,8.96">ImageCLEF 2009 Medical Image Annotation Task: PCTs forHierarchical Multi-Label Classification</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dimitrovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kocev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Loskovska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dzeroski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,407.08,544.43,46.94,8.96">CLEF 2009</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,559.43,399.94,8.96;5,119.90,571.46,384.96,8.96;5,119.90,583.46,26.67,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,279.01,559.43,226.11,8.96;5,119.90,571.46,89.53,8.96">X-ray image classification using Random Forests with Local Binary Patterns</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,237.85,571.46,267.02,8.96">International Conference on Machine Learning and Cybernetics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,598.46,400.24,8.96;5,119.90,610.46,284.80,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,335.02,598.46,170.41,8.96;5,119.90,610.46,88.55,8.96">Content-Based Image Retrieval Based On Color-Spatial Features</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mustaffa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rahmat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mahmod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,215.00,610.46,160.38,8.96">Malaysian Journal of Computer Science</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,625.46,399.75,8.96;5,119.90,637.46,384.94,8.96;5,119.90,649.46,90.57,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,231.81,625.46,273.12,8.96;5,119.90,637.46,73.78,8.96">Automatic medical image categorization and annotation using LBP and MPEG-7 edge</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,218.33,637.46,286.51,8.96;5,119.90,649.46,61.25,8.96">International Conference on Information Technology and Applications in Biomedicine</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,664.46,400.10,8.96;5,119.90,676.46,245.20,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,258.11,664.46,247.18,8.96;5,119.90,676.46,34.83,8.96">AUTOMATIC CLASSIFICATION OF MEDICAL X-RAY IMAGES</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,163.06,676.46,160.38,8.96">Malaysian Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,691.46,400.12,8.96;5,119.90,703.46,382.18,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,298.81,691.46,206.49,8.96;5,119.90,703.46,161.23,8.96">Bag-of-Visual-Words Based on Clonal Selection Algorithm for SAR Image Classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,287.49,703.46,185.32,8.96">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,718.46,341.30,8.96" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Woods</surname></persName>
		</author>
		<title level="m" coord="5,224.52,718.46,133.51,8.96">Digital Image Processing 2nd edn</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.19,733.48,399.77,8.96;5,119.90,745.48,26.67,8.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,155.24,733.48,193.46,8.96">Two-Dimensional Signal and Image Processing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Englewood Cliffs, NJ, Prentice Hall</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.19,76.38,400.01,8.96;6,119.90,88.38,81.59,8.96" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,284.94,76.38,177.12,8.96">Digital image processing Using MATLAB</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Eddins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Pearson Perntice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,103.38,395.08,8.96;6,119.90,115.38,307.90,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,298.01,103.38,206.87,8.96;6,119.90,115.38,180.01,8.96">A Comparative Study of Texture Measures with Classification Based on Feature Distributions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,306.33,115.38,79.67,8.96">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,130.38,395.30,8.96;6,119.90,142.38,195.11,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,217.23,130.38,184.23,8.96">A New Trend for face Recognition Features</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Zieadan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Nasef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,409.71,130.38,95.39,8.96;6,119.90,142.38,158.28,8.96">international jouranl of advanced image processing Techniques</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,157.38,395.12,8.96;6,119.90,169.38,225.82,8.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,274.52,157.38,226.20,8.96">Robust &amp; accurate face recognation using histograms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Suresh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,119.90,169.38,189.07,8.96">Int.J.of Mangment It, and Engineering (IJMIA)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,183.78,383.40,9.56;6,119.90,195.18,374.16,8.96;6,119.90,206.70,380.93,8.96;6,119.90,218.22,274.46,8.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,250.31,206.70,213.04,8.96">General Overview of ImageCLEF at CLEF2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar Roldan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,470.23,206.70,30.60,8.96;6,119.90,218.22,107.80,8.96">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>SpringerInternational Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,232.74,393.33,9.56;6,119.90,244.29,372.50,8.96;6,119.90,255.69,92.78,8.96" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,253.31,232.74,232.54,8.96">Overview of the ImageCLEF 2015 medical clustering task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,119.90,244.29,294.70,8.96">CLEF2015 Working Notes. CEUR Workshop Proceedings, CEURWS.org</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,109.80,270.21,388.98,9.56;6,119.90,281.73,372.76,8.96;6,119.90,293.25,49.56,8.96;6,169.58,291.06,5.04,5.83;6,177.14,293.25,272.87,8.96;6,119.90,304.77,384.38,8.96;6,119.90,316.29,280.09,8.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,421.71,270.21,77.07,8.96;6,119.90,281.73,319.66,8.96">Teaching &amp; Learning System for Diagnostic Imaging; Phase I: X-Ray Image Analysis &amp; Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S S</forename><surname>Faruque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<ptr target="https://www.dropbox.com/s/7334oyhgyezxz7q/Teaching%20%26%20Learning%20System%20for%20Diagnostic%20Imaging%20Camera%20Ready%202.pdf?dl=0" />
	</analytic>
	<monogr>
		<title level="m" coord="6,456.89,281.73,35.76,8.96;6,119.90,293.25,49.56,8.96;6,169.58,291.06,5.04,5.83;6,177.14,293.25,241.23,8.96">Proceedings of the 6 th International Conference on Computer Supported Education</title>
		<meeting>the 6 th International Conference on Computer Supported Education</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
