<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,156.97,115.96,301.41,12.62;1,242.19,133.89,130.97,12.62">Overview of the ImageCLEF 2015 Medical Classification Task</title>
				<funder ref="#_uDD6nDm">
					<orgName type="full">European Science Foundation</orgName>
					<orgName type="abbreviated">ESF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,166.14,171.56,106.97,8.74"><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Seco De Herrera</surname></persName>
							<email>alba.garciasecodeherrera@nih.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">National Library of Medicine (NLM/NIH)</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.78,171.56,66.40,8.74"><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.35,171.56,71.87,8.74"><forename type="first">Stefano</forename><surname>Bromuri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,156.97,115.96,301.41,12.62;1,242.19,133.89,130.97,12.62">Overview of the ImageCLEF 2015 Medical Classification Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9586CC54ABB544A68356CFE510F82F63</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEFmed</term>
					<term>compound figure detection</term>
					<term>multi-label classification</term>
					<term>figure separation</term>
					<term>modality classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This articles describes the ImageCLEF 2015 Medical Classification task. The task contains several subtasks that all use a data set of figures from the biomedical open access literature (PubMed Central). Particularly compound figures are targeted that are frequent in the literature. For more detailed information analysis and retrieval it is important to extract targeted information from the compound figures. The proposed tasks include compound figure detection (separating compound from other figures), multi-label classification (define all sub types present), figure separation (find boundaries of the subfigures) and modality classification (detecting the figure type of each subfigure). The tasks are described with the participation of international research groups in the tasks. The results of the participants are then described and analysed to identify promising techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The amount and availability of biomedical literature has increased considerably due to the advent of the Internet <ref type="bibr" coords="1,287.42,460.87,9.96,8.74" target="#b0">[1]</ref>. The task of medical doctors has on the other hand not become simpler as the amount of information to review for taking decisions has become overwhelming. Despite this growing complexity, physicians would use services that improve their understanding of an illness even if these involve more cognitive effort than in standard practice <ref type="bibr" coords="1,373.25,508.69,9.96,8.74" target="#b1">[2]</ref>. Images in biomedical articles can contain highly relevant information for a specific information need and can accelerate the search by filtering out irrelevant documents <ref type="bibr" coords="1,441.67,532.60,9.96,8.74" target="#b2">[3]</ref>. As a consequence image-based retrieval has been proposed as a way of improving access to the medical literature and complement text search <ref type="bibr" coords="1,399.86,556.51,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="1,412.03,556.51,7.01,8.74" target="#b4">5]</ref>.</p><p>Image classification can play an important role in improving the imagebased retrieval of the biomedical literature, as this helps to filter out irrelevant information from the retrieval process. Many images in the biomedical literature (around 40% <ref type="bibr" coords="1,193.46,604.33,10.79,8.74" target="#b5">[6]</ref>) are compound figures (see Figure <ref type="figure" coords="1,357.61,604.33,3.87,8.74" target="#fig_0">1</ref>), so determining the figure type is not clear as several different types of figures can be present in a single compound figure. Information retrieval systems for images should be capable of distinguishing the parts of compound figures that are relevant to a given query, as usually queries are limited to a single modality <ref type="bibr" coords="2,319.63,319.09,9.96,8.74" target="#b6">[7]</ref>. Compound figure detection and multi-label classification are therefore a required first step to focus retrieval of images. Some file formats, such as DICOM (Digital Imaging and Communications in Medicine), contain metadata that can be used to filter images by modality, but this information is lost when using images from the biomedical literature where images are stored as JPG, GIF or PNG files. In this case caption text and visual appearance are key to understanding the content of the image and whether or not it is a compound figure. Both types of information, text and visual, are complementary to each other and can help managing the multi-label classification <ref type="bibr" coords="2,192.89,426.69,9.96,8.74" target="#b7">[8]</ref>. From the standpoint of information retrieval and classification of compound images and associated text, the current systems could greatly benefit from the use of multi-label classification approaches <ref type="bibr" coords="2,376.16,450.60,10.52,8.74" target="#b8">[9]</ref> by a) defining models that can use the dependencies between the extracted images; b) defining models that can express the importance of a label in a compound figure. In addition, compound figures are naturally redundant sources of information with natural dependencies occurring between the different regions of the image.</p><p>Retrieval systems can fail if they are not specifically designed to work with compound figures and partial relevance. Identification of each subpart of the figures can improve retrieval accuracy by enabling comparison of figures with lower noise levels <ref type="bibr" coords="2,212.39,554.97,14.61,8.74" target="#b9">[10]</ref>.</p><p>To promote research on this field a medical classification task is proposed in the context of the ImageCLEF 2015 lab <ref type="bibr" coords="2,315.27,587.61,14.61,8.74" target="#b10">[11]</ref>. This paper describes this benchmark in detail. This article is structured as follows: Section 2 presents an overview of the participants and of the datasets used in the competition. Section 3 discusses the results with respect to the selected datasets. Finally, Section 4 concludes the paper and presents relevant future work for the next edition of ImageCLEF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tasks, Data Sets, Ground Truth, Participation</head><p>This section describes the main scenario of the benchmark including the data used, the tasks, ground truthing and participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Tasks in 2015</head><p>There were four subtasks in 2015:</p><p>compound figure detection; compound figure separation; multi-label classification; subfigure classification. This section gives an overview of each of the four subtasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compound Figure Detection</head><p>Compound figure identification is a required first step to make compound figures from the literature accessible for further analysis. Therefore, the goal of this subtask is to identify whether a figure is a compound figure or not. The task makes training data available containing compound and non-compound figures from the biomedical literature. Figure <ref type="figure" coords="3,475.61,367.72,4.98,8.74" target="#fig_2">2</ref> shows an example of a compound and a non-compound figure.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure Separation</head><p>This task was first introduced in 2013 and the same evaluation methodology is used in 2015 <ref type="bibr" coords="3,293.54,620.25,9.96,8.74" target="#b5">[6]</ref>. The goal of this task is to separate the compound figures into subfigures using separation lines. Figure <ref type="figure" coords="3,413.95,632.21,4.98,8.74" target="#fig_5">3</ref> shows a compound figure which is separated into subfigures by blue lines. In 2015, a larger number of compound figures was distributed compared to the previous years.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-label Classification</head><p>The fundamental difference with respect to compound figure separation resides in the fact that the compound figure is not separated into subfigures, but it is rather used entirely to perform a scene classification task. The intuition behind this approach resides in the fact that subfigures in medical papers are usually assembled because they add complementary information concerning the aeticle topic (see Figure <ref type="figure" coords="4,359.99,455.55,3.87,8.74" target="#fig_6">4</ref>). In this sense, much work was performed in the multi-label classification community <ref type="bibr" coords="4,393.68,467.51,15.50,8.74" target="#b11">[12]</ref> and many algorithms already exist to classify multi-label problems. A multi-label dataset in medical imaging was never considered before to the best of our knowledge. More formally, this problem can be expressed as follows:</p><p>Let X be the domain of observations and let L be the finite set of labels. Given a training set</p><formula xml:id="formula_0" coords="4,197.35,536.57,252.69,9.65">T = {(x 1 , Y 1 ), (x 2 , Y 2 ), ..., (x n , Y n )} (x i ∈ X, Y i ⊆ L) i.i.d.</formula><p>drawn from an unknown distribution D, the goal is to learn a multi-label classifier h : X → 2 L . However, it is often more convenient to learn a real-valued scoring function of the form f : X × L → R. Given an instance x i and its associated label set Y i , a working system will attempt to produce larger values for labels in Y i than those that are not in Y i , i.e. f (x i , y 1 ) &gt; f (x i , y 2 ) for any y 1 ∈ Y i and y 2 / ∈ Y i . By the use of the function f (•, •), a multi-label classifier can be obtained: h(x i ) = {y|f (x i , y) &gt; δ, y ∈ L}, where δ is a threshold to infer from the training set. The function f (•, •) can also be adapted to a ranking function rank f (•, •), which maps the outputs of f (x i , y) for any y Multi-label performance measures differ from single label ones. Following the same approach presented in <ref type="bibr" coords="5,255.08,394.02,14.61,8.74" target="#b11">[12]</ref>, the Hamming Loss is proposed as the evaluation measure for multi-label learning in ImageCLEF.</p><formula xml:id="formula_1" coords="4,134.77,644.16,345.83,21.61">∈ L to {1, 2, ..., |L|} such that if f (x i , y 1 ) &gt; f (x i , y 2 ) then rank f (x i , y 1 ) &lt; rank f (x i , y 2 ).</formula><p>More formally let a testing set S = {(x 1 , Y 1 ), (x 2 , Y 2 ), ..., (x m , Y m )}.</p><p>Hamming loss: evaluates how many times an observation-label pair is misclassified. The score is normalized between 0 and 1, where 0 is the best:</p><formula xml:id="formula_2" coords="5,239.87,457.50,240.72,30.32">hloss S (h) = 1 m m i=1 |h(x i ) Y i | |L| .<label>(1)</label></formula><p>where represents the symmetric difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subfigure Classification</head><p>The subfigure classification task is a variation of the multi-label classification task in which the subfigures contained in the multilabel figures are provided separately for classification. The main reason to proceed in this way is to provide two matched dataset that researchers can use to compare multi-label classification of the full compound image versus taking each single image in the compound image and classify it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Datasets</head><p>In 2015, the dataset was a subset of the of the full ImageCLEF 2013 dataset <ref type="bibr" coords="5,467.31,626.90,9.96,8.74" target="#b5">[6]</ref>, which is a part of PubMed Central A subset of these images containing 1,568 images are labelled for the multilabel learning task. These images are also distributed as a training set (containing 1,071 figures) and a test set (containing 497 figures). The labels were assigned using the same class hierarchy as the one used for the ImageCLEF 2012 <ref type="bibr" coords="6,465.10,226.71,15.50,8.74" target="#b12">[13]</ref> and 2013 <ref type="bibr" coords="6,177.79,238.66,10.52,8.74" target="#b5">[6]</ref> modality classification task. A slight difference is that in 2015 the class "compound" is not included because only the non-compound parts can be labels with all compound images being split.</p><p>Figure <ref type="figure" coords="6,181.69,274.58,4.98,8.74" target="#fig_7">5</ref> shows the ImageCLEF 2015 class hierarchy where the class codes with descriptions are the following ([Class code] Description):</p><p>-[Dxxx] Diagnostic images:</p><p>• [DRxx] Radiology (7 categories): In addition to the figures, the articles of the figures are provided to allow for the use of textual information.</p><formula xml:id="formula_3" coords="6,158.68,330.84,168.81,80.82">• [DRU S] Ultrasound • [DRM R] Magnetic Resonance • [DRCT ] Computerized Tomography • [DRXR] X-Ray, 2D Radiography • [DRAN ] Angiography • [DRP E] PET • [DRCO] Combined</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Participation</head><p>Over seventy groups registered for the medical classification tasks and obtained access to the data sets. Eight of the registered groups submitted results to the medical classification tasks. 7 runs were submitted to the compound figure detection task, 12 runs to the multi-label classification task, 5 runs to the figure separation task and 16 runs to the subfigure separation task.</p><p>The following groups submitted at least one run:</p><p>- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes the results obtained by the participants for each of the subtasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compound Figure Detection</head><p>Very good results were obtained for the compound figure detection task, reaching up to 85% for HDO BCSG as seen in Table <ref type="table" coords="8,342.19,457.81,3.87,8.74" target="#tab_2">1</ref>. Table <ref type="table" coords="8,383.47,457.81,4.98,8.74" target="#tab_2">1</ref> contains the results obtained by the two participants of the compound figure detection task. FHDO BCSG <ref type="bibr" coords="8,213.42,620.25,15.50,8.74" target="#b13">[14]</ref> achieved best results with an accuracy of 85.39% using a multi-modal approach. FHDO BCSG applied a combination of visual features and text. With respect to visual features they focused on features detecting the border of the figures and a bag-of-keypoints. The bag-of-words approach is used for text classification using the provided figure caption. They also proposed two runs applying only either visual or text information obtaining in general lower results that applying multi-modal approaches.</p><p>CIS UDEL <ref type="bibr" coords="9,203.53,155.54,15.50,8.74" target="#b14">[15]</ref> obtained best results when using only visual information achieving an accuracy of 82.82%. A combination of connected component analysis of subfigures and peak region detection is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Figure Separation</head><p>In 2015, two groups participated in the figure separation task. Table <ref type="table" coords="9,430.85,236.11,4.98,8.74" target="#tab_3">2</ref> shows the results achieved. Best results were obtained by NLM <ref type="bibr" coords="9,359.83,248.07,14.61,8.74" target="#b15">[16]</ref>. NLM distinguished two AAUITEC <ref type="bibr" coords="9,201.44,470.00,15.50,8.74" target="#b16">[17]</ref> submitted three runs. Each run used a specific separator line detection based on "bands" (run "aauitec figsep band") or "edges" (run "aauitec figsep edge"). Best results achieved an accuracy of 49.40% when using a combination of both detection types. A recursive algorithm is used starting by classifying the images as illustrations or not. Depending on the type of image a specific separator line detection is used, based on "bands" or "edges", respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-label Classification</head><p>With respect to the multi-label classification task, there were two participating groups, IIS <ref type="bibr" coords="9,203.53,610.34,15.50,8.74" target="#b17">[18]</ref> and Mindlab<ref type="foot" coords="9,278.57,608.77,3.97,6.12" target="#foot_1">2</ref> . Quite interestingly, none of the two participants decided to apply standard multi-label classification algorithms <ref type="bibr" coords="9,442.16,622.30,15.50,8.74" target="#b11">[12]</ref> such ask Multi-Label K-nearest neighbours (MLKNN) or Binary Relevance Support Vector Machines (BR-SVM), but rather decided to come up with two new solutions to the problem. Table <ref type="table" coords="10,258.12,130.95,4.98,8.74" target="#tab_4">3</ref> presents the results of the runs submitted by the two groups.</p><p>ISS applied Khronker decomposition to find a set of filters of the figure as features for a maximum margin layer classifier in which the multi-label task is mapped on a dual problem of the standard margin optimization with SVMs. To achieve this the authors consider the possibility of modelling the problem by introducing an additional kernel matrix calculated starting from the vector of labels associated to the compound figures.</p><p>The Mindlab approach is based on building a visual representation by means of deep convolutional neural networks, by relying on the theory of transfer learning which is based in the ability of a system to recognize and apply knowledge learned in previous domains to novel domains, which share some commonality. For this task, Mindlab used the Yangqing Jia et al. (Caffe) <ref type="bibr" coords="10,416.48,274.41,15.50,8.74" target="#b18">[19]</ref> pretrained network to represent figures. Caffe is an open source implementation of the winning convolutional network architecture of the ImageNet challenge. For the label assignment the authors proceeded as follows: Once the prediction is made a distribution of the classes is obtained and used to annotate only those with a score above 0.5. Furthermore, in the second run when a sample concept that scores above 0.5 does not exist, the two top labels are assumed as relevant.</p><p>The scores of the two presented approaches are quite close in the result, but the best result was achieved by Mindlab with a Hamming Loss of 0.5 as seen in Table <ref type="table" coords="10,162.16,382.01,3.87,8.74" target="#tab_4">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Subfigure Classification</head><p>Three groups participated in the subfigure classification task and the results can be seen in Table <ref type="table" coords="10,208.56,620.25,3.87,8.74" target="#tab_5">4</ref>. The FHDO BCSG group achieved the best classification accuracy (67.60%) by using textual and visual features as described in <ref type="bibr" coords="10,430.19,632.21,14.61,8.74" target="#b13">[14]</ref>. FHDO BCSG also achieved the best result when only using visual features (60.91%).</p><p>The method reuses existing techniques and fuses visual and textual features.</p><p>Given the high dimensionality of the data, principal component analysis (PCA) is used to reduce the dimensionality to a subset of components explaining the variance of the dataset. SVMs and Random Forests are used together for the classification.</p><p>The CMTECH group used a descriptor based on covariance of the visual features associated with the subfigures <ref type="bibr" coords="11,306.65,181.02,14.61,8.74" target="#b19">[20]</ref>. The advantage of the proposed descriptor, being based on covariance, is to be robust with respect to noise. In this sense, the feature vector provided has 11 features. As claimed by the authors, this is particularly interesting because the matrix defined with this approach lies within the Riemann manifold, where images providing similar features are close in the Riemann Geometry. From this standpoint the authors also specified the conditions under which two images can be considered close.</p><p>The paper proposes a new approach to classifying images and the approach performs well without using a complicated classifier, which demonstrates the need to define good features. The last approach was proposed by the BMET group <ref type="bibr" coords="11,379.10,524.61,14.61,8.74" target="#b20">[21]</ref>. The article present a convolutional neural networks (CNN) used for the subfigure classification. As specified by the authors, the CNN selected is a simplified version of the CNN used in LeNet-5. The major claim of the paper concerns the ability of the network to extract features in an unsupervised way and without the aid of domain knowledge. The main drawback of the paper is that the method used for the evaluation takes a long time to converge and the results were calculated on only partly optimized models. The classification results reflect this fact. Despite the relatively low results, the BMET contribution presents an interesting experimentation concerning the task proposed in ImageCLEF and it would certainly be interesting to see how these methods can be extended to improve the preliminary results obtained.</p><p>In this paper the results of the medical classification task ImageCLEF 2015 competition are presented. As in 2013, the challenge involved a subtask on the separation of compound figures from the biomedical literature. This year, three new subtasks were introduced: a subtask on detection of compound figures to identify whether a figure is compound or not; a multi-label subtask in which the subfigure labels of a compound figure need to be determined without separating the subfigures; and a subfigure classification challenge in which the separated subfigures are classified, following a traditional modality classification approach.</p><p>In the first year of this task, eight groups participated submitting forty runs. The participants present a variety of techniques for the problems on compound figure analysis. This is a wide problem than can make a large number of subfigures available for image search applications. The large number of different techniques leading to good results shows that many techniques can be used for the problem and the detailed optimization is most often responsible for obtaining a very good performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,172.63,243.99,270.10,7.89;2,156.49,115.83,85.04,113.39"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of compound figures in the biomedical literature.</figDesc><graphic coords="2,156.49,115.83,85.04,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,184.22,529.95,77.53,7.86;3,330.36,529.95,92.64,7.86"><head>( a )</head><label>a</label><figDesc>Compound figure. (b) non-compound figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,188.14,554.34,239.08,7.89;3,167.22,411.72,111.53,113.39"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of compound and non-compound figures.</figDesc><graphic coords="3,167.22,411.72,111.53,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,178.85,319.10,77.53,7.86"><head>( a )</head><label>a</label><figDesc>Compound figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,320.50,319.10,153.05,7.86"><head>( b )</head><label>b</label><figDesc>Compound figure with separation lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="4,138.76,343.48,337.84,7.89;4,138.67,115.83,157.90,198.43"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example a compound figure and its separation into subfigures by blue lines.</figDesc><graphic coords="4,138.67,115.83,157.90,198.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="5,134.77,329.03,345.83,7.89;5,134.77,340.02,345.83,7.86;5,134.77,350.98,244.10,7.86;5,222.76,115.82,169.85,198.44"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Example a compound figure containing images of multiple classes which are all related to each other with respect to the localization of transplanted cells and in situ proliferation at the infarct border in an experimental model.</figDesc><graphic coords="5,222.76,115.82,169.85,198.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="7,134.77,450.60,345.82,7.89;7,134.77,461.59,162.20,7.86"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The image class hierarchy that was developed for document images occurring in the biomedical open access literature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,156.50,209.06,302.36,226.77"><head></head><label></label><figDesc></figDesc><graphic coords="7,156.50,209.06,302.36,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,290.86,637.28,189.73,10.31"><head></head><label></label><figDesc>1 containing in total over 1,700,000 images in 2014. The distributed subset contains a total of 20,867 figures. The training set contains 10,433 figures and the test set 10,434 figures. Each of these two sets contains 6,144 compound figures and 4289-4290 non-compound figures. The entire dataset is used for the compound figure detection task. 6,784 of the compound figures are used for the figure separation task. 3,403 figures are distributed in the training set and 3,381 in the test set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,169.87,501.12,275.61,81.97"><head>Table 1 .</head><label>1</label><figDesc>Results of the runs of the compound figure detection task.</figDesc><table coords="8,194.20,520.79,226.96,62.31"><row><cell>Group</cell><cell>Run</cell><cell cols="2">Run Type Accuracy</cell></row><row><cell cols="2">FHDO BCSG task1 run2 mixed sparse1</cell><cell>mixed</cell><cell>85.39</cell></row><row><cell cols="2">FHDO BCSG task1 run1 mixed stemDict</cell><cell>mixed</cell><cell>83.88</cell></row><row><cell cols="2">FHDO BCSG task1 run3 mixed sparse2</cell><cell>mixed</cell><cell>80.07</cell></row><row><cell cols="2">FHDO BCSG task1 run4 mixed bestComb</cell><cell>mixed</cell><cell>78.32</cell></row><row><cell cols="3">FHDO BCSG task1 run6 textual sparseDict textual</cell><cell>78.34</cell></row><row><cell>CIS UDEL</cell><cell>exp1</cell><cell>visual</cell><cell>82.82</cell></row><row><cell cols="2">FHDO BCSG task1 run5 visual sparseSift</cell><cell>visual</cell><cell>72.51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,134.77,281.49,345.83,184.61"><head>Table 2 .</head><label>2</label><figDesc>Results of the runs of the figure separation task.</figDesc><table coords="9,134.77,301.15,345.83,164.94"><row><cell>Group</cell><cell>Run</cell><cell>Accuracy</cell></row><row><cell>NLM</cell><cell>run2 whole</cell><cell>visual 84.64</cell></row><row><cell>NLM</cell><cell>run1 whole</cell><cell>visual 79.85</cell></row><row><cell cols="3">AAUITEC aauitec figsep combined visual 49.40</cell></row><row><cell cols="2">AAUITEC aauitec figsep edge</cell><cell>visual 35.48</cell></row><row><cell cols="2">AAUITEC aauitec figsep band</cell><cell>visual 30.22</cell></row><row><cell cols="3">types of compound images: stitched multipanel figure and multipanel figures with</cell></row><row><cell cols="3">a gap. A manual selection of stitched multipanel figures from the whole dataset</cell></row><row><cell cols="3">is first carried out. Then, two approaches are used. Best results are obtained</cell></row><row><cell cols="3">by "run2 whole" where stitched multipanel figure separation is combined with</cell></row><row><cell cols="3">both image panel separation and label extraction. "run2 whole" achieved an</cell></row><row><cell cols="3">accuracy of 79.85% by combining stitched multipanel figure separation with</cell></row><row><cell>panel separation.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,155.79,411.49,303.79,120.08"><head>Table 3 .</head><label>3</label><figDesc>Results of the runs of the multi-label classification task.</figDesc><table coords="10,155.79,429.42,303.79,102.16"><row><cell>Run</cell><cell>Group</cell><cell>Hamming Loss</cell></row><row><cell>IIS</cell><cell>output 6</cell><cell>0.0817</cell></row><row><cell>IIS</cell><cell>output 8</cell><cell>0.0785</cell></row><row><cell>IIS</cell><cell>output 9</cell><cell>0.0710</cell></row><row><cell>IIS</cell><cell>output 7</cell><cell>0.0700</cell></row><row><cell>IIS</cell><cell>output 10</cell><cell>0.0696</cell></row><row><cell>IIS</cell><cell>output 5</cell><cell>0.0680</cell></row><row><cell>IIS</cell><cell>output 1</cell><cell>0.0678</cell></row><row><cell>IIS</cell><cell>output 3</cell><cell>0.0675</cell></row><row><cell cols="2">MindLAB predictions Mindlab ImageclefMed multi-label test comb2lbl</cell><cell>0.0674</cell></row><row><cell>IIS</cell><cell>output 4</cell><cell>0.0674</cell></row><row><cell>IIS</cell><cell>output 2</cell><cell>0.0671</cell></row><row><cell cols="2">MindLAB predictions Mindlab ImageclefMed multi-label test comb1lbl</cell><cell>0.0500</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,178.37,326.86,258.61,153.70"><head>Table 4 .</head><label>4</label><figDesc>Results of the runs of the subfigure classification task.</figDesc><table coords="11,186.77,346.53,241.82,134.04"><row><cell>Run</cell><cell>Group</cell><cell cols="2">Run Type Accuracy</cell></row><row><cell cols="2">FHDO BCSG task4 run5 train 20152013.txt</cell><cell>mixed</cell><cell>67.60</cell></row><row><cell cols="2">FHDO BCSG task4 run4 clean rf.txt</cell><cell>mixed</cell><cell>67.24</cell></row><row><cell cols="2">FHDO BCSG task4 run1 combination.txt</cell><cell>mixed</cell><cell>66.48</cell></row><row><cell cols="2">FHDO BCSG task4 run8 clean short rf.txt</cell><cell>mixed</cell><cell>66.44</cell></row><row><cell cols="2">FHDO BCSG task4 run7 clean comb librf.txt</cell><cell>mixed</cell><cell>65.99</cell></row><row><cell cols="2">FHDO BCSG task4 run6 clean libnorm.txt</cell><cell>mixed</cell><cell>64.34</cell></row><row><cell cols="2">FHDO BCSG task4 run3 textual.txt</cell><cell>textual</cell><cell>60.91</cell></row><row><cell cols="2">FHDO BCSG task4 run2 visual.txt</cell><cell>visual</cell><cell>60.91</cell></row><row><cell>CMTECH</cell><cell cols="2">resultsSubfigureRunWholeCov.txt visual</cell><cell>52.98</cell></row><row><cell>CMTECH</cell><cell>resultsSubfigure.txt</cell><cell>visual</cell><cell>48.61</cell></row><row><cell>BMET</cell><cell>sf run 3.txt</cell><cell>visual</cell><cell>45.63</cell></row><row><cell>BMET</cell><cell>sf run 6.txt</cell><cell>visual</cell><cell>45.00</cell></row><row><cell>BMET</cell><cell>sf run 4.txt</cell><cell>visual</cell><cell>44.34</cell></row><row><cell>BMET</cell><cell>sf run 2.txt</cell><cell>visual</cell><cell>43.62</cell></row><row><cell>BMET</cell><cell>sf run 1.txt</cell><cell>visual</cell><cell>37.56</cell></row><row><cell>BMET</cell><cell>sf run 5.txt</cell><cell>visual</cell><cell>37.56</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,657.44,150.64,7.47"><p>http://www.ncbi.nlm.nih.gov/pmc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="9,144.73,656.80,198.29,7.86"><p>https://sites.google.com/a/unal.edu.co/mindlab/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank the support received from the <rs type="funder">European Science Foundation (ESF)</rs> via the <rs type="projectName">ELIAS</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_uDD6nDm">
					<orgName type="project" subtype="full">ELIAS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,436.85,337.64,7.86;12,151.52,447.78,156.34,7.89" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,182.84,436.85,297.75,7.86;12,151.52,447.81,19.65,7.86">PubMed and beyond: a survey of web tools for searching biomedical literature</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,179.19,447.81,37.30,7.86">Database</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,458.89,337.64,7.86;12,151.52,469.85,329.07,7.86;12,151.52,480.81,329.07,7.86;12,151.52,491.74,175.73,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,205.91,469.85,274.68,7.86;12,151.52,480.81,283.09,7.86">Understanding the nature of information seeking behavior in critical care: Implications for the design of health information technology</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Kannampallil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Almoosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">L</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,444.99,480.81,35.60,7.86;12,151.52,491.77,95.49,7.86">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,502.86,337.63,7.86;12,151.52,513.82,329.07,7.86;12,151.52,524.78,190.70,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,384.79,502.86,95.80,7.86;12,151.52,513.82,251.60,7.86">Determining the importance of figures in journal articles to find representative images</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,425.18,513.82,55.42,7.86;12,151.52,524.78,30.69,7.86">SPIE Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">8674</biblScope>
			<biblScope unit="page" from="86740I" to="86740I" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,535.86,337.64,7.86;12,151.52,546.82,329.07,7.86;12,151.52,557.76,235.58,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,374.32,535.86,106.28,7.86;12,151.52,546.82,297.97,7.86">A review of content-based image retrieval systems in medicine-clinical benefits and future directions</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Michoux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bandon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,458.04,546.82,22.55,7.86;12,151.52,557.78,159.95,7.86">International Journal of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,568.87,337.64,7.86;12,151.52,579.83,329.07,7.86;12,151.52,590.76,163.17,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,443.73,568.87,36.87,7.86;12,151.52,579.83,289.87,7.86">Contentbased image retrieval in radiology: Current status and future directions</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Akgül</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Napel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,450.24,579.83,30.35,7.86;12,151.52,590.79,73.59,7.86">Journal of Digital Imaging</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="222" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,601.87,337.63,7.86;12,151.52,612.83,329.07,7.86;12,151.52,623.79,283.29,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,210.81,612.83,189.99,7.86">Overview of the ImageCLEF 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">García</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demner Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,421.22,612.83,59.37,7.86;12,151.52,623.79,204.39,7.86">Working Notes of CLEF 2013 (Cross Language Evaluation Forum)</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,634.88,337.64,7.86;12,151.52,645.84,329.07,7.86;12,151.52,656.77,235.44,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,151.52,645.84,325.36,7.86">A survey on visual information search behavior and requirements of radiologists</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Markonis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Holzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dungs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kriewel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,656.80,145.99,7.86">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="539" to="548" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,119.67,337.64,7.86;13,151.52,130.63,329.07,7.86;13,151.52,141.59,288.03,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,307.74,119.67,172.86,7.86;13,151.52,130.63,140.22,7.86">Semantic combination of textual and visual information in multimedia retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ah-Pine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,312.65,130.63,167.94,7.86;13,151.52,141.59,190.50,7.86">Proceedings of the 1st ACM International Conference on Multimedia Retrieval. ICMR &apos;11</title>
		<meeting>the 1st ACM International Conference on Multimedia Retrieval. ICMR &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,152.55,337.64,7.86;13,151.52,163.48,244.86,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,264.65,152.55,182.11,7.86">A review on multi-label learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,458.46,152.55,22.14,7.86;13,151.52,163.51,202.38,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,174.47,337.98,7.86;13,151.52,185.43,329.07,7.86;13,151.52,196.39,122.35,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,437.12,174.47,43.47,7.86;13,151.52,185.43,310.29,7.86">Creating a classification of image types in the medical literature for visual categorization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,151.52,196.39,89.30,7.86">SPIE Medical Imaging</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,207.34,337.97,7.86;13,151.52,218.30,329.07,7.86;13,151.52,229.26,329.07,7.86;13,151.52,240.22,329.07,7.86;13,151.52,251.18,313.03,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,449.27,229.26,31.32,7.86;13,151.52,240.22,188.21,7.86">General overview of ImageCLEF at the CLEF 2015 labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kazi Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D M</forename><surname>Roldán García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,360.28,240.22,116.11,7.86">Working Notes of CLEF 2015</title>
		<title level="s" coord="13,151.52,251.18,141.41,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,262.14,337.97,7.86;13,151.52,273.07,301.18,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,264.65,262.14,182.11,7.86">A review on multi-label learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,458.46,262.14,22.13,7.86;13,151.52,273.10,202.38,7.86">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1819" to="1837" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,284.06,337.98,7.86;13,151.52,295.02,329.07,7.86;13,151.52,305.98,329.07,7.86;13,151.52,316.93,106.67,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,234.78,295.02,245.81,7.86;13,151.52,305.98,72.70,7.86">Overview of the ImageCLEF 2012 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,245.60,305.98,234.99,7.86;13,151.52,316.93,27.77,7.86">Working Notes of CLEF 2012 (Cross Language Evaluation Forum)</title>
		<imprint>
			<date type="published" when="2012-09">September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,327.89,337.98,7.86;13,151.52,338.85,329.07,7.86;13,151.52,349.81,25.60,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,266.43,327.89,214.17,7.86;13,151.52,338.85,178.95,7.86">FHDO Biomedical Computer Science Group at Medical Classification Task of ImageCLEF 2015</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friederich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,355.55,338.85,120.84,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,360.77,337.98,7.86;13,151.52,371.73,329.07,7.86;13,151.52,382.69,25.60,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,331.38,360.77,149.21,7.86;13,151.52,371.73,181.93,7.86">CIS UDEL working notes on Image-CLEF 2015: Compound figure detection task</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shatkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kambhamettu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,356.87,371.73,119.53,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,393.65,337.97,7.86;13,151.52,404.61,284.68,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,330.05,393.65,150.54,7.86;13,151.52,404.61,111.54,7.86">NLM at ImageCLEF2015: Biomedical multipanel figure separation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,285.23,404.61,118.11,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,415.56,337.98,7.86;13,151.52,426.52,213.24,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,274.91,415.56,205.69,7.86;13,151.52,426.52,40.10,7.86">AAUITEC at ImageCLEF 2015: Cmpound figure separation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taschwer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Marques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,213.79,426.52,118.11,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,437.48,337.97,7.86;13,151.52,448.44,315.46,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,405.69,437.48,74.90,7.86;13,151.52,448.44,142.47,7.86">IIS at ImageCLEF 2015: Multi-label classification task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodríguez-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fontanella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Piater</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,316.01,448.44,118.11,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,459.40,337.98,7.86;13,151.52,470.36,329.07,7.86;13,151.52,481.32,329.07,7.86;13,151.52,492.28,60.92,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,238.21,470.36,237.77,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,167.15,481.32,273.16,7.86">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,503.24,337.98,7.86;13,151.52,514.19,259.93,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,255.99,503.24,224.60,7.86;13,151.52,514.19,86.94,7.86">Medical image classification via 2D color feature based covariance descriptors</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cirujeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Binefa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,260.47,514.19,98.24,7.86">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,525.15,337.98,7.86;13,151.52,536.11,314.81,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,396.16,525.15,84.44,7.86;13,151.52,536.11,142.11,7.86">Convolutional neural networks for subfigure classification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lyndon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">H W</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,315.36,536.11,118.10,7.86">Working Notes of CLEF 2015</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
