<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,193.84,115.96,227.67,12.62;1,203.02,133.89,209.31,12.62">AAUITEC at ImageCLEF 2015: Compound Figure Separation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,228.53,172.43,69.02,8.74"><forename type="first">Mario</forename><surname>Taschwer</surname></persName>
							<email>mario.taschwer@aau.at</email>
							<affiliation key="aff0">
								<orgName type="department">ITEC</orgName>
								<orgName type="institution">Klagenfurt University (AAU)</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.71,172.43,57.65,8.74"><forename type="first">Oge</forename><surname>Marques</surname></persName>
							<email>omarques@fau.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Florida Atlantic University (FAU)</orgName>
								<address>
									<addrLine>Boca Raton</addrLine>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,193.84,115.96,227.67,12.62;1,203.02,133.89,209.31,12.62">AAUITEC at ImageCLEF 2015: Compound Figure Separation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E24559138B19E6710DA70DFA4714B7F4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our approach to automatically separating compound figures appearing in biomedical articles is split into two image processing algorithms: one is based on detecting separator edges, and the other tries to identify background bands separating subfigures. Only one algorithm is applied to a given image, according to the prediction of a binary classifier trained to distinguish graphical illustrations from other images in biomedical articles. Our submission to the ImageCLEF 2015 compound figure separation task achieved an accuracy of 49% on the provided test set of about 3400 compound images. This stays clearly behind the best submission of other participants (85% accuracy), but is by an order of magnitude faster than other approaches reported in the literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatically separating compound figures has been identified as a relevant problem for image-based information retrieval in collections of biomedical articles <ref type="bibr" coords="1,134.77,451.14,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,146.95,451.14,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="1,156.35,451.14,7.01,8.74" target="#b4">5]</ref>. The task has been posed as a subproblem of the ImageCLEF 2015 <ref type="bibr" coords="1,470.07,451.14,10.52,8.74" target="#b5">[6]</ref> medical classification task <ref type="bibr" coords="1,251.84,463.09,9.96,8.74" target="#b3">[4]</ref>. Figure <ref type="figure" coords="1,300.51,463.09,4.98,8.74" target="#fig_0">1</ref> shows two sample compound images of the provided training dataset.</p><p>Known approaches to the compound figure separation problem <ref type="bibr" coords="1,422.55,487.87,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,434.72,487.87,7.75,8.74" target="#b1">2]</ref> focus on the detection of homogeneous image regions separating subfigures, which we call separator bands. These approaches fail for compound images where subimages are stitched together without separator bands, as shown in Fig. <ref type="figure" coords="1,400.62,523.74,16.38,8.74" target="#fig_0">1(a)</ref>. We therefore propose an approach based on edge detection that is able to separate subimages without separator bands, and is more generally applicable to subfigures whose rectangular border is represented by visible edges.</p><p>To handle subfigures not separated by vertical or horizontal edges, as shown in Fig. <ref type="figure" coords="1,169.81,584.39,16.83,8.74" target="#fig_0">1(b)</ref>, we propose a variant of our algorithm which detects separator bands. The edge-based and band-based algorithms are applied selectively to a given compound image based on the prediction of a binary classifier trained to distinguish between graphical illustrations and other images. We assume that only graphical illustrations need to be handled by the band-based separation algorithm, whereas other compound images can be processed successfully by the edge-based algorithm. Although the proposed algorithm achieved only a moderate accuracy of 49% on the ImageCLEF 2015 test dataset, we believe that it may be useful for processing large image collections due to its efficiency. The average processing time per image (0.12 seconds) is about 20 times lower than the value reported by <ref type="bibr" coords="2,470.08,387.88,10.52,8.74" target="#b1">[2]</ref> for their approach. Moreover, separation performance is likely to be increased by incorporating additional techniques found to be effective like image markup removal or image label extraction <ref type="bibr" coords="2,284.29,423.75,9.96,8.74" target="#b0">[1]</ref>.</p><p>The paper is organized as follows. Section 2 describes our approach in detail, results of the experimental evaluation at ImageCLEF 2015 are presented in Section 3, and Section 4 provides some ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>Our approach to compound figure separation is a recursive algorithm (see Fig. <ref type="figure" coords="2,471.74,512.66,4.43,8.74" target="#fig_1">2</ref>) comprising the following steps: (1) classification of the compound image as illustration or non-illustration image, (2) removal of border bands, (3) detection of separator lines, (4) decision about vertical or horizontal separation, and (5) separation and recursive application to each subfigure image. The illustration classifier is used to decide which of two separator line detection modules to apply: if the compound image is classified as an illustration image, the bandbased algorithm is applied, which aims at detecting separator bands between subfigures. Otherwise, the image is processed by the edge-based separator detection algorithm, which applies edge detection and Hough transform to locate candidate separator edges. The algorithm selection is based on the assumption that only compound images of graphical illustrations have no visible vertical or horizontal edges separating subfigures. The following four sections describe the illustration classifier, the main recursive algorithm, and the two separator detection modules in more detail. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Illustration Classifier</head><p>In order to automatically discriminate between graphical illustrations and other images in the dataset, a logistic regression classifier has been trained on the training dataset of the ImageCLEF 2015 multi-label image classification task.</p><p>The training dataset consists of about 1000 images of 29 classes (organized in a class hierarchy), which have been aggregated into two meta classes for the purpose of training the illustration classifier: the illustration meta class comprises all "general biomedical illustration" images of the training dataset except for chromatography images, screenshots, and non-clinical photos. Images of the latter classes and all diagnostic images have been assigned to the non-illustration meta class. About 36% of the images in the training set are labeled with multiple classes (compound images); for assignment to meta classes, we used only the first label and ignored all other labels. We use just two simple global image features as classifier input, computed after gray-level conversion: entropy, estimated using a 256-bin histogram, and mean intensity. Classification performance has been evaluated on the test dataset of the ImageCLEF 2015 multi-label image classification task where ground truth annotations were assigned to illustration and non-illustration meta classes as described above. The test dataset contains about 500 images where about 44% are compound images. The accuracy of our illustration classifier on the test dataset was measured as 82.5% (92.0% on training dataset due to linear decision boundary).</p><p>The illustration classifier is used to decide which separator detection algorithm to apply to a given compound image. If the image is predicted to be an illustration with probability p &gt; 0.5, the band-based separator detection is applied, otherwise the edge-based separator module is used. This decision is made only once for each compound image, so all recursive invocations use the same separator detection algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recursive Algorithm</head><p>Before applying the main algorithm (Fig. <ref type="figure" coords="4,317.93,339.74,4.43,8.74" target="#fig_1">2</ref>) to a given compound figure image, it is converted to 8-bit gray-scale. Border band removal detects a rectangular bounding box surrounded by a maximal homogeneous image region adjacent to image borders (border band). The separator line detection modules return two lists of vertical and horizontal separator lines, respectively. If both lists are empty, recursion is terminated and the current image (without border bands) is returned. Due to minimal distances between separator lines and, additionally, to borders, recursion is guaranteed to terminate by finding no more separator lines at some point. The decision about vertical or horizontal separation is trivial if one of both lists of separator lines is empty. Otherwise the decision is made based on the regularity of separator distances: locations of separator lines and borders are normalized to the range [0,1], and the direction (vertical or horizontal) yielding the lower variance of adjacent distances is chosen. The final step is subfigure separation and recursion. The current figure image is divided into subimages along the chosen separation lines, and the algorithm is applied recursively to each subimage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Edge-based Separator Detection</head><p>One of the two alternatives for separator line detection is the edge-based algorithm, which aims at detecting full-length vertical or horizontal edges in a given gray-scale image without border bands. The separator line detection module is invoked separately for vertical and horizontal directions, so the algorithm deals with a single edge direction only, which we denote by θ.</p><p>Figure <ref type="figure" coords="4,181.25,632.21,4.98,8.74" target="#fig_2">3</ref> gives an overview of the edge-based separator detection algorithm. The core components are unidirectional edge detection (Sobel filter) and peak selection in the one-dimensional Hough transform of the binary edge map. The Hough transform counts the number of edge points aligned on each line in direction θ. So the peaks correspond to the longest edges in this direction, and their locations identify candidate separator edges. Candidate edges are filtered by a similar regularity criterion as used for deciding about vertical or horizontal separation (see Section 2.2), and consolidated by filling small gaps between edge line segments. Finally, edges that are too short in comparison to image height or width, or too close to borders are discarded. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Band-based Separator Detection</head><p>For images without visible edges separating subfigures, an alternative separator detection approach is used. It aims at locating homogeneous rectangular areas covering the full width or height of the image, which we call separator bands. The steps of the proposed algorithm are depicted in Fig. <ref type="figure" coords="5,385.05,548.52,3.87,8.74" target="#fig_3">4</ref>.</p><p>Since band-based separator detection is intended to be applied to graphical illustration images, we binarize the image (using the mean intensity value as a threshold) and look for separator bands within white pixels only. We then compute mean projections along direction θ, that is, the mean value of each vertical or horizontal line of the binary image. A resulting mean value will be 1 (white) if and only if the corresponding line contains only white pixels. Candidate separator bands are then determined by identifying maximal runs of ones in the vector of mean values, and subsequently filtered using a regularity criterion similar to Hough peak selection (see Section 2.3). Finally, selected bands that are close to the image border are discarded, and the center lines of remaining bands are returned as separator lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>Three runs have been submitted for the ImageCLEF 2015 compound figure separation task: (1) aauitec figsep edge: the proposed algorithm with edge-based separator detection was applied to all test images, (2) aauitec figsep band : only the band-based separator detection was used, and (3) aauitec figsep combined : edge-based or band-based separator detection was selected using the illustration classifier as described in Section 2.1. Runs (1) and (2) did not use the illustration classifier.</p><p>The test set contains 3381 compound images, of which 1839 (54%) have been classified as illustration images by our classifier. Our algorithm was implemented in Matlab and executed on a PC with 8 GB RAM and an Intel E8400 CPU running at 3 GHz. Experimental results are shown in Table <ref type="table" coords="6,397.60,481.44,3.87,8.74" target="#tab_0">1</ref>. The combined approach using the illustration classifier shows a substantial improvement in detection accuracy compared to the other two variants of our algorithm. This fact indirectly verifies our assumption that band-based separator detection is better suited for graphical illustrations than for non-illustration images.</p><p>The run time reported in Table <ref type="table" coords="7,294.27,155.10,4.98,8.74" target="#tab_0">1</ref> is the average run time per image when executed once for all (about 3400) images in the test set. The processing rate of about 9 images per second for the combined algorithm indicates that the algorithm may be applicable to large image collections if optimized and ported to C++. Note that the efficiency of other known approaches in the literature is either not documented <ref type="bibr" coords="7,250.63,214.88,10.52,8.74" target="#b0">[1]</ref> or by an order of magnitude lower ([2] reported 2.4 seconds per image).</p><p>Figure <ref type="figure" coords="7,181.18,239.03,4.98,8.74" target="#fig_4">5</ref> shows some examples of test images where our algorithm failed for different reasons. Low-contrast edges present a problem for the edge-based algorithm, because they may appear too short compared to image height (or width). Errors of the illustration classifier may lead to the application of an inappropriate separator line detection method. The band-based algorithm fails if separator bands are cluttered with text that prevents detection of full-length white bands. Under-segmentation may occur for the band-based algorithm if separator bands are too thin; this problem may be alleviated by parameter optimization in further work. Isolated image labels may be detected as separate subfigures, both by edge-based and band-based algorithms, leading to over-segmentation. Note that the effect of border band removal in Fig. <ref type="figure" coords="7,345.05,358.58,4.29,8.74" target="#fig_4">5</ref>(e) does not reduce the score computed by the ImageCLEF evaluation procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Further Work</head><p>We presented a recursive image processing algorithm for automatic separation of compound figures appearing in scientific articles. The algorithm has been evaluated on a dataset of compound images taken from biomedical articles in the context of the ImageCLEF 2015 compound figure separation task. Although the achieved detection accuracy of 49% is clearly inferior to the best result submitted by competitors (85%), early qualitative evaluation suggests that our algorithm provides benefits in terms of run-time efficiency and spatial detection accuracy. A quantitative evaluation will be the subject of future work.</p><p>Moreover, there is some potential for improving detection performance by modifying and extending the proposed algorithm. Firstly, internal parameters of the algorithm can be optimized using a cross-validation dataset. In our current implementation, parameters were set manually, as the evaluation tool was not available during development. Secondly, the quality of the training set for the illustration classifier can be improved by using all image labels of the multi-label image classification training set. Thirdly, the illustration classifier can be applied to every detected subfigure in order to select the separator detection algorithm on each recursive invocation (not just once for the entire compound image). Finally, additional image processing steps known to help figure separation could be added. Promising candidates include image markup removal and image label extraction <ref type="bibr" coords="7,182.11,656.12,9.96,8.74" target="#b0">[1]</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,297.24,345.83,7.89;2,134.77,308.23,345.82,7.86;2,134.77,319.19,337.13,7.86;2,311.53,115.84,155.63,155.63"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample compound images (of the ImageCLEFmed 2013 dataset [3]) suitable for two different separator detection algorithms: (a) subimages are separated by vertical and horizontal edges, (b) subfigures are separated by whitespace (separator bands).</figDesc><graphic coords="2,311.53,115.84,155.63,155.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,186.05,454.40,243.26,7.89"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Recursive algorithm for compound figure separation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,191.70,441.77,231.97,7.89"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Flow chart of edge-based separator line detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,134.77,254.61,345.82,7.89;6,134.77,265.59,222.68,7.86"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Flow chart of band-based separator detection. The algorithm terminates early if no candidate separator bands are found (not shown).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,134.77,595.72,345.83,7.89;8,134.77,606.71,345.82,7.86;8,134.77,617.67,345.83,7.86;8,134.77,628.63,345.82,7.86;8,134.77,639.59,345.83,7.86;8,134.77,650.55,319.01,7.86;8,134.77,119.83,345.84,461.12"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Sample images of the compound figure separation test dataset [4] where our algorithm failed: (a) edge-based algorithm failed due to low-contrast edges; (b) illustration image processed by edge-based algorithm due to classification error (false negative of illustration classifier); (c) band-based algorithm failed due to text clutter; (d) under-segmentation by band-based algorithm due to thin separator bands; (e) over-segmentation (here by edge-based algorithm) due to isolated image labels.</figDesc><graphic coords="8,134.77,119.83,345.84,461.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,511.99,345.83,95.31"><head>Table 1 .</head><label>1</label><figDesc>Experimental results on the ImageCLEF 2015 compound figure separation test set. Accuracy was measured using the official evaluation procedure. The best run was submitted by the NLM group (U.S. National Library of Medicine).</figDesc><table coords="6,172.50,555.18,270.36,52.12"><row><cell>Run</cell><cell>Accuracy</cell><cell>Run time per image</cell></row><row><cell>aauitec figsep band</cell><cell>30%</cell><cell>46 ms</cell></row><row><cell>aauitec figsep edge</cell><cell>35%</cell><cell>157 ms</cell></row><row><cell>aauitec figsep combined</cell><cell>49%</cell><cell>117 ms</cell></row><row><cell>best submission</cell><cell>85%</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.35,142.59,342.24,7.86;9,146.91,153.55,333.68,7.86;9,146.91,164.51,333.68,7.86;9,146.91,175.46,304.44,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,146.91,153.55,333.68,7.86;9,146.91,164.51,105.82,7.86">Image retrieval from scientific publications: Text and image content processing to separate multipanel figures</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Apostolova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">R</forename><surname>Thoma</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.22810</idno>
		<ptr target="http://dx.doi.org/10.1002/asi.22810" />
	</analytic>
	<monogr>
		<title level="j" coord="9,258.61,164.51,221.98,7.86;9,146.91,175.46,63.23,7.86">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="893" to="908" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,186.42,342.24,7.86;9,146.91,197.38,333.68,7.86;9,146.91,208.34,333.45,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,146.91,197.38,330.12,7.86">Separating compound figures in journal articles to allow for subfigure classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Markonis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Meriaudeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2007897</idno>
		<ptr target="http://dx.doi.org/10.1117/12.2007897" />
	</analytic>
	<monogr>
		<title level="m" coord="9,146.91,208.34,45.45,7.86">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8674</biblScope>
			<biblScope unit="page" from="86740J" to="86740J" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,219.30,342.24,7.86;9,146.91,230.26,333.67,7.86;9,146.91,241.22,333.68,7.86;9,146.91,252.18,118.61,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,192.15,230.26,187.90,7.86">Overview of the ImageCLEF 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">García</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1179/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,399.13,230.26,81.45,7.86;9,146.91,241.22,146.81,7.86">CLEF 2013 Working Notes. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
			<biblScope unit="volume">1179</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,263.14,342.24,7.86;9,146.91,274.09,333.68,7.86;9,146.91,285.05,333.67,7.86;9,146.91,296.01,23.04,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,363.54,263.14,117.05,7.86;9,146.91,274.09,125.54,7.86">Overview of the ImageCLEF 2015 medical classification task</title>
		<author>
			<persName coords=""><forename type="first">García</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1391/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,294.11,274.09,186.48,7.86;9,146.91,285.05,46.41,7.86">CLEF 2015 Working Notes. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2015-09">September 2015</date>
			<biblScope unit="volume">1391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,306.97,342.24,7.86;9,146.91,317.93,333.68,7.86;9,146.91,328.89,333.67,7.86;9,146.91,339.85,281.49,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,256.53,317.93,224.07,7.86;9,146.91,328.89,32.07,7.86">Literature-based biomedical image classification and retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0895611114000998" />
	</analytic>
	<monogr>
		<title level="j" coord="9,191.11,328.89,205.43,7.86">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,350.81,342.24,7.86;9,146.91,361.77,333.68,7.86;9,146.91,372.72,333.68,7.86;9,146.91,383.68,333.68,7.86;9,146.91,394.64,333.68,7.86;9,146.91,405.60,239.86,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,383.69,372.72,96.91,7.86;9,146.91,383.68,134.53,7.86">General overview of Im-ageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar Roldán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,302.81,383.68,177.79,7.86;9,146.91,394.64,85.49,7.86">Sixth International Conference of the CLEF Association, CLEF&apos;15</title>
		<title level="s" coord="9,371.45,394.64,109.14,7.86;9,146.91,405.60,27.78,7.86">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Toulouse</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">September 8-11, 2015. 2015</date>
			<biblScope unit="volume">9283</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
