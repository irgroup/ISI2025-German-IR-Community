<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.62,116.90,298.11,12.68;1,253.51,134.83,108.33,12.68">Overview of the ImageCLEF 2015 liver CT annotation task</title>
				<funder ref="#_Wjn265F">
					<orgName type="full">COST Action</orgName>
				</funder>
				<funder ref="#_RFJ7RWH">
					<orgName type="full">TÜBİTAK</orgName>
				</funder>
				<funder ref="#_Gnymnws">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.80,172.92,73.82,8.80"><forename type="first">Neda</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
							<email>neda.marvasti@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Electronics Department</orgName>
								<orgName type="institution">Boğaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.17,172.92,63.14,8.80"><forename type="first">María</forename><surname>Del Mar</surname></persName>
						</author>
						<author>
							<persName coords="1,289.62,172.92,63.31,8.80"><forename type="first">Roldán</forename><surname>García</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Languages and Computing Science Department Malaga</orgName>
								<orgName type="institution">University of Malaga</orgName>
								<address>
									<postCode>29071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.49,172.92,71.47,8.80"><forename type="first">Suzan</forename><surname>Uskudarli</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Boğaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,445.52,172.92,26.42,8.80;1,249.58,184.87,31.26,8.80"><forename type="first">José</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Languages and Computing Science Department Malaga</orgName>
								<orgName type="institution">University of Malaga</orgName>
								<address>
									<postCode>29071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.77,184.87,50.54,8.80"><forename type="first">Burak</forename><surname>Acar</surname></persName>
							<email>acarbu@boun.edu.trvavlab.ee.boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Electronics Department</orgName>
								<orgName type="institution">Boğaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.62,116.90,298.11,12.68;1,253.51,134.83,108.33,12.68">Overview of the ImageCLEF 2015 liver CT annotation task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">886F241286C06E814533C5A5752AF7C0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>Liver CT annotation task</term>
					<term>Automatic annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The second Liver CT (Computed tomography) annotation challenge was organized during the 2015 Image-CLEF workshop, hosted by the Institut de Recherche en Informatique de Toulouse (IRIT), University of Toulouse, France. This challenge entailed the annotation of Liver CT scans to generate structured reports. This paper describes the motivations for this task, training and test datasets, the evaluation methods, and discusses the approaches of the participating groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>ImageCLEF <ref type="bibr" coords="1,190.58,465.35,10.51,8.80" target="#b6">[7]</ref> was part of the Cross Language Evaluation Forum (CLEF) 2015 consisting of four main tasks: Image Annotation, Medical Classification, Medical Clustering, and Liver CT Annotation. It was the second time that the automatic annotation of Liver CT images was provided as a challenge. However, there are two changes compared to the last edition of the challenge. First, the format of the given UsE (user expressed) features has been changed. Furthermore, there is no CoG (Computer generated) features provided this year. In the term of UsE features, LiCO (liver case ontology) is used instead of ONLIRA (ontology of liver for radiology) <ref type="bibr" coords="1,213.10,560.99,12.28,8.80" target="#b3">[4]</ref>, which has additional patient and study information.</p><p>The purpose of the Liver CT annotation task is to automatically generate structured reports with use of computer generated features of liver CT volumes. Structured reports are highly valuable in medical contexts due to the processing opportunities they provide, such as reporting, image retrieval, and computeraided diagnosis systems. However, structured report generation is cumbersome and time consuming. Furthermore, their creation requires administration of the domain expert, who is time constrained. Consequently, such structured medical reports are often not found or are incomplete in practice. This challenge has been designed to aid the fill a pre-prepared structured report using the imaging information derived from CT images.</p><p>The data provided for this challenge consists of 50 training and 10 test datasets. Participants were asked to answer a fixed set of multiple-choice questions about livers. The questions were automatically generated from an opensource liver case ontology (LiCO) <ref type="bibr" coords="2,285.60,179.88,10.51,8.80" target="#b3">[4]</ref> and provided in files with RDF (resource description framework) format. The answers to the questions describe the properties of the liver, the hepatic vasculature of the liver, and a specific lesion within it. During this task, the user is presented with the following training data: (1) data from a CT scan, (2) a liver mask, (3) a volume-of-interest that highlights the selected lesion, and (4) a rich set of imaging observations (annotations) provided in RDF format. The imaging observations are LiCObased annotations that were manually entered by radiologists. Participants need to extract their own image features from the CT data and use them to automatically annotate the liver CT volumes. The results have been evaluated in terms of the completeness and accuracy of the generated annotations.</p><p>The rest of the paper is organized as follows, Section 2 gives a detailed description of the task and introduces the participants. Section 3 presents the main results of the task and the results of the participants, and finally, Section 4 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Liver CT Annotation Challenge</head><p>This section describes the task and introduces the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Definition and Datasets</head><p>The Liver CT annotation task is proposed towards the generation of structured reports describing the semantic features of the liver, its vascularity, and the types of its lesions. The goal of this task is to develop automated mechanisms to assist medical experts in difficult and practically infeasible task of annotating medical records.</p><p>The training dataset includes 50 cases, each consisting of:</p><p>a cropped CT image of the liver -a 3D matrix with the same size as cropped CT image, a liver mask that specifies the part corresponding to the liver -a 3D matrix indicating the liver areas with a 1 and nonliver areas with a 0, a bounding box (ROI) corresponding to the region of the selected lesion within the liver -as a vector of 6 numbers corresponding to the coordinates of two opposite corners, -An RDF file generated using LiCOrepresenting manually entered imaging observations by a radiologist. In total, there are 73 UsE features. If a feature is not applicable for a case, it will not be represented in the corresponding RDF file.</p><p>In the training set, 50 ".mat" files, each containing the first three of above data, as well as an RDF file representing the imaging observations, have been given to the participants. In the test set, there is no RDF file and imaging observations are missing and participants are asked to predict them. The participants have been asked to extract and use their own image features to complete the task. RFD files include information of patient, study, and imaging observation. Participants are expected to predict the only imaging information, same as the last year's challenge.</p><p>The resolution of CT images may vary in the range of (x : 190 -308 pixels, y : 213 -238 pixels, and z : 41 -588 slices). The spacing may also vary in the range of (x, y : 0.674 -1.007 mm, slice : 0.399 -2.5 mm).</p><p>It is important to note that, this dataset is partially available through image-CLEF2015 system (http://medgift.hevs.ch:8080/CLEF2015/faces/Login. jsp), for academic use only. If you are interested in using this dataset, you need to properly cite this paper.</p><p>User Expressed Features Imaging observations of a radiologist for the liver domain are represented with LiCO. A web-based data collection application, called CaReRa-Web (case retrieval in radiological databases), which can be accessed for academic use from the CaReRa project website http://www.vavlab. ee.boun.edu.tr.</p><p>For each case, there are 73 UsE features represented in RDF format. These features clinically characterize the liver, hepatic vascularity, and liver's lesions. In the training set, the UsE features are manually entered by an expert radiologist. Every UsE feature corresponds to a question answered by a radiologist. Some UsE features may take on more than one values. Such features are represented with a multi-choice answers. Features with value marked as "NA" are not included in the RDF file.</p><p>In the test phase, the participants are expected to predict the UsE features in the following format <ref type="bibr" coords="3,237.99,476.91,4.61,8.80">(</ref> Values bar separated list of strings The "Group" and "Concept" are the LiCO-based concepts. Each concept may have several properties. Each property may have multiple values, whose indices and meaning are given in Table <ref type="table" coords="3,280.11,572.89,4.98,8.80">4</ref> under "Possible values" column. Properties deemed irrelevant are marked as NA by the radiologist. Note that, UsE features are grouped as: Liver, Vessel, General, and Lesion. Table <ref type="table" coords="3,396.87,596.80,4.98,8.80">4</ref> lists every group and its corresponding concepts, properties, possible values, and their assigned indices.</p><p>In every RDF file, there is a patient which has a study and a set of data properties same as Name, age and gender, as well as a set of object properties same as disease and drugs. Each study has a set of data properties including ID and dates as well as a set of object properties same as laboratory results and physical examinations. Also each study has a liver, which has a set of imaging observation. Each liver also has a lesion, which has relevant imaging observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation methodology</head><p>The evaluation is performed on the basis of completeness and accuracy of the predicted annotations with reference to the manual annotations of the test dataset. Completeness is defined as the number of predicted features divided by the total number of features, while accuracy is the number of correctly-predicted features divided by the total number of predicted features.</p><p>For answers that allow multiple values to a question, the correct prediction of a single feature is considered as the correct annotation.</p><formula xml:id="formula_0" coords="4,189.84,286.80,290.75,22.31">Completeness = number of predicted U sE f eatures T otal number of U sE f eatures<label>(1)</label></formula><p>Accuracy = number of correctly predicted U sE f eatures N umber of predicted U sE f eatures</p><p>T otalScore = Completeness × Accuracy (3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Participation</head><p>Among 32 groups, which registered for the task and signed the license agreement to access the datasets, only 1 of them submitted his results. The group name is "CREDOM", from Biomedical Engineering Laboratory, Tlemcen University, Algeria. They have submitted three runs to the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Runs submitted in 2014</head><p>Last year in 2014 <ref type="bibr" coords="4,211.41,513.49,9.96,8.80" target="#b0">[1]</ref>, three groups submitted their results. Their prediction were based on classifiers, image retrieval, and generalized-coupled tensor factorization (GCTF). Last year a set of computer generated (CoG) features were also provided for the participants as an optional data.</p><p>The best performance was achieved by the BMET group <ref type="bibr" coords="4,409.40,561.41,10.51,8.80" target="#b4">[5]</ref> submitting 8 runs using two different methods: classifier-based approach using SVM (support vector machine) and image retrieval algorithm. They also used two different sets of feature: the prepared CoG features from the database and a bag of visual words (BoVW). Their classification methods outperformed the other methods, when they employed their expanded feature set. However, their retrieval method gave the best results, when the given CoG features were employed. This observation suggests that the nature of feature sets are important for utilizing different methods.</p><p>The second best performance was achieved by CASMIP group <ref type="bibr" coords="5,420.21,119.93,10.51,8.80" target="#b1">[2]</ref> submitting only one run to the task. They tried four different classifiers in the learning phase: linear discriminant analysis (LDA), logistic regression (LR), K-nearest neighbors (KNN), and finally SVM to predict UsE features. For each UsE feature the best classifier and its related features were learnt by using exhaustive search. They used only a certain part of provided CoG features, as well as 9 additional features extracted in the lesion ROI. As a result, for most of the UsE features, they achieved the same performance using any classifier and any combination of image features.</p><p>piLabVAVlab group <ref type="bibr" coords="5,242.21,227.53,10.51,8.80" target="#b2">[3]</ref> considered the dataset as heterogeneous data and GCTF approach was applied to predict UsE features. They considered both KLdivergence and Euclidean-distance-based cost functions, as well as the coupled matrix factorization models using GCTF framework.</p><p>The BMET group achieved the highest scores with completeness of %98 (See Table <ref type="table" coords="5,162.15,287.30,3.87,8.80" target="#tab_3">3</ref>. In terms of accuracy, BMET group has also attained the best score by using an image retrieval method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Runs submitted this year in 2015</head><p>This year in 2015, three runs has been submitted by the "CREDOM" group <ref type="bibr" coords="5,134.77,358.18,9.96,8.80" target="#b5">[6]</ref>. They used two different methods: classification by using random forest (RF) classifier, and retrieval by considering the specific signature of the liver (See Table <ref type="table" coords="5,162.16,382.09,3.87,8.80" target="#tab_1">1</ref>.</p><p>For the classification-based method (run 1 and run 2), they have employed two different sets of features. The first set contains 115 liver texture features in addition to 9 lesion geometric features, and the second set includes 214 lesion texture features, in addition to 9 lesion geometric features. Classification is performed by using supervised multi-class RF classifier. In this method, they divided the UsE features into two groups. For the first group, they have used the RF classifier, but for the second group, they have used a retrieval based method with their proposed similarity metric. The reason of proposing this separation is the unbalanced dataset.</p><p>Second method (run 3) is a retrieval-based method. Basically, they have encoded the 2D image extracted from the central slice of the lesion by applying 1D Log-Gabor filter, and then break the output of the filter into small blocks and quantize the dominant angular direction of each block to four levels by using Daugman method. Afterward, the Hamming distance has been employed as the similarity metric to retrieve the five most similar images to the test image. Finally, for each UsE feature, they have used majority voting between retrieved images.</p><p>Among 73 UsE features, 7 of them were excluded from the evaluation because of their unbounded labels (numeric continuous values). Table <ref type="table" coords="5,410.47,609.23,3.87,8.80" target="#tab_1">1</ref>, compares the results of three submitted runs in terms of completeness, accuracy and total scores.</p><p>Table <ref type="table" coords="5,177.36,645.10,4.98,8.80" target="#tab_2">2</ref> compares the results of different runs in predicting different groups of UsE features. We divide UsE features into 5 groups: liver, vessels and three    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This was the second time that the liver CT annotation task was organized. We provided liver patient data collected via a hybrid patient information entry system, whose liver characteristics are based on the LiCO ontology. The challenge was to predict UsE features of patient records, given in RDF format. This year in 2015, in contrast to last year's edition, users have not been provided with CoG features. Also, they were free to use any set of image features to perform the task. As this was the first time that UsE features were provided in RDF formats, it was not surprising that few groups were finally able to submit their runs for this complex task. Out of 32 teams, 1 team submitted its runs. The approaches and results were reviewed and documented in this paper. Since the dataset was exactly the same as last year's, comparison of the results of all runs submitted to the liver CT annotation task in both 2014 and 2015 is also provided in this paper. The main challenge of the task was due to the unbalanced dataset and participants tried to overcome this issue with different methods. Among all methods, image retrieval obtained the best performance. It was observed that feature selection is important for the best performance of the prediction method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,151.10,476.91,173.72,68.95"><head></head><label></label><figDesc>73 × 4 UsE data):</figDesc><table coords="3,151.10,489.23,173.72,56.63"><row><cell cols="3">Column Annotation Features Type</cell></row><row><cell>1</cell><cell>Group</cell><cell>string</cell></row><row><cell>2</cell><cell>Concept</cell><cell>string</cell></row><row><cell>3</cell><cell>Properties</cell><cell>string</cell></row><row><cell>4</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,128.28,345.83,149.81"><head>Table 1 :</head><label>1</label><figDesc>Results of the runs of Liver CT annotation task 2015. UsE features of the liver and vessel with high accuracy. None of the runs can completely annotate the component-related concepts of lesions. Lesion-related concepts of lesion are fully completed, while showing a very low accuracy. Results show that the third run (retrieval based method), outperforms the other runs.</figDesc><table coords="6,134.77,139.65,345.83,90.62"><row><cell cols="5">Group name Run Completeness Accuracy Total Score method used</cell></row><row><cell>CREDOM run1</cell><cell>0.99</cell><cell>0.825</cell><cell>0.904</cell><cell>RDF-feature1</cell></row><row><cell>CREDOM run2</cell><cell>0.99</cell><cell>0.822</cell><cell>0.902</cell><cell>RDF-feature2</cell></row><row><cell>CREDOM run3</cell><cell>0.99</cell><cell>0.836</cell><cell>0.910</cell><cell>Image Retrieval</cell></row><row><cell cols="5">lesion groups with area, lesion and component concepts. Results show that all</cell></row><row><cell>runs have completed</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,312.38,403.43,75.67"><head>Table 2 :</head><label>2</label><figDesc>Completeness(complete.) and Accuracy(acc.) for five different groups of UsE features</figDesc><table coords="6,136.56,334.70,401.64,53.35"><row><cell cols="2">Group name Run</cell><cell cols="2">Liver</cell><cell>Vessel</cell><cell></cell><cell cols="2">LesionArea</cell><cell cols="4">LesionLesion LesionComponent</cell></row><row><cell>name</cell><cell cols="11">run complete. acc. complete. acc. complete. acc. complete. acc. complete. acc.</cell></row><row><cell cols="2">CREDOM run1</cell><cell>1.00</cell><cell>0.925</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.730</cell><cell>1.00</cell><cell>0.47</cell><cell>0.96</cell><cell>0.87</cell></row><row><cell cols="2">CREDOM run2</cell><cell>1.00</cell><cell>0.925</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.746</cell><cell>1.00</cell><cell>0.47</cell><cell>0.96</cell><cell>0.84</cell></row><row><cell cols="2">CREDOM run3</cell><cell>1.00</cell><cell>0.925</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.753</cell><cell>1.00</cell><cell>0.48</cell><cell>0.96</cell><cell>0.89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,134.77,416.99,345.83,32.71"><head>Table 3</head><label>3</label><figDesc>compares the results of both liver CT annotation task 2014 and 2015 participants. As can be seen, results indicate that the BMET group from 2014 has the best performance in this task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,158.99,483.98,297.37,64.71"><head>Table 3 :</head><label>3</label><figDesc>Results of the runs of Liver CT annotation task 2014 and 2015.</figDesc><table coords="6,167.22,495.35,277.85,53.35"><row><cell cols="5">Group name Run Completeness Accuracy Total Score method used</cell></row><row><cell>BMET</cell><cell>run5 0.98</cell><cell>0.91</cell><cell>0.947</cell><cell>IR</cell></row><row><cell>CASMIP</cell><cell>run1 0.95</cell><cell>0.91</cell><cell>0.93</cell><cell>LDA+KNN</cell></row><row><cell cols="2">piLabVAVlab run2 0.51</cell><cell>0.89</cell><cell>0.677</cell><cell>MF-EUC</cell></row><row><cell>CREDOM</cell><cell>run3 0.99</cell><cell>0.836</cell><cell>0.910</cell><cell>IR</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments The Liver CT Annotation task is supported by <rs type="funder">TÜBİTAK</rs> Grant # <rs type="grantNumber">110E264</rs> (<rs type="projectName">CaReRa</rs> project), and in part by <rs type="funder">COST Action</rs> <rs type="grantNumber">IC1302</rs> (<rs type="grantNumber">KEY-STONE</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_RFJ7RWH">
					<idno type="grant-number">110E264</idno>
					<orgName type="project" subtype="full">CaReRa</orgName>
				</org>
				<org type="funding" xml:id="_Wjn265F">
					<idno type="grant-number">IC1302</idno>
				</org>
				<org type="funding" xml:id="_Gnymnws">
					<idno type="grant-number">KEY-STONE</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group Concept</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Properties</head><p>Possible values(assigned indices)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Liver</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Liver</head><p>Liver Placement downward displacement(0), normal placement(1), leftward displacement <ref type="bibr" coords="8,390.11,141.04,12.44,7.92" target="#b1">(2)</ref>, upward displacement(3), other(4) Liver Contour irregular(0), lobulated <ref type="bibr" coords="8,414.99,152.00,11.93,7.92" target="#b0">(1)</ref>, nodular <ref type="bibr" coords="8,472.58,152.00,12.36,7.92" target="#b1">(2)</ref>, regular(3), other  </p><p>, moderate(4), other(5) Contrast Pattern NA(-1), central(0), early uptake then wash out(1), fixing contrast in late phase(2), heterogeneous(3), homogeneous(4), peripheric(5), peripheric nodular(6), spokes wheel <ref type="bibr" coords="9,344.77,415.81,12.29,7.92" target="#b6">(7)</ref>, undecided(8), other(9) Lesion Composition SolidCycsticMix(0), Solid </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,354.12,342.24,7.92;7,146.91,365.08,222.11,7.92" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,186.21,365.08,161.32,7.92">imageclef liver ct image annotation task</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kökciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Türkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yazıcı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Üsküdarlı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,375.53,342.24,7.92;7,146.91,386.49,333.67,7.92;7,146.91,397.45,333.68,7.92;7,146.91,408.41,107.79,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,272.74,375.53,207.85,7.92;7,146.91,386.49,265.53,7.92">Towards content-based image retrieval: From computer generated features to semantic descriptions of liver ct scans</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Spanier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joskowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,434.11,386.49,46.47,7.92;7,146.91,397.45,84.83,7.92">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="7,240.92,397.45,234.13,7.92">Notebook Papers. CEUR Workshop Proceedings (CEUR</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,418.86,342.25,7.92;7,146.91,429.82,333.67,7.92;7,146.91,440.78,192.20,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,249.05,418.86,231.55,7.92;7,146.91,429.82,25.98,7.92">Liver ct annotation via generalized coupled tensor factorization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,194.36,429.82,132.41,7.92">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="7,334.79,429.82,145.79,7.92;7,146.91,440.78,76.83,7.92">Notebook Papers. CEUR Workshop Proceedings (CEUR</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,451.23,342.24,7.92;7,146.91,462.19,248.42,7.92" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kokciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bakir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<title level="m" coord="7,443.99,451.23,36.60,7.92;7,146.91,462.19,219.76,7.92">Semantic description of liver ct images: An ontological approach</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,472.64,342.24,7.92;7,146.91,483.60,333.68,7.92;7,146.91,494.56,333.68,7.92;7,146.91,505.52,107.79,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,362.22,472.64,118.37,7.92;7,146.91,483.60,266.42,7.92">Automatic annotation of liver ct images: the submission of the bmet group to imageclefmed 2014</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">W</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,434.49,483.60,46.10,7.92;7,146.91,494.56,84.83,7.92">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="7,240.92,494.56,234.13,7.92">Notebook Papers. CEUR Workshop Proceedings (CEUR</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,515.97,342.24,7.92;7,146.91,526.93,333.68,7.92;7,146.91,537.89,324.53,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,403.83,515.97,76.76,7.92;7,146.91,526.93,169.65,7.92">Automatic annotation of liver ct image: Imageclefmed 2015</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Nedjar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chikh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Abi-Yad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Bouafia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,339.62,526.93,140.97,7.92;7,146.91,537.89,154.04,7.92">CLEF2015 Working Notes. CEUR Workshop Proceedings, CEUR-WS.org</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,548.34,342.24,7.92;7,146.91,559.30,333.67,7.92;7,146.91,570.25,333.68,7.92;7,146.91,581.21,333.68,7.92;7,146.91,592.17,126.63,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,381.58,570.25,99.02,7.92;7,146.91,581.21,139.00,7.92">General Overview of Im-ageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Del Mar Roldán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="7,294.15,581.21,144.73,7.92">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
