<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.64,153.11,253.99,12.22;1,231.84,171.11,131.46,12.22">Automatic Annotation of Liver CT Image: ImageCLEFmed 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.64,210.37,54.70,8.85"><forename type="first">Imane</forename><surname>Nedjar</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Biomedical Engineering Laboratory</orgName>
								<orgName type="institution">Tlemcen University</orgName>
								<address>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.76,210.37,64.01,8.85"><forename type="first">Saïd</forename><surname>Mahmoudi</surname></persName>
							<email>said.mahmoudi@umons.ac.be</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Mons</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.72,210.37,96.93,8.85"><forename type="first">Mohamed</forename><forename type="middle">Amine</forename><surname>Chikh</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Biomedical Engineering Laboratory</orgName>
								<orgName type="institution">Tlemcen University</orgName>
								<address>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,400.08,210.37,36.87,8.85;1,237.60,222.61,32.64,8.85"><forename type="first">Khadidja</forename><surname>Abi-Yad</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Pathology</orgName>
								<orgName type="institution">University Hospital Center of Tlemcen</orgName>
								<address>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.34,221.97,74.54,9.69"><forename type="first">Zouheyr</forename><surname>Bouafia</surname></persName>
							<email>zouheyr.bouafia@mail.univ-tlemcen.dz</email>
							<affiliation key="aff3">
								<orgName type="laboratory">Telecommunication Laboratory</orgName>
								<orgName type="institution">Tlemcen University</orgName>
								<address>
									<country key="DZ">Algeria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.64,153.11,253.99,12.22;1,231.84,171.11,131.46,12.22">Automatic Annotation of Liver CT Image: ImageCLEFmed 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">402D7704B4130983B9C998D28AA7AA64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Annotation</term>
					<term>Liver</term>
					<term>Random Forest Classifier</term>
					<term>Image Retrieval</term>
					<term>Computer-Aided Diagnosis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the methods that we have proposed and used in the liver image annotation task of ImageCLEF 2015.This challenge entailed the annotation of liver CT scans to generate a structured report. To meet this challenge we have proposed two methods for annotating the liver image. The first one uses a classification approach, which is composed of two main phases. The first step consists of a pre-processing, where a texture and shape based features vector is extracted, in the second phase a classification process is achieved by using random forest classifier with two different sets of features. Our second method uses a specific signature of the liver. Indeed, we have taken a slice from 3D liver CT scans, thereafter we have normalized it into a rectangular block with constant dimensions to account for imaging inconsistencies, and then we have divided the block into small blocks. After applying the 1D Log-Gabor filters transformation, the dominant phase data of each block was extracted and quantized to four levels to encode the unique pattern of the liver into a bit-wise template. The Hamming distance was employed for retrieval. We submitted 3 runs to the liver image annotation task of ImageCLEF 2015 and we obtained the following scores (90.4%, 90.2%, and 91%).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The digital imaging revolution in the medical domain over the past three decades has changed the way the present-day physicians diagnose and treat diseases. The focus now includes more effective post-processing, organization, and retrieval. In this context, a major challenge is to support the clinical decision making by retrieving and displaying the relevant cases using all available information, such as structured reports.</p><p>The structured reports are highly valuable in medical contexts due to the processing opportunities that they provide, such as reporting, image retrieval, and computer-aided diagnosis systems. However, structured reports are time consuming since they need a lot of time to be created. Furthermore, their creation requires high domain expertise, which is time constrained. Consequently, such structured medical reports are often not found or are incomplete in practice <ref type="bibr" coords="2,350.88,210.37,10.71,8.85" target="#b0">[1]</ref>.</p><p>The aim of the liver annotation task <ref type="bibr" coords="2,290.40,222.37,11.76,8.85" target="#b1">[2]</ref> is to improve computer-aided automatic annotation of liver CT volumes by filling in a structured radiology report. The main goal of this task is describing the semantic features of the liver, its vascularity, and the types of lesions in the liver.</p><p>One of the major challenges of this work was the limited amount of training data compared to the number of annotations to be recognized. In particular, there were some annotations that did not occur at all in the dataset. Similarly, there were also some instances having the same annotation for all training samples <ref type="bibr" coords="2,402.96,306.37,12.60,8.85" target="#b2">[3]</ref>.To overcome this issue we present in this paper two methods based on the visual features and the information extracted from the Liver Case Ontology (LiCO ) <ref type="bibr" coords="2,371.28,330.37,11.76,8.85" target="#b3">[4]</ref> .</p><p>This paper is organized as follows: section two presents the principles related works in this area. Section 3 presents the dataset used. The proposed methods are presented in section 4. Section 5 provides a discussion on the experimental results. Finally, section 6 gives a conclusion to the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>ImageCLEF is the image retrieval track of the Cross Language Evaluation Forum (CLEF) <ref type="bibr" coords="2,159.36,447.49,25.80,8.85">[5] [5]</ref>.In 2014, for the first time, the liver CT annotation task was proposed <ref type="bibr" coords="2,124.80,459.49,10.71,8.85" target="#b5">[6]</ref>. Three groups have participated in this challenge, the BMET group form the School of Information Technologies at the University of Sydney (Australia), and the second group is CASMIP from The Hebrew University of Jerusalem (Israel).The third participant was piLabVAVlab from Boğaziçi University (Turkey). The BMET group <ref type="bibr" coords="2,212.16,507.49,11.76,8.85" target="#b2">[3]</ref> proposes two strategies for annotating the liver images. The first method uses multi-class classification scheme where each label has a classifier that is trained to separate it from other labels. They used two stages of classification, each one consisting of a bank of several support vector machines (SVM).The first stage is composed of the 1-vs-all classifiers, and the second stage consisted of the 1vs-1 classifiers. The second method uses the similarity scores from an image retrieval algorithm as weights for a majority voting scheme, thereby reducing the inherent bias towards labels that have a high number of samples. The BMET group submitted eight runs. Four of them used a classifier based approach, and the remaining used an image retrieval algorithm. All runs achieved high scores (&gt;90%), and they also achieved the highest score of 94.7% out of all the submission done to imageCLEF2014.</p><p>On the other side, CASMIP group <ref type="bibr" coords="2,277.20,639.49,11.76,8.85" target="#b6">[7]</ref> tried four different classifiers in the learning phase: linear discriminant analysis (LDA), logistic regression (LR), K-nearest neighbors (KNN), and finally SVM, to predict labels. An exhaustive search of every combination of image features is done using leave-one-out cross validation method on training data for every label and classifier. As result, for each label the best classifier and its related features were learned. The learning step was performed using all labels of the training dataset except cluster size, lobe and segments, which were obtained directly from image features. Python scikit-Learn Machine learning toolbox was used for implementing each classifier with default parameters. As result, for most of the labels they got almost the same performance by using any classifier and any combination of image features. The group submitted one run to the task, and they obtained a score of 93%, which achieved the second best performance.</p><p>The piLabVAVlab group <ref type="bibr" coords="3,240.48,246.37,11.52,8.85" target="#b7">[8]</ref> proposed an approach based on probabilistic interpretation of tensor factorization models, i.e. Generalized Coupled Tensor Factorization (GCTF). This method can simultaneously fit a large class of matrix/tensor models to higher-order matrices/tensors with common latent factors using different loss functions. piLabVAVlab considered the dataset as heterogeneous data and the GCTF approach was applied to predict labels. They considered KLdivergence and Euclideandistance based cost functions as well as the coupled matrix factorization models by using the GCTF framework. The group submitted three runs to the task, and their highest score was of 67.7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Material</head><p>The training dataset that we use in our work includes 50 cases, each of them consisting of:</p><p> A cropped CT image of the liver -a 3D matrix. The volumes had varied resolutions (x: 190-308 pixels, y: 213-387 pixels, slices: 41-588) and spacing (x, y: 0.674-1.007mm, slice: 0.399-2.5mm),  A liver mask that specifies the part corresponding to the liver -a 3D matrix indicating the liver areas with the value 1 and nonliver areas with 0,  A bounding box (ROI) corresponding to the region of the selected lesion within the liver -as a vector of 6 numbers corresponding to the coordinates of two opposite corners,  A user expressed features generated by Liver Case Ontology (LiCO) and stored in RDF file.</p><p>The test dataset contained 10 CT volumes, with varied resolutions and pixel spacing, cropped to the region around the liver. The test data also included a mask of the liver pixels and a bounding box (ROI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>For this challenge, we proposed two methods for annotating the liver image. The first one uses a classification approach, and the second method uses the signature of the liver. First of all we have extracted the user expressed (UsE) features from the ontolo-gy of liver cases (LiCO) by using OWL API <ref type="foot" coords="4,309.60,148.19,3.24,5.69" target="#foot_0">1</ref> .The two methods are presented in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Method 1:</head><p>This method is composed of two main phases. The first step consists of a preprocessing, where a texture and shape based features vector are extracted. In the second phase a classification process is achieved by using random forest classifier.</p><p>Features extraction and description : unlike database used in the liver image annotation task of ImageCLEF 2014 that contained a set of 60 computer generated (CoG) features obtained from interactive segmentation software, the database of liver image annotation task 2015 does not include the CoG. For this reason a set of shape and texture features are extracted from both lesion and liver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The proposed liver descriptor includes:</head><p>1. Liver Mean: liver's mean intensity value. 2. Liver Variance: liver's variance intensity value. 3. Liver Skewness : liver's skewness value. 4. Liver Kurtosis: liver's kurtosis value. 5. Liver Solidity: solidity of liver. 6. Liver Convexity: convexity of liver. 7. Haralick's texture features: we have used the following features extracted from the gray level co-occurrence matrix: contrast, entropy, variance, sum mean, correlation, max probability, inverse variance, inertia <ref type="bibr" coords="4,328.32,448.45,10.53,8.85" target="#b8">[9]</ref>, and also energy, cluster shade, cluster prominence and homogeneity proposed in <ref type="bibr" coords="4,340.80,460.45,18.87,8.85" target="#b9">[10]</ref>.We have calculated the 3D gray level co-occurrence matrix for four different directions (θ∈{0°, 90°, 45°, and 135°}) with a distance d=1. Therefore, our GLCM based feature vector includes 48 elements. 8. 3D Gabor wavelet transform: we have used the mean and the standard deviation as texture features, with eight orientations and three scales, so that the feature vector includes 24 elements for the means and 24 elements for deviation. Therefore, the feature vector is composed of 48 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The proposed lesion descriptor</head><p>A pre-processing step was applied in order to segment the lesion. To do this, we have applied a morphological operation which is dilatation. This operation was done after thresholding the liver and applying the AND operator between lesion bounding box and the liver mask. Thereafter, we extracted the following features: 1. The Euclidean distance between the centroid of the liver and lesion centroid. 2. The distance between the x coordinate centroid of the liver and the x coordinatecentroid of the lesion.</p><p>3. The distance between the y coordinate centroid of the liver and the y coordinate centroid of the lesion. 4. Surface area of the lesion. 5. The perimeter of the lesion. 6. The circularity C1 of the lesion: this measure always takes a value of 1 for perfect circles <ref type="bibr" coords="5,162.61,210.37,15.16,8.85" target="#b10">[11]</ref>, it is expressed by the following formula:</p><formula xml:id="formula_0" coords="5,233.28,232.58,237.36,22.66">2 1 ( ) A rea C M a xR a d iu s  <label>(1)</label></formula><p>7. Dispersion property: the irregularity of the mass is estimated from dispersion property, which identifies the irregular shape characteristics <ref type="bibr" coords="5,360.00,279.01,15.26,8.85" target="#b10">[11]</ref>. This value is given by the equation below:</p><formula xml:id="formula_1" coords="5,243.60,311.25,227.04,24.50">( ) MaxRadius Dp Area  (2)</formula><p>8. Elongation property: the regular oval mass can be differentiated from the irregular by using Elongation <ref type="bibr" coords="5,219.36,370.69,15.26,8.85" target="#b10">[11]</ref>. Its value is expressed by the following equation :</p><p>Area En MaxRadius </p><p>(3) 9. The circularity C2 of lesion: this value presents how a mass is similar to an ellipse.</p><p>It is useful in differentiating circular /oval masses from irregular masses. This measure always takes a value of 1 for perfect squares, circles <ref type="bibr" coords="5,382.80,450.85,15.26,8.85" target="#b10">[11]</ref>. It is calculated by the equation given below:</p><formula xml:id="formula_3" coords="5,238.08,484.75,232.56,22.13">2 M i n R a d iu s C M a x R a d i u s <label>(4)</label></formula><p>The total dimension of the first descriptor is 111(6+48+24+24+9).</p><p>We have also investigated the performances of our method by using a second descriptor containing the texture features of the lesion instead of liver texture features. The two texture features are the gray level co-occurrence matrix (GLCM) for four different directions (θ∈{0°, 90°, 45°, and 135°}) with a distance d=1. Therefore, our GLCM based feature vector includes 48 elements. The second texture feature is Gabor wavelet transforms, we have used the mean and the standard deviation, with sixteen orientations and five scales, the feature vector includes 80 elements for the means and 80 elements for deviation. Therefore, the total dimension of the second descriptor is 223 (6+48+80+80+9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification</head><p>In the second phase of our experiments we have used a supervised multi-class classifier based on random forest classifier (RF) and a proposed similarity score calculation.</p><p>Random Forest (RF) is a machine learning technique that builds a forest of classification trees where each tree is grown on a bootstrap sample of the data, and the attribute at each tree node is selected from a random subset of all attributes. The final classification of an individual is determined by voting over all trees in the forest. Indeed, there are many advantages of using RF method, that make it an ideal approach for the analysis of biological data. First, it can handle a large number of input attributes -both qualitative and quantitative-. Second, it estimates the relative importance of features in determining classification. Third, RF is fairly robust in the presence of etiological heterogeneity and relatively high amounts of missing data.</p><p>For the kind of tree we have used Classification And Regression Tree (CART), and ours RF is composed of 500 tree.</p><p>The extracted computer generated (CoG) features and the RF are used to predict the following property separately:</p><p>Is Central Localized, Is Contrasted, Is Gallbladder Adjacent, Is Peripherical Localized, Is Subcapsular Localized, Has Lesion Quantity, Has Area Density, Has Area Shape, Has Area Margin Type, Has Density, Has Lesion Contrast Uptake, Has Lesion Contrast Pattern, Has composition, Has Lesion Vein Proximity, Is Located In Segment, Is Close To Vein. The property "Is Located In Lobe "is estimated according the property " Is Located In Segment ".i.e. if segment is {II,III,IV} the lesion lobe is the left lobe, if the seg-ment{V,VI,VII,VIII} the lesion lobe is the right lobe, and caudate Lobe for segment I. The height and the width of lesion are extracted directly from image.</p><p>For remaining UsE (see Table1), we used the proposed similarity score calculation between the unannotated image (U) and a training image (T) as the distance between their respective features vectors is given as bellow:</p><formula xml:id="formula_4" coords="6,245.52,471.94,104.85,28.35">1 | | ( , )<label>1</label></formula><formula xml:id="formula_5" coords="6,227.28,470.71,243.36,30.78">d i i i i u t Sim U T v     <label>(5)</label></formula><p>Where v i was the i-th maximum feature in dataset, u i was the i-th feature in the feature vector of U, t i was the i-th feature in the feature vector of T, and d was the dimensionality of the feature set. Thereafter, we selected the five most similar images, the label that has the majority voting will be assigned to the UsE. Our second method uses the signature of the liver. To do that, we have taken a slice from 3D Liver CT scans localized at lesion center. First, we normalized the liver into a rectangular block with constant dimensions to account for imaging inconsistencies. The size of the normalized block is (200×190).The retrieval process is illustrated in figure1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parenchyma</head><formula xml:id="formula_6" coords="9,221.04,151.48,245.68,22.87">f f G f f    (<label>6</label></formula><formula xml:id="formula_7" coords="9,466.72,154.93,3.92,8.85">)</formula><p>Where f 0 represents the centre frequency, and σ gives the bandwidth of the filter.</p><p>Thereafter we divided the output of filtering into a small blocks of size (5×5), consequently the size of template becomes (40×38).</p><p>Finally, the dominant angular direction of each block was extracted and quantized to four levels, using the Daugman method, where each angular direction produced two bits of data <ref type="bibr" coords="9,194.88,259.57,15.26,8.85" target="#b11">[12]</ref>. Indeed when going from one quadrant to another, only 1 bit changes. Figure <ref type="figure" coords="9,190.80,271.57,5.04,8.85" target="#fig_2">2</ref> shows the phase quantization. The encoding process produces a bitwise template containing a number of bits of information, the final size of template is 40×76. For the retrieval task, the Hamming distance was employed. This distance gives a measure of how many bits are the same between two bit patterns.</p><p>In comparing with the bit patterns X and Y, the Hamming distance, HD, is defined as the sum of disagreeing bits (sum of the exclusive-OR between X and Y) over N, the total number of bits in the bit pattern. </p><formula xml:id="formula_8" coords="9,206.16,519.67,243.04,29.58">1 ( ) N j j j HD X XOR Y N    (7)</formula><p>Thereafter, we selected the five most similar images, and the label that has the majority voting will be assigned to the UsE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>We submitted three run to the ImageCLEF2015 liver annotation challenge, two of them for the first method with two different feature sets, and the last for the second method. The runs were evaluated on accuracy, the percentage of completed questions with a correct answer, and completeness, the percentage of question that was answered. Finally, the total score is given as: The results show that all of our runs achieved good scores (&gt;90). In general, there were no large difference between the scores, especially for the first method , where we have used two different descriptors (as stated in section 4.1).</p><formula xml:id="formula_9" coords="10,205.92,152.90,264.72,10.47">TotalScore Compl Accuracy etness  <label>(8)</label></formula><p>Descriptor 1 (run1): include texture features of liver and shape features. Descriptor 2 (run2): include texture features of lesion and shape features.</p><p>The score obtained from the first and the second descriptor are respectively 90.4% and 90.2% ,this small difference shows that texture features of liver is more descriptive than the texture features of lesion. We achieved a completeness score of 99% for every run, and accuracy of 84% given by the second method. The results presented in table <ref type="table" coords="10,256.54,485.65,5.04,8.85">4</ref> shows that the scores obtained by the three runs for Liver group and Vessel group are the same. One explanation for this could be that there were instances where all the training samples had the same annotation.</p><p>We notice that the second method outperform the first method in the other groups, which shows its efficacy.</p><p>For the first method ,descriptor 1 (run1) gives a best discrimination of lesion component compared to the descriptor 2 (run2) ,in this case the texture features of liver is more suitable than texture features of lesion, in the other hand the properties of area lesion were well described by the texture features of lesion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper we have presented the methods submitted to the liver annotation task of imageCLEF2015. In the first method we have used a classification approach, and in the second method we have used a specific signature of the liver.</p><p>Our three runs achieved scores (&gt;90), and a completeness level of 99% .There were no large differences between scores, and the best accuracy level is 84% given by the second method.</p><p>In our futures works we plan to use more image features, and investigate the semantic reasoning by using the information in ONtology of the LIver for RAdiology (ONLIRA).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,219.12,597.64,157.38,8.01"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of the retrieval process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,249.84,406.36,95.78,8.01;9,218.16,292.88,161.52,105.36"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Phase Quantization</figDesc><graphic coords="9,218.16,292.88,161.52,105.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,258.00,543.19,3.45,6.06"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,170.64,181.24,256.72,64.14"><head>Table 2 .</head><label>2</label><figDesc>The score obtained for each run</figDesc><table coords="10,170.64,199.33,256.72,46.05"><row><cell>Run</cell><cell>Method</cell><cell>Score</cell></row><row><cell>1</cell><cell>1</cell><cell>0.904</cell></row><row><cell>2</cell><cell>1</cell><cell>0.902</cell></row><row><cell>3</cell><cell>2</cell><cell>0.910</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,126.48,380.68,312.96,89.34"><head>Table 3 .</head><label>3</label><figDesc>The test results for each group</figDesc><table coords="10,126.48,398.77,312.96,71.25"><row><cell>Group</cell><cell>Run1</cell><cell>Run2</cell><cell>Run3</cell></row><row><cell>Liver</cell><cell>0.925</cell><cell>0.925</cell><cell>0.925</cell></row><row><cell>Vessel</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell></row><row><cell>LesionArea</cell><cell>0.730</cell><cell>0.746</cell><cell>0.753</cell></row><row><cell>LesionLesion</cell><cell>0.470</cell><cell>0.470</cell><cell>0.480</cell></row><row><cell>LesionComponent</cell><cell>0.870</cell><cell>0.844</cell><cell>0.889</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,127.68,686.20,280.92,8.01"><p>Java API for creating, parsing, manipulating and serialising OWL Ontologies.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The authors would like to thank the organizers of the ImageCLEF 2015 liver annotation task for making the database available for the experiments.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,155.28,177.97,315.27,8.85;12,144.00,189.97,310.17,8.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,238.38,177.97,191.19,8.85">ImageCLEF Liver CT Image Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,144.00,189.97,172.89,8.85">CLEF 2014 Evaluation Labs and Workshop</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>Online Working Notes</note>
</biblStruct>

<biblStruct coords="12,155.28,204.85,315.26,8.85;12,144.00,216.85,326.65,8.85;12,144.00,228.85,326.76,8.85;12,144.00,240.85,91.08,8.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,148.84,216.85,264.03,8.85">Overview of the ImageCLEF 2015 liver CT annotation task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mar</forename><surname>Roldan Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aldana</forename><forename type="middle">J F</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,426.24,216.85,44.41,8.85;12,144.00,228.85,66.45,8.85">CLEF2015 Working Notes</title>
		<title level="s" coord="12,225.58,228.85,141.48,8.85">Workshop Proceedings.CEUR-WS</title>
		<imprint>
			<date type="published" when="1613">1613-0073. September 8-11. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,255.97,315.36,8.85;12,144.00,267.97,326.58,8.85;12,144.00,279.97,326.71,8.85;12,144.00,291.97,191.65,8.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,372.32,255.97,98.32,8.85;12,144.00,267.97,305.78,8.85">Automatic annotation of liver ct images: the submission of the bmet group to imageclefmed 2014</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">H W</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kim</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,144.00,279.97,153.29,8.85">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="12,310.13,279.97,160.58,8.85;12,144.00,291.97,91.57,8.85">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,306.85,315.31,8.85;12,144.00,318.85,326.81,8.85;12,144.00,330.85,295.09,8.85" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,433.97,306.85,36.62,8.85;12,144.00,318.85,245.16,8.85">Semantic Description of Liver CT Images: An Ontological Approach</title>
		<author>
			<persName coords=""><forename type="middle">N</forename><surname>Kökciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yolum</forename><forename type="middle">S P</forename><surname>Üsküdarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bakir</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Acar</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,402.48,318.85,68.33,8.85;12,144.00,330.85,139.85,8.85">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1363" to="1369" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,345.97,315.12,8.85;12,144.00,357.97,326.88,8.85;12,144.00,369.97,47.64,8.85" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,231.90,345.97,229.92,8.85">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="12,144.00,357.97,142.53,8.85">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="302" to="9743" />
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,384.85,315.29,8.85;12,144.00,396.85,326.63,8.85;12,144.00,408.85,72.11,8.85" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,228.04,384.85,224.34,8.85">ImageCLEF 2014: Overview and analysis of the results</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,144.00,396.85,78.23,8.85">CLEF proceedings</title>
		<title level="s" coord="12,233.76,396.85,158.94,8.85">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,423.97,315.51,8.85;12,144.00,435.97,326.94,8.85;12,144.00,447.97,326.78,8.85;12,144.00,459.97,140.29,8.85" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,286.87,423.97,183.92,8.85;12,144.00,435.97,280.51,8.85">Towards content-based image retrieval: From computer generated features to semantic descriptions of liver ct scans</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Spanier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,446.37,435.97,24.57,8.85;12,144.00,447.97,111.76,8.85">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="12,265.70,447.97,205.08,8.85;12,144.00,459.97,40.11,8.85">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,474.85,315.07,8.85;12,144.00,486.85,326.64,8.85;12,144.00,498.85,235.81,8.85" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,267.51,474.85,202.84,8.85;12,144.00,486.85,49.58,8.85">Liver ct annotation via generalized coupled tensor factorization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cemgil</forename><forename type="middle">A T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,217.89,486.85,139.37,8.85">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="12,366.71,486.85,103.93,8.85;12,144.00,498.85,135.74,8.85">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,513.97,315.24,8.85;12,144.00,525.97,326.76,8.85;12,144.00,537.97,130.67,8.85" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,354.81,513.97,115.71,8.85;12,144.00,525.97,54.19,8.85">Textural Features for Image Classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shanmugam</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dinstein</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,209.04,525.97,212.65,8.85">IEEE Transaction on Systems ,Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973-11">November 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,552.85,315.37,8.85;12,144.00,564.85,326.66,8.85;12,144.00,576.85,188.02,8.85" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,271.29,552.85,199.36,8.85;12,144.00,564.85,151.81,8.85">Texture Analysis of SAR Sea Ice Imagery Using Gray Level Co-Occurrence Matrices</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">K</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tsatsoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,309.12,564.85,161.54,8.85;12,144.00,576.85,61.93,8.85">IEEE transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1999">MARCH 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,591.97,315.32,8.85;12,144.00,603.97,326.79,8.85;12,144.00,615.97,165.71,8.85" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,280.42,591.97,190.18,8.85;12,144.00,603.97,229.33,8.85">A fuzzy rule-based approch for characterization of mammogram masses into BI-RADS shape categories</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vadivel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Surendiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,384.48,603.97,86.31,8.85;12,144.00,615.97,52.85,8.85">Computer in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="259" to="267" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,155.28,630.85,315.24,8.85;12,144.00,642.85,189.49,8.85" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,212.98,630.85,107.62,8.85">How iris recognition works</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,332.88,630.85,137.64,8.85;12,144.00,642.85,130.36,8.85">Proceedings of 2002 International Conference on Image Processing</title>
		<meeting>2002 International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
