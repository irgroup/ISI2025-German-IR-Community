<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.01,116.95,343.32,12.62;1,193.88,134.89,227.60,12.62">CIS UDEL Working Notes on ImageCLEF 2015: Compound figure detection task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.66,172.56,63.93,8.74"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
							<email>xiaolong@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.44,172.56,69.39,8.74"><forename type="first">Xiangying</forename><surname>Jiang</surname></persName>
							<email>jiangxy@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.52,172.56,88.61,8.74"><forename type="first">Abhishek</forename><surname>Kolagunda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,389.75,172.56,61.99,8.74;1,451.74,170.98,1.36,6.12"><forename type="first">Hagit</forename><surname>Shatkay</surname></persName>
							<email>shatkay@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.58,184.51,103.80,8.74;1,355.38,182.94,1.36,6.12"><forename type="first">Chandra</forename><surname>Kambhamettu</surname></persName>
							<email>chandrak@udel.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>DE</region>
									<country>US</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.01,116.95,343.32,12.62;1,193.88,134.89,227.60,12.62">CIS UDEL Working Notes on ImageCLEF 2015: Compound figure detection task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">07EABBB1AE6CED6E8753C064734B6287</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Compound figure detection</term>
					<term>visual information</term>
					<term>biomedical image analysis</term>
					<term>image classification</term>
					<term>ImageCLEF 2015</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figures that are included in biomedical publications play an important role in understanding essential aspects of the paper. Much work over the past few years has focused on figure analysis and classification in biomedical documents. As many of the figures appearing in biomedical documents comprise multiple panels (subfigures), the first step in the analysis requires identification of compound figures and their segmentation into subfigures. There is a wide variety ways to detect compound figures. In this paper, we utilize only visual information to identify compound vs non-compound figures. We have tested the proposed approach on the ImageCLEF 2015 benchmark of 10, 434 images; our approach has achieved an accuracy of 82.82%, thus demonstrating the best performance when compared to other systems that use only visual information for addressing the compound figure detection task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Figure classification and understanding within the biomedical literature has attracted much research interest over the past years. Figures included in biomedical publications form a necessary source of knowledge and understanding. Most of the works on image analysis within biomedical documents aim at recognizing different biomedical image categories. Notably, figures appearing within biomedical documents are often compound, that is, they comprise multiple panels that are typically referred to as subfigures. Categorization and analysis of images usually requires working at the subfigure level, and as such, a primary step in the analysis is the identification of compound figures and their segmentation into subfigures <ref type="bibr" coords="1,181.39,614.57,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,193.57,614.57,7.01,8.74" target="#b5">6]</ref>.</p><p>Over the past few years, several approaches were proposed for compound figure segmentation, within the field of biomedical image retrieval <ref type="bibr" coords="1,408.24,638.48,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,420.42,638.48,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="1,429.82,638.48,7.01,8.74" target="#b5">6]</ref>. Previous work can be categorized into two main schemes: The first is based on the analysis of peak region detection within the image; the peak region is then used as a reference to find separating lines for segmentation <ref type="bibr" coords="2,356.24,143.90,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,368.42,143.90,7.01,8.74" target="#b7">8]</ref>. The main drawback of this scheme is that it is susceptible to noise and may lead to over-segmentation <ref type="bibr" coords="2,134.77,167.81,9.96,8.74" target="#b7">[8]</ref>. This issue is especially prevalent in irregular compound figures, where the separators between different subfigures do not cut across a complete row or column. Moreover, setting up the threshold value for segmentation with respect to a peak region is not straightforward -different thresholds usually lead to different results. For instance, Chhatkuli et al. <ref type="bibr" coords="2,317.18,215.63,10.52,8.74" target="#b1">[2]</ref> set the threshold at 0.97 times the maximum value in a given figure. This threshold value is based on manual tests over the training data. Another factor is the occurrence of text within figures. As text is irregular, it can be an obstacle for obtaining the segmentation lines <ref type="bibr" coords="2,134.77,263.45,9.96,8.74" target="#b1">[2]</ref>. Removing text from a compound figure usually plays an important role in the final result.</p><p>The second scheme is based on connected components analysis <ref type="bibr" coords="2,434.28,287.36,9.96,8.74" target="#b4">[5]</ref>, as was done in earlier work <ref type="bibr" coords="2,224.99,299.32,9.96,8.74" target="#b5">[6]</ref>. The general idea is to evaluate the connectivity among different subfigures within a compound figure using visual information. Connected components analysis groups the pixels into different components using similarity in pixel values. Pixels in each resulting component share similar values. Once different connected regions are formed, the boundary between different regions can be used as segmentation lines separating different components. In this work, the analysis of connected components is applied first to the given figure, while we also add several post-processing steps. These post-processing steps help improve compound figure detection. We then integrate the two different schemes. The experimental results demonstrate that the fusion scheme can help improve performance compared to each of the individual schemes applied alone.</p><p>The rest of the paper is organized as following. In Section 2, we provide an overview of the datasets. The proposed compound figure detection approach is discussed in Section 3. The analysis of component connectivity based scheme is discussed first, followed by a presentation of the peak region detection scheme and the fusion scheme. Section 4 presents the experimental results submitted to the ImageCLEF 2015. In the end, conclusions are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>In our experiments, we use the dataset provided in the ImageCLEFmed 2015 benchmark. We refer the reader for more details to the respective task description <ref type="bibr" coords="2,155.48,567.88,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="2,167.66,567.88,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="2,177.07,567.88,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="2,186.48,567.88,7.01,8.74" target="#b3">4]</ref>. In this report, we focus on the medical image classification task <ref type="bibr" coords="2,134.77,579.84,10.52,8.74" target="#b2">[3]</ref> and specifically on compound figure detection. Notably, we use only visual information for addressing this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>In this report, we first discuss the proposed compound figure detection scheme, where we illustrate the details of our detection method, utilizing only visual in-formation. As shown in the ImageCLEF15 comparison of the results with those obtained by other systems, our approach achieves the highest level of performance among schemes that use only visual information, while its accuracy is only 2.57% lower than that of the top performing scheme, which combines visual and textual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Connected Component Analysis Based Scheme</head><p>The first part of our compound figure detection scheme is based on the analysis of component connectivity of subfigures in an image <ref type="bibr" coords="3,370.29,226.73,9.96,8.74" target="#b4">[5]</ref>. This scheme is based on graph traversal theory. The general idea is to determine the connectivity of the current pixel to neighboring pixels based on pixel-intensity; the method is both effective and simple to implement.</p><p>The general scheme of connected component analysis used in our work is as follows: First, RGB images are converted into grayscale images. Then we rescale the pixel intensities in the whole image into values in the range [0, 1]. The underlying assumption is that the boundary between subfigures typically consists of white pixels. The white area is defined as the region where pixel values are consistently greater than 0.9; other regions are defined as black regions. By comparing the image intensities to this threshold value, we can get the mask image M . M is a binary image as indicated in Fig. <ref type="figure" coords="3,366.64,358.24,3.87,8.74" target="#fig_0">1</ref>. In this work, the white color represents the foreground and black indicates the background region. The connected components are extracted based on the mask binary image M .</p><p>After that, we scan the resulting, simplified image pixel-by-pixel (top to bottom and left to right). Connected regions in which adjacent pixels share a similar range of intensity values [v 0 , v 1 ] are identified. The connected components labeling operator scans the whole image by moving along each row until it reaches a pixel p which has not been previously labeled. If pixel p is not labeled in the previous stage, we examine two p s predecessor neighboring pixels directly up (denoted p u ), and to the left (p l ). The label value assigned to pixel p is based on the comparison with these two neighboring pixels.</p><p>After scanning the whole image, each detected component in the figure is labeled with a different value. An important issue for compound figure detection is to minimize the influence of false positive area where non-compound regions are misclassified as compound regions. Most of these false positive areas are caused by the connected text. To address this issue, rather than directly removing text from the images <ref type="bibr" coords="3,224.81,549.52,9.96,8.74" target="#b1">[2]</ref>, we apply a criterion based on the ratio evaluation among regions' areas. Two different ratio criteria are used in this work. The first ratio value T r1 is defined as the ratio between area of the detected subfigure and the whole figure. If T r1 is smaller than 0.1, then this region is classified as false positive. The second ratio value T r2 is calculated based on the area ratio between the detected components and the maximum component. If the ratio value T r2 is smaller than 0.15, the detected region is classified as false positive. This setting has proven effective in our experiments as illustrated in Fig. <ref type="figure" coords="3,400.36,633.20,3.87,8.74" target="#fig_0">1</ref>.</p><p>The illustration of the whole scheme is presented in Fig. <ref type="figure" coords="3,397.08,645.16,3.87,8.74" target="#fig_3">4</ref>. If more than one subfigure is detected, the given figure is classified as compound figure, otherwise not. To handle compound figures separated by black rather than white regions, we invert all images and perform subfigure detection using the same procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Peak Region Detection Based Scheme</head><p>Besides the connected component analysis method described above, we also test the performance of directly using pixel intensity to segment the figure as used in works <ref type="bibr" coords="4,162.84,204.83,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="4,175.02,204.83,7.01,8.74" target="#b7">8]</ref>. The idea of this method is to find white margins based on the pixel intensity. As indicated in Fig. <ref type="figure" coords="4,262.71,216.78,3.88,8.74" target="#fig_1">2</ref>, the images are scanned in two directions, namely along the x-axis and along the y-axis. Both scanning processes are conducted iteratively until no more white margins are detected.</p><p>Consider an image I represented as a matrix I(x, y), where x is the row index and y is the column index; let W and H be the total number of rows and columns, respectively. Assuming that the subfigures are separated by white margins, the first step is pixel projections operation along the x-axis and along the y-axis as indicated in Fig. <ref type="figure" coords="4,268.13,300.47,3.87,8.74" target="#fig_1">2</ref>. Formally:</p><formula xml:id="formula_0" coords="4,242.79,321.20,237.80,24.60">I x = min I(x, y) y∈ [1, ..., H], I y = min I(x, y) x∈ [1, ..., W ],<label>(1)</label></formula><p>that is, I x is a candidate separating row and I y is a candidate separating column. The next step is to find a peak region within I x and I y . The peak region indicates an area located within the continuous region whose pixel value is greater than a predefined threshold. In this work, considering the noise and other influential factors, the threshold is set to 0.85 times of the maximum pixel intensity in the whole image. By comparing with the threshold, we can find the peak region along I x and I y vector. From this, we obtain the index and the region width. These peak regions are regarded as the margin between subfigures. Based on these detected margins, the subfigure region is then calculated. For a specific testing image, to get rid of false positives and minimize the influence of the text region, two different post-processing steps are applied. First, we set a threshold on the minimum area of a detected peak region. Another criterion is to measure the ratio value calculated between the current segmented area and the maximum segment detected. If the ratio is smaller than 0.3, the detected segmentation region is classified as false positive. If more than one sub-region is detected, input figure is classified as compound, otherwise not. As before, this method assumes that the separation between sub-figures consists of white pixels. To also consider black separators, if the figure is not classified as compound, we invert the image and go through the processing steps discussed above again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fusion Scheme</head><p>In our work, we also fuse the above two different schemes -connected component analysis is used as the first step and if no compound figure is detected, peak region detection is applied as the second step.</p><p>An illustration of the proposed scheme is shown in Fig. <ref type="figure" coords="5,388.13,119.99,3.87,8.74" target="#fig_2">3</ref>. Our results showed that connectivity component analysis is good at removing false positives caused by text regions. However, it is not as effective for detecting compound figures consisting of graph images (e.g. line graphs or diagrams). These types of compound figures can be detected using peak region detection approach. We conducted a standalone comparison between the proposed different schemes to evaluate their respective performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We evaluated the proposed approach on ImageCLEF 2015 benchmark, which includes 10,434 different figures. Several illustrations of the experimental results are provided in Fig. <ref type="figure" coords="5,226.37,272.55,3.87,8.74" target="#fig_3">4</ref>. The overall accuracy is calculated as accuracy = Cg C × 100%, where C g represents the number of correctly detected figures and C is the total number of samples in the set. In addition, we also consider the well-known recall and precision measures, as shown in Table <ref type="table" coords="5,347.63,308.42,3.87,8.74" target="#tab_0">1</ref>. The latter two measures are calculated as:</p><formula xml:id="formula_1" coords="5,255.17,350.43,225.42,47.51">P recision = T P T P + F P , Recall = T P T P + F N ,<label>(2)</label></formula><p>where T P is the number of true positives (compound figures) detected by the proposed scheme, F P is the number of false positives (figures that are noncompound, but labeled as compound by our scheme), and F N is the number of false negatives (figures that are compound, but not detected as such by the proposed approach). As listed in Table <ref type="table" coords="5,233.03,468.58,3.87,8.74" target="#tab_0">1</ref>, the connected component analysis based scheme performs better than the peak-region detection based scheme. By combining the two different schemes, we have obtained an accuracy of 82.82% on the test dataset.</p><p>For the sake of completeness, we also demonstrate several cases, shown in Fig. <ref type="figure" coords="5,155.32,516.51,3.87,8.74" target="#fig_4">5</ref>, in which our system fails to detect or to correctly segment a compound figure. As illustrated by Fig. <ref type="figure" coords="5,263.03,528.46,4.10,8.74" target="#fig_4">5</ref>(a), when the boundaries between subfigures are thin, although our algorithm can correctly classify the given compound figure, the sub-figure segmentation does not work well. Moreover, segmenting diagrams remains a challenge, as indicated in Fig. <ref type="figure" coords="5,312.78,564.33,16.83,8.74" target="#fig_4">5(b)</ref>. Over-segmentation is still a common problem for this kind of non-compound figures <ref type="bibr" coords="5,363.56,576.29,9.96,8.74" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work, we have studied the problem of compound figure detection. Two different schemes, as well as an integration of the two, are evaluated. Our integrated scheme outperforms the other systems that use only visual information, participating in this challenge, by more than 10%. In this challenge, the only system outperforming this system (by 2.57%) used a combination of textual and visual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>This work was supported by NIH Award 1R56LM011354-01A1.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,134.77,592.36,345.82,7.89;7,134.77,603.34,345.82,7.86;7,134.77,614.30,345.81,7.86;7,134.77,625.26,30.79,7.86;7,157.48,147.62,300.40,420.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of compound figure detection scheme using connected components analysis. The mask image correspond to M . The final result is based on the postprocessing of the initial figure result. The areas surrounded by blue lines are segmented regions.</figDesc><graphic coords="7,157.48,147.62,300.40,420.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,134.77,335.02,345.81,7.89;8,134.77,346.01,345.81,7.86;8,134.77,356.97,345.81,7.86;8,134.77,367.93,345.81,7.86;8,134.77,378.88,44.34,7.86;8,172.90,152.11,269.55,158.18"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of peak region detection based scheme. The minimum value of the projection along x-axis and y-axis is first obtained as indicated by the arrow. The continuous peak region calculated from the minimum value vector represents the long margin. Based on the peak region of of this vector, a compound figure is detected and segmented.</figDesc><graphic coords="8,172.90,152.11,269.55,158.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,144.21,620.74,326.92,7.89;8,173.13,465.28,269.10,130.73"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of the proposed fusion scheme for compound figure detection.</figDesc><graphic coords="8,173.13,465.28,269.10,130.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,155.00,372.06,305.34,7.89;9,163.00,132.00,289.35,215.33"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Examples of several different compound figure segmentation results.</figDesc><graphic coords="9,163.00,132.00,289.35,215.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,134.77,618.94,345.81,7.89;9,134.77,629.92,345.82,7.86;9,134.77,640.88,25.11,7.86;9,159.52,418.26,296.33,175.95"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Illustration of two failure cases obtained in the experiments. (a) Undersegmentation of the compound figure. (b) Over-segmentation of the non-compound figure.</figDesc><graphic coords="9,159.52,418.26,296.33,175.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,184.87,116.91,244.91,61.94"><head>Table 1 .</head><label>1</label><figDesc>Comparison results between proposed approaches.</figDesc><table coords="6,185.58,137.71,244.20,41.14"><row><cell>Approach</cell><cell>Accuracy Precision Recall</cell></row><row><cell cols="2">Component connectivity analysis 82.47% 82.48% 72.84%</cell></row><row><cell>Peak region detection</cell><cell>81.04% 84.94% 73.23%</cell></row><row><cell>Fusion scheme</cell><cell>82.82% 86.06% 69.49%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,351.77,342.23,7.86;6,146.91,362.73,333.66,7.86;6,146.91,373.68,184.24,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,292.04,351.77,188.53,7.86;6,146.91,362.73,41.49,7.86">Overview of the ImageCLEF 2015 medical clustering task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,206.40,362.73,229.24,7.86">CLEF2015 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,384.64,342.23,7.86;6,146.91,395.60,333.66,7.86;6,146.91,406.56,333.67,7.86;6,146.91,417.52,127.47,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,195.02,395.60,285.56,7.86;6,146.91,406.56,49.79,7.86">Separating compound figures in journal articles to allow for subfigure classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chhatkuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Markonis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Meriaudeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,214.30,406.56,86.16,7.86">SPIE medical imaging</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="86740J" to="86740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,428.48,342.22,7.86;6,146.91,439.44,333.66,7.86;6,146.91,450.40,333.66,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,366.12,428.48,114.46,7.86;6,146.91,439.44,124.17,7.86">Overview of the ImageCLEF 2015 medical classification task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,290.21,439.44,190.37,7.86;6,146.91,450.40,73.32,7.86">Working Notes of CLEF 2015 (Cross Language Evaluation Forum)</title>
		<title level="s" coord="6,226.97,450.40,144.47,7.86">CEUR Workshop Proceedings. CEUR</title>
		<imprint>
			<date type="published" when="2015-09">September 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,461.36,342.22,7.86;6,146.91,472.31,333.66,7.86;6,146.91,483.27,333.67,7.86;6,146.91,494.23,322.54,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,231.33,472.31,249.25,7.86;6,146.91,483.27,172.68,7.86">Overview of the ImageCLEF 2015 Scalable Image Annotation, Localization and Sentence Generation task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dellandrea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="6,340.47,483.27,140.11,7.86;6,146.91,494.23,89.74,7.86">CLEF2015 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11">September 8-11 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,505.19,314.14,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,266.92,505.19,97.96,7.86">Digital Image Processing</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Richard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,516.15,342.22,7.86;6,146.91,527.11,223.37,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,304.82,516.15,175.75,7.86;6,146.91,527.11,54.97,7.86">Integrating image data into biomedical text categorization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shatkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blostein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,209.90,527.11,57.94,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="446" to="e453" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,538.07,342.23,7.86;6,146.91,549.03,333.67,7.86;6,146.91,559.99,333.67,7.86;6,146.91,570.94,333.66,7.86;6,146.91,581.90,124.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,398.44,559.99,82.14,7.86;6,146.91,570.94,144.60,7.86">General Overview of ImageCLEF at the CLEF 2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Del Mar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roldán</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,299.53,570.94,140.41,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,592.86,342.23,7.86;6,146.91,603.82,333.67,7.86;6,146.91,614.78,100.34,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,237.00,592.86,243.58,7.86;6,146.91,603.82,124.38,7.86">A novel figure panel classification and extraction method for document image understanding</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,279.33,603.82,201.26,7.86;6,146.91,614.78,24.57,7.86">International journal of data mining and bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
