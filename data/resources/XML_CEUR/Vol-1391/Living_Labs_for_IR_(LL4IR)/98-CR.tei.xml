<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.79,115.90,291.77,12.90">Probabilistic Field Mapping for Product Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,210.42,153.95,112.34,8.64"><forename type="first">Aman</forename><forename type="middle">Berhane</forename><surname>Ghirmatsion</surname></persName>
							<email>ab.ghirmatsion@stud.uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.12,153.95,62.81,8.64"><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
							<email>krisztian.balog@uis.no</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Stavanger</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.79,115.90,291.77,12.90">Probabilistic Field Mapping for Product Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA5EB50B27010D1AD3587DF38DD8C894</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the product search task of the CLEF 2015 LL4IR Lab. Working within a generative language modeling framework, we represent products as semi-structured documents. Our focus is on establishing a probabilistic mapping from query terms to document fields. We present and experimentally compare three alternatives. Our results show that term-specific mapping is beneficial. We also find evidence suggesting that estimating field mapping priors based on historical clicks outperforms the setting where the priors are uniformly distributed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online shopping has become a common practice and one of the most popular activities people perform on the Internet. Its success can be credited to ease and convenience, large selection of products, 24/7-availability, low pricing, just to mention some of the benefits. Just with any other website or online service, effective information retrieval systems are indispensable for e-commerce sites. Webshops need to offer search functionality that makes their available products easy to find. Providing customers with a positive shopping experience can increase sales, and is thereby essential to success of the business. Users are accustomed to the "single search box" paradigm and expect the search engine to understand their information need. In this paper we address the task of ad-hoc product search, defined as follows: given a keyword query, return a ranked list of products from a product catalog that are relevant to the query.</p><p>Products are described by a number of attributes, such as name, brand, description, categories, and so on. These attributes have a specific semantic meaning (one that can even be known a priori), albeit the amount of text associated with each is typically rather small. Recognizing for each query term which of the product attributes (if any) is targeted, therefore, is believed to lead to improved retrieval performance. Our objective in this work is to develop, implement, and evaluate methods that establish a mapping from individual query terms to specific product fields. We represent products as semistructured documents (following the predominant approach to entity retrieval <ref type="bibr" coords="1,448.32,572.75,11.20,8.64" target="#b0">[1]</ref>) and employ the Probabilistic Retrieval Model for Semistructured Data (PRMS) <ref type="bibr" coords="1,432.78,584.71,10.58,8.64" target="#b1">[2]</ref>, a model that is known to perform well under conditions where the collection is homogeneous and fields have distinctive term distributions <ref type="bibr" coords="1,314.23,608.62,10.58,8.64" target="#b0">[1]</ref>. Our setting is exactly like that. Given the inherent uncertainty, the term-field mapping is represented as probability distribution over fields. We decompose the estimation into term-field probability and prior field probability components and propose three specific instantiations of the PRMS model. We evaluate our approaches and report results using the LL4IR platform. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task and Data</head><p>We address the task of ranking products (from a product catalog) in response to a (short) keyword query. In this section we resort to a brief description of what and how we used from the living labs API in our participation. For a detailed description of the task and setup, we refer to the LL4IR Lab overview paper <ref type="bibr" coords="2,332.31,334.37,10.58,8.64" target="#b4">[5]</ref>.</p><p>For each query, the living labs platform makes a set of candidate products available via the doclist API endpoint. For each of these products, the details can be requested via the doc API endpoint, which provides a product description in the form of key-value pairs. We built a single Lucene index from all unique products made available to us (i.e., products from all doclists) with the fields shown in Table <ref type="table" coords="2,432.75,394.15,3.74,8.64" target="#tab_0">1</ref>. Note that contents is a catch-all field that does not come from the API; it is the concatenation of all field content associated with the product, created at indexing time. In addition, we also used the historical API endpoint to obtain aggregated click-through rate (CTR) for the training queries.</p><p>We produce rankings offline using the retrieval framework and field-mapping methods described in Sections 3 and 4. Once uploaded to the API, these are interleaved with and compared against the site's production ranking system. The numbers reported in Section 5 are obtained via the outcome API endpoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Retrieval Framework</head><p>We base our approach on a generative language modeling framework. Language models provide a transparent and effective means for incorporating structural cues. They are especially appropriate under circumstances where training data is scarce. Our goal with this section is merely to present a brief introduction to the general framework and notation we use, thereby making the paper self-contained; for a more detailed description of these models we refer the reader to <ref type="bibr" coords="2,287.48,600.01,10.58,8.64" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Standard Language Modeling Approach</head><p>The standard language modeling approach works as follows. Given a query q and a document d, the relevance of the document with regard to the query can be expressed as the conditional probability P (d|q). Using Bayes theorem, P (d|q) is rewritten as shown in Eq. 1 below. Since the P (q) is identical for all candidate documents, it can be safely discarded. Thus, the posterior probability P (d|q) is given by the product of query generation probability P (q|d) and document prior probability P (d):</p><formula xml:id="formula_0" coords="3,228.67,175.60,251.92,22.31">P (d|q) = P (q|d)P (d) P (q) ≈ P (q|d)P (d).<label>(1)</label></formula><p>Assuming uniform document priors, the ranking of documents is then proportional to P (q|d). The simplest solution to estimating this probability is by assuming a bag-ofwords document representation. We let θ d be an unigram document language model where P (t|θ d ) expresses the probability of term t given the document. Ranking documents is done according to the probability that a query q is observed during repeated random sampling from the model of document d (where n(t, q) is the number of times t occurs in q):</p><formula xml:id="formula_1" coords="3,250.17,292.29,230.42,21.69">P (q|θ d ) = t∈q P (t|θ d ) n(t,q) .<label>(2)</label></formula><p>To estimate P (t|θ d ) we use a linear combination of maximum-likelihood document and collection language models (i.e., employ Jelinek-Mercer smoothing):</p><formula xml:id="formula_2" coords="3,218.36,356.20,262.23,9.65">P (t|θ d ) = (1 -λ)P M L (t|d) + λP M L (t|C),<label>(3)</label></formula><p>where P (t|d) and P (t|C) are relative frequencies of term t in the document and in the collection, respectively, and λ is the smoothing parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mixture of Language Models</head><p>The standard language modeling approach treats the document as "flat text," and is not able to make use of various document fields. An extension called Mixture of Language Models (MLM) is proposed by Ogilvie and Callan <ref type="bibr" coords="3,334.33,463.64,10.58,8.64" target="#b2">[3]</ref>, where a separate language model is calculated for each document field, and these field language models are then combined into a single document-level representation. Under this approach the document language model is taken to be:</p><formula xml:id="formula_3" coords="3,251.51,522.58,229.08,20.14">P (t|θ d ) = f ∈F α f P (t|θ d f ),<label>(4)</label></formula><p>where f is a field from the set of available fields F , α f is the relative importance of the field such that f ∈F α f = 1, and θ d f is a field-specific language model. The field language model can be estimated the same way as the document language model, except that term occurrences are considered only within the given field (this is indicated by the f subscript):</p><formula xml:id="formula_4" coords="3,206.14,614.38,274.45,10.32">P (t|θ d f ) = (1 -λ f )P M L (t|d f ) + λ f P M L (t|C f ).<label>(5)</label></formula><p>Ogilvie and Callan <ref type="bibr" coords="3,213.00,632.53,11.62,8.64" target="#b2">[3]</ref> suggest to set the field weights proportional to the length of the fields or to their individual retrieval performance. We also use the latter approach in one of our methods. We set the smoothing parameter to be the same for all fields: λ f = 0.1. </p><formula xml:id="formula_5" coords="4,215.60,140.05,174.29,48.72">P (f ) Method 1 1 |F | ∝ NDCG f Method 2 PML(t|C f ) 1 |F | Method 3 PML(t|C f ) ∝ NDCG f</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Probabilistic Retrieval Model for Semistructured Data</head><p>Instead of using a fixed field weight that is the same for all query terms, Kim et al. <ref type="bibr" coords="4,134.77,245.96,11.62,8.64" target="#b1">[2]</ref> propose the use of mapping probabilities. In their approach, called Probabilistic Retrieval Model for Semistructured Data (PRMS), α f in Eq. 4 is replaced with P (f |t): the probability of term t being mapped to field f . The estimation of the document language model then becomes:</p><formula xml:id="formula_6" coords="4,243.36,302.31,237.23,20.14">P (t|θ d ) = f ∈F P (f |t)P (t|θ d f ).<label>(6)</label></formula><p>For estimating the mapping probabilities we again make use of Bayes' theorem:</p><formula xml:id="formula_7" coords="4,208.82,349.46,271.78,24.72">P (f |t) = P (t|f )P (f ) P (t) = P (t|f )P (f ) f ∈F P (t|f )P (f ) ,<label>(7)</label></formula><p>where P (t|f ) can be estimated conveniently by P M L (t|C f ), and P (f ) is a prior mapping probability. We shall present multiple alternatives for setting the components of Eq. 7, P (t|f ) and P (f ), in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Estimating Mapping Probabilites</head><p>We present three specific instantiations of the PRMS model, shown in Table <ref type="table" coords="4,454.48,458.64,3.74,8.64" target="#tab_1">2</ref>, that only differ in the estimation of the mapping probability, given in Eq. 7. This formula has two components that need to be defined: the term-field probability P (t|f ) and the field prior P (f ). Let us point out that MLM can be seen as a special case of PRMS, where P (t|f ) = 1/|F | and P (f ) = α f . The probability of a term occurring in a given field, P (t|f ), can be taken uniform (i.e., 1/|F |) or calculated using the term counts in field f across the whole collection, P M L P (t|C f ), as it is done in the original PRMS approach <ref type="bibr" coords="4,370.92,542.32,10.58,8.64" target="#b1">[2]</ref>.</p><p>For the field prior we consider a uniform and a non-uniform setting. In case of the latter, we capitalize on the fact the we have access to training data that can be used for evaluating the retrieval performance of each field individually. Specifically, we rank training queries based on P (q|θ d f ) and measure retrieval performance in terms of NDCG, averaged over all training queries (denoted as NDCG f ). The gain of a document is set to historical CTR (as provided by the historical feedback API endpoint). P (f ) is then set proportional to NDCG as follows: Table <ref type="table" coords="5,159.03,351.83,4.98,8.64" target="#tab_2">3</ref> shows the individual performances and the estimated priors for the fields in our index. Recall that contents is a catch-all field, containing all content available for the given product.</p><formula xml:id="formula_8" coords="4,252.98,643.18,223.74,24.72">P (f ) = NDCG f f ∈F NDCG f . (<label>8</label></formula><formula xml:id="formula_9" coords="4,476.72,650.24,3.87,8.64">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We report on two sets of experiments: traditional, test collection based offline results on the training queries and online results collected via the living labs platform on the test queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training Queries</head><p>We use historical CTR as ground truth. For binary relevance (MAP and MRR) we consider each product with at least 0.001 CTR as relevant; for graded relevance (NDCG) we use CTR as the gain value. We note that for Methods 1 and 3 we train and test on the same set of queries. The numbers reported here are only meant to show how well the models can be fitted to the data. Table <ref type="table" coords="5,173.52,596.66,4.98,8.64" target="#tab_3">4</ref> presents the results. We find that all three methods perform very similarly for all three metrics. While they achieve virtually perfect MRR, i.e., the first ranked results is always a relevant one, there is room for improvement in terms of MAP and NDCG. Our CTR-based ground truth is likely to be biased based on the site's existing ranking. Therefore, a comparison against the production system would reveal more about the differences between our methods; this is exactly what follows next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Test Queries</head><p>We submitted three rankings corresponding the Methods 1-3, as shown in Table <ref type="table" coords="6,455.24,260.15,3.74,8.64" target="#tab_4">5</ref>. The main evaluation metric is outcome, which is defined as:</p><formula xml:id="formula_10" coords="6,244.11,289.59,236.49,22.31">outcome = #wins #wins + #losses ,<label>(9)</label></formula><p>where the number of wins and losses are measured against the site's production ranking system. Additionally, we report on the total number of impressions and the ratio of wins, losses, and ties. Before discussing our observations, it is important to mention that the way interleaving with the production system is performed has changed from Round #1 to Round #2, to deal correctly with unavailable products (as explained in <ref type="bibr" coords="6,390.54,381.47,10.46,8.64" target="#b3">[4]</ref>). It is therefore believed that the Round #2 results are more reliable. Nevertheless, there are some open questions, such as how many impressions are needed before one can draw firm conclusions, and whether the results obtained in Round #2 are an accurate reflection of the performance of our methods.</p><p>It is immediately apparent that the Round #2 numbers are higher, due to the aforementioned change to interleaving. Outcomes for Round #1 are above the (corrected) expected outcome of 0.28, while for Round #2 they are below the expected outcome of 0.5. For neither round were we able to outperform the organizers' baseline (with an outcome of 0.4691 and 0.5284 for Rounds #1 and #2, respectively), which clearly shows that there is considerable room for improvement.</p><p>Concerning the comparison of Methods 1-3, we make the following observations. All methods received about the same number of impressions, the relative difference between them is within 10%. In over 70% of the cases there is a tie between the experimental and production rankings; this is the same for all three methods. It is clear that Method 1 is the worst performing out of the three; it is expected, as this method is essentially MLM, which performs the field mapping independent of the query terms. As for Method 2 vs. 3, the results are mixed. In Round #1 Method 2 performed slightly better (+4% over Method 3), while in Round #2 Method 3 came first (+9% over Method 2). We further observe that Method 3 has the most ties with the production system and it is also the one with the least number of losses against it. Based on these results we can safely conclude that term-specific mapping is beneficial (Method 1 vs. Methods 2 and 3). There is also evidence suggesting that non-uniform field priors are preferred and that historical CTR offers a simple and intuitive way of setting them (Method 2 vs. 3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis</head><p>In our analysis section we ask the following question: How different are the mappings created by the different methods? We answer this both qualitatively and quantitatively.</p><p>For the former, Table <ref type="table" coords="7,219.67,572.75,4.98,8.64" target="#tab_5">6</ref> shows the estimated mapping probabilities for a number of training queries; we can see that these are indeed different. As for the latter, Table <ref type="table" coords="7,440.74,584.71,4.98,8.64" target="#tab_6">7</ref> presents the Kendall's rank correlation coefficient (τ ); the numbers are averages computed over all queries (both training and test). We observe that the correlation between all three methods is high and that Methods 2 and 3 are more similar to each other than they are to Method 1. The level of similarity (τ = 0.95) between Methods 2 and 3 explains why it is so difficult to decide a winner. Our findings concerning Method 2 vs. 3 (uniform vs. non-uniform field priors) should therefore be taken with a grain of salt. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have described our participation in the product search task of the CLEF 2015 LL4IR Lab. Our focus has been on various field mapping approaches in a language modeling framework, which we compared experimentally. We have shown that using termspecific mapping has a positive effect on retrieval performance. We have also presented evidence suggesting that estimating field mapping priors based on historical clicks outperforms the setting where the priors are uniformly distributed. While we were able to observe interesting differences between our methods, further work is needed to be able to outperform the site's production ranking system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,161.72,115.83,289.99,134.10"><head>Table 1 .</head><label>1</label><figDesc>Fields in our index.</figDesc><table coords="2,161.72,138.52,289.99,111.41"><row><cell>Field</cell><cell>Description</cell></row><row><cell>brand</cell><cell>Product's brand</cell></row><row><cell>category</cell><cell>Leaf level product category</cell></row><row><cell>characters</cell><cell>Characters associated with the product (e.g., Barbie)</cell></row><row><cell>contents</cell><cell>Catch-all contents field</cell></row><row><cell>description</cell><cell>Full textual description</cell></row><row><cell>product name</cell><cell>Product's name</cell></row><row><cell>queries</cell><cell>Queries that led to the product</cell></row><row><cell>main category</cell><cell>Top level product category</cell></row><row><cell cols="2">short description Short textual description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,215.60,115.83,173.92,32.28"><head>Table 2 .</head><label>2</label><figDesc>Overview of field mapping methods.</figDesc><table coords="4,215.60,140.05,85.15,8.06"><row><cell>Method</cell><cell>P (t|f )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,200.62,115.83,214.12,113.99"><head>Table 3 .</head><label>3</label><figDesc>Field priors based on individual field performance.</figDesc><table coords="5,219.85,140.05,171.96,89.77"><row><cell>Field name</cell><cell>NDCG f</cell><cell>P (f )</cell></row><row><cell>Brand</cell><cell>0.0684</cell><cell>0.0240</cell></row><row><cell>Product name</cell><cell>0.5632</cell><cell>0.1989</cell></row><row><cell>Characters</cell><cell>0.3792</cell><cell>0.1339</cell></row><row><cell>Category</cell><cell>0.4305</cell><cell>0.1520</cell></row><row><cell>Description</cell><cell>0.3919</cell><cell>0.1384</cell></row><row><cell>Short description</cell><cell>0.2986</cell><cell>0.1054</cell></row><row><cell>Contents</cell><cell>0.6987</cell><cell>0.2468</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,144.40,248.64,326.55,70.16"><head>Table 4 .</head><label>4</label><figDesc>Offline results for the training queries. Best scores for each metric are in boldface.</figDesc><table coords="5,218.45,273.15,175.49,45.65"><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell><cell>NDCG</cell></row><row><cell>Method 1</cell><cell>0.8118</cell><cell>0.9948</cell><cell>0.7045</cell></row><row><cell>Method 2</cell><cell>0.7916</cell><cell>0.9948</cell><cell>0.7012</cell></row><row><cell>Method 3</cell><cell>0.7997</cell><cell>0.9948</cell><cell>0.7026</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,134.77,115.76,345.82,96.81"><head>Table 5 .</head><label>5</label><figDesc>Online results for the test queries. In addition to outcome, we also report on the total number of impressions (#I) and percentage of wins (%W), losses (%L), and ties (%T). Best scores for each metric are in boldface.</figDesc><table coords="6,143.91,155.97,327.54,56.61"><row><cell>Method Run ID</cell><cell>Round #1 Outcome #I %W %L %T</cell><cell>Round #2 Outcome #I %W %L %T</cell></row><row><cell>Method 1 UiS</cell><cell>0.2827 699 7.7 19.6 72.7</cell><cell>0.4118 731 11.5 16.4 72.1</cell></row><row><cell>Method 2 Mira</cell><cell>0.3413 725 9.8 18.9 71.3</cell><cell>0.4389 757 10.4 13.3 76.2</cell></row><row><cell>Method 3 Jern</cell><cell>0.3277 665 8.7 17.9 73.4</cell><cell>0.4795 767 10.7 11.6 77.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,143.38,115.83,319.23,359.14"><head>Table 6 .</head><label>6</label><figDesc>Field mapping probabilities.</figDesc><table coords="7,143.38,140.33,319.23,334.63"><row><cell>Query</cell><cell>Term</cell><cell>Field name</cell><cell>M1</cell><cell>M2</cell><cell>M3</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.2509 0.2713</cell></row><row><cell></cell><cell></cell><cell>contents</cell><cell cols="3">0.2468 0.2592 0.3509</cell></row><row><cell>baba</cell><cell>baba</cell><cell>category</cell><cell cols="3">0.1520 0.3723 0.3024</cell></row><row><cell></cell><cell></cell><cell>short desc</cell><cell cols="3">0.1054 0.0658 0.0356</cell></row><row><cell></cell><cell></cell><cell>desc</cell><cell cols="3">0.1384 0.0516 0.0391</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.1067 0.0877</cell></row><row><cell>pötyi</cell><cell>pötyi</cell><cell>contents</cell><cell cols="3">0.2468 0.8820 0.9060</cell></row><row><cell></cell><cell></cell><cell>desc</cell><cell cols="3">0.1384 0.0109 0.0060</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.0860 0.1156</cell></row><row><cell></cell><cell></cell><cell>contents</cell><cell cols="3">0.2468 0.0860 0.1479</cell></row><row><cell>minnie</cell><cell>minnie</cell><cell>characters</cell><cell cols="3">0.1339 0.8102 0.7214</cell></row><row><cell></cell><cell></cell><cell>short desc</cell><cell cols="3">0.1054 0.0117 0.0080</cell></row><row><cell></cell><cell></cell><cell>desc</cell><cell cols="3">0.1384 0.0072 0.0068</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.0610 0.0861</cell></row><row><cell></cell><cell></cell><cell>contents</cell><cell cols="3">0.2468 0.0633 0.1118</cell></row><row><cell></cell><cell>bogyó</cell><cell>desc</cell><cell cols="3">0.1384 0.0034 0.0034</cell></row><row><cell></cell><cell></cell><cell>short desc</cell><cell cols="3">0.1054 0.0062 0.0044</cell></row><row><cell></cell><cell></cell><cell>characters</cell><cell cols="3">0.1339 0.8657 0.7941</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.0874 0.1218</cell></row><row><cell></cell><cell></cell><cell>contents</cell><cell cols="3">0.2468 0.0984 0.1714</cell></row><row><cell>bogyó és babóca</cell><cell>és</cell><cell>desc</cell><cell cols="3">0.1384 0.2578 0.2514</cell></row><row><cell></cell><cell></cell><cell>short desc</cell><cell cols="3">0.1054 0.2316 0.1613</cell></row><row><cell></cell><cell></cell><cell>characters</cell><cell cols="3">0.1339 0.3246 0.2939</cell></row><row><cell></cell><cell></cell><cell>product name</cell><cell cols="3">0.1989 0.0594 0.0823</cell></row><row><cell></cell><cell></cell><cell>contents</cell><cell cols="3">0.2468 0.0875 0.1514</cell></row><row><cell></cell><cell>babóca</cell><cell>desc</cell><cell cols="3">0.1384 0.0034 0.0033</cell></row><row><cell></cell><cell></cell><cell>short desc</cell><cell cols="3">0.1054 0.0061 0.0042</cell></row><row><cell></cell><cell></cell><cell>characters</cell><cell cols="3">0.1339 0.8434 0.7587</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,149.14,115.76,317.08,59.20"><head>Table 7 .</head><label>7</label><figDesc>Similarity of rankings measured by the Kendall rank correlation coefficient (τ ).</figDesc><table coords="8,234.02,140.27,139.41,34.69"><row><cell></cell><cell cols="2">Method 2 Method 3</cell></row><row><cell>Method 1</cell><cell>0.867</cell><cell>0.864</cell></row><row><cell>Method 2</cell><cell>-</cell><cell>0.950</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,151.36,368.19,329.64,8.82;8,151.36,380.14,329.95,8.82;8,151.36,392.10,226.34,8.82" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,196.32,368.37,107.23,8.64">Semistructured data search</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,393.84,368.19,87.16,8.59;8,151.36,380.14,141.60,8.59">Bridging Between Information Retrieval and Databases</title>
		<title level="s" coord="8,369.84,380.14,111.46,8.59;8,151.36,392.10,28.80,8.59">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8173</biblScope>
			<biblScope unit="page" from="74" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.36,404.24,329.74,8.64;8,151.36,416.01,331.02,8.82;8,151.36,427.97,301.35,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,284.14,404.24,196.97,8.64;8,151.36,416.19,15.27,8.64">A probabilistic retrieval model for semistructured data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,183.72,416.01,298.66,8.59;8,151.36,427.97,138.85,8.82">Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval, ECIR &apos;09</title>
		<meeting>the 31th European Conference on IR Research on Advances in Information Retrieval, ECIR &apos;09</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="228" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.36,440.10,329.48,8.64;8,151.36,451.88,330.37,8.82;8,151.36,463.83,326.24,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,261.06,440.10,219.78,8.64;8,151.36,452.06,23.95,8.64">Combining document representations for known-item search</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,192.37,451.88,289.36,8.59;8,151.36,463.83,204.73,8.59">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="143" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,151.36,475.97,330.93,8.64;8,151.36,487.74,330.24,8.82;8,151.36,499.70,143.84,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,301.48,475.97,180.81,8.64;8,151.36,487.92,199.82,8.64">Extended overview of the living labs for information retrieval evaluation (LL4IR) CLEF lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,393.67,487.74,87.93,8.59;8,151.36,499.70,41.26,8.59">CLEF 2015 Labs and Workshops</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>Notebook Papers</note>
</biblStruct>

<biblStruct coords="8,151.36,511.84,330.78,8.64;8,151.36,523.61,330.61,8.82;8,151.36,535.57,329.81,8.82;8,151.36,547.52,204.21,8.82" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,303.09,511.84,179.04,8.64;8,151.36,523.79,161.71,8.64">Overview of the living labs for information retrieval evaluation (LL4IR) CLEF Lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,356.82,523.61,125.14,8.59;8,151.36,535.57,142.05,8.59">Sixth International Conference of the CLEF Association, CLEF&apos;15</title>
		<title level="s" coord="8,370.20,535.57,110.98,8.59;8,151.36,547.52,56.44,8.59">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 9283. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
