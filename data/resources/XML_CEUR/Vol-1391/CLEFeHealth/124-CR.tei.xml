<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,164.16,116.95,287.04,12.62">CUNI at the CLEF eHealth 2015 Task 2</title>
				<funder ref="#_Zb5YcNd">
					<orgName type="full">Charles University Grant Agency</orgName>
				</funder>
				<funder ref="#_YJcVzWx">
					<orgName type="full">Czech Science Foundation</orgName>
				</funder>
				<funder ref="#_URdbFhg">
					<orgName type="full">EU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.72,154.62,49.35,8.74"><forename type="first">Shadi</forename><surname>Saleh</surname></persName>
						</author>
						<author>
							<persName coords="1,261.72,154.62,66.08,8.74"><forename type="first">Feraena</forename><surname>Bibyna</surname></persName>
							<email>feraena.b@gmail.com</email>
						</author>
						<author>
							<persName coords="1,355.29,154.62,55.35,8.74"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
							<email>pecina@ufal.mff.cuni.cz</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,164.16,116.95,287.04,12.62">CUNI at the CLEF eHealth 2015 Task 2</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">01C18E7A57A1118FB732C05E4E256B96</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>multilingual information retrieval</term>
					<term>language models</term>
					<term>UMLS</term>
					<term>blind relevance feedback</term>
					<term>linear interpolation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our participation as the team of the Charles University in Prague at the CLEF eHealth 2015 Task 2. We investigate performance of different retrieval models, linear interpolation of multiple models, and our own implementation of blind relevance feedback for query expansion. We employ MetaMap as an external resource for annotating the collection and the queries, then conduct retrieval at concept level rather than word level. We use MetaMap for query expansion. We also participate in the multilingual task where queries were given in several languages. We use Khresmoi medical translation system to translate the queries from Czech, French, and German into English. For the other languages we use translation by Google Translate and Bing Translator.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Can we use the current web search engines to look for medical information? Authors in <ref type="bibr" coords="1,172.09,446.40,15.50,8.74" target="#b16">[17]</ref> showed that when users pose queries describing specific symptoms or general health information, the current search engines can not effectively retrieve relevant documents. This can lead to dangerous consequences if users try to apply the results they obtain for self-treatment. The biggest challenge in medical information retrieval is that users do not have enough medical knowledge so they cannot choose the correct medical terms which described their information needs. This often leads to "circumlocution" when the query contains more and vague words instead of less but specific medical terms. Modern information retrieval systems have started to move in the direction of concepts rather than terms which helps to solve the "circumlocution" problem <ref type="bibr" coords="1,386.85,554.00,14.61,8.74" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task description</head><p>The goal of CLEF eHealth 2015 Task 2 <ref type="bibr" coords="1,311.73,604.10,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,323.90,604.10,12.73,8.74" target="#b9">10]</ref> is to design an IR system which returns a ranked list of medical documents (English web pages) from the provided test collection as a response to patients' queries. The task is defined as a standard TREC-style text IR task 1 . &lt;doc&gt; &lt;d o c i d&gt;w i k i . 0 8 4 2 1 2 0 0 9 7 3 3&lt;/ d o c i d&gt; &lt; t i t l e&gt; T e s t i n g f o r C e l i a c D i s e a s e . . . &lt;/ t i t l e&gt; &lt; t i t l e c o n c e p t s&gt; C0683443 C0007570 C0521125 . . . &lt;/ t i t l e c o n c e p t s&gt; &lt;t e x t&gt; I n t e s t i n a l b i o p s y i s t h e g o l d s t a n d a r d f o r d i a g n o s i n g c e l i a c . . . &lt;/ t e x t&gt; &lt;t e x t c o n c e p t s&gt; C1704732 C0036563 C0423896 . . . &lt;/ t e x t c o n c e p t s&gt; &lt;/ doc&gt; Fig. <ref type="figure" coords="2,231.83,307.00,4.13,7.89">1</ref>. An example of an annotated document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Collection</head><p>The collection for Task 2 contains about one million documents provided by the Khresmoi project <ref type="foot" coords="2,211.11,388.05,3.97,6.12" target="#foot_1">2</ref> . It contains automatically crawled web pages from popular medical websites. Non-HTML documents (e.g., pdf, rtf, ppt, and doc) which were found in the collection were excluded. The HTML documents were cleaned using the simple HTML-Strip<ref type="foot" coords="2,236.57,423.92,3.97,6.12" target="#foot_2">3</ref> Perl module. Other more advanced tools and statistical approaches for cleaning HTML documents did not bring any improvement in our previous experiments <ref type="bibr" coords="2,228.09,449.40,14.61,8.74" target="#b11">[12]</ref>. After cleaning the documents, we used MetaMap <ref type="bibr" coords="2,458.92,449.40,10.52,8.74" target="#b0">[1]</ref> to annotate the data with concept identifiers from the UMLS Metathesaurus <ref type="bibr" coords="2,455.68,461.36,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="2,472.84,461.36,7.75,8.74" target="#b1">2]</ref> version 2014AA. The UMLS Metathesaurus is a large vocabulary database containing information about biomedical and health-related concepts, their names and relationship between them. Terms are linked to others by various relationship such as synonymy, hypernymy, hyponymy, lexical variations, and many others. The Metathesaurus is organized by concept, which symbolize a semantic concept or a meaning. Each concept or meaning in the Metathesaurus has a unique and permanent concept identifier (CUI). We utilize MetaMap's highly configurable options in our annotation process. We use the -I option so that the concept IDs are shown, and -y option to enable word sense disambiguation. The text is broken down into the components that include sentences, phrases, lexical elements and tokens. The disambiguation module then process the variants and output a final mapping. We put this concept annotations into an additional XML field in the document and query files. An example of cleaned and annotated document is given in Figure <ref type="figure" coords="2,213.85,628.73,3.87,8.74">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Queries</head><p>We use the test queries from the CLEF eHealth 2014 Task 3 <ref type="bibr" coords="3,413.07,227.66,10.52,8.74" target="#b4">[5]</ref> to train our system. The experiments are evaluated using the newly created CLEF eHealth 2015 Task 2 test queries. We have annotated both sets of queries by MetaMap the same way as the documents. Some basic statistics associated with the query sets are shown in Table <ref type="table" coords="3,240.12,275.48,3.87,8.74" target="#tab_0">1</ref>.</p><p>4 System description</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Retrieval model</head><p>We use Terrier <ref type="bibr" coords="3,199.07,357.29,10.51,8.74" target="#b8">[9]</ref> to index the collection and to conduct the retrieval, we examine several weighting models and based on comparing P@10 performance for those models, we choose the following:</p><p>-Bayesian smoothing with Dirichlet prior weighting model (DIR) This retrieval model is based on language modelling. The documents are scored by calculating the product of each term's probability in the query using language model for that document. Term probabilities in a document are estimated by maximum likelihood estimation. This might cause zero probabilities when a query term does not appear in the document. To avoid this problem the estimated probability distribution can be smoothed by various methods <ref type="bibr" coords="3,191.27,486.44,14.61,8.74" target="#b15">[16]</ref>. This retrieval model employs Bayesian smoothing with Dirichlet prior which uses different amount of smoothing based on the length of the document, for longer documents the smoothing will be less. The smoothing parameter is set by default to 2500. For more details and comparison with another smoothing methods see <ref type="bibr" coords="3,293.03,534.26,14.61,8.74" target="#b12">[13]</ref>. -Per-field normalisation weighting model (PL2F) This model extends Poisson model with Laplace after-effect and normalisation 2 (PL2) model. PL2 is based on Divergence from Randomness (DFR) document weighting models. The basic idea behind the DFR models is that the term frequency of a term in a document carries more information when it divergences from its distribution in the collection. In PL2F, each term in the document is assigned to one field and the frequency of that term is normalised and weighted independently of other fields <ref type="bibr" coords="3,279.08,630.31,9.96,8.74" target="#b7">[8]</ref>. -LGD weighting model In this model, DFR approach is used together with log-logistic distribution, see <ref type="bibr" coords="3,274.77,654.62,9.96,8.74" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Query Expansion using the UMLS Metathesaurus</head><p>In UMLS, a concept can be represented by many different names. In other words, a concept structure represents synonymy relationships, i.e. terms assigned to the same concept are synonymous. For example, concept C0010054 corresponds to the term coronary arteriosclerosis. This term is synonymous with the term coronary heart disease, which also has the same CUI in the Metathesaurus.</p><p>There are 113 other terms that are assigned with this CUI. In our experiment, we utilize this relationship to pick the candidate for query expansion.</p><p>As mentioned in the previous section, the queries are annotated with concept identifiers. For every concept in a query, we generate a list of synonymous terms under that concept. We keep the original query terms, and the added candidate terms that are not yet in the query terms. We do not add all the synonymous terms, but only up to five words that have the highest inverse document-frequency in the collection. In one of our runs, we further filter this words by doing an initial document retrieval using the original query, and then only use the synonyms that also appeared in top n relevant documents. We utilize Terrier's query language <ref type="foot" coords="4,259.27,314.03,3.97,6.12" target="#foot_3">4</ref> to experiment on field weighting with the query. Terrier query language has several operators with different functions. In our experiment, we used the ˆoperator that is used to assign weights to words. term1ˆ2 means that the weight of term1 is multiplied by 2. There are three kinds of fields that we utilize: the original query terms, the expanded query terms, and the concept identifiers from the original terms. We assign different weights to different fields. We tune our system using the CLEF 2014 test set to get the best weights configuration. Query language is only available in Terrier for single line query format, so we have to first convert the provided TREC format to single line format. Figure <ref type="figure" coords="4,200.65,423.21,4.98,8.74">2</ref> shows some samples of weighted single line queries, where original terms, expansion terms, and concept IDs are given weight 4.1, 0.6, and 0.1 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Blind relevance feedback</head><p>Blind relevance feedback (BRF) automates user's part of relevance feedback by expanding user's query using extra information from the collection <ref type="bibr" coords="4,453.76,501.62,9.96,8.74" target="#b3">[4]</ref>. In BRF, an initial retrieval steps is performed to find a set of n highly-ranked documents. These documents are assumed to be relevant and a set of m terms from these documents is extracted and added to the original query and the final retrieval step is conducted using the expanded query. In our experiments, the term selection is based on IDF scores extracted from the entire collection. We tune both n and m parameters using the CLEF 2014 test set. We found that adding just one term from top 25 documents gives the highest P@10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Linear interpolation</head><p>In some of our experiments, we perform linear interpolation of scores from multiple retrieval models.The following equation generates a new (interpolated) score c l e f 2 0 1 5 . t e s t . 1 many ˆ4 . 1 r e d ˆ4 . 1 marks ˆ4 . 1 on ˆ4 . 1 l e g s ˆ4 . 1 a f t e r ˆ4 . 1 t r a v e l i n g ˆ4 . 1 from ˆ4 . 1 us ˆ4 . 1 c o l o r ˆ0 . 6 p o l y ˆ0 . 6 e n t i t y ˆ0 . 6 t r a v e l i n g ˆ0 . 6 t r a i l i n g ˆ0 . 6 r e d n e s s ˆ0 . 6 marking ˆ0 . 6 c r u s ˆ0 . 6 markedly ˆ0 . 6 s t a t u s ˆ0 . 6 q u a l i f i e r ˆ0 . 6 r e g i o ˆ0 . 6 m a r k i n g s ˆ0 .  for each document/query pair:</p><formula xml:id="formula_0" coords="5,184.30,429.58,246.75,9.65">Score(D, Q) = λ • Score 1 (D, Q) + (1 -λ) • Score 2 (D, Q)</formula><p>We tune lambda value using the CLEF 2014 test set to get highest P @10. Figure <ref type="figure" coords="5,152.07,460.80,4.98,8.74">3</ref> shows the curves for the CLEF 2014 test set and the CLEF 2015 test set for P@10 when we interpolate Run5 and Run6, lambda is set to 0.71.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Term weighting</head><p>In the multilingual task, we use our term weighting algorithm for languages Czech, French and German to expand queries. First we use Khresmoi translation system to translate the queries into English and return the n-best-list translations. These translations form a translations pool. Each term in the translations pool is assigned a weight, which is the score of its translation hypothesis given by the translation model, say T M (term). Then, we use the BRF algorithm as described in Section 4.3 to retrieve the n highly-ranked documents, where the queries are taken only from the best translation. For each term in the translations pool, we calculate the IDF score in the entire collection and the term frequency (TF) in the translations pool. We normalise all of these scores and then each term is weighted as follows: Where lambda values sum up to 10. After scoring terms in the translations pool, we sort them descending by their score and add top m terms into original query. Lambda values, n and m are trained using the CLEF 2014 test set.</p><formula xml:id="formula_1" coords="5,163.72,655.04,247.96,10.81">Score(term) = T M (term) λ1 • T F (term) λ2 • IDF (term) (</formula><p>5 Experiments and results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Monolingual Task</head><p>We submitted to this task 10 runs, summarised in Table <ref type="table" coords="6,384.22,434.62,3.87,8.74" target="#tab_3">2</ref>, as follows:</p><p>-Run1, Run2, and Run3 employ Terrier's implementation of DIR, LGD, and PL2F retrieval models, respectively. Indexing and retrieval are conducted at term level. -Run4 is a linear combination of Run1, Run2, and Run3 with parameters set to 0.56, 0.32, and 0.12, respectively. The values were tuned on the CLEF eHealth 2014 test queries. -Run5 employs query expansion based on the UMLS Metathesaurus. For each UMLS concept ID in each query, we retrieved all entries with that concept ID and then expanded that query with 5 words that have the highest IDF in the collection, excluding words that already occur in the original query. We used original terms, concept id, and expansion terms for the retrieval process using Terrier's implementation of PL2F. Each field is weighted differently, see Section 4.2. -Run6 uses the same settings at Run5 but employs the LGD retrieval model. -Run7 interpolates Run5 and Run6 with parameters 0.71 and 0.29, respectively. -Run8 interpolates Run1 with a system that only uses concept IDs for retrieval (using PL2F model), with parameters 0.98 and 0.01, respectively. -Run9 is similar to Run5, but the expansion terms are further filtered by relevance feedback, i.e. we only use the terms that also appeared in the initial retrieval. -Run10 employs our own implementation of blind relevance feedback. We do initial retrieval using Run1, then from top 25 ranked documents. We add one term with the highest IDF in the collection into original query, then we do the retrieval again using Run1, see Section 4.3.</p><p>Table <ref type="table" coords="7,178.74,501.70,4.98,8.74" target="#tab_5">4</ref> shows our system performance on the CLEF 2014 test set. The difference between numbers in italics and bold is not statistically significant using the Wilcoxon test <ref type="bibr" coords="7,216.95,525.61,9.96,8.74" target="#b6">[7]</ref>. Run4 which is an interpolation between the first 3 runs gives the best P@10. Run8 also brings some improvement to the baseline system. Run5, which uses the same model with Run3, brings a slight improvement with the query expansion. However, Run6 decreases slightly in P@10 compared to unexpanded Run2. Run7 brings some improvement over the two other runs that it interpolated. In case of Run9, combining our query expansion with relevance feedback decreases the performance compared to Run5.</p><p>The results of our submitted runs are shown in Table <ref type="table" coords="7,391.39,609.29,3.87,8.74" target="#tab_6">5</ref>. In terms of P@10 metric, Run1 and Run2 have the same P@10, but Run1 outperforms Run2 in terms of MAP, NDCG@10 and the number of relevant retrieved documents. We have improvement in Run4, which linearly interpolates Run1, Run2 and Run3. As in the training set, Run5 improves the P@10 when compared to Run3, and Run6 does not bring any improvement over Run2. Run7, which is the best performing run, brings improvement over Run5 and Run6. Run3 has 3 unjudged documents in the first 10 ranked documents among 66 queries, so the shown metrics may not be accurate. BRF in Run10 does not bring overall improvement in P@10, but it does in some queries. BRF still does not guarantee to choose the best term to expand the query with (see Table <ref type="table" coords="8,341.65,497.42,3.87,8.74" target="#tab_4">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multilingual Task</head><p>In this task, we are given parallel queries in Arabic, Czech, Farsi, French, German, Italian and Portuguese and the goal is to design a retrieval system to find relevant documents to these queries from the English collection. For queries in Czech, French and German, we submitted 10 runs as follows (see also Table <ref type="table" coords="8,468.97,587.28,3.87,8.74">7</ref>):</p><p>-Run1, Run2 and Run3 runs, we translate the queries using Khresmoi <ref type="bibr" coords="8,465.09,608.88,15.50,8.74" target="#b10">[11]</ref> then use Terrier's implementation of DIR, PL2F and LGD retrieval models respectively. -Run4 interpolates Run1, Run2, and Run3 with parameters (0.57, 0.40, 0.03) respectively, tuned on the CLEF eHealth 2014 test set. -Run5, Run6 and Run7, queries are translated using Bing translator, then retrieval is conducted using PL2F, DIR, and LGD respectively.</p><p>-Run8 interpolates Run5, Run6 and Run7 with the parameters 0.57, 0.40, and 0.03.</p><p>-Run9 uses Google Translate and BRF to expand queries using 25 document and 1 term and DIR model for both initial and final retrieval.</p><p>-Run10 interpolates Run1 and Run6 with the parameters 0.84 and 0.16.</p><p>The results for multilingual submission are shown in Table <ref type="table" coords="10,424.13,561.47,3.87,8.74" target="#tab_8">9</ref>. The table shows P@10 values for all languages and the last column shows the result of our monolingual task for comparison. Linear interpolation between runs use Google Translate and Bing translator together with DIR model improved the results for Farsi, French, German and Italian. The Baseline in Italian is identical to monolingual one, other Italian runs are very close to monolingual runs and sometimes higher, anyway we have many unjudged documents in our Italian submission so results may differ after full assessment. Example of how Google and Bing translate one query in different languages is shown in Table <ref type="table" coords="10,441.01,657.11,3.87,8.74" target="#tab_7">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Conclusion and future work</head><p>In this paper, we have described our participation in the CLEF eHealth 2015 Task 2. We used the Terrier IR platform to index the collection and conduct retrieval using different retrieval models and our own implementation of blind relevance feedback. We used MetaMap to annotate the documents in the collection and the queries with concepts and then built systems on concept levels, which improved the performance measured by P@10. Linear interpolation of runs conducted using different approaches, it improved P@10 when interpolating models use different retrieval models. Although query expansions did not bring improvement over the baseline, we got improvement for some individual queries. In some cases it also improved the performance compared to a system with the same retrieval model that only used the original query terms. We also submitted runs to multilingual task. We translated queries in the given languages into English and performed several experiments. The most promising results were obtained by linear interpolation of runs using different translation system for languages Farsi, French, German and Italian which use DIR model. We also used information from translation variants provided by the Khresmoi translation system (n-best lists). This did not bring overall improvement but it did for some individual queries. We believe that more thorough investigation should be done on terms selection algorithms to refine query expansion based approaches, so it will lead to better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,397.55,147.93,56.40,6.12;5,155.65,155.90,312.58,6.12;5,155.60,163.87,317.86,6.12;5,155.67,171.84,202.96,6.12;5,135.92,187.78,326.68,6.12;5,155.11,195.75,322.66,6.12;5,160.29,203.72,303.18,6.12;5,155.83,211.69,245.69,6.12;5,135.92,227.64,307.62,6.12;5,155.83,235.61,308.02,6.12;5,155.67,243.58,317.60,6.12;5,155.67,251.55,322.10,6.12;5,159.97,259.52,179.59,6.12;5,135.92,275.46,317.15,6.12;5,156.04,283.43,192.87,6.12"><head></head><label></label><figDesc>6 c r u r a l ˆ0 . 6 m a s s i v e l y ˆ0 . 6 o b s e r v a b l e ˆ0 . 6 s u b d i v i s i o n ˆ0 . 6 c o l o u r ˆ0 . 6 c r u r i s ˆ0 . 6 v a l u e ˆ0 . 6 t r a v e l s ˆ0 . 6 v a l u e s ˆ0 . 6 C0747726 ˆ0 . 1 C1260956 ˆ0 . 1 C0522501 ˆ0 . 1 C1140621 ˆ0 . 1 C0687676 ˆ0 . 1 C0040802 ˆ0 . 1 c l e f 2 0 1 5 . t e s t . 2 lump ˆ4 . 1 w i t h ˆ4 . 1 b l o o d ˆ4 . 1 s p o t s ˆ4 . 1 on ˆ4 . 1 n o s e ˆ4 . 1 body ˆ0 . 6 e n t i r e ˆ0 . 6 l o c a l i s e d ˆ0 . 6 n a e v u s ˆ0 . 6 m a s s e s ˆ0 . 6 angiomas ˆ0 . 6 m o r p h o l o g i c ˆ0 . 6 angioma ˆ0 . 6 lump ˆ0 . 6 haemangioma ˆ0 . 6 e c t a s i a ˆ0 . 6 s t r u c t u r e ˆ0 . 6 C0577559 ˆ0 . 1 C0343082 ˆ0 . 1 C1278896 ˆ0 . 1 c l e f 2 0 1 5 . t e s t . 3 dry ˆ4 . 1 r e d ˆ4 . 1 and ˆ4 . 1 s c a l y ˆ4 . 1 f e e t ˆ4 . 1 i n ˆ4 . 1 c h i l d r e n ˆ4 . 1 f e e t ˆ0 . 6 q u a l i f i e r ˆ0 . 6 c o l o r ˆ0 . 6 c o l o u r ˆ0 . 6 abnormal ˆ0 . 6 v a l u e ˆ0 . 6 r u b o r ˆ0 . 6 youth ˆ0 . 6 p e r s o n ˆ0 . 6 f o o t ˆ0 . 6 d e s q u a m a t i o n ˆ0 . 6 f i n d i n g ˆ0 . 6 p h y s i c a l ˆ0 . 6 c h i l d h o o d ˆ0 . 6 r e d n e s s ˆ0 . 6 C0205222 ˆ0 . 1 C0332575 ˆ0 . 1 C0239639 ˆ0 . 1 C0008059 ˆ0 . 1 c l e f 2 0 1 5 . t e s t . 4 i t c h y ˆ4 . 1 lumps ˆ4 . 1 s k i n ˆ4 . 1 o b s e r v a b l e ˆ0 . 6 d05 ˆ0 . 6 l o c a l i s e d ˆ0 . 6 s p e c i m e n ˆ0 . 6 m o r p h o l o g i c ˆ0 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,116.91,345.83,60.19"><head>Table 1 .</head><label>1</label><figDesc>Statistics of the query sets: number of queries, average number of tokens in titles and total number of relevant documents.</figDesc><table coords="3,172.26,146.92,270.84,30.18"><row><cell>query set</cell><cell>queries</cell><cell>title length</cell><cell>relevant documents</cell></row><row><cell>CLEF 2014 test set</cell><cell>50</cell><cell>4.30</cell><cell>3,209</cell></row><row><cell>CLEF 2015 test set</cell><cell>66</cell><cell>5.03</cell><cell>1,972</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,411.68,655.04,39.47,6.12"><head></head><label></label><figDesc>Tuning the lambda parameter on the CLEF 2014 test set and the scores obtained on the CLEF 2015 test data while interpolating Run5 and Run6.</figDesc><table coords="5,411.68,655.04,39.47,6.12"><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CLEF 2014 test set</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CLEF 2015 test set</cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P@10</cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Lambda</cell><cell></cell><cell></cell></row><row><cell>Fig. 3.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10-λ1-λ2)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,140.99,116.91,333.37,149.61"><head>Table 2 .</head><label>2</label><figDesc>Description of the monolingual runs.</figDesc><table coords="7,140.99,137.71,333.37,128.81"><row><cell>run ID</cell><cell>query</cell><cell cols="3">doc model details</cell></row><row><cell>Run1</cell><cell>term</cell><cell cols="3">term DIR -</cell></row><row><cell>Run2</cell><cell>term</cell><cell cols="3">term LGD -</cell></row><row><cell>Run3</cell><cell>term</cell><cell cols="3">term PL2F -</cell></row><row><cell>Run4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>lin. interpolation of Run1, Run2, Run3</cell></row><row><cell>Run5</cell><cell cols="4">term&amp;concept term PL2F UMLS query expansion</cell></row><row><cell>Run6</cell><cell cols="4">term&amp;concept term LGD UMLS query expansion</cell></row><row><cell>Run7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>lin. interpolation of Run5 and Run6</cell></row><row><cell>Run8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>lin. interpolation of Run1 and a concept-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>only-based PL2F model</cell></row><row><cell>Run9</cell><cell>term</cell><cell cols="3">term PL2F UMLS query expansion filtered by BRF</cell></row><row><cell>Run10</cell><cell>term</cell><cell cols="3">term DIR BRF</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,137.75,279.77,334.38,105.77"><head>Table 3 .</head><label>3</label><figDesc>BRF query expansion on P@10 on selected CLEF 2015 test set queries.</figDesc><table coords="7,137.75,300.56,334.30,84.97"><row><cell>query ID</cell><cell>original query</cell><cell cols="2">expanded term Run1 Run10</cell></row><row><cell cols="2">clef2015.test.1 many red marks on legs after trav-</cell><cell cols="2">striaestretch 0.1000 0.1000</cell></row><row><cell></cell><cell>eling from us</cell><cell></cell></row><row><cell cols="2">clef2015.test.2 lump with blood spots on nose</cell><cell>mixx</cell><cell>0.3000 0.0000</cell></row><row><cell cols="2">clef2015.test.3 dry red and scaly feet in children</cell><cell>scaleness</cell><cell>0.7000 0.9000</cell></row><row><cell cols="2">clef2015.test.4 itchy lumps skin</cell><cell cols="2">healthdental 0.2000 0.1000</cell></row><row><cell cols="2">clef2015.test.5 whistling noise and cough during</cell><cell>ringining</cell><cell>0.6000 0.6000</cell></row><row><cell></cell><cell>sleeping + children</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,143.14,116.91,329.07,138.65"><head>Table 4 .</head><label>4</label><figDesc>System performance in monolingual task on the CLEF 2014 test set.</figDesc><table coords="8,143.14,137.71,329.07,117.85"><row><cell>run ID</cell><cell>P@5</cell><cell cols="3">P@10 NDCG@5 NDCG@10</cell><cell>MAP</cell><cell cols="2">rel ret UNJ@10</cell></row><row><cell>Run1</cell><cell cols="2">0.7680 0.7160</cell><cell>0.7519</cell><cell>0.7206</cell><cell>0.3919</cell><cell>2588</cell><cell>14</cell></row><row><cell>Run2</cell><cell cols="2">0.7000 0.6900</cell><cell>0.6872</cell><cell>0.6833</cell><cell>0.3832</cell><cell>2573</cell><cell>12</cell></row><row><cell>Run3</cell><cell cols="2">0.7160 0.6980</cell><cell>0.7076</cell><cell>0.6995</cell><cell cols="2">0.4300 2658</cell><cell>9</cell></row><row><cell>Run4</cell><cell cols="2">0.7480 0.7400</cell><cell>0.7376</cell><cell>0.7362</cell><cell>0.4188</cell><cell>2637</cell><cell>1</cell></row><row><cell>Run5</cell><cell cols="2">0.7280 0.7000</cell><cell>0.7250</cell><cell>0.7057</cell><cell>0.4134</cell><cell>2628</cell><cell>8</cell></row><row><cell>Run6</cell><cell cols="2">0.7320 0.6840</cell><cell>0.7340</cell><cell>0.7002</cell><cell>0.3849</cell><cell>2503</cell><cell>24</cell></row><row><cell>Run7</cell><cell>0.7520</cell><cell>0.7200</cell><cell>0.7390</cell><cell>0.7204</cell><cell>0.4135</cell><cell>2642</cell><cell>11</cell></row><row><cell>Run8</cell><cell cols="2">0.7640 0.7200</cell><cell>0.7538</cell><cell>0.7239</cell><cell>0.3953</cell><cell>2588</cell><cell>14</cell></row><row><cell>Run9</cell><cell cols="2">0.7160 0.6940</cell><cell>0.7077</cell><cell>0.6977</cell><cell>0.4069</cell><cell>2611</cell><cell>15</cell></row><row><cell cols="3">Run10 0.7080 0.6980</cell><cell>0.6728</cell><cell>0.6756</cell><cell>0.3793</cell><cell>2588</cell><cell>36</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,143.14,270.37,329.07,138.65"><head>Table 5 .</head><label>5</label><figDesc>System performance in monolingual task on the CLEF 2015 test set.</figDesc><table coords="8,143.14,291.17,329.07,117.85"><row><cell>run ID</cell><cell>P@5</cell><cell cols="3">P@10 NDCG@5 NDCG@10</cell><cell>MAP</cell><cell cols="2">rel ret UNJ@10</cell></row><row><cell>Run1</cell><cell>0.3970</cell><cell>0.3712</cell><cell>0.3352</cell><cell>0.3423</cell><cell>0.2353</cell><cell>1703</cell><cell>0</cell></row><row><cell>Run2</cell><cell>0.4061</cell><cell>0.3712</cell><cell>0.3399</cell><cell>0.3351</cell><cell>0.2236</cell><cell>1668</cell><cell>0</cell></row><row><cell>Run3</cell><cell>0.3818</cell><cell>0.3485</cell><cell>0.3136</cell><cell>0.3138</cell><cell>0.2095</cell><cell>1637</cell><cell>3</cell></row><row><cell>Run4</cell><cell>0.4121</cell><cell>0.3742</cell><cell>0.3424</cell><cell>0.3409</cell><cell cols="2">0.2427 1702</cell><cell>2</cell></row><row><cell>Run5</cell><cell>0.3970</cell><cell>0.3530</cell><cell>0.3290</cell><cell>0.3217</cell><cell>0.2046</cell><cell>1607</cell><cell>20</cell></row><row><cell>Run6</cell><cell>0.4030</cell><cell>0.3606</cell><cell>0.3439</cell><cell>0.3364</cell><cell>0.2123</cell><cell>1606</cell><cell>48</cell></row><row><cell>Run7</cell><cell cols="2">0.4152 0.3803</cell><cell>0.3513</cell><cell>0.3465</cell><cell>0.2188</cell><cell>1627</cell><cell>10</cell></row><row><cell>Run8</cell><cell>0.4061</cell><cell>0.3621</cell><cell>0.3385</cell><cell>0.3383</cell><cell>0.2369</cell><cell>1703</cell><cell>0</cell></row><row><cell>Run9</cell><cell>0.3970</cell><cell>0.3530</cell><cell>0.3287</cell><cell>0.3215</cell><cell>0.2045</cell><cell>1607</cell><cell>19</cell></row><row><cell cols="2">Run10 0.3273</cell><cell>0.3000</cell><cell>0.2604</cell><cell>0.2597</cell><cell>0.1919</cell><cell>1695</cell><cell>121</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,141.94,116.91,314.44,128.49"><head>Table 8 .</head><label>8</label><figDesc>Sample of Google and Bing translations for query clef2015.test.2</figDesc><table coords="10,141.94,137.71,220.43,107.69"><row><cell>Google</cell><cell></cell></row><row><cell>FA</cell><cell>Highlights of the red spots on the nose</cell></row><row><cell>FR</cell><cell>bulge with blood stains on his nose</cell></row><row><cell>DE</cell><cell>tumor with bloody spots on the nose</cell></row><row><cell>IT</cell><cell>clot with blood stains on his nose</cell></row><row><cell>Bing</cell><cell></cell></row><row><cell>FA</cell><cell>The mass highlighted with red spots on nose</cell></row><row><cell>FR</cell><cell>bump with blood stains on the nose</cell></row><row><cell>DE</cell><cell>Tumor with bloody points on the nose</cell></row><row><cell>IT</cell><cell>lump with bloodstains on the nose</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,137.26,268.18,341.24,138.65"><head>Table 9 .</head><label>9</label><figDesc>System performance in multilingual task against test set.</figDesc><table coords="10,137.26,288.97,341.24,117.85"><row><cell cols="3">run ID Arabic Czech Farsi French German Italian Portuguese Monolingual</cell></row><row><cell>Run1 0.2727 0.3318 0.3258 0.3121 0.2859 0.3712</cell><cell>0.3500</cell><cell>0.3712</cell></row><row><cell>Run2 0.2621 0.2727 0.3227 0.3061 0.2562 0.3424</cell><cell>0.3576</cell><cell>0.3712</cell></row><row><cell>Run3 0.2591 0.3030 0.3242 0.3273 0.2766 0.3394</cell><cell>0.3364</cell><cell>0.3485</cell></row><row><cell>Run4 0.2621 0.3030 0.3273 0.3182 0.2828 0.3727</cell><cell>0.3485</cell><cell>0.3742</cell></row><row><cell>Run5 0.3030 0.2909 0.3045 0.2879 0.2703 0.3318</cell><cell>0.3182</cell><cell>0.3530</cell></row><row><cell>Run6 0.2894 0.3000 0.2864 0.2803 0.2437 0.3606</cell><cell>0.3333</cell><cell>0.3606</cell></row><row><cell>Run7 0.2924 0.3318 0.2803 0.3682 0.3545 0.3318</cell><cell>0.2985</cell><cell>0.3803</cell></row><row><cell>Run8 0.2879 0.2924 0.3000 0.3182 0.2985 0.3515</cell><cell>0.3318</cell><cell>0.3621</cell></row><row><cell>Run9 0.2439 0.2864 0.2727 0.3333 0.2924 0.3106</cell><cell>0.2924</cell><cell>0.3530</cell></row><row><cell>Run10 0.2924 0.3288 0.3333 0.3682 0.3561 0.3727</cell><cell>0.3379</cell><cell>0.3000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,658.44,98.85,7.47"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,647.48,89.44,7.47"><p>http://khresmoi.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,658.44,221.74,7.47"><p>http://search.cpan.org/dist/HTML-Strip/Strip.pm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,658.44,221.25,7.47"><p>http://terrier/org/docs/v4.0/querylanguage.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was supported by the <rs type="funder">Charles University Grant Agency</rs> (grant n. <rs type="grantNumber">920913</rs>), <rs type="funder">Czech Science Foundation</rs> (grant n. <rs type="grantNumber">P103/12/G084</rs>), and the <rs type="funder">EU</rs> <rs type="programName">H2020</rs> project <rs type="projectName">KConnect</rs> (contract n. <rs type="grantNumber">644753</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Zb5YcNd">
					<idno type="grant-number">920913</idno>
				</org>
				<org type="funding" xml:id="_YJcVzWx">
					<idno type="grant-number">P103/12/G084</idno>
				</org>
				<org type="funded-project" xml:id="_URdbFhg">
					<idno type="grant-number">644753</idno>
					<orgName type="project" subtype="full">KConnect</orgName>
					<orgName type="program" subtype="full">H2020</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>-Run5 uses Khresmoi to translate the queries into English, queries are expanded using term weighting algorithm as described in Section 4.5. After model tuning, we use as parameters λ 1 = 4, λ 2 = 2, n = 1, and m = 30. -In Run6, we also use Khresmoi, then we use BRF to expand queries by adding one term from the top 25 documents, which has the highest IDF in the collection into original query. Both the initial and final retrieval steps use the DIR model. -Run7, In this run we translate the queries using Google Translate, and use Terrier's implementation of DIR model -Run8 is similar to Run7, but queries are translated using Bing translator.</p><p>-Run9, we use Google Translate to translate the queries into English then use Terrier's implementation of PL2F. -Run10 interpolates Run7 and Run8, for Czech we use the parameters 0.92 and 0.08 respectively, for French 0.90, and 0.10 and for German 0.7, and 0.3.</p><p>For AR, FA, IT and PT, we submitted the following runs (see also Table <ref type="table" coords="9,468.96,604.18,3.87,8.74">6</ref>):</p><p>-Run1, Run2 and Run3, we translate the queries using Google Translate and then use Terrier's implementation of DIR, PL2F, and LGD respectively. -Run4 interpolates Run1, Run2 and Run3 with the parameters 0.56, 0.32, and 0.12 respectively.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,513.52,337.63,7.86;11,151.52,524.48,239.79,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,215.94,513.52,264.65,7.86;11,151.52,524.48,88.17,7.86">Effective mapping of biomedical text to the umls metathesaurus: the metamap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,247.30,524.48,73.36,7.86">Proc AMIA Symp</title>
		<meeting>AMIA Symp</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,535.89,337.64,7.86;11,151.52,546.85,93.46,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
		<title level="m" coord="11,220.37,535.89,260.23,7.86;11,151.52,546.85,64.78,7.86">The unified medical language system (umls): Integrating biomedical terminology</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,558.26,337.63,7.86;11,151.52,569.22,329.07,7.86;11,151.52,580.18,329.07,7.86;11,151.52,591.14,329.07,7.86;11,151.52,602.10,136.15,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,263.79,558.26,216.79,7.86;11,151.52,569.22,173.73,7.86">Bridging language modeling and divergence from randomness models: A log-logistic model for ir</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,393.83,580.18,86.76,7.86;11,151.52,591.14,85.63,7.86">Advances in Information Retrieval Theory</title>
		<title level="s" coord="11,245.12,591.14,143.45,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kazai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Rger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Shokouhi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5766</biblScope>
			<biblScope unit="page" from="54" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,613.51,337.63,7.86;11,151.52,624.47,121.85,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,230.36,613.51,67.37,7.86">Query expansion</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,306.41,613.51,174.17,7.86;11,151.52,624.47,43.01,7.86">Annual review of information science and technology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="121" to="187" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,635.88,337.64,7.86;11,151.52,646.84,329.07,7.86;11,151.52,657.79,267.40,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,243.82,646.84,236.77,7.86;11,151.52,657.79,110.17,7.86">Share/clef ehealth evaluation lab 2014, task 3: User-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,282.40,657.79,107.84,7.86">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,120.67,337.64,7.86;12,151.52,131.63,329.07,7.86;12,151.52,142.59,329.07,7.86;12,151.52,153.55,177.61,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,215.66,131.63,175.54,7.86">Overview of the clef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hanlen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nvol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,433.90,131.63,46.69,7.86;12,151.52,142.59,209.38,7.86">CLEF 2015 -6th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="12,369.09,142.59,111.50,7.86;12,151.52,153.55,56.67,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09">2015. September 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,164.51,337.63,7.86;12,151.52,175.46,329.07,7.86;12,151.52,186.42,329.07,7.86;12,151.52,197.38,91.91,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,191.38,164.51,269.96,7.86">Using statistical testing in the evaluation of retrieval experiments</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,175.46,329.07,7.86;12,151.52,186.42,172.66,7.86;12,387.08,186.42,40.34,7.86">Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="329" to="338" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;93</note>
</biblStruct>

<biblStruct coords="12,142.96,208.34,337.64,7.86;12,151.52,219.30,329.07,7.86;12,151.52,230.26,329.07,7.86;12,151.52,241.22,329.07,7.86;12,151.52,252.18,329.07,7.86;12,151.52,263.14,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,395.39,208.34,85.20,7.86;12,151.52,219.30,329.07,7.86;12,151.52,230.26,18.02,7.86">University of glasgow at webclef 2005: Experiments in per-field normalisation and language specific stemming</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,247.91,241.22,194.64,7.86">Accessing Multilingual Information Repositories</title>
		<title level="s" coord="12,450.23,241.22,30.36,7.86;12,151.52,252.18,111.38,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4022</biblScope>
			<biblScope unit="page" from="898" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,274.09,337.63,7.86;12,151.52,285.05,329.07,7.86;12,151.52,296.01,329.07,7.86;12,151.52,306.97,25.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,450.57,274.09,30.02,7.86;12,151.52,285.05,258.58,7.86">Terrier: A high performance and scalable information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,432.51,285.05,48.08,7.86;12,151.52,296.01,274.66,7.86">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval<address><addrLine>OSIR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,317.93,337.98,7.86;12,151.52,328.89,329.07,7.86;12,151.52,339.85,311.84,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,197.33,328.89,283.27,7.86;12,151.52,339.85,72.33,7.86">Clef ehealth evaluation lab 2015, task 2: Retrieving information about medical symptoms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<ptr target="CEUR-WS" />
	</analytic>
	<monogr>
		<title level="m" coord="12,245.83,339.85,137.27,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,350.81,337.98,7.86;12,151.52,361.77,329.07,7.86;12,151.52,372.73,329.07,7.86;12,151.52,383.68,231.96,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,165.13,372.73,315.46,7.86;12,151.52,383.68,61.44,7.86">Adaptation of machine translation for multilingual information retrieval in the medical domain</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hlaváčová</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mareček</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Novák</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tamchyna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Urešová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,220.64,383.68,134.17,7.86">Artificial Intelligence in Medicine</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,394.64,337.98,7.86;12,151.52,405.60,289.83,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,237.66,394.64,200.46,7.86">Cuni at the share/clef ehealth evaluation lab 2014</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,445.36,394.64,35.23,7.86;12,151.52,405.60,201.77,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<imprint>
			<biblScope unit="volume">1180</biblScope>
			<biblScope unit="page" from="226" to="235" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,416.56,337.98,7.86;12,151.52,427.52,329.07,7.86;12,151.52,438.48,25.60,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="12,261.14,416.56,219.45,7.86;12,151.52,427.52,69.35,7.86">An investigation of dirichlet prior smoothings performance advantage</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<idno>IR-445</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct coords="12,142.62,449.44,337.98,7.86;12,151.52,460.40,329.07,7.86;12,151.52,471.36,257.09,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,293.82,449.44,182.96,7.86">Circumlocution in diagnostic medical queries</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ieong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,166.02,460.40,314.57,7.86;12,151.52,471.36,146.26,7.86">Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</title>
		<meeting>the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,482.31,337.98,7.86;12,151.52,493.27,82.48,7.86" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<title level="m" coord="12,170.96,482.31,215.83,7.86">National Library of Medicine: UMLS reference manual</title>
		<meeting><address><addrLine>Bethesda, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>metathesaurus</note>
</biblStruct>

<biblStruct coords="12,142.62,504.23,337.98,7.86;12,151.52,515.19,329.07,7.86;12,151.52,526.15,60.92,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,239.56,504.23,241.04,7.86;12,151.52,515.19,92.15,7.86">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,249.74,515.19,204.79,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,537.11,337.98,7.86;12,151.52,548.07,329.07,7.86;12,151.52,559.03,263.62,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,302.63,537.11,177.96,7.86;12,151.52,548.07,255.50,7.86">Diagnose this if you can: On the effectiveness of search engines in finding medical self-diagnosis information</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,430.70,548.07,49.90,7.86;12,151.52,559.03,116.65,7.86">Advances in Information Retrieval (ECIR</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="562" to="567" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
