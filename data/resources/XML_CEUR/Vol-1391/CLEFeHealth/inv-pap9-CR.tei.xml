<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.24,116.95,312.88,12.62;1,170.43,134.89,274.49,12.62;1,270.65,152.82,74.06,12.62">CLEF eHealth Evaluation Lab 2015, Task 2: Retrieving Information About Medical Symptoms</title>
				<funder ref="#_RXZFBVa">
					<orgName type="full">Czech Science Foundation</orgName>
				</funder>
				<funder ref="#_XrGYtw8">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_nEz6WeR">
					<orgName type="full">Austrian Science Fund (FWF)</orgName>
				</funder>
				<funder ref="#_8sa9Qf4 #_8fFhJwg #_96FjfMN #_7kyR4HP">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,152.79,190.69,53.14,8.74"><forename type="first">João</forename><surname>Palotti</surname></persName>
							<email>palotti@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.48,190.69,60.96,8.74"><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
							<email>g.zuccon@qut.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,287.99,190.69,78.61,8.74"><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
							<email>lorraine.goeuriot@imag.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">Université Grenoble Alpes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.15,190.69,51.34,8.74"><forename type="first">Liadh</forename><surname>Kelly</surname></persName>
							<email>liadh.kelly@tcd.ie</email>
							<affiliation key="aff3">
								<orgName type="institution">Trinity College</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,439.04,190.69,23.52,8.74;1,166.15,202.64,37.94,8.74"><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
							<email>hanbury@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.65,202.64,78.33,8.74"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<email>gareth.jones@computing.dcu.ie</email>
							<affiliation key="aff4">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.54,202.64,51.34,8.74"><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
							<email>lupu@ifs.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.81,202.64,55.35,8.74"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
							<email>pecina@ufal.mff.cuni.cz</email>
							<affiliation key="aff5">
								<orgName type="institution">Charles University in Prague</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Medical Information Analysis and Retrieval</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.24,116.95,312.88,12.62;1,170.43,134.89,274.49,12.62;1,270.65,152.82,74.06,12.62">CLEF eHealth Evaluation Lab 2015, Task 2: Retrieving Information About Medical Symptoms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">867B4170D310D69ABF106E2A7A6DC429</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Information Retrieval</term>
					<term>Health Information Seeking and Retrieval In alphabetical order</term>
					<term>JP</term>
					<term>GZ led Task 2;</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper details methods, results and analysis of the CLEF 2015 eHealth Evaluation Lab, Task 2. This task investigates the effectiveness of web search engines in providing access to medical information with the aim of fostering advances in the development of these technologies. The problem considered in this year's task was to retrieve web pages to support information needs of health consumers that are confronted with a sign, symptom or condition and that seek information through a search engine, with the aim to understand which condition they may have. As part of this evaluation exercise, 66 query topics were created by potential users based on images and videos of conditions. Topics were first created in English and then translated into a number of other languages. A total of 97 runs by 12 different teams were submitted for the English query topics; one team submitted 70 runs for the multilingual topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This document reports on the CLEF 2015 eHealth Evaluation Lab, Task 2. The task investigated the problem of retrieving web pages to support information needs of health consumers (including their next-of-kin) that are confronted with a sign, symptom or condition and that use a search engine to seek understanding about which condition they may have. Task 2 has been developed within the CLEF 2015 eHealth Evaluation Lab, which aims to foster the development of approaches to support patients, their next-of-kin, and clinical staff in understanding, accessing and authoring health information <ref type="bibr" coords="2,369.94,131.95,9.96,8.74" target="#b0">[1]</ref>.</p><p>The use of the Web as source of health-related information is a wide-spread phenomena. Search engines are commonly used as a means to access health information available online <ref type="bibr" coords="2,236.08,167.83,9.96,8.74" target="#b1">[2]</ref>. Previous iterations of this task (i.e. the 2013 and 2014 CLEFeHealth Lab Task 3 <ref type="bibr" coords="2,250.65,179.79,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,262.83,179.79,7.75,8.74" target="#b3">4]</ref>) aimed at evaluating the effectiveness of search engines to support people when searching for information about their conditions, e.g. to answer queries like "thrombocytopenia treatment corticosteroids length". These past two evaluation exercises have provided valuable resources and an evaluation framework for developing and testing new and existing techniques. The fundamental contribution of these tasks to the improvement of search engine technology aimed at answering this type of health information need is demonstrated by the improvements in retrieval effectiveness provided by the best 2014 system <ref type="bibr" coords="2,167.90,275.43,10.52,8.74" target="#b4">[5]</ref> over the best 2013 system <ref type="bibr" coords="2,298.46,275.43,10.52,8.74" target="#b5">[6]</ref> (using different, but comparable, topic sets).</p><p>Searching for self-diagnosis information is another important type of health information seeking activity <ref type="bibr" coords="2,262.52,311.32,9.96,8.74" target="#b1">[2]</ref>; this seeking activity has not been considered in the previous CLEF eHealth tasks, nor in other information retrieval evaluation campaigns. These information needs often arise before attending a medical professional (or to help the decision of attending). Previous research has shown that exposing people with no or scarce medical knowledge to complex medical language may lead to erroneous self-diagnosis and self-treatment and that access to medical information on the Web can lead to the escalation of concerns about common symptoms (e.g., cyberchondria) <ref type="bibr" coords="2,320.24,395.00,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="2,332.41,395.00,7.01,8.74" target="#b7">8]</ref>. Research has also shown that current commercial search engines are yet far from being effective in answering such queries <ref type="bibr" coords="2,190.75,418.91,9.96,8.74" target="#b8">[9]</ref>. This type of query is the subject of investigation in this CLEF 2015 eHealth Lab Task 2. We expected these queries to pose a new challenge to the participating teams; a challenge that, if solved, would lead to significant contributions towards improving how current commercial search engines answer health queries.</p><p>The remainder of this paper is structured as follows: Section 2 details the task, the document collection, topics, baselines, pooling strategy, and evaluation metrics; Section 3 presents the participants' approaches, while Section 4 presents their results; Section 5 concludes the paper. <ref type="bibr" coords="2,134.77,545.17,6.72,10.52" target="#b1">2</ref> The CLEF 2015 eHealth Task 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Task</head><p>The goal of the task is to design systems which improve health search, especially in the case of search for self-diagnosis information. The dataset provided to participants is comprised of a document collection, topics in various languages, and the corresponding relevance information. The collection was provided to participants after signing an agreement, through the PhysioNet website <ref type="foot" coords="2,446.57,636.88,3.97,6.12" target="#foot_0">7</ref> .</p><p>Participating teams were asked to submit up to ten runs for the English queries, and an additional ten runs for each of the multilingual query languages. Teams were required to number runs such as that run 1 was a baseline run for the team; other runs were numbered from 2 to 10, with lower numbers indicating higher priority for selection of documents to contribute to the assessment pool (i.e. run 2 was considered of higher priority than run 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Collection</head><p>The document collection provided in the CLEF 2014 eHealth Lab Task 3 <ref type="bibr" coords="3,470.07,230.75,10.52,8.74" target="#b3">[4]</ref> is also adopted in this year's task. Documents in this collection have been obtained through a large crawl of health resources on the Web; the collection contains approximately one million documents and originated from the Khresmoi project 8 <ref type="bibr" coords="3,174.65,278.57,14.61,8.74" target="#b9">[10]</ref>. The crawled domains were predominantly health and medicine sites, which were certified by the HON Foundation as adhering to the HONcode principles (appr. 60-70% of the collection), as well as other commonly used health and medicine sites such as Drugbank, Diagnosia and Trip Answers 9 . Documents consisted of web pages on a broad range of health topics and were likely targeted at both the general public and healthcare professionals. They were made available for download in their raw HTML format along with their URLs to registered participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topics</head><p>Queries were manually built with the following process: images and videos related to medical symptoms were shown to users, who were then asked which queries they would issue to a web search engine if they, or their next-of-kin, were exhibiting such symptoms. Thus, these queries aimed to simulate the situation of health consumers seeking information to understand symptoms or conditions they may be affected by; this is achieved using imaginary or video stimuli. This methodology for eliciting circumlocutory, self-diagnosis queries was shown to be effective by <ref type="bibr" coords="3,186.39,496.93,76.43,8.74">Stanton et al. [11]</ref>; Zuccon et al. <ref type="bibr" coords="3,328.22,496.93,10.52,8.74" target="#b8">[9]</ref> showed that current commercial search engines are yet far from being effective in answering such queries.</p><p>Following the methodology in <ref type="bibr" coords="3,283.56,520.95,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="3,295.73,520.95,11.62,8.74" target="#b10">11]</ref>, 23 symptoms or conditions that manifest with visual or audible signs (e.g. ringworm or croup) were selected to be presented to users to collect queries. A cohort of 12 volunteer university students and researchers based in the organisers' institutions generated the queries. English was the mother-tongue for all volunteers and they had no particular prior knowledge about the symptoms or conditions, nor they had any specific medical background: this cohort was then somehow representative of the average user of web search engines seeking health advice (although they had a higher education level than the average level). Each volunteer was given 10 conditions for which they were asked to generate up to 3 queries per condition (thus each condition/image pair was presented to more than one assessor <ref type="foot" coords="4,409.30,142.33,7.94,6.12" target="#foot_1">10</ref> ). An example of images and instructions provided to the volunteers is given in Figure <ref type="figure" coords="4,449.39,155.86,4.98,8.74" target="#fig_1">1</ref>   A total of 266 possible unique queries were collected; of these, 67 queries (22 conditions with 3 queries and 1 condition with 1 query) were selected to be used in this year's task. Queries were selected by randomly picking one query per condition (we called this the pivot query), and then manually selecting the query that appeared most similar (called most) and the one that appeared least similar (called least) to the pivot query. Candidates for the most and least queries were identified independently by three organisers and then majority voting was used to establish which queries should be selected. This set of queries formed the English query set distributed to participants to collect runs.</p><p>In addition, we developed translations of this query set into Arabic (AR), Czech (CS), German (DE), Farsi (FA), French (FR), Italian (IT) and Portuguese (PT); these formed the multilingual query sets which were made available to participants for submission of multilingual runs. Queries were translated by medical experts available at the organisers institutions.</p><p>After the query set was released, numbered qtest1-qtest67, one typo was found in query qtest62, which could compromise the translations. In order to keep consistency between the English query and all translations made by the experts, qtest62 was excluded. Thus, the final query set used in the CLEF 2015 eHealth Lab Task 2 for both English and multilingual queries consisted of 66 queries.</p><p>An example of one of the query topics generated from the image shown in Figure <ref type="figure" coords="5,165.74,156.45,4.98,8.74" target="#fig_1">1</ref> is provided in Figure <ref type="figure" coords="5,265.78,156.45,3.87,8.74">2</ref>. To develop their submissions, participants were only given the query field of each query topic, that is, teams were unaware of the query type (pivot, most, least), the target condition and the image or video that was shown to assessors to collect queries.  <ref type="figure" coords="5,404.58,387.57,3.58,7.86" target="#fig_1">1</ref>. This query is of type most and refers to the image condition 22 (as indicated by the field query index).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Relevance Assessment</head><p>Relevance assessments were collected by pooling participants' submitted runs as well as baseline runs (see below for a description of pooling methodology and baseline runs). Assessment was performed by five paid medical students employed at the Medizinische Universität Graz (Austria); assessors used Relevation! <ref type="bibr" coords="5,173.32,525.01,15.50,8.74" target="#b11">[12]</ref> to visualise and judge documents. For each document, assessors had access to the query the document was retrieved for, as well as the target symptom or condition that was used to obtained the query during the query generation phase.</p><p>Target symptoms or conditions were used to provide the relevance criteria assessors should judge against; for example for query qtest1 -"many red marks on legs after traveling from US" (the condition used for generating the query was "Rocky Mountain spotted fever (RMSF)"), the relevance criterion read "Relevant documents should contain information allowing the user to understand that they have Rocky Mountain spotted fever (RMSF).". Relevance assessments were provided on a three point scale: 0, Not Relevant; 1, Somewhat Relevant; 2, Highly Relevant.</p><p>Along with relevance assessments, readability judgements were also collected for the assessment pool. The notion of readability and understandability of information is of important concern when retrieving information for health consumers <ref type="bibr" coords="6,167.50,155.86,14.61,8.74" target="#b12">[13]</ref>. It has been shown that if the readability of information is accounted for in the evaluation framework, judgements of relative system effectiveness can vary with respect to taking into account (topical) relevance only <ref type="bibr" coords="6,422.00,179.77,15.50,8.74" target="#b13">[14]</ref> (this was the case also when considering the CLEF 2013 and 2014 eHealth Evaluation Labs).</p><p>Readability assessments were collected by asking the assessors whether they believed a patient would understand the retrieved document. Assessments were provided on a four point scale: 0, "It is very technical and difficult to read and understand"; 1, "It is somewhat technical and difficult to read and understand"; 2, "It is somewhat easy to read and understand"; 3, "It is very easy to read and understand".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Example Topics</head><p>A different set of 5 queries was released to participants as example queries (called training) to help develop their systems (both in English and the other considered languages). These queries were released together with associated relevance assessments, obtained by evaluating a pool of 112 documents retrieved by a set of baseline retrieval systems (TF-IDF, BM25, Language Model with Dirichlet smoothing as implemented in Terrier <ref type="bibr" coords="6,300.93,384.97,14.61,8.74" target="#b14">[15]</ref>, with the associated default parameter values); the pool was formed by sampling the top 10 retrieved documents for each query. Note that, given the very limited pool and system sample sizes, these example queries should not be used to evaluate, tune or train systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Baseline Systems</head><p>The organisers generated baseline runs using BM25, TF-IDF and Language Model with Dirichlet smoothing, as well as a set of benchmark systems that ranked documents by estimating both (topical) relevance and readability. Table <ref type="table" coords="6,151.16,506.49,4.98,8.74" target="#tab_1">1</ref> shows the 13 baseline systems created, 7 of them took into consideration some estimation of text readability. No baselines were created for the multilingual queries.</p><p>The first 6 baselines, named baseline1 -6, were created using either Xapian or Lucene as retrieval toolkit. We vary the retrieval model used, including BM25 (with parameters k 1 = 1, k 2 = 0, k 3 = 1 and b = 0.5) in baseline1, Vector Space Model (VSM) with TF-IDF weighting (the default Lucene implementation) in baseline2, and Language Model (LM), with Dirichlet smoothing with µ = 2, 000 in baseline3. Our preliminary runs based on the 2014 topics showed that removing HTML tags from documents in this collection could lead to higher retrieval effectiveness when using BM25 and LM. We used the python package Beauti-fulSoap (BS4) <ref type="foot" coords="6,195.89,636.42,7.94,6.12" target="#foot_3">12</ref> to parse the HTML files and remove HTML tags. Note that it does not remove the boilerplate from the HTML (such as headers or navigation menus), being one of the simplest approaches to clean a HTML page and prepare it to serve as the input of readability formulas <ref type="bibr" coords="7,344.80,143.90,15.50,8.74" target="#b15">[16]</ref> (see below). Baselines 4, 5 and 6 implement the same methods as in baselines 1, 2 and 3, respectively, but execute a query that has been enhanced by augmenting the original query with the known target disease names. Note that the target disease names were only known to the organisers, participants had no access to this information.</p><p>For the baseline runs that take into account readability estimations, we used two well-known automatic readability measures: the Dale-Chall measure <ref type="bibr" coords="7,465.09,215.63,15.50,8.74" target="#b16">[17]</ref> and Flesch-Kincaid readability index <ref type="bibr" coords="7,299.00,227.59,14.61,8.74" target="#b17">[18]</ref>. The python package ReadabilityCalculator <ref type="foot" coords="7,165.23,237.97,7.94,6.12" target="#foot_4">13</ref> was used to compute the readability measures from the cleansed web documents. We also tested a readability measure based on the frequency of words in a large collection such as Wikipedia; the intuition behind this measure is that an easy text would contain a large number of common words with high frequency in Wikipedia, while a technical and difficult text would have a large number of rare words, characterised by a low frequency in Wikipedia. In order to retrieving documents accounting for their readability levels, we first generate a readability score Read(d) for each document d in the collection using one of the three measures above. We then combine the readability score of a document with its relevance score Rel(d) generated by some retrieval model. Three score combination methods were considered:</p><formula xml:id="formula_0" coords="7,138.97,375.88,341.58,47.80">1. Linear combination: Score(d) = α × Rel(d) + (1.0 -α) × Read(d), where α is a hyperparameter and 0 ≤ α ≤ 1 (in readability1 α is 0.9) 2. Direct Multiplication: Score(d) = Rel(doc) × Read(d) 3. Inverse Logarithm: Score(d) = Rel(doc) log(Read(d))</formula><p>Table <ref type="table" coords="7,177.04,430.63,4.98,8.74" target="#tab_1">1</ref> shows the settings of retrieval model, HTML processing, readability measure and query expansion or score combination method that were considered to produce the 7 readability baselines used in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Pooling Methodology</head><p>In Task 2, for each query, the top 10 documents returned in runs 1, 2 and 3 produced by the participants <ref type="foot" coords="7,264.03,509.70,7.94,6.12" target="#foot_5">14</ref> were pooled to form the relevance assessment pool. In addition, the baseline runs developed by the organisers were also pooled with the same methodology used for participants runs. A pool depth of 10 documents was chosen because this task resembles web-based search, where often users consider only the first page of results (that is, the first 10 results). Thus, this pooling methodology allowed a full evaluation of the top 10 results for the 3 submissions with top priority for each participating team. The pooling of more submissions or a deeper pool, although preferable, was ruled out because of the limited availability of resources for document relevance assessment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Multilingual Evaluation: Additional Pooling and Relevance Assessments</head><p>Because only one team submitted runs for the multilingual queries and only limited relevance assessment capabilities were available through the paid medical students that performed the assessment of submissions for the English queries, multilingual runs were not considered when forming the pools for relevance assessments. However, additional relevance assessments were sought through the team that participated in the multilingual task: they were thus asked to perform a self-assessment of the submissions they produced. A new pool of documents was sampled with the same pooling methodology used for English runs (see the previous section). Documents that were already judged by the official assessors were excluded from the pool with the aim to limit the additional relevance assessment effort required by the team. Additional relevance assessments for the multilingual runs were then performed by a medical doctor (native Czech speaker with fluent English) associated with Team CUNI <ref type="bibr" coords="8,238.35,525.61,14.61,8.74" target="#b21">[22]</ref>. The assessor was provided with the same instructions and assessment system that the official assessors used. Assessments were collected and aggregated with those provided by the official relevance assessors to form the multilingual merged qrels. These qrels should be used with caution: at the moment of writing this paper, it is unknown whether these multilingual assessments are comparable with those compiled by the original, also medically trained, assessors. The collection of further assessments from the team to verify their agreement with the official assessors is left for future work. Another limitation of these additional relevance assessments is that only one system that considered multilingual queries, that developed by team CUNI, was sampled and thus it may further bias the assessment of retrieval systems with respect to how multilingual queries are coped with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9">Evaluation Metrics</head><p>Evaluation was performed in terms of graded and binary assessments. Binary assessments were formed by transforming the graded assessments such that label 0 was maintained (i.e. irrelevant) and labels 1 and 2 were converted to 1 (relevant). Binary assessments for the readability measures were obtained similarly, with labels 0 and 1 being converted into 0 (not readable) and labels 2 and 3 being converted into 1 (readable).</p><p>System evaluation was conducted using precision at 10 (p@10) and normalised discounted cumulative gain <ref type="bibr" coords="9,293.83,227.07,15.50,8.74" target="#b18">[19]</ref> at 10 (nDCG@10) as the primary and secondary measures, respectively. Precision was computed using the binary relevance assessments; nDCG was computed using the graded relevance assessments. These evaluation metrics were computed using trec eval with the following commands:</p><p>./trec eval -c -M1000 qrels.clef2015.test.bin.txt runName ./trec eval -c -M1000 -m ndcg cut qrels.clef2015.test.graded.txt runName respectively to compute precision and nDCG values.</p><p>A separate evaluation was conducted using both relevance assessments and readability assessments following the methods in <ref type="bibr" coords="9,348.41,347.94,14.61,8.74" target="#b13">[14]</ref>. For all runs, Rank Biased Precision (RBP) <ref type="bibr" coords="9,209.68,359.89,15.50,8.74" target="#b19">[20]</ref> was computed along with readability-biased modifications of RBP, namely uRBP (using the binary readability assessments) and uRBPgr (using the graded readability assessments).</p><p>The RBP parameter ρ which attempts to model user behaviour <ref type="foot" coords="9,442.13,394.76,7.94,6.12" target="#foot_6">15</ref> (RBP persistence parameter) was set to 0.8 for all variations of this measure, following the findings of Park and Zhang <ref type="bibr" coords="9,274.19,420.25,14.61,8.74" target="#b20">[21]</ref>.</p><p>To compute uRBP, readability assessments were mapped to binary classes, with assessments 0 and 1 (indicating low readability) mapped to value 0 and assessments 2 and 3 (indicating high readability) mapped to value 1. Then, uRBP (up to rank K) was calculated according to</p><formula xml:id="formula_1" coords="9,233.90,491.05,246.69,30.55">uRBP = (1 -ρ) K k=1 ρ k-1 r(k)u(k)<label>(1)</label></formula><p>where r(k) is the standard RBP gain function that is 1 if the document at rank k is relevant and 0 otherwise; u(k) is a similar gain function but for the readability dimension and is 1 if the document at k is readable (binary class 1), and zero otherwise (binary class 0). To compute uRBPgr, i.e. the graded version of uRBP, each readability label was mapped to a different gain value. Specifically, label 0 was assigned gain 0 (least readability, no gain), label 1 gain 0.4, label 2 gain 0.8 and label 3 gain 1 (highest readability, full gain). Thus, a document that is somewhat difficult to read does still generate a gain, which is half the gain generated by a document that is somewhat easy to read. These gains are then used to evaluate the function u(k) in Equation <ref type="formula" coords="10,211.70,131.95,4.98,8.74" target="#formula_1">1</ref>to obtain uRBPgr.</p><p>The readability-biased evaluation was performed using ubire 16 , which is publicly available for download.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Participants and Approaches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>This year, 52 groups registered for the task on the web site, 27 got access to the data and 12 submitted any run for task 2. The groups are from 9 countries in 4 continents as listed in Table <ref type="table" coords="10,255.90,251.62,3.87,8.74" target="#tab_2">2</ref>. 7 out of the 12 participants had never participated in this task before. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Participant Approaches</head><p>Team CUNI <ref type="bibr" coords="10,191.87,555.50,15.50,8.74" target="#b21">[22]</ref> used the Terrier toolkit to produce their submissions. Runs explored three different retrieval models: Bayesian smoothing with Dirichlet prior, Per-field normalisation (PL2F) and LGD. Query expansion using the UMLS metathesaurus was explored by considering terms assigned to the same concept as synonymous and choosing the terms with the highest inverse documentfrequency. Blind relevance feedback was also used as contrasting technique. Finally, they also experimented with linear interpolations of the search results produced by the above techniques.</p><p>Team ECNU <ref type="bibr" coords="11,198.51,119.99,15.50,8.74" target="#b22">[23]</ref> explored query expansion and learning to rank. For query expansion, Google was queried and the titles and snippets associated with the top ten web results were selected. Medical terms were then extracted from these resources by matching them with terms contained in MeSH; the query was then expanded using those medical terms that appeared more often than a threshold. As Learning to Rank approach, Team ECNU combined scores and ranks from BM25, PL2 and BB2 into a six-dimensional vector. The 2013 and 2014 CLEF eHealth tasks were used to train the system and a Random Forest classifier was use to calculate the new scores.</p><p>Team FDUSGInfo explored query expansion methods that use a range of knowledge resources to improve the effectiveness of a statistical Language Model baseline. The knowledge sources that have been considering for drawing expansion terms are MeSH and Freebase. Different techniques were evaluated to select the expansion terms, including manual term selection. Team FDUSGInfo, unfortunately, did not submit their working notes and thus the details of their methods are unknown.</p><p>Team GRIUM <ref type="bibr" coords="11,203.92,344.40,15.50,8.74" target="#b24">[25]</ref> explored the use of concept based query expansion. Their query expansion mechanism exploited Wikipedia articles and UMLS Concept definitions and were compared to a baseline method based on Dirichlet smoothing.</p><p>Team KISTI <ref type="bibr" coords="11,194.64,408.79,15.50,8.74" target="#b25">[26]</ref> focused on re-ranking approaches. Lucene was used for indexing and initial search, and the baseline used the query likelihood model with Dirichlet smoothing. They explored three approaches for re-ranking: explicit semantic analysis (ESA), concept-based document centrality (CBDC), and clusterbased external expansion model (CBEEM). Their submissions evaluated these re-ranking approaches as well as their combinations.</p><p>Team KUCS <ref type="bibr" coords="11,192.84,497.09,15.50,8.74" target="#b26">[27]</ref> implemented an adaptive query expansion. Based on the results returned by a query performance prediction approach, their method selected the query expansion that is hypothesised to be the most suitable for improving effectiveness. An additional process was responsible for re-ranking results based on readability estimations.</p><p>Team LIMSI <ref type="bibr" coords="11,198.17,573.43,15.50,8.74" target="#b27">[28]</ref> explored query expansion approaches that exploit external resources. Their first approach used MetaMap to identify UMLS concepts from which to extract medical terms to expand the original queries. Their second approach used a selected number of Wikipedia articles describing the most common diseases and conditions along with a selection of MedlinePlus; for each query the most relevant articles from these corpora are retrieved and their titles used to expand the original queries, which are in turn used to retrieve relevant documents from the task collection.</p><p>Team Miracl <ref type="bibr" coords="12,193.20,119.99,14.80,8.74" target="#b28">[29]</ref>'s submissions were based on blind relevance feedback combined with term selection using their previous work on modeling semantic relations between words. Their baseline run was based on the traditional Vector Space Model and the Terrier toolkit. The other runs employed the investigated method by varying settings of two method parameters: the first controlling the number of highly ranked documents from the initial retrieval step and the second controlling the degree of semantic relationship of the expansion terms.</p><p>Team HCMUS <ref type="bibr" coords="12,203.98,214.94,15.50,8.74" target="#b29">[30]</ref> experimented with two approaches. The first was based on concept-based retrieval where only medical terminological expressions in documents were retained, while other words were filtered-out. The second was based on query expansion with blind relevance feedback. Common to all their approaches was the use of Apache Lucene and a bag-of-word baseline based on Language Modelling with Dirichlet smoothing and standard stemming and stopword removal.</p><p>Team UBML <ref type="bibr" coords="12,198.66,309.89,15.50,8.74" target="#b30">[31]</ref> investigated the empirical merits of query expansion based on KL divergence and the Bose-Einstein 1 model for improving a BM25 baseline. The query expansion process selected terms from the local collection or two external collections. Learning to rank was also investigated along a Markov Random Fields approach.</p><p>Team USST <ref type="bibr" coords="12,192.01,380.93,15.50,8.74" target="#b31">[32]</ref> used BM25 as a baseline system and explored query expansion approaches. They investigated pseudo relevance feedback approaches based on Kullback-Liebler Divergence and Bose-Einstein models.</p><p>Team YorkU <ref type="bibr" coords="12,197.05,428.06,15.50,8.74" target="#b32">[33]</ref> explored BM25 and Divergence from Randomness methods as provided by the Terrier toolkit, along with the associated relevance feedback retrieval approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Findings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pooling and Coverage of Relevance Assessments</head><p>A total of 8,713 documents were assessed. Of these, 6,741 (77.4%) were assessed as irrelevant (0), 1,515 (17.4%) as somewhat relevant (1), 457 (5.2%) as highly relevant (2). For readability assessments, the recorded distribution was: 1,145 (13.1%) documents assessed as difficult (0), 1,568 (18.0%) as somewhat difficult (1), 2,769 (31.8%) as somewhat easy (2), and 3,231 (37.1%) as easy (3). Table <ref type="table" coords="12,176.92,585.38,4.98,8.74" target="#tab_3">3</ref> details the coverage of the relevance assessments with respect to the participant submissions, averaged over the whole query set. While in theory all runs 1-3 should have full coverage (100%), in practice a small portion of documents included in the relevance assessment pool were left unjudged because the documents were not in the collection (participants provided an invalid document identifier) or the page failed to render in the relevance assessment toolkit (for example because the page contained redirect scripts or other scripts that were ). Overall, the mean coverage for runs 1-3 was above 99%, with only run 3 from team KUCS being sensibly below this value. This suggests that the retrieval effectiveness for runs 1-3 can be reliably measured. The coverage beyond submissions 3 is lower but always above 90% (and the mean above 95%); this suggest that the evaluation of runs 4-10 in terms of precision at 10 may be underestimated of an average maximum of 0.05 points over the whole query set. Table <ref type="table" coords="13,176.38,366.46,4.98,8.74">4</ref> details the coverage of relevance assessment for the multilingual runs. As mentioned in Section 2.8, due to limited relevance assessment availability, only the English runs were considered when forming the pool for relevance assessment. The coverage of these relevance assessments with respect to the top 10 documents ranked by each participants' submissions is shown in the columns marked as Eng. in Table <ref type="table" coords="13,173.39,426.23,3.87,8.74">4</ref>. An additional document pool, made using only documents in runs1-3 of multilingual submissions, was created to further increase the coverage of multilingual submissions; the coverage of the union of the original assessments and these additional ones (referred to as merged ) is shown in the columns marked as Merged in Table <ref type="table" coords="13,226.38,474.05,4.98,8.74">4</ref> for the multilingual runs. The merged set of relevance assessments was enough to provide a fairly high coverage for all runs, including those not in the pool (i.e., runs beyond number 3), with a minimal coverage of 97%; this is likely because only one team submitted runs for the multilingual challenge, thus providing only minimal variation in terms of top retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Results and Findings</head><p>Table <ref type="table" coords="13,161.52,580.54,4.98,8.74" target="#tab_5">5</ref> reports the evaluation of the participants submissions and the organisers baselines based on P@10 and nDCG@10 for English queries. The evaluation based on RBP and the readability measures is reported in Table <ref type="table" coords="13,419.17,604.45,3.87,8.74" target="#tab_6">6</ref>.</p><p>Most of the approaches developed by team ECNU obtain significantly higher values of P@10 and nDCG@10 compared to the other participants, demonstrat-Table <ref type="table" coords="14,164.40,116.91,4.13,7.89">4</ref>. Coverage of the relevance assessments for the top 10 results submitted by CUNI in the multilingual evaluation. As described in Section 2.8, two set of qrels were used: those for the English task (Eng.), and those produced by merging the assessments for English queries and the ones for multilingual queries (Merged.) ing about 40% increase in effectiveness in their best run compared to the runnerup team (KISTI). The best submission developed by the organisers and based on both relevance and readability estimates has been proved difficult to outperform by most teams (only 4 out of 12 teams obtained higher effectiveness). The pooling methodology does not appear to have significantly influenced the evaluation of non-pooled submissions, as demonstrated by the fact that the best runs of some teams are not those that were fully pooled (e.g. team KISTI, team CUNI, team GRIUM).</p><formula xml:id="formula_2" coords="14,140.35,176.93,14.53,5.81">Run</formula><p>There are no large differences between system rankings produced using P@10 or nDCG@10 as evaluation measure (Kendall τ = 0.88). This is unlike when readability is also considered in the evaluation (the Kendall τ between system rankings obtained with P@10 or uRBP is 0.76). In this latter case, while ECNU's submissions are confirmed to be the most effective, there are large variations in system rankings when compared to those obtained considering relevance judgements only. In particular, runs from team KISTI, which in the relevance-based evaluation were ranked among the top 20 runs, are not performing as well when considering also readability, with their top run (KISTI EN RUN.7) being ranked only 37th according to uRBP.</p><p>The following considerations could be drawn when comparing the different methods employed by the participating teams. Query expansion is found to often improve results. In particular, team ECNU obtained the highest effectiveness among the systems that took part in this task; this was achieved when query expansion terms are mined from Google search results returned for the original queries (ECNU EN Run.3). This approach indeed obtained higher effectiveness compared to learning-to-rank alternatives (ECNU EN Run.10). The results of team UBML show that query expansion using the Bose-Einstein model 1 and the local collection works better than other query expansion methods and external collections. Team USST also found that query expansion was effective to improve results, however they found that the Bose-Einstein models did not provide improvements over their baseline, while the Kullback-Liebler Divergence based query expansion provided minor improvements. Health-specific query expansion methods based on the UMLS were shown to be effective above common baselines and other considered query expansion methods by Team LIMSI and GRIUM (this form of query expansion was the only one that delivered higher effectiveness than their baseline).Team KISTI found that the combination of concept-based document centrality (CBDC) and cluster-based external expansion model (CBEEM) improved the results best. Few teams did not observe improvements over their baselines; this was the case for teams KUCS, Miracl, FDUSGInfo and HCMUS.</p><p>Tables <ref type="table" coords="15,181.52,245.30,4.98,8.74" target="#tab_7">7</ref> and<ref type="table" coords="15,210.16,245.30,4.98,8.74" target="#tab_8">8</ref> report the evaluation of the multilingual submissions based on P@10 and nDCG@10; results are reported with respect to both the original qrels (obtained by sampling English runs only) and the additional qrels (obtained by sampling also multilingual runs, but using a different set of assessors); see Section 2.8 for details about the difference between these relevance assessments. Only one team (CUNI) participated in the multilingual task; they also submitted to the English-based task and thus it is possible to discuss the effectiveness of their retrieval system when answering multilingual queries compared to that achieved when answering English queries.</p><p>The evaluation based on the original qrels allows us to compare multilingual runs directly with English runs. Note that the original relevance assessments exhibit a level of coverage for the multilingual runs that is similar to those obtained for English submissions numbered 4-10. The evaluation based on the additional qrels (merged) allows analysis of the multilingual runs using the same pooling method used for English runs; thus submissions 1-3 for the multilingual runs can be directly compared to the corresponding English ones, at the net of differences in expertise, sensibility and systematic errors between the paid medical assessors and the volunteer, student self-assessor used to gather judgements for the multilingual runs.</p><p>When only multilingual submissions are considered, it can be observed that there is not a language in which CUNI's system is more effective: e.g. submissions that considered Italian queries are among the best performing with original assessments and are the best performing with the additional assessments, but differences in effectiveness among top runs for different languages are not statistically significant. However, it can be observed that none of CUNI's submissions that addressed queries expressed in not European languages (Farsi and Arabic) are among the top ranked systems, regardless of the type of relevance assessments.</p><p>The use of the additional relevance assessments naturally translates in observing increased retrieval effectiveness across all multilingual runs (because some of the documents in the top 10 ranks that were not assessed, and thus irrelevant, in the original assessments may have been marked as relevant in the additional assessments). However, a noteworthy observation is that the majority of the most effective runs according to the additional assessments are those that were not fully sampled to form the relevance assessment pools (i.e. runs 4-10, as opposed to the pooled runs 1-3).</p><p>When the submissions of team CUNI are compared across English and multilingual queries, it is possible to observe that the best multilingual runs do not outperform English runs (unlike when the same comparison was instructed in the 2014 task <ref type="bibr" coords="16,198.56,180.63,10.30,8.74" target="#b3">[4]</ref>), regardless of the type of relevance assessments. This result does not come as unexpected and it indicates that the translation from a foreign language to English as part of the retrieval process does degrade the quality of queries (in terms of retrieval effectiveness), suggesting that more work is needed to bridge the gap in effectiveness between English and multilingual queries when these are used to retrieve English content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper has described methods, results and analysis of the CLEF 2015 eHealth Evaluation Lab, Task 2. The task considered the problem of retrieving web pages for people seeking health information regarding unknown conditions or symptoms. 12 teams participated in the task; the results have shown that query expansion plays an important role in improving search effectiveness. The best results were achieved by a query expansion method that mined the top results from the Google search engine. Despite the improvements over the organisers' baselines achieved by some teams, further work is needed to sensibly improve search in this context, as only about half of the top 10 results retrieved by the best system were found to be relevant.</p><p>As a by-product of this evaluation exercise, the task contributes to the research community a collection with associated assessments and evaluation framework (including readability evaluation) that can be used to evaluate the effectiveness of retrieval methods for health information seeking on the web. Queries, assessments and participants runs are publicly available at http://github.com/ CLEFeHealth/CLEFeHealth2015Task2. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,454.37,154.28,7.94,6.12;4,462.81,155.86,2.77,8.74;4,134.77,189.45,282.44,7.47;4,134.77,200.41,371.87,7.47;4,134.77,211.37,61.20,7.47;4,134.77,222.33,211.83,7.47;4,134.77,233.29,258.90,7.47"><head>11 .</head><label>11</label><figDesc>Imagine you are experiencing the health problem shown below. Please provide 3 search queries that you would issue to find out what is wrong. Instructions: * You must provide 3 distinct search queries. * The search queries must relate to what you see below.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,134.77,359.94,345.82,7.89;4,134.77,370.93,97.43,7.86;4,134.77,251.71,172.92,93.46"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example of instructions and images provided to volunteers for generating potential search queries.</figDesc><graphic coords="4,134.77,251.71,172.92,93.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,238.78,266.13,156.66"><head></head><label></label><figDesc>Example query topic generated from the image of Figure</figDesc><table coords="5,134.77,238.78,240.07,156.66"><row><cell>&lt;topics&gt;</cell></row><row><cell>...</cell></row><row><cell>&lt;top&gt;</cell></row><row><cell>&lt;num&gt;qtest.23&lt;/num&gt;</cell></row><row><cell>&lt;query&gt;red bloodshot eyes&lt;/query&gt;</cell></row><row><cell>&lt;disease&gt;non-ulcerative sterile keratitis&lt;/disease&gt;</cell></row><row><cell>&lt;type&gt;most&lt;/type&gt;</cell></row><row><cell>&lt;query_index&gt;22&lt;/query_index&gt;</cell></row><row><cell>&lt;/top&gt;</cell></row><row><cell>...</cell></row><row><cell>&lt;/topics&gt;</cell></row><row><cell>Fig. 2.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,116.91,345.83,190.46"><head>Table 1 .</head><label>1</label><figDesc>Scheme showing the settings of retrieval model, HTML processing, readability measure and query expansion or score combination used to generate the organisers baselines.</figDesc><table coords="8,138.85,160.61,337.66,146.76"><row><cell>System</cell><cell cols="4">Index Model Cleaning Expansion/Combination Readability</cell></row><row><cell>baseline1</cell><cell cols="2">Xapian BM25 BS4</cell><cell>-</cell><cell>-</cell></row><row><cell>baseline2</cell><cell cols="2">Lucene VSM -</cell><cell>-</cell><cell>-</cell></row><row><cell>baseline3</cell><cell>Lucene LM</cell><cell>BS4</cell><cell>-</cell><cell>-</cell></row><row><cell>baseline4</cell><cell cols="2">Xapian BM25 BS4</cell><cell>Disease Name added</cell><cell>-</cell></row><row><cell>baseline5</cell><cell cols="2">Lucene VSM -</cell><cell>Disease Name added</cell><cell>-</cell></row><row><cell>baseline6</cell><cell>Lucene LM</cell><cell>BS4</cell><cell>Disease Name added</cell><cell>-</cell></row><row><cell cols="3">readability1 Xapian BM25 BS4</cell><cell>Linear Combination</cell><cell>Dale-Chall</cell></row><row><cell cols="3">readability2 Xapian BM25 BS4</cell><cell>Direct Multiplication</cell><cell>Wikipedia Frequency</cell></row><row><cell cols="3">readability3 Xapian BM25 BS4</cell><cell>Inverse Logarithm</cell><cell>Dale-Chall</cell></row><row><cell cols="3">readability4 Xapian BM25 BS4</cell><cell>Inverse Logarithm</cell><cell>Flesch-Kincaid</cell></row><row><cell cols="3">readability5 Lucene VSM -</cell><cell>Direct Multiplication</cell><cell>Wikipedia Frequency</cell></row><row><cell cols="3">readability6 Lucene VSM BS4</cell><cell>Inverse Logarithm</cell><cell>Dale-Chall</cell></row><row><cell cols="3">readability7 Lucene VSM BS4</cell><cell>Inverse Logarithm</cell><cell>Flesch-Kincaid</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,162.90,292.49,289.56,196.47"><head>Table 2 .</head><label>2</label><figDesc>Participants for task 2 and their total number of submissions.</figDesc><table coords="10,165.76,316.45,283.84,172.51"><row><cell cols="2">Continent Country</cell><cell>Team Name</cell><cell cols="2">Runs Submitted English Multilingual</cell></row><row><cell>Africa</cell><cell>Botswana Tunisia</cell><cell>UBML Miracl</cell><cell>10 5</cell><cell>--</cell></row><row><cell>America</cell><cell>Canada Canada</cell><cell>GRIUM YORKU</cell><cell>7 10</cell><cell>--</cell></row><row><cell></cell><cell>China</cell><cell>ECNU</cell><cell>10</cell><cell>-</cell></row><row><cell></cell><cell>China</cell><cell>FDUSGInfo</cell><cell>10</cell><cell>-</cell></row><row><cell>Asia</cell><cell>China South Korea</cell><cell>USST KISTI</cell><cell>10 8</cell><cell>--</cell></row><row><cell></cell><cell>Thailand</cell><cell>KU-CS</cell><cell>4</cell><cell>-</cell></row><row><cell></cell><cell>Vietnam</cell><cell>HCMUS</cell><cell>8</cell><cell>-</cell></row><row><cell>Europe</cell><cell>Czech Republic France</cell><cell>CUNI LIMSI</cell><cell>10 5</cell><cell>70 -</cell></row><row><cell>Total</cell><cell>9 Countries</cell><cell>12 Teams</cell><cell>97</cell><cell>70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,134.77,116.91,345.83,174.60"><head>Table 3 .</head><label>3</label><figDesc>Coverage of the relevance assessments for the top 10 results submitted by participants in the task: 100% means that all top 10 results for all queries have been assessed; 90% means that, on average, 9 out of 10 documents in the top 10 results have been assessed, with one document being left unjudged.</figDesc><table coords="13,134.77,171.75,343.11,119.76"><row><cell cols="13">Run Baseline Readab. CUNI ENUC FDUSG. GRIUM KISTI KUCS LIMSI Miracl HCMUS UBML USST YorkU Mean</cell></row><row><cell>1</cell><cell>99.98</cell><cell>100.0</cell><cell>100.0 99.98</cell><cell>98.77</cell><cell>100.0</cell><cell cols="4">100.0 99.64 99.83 99.98</cell><cell>99.92</cell><cell cols="2">99.92 100.0 99.62 99.83</cell></row><row><cell>2</cell><cell>99.82</cell><cell>99.98</cell><cell>100.0 99.88</cell><cell>98.77</cell><cell>100.0</cell><cell cols="4">99.98 98.77 99.92 99.98</cell><cell>99.89</cell><cell cols="2">100.0 100.0 100.0 99.79</cell></row><row><cell>3</cell><cell>99.98</cell><cell>99.95</cell><cell>99.94 99.95</cell><cell>98.77</cell><cell>100.0</cell><cell cols="4">100.0 92.61 99.85 100.0</cell><cell>99.79</cell><cell cols="2">100.0 100.0 100.0 99.35</cell></row><row><cell>4</cell><cell>93.64</cell><cell>94.65</cell><cell>99.95 99.86</cell><cell>98.08</cell><cell>99.65</cell><cell cols="4">99.80 91.58 92.00 96.82</cell><cell>97.65</cell><cell cols="2">98.38 98.64 99.98 97.19</cell></row><row><cell>5</cell><cell>92.61</cell><cell>99.15</cell><cell>99.58 96.00</cell><cell>97.91</cell><cell>99.94</cell><cell>99.58</cell><cell>-</cell><cell cols="2">92.00 99.15</cell><cell>94.67</cell><cell cols="2">98.42 98.30 99.85 97.47</cell></row><row><cell>6</cell><cell>93.74</cell><cell>98.89</cell><cell>99.23 98.11</cell><cell>91.65</cell><cell>99.98</cell><cell>99.73</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>93.12</cell><cell cols="2">98.58 97.91 99.68 97.33</cell></row><row><cell>7</cell><cell>-</cell><cell>97.33</cell><cell>99.79 96.56</cell><cell>91.65</cell><cell>99.98</cell><cell>99.70</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>94.65</cell><cell cols="2">99.48 96.24 99.53 97.49</cell></row><row><cell>8</cell><cell>-</cell><cell>-</cell><cell>99.98 98.76</cell><cell>91.65</cell><cell>-</cell><cell>99.73</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>93.14</cell><cell cols="2">98.29 95.85 99.23 97.08</cell></row><row><cell>9</cell><cell>-</cell><cell>-</cell><cell>99.61 99.79</cell><cell>91.33</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">98.45 95.24 98.83 97.21</cell></row><row><cell>10</cell><cell>-</cell><cell>-</cell><cell>97.94 98.70</cell><cell>91.33</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">97.70 95.06 98.33 96.51</cell></row><row><cell cols="2">Mean 96.63</cell><cell>98.57</cell><cell>99.60 98.76</cell><cell>94.99</cell><cell>99.94</cell><cell cols="4">99.81 95.65 96.72 99.19</cell><cell>96.60</cell><cell>98.92 97.72 99.51</cell><cell>98</cell></row><row><cell cols="6">not executed within Relevation 17</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="14,138.05,172.90,339.25,113.53"><head></head><label></label><figDesc>Mean 94.99 98.93 94.15 98.37 95.39 98.85 95.30 98.71 95.19 99.23 95.21 99.37 95.60 99.00</figDesc><table coords="14,143.71,172.90,333.60,101.78"><row><cell></cell><cell>AR</cell><cell>CS</cell><cell>DE</cell><cell>FA</cell><cell>FR</cell><cell>IT</cell><cell>PT</cell></row><row><cell></cell><cell cols="7">Eng. Merged Eng. Merged Eng. Merged Eng. Merged Eng. Merged Eng. Merged Eng. Merged</cell></row><row><cell>1</cell><cell cols="7">95.32 99.97 94.52 99.94 95.21 99.80 95.59 99.91 95.14 99.91 95.48 99.95 95.76 99.94</cell></row><row><cell>2</cell><cell cols="7">94.95 99.91 93.88 99.82 94.85 99.82 95.36 99.89 94.59 99.92 95.35 99.85 95.56 99.91</cell></row><row><cell>3</cell><cell cols="7">94.64 99.91 93.74 99.86 94.70 99.91 95.11 99.91 94.65 99.92 94.89 99.89 95.18 99.83</cell></row><row><cell>4</cell><cell cols="7">95.20 99.77 94.09 99.79 95.11 99.77 95.62 99.79 94.88 99.88 95.58 99.89 95.83 99.85</cell></row><row><cell>5</cell><cell cols="7">95.00 98.03 94.02 97.32 94.98 97.47 95.29 97.70 94.67 98.56 95.14 98.97 95.65 98.33</cell></row><row><cell>6</cell><cell cols="7">95.03 98.03 94.11 98.56 94.35 98.26 95.42 97.71 94.59 98.56 95.15 99.05 95.91 98.30</cell></row><row><cell>7</cell><cell cols="7">94.73 97.73 94.29 97.36 96.47 98.91 94.85 97.30 96.00 99.29 94.76 98.98 95.42 97.88</cell></row><row><cell>8</cell><cell cols="7">95.03 98.12 94.45 97.21 96.11 98.21 95.42 97.68 95.89 98.73 95.18 98.94 95.94 98.27</cell></row><row><cell>9</cell><cell cols="7">94.64 98.29 94.00 96.52 95.47 97.58 94.62 97.73 95.33 98.29 95.00 98.48 94.80 98.18</cell></row><row><cell cols="8">10 95.33 99.55 94.38 97.29 96.62 98.76 95.70 99.48 96.17 99.24 95.59 99.70 95.94 99.48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="19,138.47,121.78,338.42,533.90"><head>Table 5 .</head><label>5</label><figDesc>Participants and baseline results sorted by p@10.</figDesc><table coords="19,138.47,144.87,338.42,510.82"><row><cell>R Run Name</cell><cell cols="3">p@10 nDCG@10 R Run Name</cell><cell cols="2">p@10 nDCG@10</cell></row><row><cell>1 ECNU EN Run.3</cell><cell cols="3">0.5394 0.5086 55 readability run.6</cell><cell>0.2970</cell><cell>0.2456</cell></row><row><cell>2 ECNU EN Run.10</cell><cell>0.4667</cell><cell>0.4525</cell><cell>57 Miracl EN Run.5</cell><cell>0.2939</cell><cell>0.2465</cell></row><row><cell>3 ECNU EN Run.8</cell><cell>0.4530</cell><cell>0.4226</cell><cell>57 YorkU EN Run.8</cell><cell>0.2939</cell><cell>0.2729</cell></row><row><cell>4 ECNU EN Run.6</cell><cell>0.4227</cell><cell>0.3978</cell><cell>59 YorkU EN Run.2</cell><cell>0.2924</cell><cell>0.2714</cell></row><row><cell>5 KISTI EN RUN.6</cell><cell cols="3">0.3864 0.3464 59 YorkU EN Run.4</cell><cell>0.2924</cell><cell>0.2717</cell></row><row><cell>5 KISTI EN RUN.8</cell><cell>0.3864</cell><cell>0.3464</cell><cell>59 YorkU EN Run.6</cell><cell>0.2924</cell><cell>0.2694</cell></row><row><cell>7 CUNI EN Run.7</cell><cell cols="2">0.3803 0.3465</cell><cell cols="2">62 FDUSGInfo EN Run.4 0.2848</cell><cell>0.2687</cell></row><row><cell>8 KISTI EN RUN.4</cell><cell>0.3788</cell><cell>0.3424</cell><cell>62 baseline run.4</cell><cell>0.2848</cell><cell>0.3483</cell></row><row><cell>9 CUNI EN Run.4</cell><cell>0.3742</cell><cell>0.3409</cell><cell cols="2">64 FDUSGInfo EN Run.5 0.2803</cell><cell>0.2665</cell></row><row><cell>10 KISTI EN RUN.7</cell><cell>0.3727</cell><cell>0.3459</cell><cell>64 YorkU EN Run.3</cell><cell>0.2803</cell><cell>0.2719</cell></row><row><cell>11 CUNI EN Run.1</cell><cell>0.3712</cell><cell>0.3423</cell><cell>66 YorkU EN Run.9</cell><cell>0.2788</cell><cell>0.2637</cell></row><row><cell>11 CUNI EN Run.2</cell><cell>0.3712</cell><cell>0.3351</cell><cell>67 UBML EN Run.5</cell><cell>0.2773</cell><cell>0.2500</cell></row><row><cell>13 ECNU EN Run.4</cell><cell>0.3652</cell><cell>0.3168</cell><cell>68 UBML EN Run.4</cell><cell>0.2742</cell><cell>0.2460</cell></row><row><cell>14 HCMUS EN Run.1</cell><cell cols="3">0.3636 0.3323 69 USST EN Run.4</cell><cell>0.2727</cell><cell>0.2305</cell></row><row><cell>15 CUNI EN Run.8</cell><cell>0.3621</cell><cell>0.3383</cell><cell>70 UBML EN Run.9</cell><cell>0.2697</cell><cell>0.2538</cell></row><row><cell>16 CUNI EN Run.6</cell><cell>0.3606</cell><cell>0.3364</cell><cell>70 YorkU EN Run.10</cell><cell>0.2667</cell><cell>0.2546</cell></row><row><cell>16 ECNU EN Run.2</cell><cell>0.3606</cell><cell>0.3220</cell><cell>72 UBML EN Run.8</cell><cell>0.2652</cell><cell>0.2533</cell></row><row><cell>16 ECNU EN Run.9</cell><cell>0.3606</cell><cell>0.3203</cell><cell>73 LIMSI EN run.3</cell><cell cols="2">0.2621 0.1960</cell></row><row><cell>16 KISTI EN RUN.1</cell><cell>0.3606</cell><cell>0.3352</cell><cell>73 UBML EN Run.6</cell><cell>0.2621</cell><cell>0.2265</cell></row><row><cell>16 KISTI EN RUN.5</cell><cell>0.3606</cell><cell>0.3362</cell><cell>73 baseline run.6</cell><cell>0.2621</cell><cell>0.3123</cell></row><row><cell>16 readability run.2</cell><cell cols="4">0.3606 0.3299 76 FDUSGInfo EN Run.2 0.2606</cell><cell>0.2488</cell></row><row><cell>22 KISTI EN RUN.3</cell><cell>0.3591</cell><cell>0.3395</cell><cell>76 HCMUS EN Run.3</cell><cell>0.2606</cell><cell>0.2341</cell></row><row><cell>23 CUNI EN Run.5</cell><cell>0.3530</cell><cell>0.3217</cell><cell>78 KUCS EN Run.1</cell><cell cols="2">0.2545 0.2205</cell></row><row><cell>23 CUNI EN Run.9</cell><cell>0.3530</cell><cell>0.3215</cell><cell>79 Miracl EN Run.3</cell><cell>0.2515</cell><cell>0.1833</cell></row><row><cell>25 CUNI EN Run.3</cell><cell>0.3485</cell><cell>0.3138</cell><cell>80 UBML EN Run.10</cell><cell>0.2485</cell><cell>0.2294</cell></row><row><cell>26 ECNU EN Run.1</cell><cell>0.3470</cell><cell>0.3144</cell><cell>81 USST EN Run.5</cell><cell>0.2470</cell><cell>0.2082</cell></row><row><cell>27 KISTI EN RUN.2</cell><cell>0.3455</cell><cell>0.3223</cell><cell>81 USST EN Run.6</cell><cell>0.2470</cell><cell>0.2056</cell></row><row><cell>28 readability run.1</cell><cell>0.3424</cell><cell>0.3226</cell><cell>83 USST EN Run.7</cell><cell>0.2439</cell><cell>0.2220</cell></row><row><cell>29 USST EN Run.2</cell><cell cols="3">0.3379 0.3000 84 Miracl EN Run.2</cell><cell>0.2424</cell><cell>0.1965</cell></row><row><cell>30 readability run.3</cell><cell>0.3364</cell><cell>0.2890</cell><cell cols="2">85 FDUSGInfo EN Run.3 0.2348</cell><cell>0.2234</cell></row><row><cell>31 HCMUS EN Run.2</cell><cell>0.3348</cell><cell>0.3137</cell><cell>86 LIMSI EN run.1</cell><cell>0.2318</cell><cell>0.1801</cell></row><row><cell>32 baseline run.1</cell><cell cols="3">0.3333 0.3151 87 LIMSI EN run.2</cell><cell>0.2303</cell><cell>0.1675</cell></row><row><cell>33 baseline run.3</cell><cell>0.3242</cell><cell>0.2960</cell><cell>88 KUCS EN Run.2</cell><cell>0.2288</cell><cell>0.1980</cell></row><row><cell>34 ECNU EN Run.7</cell><cell>0.3227</cell><cell>0.3004</cell><cell>88 readability run.7</cell><cell>0.2288</cell><cell>0.1834</cell></row><row><cell>35 Miracl EN Run.1</cell><cell cols="3">0.3212 0.2787 90 USST EN Run.8</cell><cell>0.1985</cell><cell>0.1757</cell></row><row><cell>36 UBML EN Run.2</cell><cell cols="3">0.3197 0.2909 91 HCMUS EN Run.4</cell><cell>0.1955</cell><cell>0.1866</cell></row><row><cell>37 GRIUM EN Run.6</cell><cell cols="3">0.3182 0.2944 91 baseline run.5</cell><cell>0.1955</cell><cell>0.2417</cell></row><row><cell>37 UBML EN Run.3</cell><cell>0.3182</cell><cell>0.2919</cell><cell>93 Miracl EN Run.4</cell><cell>0.1894</cell><cell>0.1572</cell></row><row><cell>39 GRIUM EN Run.3</cell><cell>0.3167</cell><cell>0.2913</cell><cell>93 YorkU EN Run.1</cell><cell>0.1894</cell><cell>0.1718</cell></row><row><cell>40 ECNU EN Run.5</cell><cell>0.3152</cell><cell>0.3006</cell><cell>95 HCMUS EN Run.5</cell><cell>0.1545</cell><cell>0.1574</cell></row><row><cell>41 GRIUM EN Run.1</cell><cell>0.3136</cell><cell>0.2875</cell><cell>96 HCMUS EN Run.7</cell><cell>0.1470</cell><cell>0.1550</cell></row><row><cell>42 UBML EN Run.1</cell><cell>0.3106</cell><cell>0.2897</cell><cell>97 USST EN Run.9</cell><cell>0.1439</cell><cell>0.1241</cell></row><row><cell>43 GRIUM EN Run.2</cell><cell>0.3091</cell><cell>0.2850</cell><cell>98 USST EN Run.10</cell><cell>0.1348</cell><cell>0.1145</cell></row><row><cell>43 UBML EN Run.7</cell><cell>0.3091</cell><cell>0.2887</cell><cell>99 readability run.4</cell><cell>0.1227</cell><cell>0.0958</cell></row><row><cell>45 readability run.5</cell><cell>0.3076</cell><cell>0.2595</cell><cell>100 HCMUS EN Run.6</cell><cell>0.1045</cell><cell>0.1139</cell></row><row><cell>46 GRIUM EN Run.7</cell><cell>0.3061</cell><cell>0.2798</cell><cell>101 HCMUS EN Run.8</cell><cell>0.0970</cell><cell>0.1078</cell></row><row><cell>47 GRIUM EN Run.5</cell><cell>0.3045</cell><cell>0.2803</cell><cell cols="2">102 FDUSGInfo EN Run.6 0.0773</cell><cell>0.0708</cell></row><row><cell>47 USST EN Run.1</cell><cell>0.3045</cell><cell>0.2841</cell><cell cols="2">102 FDUSGInfo EN Run.7 0.0773</cell><cell>0.0708</cell></row><row><cell>49 GRIUM EN Run.4</cell><cell>0.3030</cell><cell>0.2788</cell><cell cols="2">102 FDUSGInfo EN Run.8 0.0773</cell><cell>0.0708</cell></row><row><cell>49 USST EN Run.3</cell><cell>0.3030</cell><cell>0.2627</cell><cell cols="2">105 FDUSGInfo EN Run.9 0.0682</cell><cell>0.0602</cell></row><row><cell>51 YorkU EN Run.7</cell><cell cols="4">0.3015 0.2766 105 FDUSGInfo EN Run.10 0.0682</cell><cell>0.0602</cell></row><row><cell>51 baseline run.2</cell><cell>0.3015</cell><cell>0.2479</cell><cell>107 LIMSI EN run.4</cell><cell>0.0561</cell><cell>0.0378</cell></row><row><cell>53 CUNI EN Run.10</cell><cell>0.3000</cell><cell>0.2597</cell><cell>107 LIMSI EN run.5</cell><cell>0.0561</cell><cell>0.0378</cell></row><row><cell>53 YorkU EN Run.5</cell><cell>0.3000</cell><cell>0.2752</cell><cell>109 KUCS EN Run.3</cell><cell>0.0364</cell><cell>0.0299</cell></row><row><cell cols="4">55 FDUSGInfo EN Run.1 0.2970 0.2718 110 KUCS EN Run.4</cell><cell>0.0182</cell><cell>0.0163</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="20,138.67,180.84,338.34,416.05"><head>Table 6 .</head><label>6</label><figDesc>Participants and baseline results sorted by uRBP.</figDesc><table coords="20,138.67,203.52,338.34,393.36"><row><cell>R Run Name</cell><cell>RBP uRBP uRBPgr R Run Name</cell><cell>RBP uRBP uRBPgr</cell></row><row><cell>1 ECNU EN Run.3</cell><cell cols="2">0.5339 0.3877 0.4046 56 FDUSGInfo EN Run.4 0.3019 0.2373 0.2393</cell></row><row><cell>2 ECNU EN Run.10</cell><cell>0.4955 0.3768 0.3873 57 YorkU EN Run.6</cell><cell>0.3081 0.2365 0.2431</cell></row><row><cell>3 CUNI EN Run.7</cell><cell>0.3946 0.3422 0.3312 58 YorkU EN Run.5</cell><cell>0.3109 0.2357 0.2416</cell></row><row><cell>4 ECNU EN Run.6</cell><cell>0.4459 0.3374 0.3453 59 UBML EN Run.8</cell><cell>0.2978 0.2352 0.2368</cell></row><row><cell>5 CUNI EN Run.2</cell><cell>0.3796 0.3354 0.3239 60 UBML EN Run.6</cell><cell>0.2766 0.2348 0.2310</cell></row><row><cell>6 CUNI EN Run.5</cell><cell cols="2">0.3736 0.3295 0.3169 61 FDUSGInfo EN Run.5 0.2989 0.2340 0.2356</cell></row><row><cell>7 CUNI EN Run.9</cell><cell>0.3727 0.3287 0.3163 62 YorkU EN Run.2</cell><cell>0.3151 0.2334 0.2404</cell></row><row><cell>8 CUNI EN Run.4</cell><cell>0.3894 0.3284 0.3256 63 UBML EN Run.9</cell><cell>0.2993 0.2332 0.2362</cell></row><row><cell>9 ECNU EN Run.8</cell><cell>0.4472 0.3273 0.3373 64 YorkU EN Run.4</cell><cell>0.3152 0.2319 0.2397</cell></row><row><cell>10 ECNU EN Run.9</cell><cell>0.3730 0.3249 0.3107 65 KUCS EN Run.1</cell><cell>0.2785 0.2312 0.2251</cell></row><row><cell>11 CUNI EN Run.6</cell><cell>0.3779 0.3224 0.3152 66 baseline run.4</cell><cell>0.3196 0.2291 0.2323</cell></row><row><cell>12 CUNI EN Run.3</cell><cell>0.3650 0.3218 0.3110 67 Miracl EN Run.5</cell><cell>0.2982 0.2262 0.2357</cell></row><row><cell>13 readability run.2</cell><cell>0.3756 0.3154 0.3117 68 UBML EN Run.4</cell><cell>0.2953 0.2255 0.2300</cell></row><row><cell>14 readability run.1</cell><cell cols="2">0.3675 0.3140 0.3064 69 FDUSGInfo EN Run.2 0.2757 0.2237 0.2252</cell></row><row><cell>15 ECNU EN Run.4</cell><cell>0.3638 0.3103 0.2990 70 UBML EN Run.5</cell><cell>0.2960 0.2220 0.2279</cell></row><row><cell>16 ECNU EN Run.1</cell><cell>0.3549 0.3080 0.2971 71 YorkU EN Run.3</cell><cell>0.3074 0.2216 0.2300</cell></row><row><cell>17 readability run.3</cell><cell>0.3390 0.3067 0.2929 72 USST EN Run.3</cell><cell>0.3148 0.2181 0.2336</cell></row><row><cell>18 CUNI EN Run.8</cell><cell>0.3842 0.3060 0.3102 73 UBML EN Run.10</cell><cell>0.2658 0.2125 0.2159</cell></row><row><cell>19 CUNI EN Run.1</cell><cell cols="2">0.3824 0.3027 0.3081 74 FDUSGInfo EN Run.3 0.2518 0.2114 0.2087</cell></row><row><cell>20 HCMUS EN Run.1</cell><cell>0.3715 0.3017 0.3062 75 USST EN Run.7</cell><cell>0.2726 0.2055 0.2102</cell></row><row><cell>21 baseline run.1</cell><cell>0.3567 0.2990 0.2933 76 LIMSI EN run.3</cell><cell>0.2417 0.2036 0.2060</cell></row><row><cell>22 ECNU EN Run.2</cell><cell>0.3527 0.2917 0.2830 77 baseline run.6</cell><cell>0.2843 0.2035 0.2143</cell></row><row><cell>23 ECNU EN Run.7</cell><cell>0.3548 0.2841 0.2869 78 HCMUS EN Run.3</cell><cell>0.2700 0.2012 0.2089</cell></row><row><cell>24 GRIUM EN Run.2</cell><cell>0.3305 0.2809 0.2768 79 USST EN Run.4</cell><cell>0.2815 0.1978 0.2110</cell></row><row><cell>25 UBML EN Run.7</cell><cell>0.3339 0.2795 0.2772 80 LIMSI EN run.1</cell><cell>0.2296 0.1929 0.1889</cell></row><row><cell>26 GRIUM EN Run.6</cell><cell>0.3306 0.2791 0.2761 81 KUCS EN Run.2</cell><cell>0.2562 0.1818 0.1906</cell></row><row><cell>27 GRIUM EN Run.5</cell><cell>0.3278 0.2780 0.2744 82 LIMSI EN run.2</cell><cell>0.2163 0.1815 0.1774</cell></row><row><cell>28 GRIUM EN Run.4</cell><cell>0.3244 0.2778 0.2719 83 USST EN Run.5</cell><cell>0.2540 0.1746 0.1890</cell></row><row><cell>29 GRIUM EN Run.3</cell><cell>0.3296 0.2775 0.2745 84 Miracl EN Run.3</cell><cell>0.2200 0.1698 0.1698</cell></row><row><cell>30 GRIUM EN Run.7</cell><cell>0.3272 0.2774 0.2739 85 USST EN Run.6</cell><cell>0.2410 0.1633 0.1771</cell></row><row><cell>31 ECNU EN Run.5</cell><cell>0.3531 0.2771 0.2804 86 Miracl EN Run.2</cell><cell>0.2291 0.1589 0.1626</cell></row><row><cell>32 UBML EN Run.3</cell><cell>0.3358 0.2757 0.2789 87 baseline run.5</cell><cell>0.2226 0.1530 0.1610</cell></row><row><cell>33 UBML EN Run.1</cell><cell>0.3294 0.2745 0.2771 88 KUCS EN Run.3</cell><cell>0.1679 0.1514 0.1425</cell></row><row><cell>34 baseline run.3</cell><cell>0.3369 0.2736 0.2751 89 Miracl EN Run.4</cell><cell>0.2001 0.1507 0.1570</cell></row><row><cell>35 GRIUM EN Run.1</cell><cell>0.3249 0.2725 0.2700 90 USST EN Run.8</cell><cell>0.2246 0.1492 0.1595</cell></row><row><cell>36 UBML EN Run.2</cell><cell>0.3305 0.2709 0.2735 91 HCMUS EN Run.4</cell><cell>0.2099 0.1467 0.1582</cell></row><row><cell>37 KISTI EN RUN.7</cell><cell>0.3299 0.2703 0.2739 92 HCMUS EN Run.5</cell><cell>0.1861 0.1299 0.1386</cell></row><row><cell>38 KISTI EN RUN.5</cell><cell>0.3203 0.2702 0.2725 93 HCMUS EN Run.7</cell><cell>0.1853 0.1266 0.1348</cell></row><row><cell>39 USST EN Run.2</cell><cell>0.3557 0.2659 0.2727 94 YorkU EN Run.1</cell><cell>0.1798 0.1127 0.1195</cell></row><row><cell>40 KISTI EN RUN.4</cell><cell>0.3306 0.2644 0.2709 95 USST EN Run.9</cell><cell>0.1629 0.1115 0.1195</cell></row><row><cell>41 baseline run.2</cell><cell>0.3150 0.2633 0.2587 96 readability run.4</cell><cell>0.1143 0.1080 0.1000</cell></row><row><cell>42 KISTI EN RUN.6</cell><cell>0.3332 0.2607 0.2695 97 USST EN Run.10</cell><cell>0.1467 0.0947 0.1039</cell></row><row><cell>42 KISTI EN RUN.8</cell><cell>0.3332 0.2607 0.2695 98 HCMUS EN Run.6</cell><cell>0.1257 0.0746 0.0861</cell></row><row><cell>42 KISTI EN RUN.2</cell><cell>0.3038 0.2607 0.2614 99 HCMUS EN Run.8</cell><cell>0.1210 0.0698 0.0808</cell></row><row><cell>45 KISTI EN RUN.3</cell><cell cols="2">0.3295 0.2596 0.2666 100 FDUSGInfo EN Run.6 0.0805 0.0609 0.0577</cell></row><row><cell>46 KISTI EN RUN.1</cell><cell cols="2">0.3222 0.2593 0.2646 100 FDUSGInfo EN Run.7 0.0805 0.0609 0.0577</cell></row><row><cell cols="3">47 FDUSGInfo EN Run.1 0.3134 0.2572 0.2568 100 FDUSGInfo EN Run.8 0.0805 0.0609 0.0577</cell></row><row><cell>48 USST EN Run.1</cell><cell>0.3342 0.2564 0.2639 103 KUCS EN Run.4</cell><cell>0.0656 0.0600 0.0567</cell></row><row><cell>49 HCMUS EN Run.2</cell><cell>0.3483 0.2556 0.2698 104 LIMSI EN run.4</cell><cell>0.0562 0.0476 0.0462</cell></row><row><cell>50 Miracl EN Run.1</cell><cell>0.3287 0.2546 0.2631 104 LIMSI EN run.5</cell><cell>0.0562 0.0476 0.0462</cell></row><row><cell>51 YorkU EN Run.8</cell><cell cols="2">0.3072 0.2504 0.2533 106 FDUSGInfo EN Run.9 0.0646 0.0473 0.0473</cell></row><row><cell>52 YorkU EN Run.7</cell><cell cols="2">0.3125 0.2470 0.2523 107 FDUSGInfo EN Run.10 0.0646 0.0473 0.0473</cell></row><row><cell>52 YorkU EN Run.9</cell><cell>0.2962 0.2470 0.2485 108 readability run.5</cell><cell>0.0362 0.0160 0.0227</cell></row><row><cell>54 CUNI EN Run.10</cell><cell>0.3060 0.2442 0.2459 109 readability run.6</cell><cell>0.0194 0.0117 0.0134</cell></row><row><cell>55 YorkU EN Run.10</cell><cell>0.2853 0.2415 0.2420 109 readability run.7</cell><cell>0.0194 0.0117 0.0134</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="21,134.77,199.50,345.82,377.64"><head>Table 7 .</head><label>7</label><figDesc>Results for multilingual submissions, sorted by p@10, obtained using the original qrels.</figDesc><table coords="21,139.58,234.48,336.19,342.65"><row><cell>R Run Name</cell><cell cols="3">p@10 nDCG@10 R Run Name</cell><cell>p@10 nDCG@10</cell></row><row><cell cols="2">1 CUNI DE Run10 0.2985</cell><cell>0.2825</cell><cell cols="2">34 CUNI IT Run5 0.2182</cell><cell>0.1856</cell></row><row><cell cols="2">2 CUNI DE Run7 0.2970</cell><cell>0.2757</cell><cell cols="2">37 CUNI AR Run1 0.2167</cell><cell>0.2117</cell></row><row><cell cols="2">3 CUNI FR Run10 0.2833</cell><cell>0.2615</cell><cell cols="2">37 CUNI AR Run7 0.2167</cell><cell>0.2133</cell></row><row><cell cols="2">4 CUNI FR Run7 0.2773</cell><cell>0.2568</cell><cell cols="2">39 CUNI CS Run8 0.2152</cell><cell>0.2137</cell></row><row><cell cols="2">5 CUNI IT Run10 0.2758</cell><cell>0.2369</cell><cell cols="2">39 CUNI FR Run1 0.2152</cell><cell>0.2056</cell></row><row><cell cols="2">6 CUNI IT Run1 0.2652</cell><cell>0.2278</cell><cell cols="2">39 CUNI PT Run2 0.2152</cell><cell>0.2227</cell></row><row><cell cols="2">7 CUNI IT Run4 0.2621</cell><cell>0.2221</cell><cell cols="2">42 CUNI FA Run6 0.2136</cell><cell>0.2107</cell></row><row><cell cols="2">8 CUNI PT Run6 0.2530</cell><cell>0.2492</cell><cell cols="2">43 CUNI CS Run1 0.2121</cell><cell>0.1924</cell></row><row><cell cols="2">9 CUNI PT Run8 0.2515</cell><cell>0.2382</cell><cell cols="2">43 CUNI DE Run1 0.2121</cell><cell>0.1969</cell></row><row><cell cols="2">10 CUNI DE Run8 0.2500</cell><cell>0.2413</cell><cell cols="2">43 CUNI IT Run7 0.2121</cell><cell>0.1812</cell></row><row><cell cols="2">10 CUNI FR Run9 0.2500</cell><cell>0.2188</cell><cell cols="2">43 CUNI PT Run3 0.2121</cell><cell>0.2253</cell></row><row><cell cols="2">12 CUNI FR Run8 0.2455</cell><cell>0.2271</cell><cell cols="2">47 CUNI FA Run7 0.2091</cell><cell>0.1806</cell></row><row><cell cols="2">12 CUNI IT Run6 0.2455</cell><cell>0.2142</cell><cell cols="2">48 CUNI CS Run5 0.2076</cell><cell>0.1958</cell></row><row><cell cols="2">14 CUNI DE Run9 0.2409</cell><cell>0.2107</cell><cell cols="2">48 CUNI FR Run3 0.2076</cell><cell>0.1943</cell></row><row><cell cols="2">14 CUNI PT Run10 0.2409</cell><cell>0.2451</cell><cell cols="2">48 CUNI FR Run5 0.2076</cell><cell>0.2017</cell></row><row><cell cols="2">16 CUNI IT Run2 0.2394</cell><cell>0.1913</cell><cell cols="2">51 CUNI FR Run4 0.2061</cell><cell>0.2074</cell></row><row><cell cols="2">17 CUNI IT Run3 0.2348</cell><cell>0.1952</cell><cell cols="2">52 CUNI AR Run8 0.2045</cell><cell>0.2026</cell></row><row><cell cols="2">17 CUNI PT Run7 0.2348</cell><cell>0.2266</cell><cell cols="2">52 CUNI DE Run5 0.2045</cell><cell>0.1940</cell></row><row><cell cols="2">19 CUNI IT Run8 0.2333</cell><cell>0.2105</cell><cell cols="2">CUNI AR Run4 0.2030</cell><cell>0.1966</cell></row><row><cell cols="2">20 CUNI CS Run10 0.2303</cell><cell>0.1926</cell><cell cols="2">54 CUNI AR Run9 0.2030</cell><cell>0.1768</cell></row><row><cell cols="2">20 CUNI FA Run10 0.2303</cell><cell>0.2277</cell><cell cols="2">54 CUNI CS Run6 0.2030</cell><cell>0.1605</cell></row><row><cell cols="2">20 CUNI PT Run1 0.2303</cell><cell>0.2338</cell><cell cols="2">57 CUNI DE Run4 0.2015</cell><cell>0.1869</cell></row><row><cell cols="2">20 CUNI PT Run5 0.2303</cell><cell>0.2180</cell><cell cols="2">58 CUNI DE Run3 0.2000</cell><cell>0.1652</cell></row><row><cell cols="2">24 CUNI PT Run4 0.2288</cell><cell>0.2352</cell><cell cols="2">59 CUNI FA Run9 0.1985</cell><cell>0.1735</cell></row><row><cell cols="2">25 CUNI AR Run10 0.2273</cell><cell>0.2202</cell><cell cols="2">60 CUNI FR Run6 0.1970</cell><cell>0.1661</cell></row><row><cell cols="2">25 CUNI FA Run4 0.2273</cell><cell>0.2267</cell><cell cols="2">61 CUNI CS Run9 0.1924</cell><cell>0.1530</cell></row><row><cell cols="2">25 CUNI IT Run9 0.2273</cell><cell>0.1856</cell><cell cols="2">62 CUNI CS Run4 0.1894</cell><cell>0.1721</cell></row><row><cell cols="2">28 CUNI FA Run1 0.2258</cell><cell>0.2227</cell><cell cols="2">63 CUNI AR Run2 0.1879</cell><cell>0.1831</cell></row><row><cell cols="2">29 CUNI CS Run7 0.2242</cell><cell>0.1897</cell><cell cols="2">63 CUNI FR Run2 0.1879</cell><cell>0.1854</cell></row><row><cell cols="2">30 CUNI FA Run3 0.2227</cell><cell>0.2049</cell><cell cols="2">63 CUNI PT Run9 0.1879</cell><cell>0.1719</cell></row><row><cell cols="2">30 CUNI FA Run5 0.2227</cell><cell>0.1991</cell><cell cols="2">66 CUNI AR Run3 0.1864</cell><cell>0.1894</cell></row><row><cell cols="2">32 CUNI AR Run5 0.2197</cell><cell>0.2148</cell><cell cols="2">67 CUNI CS Run3 0.1848</cell><cell>0.1609</cell></row><row><cell cols="2">32 CUNI AR Run6 0.2197</cell><cell>0.2017</cell><cell cols="2">68 CUNI DE Run6 0.1818</cell><cell>0.1485</cell></row><row><cell cols="2">34 CUNI FA Run2 0.2182</cell><cell>0.2087</cell><cell cols="2">69 CUNI CS Run2 0.1697</cell><cell>0.1470</cell></row><row><cell cols="2">34 CUNI FA Run8 0.2182</cell><cell>0.2201</cell><cell cols="2">69 CUNI DE Run2 0.1697</cell><cell>0.1517</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="22,134.77,201.41,345.83,373.86"><head>Table 8 .</head><label>8</label><figDesc>Results for multilingual submissions, sorted by p@10, obtained using additional qrels (merged ).</figDesc><table coords="22,139.52,236.83,336.33,338.44"><row><cell>R Run Name</cell><cell cols="3">p@10 nDCG@10 R Run Name</cell><cell>p@10 nDCG@10</cell></row><row><cell cols="2">1 CUNI IT Run10 0.3727</cell><cell>0.3094</cell><cell cols="2">36 CUNI FR Run2 0.3061</cell><cell>0.2498</cell></row><row><cell cols="2">1 CUNI IT Run4 0.3727</cell><cell>0.3045</cell><cell cols="2">37 CUNI FA Run5 0.3045</cell><cell>0.2539</cell></row><row><cell cols="2">3 CUNI IT Run1 0.3712</cell><cell>0.3065</cell><cell cols="2">38 CUNI AR Run5 0.3030</cell><cell>0.2661</cell></row><row><cell cols="2">4 CUNI FR Run10 0.3682</cell><cell>0.3111</cell><cell cols="2">38 CUNI CS Run3 0.3030</cell><cell>0.2259</cell></row><row><cell cols="2">4 CUNI FR Run7 0.3682</cell><cell>0.3093</cell><cell cols="2">38 CUNI CS Run4 0.3030</cell><cell>0.2343</cell></row><row><cell cols="2">6 CUNI IT Run6 0.3606</cell><cell>0.2981</cell><cell cols="2">41 CUNI CS Run6 0.3000</cell><cell>0.2206</cell></row><row><cell cols="2">7 CUNI PT Run2 0.3576</cell><cell>0.3009</cell><cell cols="2">41 CUNI FA Run8 0.3000</cell><cell>0.2669</cell></row><row><cell cols="2">8 CUNI DE Run10 0.3561</cell><cell>0.3182</cell><cell cols="2">43 CUNI DE Run8 0.2985</cell><cell>0.2672</cell></row><row><cell cols="2">9 CUNI DE Run7 0.3545</cell><cell>0.3092</cell><cell cols="2">43 CUNI PT Run7 0.2985</cell><cell>0.2613</cell></row><row><cell cols="2">10 CUNI IT Run8 0.3515</cell><cell>0.2966</cell><cell cols="2">45 CUNI AR Run10 0.2924</cell><cell>0.2556</cell></row><row><cell cols="2">11 CUNI PT Run1 0.3500</cell><cell>0.2936</cell><cell cols="2">45 CUNI AR Run7 0.2924</cell><cell>0.2569</cell></row><row><cell cols="2">12 CUNI PT Run4 0.3485</cell><cell>0.2976</cell><cell cols="2">45 CUNI CS Run8 0.2924</cell><cell>0.2544</cell></row><row><cell cols="2">13 CUNI IT Run2 0.3424</cell><cell>0.2683</cell><cell cols="2">45 CUNI DE Run9 0.2924</cell><cell>0.2397</cell></row><row><cell cols="2">14 CUNI IT Run3 0.3394</cell><cell>0.2694</cell><cell cols="2">45 CUNI PT Run9 0.2924</cell><cell>0.2255</cell></row><row><cell cols="2">15 CUNI PT Run10 0.3379</cell><cell>0.2936</cell><cell cols="2">50 CUNI CS Run5 0.2909</cell><cell>0.2426</cell></row><row><cell cols="2">16 CUNI PT Run3 0.3364</cell><cell>0.2893</cell><cell cols="2">51 CUNI AR Run6 0.2894</cell><cell>0.2392</cell></row><row><cell cols="2">17 CUNI FA Run10 0.3333</cell><cell>0.2807</cell><cell cols="2">52 CUNI AR Run8 0.2879</cell><cell>0.2493</cell></row><row><cell cols="2">17 CUNI FR Run9 0.3333</cell><cell>0.2677</cell><cell cols="2">52 CUNI FR Run5 0.2879</cell><cell>0.2446</cell></row><row><cell cols="2">17 CUNI PT Run6 0.3333</cell><cell>0.2893</cell><cell cols="2">54 CUNI CS Run9 0.2864</cell><cell>0.2122</cell></row><row><cell cols="2">20 CUNI CS Run1 0.3318</cell><cell>0.2633</cell><cell cols="2">54 CUNI FA Run6 0.2864</cell><cell>0.2504</cell></row><row><cell cols="2">20 CUNI CS Run7 0.3318</cell><cell>0.2571</cell><cell cols="2">56 CUNI FA Run7 0.2803</cell><cell>0.2256</cell></row><row><cell cols="2">20 CUNI IT Run5 0.3318</cell><cell>0.2666</cell><cell cols="2">56 CUNI FR Run6 0.2803</cell><cell>0.2070</cell></row><row><cell cols="2">20 CUNI IT Run7 0.3318</cell><cell>0.2654</cell><cell cols="2">58 CUNI DE Run1 0.2773</cell><cell>0.2327</cell></row><row><cell cols="2">20 CUNI PT Run8 0.3318</cell><cell>0.2838</cell><cell cols="2">59 CUNI DE Run4 0.2742</cell><cell>0.2255</cell></row><row><cell cols="2">25 CUNI CS Run10 0.3288</cell><cell>0.2567</cell><cell cols="2">60 CUNI AR Run1 0.2727</cell><cell>0.2403</cell></row><row><cell cols="2">26 CUNI FA Run4 0.3273</cell><cell>0.2788</cell><cell cols="2">60 CUNI CS Run2 0.2727</cell><cell>0.2058</cell></row><row><cell cols="2">26 CUNI FR Run3 0.3273</cell><cell>0.2612</cell><cell cols="2">60 CUNI FA Run9 0.2727</cell><cell>0.2101</cell></row><row><cell cols="2">28 CUNI FA Run1 0.3258</cell><cell>0.2720</cell><cell cols="2">63 CUNI DE Run3 0.2682</cell><cell>0.2039</cell></row><row><cell cols="2">29 CUNI FA Run3 0.3242</cell><cell>0.2660</cell><cell cols="2">64 CUNI AR Run2 0.2621</cell><cell>0.2178</cell></row><row><cell cols="2">30 CUNI FA Run2 0.3227</cell><cell>0.2674</cell><cell cols="2">64 CUNI AR Run4 0.2621</cell><cell>0.2237</cell></row><row><cell cols="2">31 CUNI FR Run4 0.3182</cell><cell>0.2661</cell><cell cols="2">64 CUNI DE Run5 0.2621</cell><cell>0.2211</cell></row><row><cell cols="2">31 CUNI FR Run8 0.3182</cell><cell>0.2659</cell><cell cols="2">67 CUNI AR Run3 0.2591</cell><cell>0.2261</cell></row><row><cell cols="2">31 CUNI PT Run5 0.3182</cell><cell>0.2717</cell><cell cols="2">68 CUNI DE Run2 0.2485</cell><cell>0.1984</cell></row><row><cell cols="2">34 CUNI FR Run1 0.3121</cell><cell>0.2557</cell><cell cols="2">69 CUNI AR Run9 0.2439</cell><cell>0.1954</cell></row><row><cell cols="2">35 CUNI IT Run9 0.3106</cell><cell>0.2417</cell><cell cols="2">70 CUNI DE Run6 0.2364</cell><cell>0.1811</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_0" coords="2,144.73,658.44,98.85,7.47"><p>http://physionet.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_1" coords="4,144.73,635.88,317.25,7.86"><p>With exception of one condition, for which only one query could be generated.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_2" coords="4,144.73,646.84,335.87,7.86;4,144.73,657.79,175.97,7.86"><p>Note that additional instructions were given to volunteers at the start and end of the task, including training and de-briefing.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_3" coords="6,144.73,657.79,181.62,7.86"><p>https://pypi.python.org/pypi/beautifulsoup4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_4" coords="7,144.73,624.92,215.51,7.86"><p>https://pypi.python.org/pypi/ReadabilityCalculator/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_5" coords="7,144.73,635.88,335.86,7.86;7,144.73,646.84,335.86,7.86;7,144.73,657.79,175.23,7.86"><p>With the exclusion of multilingual submissions, for which runs were not pooled due to the larger assessment effort pooling these runs would have required. Note that only one team submitted multilingual runs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_6" coords="9,144.73,646.84,335.87,7.86;9,144.73,657.79,22.65,7.86"><p>High values of ρ representing persistent users, low values representing impatient users.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_7" coords="13,144.73,646.84,335.86,7.86;13,144.73,657.79,221.19,7.86"><p>Note that before the relevance assessment exercise started, we removed the majority of scripts from the pooled pages to avoid this problem.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This task has been supported in part by the <rs type="funder">European Union</rs> <rs type="programName">Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013</rs>) under grant agreement n o <rs type="grantNumber">257528</rs> (<rs type="projectName">KHRES</rs><rs type="grantNumber">-MOI</rs>), by <rs type="programName">Horizon 2020 program</rs> (<rs type="grantNumber">H2020-ICT-2014-1</rs>) under grant agreement n o <rs type="grantNumber">644753</rs> (KCONNECT), by the <rs type="funder">Austrian Science Fund (FWF)</rs> project n o <rs type="grantNumber">I1094-N23</rs> (MUCKE), and by the <rs type="funder">Czech Science Foundation</rs> (grant number <rs type="grantNumber">P103/12/G084</rs>). We acknowledge the time of the people involved in the translation and relevance assessment tasks, in special we want to thank <rs type="person">Dr. Johannes Bernhardt-Melischnig</rs> (<rs type="affiliation">Medizinische Universitat Graz</rs>) for coordinating the recruitment and management of the paid medical students that participated in the relevance assessment exercise.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_XrGYtw8">
					<idno type="grant-number">FP7/2007-2013</idno>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
				<org type="funded-project" xml:id="_8sa9Qf4">
					<idno type="grant-number">257528</idno>
					<orgName type="project" subtype="full">KHRES</orgName>
				</org>
				<org type="funding" xml:id="_8fFhJwg">
					<idno type="grant-number">-MOI</idno>
					<orgName type="program" subtype="full">Horizon 2020 program</orgName>
				</org>
				<org type="funding" xml:id="_96FjfMN">
					<idno type="grant-number">H2020-ICT-2014-1</idno>
				</org>
				<org type="funding" xml:id="_nEz6WeR">
					<idno type="grant-number">644753</idno>
				</org>
				<org type="funding" xml:id="_RXZFBVa">
					<idno type="grant-number">I1094-N23</idno>
				</org>
				<org type="funding" xml:id="_7kyR4HP">
					<idno type="grant-number">P103/12/G084</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="17,142.96,143.37,337.64,7.86;17,151.52,154.33,329.07,7.86;17,151.52,165.29,329.07,7.86;17,151.52,176.25,177.61,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="17,216.48,154.33,174.13,7.86">Overview of the clef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hanlen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,434.13,154.33,46.46,7.86;17,151.52,165.29,209.38,7.86">CLEF 2015 -6th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="17,369.09,165.29,111.50,7.86;17,151.52,176.25,56.67,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09">2015. September 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,187.16,337.64,7.86;17,151.52,198.12,183.75,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fox</surname></persName>
		</author>
		<title level="m" coord="17,188.35,187.16,288.44,7.86">Health topics: 80% of internet users look for health information online</title>
		<imprint>
			<publisher>Pew Internet &amp; American Life Project</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,209.04,337.64,7.86;17,151.52,220.00,329.07,7.86;17,151.52,230.96,329.07,7.86;17,151.52,241.91,201.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="17,271.89,220.00,208.69,7.86;17,151.52,230.96,325.19,7.86">ShARe/CLEF eHealth Evaluation Lab 2013, Task 3: Information retrieval to address patients&apos; questions when reading clinical reports</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salanterä</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,165.60,241.91,125.04,7.86">Online Working Notes of CLEF</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,252.83,337.64,7.86;17,151.52,263.79,329.07,7.86;17,151.52,274.75,329.07,7.86;17,151.52,285.71,223.37,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="17,262.26,263.79,159.19,7.86;17,450.44,263.79,30.16,7.86;17,151.52,274.75,166.90,7.86">Task 3: User-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,343.98,274.75,136.61,7.86;17,151.52,285.71,133.89,7.86">CLEF 2014 Evaluation Labs and Workshop: Online Working Notes</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>ShARe/CLEF eHealth Evaluation Lab</note>
</biblStruct>

<biblStruct coords="17,142.96,296.62,189.05,7.86;17,348.14,296.62,132.46,7.86;17,151.52,307.58,329.07,7.86;17,151.52,318.54,329.07,7.86;17,151.52,329.50,25.60,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="17,348.14,296.62,132.46,7.86;17,151.52,307.58,329.07,7.86;17,151.52,318.54,84.60,7.86">An investigation of the effectiveness of concept-based approach in medical information retrieval grium@ clef2014ehealthtask 3</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,244.75,318.54,235.84,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,340.42,337.64,7.86;17,151.52,351.37,329.07,7.86;17,151.52,362.33,124.67,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="17,361.48,340.42,119.11,7.86;17,151.52,351.37,186.47,7.86">Using discharge summaries to improve information retrieval in clinical domain</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,345.27,351.37,135.33,7.86;17,151.52,362.33,96.00,7.86">Proceedings of the ShARe/-CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/-CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,373.25,337.64,7.86;17,151.52,384.18,185.49,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="17,246.53,373.25,200.52,7.86">Shortcomings of health information on the internet</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Benigeri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pluye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,453.71,373.25,26.88,7.86;17,151.52,384.21,96.04,7.86">Health promotion international</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="386" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,395.12,337.63,7.86;17,151.52,406.06,215.03,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="17,267.56,395.12,213.03,7.86;17,151.52,406.08,90.43,7.86">Cyberchondria: studies of the escalation of medical concerns in web search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,249.96,406.08,47.10,7.86">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.96,417.00,337.63,7.86;17,151.52,427.96,329.07,7.86;17,151.52,438.92,191.43,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="17,302.92,417.00,177.67,7.86;17,151.52,427.96,253.51,7.86">Diagnose this if you can: On the effectiveness of search engines in finding medical self-diagnosis information</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,430.98,427.96,49.61,7.86;17,151.52,438.92,85.63,7.86">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="562" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,449.83,337.98,7.86;17,151.52,460.79,177.61,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,252.50,449.83,228.09,7.86;17,151.52,460.79,23.54,7.86">Khresmoi -multimodal multilingual medical information search</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,197.15,460.79,99.47,7.86">MIE village of the future</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,471.71,337.98,7.86;17,151.52,482.67,329.07,7.86;17,151.52,493.63,238.65,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="17,294.61,471.71,182.16,7.86">Circumlocution in diagnostic medical queries</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ieong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,166.02,482.67,314.57,7.86;17,151.52,493.63,146.26,7.86">Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</title>
		<meeting>the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,504.54,337.98,7.86;17,151.52,515.50,329.07,7.86;17,151.52,526.46,329.07,7.86;17,151.52,537.42,41.47,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="17,268.47,504.54,212.12,7.86;17,151.52,515.50,120.29,7.86">Relevation!: an open source system for information retrieval relevance assessment</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,299.31,515.50,181.28,7.86;17,151.52,526.46,273.98,7.86">Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</title>
		<meeting>the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1243" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,548.33,337.97,7.86;17,151.52,559.27,251.50,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="17,271.53,548.33,209.05,7.86;17,151.52,559.29,73.46,7.86">Readability assessment of internet-based consumer health information</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Volsko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,233.19,559.29,66.55,7.86">Respiratory care</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1310" to="1315" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,570.21,337.97,7.86;17,151.52,581.17,329.07,7.86;17,151.52,592.13,65.02,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="17,261.38,570.21,219.21,7.86;17,151.52,581.17,108.57,7.86">Integrating understandability in the evaluation of consumer health search engines</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,279.95,581.17,200.64,7.86;17,151.52,592.13,16.79,7.86">Medical Information Retrieval Workshop at SIGIR 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.61,603.04,337.98,7.86;17,151.52,614.00,282.64,7.86" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<title level="m" coord="17,363.07,603.04,114.05,7.86;17,151.52,614.00,253.97,7.86">Novatica UPGRADE Special Issue on Web Information Access</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Research directions in terrier</note>
</biblStruct>

<biblStruct coords="17,142.61,624.92,337.98,7.86;17,151.52,635.88,329.07,7.86;17,151.52,646.84,329.07,7.86;17,151.52,657.79,63.99,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="17,305.34,624.92,175.25,7.86;17,151.52,635.88,158.92,7.86">The influence of pre-processing on the estimation of readability of web documents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,333.85,635.88,146.74,7.86;17,151.52,646.84,329.07,7.86;17,151.52,657.79,30.28,7.86">Proceedings of the 24th ACM International Conference on Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the 24th ACM International Conference on Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,120.67,337.98,7.86;18,151.52,131.63,254.07,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="18,359.83,120.67,120.76,7.86;18,151.52,131.63,151.34,7.86">Derivation of New Readability Formulas for Navy Enlisted Personnel</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fishburne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="18,142.62,142.59,337.98,7.86;18,151.52,153.55,254.07,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="18,359.83,142.59,120.76,7.86;18,151.52,153.55,151.34,7.86">Derivation of New Readability Formulas for Navy Enlisted Personnel</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fishburne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="18,142.62,164.51,337.98,7.86;18,151.52,175.44,264.53,7.89" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="18,272.19,164.51,204.35,7.86">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,151.52,175.46,175.08,7.86">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,186.42,337.98,7.86;18,151.52,197.36,295.61,7.89" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="18,239.10,186.42,241.50,7.86;18,151.52,197.38,15.24,7.86">Rank-biased precision for measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,174.66,197.38,207.59,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,208.34,337.98,7.86;18,151.52,219.30,329.07,7.86;18,151.52,230.26,51.70,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="18,245.08,208.34,235.51,7.86;18,151.52,219.30,21.55,7.86">On the distribution of user persistence for rank-biased precision</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,194.24,219.30,281.58,7.86">Proceedings of the 12th Australasian document computing symposium</title>
		<meeting>the 12th Australasian document computing symposium</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,241.22,337.98,7.86;18,151.52,252.18,279.23,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="18,291.32,241.22,185.69,7.86">CUNI at the CLEF 2015 eHealth Lab Task 2</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bibyna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,165.60,252.18,231.97,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,263.14,337.98,7.86;18,151.52,274.09,329.07,7.86;18,151.52,285.05,75.39,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="18,296.07,263.14,184.53,7.86;18,151.52,274.09,115.29,7.86">ECNU at 2015 eHealth Task 2: User-centred Health Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,288.48,274.09,192.12,7.86;18,151.52,285.05,42.20,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,296.01,337.97,7.86;18,151.52,306.97,46.71,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="18,208.13,296.01,28.98,7.86">Missing</title>
		<author>
			<persName coords=""><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,261.99,296.01,218.60,7.86;18,151.52,306.97,13.54,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,317.93,337.97,7.86;18,151.52,328.89,329.07,7.86;18,151.52,339.85,93.18,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="18,247.86,317.93,232.73,7.86;18,151.52,328.89,143.47,7.86">Bridging Layperson&apos;s Queries with Medical Concepts -GRIUM@CLEF2015 eHealth Task 2</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,314.74,328.89,165.85,7.86;18,151.52,339.85,59.99,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,350.81,337.98,7.86;18,151.52,361.77,250.41,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="18,286.29,350.81,152.58,7.86">KISTI at CLEF eHealth 2015 Task 2</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,463.04,350.81,17.56,7.86;18,151.52,361.77,217.24,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,372.73,337.98,7.86;18,151.52,383.68,329.07,7.86;18,151.52,394.64,127.23,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="18,290.76,372.73,189.83,7.86;18,151.52,383.68,161.37,7.86">Task 2a: Team KU-CS: Query Coherence Analysis for PRF and Genomics Expansion</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Thesprasith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jaruskulchai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,341.34,383.68,139.26,7.86;18,151.52,394.64,94.05,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,405.60,337.98,7.86;18,151.52,416.56,279.23,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="18,322.99,405.60,154.02,7.86">LIMSI @ CLEF eHealth 2015 -task 2</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,165.60,416.56,231.97,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,427.52,337.98,7.86;18,151.52,438.48,329.07,7.86;18,151.52,449.44,127.23,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="18,374.37,427.52,106.22,7.86;18,151.52,438.48,172.08,7.86">Miracl at Clef 2015 : User-Centred Health Information Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ksentini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gargouri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,345.92,438.48,134.68,7.86;18,151.52,449.44,94.05,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,460.40,337.97,7.86;18,151.52,471.36,329.07,7.86;18,151.52,482.31,155.00,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="18,296.37,460.40,184.22,7.86;18,151.52,471.36,193.37,7.86">TeamHCMUS: A Concept-Based Information Retrieval Approach for Web Medical Documents</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,367.60,471.36,112.99,7.86;18,151.52,482.31,121.82,7.86">Proceedings of the ShARe/-CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/-CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,493.27,337.98,7.86;18,151.52,504.23,329.07,7.86;18,151.52,515.19,93.18,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="18,353.21,493.27,127.38,7.86;18,151.52,504.23,137.32,7.86">UBML participation to CLEF eHealth IR challenge 2015: Task 2</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Thuma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mosweunyane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,311.13,504.23,169.46,7.86;18,151.52,515.19,59.99,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,526.15,337.98,7.86;18,151.52,537.11,279.23,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="18,183.99,526.15,292.45,7.86">Employing query expansion models to help patients diagnose themselves</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,165.60,537.11,231.97,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,142.62,548.07,337.98,7.86;18,151.52,559.03,329.07,7.86;18,151.52,569.99,75.39,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="18,316.30,548.07,164.30,7.86;18,151.52,559.03,113.96,7.86">York University at CLEF eHealth 2015: Medical Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ghoddousi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,287.62,559.03,192.97,7.86;18,151.52,569.99,42.20,7.86">Proceedings of the ShARe/CLEF eHealth Evaluation Lab</title>
		<meeting>the ShARe/CLEF eHealth Evaluation Lab</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
