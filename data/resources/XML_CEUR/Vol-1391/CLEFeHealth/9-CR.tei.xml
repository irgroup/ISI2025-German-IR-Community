<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.41,116.95,296.54,12.62;1,261.03,134.89,93.29,12.62">Supervised Named Entity Recognition for Clinical Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,275.83,172.56,63.71,8.74"><forename type="first">Devanshu</forename><surname>Jain</surname></persName>
							<email>devanshu.jain919@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Dhirubhai Ambani Institute of Information and Communication Technology</orgName>
								<address>
									<postCode>382007</postCode>
									<settlement>Gandhinagar</settlement>
									<region>Gujarat</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.41,116.95,296.54,12.62;1,261.03,134.89,93.29,12.62">Supervised Named Entity Recognition for Clinical Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E0CEFF1437E296A145221EBB21CA4EFB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Clinical Data</term>
					<term>Named Entity Recognition</term>
					<term>UMLS</term>
					<term>Machine Learning</term>
					<term>CRF</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clinical Named Entity Recognition is a part of Task 1b, organised by CLEF eHealth organisation in 2015. The aim is to automatically identify clinically relevant entities in medical text in French. A supervised learning approach has been used for training the tagger. For the purpose of training, Conditional Random Fields(CRF) has been used. An extensive set of features was used for training. Precision, recall and F1 Score were used as evaluation metrics. Ten fold cross validation technique was used to evaluate the system. The best precision obtained was 0.91 and the best recall obtained was 0.66. After the test results were announced, the best F1 score obtained for exact matching was 0.67 and for relaxed case (i.e. inexact matching), it was 0.73.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There is a huge amount of raw medical data available in the form of textual information. The goal of Information Extraction, here, is to present the data in a way that enhances user experience and allows better comprehension. The major task involved in this process is the identification of named entities within the document. This allows the user to have a better understanding of the jargons. It also allows to identify important terms that may be helpful in summarising the medical document.</p><p>The Clinical Named Entity Recognition is different from other common sequence tagging problems, like POS (Part of Speech) tagging. The major point of difference is the existence of ambiguity in the medical document. The span of an entity may overlap with the span of another entity i.e. the same word can be a part of multiple entities. Another issue with it is the presence of non contiguous entities. That is, the span of the entity may be discontinuous over a sentence. Moreover, there are ample resources such as thesaurus, but almost all of them are English centric. The training data, being in French language, poses another challenge.</p><p>In order to annotate the clinical entities, UMLS (Unified Medical Language System) is used. It is a compendium of vocabularies in biomedical science. There are various semantic groups, under which an entity can lie.</p><p>In order to tackle the problem, an extensive list of features were used. CRFsuite software was used to train the tagger. The following sections explains in greater details the methods and tools used for tackling the problem. The available data was first pre-processed by stemming all the words. We have considered the NER task as a sequence tagging problem. We, therefore have used CRF basic tagger to train the system. CRF is a state of the art method used for the purpose of sequence tagging. We have used CRFsuite software for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>Following features were used for training the CRF:</p><p>1. Lexical Features: Uni-grams, bi-grams and tri-grams of words were used as features within a window of ±3 around the current word. Then the POS tags of the words in the window were also chosen as features. Finally, we used capitalisation of letters and presence of digit as features too. In addition, prefixes and suffixes of 3 letter length were also used as features for each word. 2. UMLS Features: UMLS features were extracted using MetaMap. Since, MetaMap is English-centric, therefore, all the French words in the training data were translated into English, separately. Then, using MetaMap API, semantic group of these words were obtained and used as features for training. 3. Global Features: For every word, we calculated the position of the word in that sentence. To do this, we treated the word as LEFT, when it lied in the left quarter of the sentence. When it lied in the right quarter of the sentence, it was treated as being RIGHT. Otherwise, it was treated as being CENTER.</p><p>In order to account for the case when the span of entities was over multiple words in a contiguous manner, we used BIO format. For the starting of an entity, its name was prefixed with -B. If it was an intermediate word, the entity name was prefixed with -I. Otherwise, it was named as O. The system currently does not handle the discontinous terms.</p><p>3 Tools Used 1. Microsoft Bing translator was used for translating each french word (separately) into English. 2. Snowball stemmer was used for the stemming during pre-processing step 3. CRFSuite tagger was used to train the model based on the traing data and for tagging the test files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training Data</head><p>The training data was provided by the CLEF organisation itself. The data consisted of 833 MEDLINE documents, that contained single lines of medical data in French language. An additional 11 EMEA documents were also provided. Annotation files for each document were also given. Some statistics of the training data is as follows: As can be seen, the non contiguous annotations account for just 0.7% of the total number of annotations and hence don't affect the validations, much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Precision, Recall and F1 measure were used as evaluation metrics to evaluate the system. These are defined as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P recision = T rueP ositives T rueP ositives+F alsepositives</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall =</head><p>T rueP ositives T rueP ositives+F alseN egatives F 1Score = 2 * P recision * Recall</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P recision+Recall</head><p>We used ten fold cross validation techniques. The available data was partitioned into training data and validation data. The partition was done randomly, i.e. random samples were taken from the data and used for validation. The partition was done four times in the ratio of 60:40, 70:30, 80:20 and 90:10. Ten different and random partitions for each ratio were created. Then, the average precision and recall was calculated.</p><p>When MetaMap was not used as an external source of information, following results were obtained: As can be seen, some improvement in recall was observed when MetaMap thesaurus was used in the system.</p><p>6 Official Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Runs</head><p>We submitted two runs, which are described as follows:</p><p>1. Run 1: Predictions were completely made by CRFsuite based on the model generated using training data.</p><p>2. Run 2: Predictions made use of CRFsuite software as well as UMLS Metathesaurus information obtained by MetaMap. Whenever the model tagged a token as a non-entity, information from MetaMap was used to specify the tag for it. It was done at the level of single word only.</p><p>The runs were submitted for entity identification only. We didn't participate in entity normalisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>For the EMEA documents, following results were obtained: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We present a supervised Clinical named Entity Recognition system that can detect the named entities from a French medical data, using an extensive list of features, with an F1 Score of 0.68. It also uses UMLS Metathesaurus information obtained by MetaMap, using the English translated version of French words. The surprising thing to observe was that although, we used extra UMLS Metathesaurus information obtained by MetaMap in run2, although it improved the precision, but reduced the recall drastically. This remains to be investigated.</p><p>The system does not handle the non contiguous entities properly. We can use mutual information as a technique to identify the relationship between different entities, in order to detect that.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,232.99,316.85,149.37,7.89;2,134.77,243.95,345.83,58.14"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flow Diagram of the process.</figDesc><graphic coords="2,134.77,243.95,345.83,58.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,234.29,407.04,146.78,62.81"><head>Table 1 .</head><label>1</label><figDesc>Training data Stats</figDesc><table coords="3,234.29,407.04,146.78,41.94"><row><cell>Total Word Count</cell><cell>25,500</cell></row><row><cell>Number of Annotations</cell><cell>5,690</cell></row><row><cell cols="2">Non Contiguous Annotations 40</cell></row><row><cell cols="2">Overlapping Spans of entities 797</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,260.57,345.84,209.36"><head>Table 2 .</head><label>2</label><figDesc>Run1: Validation ResultsWhen MetaMap outputs were used by the tagger, following results were obtained:</figDesc><table coords="4,152.50,260.57,310.36,209.36"><row><cell cols="5">Training % Validation % Avg. Precision Avg. Recall Avg. F1 Score</cell></row><row><cell>60%</cell><cell>40%</cell><cell>0.928</cell><cell>0.453</cell><cell>0.609</cell></row><row><cell>70%</cell><cell>30%</cell><cell>0.933</cell><cell>0.466</cell><cell>0.622</cell></row><row><cell>80%</cell><cell>20%</cell><cell>0.932</cell><cell>0.485</cell><cell>0.638</cell></row><row><cell>90%</cell><cell>10%</cell><cell>0.936</cell><cell>0.488</cell><cell>0.642</cell></row><row><cell cols="5">Training % Validation % Avg. Precision Avg. Recall Avg. F1 Score</cell></row><row><cell>60%</cell><cell>40%</cell><cell>0.928</cell><cell>0.515</cell><cell>0.662</cell></row><row><cell>70%</cell><cell>30%</cell><cell>0.925</cell><cell>0.521</cell><cell>0.667</cell></row><row><cell>80%</cell><cell>20%</cell><cell>0.926</cell><cell>0.531</cell><cell>0.675</cell></row><row><cell>90%</cell><cell>10%</cell><cell>0.919</cell><cell>0.541</cell><cell>0.681</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,236.96,482.91,141.43,7.89"><head>Table 3 .</head><label>3</label><figDesc>Run2: Validation Results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,149.71,270.91,288.89,191.57"><head>Table 4 .</head><label>4</label><figDesc>EMEA ResultsFor the MEDLINE titles, following results were obtained:</figDesc><table coords="5,173.68,270.91,264.92,191.57"><row><cell>Run</cell><cell cols="2">Exact Match</cell><cell>Inexact Match</cell></row><row><cell></cell><cell cols="3">Precision Recall F1 Score Precision Recall F1 Score</cell></row><row><cell cols="2">Run 1 0.8591 0.5478</cell><cell>0.669</cell><cell>0.9091 0.6085 0.7290</cell></row><row><cell cols="3">Run 2 0.3567 0.5792 0.4415</cell><cell>0.3926 0.6653 0.4938</cell></row><row><cell>Run</cell><cell cols="2">Exact Match</cell><cell>Inexact Match</cell></row><row><cell></cell><cell cols="3">Precision Recall F1 Score Precision Recall F1 Score</cell></row><row><cell cols="2">Run 1 0.7126 0.4081</cell><cell>0.519</cell><cell>0.8188 0.5084 0.6273</cell></row><row><cell cols="3">Run 2 0.3973 0.4582 0.4256</cell><cell>0.4634 0.5845 0.5170</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,249.31,480.32,116.73,7.89"><head>Table 5 .</head><label>5</label><figDesc>MEDLINE Results</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,143.59,342.24,8.11;6,146.91,155.19,69.46,7.47" xml:id="b0">
	<monogr>
		<ptr target="https://sites.google.com/site/clefehealth2015/task-1/task-1b" />
		<title level="m" coord="6,146.91,143.59,108.82,7.86">Clef e health: Task 1b 2015</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,165.50,342.24,8.11;6,146.91,177.11,143.77,7.47" xml:id="b1">
	<monogr>
		<ptr target="http://www.chokkan.org/software/crfsuite/" />
		<title level="m" coord="6,146.91,165.50,271.81,7.86">Crfsuite: a fast implementation of conditional random fields (crfs)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,187.42,342.22,7.86;6,146.91,198.38,333.68,7.86;6,146.91,209.34,191.72,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,291.18,187.42,189.39,7.86;6,146.91,198.38,189.16,7.86">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">S F I K C</forename><surname>Czajkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,360.23,198.38,120.36,7.86;6,146.91,209.34,187.55,7.86">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,220.30,342.23,7.86;6,146.91,231.26,244.22,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,200.68,220.30,279.90,7.86;6,146.91,231.26,72.28,7.86">Effective mapping of biomedical text to the umls metathesaurus: the metamap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,239.36,231.26,147.00,7.86">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,242.22,342.23,7.86;6,146.91,253.17,333.68,7.86;6,146.91,264.13,333.67,7.86;6,146.91,275.09,175.55,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,216.67,253.17,173.18,7.86">Overview of theclef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Souminen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hanlen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,433.19,253.17,47.40,7.86;6,146.91,264.13,211.83,7.86">CLEF 2015 -6th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="6,367.48,264.13,113.10,7.86;6,146.91,275.09,56.67,7.86">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09">2015. September 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,286.05,342.23,7.86;6,146.91,297.01,333.66,7.86;6,146.91,307.97,228.31,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,174.96,297.01,301.69,7.86">CLEF eHealth evaluation lab 2015 task 1b: clinical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,158.43,307.97,138.62,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
