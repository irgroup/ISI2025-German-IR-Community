<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.67,116.95,340.02,12.62;1,142.54,134.89,330.27,12.62">Biomedical Concept Recognition in French Text Using Automatic Translation of English Terms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,166.29,175.27,53.34,8.74"><forename type="first">Zubair</forename><surname>Afzal</surname></persName>
							<email>m.afzal@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.21,175.27,76.41,8.74"><forename type="first">Saber</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
							<email>s.ahmadakhondi@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.91,175.27,132.13,8.74"><forename type="first">Herman</forename><forename type="middle">H H B M</forename><surname>Van Haagen</surname></persName>
							<email>h.vanhaagen@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.56,187.23,91.95,8.74"><forename type="first">Erik</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
							<email>e.vanmulligen@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,340.72,187.23,53.07,8.74"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
							<email>j.kors@erasmusmc.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.67,116.95,340.02,12.62;1,142.54,134.89,330.27,12.62">Biomedical Concept Recognition in French Text Using Automatic Translation of English Terms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7652D078BBF41B684C873401BCD4E527</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Entity recognition</term>
					<term>Concept identification</term>
					<term>Term translation</term>
					<term>French terminology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We addressed the task to automatically recognize and normalize entities in a French medical corpus. To increase the coverage of our initial French terminology, English terms were translated into French by two different automatic translators. Indexing with a terminology that contained the intersection of the translated terms in combination with several post-processing steps to reduce the number of false-positive detections, gave the best performance results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF eHealth 2015 task 1b focuses on concept recognition in French medical text <ref type="bibr" coords="1,169.90,498.98,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,182.08,498.98,7.01,8.74" target="#b1">2]</ref>. The task consists of three subtasks: recognition of relevant entities in a French medical corpus, normalization of the recognized entities, and normalization of entity mentions that had been manually annotated. The entities covered a wide variety of semantic groups. The normalization had to be based on the Unified Medical Language System (UMLS), and involved assigning UMLS concept unique identifiers (CUIs) to the entities that were recognized or provided. Each subtask should be performed fully automatically.</p><p>We addressed all three subtasks. Central in our approach to entity recognition and normalization are French terminologies based on the UMLS and postprocessing steps to reduce the number of false-positive detections. The UMLS already contains a number of French vocabularies, but their coverage is rather limited. We therefore explored the possibility to expand the coverage by automatic translation of English UMLS terms into French. For this purpose, we utilized two automatic translators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpora</head><p>We utilized two corpora in our experiments: the Quaero medical corpus, a French annotated resource for medical entity recognition and normalization <ref type="bibr" coords="2,438.39,172.17,9.96,8.74" target="#b2">[3]</ref>, which was the basis for the training and test sets provided in task 1b; and the Mantra corpus, a large multilingual biomedical corpus developed as part of the Mantra project <ref type="bibr" coords="2,169.44,208.04,9.96,8.74" target="#b3">[4]</ref>, which we used to determine the terms for term translation and to create a term exclusion list. Each corpus is briefly described below.</p><p>Quaero Corpus. The Quaero corpus consists of three subcorpora (1): titles from French Medline abstracts, drug labels from the European Medicines Agency (EMEA), and patents from the European Patent Office. For the task 1b challenge, only Medline titles and EMEA documents were made available. The training set consisted of 833 Medline titles and 11 EMEA documents; the test set contained 832 Medline titles and 12 EMEA documents.</p><p>The annotations in the Quaero corpus are based on a subset of the Unified Medical Language System (UMLS) <ref type="bibr" coords="2,294.47,331.77,9.96,8.74" target="#b4">[5]</ref>. Briefly, the UMLS is a metathesaurus integrating more than 150 biomedical terminologies. Each concept in the UMLS is assigned a concept unique identifier (CUI), a set of corresponding terms, and one or more semantic types, which are mapped to one of 15 semantic groups (SGs) <ref type="bibr" coords="2,163.48,379.59,9.96,8.74" target="#b5">[6]</ref>. Typically, each concept belongs to one semantic group. An entity in the Quaero corpus was only annotated if the concept belonged to the UMLS and the corresponding SG was any of the following 10 SGs: Anatomy, Chemicals and drugs, Devices, Disorders, Geographic areas, Living beings, Objects, Phenomena, Physiology, and Procedures. Nested or overlapping entities were all annotated, as were ambiguous entities (i.e., if an entity could refer to more than one concept, all concepts were annotated).</p><p>Mantra Corpus. The Mantra corpus was developed as part of the Mantra project <ref type="bibr" coords="2,169.44,491.36,9.96,8.74" target="#b3">[4]</ref>, aimed at providing multilingual resources in English, French, German, Spanish, and Dutch. The corpus consists of 1.6 million bilingual Medline titles (always in English and one of the other languages), 130k sentences of EMEA drug labels (available in all five languages), and 155k sentences of EPO patents (in English, French, and German in parallel). The texts in the Quaero corpus are a subset of the French texts in the Mantra corpus. The Mantra corpus is supplied with automatically generated silver-standard annotations, and recently multilingual gold-standard annotations have become available for a small subset of the Mantra corpus <ref type="bibr" coords="2,232.09,587.00,9.96,8.74" target="#b6">[7]</ref>, but none of these resources were used in the current work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Term Translation</head><p>The UMLS version 2014AB contains 178,860 unique French terms from 88,986 concepts, mainly stemming from MedDRA and MeSH, and only covering a few percent of the more than 5 million English terms and 2.6 million concepts in the UMLS. To expand the number of French terms, we used the web services application programming interface from Google Translate (GT) <ref type="bibr" coords="3,408.37,143.90,10.52,8.74" target="#b7">[8]</ref> and Microsoft Bing (MB) <ref type="bibr" coords="3,184.71,155.86,10.52,8.74" target="#b8">[9]</ref> to automatically translate English terms into French. Initially, we considered the translation of all English terms in the UMLS, but dismissed this approach as being too expensive and time-consuming. Instead, we reasoned that only the concepts that are found in a large English corpus that is representative of the task domain, may also be found in the Quaero corpus. We therefore indexed all English Medline titles and EMEA sentences from the Mantra corpus with our indexing system Peregrine <ref type="bibr" coords="3,251.09,227.59,14.61,8.74" target="#b9">[10]</ref>, using the full English UMLS, and found 133,246 unique concepts. The 745,158 English terms corresponding with these concepts were translated into French using the automatic translators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Terminologies</head><p>In our experiments on the Quaero corpus we used five French terminologies:</p><p>-Baseline: all French terms in UMLS version 2014AB. Only terms belonging to concepts in the ten SGs listed above were considered.</p><p>-GT: all terms from Google Translate and the baseline terminology.</p><p>-MB: all terms from Microsoft Bing and the baseline terminology.</p><p>-Union: all terms from Google Translate, Microsoft Bing, and the baseline terminology.</p><p>-Intersection: all terms that had the same translation by Google Translate and Microsoft Bing, supplemented with the baseline terminology.</p><p>The English terminology for indexing the Mantra corpus consisted of all English terms in UMLS version 2014 AB, filtered for the ten relevant SGs.</p><p>Both on the English terminology and the French baseline terminology we applied a set of term rewrite and suppression rules <ref type="bibr" coords="3,360.25,460.21,14.61,8.74" target="#b10">[11]</ref>. In a separate step (explained below), we supplemented the French terminologies with the concepts and terms in the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Entity Recognition and Entity Normalization</head><p>The processing for the entity recognition and the entity normalization included an indexing and a post-processing step, which are described below.</p><p>Indexing. The corpora were indexed with Peregrine, a dictionary-based concept recognition system <ref type="bibr" coords="3,218.43,585.38,14.61,8.74" target="#b9">[10]</ref>. Peregrine can find partially overlapping concepts, but it cannot detect nested concepts (it only returns the concept corresponding with the longest term). We therefore implemented an additional indexing step. For each term found by Peregrine and consisting of n words (n &gt; 1), all subsets of 1 to n-1 words were generated, under the condition that for subsets consisting of more than one word, the words had to be adjacent in the original term. All word subsets were then also indexed by Peregrine.</p><p>Post-processing. To reduce the number of false-positive detections that resulted from the indexing, we applied several post-processing steps. First, we removed terms that were part of an exclusion list. The list was manually created by indexing the French Mantra corpus with the largest available French terminology (union), ordering the detected terms by their frequency in the corpus, and selecting the incorrect terms from the 2,500 top-ranked terms.</p><p>Second, for any term-SG-CUI combination and SG-CUI combination that was found by Peregrine and had also been annotated in the training data, we computed precision scores: true positives / (true positives + false negatives). For a given term, only term-SG-CUI combinations with a precision above a certain threshold value were kept. If multiple combinations qualified, only the two with the highest precision scores were selected. If for a given term none of the found term-SG-CUI combinations had been annotated in the training data, but precision scores were available for the SG-CUI combinations, a term-SG-CUI combination was still kept if the precision of the SG-CUI combination was higher than the threshold. If multiple combinations qualified, the two with the highest precision were kept if they had the same SG; otherwise, only the combination with the highest precision was kept. If none of the SG-CUI combinations had been annotated, a single term-SG-CUI combination was selected, taking into account whether the term was the preferred term for a CUI, and the CUI number (lowest first).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Normalization Based on Gold-Standard Entity Recognition</head><p>For entity normalization given the gold-standard terms and SGs, we developed the following processing pipeline. First, we computed precision scores for all term-SG-CUI combinations in the training set. If a given term-SG combination in the test set was also present in the training set, we selected the CUI of the term-SG-CUI combination with the highest precision score. If the second largest precision score was larger than 0.3, the CUI of the corresponding term-SG-CUI combination was also selected.</p><p>Second, if a term-SG combination in the test set had not been seen in the training set, we searched the terminology for terms that had a Levenshtein edit distance of maximum one. If one such term was found, the corresponding CUI was selected. If multiple terms were found, for each term the corresponding SG-CUI combination was sought in the training data. If present, precision scores were computed and the CUI of the SG-CUI combination with the largest precision was selected. If the SG-CUI combination did not exist in the training data, it was checked if the term was the preferred term for any of the CUIs. If this was the case for just one CUI, it was selected. Otherwise, a single CUI was selected, taking into account whether the CUI had been annotated in the training set, and the CUI number (lowest first).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance on the Quaero Training Set</head><p>We used the Quaero training data to optimize the performance of the indexing and post-processing steps for entity recognition and normalization. Table <ref type="table" coords="5,448.00,174.06,4.98,8.74" target="#tab_0">1</ref> shows the results for the five French terminologies that we generated: Baseline (UMLS French), GT, MB, Union, and Intersection. The results have been generated with the task 1b evaluation script, using exact matching for both entity recognition and normalization. The terminologies based on automatic term translations (GT and MB) substantially increase recall as compared to the UMLS baseline terminology, but at the expense of a large decrease in precision. GT performs slightly better than MB in terms of F-score. The union of both terminologies results in a small further increase of the recall. The intersection improves precision considerably at the expense of some loss of recall. The performance of the terminologies with translated terms is better on the EMEA documents than on the Medline titles, primarily because the recall is higher. Interestingly, the reverse is true for the baseline terminology, which performs slightly better on the Medline titles. As expected, the performance for entity normalization is lower than for entity recognition, mainly because of a lower precision. This is largely caused by the ambiguity of many terms. At this stage, our indexing system did not try to disambiguate when multiple CUIs for the same term were found, and thus many of the CUIs were scored as false positives.</p><p>In our further experiments we decided to focus on the Union and Intersection terminologies. First, we tested the effect of expanding our terminologies with terms from concepts in the training data that were missed by our indexing system (false negatives). In order not to optimistically bias our performance results, we split the Quaero training data in an equally-sized training set and test set. Table <ref type="table" coords="5,199.91,657.11,4.98,8.74" target="#tab_1">2</ref> shows the performance results on the test set. Addition of the false negatives results in a clear improvement of the recall, with only a small decrease in precision.</p><p>Based on the expanded terminologies, we tested the effect of our post-processing steps, aimed at removing incorrectly indexed terms (false positives). An important parameter in this process is the precision threshold (see post-processing description above). Using half of the Quaero training data, we varied this threshold between 0.1 and 0.5 with steps of 0.1, and tested on the other half of the training data. The best F-score was obtained for a threshold of 0.3. Table <ref type="table" coords="6,428.72,324.93,4.98,8.74" target="#tab_2">3</ref> shows the results of the post-processing steps using this threshold. The post-processing steps reduce recall but strongly increase precision, as well as the F-scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance on the Quaero Test Data</head><p>We submitted two runs for both the entity recognition and normalization tasks, one run using the Union terminology, the other using the Intersection terminology. Both terminologies were expanded with all false negatives of the Quaero training set. Table <ref type="table" coords="6,216.59,596.76,4.98,8.74" target="#tab_3">4</ref> shows our performance results on the final test set for exact match. (Note: we swapped the test run precision and recall values that the task organizers provided to us, since we could deduce from the FP and FN counts that they had been reversed.)</p><p>Our results on the test set were better than on the training set, mainly because of higher precision values. Overall, the system using the Intersection terminology performed best. These results are well above the average and median of the scores from all participant runs, as provided by the task organizers. We also submitted two runs for the normalization using the gold-standard entity recognition results. The difference between the two runs was that the first run did not include the final disambiguation step (selection of CUIs if they had been annotated in the training set and based on CUI number). Table <ref type="table" coords="7,434.93,288.75,4.98,8.74" target="#tab_4">5</ref> gives the performance results. As was to be expected, use of the gold-standard entity recognition improved the normalization results. In particular precision was boosted, with a remarkable precision of 1 for the EMEA corpus. The final disambiguation hardly affected the performance results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Our results show that expanding the coverage of the French UMLS baseline terminology with the use of an automated term translator is a viable way to improve the recall for entity recognition and normalization, but also reduces precision considerably. Taking the intersection of the term translations increases precision again, while only slightly reducing recall. The various post-processing steps further improve precision. The union of the term translations did hardly further improve the recall, indicating that the annotated corpus contained few terms that were uniquely provided by one of the translators. Although the precision of the Union terminology on the Quaero training set was substantially less than the precision of the Intersection, the difference on the test set was much smaller.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,144.31,251.01,326.72,149.61"><head>Table 1 .</head><label>1</label><figDesc>Performance of five French terminologies on the Quaero training set</figDesc><table coords="5,144.31,271.81,326.72,128.81"><row><cell></cell><cell cols="3">Entity recognition</cell><cell cols="3">Entity normalization</cell></row><row><cell cols="4">Corpus Terminology Precision Recall F-score</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>EMEA Baseline</cell><cell>0.724</cell><cell>0.399</cell><cell>0.515</cell><cell>0.588</cell><cell>0.359</cell><cell>0.446</cell></row><row><cell>GT</cell><cell>0.368</cell><cell>0.763</cell><cell>0.496</cell><cell>0.220</cell><cell>0.670</cell><cell>0.332</cell></row><row><cell>MB</cell><cell>0.345</cell><cell>0.791</cell><cell>0.481</cell><cell>0.208</cell><cell>0.687</cell><cell>0.316</cell></row><row><cell>Union</cell><cell>0.298</cell><cell>0.807</cell><cell>0.435</cell><cell>0.172</cell><cell>0.702</cell><cell>0.274</cell></row><row><cell>Intersection</cell><cell>0.454</cell><cell>0.756</cell><cell>0.567</cell><cell>0.273</cell><cell>0.669</cell><cell>0.388</cell></row><row><cell>Medline Baseline</cell><cell>0.716</cell><cell>0.433</cell><cell>0.540</cell><cell>0.591</cell><cell>0.376</cell><cell>0.460</cell></row><row><cell>GT</cell><cell>0.392</cell><cell>0.658</cell><cell>0.491</cell><cell>0.236</cell><cell>0.572</cell><cell>0.335</cell></row><row><cell>MB</cell><cell>0.370</cell><cell>0.664</cell><cell>0.475</cell><cell>0.229</cell><cell>0.579</cell><cell>0.328</cell></row><row><cell>Union</cell><cell>0.343</cell><cell>0.705</cell><cell>0.461</cell><cell>0.199</cell><cell>0.612</cell><cell>0.300</cell></row><row><cell>Intersection</cell><cell>0.447</cell><cell>0.628</cell><cell>0.523</cell><cell>0.274</cell><cell>0.550</cell><cell>0.366</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,116.91,345.81,94.81"><head>Table 2 .</head><label>2</label><figDesc>Performance after expanding the terminologies with false negatives from half of the Quaero training set and testing on the other half</figDesc><table coords="6,144.31,148.67,326.72,63.06"><row><cell></cell><cell cols="3">Entity recognition</cell><cell cols="3">Entity normalization</cell></row><row><cell cols="4">Corpus Terminology Precision Recall F-score</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>EMEA Union</cell><cell>0.301</cell><cell>0.869</cell><cell>0.447</cell><cell>0.182</cell><cell>0.794</cell><cell>0.297</cell></row><row><cell>Intersection</cell><cell>0.433</cell><cell>0.861</cell><cell>0.576</cell><cell>0.264</cell><cell>0.793</cell><cell>0.396</cell></row><row><cell>Medline Union</cell><cell>0.401</cell><cell>0.708</cell><cell>0.512</cell><cell>0.246</cell><cell>0.638</cell><cell>0.355</cell></row><row><cell>Intersection</cell><cell>0.513</cell><cell>0.668</cell><cell>0.580</cell><cell>0.326</cell><cell>0.607</cell><cell>0.424</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,369.53,345.82,94.81"><head>Table 3 .</head><label>3</label><figDesc>Performance of the expanded terminologies with post-processing steps on half of the Quaero training set</figDesc><table coords="6,144.31,401.29,326.72,63.06"><row><cell></cell><cell cols="3">Entity recognition</cell><cell cols="3">Entity normalization</cell></row><row><cell cols="4">Corpus Terminology Precision Recall F-score</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>EMEA Union</cell><cell>0.452</cell><cell>0.786</cell><cell>0.574</cell><cell>0.407</cell><cell>0.727</cell><cell>0.521</cell></row><row><cell>Intersection</cell><cell>0.679</cell><cell>0.784</cell><cell>0.728</cell><cell>0.619</cell><cell>0.736</cell><cell>0.672</cell></row><row><cell>Medline Union</cell><cell>0.579</cell><cell>0.605</cell><cell>0.592</cell><cell>0.477</cell><cell>0.508</cell><cell>0.492</cell></row><row><cell>Intersection</cell><cell>0.747</cell><cell>0.581</cell><cell>0.654</cell><cell>0.634</cell><cell>0.500</cell><cell>0.559</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,139.81,116.91,335.72,83.86"><head>Table 4 .</head><label>4</label><figDesc>Entity recognition and normalization performance on the Quaero test set</figDesc><table coords="7,144.31,137.71,326.72,63.06"><row><cell></cell><cell cols="3">Entity recognition</cell><cell cols="3">Entity normalization</cell></row><row><cell cols="4">Corpus Terminology Precision Recall F-score</cell><cell cols="3">Precision Recall F-score</cell></row><row><cell>EMEA Union</cell><cell>0.710</cell><cell>0.776</cell><cell>0.741</cell><cell>0.653</cell><cell>0.705</cell><cell>0.678</cell></row><row><cell>Intersection</cell><cell>0.751</cell><cell>0.761</cell><cell>0.756</cell><cell>0.707</cell><cell>0.714</cell><cell>0.711</cell></row><row><cell>Medline Union</cell><cell>0.683</cell><cell>0.662</cell><cell>0.662</cell><cell>0.559</cell><cell>0.552</cell><cell>0.575</cell></row><row><cell>Intersection</cell><cell>0.711</cell><cell>0.625</cell><cell>0.665</cell><cell>0.634</cell><cell>0.547</cell><cell>0.587</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,134.77,332.49,345.81,83.86"><head>Table 5 .</head><label>5</label><figDesc>Normalization performance on the test set given the entity recognition, with and without the final disambiguation step</figDesc><table coords="7,198.97,364.25,217.41,52.10"><row><cell cols="5">Corpus Disambiguation Precision Recall F-score</cell></row><row><cell>EMEA</cell><cell>No</cell><cell>1.000</cell><cell>0.767</cell><cell>0.868</cell></row><row><cell></cell><cell>Yes</cell><cell>1.000</cell><cell>0.774</cell><cell>0.872</cell></row><row><cell>Medline</cell><cell>No</cell><cell>0.817</cell><cell>0.573</cell><cell>0.674</cell></row><row><cell></cell><cell>Yes</cell><cell>0.805</cell><cell>0.575</cell><cell>0.671</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,143.59,337.62,7.86;8,151.52,154.54,329.05,7.86;8,151.52,165.50,329.06,7.86;8,151.52,176.46,180.66,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,211.43,154.54,185.39,7.86">Overview of the CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hanlen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,435.29,154.54,45.28,7.86;8,151.52,165.50,209.88,7.86">CLEF 2015 -6th Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="8,369.46,165.50,111.12,7.86;8,151.52,176.46,56.66,7.86">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,187.42,337.62,7.86;8,151.52,198.38,329.05,7.86;8,151.52,209.34,270.89,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,193.22,198.38,287.35,7.86;8,151.52,209.34,46.11,7.86">CLEF eHealth Evaluation Lab 2015 Task 1b: Clinical Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,204.89,209.34,137.27,7.86">CLEF 2015 Online Working Notes</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,220.30,337.62,7.86;8,151.52,231.26,329.06,7.86;8,151.52,242.22,329.05,7.86;8,151.52,253.17,232.17,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,419.52,220.30,61.05,7.86;8,151.52,231.26,329.06,7.86;8,151.52,242.22,25.98,7.86">The QUAERO French Medical Corpus: a Ressource for Medical Entity Recognition and Normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Leixa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.99,242.22,283.58,7.86;8,151.52,253.17,156.82,7.86">Fourth Workshop on Building and Evaluating Resources for Health and Biomedical Text Processing (BioTxtM)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="24" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,264.13,240.28,8.11" xml:id="b3">
	<monogr>
		<ptr target="http://www.mantra-project.eu" />
		<title level="m" coord="8,151.52,264.13,92.33,7.86">Mantra project website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,275.09,337.62,7.86;8,151.52,286.05,263.40,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,225.45,275.09,255.13,7.86;8,151.52,286.05,95.14,7.86">The Unified Medical Language System (UMLS): Integrating Biomedical Terminology</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,254.07,286.05,74.98,7.86">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="270" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,297.01,337.62,7.86;8,151.52,307.97,195.41,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,283.47,297.01,197.10,7.86;8,151.52,307.97,33.06,7.86">Exploring Semantic Groups Through Visual Approaches</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,191.78,307.97,76.30,7.86">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="414" to="432" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,318.93,337.62,7.86;8,151.52,329.89,329.05,7.86;8,151.52,340.85,283.46,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,165.97,329.89,314.61,7.86;8,151.52,340.85,48.96,7.86">A Multilingual Gold-Standard Corpus for Biomedical Concept Recognition: the Mantra GSC</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,208.94,340.85,110.89,7.86">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>epub ahead of print</note>
</biblStruct>

<biblStruct coords="8,142.96,351.80,214.74,8.11" xml:id="b7">
	<monogr>
		<ptr target="https://translate.google.com" />
		<title level="m" coord="8,151.52,351.80,67.27,7.86">Google Translate</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,362.76,260.14,8.11" xml:id="b8">
	<monogr>
		<ptr target="http://www.bing.com/translator" />
		<title level="m" coord="8,151.52,362.76,103.25,7.86">Microsoft Bing Translator</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,373.72,337.96,7.86;8,151.52,384.68,329.06,7.86;8,151.52,395.64,140.04,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,314.29,373.72,166.28,7.86;8,151.52,384.68,132.89,7.86">Peregrine: Lightweight Gene Name Normalization by Dictionary Lookup</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jelier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,292.56,384.68,183.26,7.86">Proceedings of the BioCreAtIvE II Workshop</title>
		<meeting>the BioCreAtIvE II Workshop<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="131" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,406.60,337.96,7.86;8,151.52,417.56,329.05,7.86;8,151.52,428.52,192.29,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,175.49,417.56,305.09,7.86;8,151.52,428.52,52.08,7.86">Rewriting and Suppressing UMLS Terms for Improved Biomedical Term Identification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Hettne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J A</forename><surname>Schijvenaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,210.40,428.52,86.83,7.86">J. Biomed. Semantics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
