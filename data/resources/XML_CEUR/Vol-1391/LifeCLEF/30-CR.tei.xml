<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.23,115.96,254.90,12.62;1,155.41,133.89,304.54,12.62;1,150.38,151.82,314.59,12.62">A comparative study of fine-grained classification methods in the context of the LifeCLEF plant identification challenge 2015</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.37,189.49,61.02,8.74"><forename type="first">Julien</forename><surname>Champ</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.28,189.49,68.81,8.74"><forename type="first">Titouan</forename><surname>Lorieul</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.98,189.49,94.13,8.74"><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,441.37,189.49,26.62,8.74;1,293.21,201.45,18.13,8.74"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.23,115.96,254.90,12.62;1,155.41,133.89,304.54,12.62;1,150.38,151.82,314.59,12.62">A comparative study of fine-grained classification methods in the context of the LifeCLEF plant identification challenge 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FAFE7294D379EDEDCC4EAE79E8B6C79B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>plant</term>
					<term>leaves</term>
					<term>leaf</term>
					<term>flower</term>
					<term>fruit</term>
					<term>bark</term>
					<term>stem</term>
					<term>branch</term>
					<term>species</term>
					<term>retrieval</term>
					<term>images</term>
					<term>collection</term>
					<term>species identification</term>
					<term>citizen-science</term>
					<term>fine-grained classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of Inria to the plant identification task of the LifeCLEF 2015 challenge. The aim of the task was to produce a list of relevant species for a large set of plant observations related to 1000 species of trees, herbs and ferns living in Western Europe. Each plant observation contained several annotated pictures with organ/view tags: Flower, Leaf, Fruit, Stem, Branch, Entire, Scan (exclusively of leaf). To address this challenge, we experimented two popular families of classification techniques, i.e. convolutional neural networks (CNN) on one side and fisher vectors-based discriminant models on the other side. Our results show that the CNN approach achieves much better performance than the fisher vectors. Beyond, we show that the fusion of both techniques, based on a Bayesian inference using the confusion matrix of each classifier, did not improve the results of the CNN alone.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Content-based image retrieval and computer vision approaches are considered as one of the most promising solutions to help bridging the taxonomic gap, as discussed in <ref type="bibr" coords="1,189.80,531.00,11.84,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,201.64,531.00,7.90,8.74" target="#b0">1,</ref><ref type="bibr" coords="1,209.54,531.00,11.84,8.74" target="#b34">36,</ref><ref type="bibr" coords="1,221.38,531.00,11.84,8.74" target="#b32">34,</ref><ref type="bibr" coords="1,233.23,531.00,11.84,8.74" target="#b16">17]</ref>. We therefore see an increasing interest in this transdisciplinary challenge in the multimedia community (e.g. in <ref type="bibr" coords="1,403.66,542.95,16.20,8.74" target="#b24">[26,</ref><ref type="bibr" coords="1,419.85,542.95,12.15,8.74" target="#b9">10,</ref><ref type="bibr" coords="1,432.00,542.95,8.10,8.74" target="#b1">2,</ref><ref type="bibr" coords="1,440.10,542.95,12.15,8.74" target="#b23">25,</ref><ref type="bibr" coords="1,452.25,542.95,12.15,8.74">20,</ref><ref type="bibr" coords="1,464.39,542.95,12.15,8.74" target="#b11">12]</ref>. Beyond the raw identification performances achievable by state-of-the-art computer vision algorithms, recent visual search paradigms actually offer much more efficient and interactive ways of browsing large flora than standard field guides or online web catalogs ( <ref type="bibr" coords="1,226.02,590.77,10.52,8.74" target="#b2">[3]</ref>). Smartphone applications relying on such image-based identification services are particularly promising for setting-up massive ecological monitoring systems, involving thousands of contributors at a very low cost. A first step in this way has been achieved by the US consortium behind LeafSnap <ref type="foot" coords="1,150.82,637.02,3.97,6.12" target="#foot_0">3</ref> , an i-phone application allowing the identification of 184 common american plant species based on pictures of cut leaves on an uniform background (see <ref type="bibr" coords="2,465.10,118.99,15.50,8.74" target="#b21">[23]</ref> for more details). Then, the French consortium supporting Pl@ntNet ( <ref type="bibr" coords="2,437.96,130.95,15.50,8.74" target="#b16">[17]</ref>) went one step beyond by building an interactive image-based plant identification application that is continuously enriched by the members of a social network specialized in botany. Inspired by the principles of citizen sciences and participatory sensing, this project quickly met a large public with more than 300K downloads of the mobile applications ( <ref type="bibr" coords="2,255.09,190.72,10.79,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,265.88,190.72,7.20,8.74" target="#b6">7]</ref>). A related initiative is the plant identification evaluation task organized since 2011 in the context of the international evaluation forum CLEF <ref type="foot" coords="2,217.26,213.06,3.97,6.12" target="#foot_1">4</ref> and that is based on the data collected within Pl@ntNet. This paper presents the participation of Inria ZENITH team to the 2015-edition of this challenge <ref type="bibr" coords="2,208.43,238.55,11.15,8.74" target="#b8">[9,</ref><ref type="bibr" coords="2,219.58,238.55,11.15,8.74" target="#b18">19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>From a computer vision and technological perspective, our work is more generally related to image classification. Most popular methods for this problem are typically based on the pooling of local visual features into global image representations and the use of powerful classifiers in the resulting high-dimensional embedded space such as linear support vector machines ( <ref type="bibr" coords="2,389.08,361.54,15.50,8.74" target="#b22">[24,</ref><ref type="bibr" coords="2,404.58,361.54,11.62,8.74" target="#b26">28]</ref>). The Bag-ofword representation (BoW) notably remains a key concept although the raw initial scheme of ( <ref type="bibr" coords="2,213.03,385.45,15.50,8.74" target="#b31">[33]</ref>) is now outperformed by several alternative new schemes ( <ref type="bibr" coords="2,138.76,397.41,15.99,8.74" target="#b22">[24,</ref><ref type="bibr" coords="2,154.75,397.41,11.99,8.74" target="#b15">16,</ref><ref type="bibr" coords="2,166.74,397.41,11.99,8.74" target="#b25">27,</ref><ref type="bibr" coords="2,178.74,397.41,7.99,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,186.73,397.41,11.99,8.74" target="#b13">14]</ref>). Its principle is to first train a so called visual vocabulary thanks to an unsupervised clustering algorithm computed on a given training set of local features. The produced partition is then used to quantize the visual features of a given new image into visual words that are aggregated within a single high-dimensional histogram. Partial geometry can be embedded in the image representation by using the Spatial Pyramid Matching scheme of ( <ref type="bibr" coords="2,432.05,457.18,14.87,8.74" target="#b22">[24]</ref>). As it relies on vector quantization, the BoW representation is however affected by quantization errors. Very similar visual features might be split across distinct clusters whereas more dissimilar ones might be affected to the same visual word. This results in both mismatches and potentially irrelevant matches. To alleviate this problem, several improvements have been proposed in the literature. The first one consists in expanding the assignment of a given local feature to its nearest visual words ( <ref type="bibr" coords="2,212.24,540.87,15.79,8.74" target="#b15">[16,</ref><ref type="bibr" coords="2,228.03,540.87,11.84,8.74" target="#b27">29,</ref><ref type="bibr" coords="2,239.87,540.87,7.90,8.74" target="#b5">6,</ref><ref type="bibr" coords="2,247.77,540.87,11.84,8.74" target="#b13">14]</ref>). This allows reducing the number of mismatches without degrading much the encoding time. Other researchers have investigated alternative ways to avoid the vector quantization step, using sparse coding ( <ref type="bibr" coords="2,461.22,564.78,15.50,8.74" target="#b36">[38]</ref>) or locality-constrained linear coding ( <ref type="bibr" coords="2,299.80,576.73,14.87,8.74" target="#b35">[37]</ref>). Such methods optimize the affectation of a given local feature to a small number of visual words thanks to sparsity or locality constraints on the global representation. Another alternative is to use aggregation-based models such as the improved Fisher Vector of <ref type="bibr" coords="2,435.71,612.60,15.50,8.74" target="#b25">[27]</ref> or the VLAD encoding scheme ( <ref type="bibr" coords="2,248.59,624.55,14.87,8.74" target="#b13">[14]</ref>). Such methods do not only encode the number of occurrences of each visual word but also encode additional information about the distribution of the descriptors by aggregating the component-wise differences. When used with discriminative linear classifiers, such high-dimensional representations benefit of both generative and discrimination approaches leading to state-of-the-art classification performances on fine-grained classification benchmarks ( <ref type="bibr" coords="3,193.63,166.81,14.87,8.74" target="#b10">[11]</ref>). A radically different approach to image classification is the use of deep convolutional neural networks. Rather than extracting the features according to hand-tuned or psycho-vision oriented filters, such methods directly work on the image signal. The weights learned by the first convolutional layers allows to automatically build relevant image filters whereas the intermediate layers are in charge of pooling these raw responses into high-level visual patterns. The last fully connected layers work more traditionally as any discriminative classifier on the image representation resulting from the previous layers. Deep convolutional neural networks have been recently proved to achieve better results on large-scale image classification datasets such as ImageNet ( <ref type="bibr" coords="3,394.19,286.37,15.50,8.74" target="#b20">[22]</ref>) and do attract more and more interest in the computer and multimedia vision communities. A known drawback of Deep Convolutional Neural Networks is however that they require a lot of training data mainly because of the huge number of parameters to be learned. Their performances on fine-grained classification are consequently more controversial and they are still often outperformed by local features based approaches, as shown in our experiments. Besides, it is important to notice that they inspire the investigation of new deep learning models making use of more traditional visual features embedding methods (e.g. <ref type="bibr" coords="3,362.75,382.01,14.75,8.74" target="#b29">[31]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimented fine-grained image classification systems</head><p>We did experiment two families of image classification techniques that are known to provide state-of-the-art classification performances, in particular in fine-grained recognition challenges ( <ref type="bibr" coords="3,236.97,474.20,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="3,252.46,474.20,11.62,8.74" target="#b17">18]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolutional neural networks</head><p>Convolutional Neural Networks (CNN) have been mainly used since the 90's for their performances in digit classification. But since a few years, they appear to have now surpassed all state of the art methods for large-scale image classification <ref type="bibr" coords="3,165.16,560.42,14.61,8.74" target="#b20">[22]</ref>. In this experimentation, we have used Caffe <ref type="bibr" coords="3,385.50,560.42,14.61,8.74" target="#b14">[15]</ref>, a Deep Learning Framework, allowing us to use CNN architectures and models from the literature. We have chosen in the Caffe model Zoo the "GoogLeNet GPU implementation" model, based on Google winning architecture in the ImageNet 2014 Challenge <ref type="bibr" coords="3,134.77,608.24,14.61,8.74" target="#b33">[35]</ref>, and we fine-tuned this model on the LifeCLEF datasets.</p><p>The GoogLeNet architecture consists of a 22 layers deep network with a softmax loss as the top classifier. It is composed of three "inception modules" stacked on top of each other. Each intermediate inception module is connected to an auxiliary classifier during training, so as to encourage discrimination in the lower stages of the classifier, increase the gradient signal that gets propagated back, and provide additional regularization. These auxiliary classifiers are only used during the training part, and then discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Setup</head><p>The previously described GoogLeNet CNN uses square images as input. For each image in the training and test sets, we therefore cropped the largest square in the center, and re-sized it to 256x256 pixels. Instead of starting to train our CNN from scratch only on plant images, and as it was authorized in this year's challenge, we started with a CNN trained on the popular generalist ImageNet dataset. We only removed its top layers (the fully connected ones), changed the number of outputs, and trained this new model using the desired dataset. As it was implemented within Caffe library, it makes also use of a simple data augmentation technique, consisting in cropping randomly a 224x224 pixels image, and eventually mirroring it horizontally.</p><p>During our preliminary experiments, we have tried several training strategies that are presented are presented in Table <ref type="table" coords="4,317.91,305.86,3.87,8.74" target="#tab_0">1</ref>. We have tested all these configurations using the PlantCLEF 2014 data and groundtruth (500 species, 47815 train images and 13146 test images). CNN1 configuration was the simplest and the first that we have tested, but finally also the one providing the best results. The Data Augmentation method proposed for CNN2 configuration increased significantly the number of train images as we generated 8 new images by applying rotations, and a set of colorimetric transformations with randomized parameters, i.e. brightness &amp; saturation modulation in the HSL color space (multiplier factor randomized between 0.8 and 1.2), and contrast modulation (multiplier factor randomized between 0.7 and 1.3). Even with additional iterations to train the CNN, results remained nearly the same than those for CNN1. The CNN3 configuration consisted in training several CNNs, one for each view type (thanks to the tags provided in the meta-data). On one hand, as some species haven't images for all views, the number of output for each CNN is lower than 1000 and that could help to obtain better results because of the reduction of the confusion risk. On the other hand, some images from a given view (Branch for example) can really help to identify some images tagged with another view (Entire for example). Results were slightly lower for the Branch, Entire, Leaf, Fruit, and Flower views than what was obtained with the standalone CNN. This could be explained by a less important number of images to train the network, and proves that images from a given view can help when identifying an image tagged with another view. This conclusion is not true for the Stem and LeafScan views. The reason is probably that the LeafScan view is specific, very different from other views, and does not contain background information, and as the Stem tag identifies a closeup view of the plant which is not really apparent on other images.</p><p>Training parameters As a reminder, here are the most important parameters for Caffe to obtain our submitted run (CNN1). The base learning rate parameter was set to 10 -5 . The learning rate is divided by 10 every 60k iterations. After 150k iterations the training is over, and the batch size was fixed to 32. All other parameters were unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fisher vectors &amp; Logistic Regression</head><p>Fisher vectors (FV) were first introduced in image classification by <ref type="bibr" coords="5,444.29,298.85,15.50,8.74" target="#b25">[27]</ref> and proved to be very efficient in fine-grained classification tasks later on ( <ref type="bibr" coords="5,458.29,310.80,14.87,8.74" target="#b10">[11]</ref>). According to recent surveys such as <ref type="bibr" coords="5,292.21,322.76,14.61,8.74" target="#b12">[13]</ref>, it is the best performing pooling strategy currently available. We will only recall here the main steps used to extract Fisher vectors, for detailed explanations of the theoretical derivation and for performance analysis we redirect the readers to <ref type="bibr" coords="5,341.56,358.62,14.61,8.74" target="#b28">[30]</ref>. The pipeline for computing the Fisher vector describing an image consists in:</p><p>1. Dense extraction of local features: descriptors, often SIFT descriptors, are extracted on densely sampled overlapping patches at several scales. 2. PCA transformation: the descriptors are then de-correlated and compressed using a Principal Component Analysis. 3. Feature space density estimation: the distribution of features is modeled as a Gaussian Mixture Model (GMM) that is learned using the popular Expectation-Maximisation (EM) algorithm. We thus obtain a probability distribution of the form of u(x) = K k=1 w k u k (x) where u k follows a Gaussian distribution of mean µ k and covariance matrix Σ k , u k ∼ N (µ k , Σ k ), with Σ k being diagonal because the features are decorrelated, and where w k is the weight of the k-th Gaussian, these weights satisfy k w k = 1. 4. Encoding and pooling: the features are encoded and pooled using</p><formula xml:id="formula_0" coords="5,228.41,546.72,169.52,73.75">G µ k = 1 √ w k N i=1 γ k (x i ) x i -µ k σ k G σ k = 1 √ w k N i=1 γ k (x i ) √ 2 x i -µ k σ k 2 -1</formula><p>where all the divisions and squaring are element-wise operations and where x) . Theses 2K vectors are concatenated to produce the final representation of dimension 2dK.</p><formula xml:id="formula_1" coords="5,151.70,638.31,91.43,17.66">γ k (x) = w k u k (x) K k =1 w k u k (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>Post-processing: the vectors are L2-normalized and element-wise squarerooted using x → sign(x). |x|.</p><p>Usually, the classification of Fisher Vectors is performed using a linear classifier as it has been shown that using kernelization techniques on such highdimensional spaces does not improve significantly the performances. In our experiments, we used the Logistic Regression classifier implemented within the LibLinear library ( <ref type="bibr" coords="6,218.39,196.80,10.52,8.74" target="#b3">[4]</ref>). This method was preferred over Support Vectors Machine because it directly outputs probabilities which then can be used for fusion purposes.</p><p>Here, we used two types of Fisher Vectors with two different types of descriptors. The first system was built with RootSIFT descriptors, l2-normalized and square-rooted SIFT descriptors, of 128 dimensions which are then reduced to 80 dimensions through PCA. The second one was based on some complementary descriptors used in the Pl@ntNet application <ref type="bibr" coords="6,381.36,280.48,14.61,8.74" target="#b16">[17]</ref>. It consists in the concatenation of several basic descriptors such as Fourier histograms, Edge Orientation Histograms (EOH), HSV histograms and Hough transform histograms. This concatenation was then compressed and de-correlated using PCA. The association of descriptors used depends on the organ, for Branch, Entire, Leaf, LeafScan, Stem only Fourier, EOH and Hough histograms are used resulting in 44-dimension final descriptors compressed to 14 dimensions after PCA while Flower and Fruit add HSV histograms giving descriptors of dimension 74 reduced to 38 after compression. In both systems, the GMM used to estimate the probability distribution of the features learns a codebook of 128 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Fusion methods</head><p>Combining multiple classifiers or even multiple results (i.e. several images of a single observation) from a single classifier is a way to increase the classification quality. This section presents three main approaches we used to merge the various results from our classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Max and Borda</head><p>Maximum and Borda Count are two approaches used to merge top-k lists. While the maximum relies on the score of each class with the lists, Borda Count uses their rank.</p><p>More precisely, the maximum based approach associates to each class the maximum score it reaches among the different lists. In the Borda Count approach, we have associated each class within a list to a score decreasing while the rank increases. In more details, since we only retrieve the top-K most likely classes, the score of a given species s is computed as follows:</p><formula xml:id="formula_2" coords="6,253.89,626.63,226.71,20.06">score(s) = c∈C K -r c (s)<label>(1)</label></formula><p>where r c (s) is the ranking of species s returned by the classifier c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bayesian inference</head><p>Framework presentation This fusion method is inspired by what is done in crowdsourcing multi-labeled classification tasks <ref type="bibr" coords="7,359.59,155.00,15.50,8.74" target="#b19">[21,</ref><ref type="bibr" coords="7,375.09,155.00,11.62,8.74" target="#b30">32]</ref>. For this purpose we used the Bayesian inference framework described in Figure <ref type="figure" coords="7,394.37,166.96,3.87,8.74" target="#fig_0">1</ref>. In such inference framework, we are given a set of classifiers k ∈ 1, ..., K and a confusion matrix π (k) is assigned to each one of them. Such matrix enables to evaluate the classification quality of each classifier. In a more precise way, π (k) i,j refers to the probability that the classifier k, given an image, will answer class j while the right class is i. The set of all confusion matrices is noted Π. Notice that, as presented in Figure <ref type="figure" coords="7,257.10,443.96,3.87,8.74" target="#fig_0">1</ref>, the confusion matrix π (k) is directly derived from the parameters matrix α (k) . The set of all parameters matrices is noted A. In parallel, each observation (i.e. set of images corresponding to a single plant) is associated to a distribution probability, noted t i for the i th observation. This probability depends on the proportion of each species in the database, and we note κ the vector referring to this proportion. Finally, based on the probabilities t i and on the confusion matrix of a given classifier k, we can infer the probability of the classifier's answer for the i th observation, noted c (k) i . Therefore, the joint probability of this Bayesian framework follows Equation 2.</p><formula xml:id="formula_3" coords="7,238.90,210.19,126.49,119.47">! ( k ) " (k) # t i c i (k) k = 1, …, K i = 1, …, N</formula><formula xml:id="formula_4" coords="7,215.20,565.05,265.39,30.55">p(Π, t, c|A, κ) = N i=1 {κ ti K k=1 π (k) ti,c (k) i }p(Π|A)<label>(2)</label></formula><p>Once the classifiers answers (i.e. the set of answers c</p><formula xml:id="formula_5" coords="7,376.76,605.16,10.63,14.07">(k) i</formula><p>for all k and i) are known, the probabilities of A, Π, κ and t can be updated, thus inferring the correct class of each observation (i.e. the one with the highest probability in t i ). In the following, we suppose κ known thanks to the very large size of the training set.</p><p>Addressing the large dimensionality Generally, in the state of the art solutions, several approaches are proposed to compute the posterior probabilities such as Gibbs sampling <ref type="bibr" coords="8,237.71,142.90,15.50,8.74" target="#b19">[21]</ref> or Variational Bayes <ref type="bibr" coords="8,345.87,142.90,14.61,8.74" target="#b30">[32]</ref>. In our experiments we had to face the very large dimension of the problem: each confusion matrix being of size 1000 × 1000. Classical method are therefore intractable in our context. To address this challenge, we used a single-shot approach: only p(t i = j|rest) is computed and used to update A and π -recall that κ is known and does not need to be updated. Thus, the confusion matrix of each classifier evolves while the number of identifications increases and the quality of inference is refined and more.</p><p>Experiments Setup In this subsection, we present three aspects of the setup: parameters initialization, parameters refinement and classifier's confusion refinement.</p><p>An important part of the fusion is to learn the confusion matrix (and its parameters). To do so, we have initialized each parameters matrix A with a value of S in the diagonal and S/(dimension -1) in the other cells, meaning that there is a 50% probability that the classifier will be correct and that given the correct class and a wrong one, it is more likely that the classifier will return the correct one. In our experiments the value of S has been fixed to 5 (best choice among several runs).</p><p>Then, we tried to enhance the confusion matrix quality based on the training data. For each image of the set, we asked the classifiers to re-propose a top-30 classification, and, given the correct class i, we have added in each cell a i,j of the matrices A a value inversely proportional to the species rank in the top-30:</p><formula xml:id="formula_6" coords="8,135.96,420.78,21.53,13.47">1 rank .</formula><p>Finally, to be as fine-grained as possible, each classifier was associated to several confusion matrices corresponding to each plants organs. Thus, the system knows the confusion of each classifier for all possible organs. In a way, we consider each couple {organ, classif ier} as a single classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Official Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Runs details</head><p>3 runs were finally submitted to the LifeCLEF 2015 plant challenge:</p><p>-INRIA Zenith Run 1 is based on the results provided by the single Convolutionnal Neural Network finetuned using all provided data (CNN1), and described in 3.1. Observations composed of several images, are combined using a Max function to provide Observation Results. -INRIA Zenith Run 2 is based on Fisher Vectors described in 3.2. To obtain Observation Results we used the Borda Count Algorithm. -INRIA Zenith Run 3 is the combination of the results obtained by previous methods (CNN and Fisher Vectors) using the Bayesian inference method described in 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Table <ref type="table" coords="9,161.86,138.71,4.98,8.74" target="#tab_1">2</ref> summarizes the scores of the 11 best submitted runs out of a total of 18 runs. Figure <ref type="figure" coords="9,191.18,150.67,4.98,8.74" target="#fig_1">2</ref> gives a complementary graphical overview of all results obtained by the participants. If we compare the best runs of each team, the INRIA Zenith Run 1, the one using CNN, is ranked 3rd regarding to observation results. We can note that all the 4 best teams used Deep Neural Networks. Our second run, INRIA Zenith Run 2, the one using Fisher Vectors, is disappointingly distanced by the CNN runs: its final score is two times lower (0.3 instead of 0.609 for INRIA Zenith Run 1 ). In LifeCLEF 2014, the best performances were obtained by Fisher Vectors, but the use of external training data was not allowed which explains why CNN were not performing better. Our final run, INRIA Zenith Run 3, is the Bayesian inference fusion method using previous runs. It was made in order to benefit from both technologies. Unfortunately, the results obtained are a little bit lower than the standalone CNN of INRIA Zenith Run 1 (0.592 instead of 0.609). Two main reasons can be highlighted to explain this quality loss. First, the two classifiers are not necessarily independent, thus, there combination does not enable to obtain quality gain. Second, building a confusion matrix for such high dimension problems (i.e. 1000 × 1000) is very challenging and the size of the test set is not enough to learn an accurate confusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Inria Zenith team submitted 3 runs, using different strategies. The first run was based on the well-known GoogLeNet CNN architecture, finetuned over Imagenet dataset, and using a max method to fuse image results to observation results. Our second run did not used external data, and was based on fisher vectors which    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,163.46,346.54,288.43,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A Bayesian network to merge multiple classifiers identifications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,263.21,308.40,88.94,7.89;10,160.71,115.83,290.88,177.79"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Official results</figDesc><graphic coords="10,160.71,115.83,290.88,177.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,134.77,444.53,227.28,10.52"><head>7</head><label></label><figDesc>Appendix: Complementary Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,134.77,582.65,345.83,7.89;11,134.77,593.64,133.62,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Distribution of the top 1 probabilities returned by the CNN and the Fisher Vectors with Logistic Regression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,193.46,337.88,228.43,62.73"><head>Table 1 .</head><label>1</label><figDesc>Various approaches using CNNs.</figDesc><table coords="4,193.46,358.65,228.43,41.96"><row><cell>Name</cell><cell># CNNs</cell><cell>Data Augmentation</cell></row><row><cell cols="2">CNN1 1 CNN with all images</cell><cell>No</cell></row><row><cell cols="2">CNN2 1 CNN with all images</cell><cell>Yes</cell></row><row><cell cols="2">CNN3 7 CNNs (1 for each view)</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,199.38,194.01,216.60,151.85"><head>Table 2 .</head><label>2</label><figDesc>PlantCLEF 2015 scores of the 11 best runs.</figDesc><table coords="9,242.41,213.04,130.55,132.82"><row><cell>Name</cell><cell>Score</cell></row><row><cell cols="2">SNUMED INFO run4 0.667</cell></row><row><cell cols="2">SNUMED INFO run3 0.663</cell></row><row><cell>QUT RV run2</cell><cell>0.633</cell></row><row><cell>QUT RV run3</cell><cell>0.624</cell></row><row><cell cols="2">SNUMED INFO run2 0.611</cell></row><row><cell cols="2">INRIA ZENITH run1 0.609</cell></row><row><cell cols="2">SNUMED INFO run1 0.604</cell></row><row><cell cols="2">INRIA ZENITH run3 0.592</cell></row><row><cell>QUT RV run1</cell><cell>0.563</cell></row><row><cell>ECOUAN run1</cell><cell>0.487</cell></row><row><cell cols="2">INRIA ZENITH run2 0.300</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,228.41,489.92,157.91,62.73"><head>Table 3 .</head><label>3</label><figDesc>Results for individual images</figDesc><table coords="10,228.41,510.69,155.47,41.96"><row><cell>Methods</cell><cell>Score</cell></row><row><cell cols="2">FV (color + basic texture) 0.184</cell></row><row><cell>FV (SIFT)</cell><cell>0.267</cell></row><row><cell>CNN</cell><cell>0.581</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,136.56,177.33,338.07,389.87"><head>Table 4 .</head><label>4</label><figDesc>Fusion results for observations</figDesc><table coords="11,136.56,196.36,338.07,64.98"><row><cell>Descriptors</cell><cell>Maximum</cell><cell>Borda</cell><cell>Bayesian</cell></row><row><cell>FV (color + basic texture)</cell><cell>0.196</cell><cell>0.197</cell><cell>0.186</cell></row><row><cell>FV (SIFT)</cell><cell>0.286</cell><cell>0.283</cell><cell>0.259</cell></row><row><cell>FV (color + basic texture + SIFT)</cell><cell>0.285</cell><cell>0.300</cell><cell>0.293</cell></row><row><cell>CNN</cell><cell>0.609</cell><cell>0.607</cell><cell>0.598</cell></row><row><cell>Global fusion</cell><cell>0.599</cell><cell>0.487</cell><cell>0.592</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="1,144.73,656.80,85.04,7.86"><p>http://leafsnap.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,656.80,120.33,7.86"><p>http://www.clef-initiative.eu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,623.92,337.64,7.86;10,151.52,634.88,329.07,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,43.91,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,333.77,623.92,146.82,7.86;10,151.52,634.88,141.77,7.86">Sensor network for the monitoring of ecosystem: Bird species recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,315.16,634.88,165.44,7.86;10,151.52,645.84,46.01,7.86;10,231.50,645.84,191.14,7.86">Intelligent Sensors, Sensor Networks and Information</title>
		<imprint>
			<date type="published" when="2007-12">2007. Dec 2007</date>
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
	<note>ISSNIP 2007. 3rd International Conference on</note>
</biblStruct>

<biblStruct coords="12,142.96,119.67,337.63,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,329.07,8.11;12,151.52,153.20,156.34,7.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,360.80,119.67,119.79,7.86;12,151.52,130.63,185.13,7.86">A Parametric Active Polygon for Leaf Segmentation and Shape Estimation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tougne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coquin</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-00622269" />
	</analytic>
	<monogr>
		<title level="m" coord="12,360.15,130.63,120.44,7.86;12,151.52,141.59,85.40,7.86">7th International Symposium on Visual Computing</title>
		<meeting><address><addrLine>Las Vegas, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep 2011</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,164.25,337.64,7.86;12,151.52,175.21,329.07,7.86;12,151.52,186.17,73.78,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="12,416.05,175.21,64.54,7.86;12,151.52,186.17,45.11,7.86">Next-generation field guides</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Farnsworth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">D</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Courtney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">K</forename><surname>Vandyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,197.87,337.64,7.86;12,151.52,208.82,329.07,7.86;12,151.52,219.78,25.60,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,390.63,197.87,89.96,7.86;12,151.52,208.82,97.09,7.86">Liblinear: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,254.80,208.82,171.89,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,231.48,337.63,7.86;12,151.52,242.44,329.07,7.86;12,151.52,253.40,60.92,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,265.15,231.48,170.59,7.86">Automated species identification: why not?</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">J</forename><surname>Gaston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,437.92,231.48,42.67,7.86;12,151.52,242.44,284.26,7.86">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">1444</biblScope>
			<biblScope unit="page" from="655" to="667" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,265.10,337.64,7.86;12,151.52,276.06,329.07,7.86;12,151.52,287.02,96.76,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,455.20,265.10,25.39,7.86;12,151.52,276.06,234.72,7.86">Visual word ambiguity. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,392.52,276.06,88.07,7.86">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1271" to="1283" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,298.72,337.64,7.86;12,151.52,309.67,329.07,7.86;12,151.52,320.63,329.07,7.86;12,151.52,331.59,80.63,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,315.77,309.67,164.82,7.86;12,151.52,320.63,48.56,7.86">Pl@ ntnet mobile 2014: Android port and new features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vignau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,219.58,320.63,257.13,7.86">Proceedings of International Conference on Multimedia Retrieval</title>
		<meeting>International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">527</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,343.29,337.63,7.86;12,151.52,354.25,329.07,7.86;12,151.52,365.21,328.53,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,319.14,354.25,80.86,7.86">Plantnet mobile app</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,421.85,354.25,58.74,7.86;12,151.52,365.21,216.84,7.86">Proceedings of the 21st ACM international conference on Multimedia</title>
		<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="423" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,376.91,337.64,7.86;12,151.52,387.87,106.05,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,284.89,376.91,149.03,7.86">Lifeclef plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,455.89,376.91,24.70,7.86;12,151.52,387.87,55.88,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,399.56,337.98,7.86;12,151.52,410.52,329.07,7.86;12,151.52,421.48,329.07,8.11;12,151.52,433.09,71.10,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,429.55,399.56,51.05,7.86;12,151.52,410.52,202.02,7.86">Visual-based plant species identification from crowdsourced data</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Joyeux</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00642236" />
	</analytic>
	<monogr>
		<title level="m" coord="12,373.50,410.52,107.09,7.86">MM&apos;11 -ACM Multimedia</title>
		<meeting><address><addrLine>Scottsdale, United States</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-11">2011. Nov 2011</date>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,444.14,337.97,7.86;12,151.52,455.10,303.21,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,370.74,444.14,109.85,7.86;12,151.52,455.10,114.09,7.86">Revisiting the fisher vector for fine-grained classification</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">H</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,272.24,455.10,112.87,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="92" to="98" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,466.80,337.97,7.86;12,151.52,477.76,329.07,8.12;12,151.52,489.36,81.52,7.47" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,290.05,466.80,186.25,7.86">An interactive flower image recognition system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11042-010-0490-6</idno>
		<ptr target="http://dx.doi.org/10.1007/s11042-010-0490-6" />
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,477.76,97.05,7.86">Multimedia Tools Appl</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="73" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,500.41,337.98,7.86;12,151.52,511.37,329.07,7.86;12,151.52,522.33,122.92,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,314.55,500.41,166.05,7.86;12,151.52,511.37,82.10,7.86">Feature coding in image classification: A comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,241.19,511.37,239.40,7.86;12,151.52,522.33,32.31,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="506" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="12,142.62,534.03,337.97,7.86;12,151.52,544.99,329.07,7.86;12,151.52,555.95,240.12,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,453.69,534.03,26.89,7.86;12,151.52,544.99,199.40,7.86">Aggregating local image descriptors into compact codes</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,358.10,544.99,122.50,7.86;12,151.52,555.95,140.28,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1704" to="1716" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="12,142.62,567.65,337.97,7.86;12,151.52,578.61,329.07,7.86;12,151.52,589.56,154.44,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="12,237.79,578.61,238.19,7.86">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.62,601.26,337.98,7.86;12,151.52,612.22,329.07,7.86;12,151.52,623.18,296.25,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,290.74,601.26,189.86,7.86;12,151.52,612.22,159.08,7.86">Towards optimal bag-of-features for object categorization and semantic video retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">W</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,331.04,612.22,149.55,7.86;12,151.52,623.18,185.44,7.86">Proceedings of the 6th ACM international conference on Image and video retrieval</title>
		<meeting>the 6th ACM international conference on Image and video retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="494" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,634.88,337.97,7.86;12,151.52,645.84,329.07,7.86;12,151.52,656.80,209.08,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,298.24,645.84,182.35,7.86;12,151.52,656.80,43.01,7.86">Interactive plant identification based on social image data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,201.70,656.80,89.28,7.86">Ecological Informatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="22" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,119.67,337.97,7.86;13,151.52,130.63,329.07,7.86;13,151.52,141.59,329.07,7.86;13,151.52,152.55,262.19,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,359.77,130.63,120.82,7.86;13,151.52,141.59,125.40,7.86">Lifeclef 2014: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,298.32,141.59,182.28,7.86;13,151.52,152.55,138.98,7.86">Information Access Evaluation. Multilinguality, Multimodality, and Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="229" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,163.52,337.97,7.86;13,151.52,174.48,329.07,7.86;13,151.52,185.44,40.24,7.86;13,134.77,196.40,345.83,7.86;13,151.52,207.36,329.07,8.11;13,151.52,218.97,98.85,7.47" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,276.16,174.48,204.44,7.86;13,151.52,185.44,40.24,7.86;13,134.77,196.40,7.85,7.86;13,304.35,196.40,176.24,7.86;13,151.52,207.36,63.18,7.86">Lifeclef 2015: multimedia life species identification challenges 20</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kebapci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Unal</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/bxq037</idno>
		<ptr target="http://dx.doi.org/10.1093/comjnl/bxq037" />
	</analytic>
	<monogr>
		<title level="j" coord="13,222.38,207.36,46.50,7.86">Comput. J</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1475" to="1490" />
			<date type="published" when="2011-09">Sep 2011</date>
		</imprint>
	</monogr>
	<note>Plant image retrieval using color, shape and texture features</note>
</biblStruct>

<biblStruct coords="13,142.62,229.29,337.98,7.86;13,151.52,240.25,263.87,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,266.41,229.29,122.11,7.86">Bayesian classifier combination</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,408.92,229.29,71.67,7.86;13,151.52,240.25,180.55,7.86">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="619" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,251.22,337.98,7.86;13,151.52,262.18,329.07,7.86;13,151.52,273.14,86.01,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,328.09,251.22,152.50,7.86;13,151.52,262.18,103.94,7.86">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,275.64,262.18,200.74,7.86">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,284.10,337.98,7.86;13,151.52,295.06,329.07,7.86;13,151.52,306.02,298.98,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,204.15,295.06,276.44,7.86;13,151.52,306.02,34.91,7.86">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">V</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,207.07,306.02,119.90,7.86">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="502" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,316.99,337.98,7.86;13,151.52,327.95,329.07,7.86;13,151.52,338.91,329.07,7.86;13,151.52,349.87,50.81,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,307.33,316.99,173.27,7.86;13,151.52,327.95,192.32,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.91,327.95,117.68,7.86;13,151.52,338.91,46.11,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,360.83,337.98,7.86;13,151.52,371.79,329.07,7.86;13,151.52,382.75,329.07,7.86;13,151.52,393.71,259.38,8.12" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,343.84,360.83,136.76,7.86;13,151.52,371.79,182.93,7.86">Advanced shape context for plant species identification using leaf image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mouine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Verroust-Blondet</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00726785" />
	</analytic>
	<monogr>
		<title level="m" coord="13,455.38,371.79,25.21,7.86;13,151.52,382.75,271.50,7.86">ICMR &apos;12 -2nd ACM International Conference on Multimedia Retrieval</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</editor>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-06">Jun 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,404.68,337.97,7.86;13,151.52,415.64,329.07,7.86;13,151.52,426.60,211.09,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,275.31,404.68,205.28,7.86;13,151.52,415.64,36.57,7.86">Automated flower classification over a large number of classes</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,210.55,415.64,185.38,7.86;13,428.86,415.64,51.72,7.86;13,151.52,426.60,97.56,7.86">Computer Vision, Graphics Image Processing</title>
		<imprint>
			<date type="published" when="2008-12">2008. Dec 2008</date>
			<biblScope unit="page" from="722" to="729" />
		</imprint>
	</monogr>
	<note>ICVGIP &apos;08. Sixth Indian Conference</note>
</biblStruct>

<biblStruct coords="13,142.62,437.56,337.98,7.86;13,151.52,448.52,329.07,7.86;13,151.52,459.48,148.89,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="13,261.41,437.56,219.18,7.86;13,151.52,448.52,38.65,7.86">Fisher kernels on visual vocabularies for image categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,211.67,448.52,170.70,7.86;13,414.18,448.52,66.41,7.86;13,151.52,459.48,44.32,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR&apos;07. IEEE Conference</note>
</biblStruct>

<biblStruct coords="13,142.62,470.45,337.97,7.86;13,151.52,481.41,329.07,7.86;13,151.52,492.37,25.60,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="13,324.74,470.45,155.85,7.86;13,151.52,481.41,97.40,7.86">Improving the fisher kernel for largescale image classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,268.54,481.41,118.81,7.86">Computer Vision-ECCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,503.34,337.97,7.86;13,151.52,514.30,329.07,7.86;13,151.52,525.25,329.07,7.86;13,151.52,536.21,50.81,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="13,394.77,503.34,85.82,7.86;13,151.52,514.30,267.89,7.86">Lost in quantization: Improving particular object retrieval in large scale image databases</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,440.12,514.30,40.47,7.86;13,151.52,525.25,125.53,7.86;13,307.93,525.25,122.63,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference</note>
</biblStruct>

<biblStruct coords="13,142.62,547.18,337.98,7.86;13,151.52,558.14,329.07,7.86;13,151.52,569.10,60.92,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,365.92,547.18,114.67,7.86;13,151.52,558.14,132.92,7.86">Image classification with the fisher vector: Theory and practice</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,290.73,558.14,159.24,7.86">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="222" to="245" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,580.07,337.98,7.86;13,151.52,591.03,329.07,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="13,330.38,580.07,150.21,7.86;13,151.52,591.03,75.60,7.86">Deep Fisher networks for large-scale image classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,246.20,591.03,206.54,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,601.99,337.97,7.86;13,151.52,612.95,329.07,7.86;13,151.52,623.91,94.57,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="13,361.41,601.99,119.18,7.86;13,151.52,612.95,141.92,7.86">Dynamic Bayesian Combination of Multiple Imperfect Classiers</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Psorakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,314.26,612.95,166.34,7.86;13,151.52,623.91,65.91,7.86">Decision Making with Imperfect Decision Makers Springer</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,634.88,337.97,7.86;13,151.52,645.84,329.07,7.86;13,151.52,656.80,176.52,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="13,250.78,634.88,229.81,7.86;13,151.52,645.84,50.13,7.86">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,223.21,645.84,67.75,7.86;13,322.58,645.84,158.02,7.86;13,151.52,656.80,44.32,7.86">Proceedings. Ninth IEEE International Conference</title>
		<meeting>Ninth IEEE International Conference</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct coords="14,142.62,119.67,337.98,7.86;14,151.52,130.63,329.07,7.86;14,151.52,141.59,113.40,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="14,357.33,119.67,123.27,7.86;14,151.52,130.63,32.39,7.86">Multimedia analysis for ecological data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mezaris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Van Ossenbruggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,203.36,130.63,272.79,7.86">Proceedings of the 20th ACM international conference on Multimedia</title>
		<meeting>the 20th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1507" to="1508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,152.55,337.98,7.86;14,151.52,163.51,329.07,7.86;14,151.52,174.47,172.45,8.12" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="14,263.85,163.51,125.06,7.86">Going deeper with convolutions</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno>CoRR abs/1409.4842</idno>
		<ptr target="http://arxiv.org/abs/1409.4842" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,185.43,337.98,7.86;14,151.52,196.39,329.07,7.86;14,151.52,207.34,185.41,7.86" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="14,379.40,185.43,101.19,7.86;14,151.52,196.39,281.31,7.86">Automated species recognition of antbirds in a Mexican rainforest using hidden Markov models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Trifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N G</forename><surname>Kirschel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">E</forename><surname>Vallejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,440.01,196.39,40.58,7.86;14,151.52,207.34,139.85,7.86">Journal of The Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,218.30,337.98,7.86;14,151.52,229.26,329.07,7.86;14,151.52,240.22,262.66,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="14,398.73,218.30,81.86,7.86;14,151.52,229.26,142.15,7.86">Locality-constrained linear coding for image classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,312.67,229.26,167.93,7.86;14,151.52,240.22,31.16,7.86">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="3360" to="3367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,251.18,337.97,7.86;14,151.52,262.14,329.07,7.86;14,151.52,273.10,301.06,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="14,320.27,251.18,160.32,7.86;14,151.52,262.14,148.56,7.86">Linear spatial pyramid matching using sparse coding for image classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,321.20,262.14,159.39,7.86;14,151.52,273.10,14.75,7.86;14,197.09,273.10,123.28,7.86">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1794" to="1801" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
