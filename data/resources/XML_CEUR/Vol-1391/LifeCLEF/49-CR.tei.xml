<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.52,116.95,318.31,12.62;1,203.20,134.89,208.95,12.62">Exploring the use of local descriptors for fish recognition in LifeCLEF 2015</title>
				<funder>
					<orgName type="full">Institute of Intelligent Systems and Numerical Applications in Engineering and the Computer Science Department at ULPGC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.59,172.56,92.63,8.74"><forename type="first">Jorge</forename><surname>Cabrera-Gámez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,236.62,172.56,119.98,8.74"><forename type="first">Modesto</forename><surname>Castrillón-Santana</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.33,172.56,110.61,8.74"><forename type="first">Antonio</forename><surname>Domínguez-Brito</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,145.03,184.51,98.38,8.74"><forename type="first">Daniel</forename><surname>Hernández-Sosa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.52,184.51,89.70,8.74"><forename type="first">Josep</forename><surname>Isern-González</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.38,184.51,101.95,8.74"><forename type="first">Javier</forename><surname>Lorenzo-Navarro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SIANI Universidad de Las Palmas de Gran Canaria</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.52,116.95,318.31,12.62;1,203.20,134.89,208.95,12.62">Exploring the use of local descriptors for fish recognition in LifeCLEF 2015</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DD298DDBFDC4BAC8E11C32AC18C35177</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Local descriptors</term>
					<term>score level fusion</term>
					<term>SVM based classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes the proposal made by the SIANI team for the LifeCLEF 2015 Fish task. The approach makes use of standard detection techniques, applying a multiclass SVM based classifier on large enough Regions Of Interest (ROIs) automatically extracted from the provided video frames. The selection of the detection and classification modules is based on the best performance achieved for the validation dataset consisting of 20 annotated videos. For that dataset, the best classification achieved for an ideal detection module, reaches an accuracy around 40%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There are different scenarios of application where underwater monitoring is a required ability such as biological, fisheries, geological and physical surveys. The everyday larger availability of media captured in this environment poses the challenge to extract useful data automatically. This is indeed a hard scenario where effective techniques are needed to reduce costs and human exposition.</p><p>With this aim, CLEF presented in 2014 for the first time LifeCLEF: the Labs dedicated to multimedia life species identification <ref type="bibr" coords="1,357.38,525.61,14.61,8.74" target="#b9">[10]</ref>, including FishCLEF: a video-based fish identification task. The short term goal was simply to automatically detect any fish and its species. The medium term goal is to provide researchers tools to automatically monitor species with high accuracy, in order to extract information of living species for a sustainable development and biodiversity conservation.</p><p>This year the Labs <ref type="bibr" coords="1,234.49,597.34,10.52,8.74" target="#b2">[3]</ref> and task have been reedited <ref type="bibr" coords="1,372.67,597.34,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="1,389.83,597.34,11.62,8.74" target="#b13">14]</ref>. The participants could initially access to training data, to later submit labels for the test set. The task to be accomplished was "count fish per species in video segments".</p><p>This paper describes the approach adopted by the SIANI team. The following sections detail the different elements integrated that basically perform initially a detection to later identify the fish species of the cropped image.</p><p>As succinctly mentioned above, the fish identification task has been decomposed into two phases: detection and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Detection</head><p>The goal of the detection phase is to reduce the searching area extracting candidate ROIs from the video stream. Three different foreground detection approaches have been tested: fast, histogram backprojection and Gaussian Mixture Modeling (GMM).</p><p>Fast. This approach makes use of a simple and fast background model computed from the video frames, that is robust enough for the detection and extraction problem in some scenarios. This background modeling solution takes advantage of the static camera configuration in this particular scenario.</p><p>To define the scene background model, bg, we have used a similar method to commonly-used techniques like mean filter or median filter <ref type="bibr" coords="2,404.98,336.61,14.61,8.74" target="#b12">[13]</ref>. We compute the mode image, I, that is calculated as the most frequent values in each RGB component of each pixel each pixel along the video frames.</p><p>Once the background model is available, simple and fast background subtraction techniques may be applied in each RGB component of the input image, I. The foreground is computed based on a defined threshold applied to the sum of squares of RGB components of the subtracted image (D R , D B , D G ) pixel value</p><formula xml:id="formula_0" coords="2,215.83,428.96,264.76,11.72">S(i, j) = D R (i, j) 2 + D G (i, j) 2 + D B (i, j) 2<label>(1)</label></formula><p>where D x = I x -bg x for every RGB component (x = R, G, B).</p><p>For a pixel in a given image, I(i, j), its corresponding pixel in the foreground image, f g, is computed as</p><formula xml:id="formula_1" coords="2,236.42,499.98,244.17,20.69">f g(i, j) = I(i, j) if S(i, j) ≥ τ 1 0 otherwise (2)</formula><p>The definition of the threshold (τ 1 ) in equation 2 has been determined by the application scenario. The extracted pixels are considered foreground, i.e. region of interest in the detection problem.</p><p>Histogram Backprojection (BackProj). The second detection method evaluated is inspired in the idea proposed in <ref type="bibr" coords="2,307.05,598.04,15.50,8.74" target="#b15">[16]</ref> that we have adapted to background segmentation. The method is based on the backprojection of temporal color histogram, and comprises the following steps:</p><p>1. Calculate for each color component the temporal histogram of every image pixel: h x = hist t (I x (i, j))</p><p>2. Add to each histogram bin, k, the values of its neighborhood, ±s, (convolution mask): c x (k) = k+s l=k-s (h x (l)) 3. Normalize the resulting histogram: h x (k) = c x (k)/max(c x ) 4. Backproject the histogram on every image: P x (i, j) = h x (I x (i, j)) 5. Sum the squares of values of each component of the pixels: S(i, j) = P R (i, j) 2 + P G (i, j) 2 + P B (i, j) 2 6. Use a threshold to separate the foreground of the background:</p><formula xml:id="formula_2" coords="3,244.89,216.96,235.71,20.69">f g(i, j) = I(i, j) if S(i, j) &lt; τ 2 0 otherwise<label>(3)</label></formula><p>Also in this case, the definition of the threshold (τ 2 ) in equation 3 has been determined by the application scenario.</p><p>GMM Based Background Modeling (GMM). The third background subtraction method analyzed is the one proposed by Zivkovic and van der Heijden <ref type="bibr" coords="3,153.70,317.79,14.61,8.74" target="#b19">[20]</ref>. This method performs a pixel-level background subtraction, modeling each background pixel with a GMM, extending the method proposed by Stauffer and Grimson <ref type="bibr" coords="3,194.70,341.70,14.61,8.74" target="#b14">[15]</ref>. Thus the background model is defined as:</p><formula xml:id="formula_3" coords="3,224.84,363.00,255.75,30.20">p(x|X T , bg) ≈ B m=1 πm N (x; μm , σ2 m Id)<label>(4)</label></formula><p>where X T = {x (t) , . . . , x (t-T ) } is the training set, for the time period T , μ1 , . . . , μB are the estimates of the means, σ1 , . . . , σB are the estimates of the variances, and Id is the identity matrix. B is the number of components weighted by πm . An optimization process was launched over the training videos to try to find a suitable configuration for the GMM foreground detection algorithm, including the number of distributions, the background ratio and the number of training frames and learning rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>Detected ROIs are fed to the detection phase to identify the fish species. The classification phase has been designed based on local descriptors, that are currently well known techniques in different Computer Vision (CV) problems.</p><p>In texture analysis, an image is described in terms of a local descriptor codes making use of a histogram, h i , where the bins contain the number of occurrences of the different descriptor codes present in the image. This approach follows a Bag of Words scheme <ref type="bibr" coords="3,230.91,597.20,9.96,8.74" target="#b5">[6]</ref>. For some problems, the use of a single histogram may introduce the loss of spatial information. To avoid this effect, a grid of cells is used defining the number of horizontal and vertical cells, respectively cx and cy, making a total of cx × cy cells on the analyzed pattern.</p><p>Once defined the grid setup, for a particular descriptor, d, the resulting feature vector, x d I , contains the concatenation of cx × cy cell histograms, i.e. the feature vector is defined as x d I = {h 1 , h 2 , ..., h cx×cy }, where h i is the descriptor histogram for cell i.</p><p>In this particular task, we have evaluated different descriptors and grid configurations. In this sense, we have considered the following 8 descriptors:</p><p>-Histogram of Oriented Gradients (HOG) <ref type="bibr" coords="4,332.75,178.15,9.96,8.74" target="#b6">[7]</ref>.</p><p>-Local Binary Patterns (LBP) and uniform Local Binary Patterns (LBP u2 ) <ref type="bibr" coords="4,469.14,190.17,9.96,8.74" target="#b0">[1]</ref>.</p><p>-Local Gradient Patterns (LGP) <ref type="bibr" coords="4,292.81,202.19,14.61,8.74" target="#b11">[12]</ref>.</p><p>-Local Ternary Patterns (LTP) <ref type="bibr" coords="4,287.17,214.21,14.61,8.74" target="#b16">[17]</ref>.</p><p>-Local Phase Quantization (LPQ) <ref type="bibr" coords="4,299.54,226.23,14.61,8.74" target="#b17">[18]</ref>.</p><p>-Weber Local Descriptor (WLD) <ref type="bibr" coords="4,293.82,238.25,9.96,8.74" target="#b4">[5]</ref>.</p><p>-Local Oriented Statistics Information Booster (LOSIB) <ref type="bibr" coords="4,396.05,250.27,9.96,8.74" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes the results obtained for the different fish identification task phases, highlighting those configurations that were submitted to the 2015 Lab focused on this particular problem <ref type="bibr" coords="4,308.34,330.60,14.61,8.74" target="#b13">[14]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>Before granting the access to the test data, the organizers provided two datasets, see Figure <ref type="figure" coords="4,181.69,537.44,3.87,8.74" target="#fig_0">1</ref>. Even though a better description of the data may be found in <ref type="bibr" coords="4,462.34,537.44,14.61,8.74" target="#b13">[14]</ref>, we summarize some relevant characteristics below.</p><p>The first dataset, that we call the training dataset, is a collection of cropped images of the different fish species. The second collection contains annotated videos, including media that may present a similar scenario to the test data. We called this collection the validation dataset.</p><p>This validation dataset is used in the following subsections to analyze the different detection and classification alternatives, providing a cue to decide the final system setup chosen for the Fish task submission. In fact, we used both training and validation datasets to select the classification approach, and the validation dataset, to select the detection technique and tune its parameters.</p><p>Briefly, the training set contains samples of the 15 different fish species, i.e. classes. The number of samples per species is indicated in Table <ref type="table" coords="5,421.17,131.95,3.87,8.74" target="#tab_0">1</ref>. The reader will observe that the different species are not equally represented through the dataset, circumstance that also is present in the validation and test sets. The average dimension in the training samples is 88 ± 38 × 102 ± 49 pixels. The validation dataset contains 9162 samples distributed per class according to the last column of Table <ref type="table" coords="5,258.67,456.86,3.87,8.74" target="#tab_0">1</ref>. The average dimension of those samples is 52 ± 37 × 56 ± 39 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Detection Results</head><p>As mentioned above, the annotated validation dataset videos were used to analyze the performance of different detection algorithms. The detection rates for the three implementations are shown in Table <ref type="table" coords="5,343.32,549.52,3.87,8.74" target="#tab_1">2</ref>, being computed as the total number of correct or positive detections divided by the number of annotations. The false detection rate presented is also the ratio between the number of unmatched or false detections and the number of annotations. This was done to have a clear evidence of the number of false detections in relation to the number of annotations. False detections do not necessarily mean a failure in the detection module, but that there is not annotation for that particular frame and ROI. Indeed, the annotations were done only when the fish species was clearly identifiable <ref type="bibr" coords="5,167.84,645.16,14.61,8.74" target="#b13">[14]</ref>. In this sense, we have made use of the minimal size for annotation, and applied a dimension filter to remove small detected ROIs.</p><p>A positive detection is considered when there is a significant intersection between a given detection container, B and an annotation container, A. As confidence measure, we employed the Jaccard Index, JI. This index relates the intersection of both containers with their union, JI = A∩B A∪B , providing a value between 0 and 1, larger values meaning better matching. For the analysis summarized in Table <ref type="table" coords="6,211.46,179.77,3.87,8.74" target="#tab_1">2</ref>, we have considered 0.4 and 0.5 threshold values. The high variability of the video segments made extremely difficult to obtain a good tuning of the algorithm parameters. As a consequence, simple approaches yielded better results both in execution time and detection. Indeed, among the techniques analyzed, both Fast and BackProj algorithms provided not brilliant but acceptable detection rates. Fast was chosen with different tuning parameters to setup run1, while BackProj was used for the other two submitted runs (run2 and run3 ). The detection approach is later combined with the classifier providing the best performance in the validation dataset classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Classification Results</head><p>The detection rates achieved, described in the previous section, allowed us to explore our model based approach on the dataset. Certainly, a model approach is not a priori the best solution for the unbalanced classification task, but being newcomers, we were interested in applying our experience in other CV problems to evaluate local descriptors in this scenario.</p><p>The analysis described in this section presents results in two steps. Firstly, the study evaluates different descriptors with the training set, i.e. the collection of cropped images, see Table <ref type="table" coords="6,259.94,548.88,3.87,8.74" target="#tab_0">1</ref>. Secondly, the best descriptors are later evaluated with the validation dataset, to adopt the most promising configuration for the test set.</p><p>Table <ref type="table" coords="6,176.68,585.38,4.98,8.74" target="#tab_2">3</ref> summarizes the results for different local descriptors in a 5-fold cross validation experiment defined on the provided training dataset, considering a single multi-class SVM based classifier. This kind of approach has already been applied for the task <ref type="bibr" coords="6,227.00,621.25,9.96,8.74" target="#b1">[2]</ref>. Each descriptor is evaluated for different grid configurations in the ranges cx ∈ <ref type="bibr" coords="6,261.38,633.20,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="6,273.55,633.20,7.75,8.74" target="#b3">4]</ref> and cy ∈ <ref type="bibr" coords="6,329.90,633.20,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="6,342.08,633.20,7.01,8.74" target="#b3">4]</ref>. Unfortunately, for the given deadline (its extension was not evident), we could not manage to evaluate all the grid configurations with dimensions larger than 3 × 3. With the exception of WLD, the whole collection of descriptors reported a high accuracy at least for a particular grid setup. However, this was not the case in the following analysis on the annotated ROIs extracted from the validation dataset, as summarized in Table <ref type="table" coords="7,300.41,316.57,3.87,8.74" target="#tab_3">4</ref>. It seems, that the grid configuration is important for some descriptors. A larger number of cells is preferred for HOG, LBP u2 , LGP and LOSIB, while other descriptors such as LBP, LTP and LPQ provide better results with a lower number of cells. Again, WLD is not providing useful classification results. Considering the vital importance of combining several descriptors <ref type="bibr" coords="7,435.84,561.47,14.61,8.74" target="#b18">[19]</ref>, a further evaluation of a fusion approach was considered. According to the score level (SL) fusion literature and previous results in the context of facial processing <ref type="bibr" coords="7,470.09,585.38,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="7,134.77,597.34,7.01,8.74" target="#b8">9]</ref>, we adopted a score level fusion approach where the first layer is composed by a set of classifiers designed according to the chosen descriptors, while the second layer classifier takes the first layer scores as input. In summary, the fusion alternatives analyzed below follow the approach outlined in Figure <ref type="figure" coords="7,428.67,633.20,3.87,8.74" target="#fig_1">2</ref>.</p><p>Table <ref type="table" coords="7,176.61,645.16,4.98,8.74" target="#tab_4">5</ref> summarizes the results achieved for different fusion alternatives. The selection of descriptors and grids are based on the single descriptors results achieved for the validation dataset, see again Table <ref type="table" coords="8,354.77,336.33,3.87,8.74" target="#tab_3">4</ref>. This table does not include results with 4 × 4 grids, as they were not available in time for the deadline.</p><p>The first three alternatives combine the best descriptors for a given grid resolution; the higher the resolution, the better the accuracy. However, there is no real restriction to make use of a unique grid resolution. For that reason we also evaluated the fusion of the best descriptors with different grid resolutions, achieving the best overall accuracy with a RBF kernel using the first 90 PCA components.</p><p>For each combination, the selected descriptors and grid setups are indicated, reporting the results using SVM based classifiers, including linear and RBF kernels, with and without a previous dimensionality reduction by means of a Principal Component Analysis (PCA).</p><p>The best performing classifier, the fourth combination using RBF kernel with a PCA based features, is used in combination with the selected detection approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion</head><p>As mentioned above, our team submitted three runs. They all made use of an identical second phase based on a two stages classifier. The selected descriptors combination is the one highlighted in Table <ref type="table" coords="8,321.15,584.81,3.87,8.74" target="#tab_4">5</ref>. This score fusion selection contains six single descriptor classifiers in the first stage: LTP 1×1 , LPQ 1×1 , HOG 3×3 , LBP u2 3×3 , LGP 3×3 and LOSIB 3×3 . The second stage makes use of the classifiers scores, that are projected into a PCA space.</p><p>Each run differs in its detection phase. Our first run made use of the Fast detection algorithm, while the other two integrate the BackProj detector with different parameters setup. The normalized counting scores of the referred runs in the overall Lab analysis are reported in Figure <ref type="figure" coords="9,252.14,375.22,3.87,8.74" target="#fig_2">3</ref>. Two teams are over 50%, followed at a remarkable distance by the best runs of other two teams, including our run3, achieving over 30%. Our main focus was on the classification phase, that has provided unbalanced results for different classes, likely due to the non homogeneous number of training samples per class. A focus based exclusively on the fusion of local descriptors seems not to be reliable enough for the problem. However, the detection phase requires further attention as a larger number of proper detections would improve the overall score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>This document describes the model based approach submitted to the LifeCLEF 2015 Fish task by the SIANI team. The proposal explores the use of local descriptors for this problem. We employed standard detection techniques to later apply an ensemble of SVM multiclass classifiers.</p><p>Three runs were submitted with identical classification stage. One is based on the Fast detection algorithm, while the other two are based on the BackProj algorithm.</p><p>The best accuracy achieved for the ideal annotated containers reaches 40%, suggesting that the approach is still far from being reliable in this scenario. In the close future, our aim is on the one side at improving detection, that might be combined with tracking. On the other side, once we have observed the problems originated in the multiclass classification of an unbalanced dataset, and apart from computing more dense grids, we should explore the combination with other techniques to leverage the classification stage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,442.73,345.81,7.89;4,134.77,453.72,219.22,7.86;4,179.22,362.70,84.00,69.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. From left to right, a training sample, and two validation samples of Abudefduf vaigiensis. They are presented in similar relative scale.</figDesc><graphic coords="4,179.22,362.70,84.00,69.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,152.06,281.29,311.24,7.89;8,152.06,292.27,311.24,7.86;8,159.84,116.83,295.68,149.69"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of two stage classification fusion architecture, with n classifiers in the first stage whose scores are fed into a second stage meta classifier.</figDesc><graphic coords="8,159.84,116.83,295.68,149.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,146.62,294.56,319.04,7.89;10,158.88,116.83,297.60,162.96"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Normalized counting score of the participant runs. Extracted from [14].</figDesc><graphic coords="10,158.88,116.83,297.60,162.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,149.65,200.70,316.04,215.36"><head>Table 1 .</head><label>1</label><figDesc>Number of samples per class in the training and validation datasets.</figDesc><table coords="5,185.40,221.10,241.48,194.96"><row><cell></cell><cell cols="2">Number of instances per dataset</cell></row><row><cell>Fish type</cell><cell>Training</cell><cell>Validation</cell></row><row><cell>Abudefduf vaigiensis</cell><cell>305</cell><cell>132</cell></row><row><cell>Acanthurus nigrofuscus</cell><cell>2511</cell><cell>294</cell></row><row><cell>Amphiprion clarkii</cell><cell>2985</cell><cell>363</cell></row><row><cell>Chaetodon lunulatus</cell><cell>2494</cell><cell>1217</cell></row><row><cell>Chaetodon speculum</cell><cell>24</cell><cell>138</cell></row><row><cell>Chaetodon trifascialis</cell><cell>375</cell><cell>335</cell></row><row><cell>Chromis chrysura</cell><cell>3593</cell><cell>275</cell></row><row><cell>Dascyllus aruanus</cell><cell>904</cell><cell>894</cell></row><row><cell>Dascyllus reticulatus</cell><cell>3196</cell><cell>3165</cell></row><row><cell>Hemigymnus melapterus</cell><cell>147</cell><cell>214</cell></row><row><cell>Myripristis kuntee</cell><cell>3004</cell><cell>242</cell></row><row><cell>Neoglyphidodon nigroris</cell><cell>129</cell><cell>85</cell></row><row><cell>Pempheris Vanicolensis</cell><cell>49</cell><cell>999</cell></row><row><cell cols="2">Plectrogly-Phidodon dickii 2456</cell><cell>737</cell></row><row><cell>Zebrasoma scopas</cell><cell>271</cell><cell>72</cell></row><row><cell>Total</cell><cell>22443</cell><cell>9162</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,212.53,345.82,83.46"><head>Table 2 .</head><label>2</label><figDesc>Detection rates considering different detection techniques and JI thresholds.</figDesc><table coords="6,212.77,232.93,186.73,63.06"><row><cell cols="3">Detection Detection rate (false detection rate)</cell></row><row><cell cols="2">algorithm JI=0.5</cell><cell>JI=0.4</cell></row><row><cell cols="2">Fast I 0.80(4.60)</cell><cell>0.85(4.55)</cell></row><row><cell cols="2">Fast II 0.74(3.74)</cell><cell>0.80(3.67)</cell></row><row><cell cols="2">BackProj 0.82(2.77)</cell><cell>0.88(2.49)</cell></row><row><cell>GMM</cell><cell>-</cell><cell>0.40(2.49)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,116.91,345.81,136.51"><head>Table 3 .</head><label>3</label><figDesc>Mean accuracy achieved in a 5-fold cross validation experiment on the training dataset. The cell color serves to cluster accuracies.</figDesc><table coords="7,235.62,146.52,141.05,106.89"><row><cell>Descriptor</cell><cell>Grid setup 1 × 1 2 × 2 3 × 3 4 × 4</cell></row><row><cell>HOG</cell><cell>54.69 87.71 95.66 97.50</cell></row><row><cell cols="2">LBPu2 77.79 94.11 96.72 96.88</cell></row><row><cell>LBP</cell><cell>88.20 91.62 85.98 65.58</cell></row><row><cell>LGP</cell><cell>61.57 84.00 92.06 95.13</cell></row><row><cell>LTP</cell><cell>89.90 86.18 34.91 26.60</cell></row><row><cell>LPQ</cell><cell>90.74 95.70 88.73 53.87</cell></row><row><cell cols="2">WLD 16.01 16.01 15.92 13.30</cell></row><row><cell cols="2">LOSIB 40.32 73.13 87.63 92.28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,393.90,345.81,138.25"><head>Table 4 .</head><label>4</label><figDesc>Accuracy achieved with a single descriptor training with the training dataset and testing with the extracted annotated samples on validation dataset.</figDesc><table coords="7,235.62,425.25,141.05,106.89"><row><cell>Descriptor</cell><cell>Grid setup 1 × 1 2 × 2 3 × 3 4 × 4</cell></row><row><cell>HOG</cell><cell>19.25 28.24 33.55 36.76</cell></row><row><cell cols="2">LBPu2 19.09 25.92 33.08 31.18</cell></row><row><cell>LBP</cell><cell>20.91 18.94 12.88 4.99</cell></row><row><cell>LGP</cell><cell>14.85 22.36 28.17 30.84</cell></row><row><cell>LTP</cell><cell>18.55 16.88 4.63 3.00</cell></row><row><cell>LPQ</cell><cell>22.15 20.85 15.72 6.48</cell></row><row><cell>WLD</cell><cell>3.00 3.00 3.00 3.96</cell></row><row><cell cols="2">LOSIB 12.55 19.21 27.42 28.47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,116.91,348.98,216.16"><head>Table 5 .</head><label>5</label><figDesc>Accuracy achieved with fusion approaches training with the image folder and testing with the extracted annotated samples on the folder of validation videos.</figDesc><table coords="9,136.16,148.27,347.58,184.80"><row><cell>Descriptors</cell><cell cols="2">SVM Approach Accuracy</cell></row><row><cell></cell><cell>RBF</cell><cell>24.56</cell></row><row><cell>HOG1×1+LBP1×1+LBP u2 1×1 +LTP1×1+LPQ1×1</cell><cell>RBF+PCA Linear</cell><cell>25.45 27.42</cell></row><row><cell></cell><cell>Linear+PCA</cell><cell>27.21</cell></row><row><cell></cell><cell>RBF</cell><cell>20.44</cell></row><row><cell>HOG2×2+LBP2×2+LBP u2 2×2 +LTP2×2+LPQ2×2</cell><cell>RBF+PCA Linear</cell><cell>29.54 21.06</cell></row><row><cell></cell><cell>Linear+PCA</cell><cell>29.69</cell></row><row><cell></cell><cell>RBF</cell><cell>35.63</cell></row><row><cell>HOG3×3+LBP u2 3×3 +LGP3×3+LOSIB3×3</cell><cell>RBF+PCA Linear</cell><cell>38.65 36.96</cell></row><row><cell></cell><cell>Linear+PCA</cell><cell>38.75</cell></row><row><cell></cell><cell>RBF</cell><cell>34.99</cell></row><row><cell>LTP1×1+LPQ1×1+HOG3×3+LBP u2 3×3 +LGP3×3+LOSIB3×3</cell><cell>RBF+PCA Linear</cell><cell>40.41 36.43</cell></row><row><cell></cell><cell>Linear+PCA</cell><cell>39.74</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. Work partially funded by the <rs type="funder">Institute of Intelligent Systems and Numerical Applications in Engineering and the Computer Science Department at ULPGC</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,449.69,337.62,7.86;10,151.52,460.65,329.05,7.86;10,151.52,471.61,182.68,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,320.35,449.69,160.23,7.86;10,151.52,460.65,147.01,7.86">Face description with local binary patterns: Application to face recognition</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,305.10,460.65,175.48,7.86;10,151.52,471.61,82.43,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2006-12">December 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,482.55,337.62,7.86;10,151.52,493.51,250.21,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,310.86,482.55,169.72,7.86;10,151.52,493.51,52.41,7.86">Fish species recognition from video using svm classifier</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Blanc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lingrand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Precioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,224.40,493.51,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="778" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,504.45,337.62,7.86;10,151.52,515.41,329.05,7.86;10,151.52,526.37,224.57,7.86" xml:id="b2">
	<analytic>
		<ptr target="http://ceur-ws.org/Vol-1391/" />
	</analytic>
	<monogr>
		<title level="m" coord="10,391.73,504.45,88.84,7.86;10,151.52,515.41,41.81,7.86">CLEF 2015 Labs and Workshops</title>
		<title level="s" coord="10,203.31,515.41,236.14,7.86">Notebook Papers. CEUR Workshop Proceedings (CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>San Juan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,537.31,337.62,7.86;10,151.52,548.26,329.05,7.86;10,151.52,559.22,25.60,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,315.95,537.31,164.63,7.86;10,151.52,548.26,44.37,7.86">Improving gender classification accuracy in the wild</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Castrillón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lorenzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ramón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,219.12,548.26,261.45,7.86">18th Iberoamerican Congress on Pattern Recognition (CIARP)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,570.16,337.62,7.86;10,151.52,581.12,329.06,7.86;10,151.52,592.08,209.29,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,455.75,570.16,24.83,7.86;10,151.52,581.12,124.83,7.86">WLD: A robust local image descriptor</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,283.05,581.12,197.53,7.86;10,151.52,592.08,63.86,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1705" to="1720" />
			<date type="published" when="2010-09">September 2010</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="10,142.96,603.02,337.62,7.86;10,151.52,613.98,329.06,7.86;10,151.52,624.94,95.09,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,396.30,603.02,84.27,7.86;10,151.52,613.98,88.70,7.86">Visual categorization with bags of keypoints</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">R</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,261.10,613.98,219.48,7.86;10,151.52,624.94,23.24,7.86">Workshop on Statistical Learning in Computer Vision, ECCV</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,635.88,337.62,7.86;10,151.52,646.84,329.06,7.86;10,151.52,657.80,252.33,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,242.26,635.88,219.46,7.86">Histograms of oriented gradients for human detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,322.94,646.84,157.64,7.86;10,151.52,657.80,118.50,7.86">International Conference on Computer Vision &amp; Pattern Recognition</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="886" to="893" />
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,120.67,337.62,7.86;11,151.52,131.63,329.06,7.86;11,151.52,142.59,248.62,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,458.69,120.67,21.88,7.86;11,151.52,131.63,295.53,7.86">Local oriented statistics information booster (LOSIB) for texture classification</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>García-Olalla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alegre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fernández-Robles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>González-Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,476.74,131.63,3.84,7.86;11,151.52,142.59,219.96,7.86">ternational Conference in Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,153.55,337.62,7.86;11,151.52,164.51,329.06,7.86;11,151.52,175.47,57.64,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,292.31,153.55,188.27,7.86;11,151.52,164.51,88.90,7.86">A component-based framework for face detection and identification</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Heisele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,247.49,164.51,208.69,7.86">International Journal of Computer Vision Research</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,186.42,337.96,7.86;11,151.52,197.38,329.05,7.86;11,151.52,208.34,329.06,7.86;11,151.52,219.30,329.06,7.86;11,151.52,230.26,157.72,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,359.02,197.38,121.56,7.86;11,151.52,208.34,126.34,7.86">Lifeclef 2014: Multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planque</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,300.21,208.34,180.37,7.86;11,151.52,219.30,140.46,7.86">nformation Access Evaluation. Multilinguality, Multimodality, and Interaction</title>
		<title level="s" coord="11,299.44,219.30,144.80,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8685</biblScope>
			<biblScope unit="page" from="229" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,241.22,337.96,7.86;11,151.52,252.18,329.06,7.86;11,151.52,263.14,196.46,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,276.15,252.18,204.43,7.86;11,151.52,263.14,38.91,7.86">Lifeclef 2015: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,211.47,263.14,107.85,7.86">Proceedings of CLEF 2015</title>
		<meeting>CLEF 2015</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,274.10,337.96,7.86;11,151.52,285.05,240.38,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,225.00,274.10,255.58,7.86;11,151.52,285.05,51.74,7.86">Robust face detection using local gradient patterns and evidence accumulation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,210.65,285.05,81.43,7.86">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3304" to="3316" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,296.01,337.96,7.86;11,151.52,306.97,329.06,7.86;11,151.52,317.93,199.92,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,232.81,296.01,247.77,7.86;11,151.52,306.97,20.75,7.86">Automatic congestion detection system for underground platforms</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,192.10,306.97,288.48,7.86;11,151.52,317.93,115.96,7.86">Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing</title>
		<meeting>2001 International Symposium on Intelligent Multimedia, Video and Speech Processing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="158" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,328.89,337.96,7.86;11,151.52,339.85,133.82,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,315.99,328.89,145.23,7.86">Lifeclef fish identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,339.85,83.64,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,350.81,337.96,7.86;11,151.52,361.77,329.06,7.86;11,151.52,372.73,76.79,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,227.49,350.81,235.71,7.86">Adaptive background mixture models for real-time tracking</title>
		<author>
			<persName coords=""><forename type="first">Grimson</forename><surname>Stauffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,361.77,324.86,7.86">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="246" to="252" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,383.68,337.96,7.86;11,151.52,394.64,329.06,8.11;11,151.52,406.25,80.02,7.47" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,277.00,383.68,60.70,7.86">Color indexing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<ptr target="http://www.springerlink.com/content/n231l41541p12l1g/" />
	</analytic>
	<monogr>
		<title level="j" coord="11,347.88,383.68,132.70,7.86;11,151.52,394.64,55.43,7.86">International Journal on Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,416.56,337.96,7.86;11,151.52,427.52,329.06,7.86;11,151.52,438.48,54.78,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,232.63,416.56,247.95,7.86;11,151.52,427.52,107.46,7.86">Enhanced local texture feature sets for face recognition under difficult lighting conditions</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,266.28,427.52,165.64,7.86">Image Processing, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1635" to="1650" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,449.44,337.96,7.86;11,151.52,460.40,271.35,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,206.53,449.44,269.99,7.86">Blur insensitive texture classification using local phase quantization</title>
		<author>
			<persName coords=""><forename type="first">V</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,165.60,460.40,173.10,7.86">Proc. Image and Signal Processing (ICISP)</title>
		<meeting>Image and Signal essing (ICISP)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,471.36,337.96,7.86;11,151.52,482.32,329.05,7.86;11,151.52,493.27,203.46,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,361.84,471.36,118.74,7.86;11,151.52,482.32,270.49,7.86">Local features and kernels for classification of texture and object categories: a comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marsza Lek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,428.34,482.32,52.24,7.86;11,151.52,493.27,112.85,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,504.23,337.96,7.86;11,151.52,515.19,329.05,7.86;11,151.52,526.15,25.60,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,270.71,504.23,209.87,7.86;11,151.52,515.19,156.51,7.86">Effcient adaptive density estimation per image pixel for the task of background subtraction</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zivkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Der Heijden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,315.60,515.19,113.83,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="773" to="780" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
