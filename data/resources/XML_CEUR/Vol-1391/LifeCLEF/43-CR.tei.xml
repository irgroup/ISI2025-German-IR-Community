<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,222.01,116.95,171.32,12.62;1,136.47,134.89,342.43,12.62">Sabanci-Okan System in LifeCLEF 2015 Plant Identification Competition</title>
				<funder ref="#_P9MUNxK">
					<orgName type="full">Turkish Scientific and Research Council of Turkey (TUBITAK)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.42,173.13,114.72,8.74"><forename type="first">Mostafa</forename><forename type="middle">Mehdipour</forename><surname>Ghazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.70,173.13,74.08,8.74"><forename type="first">Berrin</forename><surname>Yanikoglu</surname></persName>
							<email>berrin@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.34,173.13,69.36,8.74"><forename type="first">Erchan</forename><surname>Aptoula</surname></persName>
							<email>erchan.aptoula@okan.edu.tr</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Okan University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.09,185.08,57.89,8.74"><forename type="first">Ozlem</forename><surname>Muslu</surname></persName>
							<email>ozlemmuslu@sabanciuniv.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.91,185.08,88.88,8.74"><forename type="first">Murat</forename><surname>Can Ozdemir</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering and Natural Sciences</orgName>
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,222.01,116.95,171.32,12.62;1,136.47,134.89,342.43,12.62">Sabanci-Okan System in LifeCLEF 2015 Plant Identification Competition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">065CF59E07150ED9C26A18AAD2A2CD87</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>plant identification</term>
					<term>deep learning</term>
					<term>PCANet</term>
					<term>support vector machine</term>
					<term>inverse rank score</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present our deep learning based plant identification system in the LifeCLEF 2015. The approach is based on a simple deep convolutional network called PCANet and does not require large amounts of data due to using principal component analysis to learn the weights. After learning multistage filter banks, a simple binary hashing is applied to the filtered data, and features are pooled from block histograms. A multiclass linear support vector machine is then trained and the system is evaluated using the plant task datasets of LifeCLEF 2014 and 2015. As announced by the organizers, our submission achieved an overall inverse rank score of 0.153 in the image-based and an inverse rank score of 0.162 in the observation-based task of LifeCLEF 2015, as well as an inverse rank score of 0.51 for the LeafScan dataset of LifeCLEF 2014.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Overview</head><p>In recent years, research in the area of automatic plant identification from photographs has concentrated around annual plant identification competitions that are organized within the CLEF campaigns including ImageCLEF <ref type="bibr" coords="1,418.65,525.03,8.19,8.74" target="#b0">[1]</ref><ref type="bibr" coords="1,426.84,525.03,4.10,8.74" target="#b1">[2]</ref><ref type="bibr" coords="1,430.93,525.03,8.19,8.74" target="#b2">[3]</ref> and Life-CLEF <ref type="bibr" coords="1,166.07,536.99,7.75,8.74" target="#b3">[4]</ref><ref type="bibr" coords="1,173.82,536.99,3.87,8.74" target="#b4">[5]</ref><ref type="bibr" coords="1,177.70,536.99,7.75,8.74" target="#b5">[6]</ref>. CLEF is devoted to promoting and evaluating multilingual and multimodal information retrieval systems and the main goal of these competitions is to benchmark the challenging task of content-based identification and retrieval of plant species which is of immense importance in botany, agriculture, plant taxonomy, pharmacy, and pharmacology. The task is carried out using images of different types of plant parts, such as leaves, branches, stems, flowers, and fruits.</p><p>Since 2011, competitive submissions for the plant identification task have been made to ImageCLEF and LifeCLEF in which the participating systems have utilized widely different approaches; still, the problem is far from being solved due to several challenges including large variations in color, illumination, background, size, and shape. Deep learning approaches are new and suitable for solving such problems with large amounts of intra-class variability <ref type="bibr" coords="2,426.90,131.95,9.96,8.74" target="#b6">[7]</ref>.</p><p>There are two tasks within the LifeCLEF 2015 campaign: image-based and observation-based plant identification tasks. The image-based task requires identification given a single image while the goal of the observation-based task is to identify plants based on multi-image query. The latter corresponds to the scenario in which a photographer uses the same camera to take snapshots from different views of various organs of a plant species under the similar lighting conditions and on the same day. The campaign started in 2011 with the imagebased task covering over 70 tree species, and the observation-based task became the main track later in 2014. By 2015 <ref type="bibr" coords="2,309.73,239.59,9.96,8.74" target="#b5">[6]</ref>, the number of species has reached about 1000, covering the entire flora of a given region.</p><p>In this work, we have utilized a system different from our previous submissions <ref type="bibr" coords="2,159.64,275.50,8.49,8.74" target="#b7">[8]</ref><ref type="bibr" coords="2,168.13,275.50,4.24,8.74" target="#b8">[9]</ref><ref type="bibr" coords="2,168.13,275.50,4.24,8.74" target="#b9">[10]</ref><ref type="bibr" coords="2,172.37,275.50,12.73,8.74" target="#b10">[11]</ref> to recognize plant species using a new deep convolutional network known as PCANet <ref type="bibr" coords="2,217.80,287.45,9.96,8.74" target="#b6">[7]</ref>. Although the PCANet method is suboptimal in comparison with common convolutional neural networks (CNN) <ref type="bibr" coords="2,376.89,299.41,15.83,8.74" target="#b11">[12,</ref><ref type="bibr" coords="2,392.72,299.41,11.87,8.74" target="#b12">13]</ref>, our experiments using PCANet resulted in good performances for aligned images such as scanned leaves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PCANet</head><p>PCANet is a recently proposed convolutional network architecture that combines the strengths of principal component analysis (PCA) and deep learning <ref type="bibr" coords="2,454.41,391.52,9.96,8.74" target="#b6">[7]</ref>. In comparison with the CNN which attempts to find optimal filters for feature mapping, PCANet is suboptimal in that it learns the filter banks by applying PCA on the input data. On the other hand, its advantages lie in the facts that it does not require large amounts of data or long learning time while still using the core concept of the deep convolutional network architecture.</p><p>The general structure of PCANet and our proposed architecture for plant identification are presented in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">General PCANet Architecture</head><p>PCANet initializes by applying principal component analysis to overlapping patches of all images. The selected principal components form the first layer filters and the projections of the patches on to the principal components form the response of units in the first layer.</p><p>We then repeat this methodology to form a cascaded linear map in the next layers of the deep convolutional network architecture. Next, the method uses binary quantization and hashing for the multi-stage filtered image sets to concatenate them in the decimal form. Finally, local histograms are extracted from the blocks of the quantized images and spatial pyramid pooling method is applied to these histograms to extract features.</p><p>The algorithm is explained in detail as follows. The training data contains i = 1, 2, ..., N images I i of size m × n. In the first stage, patches of size k 1 × k 2 pixels are extracted around each pixel in the image I i . Afterwards, all such overlapping patches are collected, vectorized, and mean subtracted to obtain X i . Repeating this operation for all images, we obtain a patch collection X, as:</p><formula xml:id="formula_0" coords="3,231.41,162.81,249.18,11.72">X = [X 1 , X 2 , ..., X N ] ∈ R k1k2×N mn (1)</formula><p>Next, in order to calculate the desired filter banks of orthonormal filters, V , PCA minimizes the reconstruction error to compute their L 1 principal components. The constrained optimization is formulated as:</p><formula xml:id="formula_1" coords="3,192.89,228.28,287.70,20.66">min V ∈R k 1 k 2 ×L 1 X -V V T X 2 F subject to V T V = I L1<label>(2)</label></formula><p>where • F is Frobenius norm, I L1 is the identity matrix of size L 1 × L 1 and the solution simply consists of finding L 1 principal eigenvectors of XX T . Therefore, the PCA filters for the first layer form weights W 1 l1 for l 1 = 1, 2, ..., L 1 , by converting the eigenvectors to matrices of size k 1 × k 2 . Hence, the l 1 th filtered image is calculated by convolving the l 1 th filter with the i th patch-mean removed image, Īi , as,</p><formula xml:id="formula_2" coords="3,278.29,340.21,202.30,13.45">I l1 i = Īi * W 1 l1<label>(3)</label></formula><p>We can repeat the same approach to learn L 2 PCA filters for the second layer to create double filtered images. For this purpose, all the overlapping patches of each filtered image I l1 i are collected, vectorized, and mean subtracted to obtain Y l1 i . Repeating this algorithm for all filtered images, we obtain,</p><formula xml:id="formula_3" coords="3,178.49,420.27,302.11,13.47">Y = [Y 1 1 , ..., Y 1 N , Y 2 1 , ..., Y 2 N , ..., Y L1 1 , ..., Y L1 N ] ∈ R k1k2×L1N mn<label>(4)</label></formula><p>Similarly, PCA filters for the second layer, W 2 l2 for l 2 = 1, 2, ..., L 2 , are obtained by finding L 2 principal eigenvectors of Y Y T and rearranging them as matrices of size k 1 × k 2 . Therefore, the double filtered image, computed sequentially using the l 1 th and l 2 th filters, is obtained by convolving the l 2 th filter with the i th patch-mean removed filtered image, Īl1</p><p>i , as,</p><formula xml:id="formula_4" coords="3,270.36,512.40,210.23,13.68">O l1,l2 i = Īl1 i * W 2 l2<label>(5)</label></formula><p>As can be seen, in the output O for each image, we have L 1 × L 2 double filtered images with real values. To decrease the number of images, it is proposed to first binarize them using Heaviside step function H( • ). Next, for each pixel, we map L 2 quantized binary bits to a decimal number as</p><formula xml:id="formula_5" coords="3,246.55,591.76,234.05,30.66">T l1 i = L2 l2=1 2 l2-1 H( Īl1 i * W 2 l2 )<label>(6)</label></formula><p>In fact, this conversion maps each L 2 binary bits acquired from corresponding pixels of the double filtered binary images into a single graylevel image pixel in the range [0, 2 L2 -1]. Finally, we partition each of L 1 decimal images (T l1 i ) into B blocks and compute block histograms (with 2 L2 bins) for all L 1 images as the features of i th image,</p><formula xml:id="formula_6" coords="4,141.96,321.17,338.63,14.65">f i = [hist 1 (T 1 i ), ..., hist B (T 1 i ), ..., hist 1 (T L1 i ), ..., hist B (T L1 i )] ∈ R 1×2 L 2 L1B (7)</formula><p>where hist j ( • ) indicates the histogram of the j th block of the partitioned im- age. Utilizing local histograms provides translation invariance in the extracted features. Figure <ref type="figure" coords="4,206.42,370.47,4.98,8.74" target="#fig_0">1</ref> displays the block diagram of a two-stage PCANet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">PCANet Architecture for Plant Identification</head><p>In order to process each plant image, color images are converted from RGB to HSY color space <ref type="bibr" coords="4,225.81,430.11,15.50,8.74" target="#b13">[14]</ref> and scaled identically to 128 × 128 pixels. We apply PCANet on each color component of the scaled plant images assuming a 2-stage convolutional network with L 1 = 10 and L 2 = 8 as the number of filter banks in each stage with the overlapping image patches of size 7 × 7 and histogram block size of 20×10. Because of the massive size of data obtained after feature pooling, we chose the multi-class linear Support Vector Machine (SVM) classifier for complexity and accuracy issues in the final stage. For the SVM implementation, we used the Liblinear toolbox <ref type="bibr" coords="4,270.08,513.79,15.50,8.74" target="#b14">[15]</ref> and applied the dual L2-regularized-L2-loss model and a misclassification penalty cost of one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Score Fusion in the Observation-Based Task</head><p>For the observation-based task, we applied the Borda count fusion method <ref type="bibr" coords="4,465.11,573.43,15.50,8.74" target="#b15">[16]</ref> to the proposed system outputs to combine the scores obtained by different photographs of individual plants. In this method, each class that appears in the list of top classes returned by the classifier receives a vote that is inversely proportional to its rank in that list. Note that for each observation with k images, there are k such class lists. We modified the Borda count in this problem such that votes are distributed not only to the class, but also to the members in the same genus.</p><p>In this section, we will explain the competition datasets and adjust optimal parameters of our proposed system by extracting validation sets from the training data. We then define the performance metrics and report the experimental results on the validation and official test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The plant identification task in LifeCLEF 2015 involves identifying 1,000 species of trees, herbs, and ferns from photographs of their different organs mostly taken within France by different users. The collected dataset contains 113,205 pictures, 91,759 images for training and 21,446 images for testing. Table <ref type="table" coords="5,401.55,267.28,4.98,8.74" target="#tab_0">1</ref> shows the details of the provided datasets and their sample images. To validate our results, we used the proportionate stratified random sampling, i.e. we first randomly split the training dataset into two subsets after placing images of each plant species into both the training and the validation sets. The proportion of validation sets to training sets is assumed to be around 1 to 3. In other words, for any dataset, we randomly selected one-fourth of available samples of each individual class, if possible, as samples of the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>We next applied our proposed plant identification system for different plant categories on the obtained training and validation sets. Table <ref type="table" coords="5,395.70,597.22,4.98,8.74" target="#tab_1">2</ref> shows the system performance in terms of the obtained first rank classification accuracies. As expected, the flower, fruit, and stem photographs are relatively easier to classify compared to branch, leaf, and entire categories.</p><p>LifeCLEF lab itself employs a user-based metric called the average inverse rank score <ref type="bibr" coords="5,183.66,657.11,15.50,8.74" target="#b16">[17]</ref> instead of the total classification accuracy. The average inverse </p><p>where U is the number of users who have taken the query pictures; P u is the number of individual plants observed by the u th user; N u,p is the number of pictures taken from the p th plant observed by the u th user; and s u,p,n is the inverse of the rank of the correct species for the given image, ranging from 0 to 1. Considering this metric, we applied PCANet to the test sets using the learned parameters in the training step and submitted our prediction results to the organizers of LifeCLEF 2015 for official evaluation. Table <ref type="table" coords="6,366.13,537.56,4.98,8.74" target="#tab_2">3</ref> displays the inverse rank scores of our best run in the image-based LifeCLEF 2015 for different categories of plant identification task. In the observation-based task, our approach using Borda count achieved an inverse rank score of 0.162. Bearing in mind that this large dataset consists of 1,000 classes of similar categories, our official overall rank score of 0.153 in the image-based task shows a fair performance for our submission. Comparing the official test results given in Table <ref type="table" coords="6,175.01,621.25,4.98,8.74" target="#tab_2">3</ref> with the higher accuracies reported in Table <ref type="table" coords="6,384.88,621.25,3.87,8.74" target="#tab_1">2</ref>, we conclude that a considerable amount of overfitting existed during validation. This situation could have been improved if we had used more data, but the time complexity was an issue even with the simple architecture. Furthermore, since a very small subset of the test data in LifeCLEF 2015 belonged to scanned leaves, we skipped the preprocessing and segmentation phase <ref type="bibr" coords="7,162.01,143.90,15.50,8.74" target="#b17">[18]</ref> which had been applied to the LeafScan category in our previous submissions <ref type="bibr" coords="7,174.91,155.86,8.07,8.74" target="#b7">[8]</ref><ref type="bibr" coords="7,182.98,155.86,4.03,8.74" target="#b8">[9]</ref><ref type="bibr" coords="7,182.98,155.86,4.03,8.74" target="#b9">[10]</ref><ref type="bibr" coords="7,187.01,155.86,12.10,8.74" target="#b10">[11]</ref>. Once we applied PCANet to the segmented and preprocessed LeafScan images of LifeCLEF 2014, we achieved the inverse rank score of 0.51 as measured by the campaign organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Time Complexity</head><p>We measured the complexity of our system in terms of the running time for feature extraction and training the classifier. On average over all categories, PCANet took 1.37 seconds/image and 6.13 seconds/image for feature extraction and training, respectively. All codes were implemented in MATLAB (run in 80 GB RAM and 2.50 GHz CPU with two processors).</p><p>Although the campaign within the LifeCLEF 2015 had allowed using external training data, we restricted ourselves to the provided LifeCLEF datasets. That was due to the reasons that PCANet does not require large data to learn the weights and that using external datasets would increase the processing time for our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Effects of Parameter Selection</head><p>Parameters of the proposed PCANet-based plant identification system were selected experimentally through validation. Due to combinatorial increase, each time we adjusted only one of the parameters until finding the optimal point. For instance, we observed that by increasing or decreasing the image patch size from 7 × 7, the performance rapidly decreased. The same conditions were held for the block size of histograms (20 × 10).</p><p>On the other hand, we observed that by increasing the normalization size of input images and/or the number of filter banks (especially within the first stage), the performance improved. However, there was a trade-off between complexity and accuracy, i.e. by increasing the input image size and/or the number of filters, the accuracy improved slightly while the size of the output feature vectors expanded as well. Consequently, the training time increased drastically. Therefore, we set the system parameters equal to values mentioned in the Section 2.2 to evaluate our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Summary and Discussions</head><p>In this work, we used a simple deep convolutional approach called PCANet in order to identify the plant species within the LifeCLEF 2015 plant identification dataset. Our best run has shown a fair performance with overall inverse rank scores of 0.153 and 0.162 in the image-based and observation-based tasks, respectively. It seems that the proposed system is fast and efficient for aligned images such as preprocessed scanned leaves.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,208.91,243.73,197.54,8.74"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Block diagram of a two-stage PCANet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,329.63,345.84,78.64"><head>Table 1 :</head><label>1</label><figDesc>Details of the datasets for plant identification task within the LifeCLEF 2015</figDesc><table coords="5,139.27,356.52,331.65,51.75"><row><cell></cell><cell cols="4">Branch Entire Flower Fruit</cell><cell cols="3">Leaf LeafScan Stem</cell></row><row><cell cols="2"># Training Samples 8,130</cell><cell cols="2">16,235 28,225</cell><cell>7,720</cell><cell>13,367</cell><cell>12,605</cell><cell>5,476</cell></row><row><cell># Test Samples</cell><cell>2,088</cell><cell>6,113</cell><cell>8,327</cell><cell>1,423</cell><cell>2,690</cell><cell>221</cell><cell>584</cell></row><row><cell># Classes</cell><cell>891</cell><cell>993</cell><cell>997</cell><cell>755</cell><cell>899</cell><cell>351</cell><cell>649</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,135.56,345.84,154.48"><head>Table 2 :</head><label>2</label><figDesc>Top rank classification accuracies for the proposed plant identification system</figDesc><table coords="6,143.36,163.26,328.97,126.77"><row><cell cols="4">Category # Training Samples # Validation Samples Accuracy</cell></row><row><cell>Branch</cell><cell>6,447</cell><cell>1,683</cell><cell>23.53 %</cell></row><row><cell>Entire</cell><cell>12,567</cell><cell>3,668</cell><cell>25.08 %</cell></row><row><cell>Flower</cell><cell>21,531</cell><cell>6,694</cell><cell>34.02 %</cell></row><row><cell>Fruit</cell><cell>6,072</cell><cell>1,648</cell><cell>40.41 %</cell></row><row><cell>Leaf</cell><cell>10,367</cell><cell>3,000</cell><cell>33.80 %</cell></row><row><cell>LeafScan</cell><cell>9,576</cell><cell>3,029</cell><cell>90.49 %</cell></row><row><cell>Stem</cell><cell>4,344</cell><cell>1,132</cell><cell>37.19 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,323.73,345.84,131.22"><head>Table 3 :</head><label>3</label><figDesc>Official average inverse rank scores of our best run in the imaged-based task of LifeCLEF 2015</figDesc><table coords="6,134.77,351.55,337.55,103.39"><row><cell cols="9">Branch Entire Flower Fruit Leaf LeafScan Stem Overall</cell></row><row><cell>0.053</cell><cell>0.106</cell><cell cols="2">0.189</cell><cell cols="4">0.143 0.111</cell><cell>0.216</cell><cell>0.120</cell><cell>0.153</cell></row><row><cell cols="3">rank score S is defined as</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>S =</cell><cell>1 U</cell><cell>U u=1</cell><cell>1 P u</cell><cell>Pu p=1</cell><cell>1 N u,p</cell><cell>Nu,p n=1</cell><cell>s u,p,n</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This project is supported by <rs type="funder">Turkish Scientific and Research Council of Turkey (TUBITAK)</rs> under project number <rs type="grantNumber">113E499</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_P9MUNxK">
					<idno type="grant-number">113E499</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,182.99,337.62,7.86;8,151.52,193.95,329.05,7.86;8,151.52,204.91,291.47,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,305.00,193.95,175.57,7.86;8,151.52,204.91,15.40,7.86">The CLEF 2011 plant images classification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,188.93,204.91,170.77,7.86">CLEF (Notebook Papers/Labs/Workshop)</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,215.37,337.62,7.86;8,151.52,226.33,329.06,7.86;8,151.52,237.29,189.61,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,209.20,226.33,189.34,7.86">The ImageCLEF 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,422.19,226.33,58.39,7.86;8,151.52,237.29,130.06,7.86">CLEF (Online Working Notes/Labs/Workshop)</title>
		<meeting><address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,247.76,337.62,7.86;8,151.52,258.72,329.06,7.86;8,151.52,269.68,62.46,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,174.00,258.72,187.19,7.86">The ImageCLEF 2013 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,383.15,258.72,93.29,7.86">CLEF (Working Notes)</title>
		<meeting><address><addrLine>Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,280.14,337.62,7.86;8,151.52,291.10,329.05,7.86;8,151.52,302.06,60.92,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,167.25,291.10,157.96,7.86">LifeCLEF plant identification task 2014</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,346.96,291.10,92.85,7.86">CLEF (Working Notes)</title>
		<meeting><address><addrLine>Sheffield</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="598" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,312.53,337.62,7.86;8,151.52,323.49,329.06,7.86;8,151.52,334.44,329.06,7.86;8,151.52,345.40,25.60,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,351.19,323.49,129.38,7.86;8,151.52,334.44,128.56,7.86">LifeCLEF 2015: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,309.18,334.44,171.39,7.86">CLEF 2015 Proceedings. Springer LNCS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,355.87,337.62,7.86;8,151.52,366.83,137.07,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,279.33,355.87,156.06,7.86">LifeCLEF plant identification task 2015</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,455.87,355.87,24.70,7.86;8,151.52,366.83,65.56,7.86">CLEF (Working Notes)</title>
		<meeting><address><addrLine>Toulouse</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,377.30,337.62,7.86;8,151.52,388.25,329.06,7.86;8,151.52,399.21,140.57,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,381.79,377.30,98.78,7.86;8,151.52,388.25,297.95,7.86">PCANet: A simple deep learning baseline for image classification? Computing Research Repository</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.3606v2</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">CoRR -arXiv</note>
</biblStruct>

<biblStruct coords="8,142.96,409.68,337.62,7.86;8,151.52,420.64,322.00,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,314.33,409.68,166.24,7.86;8,151.52,420.64,95.91,7.86">Sabanci-Okan system at ImageClef 2011: Plant identification task</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tirkaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,269.44,420.64,166.13,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,431.11,337.62,7.86;8,151.52,442.06,329.06,7.86;8,151.52,453.02,141.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,314.33,431.11,166.24,7.86;8,151.52,442.06,224.80,7.86">Sabanci-Okan system at ImageClef 2012: Combining features and classifiers for plant identification</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tirkaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,396.17,442.06,84.41,7.86;8,151.52,453.02,103.64,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,463.49,337.96,7.86;8,151.52,474.45,274.08,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,321.35,463.49,159.22,7.86;8,151.52,474.45,125.58,7.86">Sabanci-Okan system at ImageClef 2013 plant identification competition</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Yildiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,299.46,474.45,93.33,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,484.91,337.96,7.86;8,151.52,495.87,329.05,7.86;8,151.52,506.83,32.25,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,381.49,484.91,99.08,7.86;8,151.52,495.87,186.12,7.86">Sabanci-Okan system at LifeCLEF 2014 plant identification competition</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Yildiran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tirkaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,357.42,495.87,91.34,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="771" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,517.30,337.96,7.86;8,151.52,528.23,307.90,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,350.53,517.30,130.04,7.86;8,151.52,528.26,96.95,7.86">Gradient-based learning applied to document recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,256.48,528.26,99.66,7.86">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,538.72,337.96,7.86;8,151.52,549.68,329.06,7.86;8,151.52,560.64,41.47,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,341.27,538.72,139.31,7.86;8,151.52,549.68,118.22,7.86">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,291.49,549.68,156.27,7.86">Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page" from="1106" to="1114" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,571.11,337.96,7.86;8,151.52,582.07,329.06,7.86;8,151.52,593.03,60.92,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,208.38,571.11,272.20,7.86;8,151.52,582.07,30.35,7.86">A 3D-polar coordinate colour representation well adapted to image analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,204.75,582.07,272.03,7.86">Proceedings of the 13th Scandinavian conference on Image analysis</title>
		<meeting>the 13th Scandinavian conference on Image analysis</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="804" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,603.49,337.96,7.86;8,151.52,614.43,329.07,7.89;8,151.52,625.41,70.13,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,415.24,603.49,65.34,7.86;8,151.52,614.45,147.35,7.86">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,310.46,614.45,160.42,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,635.88,337.96,7.86;8,151.52,646.84,329.05,7.86;8,151.52,657.80,306.59,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,208.31,646.84,191.12,7.86">Artificial neural networks and machine learning</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Mladenov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koprinkova-Hristova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E P</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Appollini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kasabov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.90,646.84,58.68,7.86;8,151.52,657.80,256.59,7.86">Proceedings of the 23rd International Conference on Artificial Neural Networks</title>
		<meeting>the 23rd International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,120.67,337.96,7.86;9,151.52,131.63,329.05,7.86;9,151.52,142.59,92.26,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,370.61,120.67,109.96,7.86;9,151.52,131.63,162.26,7.86">ImageCLEF: Experimental evaluation in visual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselarers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="9,375.28,131.63,105.29,7.86;9,151.52,142.59,22.01,7.86">The Information Retrieval Series</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,153.55,337.96,7.86;9,151.52,164.48,273.92,7.89" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,314.39,153.55,166.19,7.86;9,151.52,164.51,33.28,7.86">Automatic plant identification from photographs</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tirkaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,193.05,164.51,133.71,7.86">Machine Vision and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1369" to="1383" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
