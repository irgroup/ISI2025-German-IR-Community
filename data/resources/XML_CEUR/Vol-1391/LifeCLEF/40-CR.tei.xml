<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.59,152.85,340.01,13.60;1,210.91,170.37,173.37,13.60">SVM classification of moving objects tracked by Kalman filter and Hungarian method</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,212.21,209.54,52.63,11.04"><forename type="first">Gábor</forename><surname>Szűcs</surname></persName>
							<email>szucs@tmit.bme.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technolo-gy and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.74,209.54,48.07,11.04"><forename type="first">Dávid</forename><surname>Papp</surname></persName>
							<email>pappdavid27@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technolo-gy and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.27,209.54,55.91,11.04"><forename type="first">Dániel</forename><surname>Lovas</surname></persName>
							<email>lovas.daniel@simonyi.bme.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technolo-gy and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.59,152.85,340.01,13.60;1,210.91,170.37,173.37,13.60">SVM classification of moving objects tracked by Kalman filter and Hungarian method</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F22CD4E8C08176DE77BA26DD20649A98</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>SVM method</term>
					<term>fish classification</term>
					<term>tracking</term>
					<term>Kalman filter</term>
					<term>Hungarian method</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fishery video data often require laborious visual analysis, therefore a video-based fish identification challenge is announced in the LifeCLEF campaign for automatic fish categorization and enumeration. We have elaborated a complex system to detect, classify and track objects (fishes) in underwater video by examining each image frame of it. For the detection process we used background subtraction and morphologic methods, and then our solution calculated bounding boxes based on object contours. We used Kalman filter to track the moving objects, but an additional matching method was required to pair the objects in consecutive time periods because of many fishes. We used Hungarian method for this matching problem. We categorized the detected fishes with C-SVC classifier, as an advanced SVM (Support Vector Machine) classifier. The classifier used high level descriptors, which are based on the extracted SURF vectors in each object. For optimization the C-SVC classifier we conducted a preliminary test, and we used the best parameters for teaching the classifier. We predicted the fish species in the official test video set, and our predictions were evaluated officially by NCS (Normalized Counting Score).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The analysis of video data usually requires very time-consuming and expensive input by human observers, and this is true for underwater videos as well, although the statistics of data collection would be very useful for exploratory applications, in particular for fisheries and biological areas. This analytical "bottleneck" greatly restricts the use of the powerful video technologies and demands effective methods for automatic content analysis to enable proactive provision of analytical information; and in order to solve this problem a challenge is announced in the LifeCLEF <ref type="bibr" coords="1,299.57,683.14,12.27,11.04" target="#b0">[1]</ref> campaign of ImageCLEF <ref type="bibr" coords="1,422.59,683.14,11.26,11.04" target="#b1">[2]</ref>.</p><p>In this challenge two datasets (training data set with ground truth and a test set) were released for the video-based fish identification task <ref type="bibr" coords="2,412.75,164.90,11.27,11.04" target="#b2">[3]</ref>. The goal was to automatically count fish per species in video segments (e.g., video X contains N 1 instances of fish of species 1, ..., N n instances of fish species n).</p><p>We have divided the problem into subtasks: object detection, classification and tracking, where the objects were the fishes; and we have implemented a video analysis system to solve these tasks. The applied methods and our solution are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Object detection, classification and tracking system</head><p>Object classification and tracking are different tasks, but both of them based on object detection (fish detection) in images of videos. We have implemented fish detection in OpenCV in such way that the bounding boxes of detected fishes are stored as small images with corresponding information (actual timestamp, identifier, etc). The common subtask in both of the problems is mapping, i.e. interconnection of bounding box images and fish identifiers (these identifiers are generated for only distinguishable aim), because the results of the mapping can be used for classification and tracking as well.</p><p>Thus the bounding box images are input for classification method, which estimates the species of fishes. The consecutive images with common fish identifiers can be classified into different species; therefore the final decision of classification in our solution is based on majority voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Detection of many fishes</head><p>The one of the challenges in the fish detection was the observation of many objects in an image. For object detection at first we have used background subtraction <ref type="bibr" coords="2,179.78,577.63,11.25,11.04" target="#b3">[4]</ref>, in order to separate the foreground from background. The most common morphological methods (erosion, dilation and the combination of them, the closing) have been applied in order to get smooth and solid edges <ref type="bibr" coords="2,153.62,623.95,11.36,11.04" target="#b4">[5]</ref>. After this smoothing an algorithm for contours of objects has been applied, that is evolved by Suzuki and Abe <ref type="bibr" coords="2,321.89,639.43,11.37,11.04" target="#b5">[6]</ref>. Using the contours our solution calculates the bounding boxes and the object centres. Some of detected objects were too small to substantively use in classification, hence those objects that were smaller then 15x15 pixel were filtered out (deleted).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fish tracking with Kalman filter and Hungarian method</head><p>After the detection in our solution Kalman filter <ref type="bibr" coords="3,341.59,221.78,12.37,11.04" target="#b6">[7]</ref>[8] has been used to track objects in three steps: (i) initialization, and after that there is a cycle process with (ii) prediction and (iii) correction.</p><p>Initialization: at the first frame, where any detection was, the Kalman filter was initialized; and for every detected object an identity number and a confidence value (CFV) were attached.</p><p>Prediction: In this step a prediction was made by Kalman filter on each detected object (using the calculated object centre) to forecast the future position of the investigated fish.</p><p>Correction: After prediction the new detections (in next frame of the video) give the measurements (which are used in the comparison of the measurements with predictions). These measurements were used for correct the Kalman filter objects. In order to reach the best tracked-measured coupling we applied the Hungarian method <ref type="bibr" coords="3,283.97,452.57,12.38,11.04" target="#b8">[9]</ref>[10], completed with a restriction that we removed those objects that not belong to a new measurement. We present this applied method below.</p><p>Let v i be a tracked object, where i = 0...k and let w j be a newly detected object where j = 0...l. Before our solution used the Hungarian method a M kxl matrix was calculated, where M[i,j] denotes the Euclidean distance (measured in pixels in the image) of v i and w j objects. The rows and columns with higher elements than a given threshold were removed to prevent false matching. If a row corresponding to v i was removed from M, then we lowered the confidence value (CFV) of that particular tracking. On the other side removing w j means that we should track this object, i.e. probably this is a new object (a new Kalman filter has been created for this object), because this is far from all others. The Fig. <ref type="figure" coords="4,167.65,334.37,4.21,11.04" target="#fig_0">1</ref>. illustrates the mechanism of the applied Hungarian method, where the v i objects are representing by a set of black and grey vertices (T) and w j object by red and pink ones (N). The thick edges connect the matched (v,w) pairs, whereas grey and pink colour denote those nodes that have no pair. After the Hungarian method the matched object pairs will be the input of the correction phase of Kalman filter (black vertices are tracked objects and the red ones are the measurements).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Fish classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Elaboration of image descriptors</head><p>The first part of the classification process is the representation of each image based on their visual content. This consists of three steps: (i) feature detection, (ii) feature description, (iii) image description as usual phases in computer vision.</p><p>Feature detection and description: Lots of different feature types can be detected in an image, e.g. corners, edges, ridges, as "interesting" part of an image. In our solution we have used Fast-Hessian Detector <ref type="bibr" coords="4,391.27,601.99,17.91,11.04" target="#b10">[11]</ref> to determine the "key points" in each image, and SURF (Speed Up Robust Features) <ref type="bibr" coords="4,452.83,617.47,17.94,11.04" target="#b10">[11]</ref> descriptor to extract local information at each key point. The SURF is based on Lowe's SIFT (Scale Invariant Feature Transform) <ref type="bibr" coords="4,353.95,648.31,17.89,11.04" target="#b11">[12]</ref>[13] with the expectation to be faster and more robust. Both of these methods are widely used in practice and in theoretical works (as well) with some possible further devel-opment; but we have chosen SURF, because in videos the processing speed is more important. A SURF descriptor vector belongs to only one interesting point of an image, but an image possesses many feature descriptor vectors, which should be aggregated into an image descriptor.</p><p>Image description: The next step of creating the representation is the completion of high-level representation of each image. We have applied BoW (bag-of-words) model <ref type="bibr" coords="5,225.36,252.14,35.96,11.04">[14][15]</ref> for this purpose, where images are treated as text documents. According to this, "visual words" (so called "codewords") in images need to be defined from feature descriptors. The whole set of codewords gives the codebook (similarly to dictionary in text tasks). To determine the codebook we clustered the SURF descriptors with K-means <ref type="bibr" coords="5,426.17,313.85,17.93,11.04" target="#b15">[16]</ref> algorithm, and the resulting cluster centers will represent the codewords, since a centroid represents similar feature descriptors. We have experimented with different cluster sizes (k=5000 and k=10000), these are discussed later. At this point, the codebook with codewords was available for further calculations, which can be considered as a concise representation of the whole image set. According to the codebook the next step is to create a descriptor that specifies the distribution of the visual codewords in any image, called high-level descriptor. We have built histograms as high-level descriptors for each image:</p><formula xml:id="formula_0" coords="5,145.10,477.17,100.21,13.46"> Let ( ) ( )</formula><p>( ) be the initial histogram of the r th image, where denotes the size of the codebook (each element represent a codeword in H).  We performed 1NN (1-nearest neighbour) algorithm for each SURF descriptor to find the closest codeword (based on Euclidean distance), then the corresponding element of H was incremented by 1, where i cycles through the descriptors created for the r th image</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Training the classifier</head><p>For the classification task we have divided the labelled image set into two subsets: training and test set. We used the first one to create the codebook, and train the classifiers, and the latter for preliminary testing. The histograms were created for each training image, then we performed a variation of SVM (Support Vector Machine), the C-SVC (C-support vector classification)</p><p>[17] <ref type="bibr" coords="6,142.65,149.42,17.95,11.04" target="#b17">[18]</ref> with linear kernel function to train the classifier (classification model). The SVM is basically a binary linear classifier, thus in order to extend it to a number of classified categories, the one-against-all technique was used.</p><p>During this method a binary classifier was created for each category in the training set. We have executed kFold cross-validation technique before the preliminary test to determine the parameter of the C-SVC classifier. (After the training, the codebook was already available.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Preliminary test of classification</head><p>For the maximization the goodness of classification part we have conducted a preliminary test, as validation phase of the learning process. The labelled image set was divided into train set (11221 images) and preliminary test set (11220 images). The training phase was executed by different parameters according to the number of codewords sizes (5000 and 10000), the number of dimensions of SURF vectors (64 and 128), and the number of SURF vectors in an image (80, 200, and 500). Besides the accuracy we have measured the speed of the algorithm as well, and the results can be seen in Table <ref type="table" coords="6,426.85,399.29,5.60,11.04" target="#tab_0">1</ref> and<ref type="table" coords="6,454.19,399.29,4.21,11.04" target="#tab_1">2</ref>.  The best result of the preliminary testing is the 0.663 at case of 128 dimensions, 500 vectors and 5000 codewords. The run time of the training phase was long, but the largest part (92-94%) of this was the SVM teaching, which was important for good accuracy, while the other parts are fast (creating codewords: 3-6%, histogram calculation: less, than 1%); furthermore the test phase was also quick (10 minutes). The run time values were measured on a PC (with Intel Core i7-4770K processor, 16 GB RAM and SSD).</p><p>For the prediction of official test we have chosen the SVM model with the best parameters (128 dimensions, 500 vectors and 5000 codewords), and we have submitted 2 prediction files (as results of 2 runs). The used method of the runs was the same (as described above), only small difference was between the two submissions. The first run (BME TMIT RUN1) contains false detections, because of the glances (blinks) and the low level threshold in detection (higher level threshold could avoid these); while at the second run (BME TMIT RUN2) these detections were filtered out, and corresponding predictions in the crucial videos were deleted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation metrics</head><p>In the official evaluation the normalised counting score is measured (instead of accuracy as in our preliminary testing). The counting score (CS) is defined as can be seen in Equation <ref type="bibr" coords="7,249.89,505.87,11.32,11.04" target="#b0">(1)</ref>, where d is the difference between the number of occurrences in the run (per species) and the number of occurrences in the ground truth (Ngt).</p><formula xml:id="formula_1" coords="7,254.73,564.39,215.99,31.72">Ngt d e CS  <label>(1)</label></formula><p>The precision (Pr) is defined as Pr= TP/(TP+FP) with TP and FP being, respectively, the true positives and the false positives. The normalised counting score (NCS) is defined as NCS = CS x Pr.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Final official results</head><p>Our final official results for each fish species can be seen in Table <ref type="table" coords="8,427.87,172.94,3.73,11.04" target="#tab_2">3</ref>., where the occurrences of fish species in the test set and the NCS (Normalized Counting Score) results are presented. In cases, there were no occurrences of a given species and in the runs no fish were observed of those species, CS = 1 (since d = 0) and Pr was equal to 1. It can be seen in Table <ref type="table" coords="8,221.93,570.79,5.60,11.04" target="#tab_2">3</ref> that our solution has perfectly found this absence at two species (among three fish species: 5, 10, 13).</p><p>The aggregated official results of different fish species can be seen in Table <ref type="table" coords="8,462.15,611.59,4.22,11.04" target="#tab_3">4</ref>.</p><p>(the last column is the product of previous ones), and we can conclude that the second run of our submissions was better. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have elaborated a complex system to detect and track objects (fish) in underwater video by examining each image frame of it. For the detection process we used background subtraction and morphologic methods, and then our solution calculated bounding boxes based on object contours. The first time we detect an object, we assign a Kalman filter to it, which is able to predict the possible location of that object in the next frame. We likely detect that particular object (the same fish) in the next frame also, but we should not apply a new Kalman filter. To deal with this, we used Hungarian method to pair the existing Kalman filters with the new "candidate" ones. Then we erased the candidate Kalman filters with matching pair, and kept the single ones. This way we were able to track the detected objects. We also categorized the detected fishes with C-SVC classifier; however this required representing the objects based on visual information. For this purpose, our system calculated SURF descriptors for each object, and then clustered them with algorithm. Our solution built histograms for each fish based on the resulting cluster centres (according to BoW model), and these histograms were the input of the C-SVC. For optimization the C-SVC classifier we conducted a preliminary test, and we used the best parameters for teaching the classifier. We predicted the fish species in the official test video set based on our implemented model, and the number of occurrences of each fish species was enumerated. At the official evaluation (by the second submission) we reached 0.34 value of NCS (Normalized Counting Score).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,224.09,311.06,146.88,9.00;4,177.57,188.28,240.14,108.95"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Mechanism of Hungarian method</figDesc><graphic coords="4,177.57,188.28,240.14,108.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,124.70,426.38,346.18,151.01"><head>Table 1 .</head><label>1</label><figDesc>Results of the preliminary testing at 5000 codewords</figDesc><table coords="6,124.70,444.62,346.18,132.77"><row><cell></cell><cell cols="2">number of dimensions: 128</cell><cell cols="2">number of dimensions: 64</cell></row><row><cell></cell><cell>run time (s)</cell><cell>accuracy</cell><cell>run time (s)</cell><cell>accuracy</cell></row><row><cell>vectors: 80</cell><cell>N.A.</cell><cell>0.259</cell><cell>N.A.</cell><cell>0.253</cell></row><row><cell>vectors: 200</cell><cell>9744</cell><cell>0.644</cell><cell>8672</cell><cell>0.595</cell></row><row><cell>vectors: 500</cell><cell>11863</cell><cell>0.663</cell><cell>9406</cell><cell>0.629</cell></row><row><cell cols="5">After the preliminary testing at 5000 codewords the case of 10000 code-</cell></row><row><cell cols="5">words was testing with only 200 and 500 SURF vectors, because 80 vectors</cell></row><row><cell cols="2">has resulted in very poor accuracy.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,136.46,593.44,321.33,67.92"><head>Table 2 .</head><label>2</label><figDesc>Results of the preliminary testing at 10000 codewords</figDesc><table coords="6,136.46,611.68,321.33,49.68"><row><cell></cell><cell cols="2">number of dimensions: 128</cell><cell cols="2">number of dimensions: 64</cell></row><row><cell></cell><cell>run time (s)</cell><cell>accuracy</cell><cell>run time (s)</cell><cell>accuracy</cell></row><row><cell>vectors: 200</cell><cell>12532</cell><cell>0.611</cell><cell>11179</cell><cell>0.227</cell></row><row><cell>vectors: 500</cell><cell>15791</cell><cell>0.625</cell><cell>13927</cell><cell>0.381</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,147.86,230.99,298.87,301.25"><head>Table 3 .</head><label>3</label><figDesc>Occurrences and NCS (Normalized Counting Score) results at fish species</figDesc><table coords="8,147.86,248.75,296.45,283.49"><row><cell>Fish species ID</cell><cell>Occurrences in</cell><cell>BME TMIT</cell><cell>BME TMIT</cell></row><row><cell>(identifier)</cell><cell>the test set</cell><cell>RUN1</cell><cell>RUN2</cell></row><row><cell>1</cell><cell>93</cell><cell>0.00</cell><cell>0.05</cell></row><row><cell>2</cell><cell>129</cell><cell>0.03</cell><cell>0.12</cell></row><row><cell>3</cell><cell>517</cell><cell>0.21</cell><cell>0.29</cell></row><row><cell>4</cell><cell>1876</cell><cell>0.07</cell><cell>0.19</cell></row><row><cell>5</cell><cell>0</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>6</cell><cell>1317</cell><cell>0.42</cell><cell>0.58</cell></row><row><cell>7</cell><cell>24</cell><cell>0.08</cell><cell>0.19</cell></row><row><cell>8</cell><cell>1985</cell><cell>0.43</cell><cell>0.59</cell></row><row><cell>9</cell><cell>5016</cell><cell>0.02</cell><cell>0.05</cell></row><row><cell>10</cell><cell>0</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell>11</cell><cell>118</cell><cell>0.02</cell><cell>0.09</cell></row><row><cell>12</cell><cell>1531</cell><cell>0.34</cell><cell>0.38</cell></row><row><cell>13</cell><cell>0</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell>14</cell><cell>700</cell><cell>0.00</cell><cell>0.03</cell></row><row><cell>15</cell><cell>187</cell><cell>0.83</cell><cell>0.86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,137.18,149.27,318.80,73.68"><head>Table 4 .</head><label>4</label><figDesc>Our final official results</figDesc><table coords="9,137.18,166.91,318.80,56.04"><row><cell>Run identifier</cell><cell>Counting score</cell><cell>Precision</cell><cell>Normalized Counting</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Score</cell></row><row><cell>BME TMIT RUN1</cell><cell>0.62</cell><cell>0.44</cell><cell>0.27</cell></row><row><cell>BME TMIT RUN2</cell><cell>0.67</cell><cell>0.51</cell><cell>0.34</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,132.67,176.15,338.04,9.00;10,141.74,187.19,328.99,9.00;10,141.74,198.23,89.40,9.00" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,203.69,187.19,267.04,9.00;10,141.74,198.23,43.34,9.00">LifeCLEF 2015: multimedia life species identification challenges, Proceedings of CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,209.15,337.63,9.00;10,141.74,220.19,328.87,9.00;10,141.74,231.23,328.93,9.00;10,141.74,242.15,157.54,9.00" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,251.19,231.23,185.60,9.00">General Overview of ImageCLEF at CLEF2015 Labs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Aldana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M R</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="10,443.71,231.23,26.96,9.00;10,141.74,242.15,95.71,9.00">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,253.19,338.08,9.00;10,141.74,264.23,97.80,9.00" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,302.81,253.19,142.67,9.00">LifeCLEF Fish Identification Task 2015</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,453.79,253.19,16.97,9.00;10,141.74,264.23,51.72,9.00">CLEF working notes</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,275.15,337.83,9.00;10,141.74,286.22,329.11,9.00;10,141.74,297.26,231.02,9.00" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,281.45,275.15,189.05,9.00;10,141.74,286.22,172.71,9.00">An Improved Adaptive Background Mixture Model for Real-time Tracking with Shadow Detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kaewtrakulpong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,330.76,286.22,140.09,9.00;10,141.74,297.26,148.19,9.00">Proc. 2nd European Workshop on Advanced Video Based Surveillance Systems</title>
		<meeting>2nd European Workshop on Advanced Video Based Surveillance Systems<address><addrLine>AVBS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">Sept (2001</date>
			<biblScope unit="volume">01</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,308.18,338.03,9.00;10,141.74,319.22,210.28,9.00" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Perkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Wolfart</surname></persName>
		</author>
		<ptr target="http://homepages.inf.ed.ac.uk/rbf/HIPR2/matmorph.htm" />
		<title level="m" coord="10,336.91,308.18,99.91,9.00">Mathematical Morphology</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,330.26,338.06,9.00;10,141.74,341.18,311.06,9.00" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,229.00,330.26,241.73,9.00;10,141.74,341.18,47.97,9.00">Topological Structural Analysis of Digitized Binary Images by Border Following</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,195.50,341.18,179.04,9.00">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="46" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,352.22,320.71,9.00;10,141.74,363.26,141.01,9.00" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,193.70,352.22,217.43,9.00">A New Approach to Linear Filtering and Prediction Problems</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,417.43,352.22,35.95,9.00;10,141.74,363.26,62.79,9.00">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,374.18,303.69,9.00" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,189.86,374.18,47.39,9.00">Kalman Filter</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">F</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,242.45,374.18,129.86,9.00">Computer Vision: A Reference Guide</title>
		<imprint>
			<biblScope unit="page" from="435" to="437" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.67,385.22,338.02,9.00;10,141.74,396.26,113.04,9.00" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,190.22,385.22,187.54,9.00">The Hungarian method for the assignment problem</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,384.55,385.22,86.14,9.00;10,141.74,396.26,32.27,9.00">Naval research logistics quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,407.18,338.44,9.00;10,141.74,418.22,102.00,9.00" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,179.66,407.18,202.94,9.00">On Kuhn&apos;s Hungarian method-a tribute from Hungary</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,389.59,407.18,81.14,9.00;10,141.74,418.22,32.85,9.00">Naval Research Logistics (NRL)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="5" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,429.26,311.30,9.00;10,443.59,426.95,5.12,6.00;10,451.15,429.26,19.58,9.00;10,141.74,440.18,162.72,9.00" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,303.65,429.26,129.15,9.00">SURF: Speeded Up Robust Features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,439.03,429.26,4.56,9.00;10,443.59,426.95,5.12,6.00;10,451.15,429.26,19.58,9.00;10,141.74,440.18,133.46,9.00">9 th European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,451.22,298.31,9.00" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,177.70,451.22,193.22,9.00">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,388.03,451.22,16.77,9.00">ICCV</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,462.26,338.39,9.00;10,141.74,473.20,191.88,9.00" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,194.49,462.26,220.42,9.00">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,423.05,462.26,47.63,9.00;10,141.74,473.20,96.97,9.00">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,484.24,338.36,9.00;10,141.74,495.28,325.97,9.00" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,288.89,484.24,160.06,9.00">Recognizing and Learning Object Categories</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,455.23,484.24,15.43,9.00;10,141.74,495.28,296.35,9.00">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,506.20,337.98,9.00;10,141.74,517.24,328.99,9.00;10,141.74,528.28,281.76,9.00" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,281.50,506.20,188.78,9.00;10,141.74,517.24,153.10,9.00">Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,301.81,517.24,168.92,9.00;10,141.74,528.28,132.66,9.00">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,539.20,338.03,9.00;10,141.74,550.24,328.97,9.00;10,141.74,561.28,94.80,9.00" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,196.79,539.20,269.74,9.00">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,141.74,550.24,325.48,9.00">Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,572.20,338.37,9.00;10,141.74,583.24,325.22,9.00" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,260.57,572.20,185.45,9.00">A Training Algorithm for Optimal Margin Classifier</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,451.97,572.20,18.69,9.00;10,141.74,583.24,249.65,9.00">Proc. of the 5th Annual ACM Workshop on Computational Learning Theory</title>
		<meeting>of the 5th Annual ACM Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.29,594.28,338.25,9.00;10,141.74,605.20,55.89,9.00" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,228.17,594.28,91.09,9.00">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,326.83,594.28,65.65,9.00">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
